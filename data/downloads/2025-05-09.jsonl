{"created":"2025-05-09","title":"How Social is It? A Benchmark for LLMs' Capabilities in Multi-user Multi-turn Social Agent Tasks","abstract":"Expanding the application of large language models (LLMs) to societal life, instead of primary function only as auxiliary assistants to communicate with only one person at a time, necessitates LLMs' capabilities to independently play roles in multi-user, multi-turn social agent tasks within complex social settings. However, currently the capability has not been systematically measured with available benchmarks. To address this gap, we first introduce an agent task leveling framework grounded in sociological principles. Concurrently, we propose a novel benchmark, How Social Is It (we call it HSII below), designed to assess LLM's social capabilities in comprehensive social agents tasks and benchmark representative models. HSII comprises four stages: format parsing, target selection, target switching conversation, and stable conversation, which collectively evaluate the communication and task completion capabilities of LLMs within realistic social interaction scenarios dataset, HSII-Dataset. The dataset is derived step by step from news dataset. We perform an ablation study by doing clustering to the dataset. Additionally, we investigate the impact of chain of thought (COT) method on enhancing LLMs' social performance. Since COT cost more computation, we further introduce a new statistical metric, COT-complexity, to quantify the efficiency of certain LLMs with COTs for specific social tasks and strike a better trade-off between measurement of correctness and efficiency. Various results of our experiments demonstrate that our benchmark is well-suited for evaluating social skills in LLMs.","authors":["Yusen Wu","Junwu Xiong","Xiaotie Deng"],"url":"https://arxiv.org/abs/2505.04628"}
{"created":"2025-05-09","title":"MatMMFuse: Multi-Modal Fusion model for Material Property Prediction","abstract":"The recent progress of using graph based encoding of crystal structures for high throughput material property prediction has been quite successful. However, using a single modality model prevents us from exploiting the advantages of an enhanced features space by combining different representations. Specifically, pre-trained Large language models(LLMs) can encode a large amount of knowledge which is beneficial for training of models. Moreover, the graph encoder is able to learn the local features while the text encoder is able to learn global information such as space group and crystal symmetry. In this work, we propose Material Multi-Modal Fusion(MatMMFuse), a fusion based model which uses a multi-head attention mechanism for the combination of structure aware embedding from the Crystal Graph Convolution Network (CGCNN) and text embeddings from the SciBERT model. We train our model in an end-to-end framework using data from the Materials Project Dataset. We show that our proposed model shows an improvement compared to the vanilla CGCNN and SciBERT model for all four key properties: formation energy, band gap, energy above hull and fermi energy. Specifically, we observe an improvement of 40% compared to the vanilla CGCNN model and 68% compared to the SciBERT model for predicting the formation energy per atom. Importantly, we demonstrate the zero shot performance of the trained model on small curated datasets of Perovskites, Chalcogenides and the Jarvis Dataset. The results show that the proposed model exhibits better zero shot performance than the individual plain vanilla CGCNN and SciBERT model. This enables researchers to deploy the model for specialized industrial applications where collection of training data is prohibitively expensive.","authors":["Abhiroop Bhattacharya","Sylvain G. Cloutier"],"url":"https://arxiv.org/abs/2505.04634"}
{"created":"2025-05-09","title":"Adaptive Token Boundaries: Integrating Human Chunking Mechanisms into Multimodal LLMs","abstract":"Recent advancements in multimodal large language models (MLLMs) have demonstrated remarkable capabilities in processing diverse data types, yet significant disparities persist between human cognitive processes and computational approaches to multimodal information integration. This research presents a systematic investigation into the parallels between human cross-modal chunking mechanisms and token representation methodologies in MLLMs. Through empirical studies comparing human performance patterns with model behaviors across visual-linguistic tasks, we demonstrate that conventional static tokenization schemes fundamentally constrain current models' capacity to simulate the dynamic, context-sensitive nature of human information processing. We propose a novel framework for dynamic cross-modal tokenization that incorporates adaptive boundaries, hierarchical representations, and alignment mechanisms grounded in cognitive science principles. Quantitative evaluations demonstrate that our approach yields statistically significant improvements over state-of-the-art models on benchmark tasks (+7.8% on Visual Question Answering, +5.3% on Complex Scene Description) while exhibiting more human-aligned error patterns and attention distributions. These findings contribute to the theoretical understanding of the relationship between human cognition and artificial intelligence, while providing empirical evidence for developing more cognitively plausible AI systems.","authors":["Dongxing Yu"],"url":"https://arxiv.org/abs/2505.04637"}
{"created":"2025-05-09","title":"Towards Artificial Intelligence Research Assistant for Expert-Involved Learning","abstract":"Large Language Models (LLMs) and Large Multi-Modal Models (LMMs) have emerged as transformative tools in scientific research, yet their reliability and specific contributions to biomedical applications remain insufficiently characterized. In this study, we present \\textbf{AR}tificial \\textbf{I}ntelligence research assistant for \\textbf{E}xpert-involved \\textbf{L}earning (ARIEL), a multimodal dataset designed to benchmark and enhance two critical capabilities of LLMs and LMMs in biomedical research: summarizing extensive scientific texts and interpreting complex biomedical figures. To facilitate rigorous assessment, we create two open-source sets comprising biomedical articles and figures with designed questions. We systematically benchmark both open- and closed-source foundation models, incorporating expert-driven human evaluations conducted by doctoral-level experts. Furthermore, we improve model performance through targeted prompt engineering and fine-tuning strategies for summarizing research papers, and apply test-time computational scaling to enhance the reasoning capabilities of LMMs, achieving superior accuracy compared to human-expert corrections. We also explore the potential of using LMM Agents to generate scientific hypotheses from diverse multimodal inputs. Overall, our results delineate clear strengths and highlight significant limitations of current foundation models, providing actionable insights and guiding future advancements in deploying large-scale language and multi-modal models within biomedical research.","authors":["Tianyu Liu","Simeng Han","Xiao Luo","Hanchen Wang","Pan Lu","Biqing Zhu","Yuge Wang","Keyi Li","Jiapeng Chen","Rihao Qu","Yufeng Liu","Xinyue Cui","Aviv Yaish","Yuhang Chen","Minsheng Hao","Chuhan Li","Kexing Li","Arman Cohan","Hua Xu","Mark Gerstein","James Zou","Hongyu Zhao"],"url":"https://arxiv.org/abs/2505.04638"}
{"created":"2025-05-09","title":"Language translation, and change of accent for speech-to-speech task using diffusion model","abstract":"Speech-to-speech translation (S2ST) aims to convert spoken input in one language to spoken output in another, typically focusing on either language translation or accent adaptation. However, effective cross-cultural communication requires handling both aspects simultaneously - translating content while adapting the speaker's accent to match the target language context. In this work, we propose a unified approach for simultaneous speech translation and change of accent, a task that remains underexplored in current literature. Our method reformulates the problem as a conditional generation task, where target speech is generated based on phonemes and guided by target speech features. Leveraging the power of diffusion models, known for high-fidelity generative capabilities, we adapt text-to-image diffusion strategies by conditioning on source speech transcriptions and generating Mel spectrograms representing the target speech with desired linguistic and accentual attributes. This integrated framework enables joint optimization of translation and accent adaptation, offering a more parameter-efficient and effective model compared to traditional pipelines.","authors":["Abhishek Mishra","Ritesh Sur Chowdhury","Vartul Bahuguna","Isha Pandey","Ganesh Ramakrishnan"],"url":"https://arxiv.org/abs/2505.04639"}
{"created":"2025-05-09","title":"A Comparative Benchmark of a Moroccan Darija Toxicity Detection Model (Typica.ai) and Major LLM-Based Moderation APIs (OpenAI, Mistral, Anthropic)","abstract":"This paper presents a comparative benchmark evaluating the performance of Typica.ai's custom Moroccan Darija toxicity detection model against major LLM-based moderation APIs: OpenAI (omni-moderation-latest), Mistral (mistral-moderation-latest), and Anthropic Claude (claude-3-haiku-20240307). We focus on culturally grounded toxic content, including implicit insults, sarcasm, and culturally specific aggression often overlooked by general-purpose systems. Using a balanced test set derived from the OMCD_Typica.ai_Mix dataset, we report precision, recall, F1-score, and accuracy, offering insights into challenges and opportunities for moderation in underrepresented languages. Our results highlight Typica.ai's superior performance, underlining the importance of culturally adapted models for reliable content moderation.","authors":["Hicham Assoudi"],"url":"https://arxiv.org/abs/2505.04640"}
{"created":"2025-05-09","title":"Rethinking Multimodal Sentiment Analysis: A High-Accuracy, Simplified Fusion Architecture","abstract":"Multimodal sentiment analysis, a pivotal task in affective computing, seeks to understand human emotions by integrating cues from language, audio, and visual signals. While many recent approaches leverage complex attention mechanisms and hierarchical architectures, we propose a lightweight, yet effective fusion-based deep learning model tailored for utterance-level emotion classification. Using the benchmark IEMOCAP dataset, which includes aligned text, audio-derived numeric features, and visual descriptors, we design a modality-specific encoder using fully connected layers followed by dropout regularization. The modality-specific representations are then fused using simple concatenation and passed through a dense fusion layer to capture cross-modal interactions. This streamlined architecture avoids computational overhead while preserving performance, achieving a classification accuracy of 92% across six emotion categories. Our approach demonstrates that with careful feature engineering and modular design, simpler fusion strategies can outperform or match more complex models, particularly in resource-constrained environments.","authors":["Nischal Mandal","Yang Li"],"url":"https://arxiv.org/abs/2505.04642"}
{"created":"2025-05-09","title":"Prediction-powered estimators for finite population statistics in highly imbalanced textual data: Public hate crime estimation","abstract":"Estimating population parameters in finite populations of text documents can be challenging when obtaining the labels for the target variable requires manual annotation. To address this problem, we combine predictions from a transformer encoder neural network with well-established survey sampling estimators using the model predictions as an auxiliary variable. The applicability is demonstrated in Swedish hate crime statistics based on Swedish police reports. Estimates of the yearly number of hate crimes and the police's under-reporting are derived using the Hansen-Hurwitz estimator, difference estimation, and stratified random sampling estimation. We conclude that if labeled training data is available, the proposed method can provide very efficient estimates with reduced time spent on manual annotation.","authors":["Hannes Waldetoft","Jakob Torgander","M{\\aa}ns Magnusson"],"url":"https://arxiv.org/abs/2505.04643"}
{"created":"2025-05-09","title":"ChatGPT for automated grading of short answer questions in mechanical ventilation","abstract":"Standardised tests using short answer questions (SAQs) are common in postgraduate education. Large language models (LLMs) simulate conversational language and interpret unstructured free-text responses in ways aligning with applying SAQ grading rubrics, making them attractive for automated grading. We evaluated ChatGPT 4o to grade SAQs in a postgraduate medical setting using data from 215 students (557 short-answer responses) enrolled in an online course on mechanical ventilation (2020--2024). Deidentified responses to three case-based scenarios were presented to ChatGPT with a standardised grading prompt and rubric. Outputs were analysed using mixed-effects modelling, variance component analysis, intraclass correlation coefficients (ICCs), Cohen's kappa, Kendall's W, and Bland--Altman statistics. ChatGPT awarded systematically lower marks than human graders with a mean difference (bias) of -1.34 on a 10-point scale. ICC values indicated poor individual-level agreement (ICC1 = 0.086), and Cohen's kappa (-0.0786) suggested no meaningful agreement. Variance component analysis showed minimal variability among the five ChatGPT sessions (G-value = 0.87), indicating internal consistency but divergence from the human grader. The poorest agreement was observed for evaluative and analytic items, whereas checklist and prescriptive rubric items had less disagreement. We caution against the use of LLMs in grading postgraduate coursework. Over 60% of ChatGPT-assigned grades differed from human grades by more than acceptable boundaries for high-stakes assessments.","authors":["Tejas Jade","Alex Yartsev"],"url":"https://arxiv.org/abs/2505.04645"}
{"created":"2025-05-09","title":"Computational Irreducibility as the Foundation of Agency: A Formal Model Connecting Undecidability to Autonomous Behavior in Complex Systems","abstract":"This article explores the emergence of autonomy and agency by connecting fundamental computational limits (decidability, completeness, computational irreducibility) with physical concepts. We introduce a formal model of a \"minimal agent\" operating within potentially Turing-complete environments. Using algorithmic information theory, we argue that the inherent undecidability and computational irreducibility of agent-environment interaction lead to unpredictability and novel information generation, enabling agency (effective goal-directed action). Computational irreducibility prevents full external prediction, creating necessary conditions for autonomous behavior. We relate this to computational sourcehood, where an agent is the irreducible origin of its behavior, though formalizing this concept remains challenging. Our central thesis, formally proven, is that genuine autonomy necessarily implies undecidability from an external perspective, distinguishing autonomous systems from predictable ones. We propose that agency arises when agent-environment coupling complexity allows mutual information between internal states and relevant environmental variables to increase, particularly where analytical solutions are absent and operational closure is needed for persistence. This framework links agency directly to the computational properties of interaction, offering implications for understanding consciousness, designing autonomous AI, and reconceptualizing free will in a deterministic yet computationally irreducible universe.","authors":["Poria Azadi"],"url":"https://arxiv.org/abs/2505.04646"}
{"created":"2025-05-09","title":"ChannelExplorer: Exploring Class Separability Through Activation Channel Visualization","abstract":"Deep neural networks (DNNs) achieve state-of-the-art performance in many vision tasks, yet understanding their internal behavior remains challenging, particularly how different layers and activation channels contribute to class separability. We introduce ChannelExplorer, an interactive visual analytics tool for analyzing image-based outputs across model layers, emphasizing data-driven insights over architecture analysis for exploring class separability. ChannelExplorer summarizes activations across layers and visualizes them using three primary coordinated views: a Scatterplot View to reveal inter- and intra-class confusion, a Jaccard Similarity View to quantify activation overlap, and a Heatmap View to inspect activation channel patterns. Our technique supports diverse model architectures, including CNNs, GANs, ResNet and Stable Diffusion models. We demonstrate the capabilities of ChannelExplorer through four use-case scenarios: (1) generating class hierarchy in ImageNet, (2) finding mislabeled images, (3) identifying activation channel contributions, and(4) locating latent states' position in Stable Diffusion model. Finally, we evaluate the tool with expert users.","authors":["Md Rahat-uz- Zaman","Bei Wang","Paul Rosen"],"url":"https://arxiv.org/abs/2505.04647"}
{"created":"2025-05-09","title":"FRAME: Feedback-Refined Agent Methodology for Enhancing Medical Research Insights","abstract":"The automation of scientific research through large language models (LLMs) presents significant opportunities but faces critical challenges in knowledge synthesis and quality assurance. We introduce Feedback-Refined Agent Methodology (FRAME), a novel framework that enhances medical paper generation through iterative refinement and structured feedback. Our approach comprises three key innovations: (1) A structured dataset construction method that decomposes 4,287 medical papers into essential research components through iterative refinement; (2) A tripartite architecture integrating Generator, Evaluator, and Reflector agents that progressively improve content quality through metric-driven feedback; and (3) A comprehensive evaluation framework that combines statistical metrics with human-grounded benchmarks. Experimental results demonstrate FRAME's effectiveness, achieving significant improvements over conventional approaches across multiple models (9.91% average gain with DeepSeek V3, comparable improvements with GPT-4o Mini) and evaluation dimensions. Human evaluation confirms that FRAME-generated papers achieve quality comparable to human-authored works, with particular strength in synthesizing future research directions. The results demonstrated our work could efficiently assist medical research by building a robust foundation for automated medical research paper generation while maintaining rigorous academic standards.","authors":["Chengzhang Yu","Yiming Zhang","Zhixin Liu","Zenghui Ding","Yining Sun","Zhanpeng Jin"],"url":"https://arxiv.org/abs/2505.04649"}
{"created":"2025-05-09","title":"Multimodal Benchmarking and Recommendation of Text-to-Image Generation Models","abstract":"This work presents an open-source unified benchmarking and evaluation framework for text-to-image generation models, with a particular focus on the impact of metadata augmented prompts. Leveraging the DeepFashion-MultiModal dataset, we assess generated outputs through a comprehensive set of quantitative metrics, including Weighted Score, CLIP (Contrastive Language Image Pre-training)-based similarity, LPIPS (Learned Perceptual Image Patch Similarity), FID (Frechet Inception Distance), and retrieval-based measures, as well as qualitative analysis. Our results demonstrate that structured metadata enrichments greatly enhance visual realism, semantic fidelity, and model robustness across diverse text-to-image architectures. While not a traditional recommender system, our framework enables task-specific recommendations for model selection and prompt design based on evaluation metrics.","authors":["Kapil Wanaskar","Gaytri Jena","Magdalini Eirinaki"],"url":"https://arxiv.org/abs/2505.04650"}
{"created":"2025-05-09","title":"Scientific Hypothesis Generation and Validation: Methods, Datasets, and Future Directions","abstract":"Large Language Models (LLMs) are transforming scientific hypothesis generation and validation by enabling information synthesis, latent relationship discovery, and reasoning augmentation. This survey provides a structured overview of LLM-driven approaches, including symbolic frameworks, generative models, hybrid systems, and multi-agent architectures. We examine techniques such as retrieval-augmented generation, knowledge-graph completion, simulation, causal inference, and tool-assisted reasoning, highlighting trade-offs in interpretability, novelty, and domain alignment. We contrast early symbolic discovery systems (e.g., BACON, KEKADA) with modern LLM pipelines that leverage in-context learning and domain adaptation via fine-tuning, retrieval, and symbolic grounding. For validation, we review simulation, human-AI collaboration, causal modeling, and uncertainty quantification, emphasizing iterative assessment in open-world contexts. The survey maps datasets across biomedicine, materials science, environmental science, and social science, introducing new resources like AHTech and CSKG-600. Finally, we outline a roadmap emphasizing novelty-aware generation, multimodal-symbolic integration, human-in-the-loop systems, and ethical safeguards, positioning LLMs as agents for principled, scalable scientific discovery.","authors":["Adithya Kulkarni","Fatimah Alotaibi","Xinyue Zeng","Longfeng Wu","Tong Zeng","Barry Menglong Yao","Minqian Liu","Shuaicheng Zhang","Lifu Huang","Dawei Zhou"],"url":"https://arxiv.org/abs/2505.04651"}
{"created":"2025-05-09","title":"Advancing Conversational Diagnostic AI with Multimodal Reasoning","abstract":"Large Language Models (LLMs) have demonstrated great potential for conducting diagnostic conversations but evaluation has been largely limited to language-only interactions, deviating from the real-world requirements of remote care delivery. Instant messaging platforms permit clinicians and patients to upload and discuss multimodal medical artifacts seamlessly in medical consultation, but the ability of LLMs to reason over such data while preserving other attributes of competent diagnostic conversation remains unknown. Here we advance the conversational diagnosis and management performance of the Articulate Medical Intelligence Explorer (AMIE) through a new capability to gather and interpret multimodal data, and reason about this precisely during consultations. Leveraging Gemini 2.0 Flash, our system implements a state-aware dialogue framework, where conversation flow is dynamically controlled by intermediate model outputs reflecting patient states and evolving diagnoses. Follow-up questions are strategically directed by uncertainty in such patient states, leading to a more structured multimodal history-taking process that emulates experienced clinicians. We compared AMIE to primary care physicians (PCPs) in a randomized, blinded, OSCE-style study of chat-based consultations with patient actors. We constructed 105 evaluation scenarios using artifacts like smartphone skin photos, ECGs, and PDFs of clinical documents across diverse conditions and demographics. Our rubric assessed multimodal capabilities and other clinically meaningful axes like history-taking, diagnostic accuracy, management reasoning, communication, and empathy. Specialist evaluation showed AMIE to be superior to PCPs on 7/9 multimodal and 29/32 non-multimodal axes (including diagnostic accuracy). The results show clear progress in multimodal conversational diagnostic AI, but real-world translation needs further research.","authors":["Khaled Saab","Jan Freyberg","Chunjong Park","Tim Strother","Yong Cheng","Wei-Hung Weng","David G. T. Barrett","David Stutz","Nenad Tomasev","Anil Palepu","Valentin Li\\'evin","Yash Sharma","Roma Ruparel","Abdullah Ahmed","Elahe Vedadi","Kimberly Kanada","Cian Hughes","Yun Liu","Geoff Brown","Yang Gao","Sean Li","S. Sara Mahdavi","James Manyika","Katherine Chou","Yossi Matias","Avinatan Hassidim","Dale R. Webster","Pushmeet Kohli","S. M. Ali Eslami","Jo\\\"elle Barral","Adam Rodman","Vivek Natarajan","Mike Schaekermann","Tao Tu","Alan Karthikesalingam","Ryutaro Tanno"],"url":"https://arxiv.org/abs/2505.04653"}
{"created":"2025-05-09","title":"A Comparative Analysis of Ethical and Safety Gaps in LLMs using Relative Danger Coefficient","abstract":"Artificial Intelligence (AI) and Large Language Models (LLMs) have rapidly evolved in recent years, showcasing remarkable capabilities in natural language understanding and generation. However, these advancements also raise critical ethical questions regarding safety, potential misuse, discrimination and overall societal impact. This article provides a comparative analysis of the ethical performance of various AI models, including the brand new DeepSeek-V3(R1 with reasoning and without), various GPT variants (4o, 3.5 Turbo, 4 Turbo, o1/o3 mini) and Gemini (1.5 flash, 2.0 flash and 2.0 flash exp) and highlights the need for robust human oversight, especially in situations with high stakes. Furthermore, we present a new metric for calculating harm in LLMs called Relative Danger Coefficient (RDC).","authors":["Yehor Tereshchenko","Mika H\\\"am\\\"al\\\"ainen"],"url":"https://arxiv.org/abs/2505.04654"}
{"created":"2025-05-09","title":"Integration of Large Language Models and Traditional Deep Learning for Social Determinants of Health Prediction","abstract":"Social Determinants of Health (SDoH) are economic, social and personal circumstances that affect or influence an individual's health status. SDoHs have shown to be correlated to wellness outcomes, and therefore, are useful to physicians in diagnosing diseases and in decision-making. In this work, we automatically extract SDoHs from clinical text using traditional deep learning and Large Language Models (LLMs) to find the advantages and disadvantages of each on an existing publicly available dataset. Our models outperform a previous reference point on a multilabel SDoH classification by 10 points, and we present a method and model to drastically speed up classification (12X execution time) by eliminating expensive LLM processing. The method we present combines a more nimble and efficient solution that leverages the power of the LLM for precision and traditional deep learning methods for efficiency. We also show highly performant results on a dataset supplemented with synthetic data and several traditional deep learning models that outperform LLMs. Our models and methods offer the next iteration of automatic prediction of SDoHs that impact at-risk patients.","authors":["Paul Landes","Jimeng Sun","Adam Cross"],"url":"https://arxiv.org/abs/2505.04655"}
{"created":"2025-05-09","title":"MeshGen: Generating PBR Textured Mesh with Render-Enhanced Auto-Encoder and Generative Data Augmentation","abstract":"In this paper, we introduce MeshGen, an advanced image-to-3D pipeline that generates high-quality 3D meshes with detailed geometry and physically based rendering (PBR) textures. Addressing the challenges faced by existing 3D native diffusion models, such as suboptimal auto-encoder performance, limited controllability, poor generalization, and inconsistent image-based PBR texturing, MeshGen employs several key innovations to overcome these limitations. We pioneer a render-enhanced point-to-shape auto-encoder that compresses meshes into a compact latent space by designing perceptual optimization with ray-based regularization. This ensures that the 3D shapes are accurately represented and reconstructed to preserve geometric details within the latent space. To address data scarcity and image-shape misalignment, we further propose geometric augmentation and generative rendering augmentation techniques, which enhance the model's controllability and generalization ability, allowing it to perform well even with limited public datasets. For the texture generation, MeshGen employs a reference attention-based multi-view ControlNet for consistent appearance synthesis. This is further complemented by our multi-view PBR decomposer that estimates PBR components and a UV inpainter that fills invisible areas, ensuring a seamless and consistent texture across the 3D mesh. Our extensive experiments demonstrate that MeshGen largely outperforms previous methods in both shape and texture generation, setting a new standard for the quality of 3D meshes generated with PBR textures. See our code at https://github.com/heheyas/MeshGen, project page https://heheyas.github.io/MeshGen","authors":["Zilong Chen","Yikai Wang","Wenqiang Sun","Feng Wang","Yiwen Chen","Huaping Liu"],"url":"https://arxiv.org/abs/2505.04656"}
{"created":"2025-05-09","title":"GSsplat: Generalizable Semantic Gaussian Splatting for Novel-view Synthesis in 3D Scenes","abstract":"The semantic synthesis of unseen scenes from multiple viewpoints is crucial for research in 3D scene understanding. Current methods are capable of rendering novel-view images and semantic maps by reconstructing generalizable Neural Radiance Fields. However, they often suffer from limitations in speed and segmentation performance. We propose a generalizable semantic Gaussian Splatting method (GSsplat) for efficient novel-view synthesis. Our model predicts the positions and attributes of scene-adaptive Gaussian distributions from once input, replacing the densification and pruning processes of traditional scene-specific Gaussian Splatting. In the multi-task framework, a hybrid network is designed to extract color and semantic information and predict Gaussian parameters. To augment the spatial perception of Gaussians for high-quality rendering, we put forward a novel offset learning module through group-based supervision and a point-level interaction module with spatial unit aggregation. When evaluated with varying numbers of multi-view inputs, GSsplat achieves state-of-the-art performance for semantic synthesis at the fastest speed.","authors":["Feng Xiao","Hongbin Xu","Wanlin Liang","Wenxiong Kang"],"url":"https://arxiv.org/abs/2505.04659"}
{"created":"2025-05-09","title":"AI-Generated Fall Data: Assessing LLMs and Diffusion Model for Wearable Fall Detection","abstract":"Training fall detection systems is challenging due to the scarcity of real-world fall data, particularly from elderly individuals. To address this, we explore the potential of Large Language Models (LLMs) for generating synthetic fall data. This study evaluates text-to-motion (T2M, SATO, ParCo) and text-to-text models (GPT4o, GPT4, Gemini) in simulating realistic fall scenarios. We generate synthetic datasets and integrate them with four real-world baseline datasets to assess their impact on fall detection performance using a Long Short-Term Memory (LSTM) model. Additionally, we compare LLM-generated synthetic data with a diffusion-based method to evaluate their alignment with real accelerometer distributions. Results indicate that dataset characteristics significantly influence the effectiveness of synthetic data, with LLM-generated data performing best in low-frequency settings (e.g., 20Hz) while showing instability in high-frequency datasets (e.g., 200Hz). While text-to-motion models produce more realistic biomechanical data than text-to-text models, their impact on fall detection varies. Diffusion-based synthetic data demonstrates the closest alignment to real data but does not consistently enhance model performance. An ablation study further confirms that the effectiveness of synthetic data depends on sensor placement and fall representation. These findings provide insights into optimizing synthetic data generation for fall detection models.","authors":["Sana Alamgeer","Yasine Souissi","Anne H. H. Ngu"],"url":"https://arxiv.org/abs/2505.04660"}
{"created":"2025-05-09","title":"Crafting Physical Adversarial Examples by Combining Differentiable and Physically Based Renders","abstract":"Recently we have witnessed progress in hiding road vehicles against object detectors through adversarial camouflage in the digital world. The extension of this technique to the physical world is crucial for testing the robustness of autonomous driving systems. However, existing methods do not show good performances when applied to the physical world. This is partly due to insufficient photorealism in training examples, and lack of proper physical realization methods for camouflage. To generate a robust adversarial camouflage suitable for real vehicles, we propose a novel method called PAV-Camou. We propose to adjust the mapping from the coordinates in the 2D map to those of corresponding 3D model. This process is critical for mitigating texture distortion and ensuring the camouflage's effectiveness when applied in the real world. Then we combine two renderers with different characteristics to obtain adversarial examples that are photorealistic that closely mimic real-world lighting and texture properties. The method ensures that the generated textures remain effective under diverse environmental conditions. Our adversarial camouflage can be optimized and printed in the form of 2D patterns, allowing for direct application on real vehicles. Extensive experiments demonstrated that our proposed method achieved good performance in both the digital world and the physical world.","authors":["Yuqiu Liu","Huanqian Yan","Xiaopei Zhu","Xiaolin Hu","Liang Tang","Hang Su","Chen Lv"],"url":"https://arxiv.org/abs/2505.04662"}
{"created":"2025-05-09","title":"Personalized Risks and Regulatory Strategies of Large Language Models in Digital Advertising","abstract":"Although large language models have demonstrated the potential for personalized advertising recommendations in experimental environments, in actual operations, how advertising recommendation systems can be combined with measures such as user privacy protection and data security is still an area worthy of in-depth discussion. To this end, this paper studies the personalized risks and regulatory strategies of large language models in digital advertising. This study first outlines the principles of Large Language Model (LLM), especially the self-attention mechanism based on the Transformer architecture, and how to enable the model to understand and generate natural language text. Then, the BERT (Bidirectional Encoder Representations from Transformers) model and the attention mechanism are combined to construct an algorithmic model for personalized advertising recommendations and user factor risk protection. The specific steps include: data collection and preprocessing, feature selection and construction, using large language models such as BERT for advertising semantic embedding, and ad recommendations based on user portraits. Then, local model training and data encryption are used to ensure the security of user privacy and avoid the leakage of personal data. This paper designs an experiment for personalized advertising recommendation based on a large language model of BERT and verifies it with real user data. The experimental results show that BERT-based advertising push can effectively improve the click-through rate and conversion rate of advertisements. At the same time, through local model training and privacy protection mechanisms, the risk of user privacy leakage can be reduced to a certain extent.","authors":["Haoyang Feng","Yanjun Dai","Yuan Gao"],"url":"https://arxiv.org/abs/2505.04665"}
{"created":"2025-05-09","title":"Fine-Tuning Large Language Models and Evaluating Retrieval Methods for Improved Question Answering on Building Codes","abstract":"Building codes are regulations that establish standards for the design, construction, and safety of buildings to ensure structural integrity, fire protection, and accessibility. They are often extensive, complex, and subject to frequent updates, making manual querying challenging and time-consuming. Key difficulties include navigating large volumes of text, interpreting technical language, and identifying relevant clauses across different sections. A potential solution is to build a Question-Answering (QA) system that answers user queries based on building codes. Among the various methods for building a QA system, Retrieval-Augmented Generation (RAG) stands out in performance. RAG consists of two components: a retriever and a language model. This study focuses on identifying a suitable retriever method for building codes and optimizing the generational capability of the language model using fine-tuning techniques. We conducted a detailed evaluation of various retrieval methods by performing the retrieval on the National Building Code of Canada (NBCC) and explored the impact of domain-specific fine-tuning on several language models using the dataset derived from NBCC. Our analysis included a comparative assessment of different retrievers and the performance of both pre-trained and fine-tuned models to determine the efficacy and domain-specific adaptation of language models using fine-tuning on the NBCC dataset. Experimental results showed that Elasticsearch proved to be the most robust retriever among all. The findings also indicate that fine-tuning language models on an NBCC-specific dataset can enhance their ability to generate contextually relevant responses. When combined with context retrieved by a powerful retriever like Elasticsearch, this improvement in LLM performance can optimize the RAG system, enabling it to better navigate the complexities of the NBCC.","authors":["Mohammad Aqib","Mohd Hamza","Qipei Mei","Ying Hei Chui"],"url":"https://arxiv.org/abs/2505.04666"}
{"created":"2025-05-09","title":"SGCR: Spherical Gaussians for Efficient 3D Curve Reconstruction","abstract":"Neural rendering techniques have made substantial progress in generating photo-realistic 3D scenes. The latest 3D Gaussian Splatting technique has achieved high quality novel view synthesis as well as fast rendering speed. However, 3D Gaussians lack proficiency in defining accurate 3D geometric structures despite their explicit primitive representations. This is due to the fact that Gaussian's attributes are primarily tailored and fine-tuned for rendering diverse 2D images by their anisotropic nature. To pave the way for efficient 3D reconstruction, we present Spherical Gaussians, a simple and effective representation for 3D geometric boundaries, from which we can directly reconstruct 3D feature curves from a set of calibrated multi-view images. Spherical Gaussians is optimized from grid initialization with a view-based rendering loss, where a 2D edge map is rendered at a specific view and then compared to the ground-truth edge map extracted from the corresponding image, without the need for any 3D guidance or supervision. Given Spherical Gaussians serve as intermedia for the robust edge representation, we further introduce a novel optimization-based algorithm called SGCR to directly extract accurate parametric curves from aligned Spherical Gaussians. We demonstrate that SGCR outperforms existing state-of-the-art methods in 3D edge reconstruction while enjoying great efficiency.","authors":["Xinran Yang","Donghao Ji","Yuanqi Li","Jie Guo","Yanwen Guo","Junyuan Xie"],"url":"https://arxiv.org/abs/2505.04668"}
{"created":"2025-05-09","title":"LLM Code Customization with Visual Results: A Benchmark on TikZ","abstract":"With the rise of AI-based code generation, customizing existing code out of natural language instructions to modify visual results -such as figures or images -has become possible, promising to reduce the need for deep programming expertise. However, even experienced developers can struggle with this task, as it requires identifying relevant code regions (feature location), generating valid code variants, and ensuring the modifications reliably align with user intent. In this paper, we introduce vTikZ, the first benchmark designed to evaluate the ability of Large Language Models (LLMs) to customize code while preserving coherent visual outcomes. Our benchmark consists of carefully curated vTikZ editing scenarios, parameterized ground truths, and a reviewing tool that leverages visual feedback to assess correctness. Empirical evaluation with stateof-the-art LLMs shows that existing solutions struggle to reliably modify code in alignment with visual intent, highlighting a gap in current AI-assisted code editing approaches. We argue that vTikZ opens new research directions for integrating LLMs with visual feedback mechanisms to improve code customization tasks in various domains beyond TikZ, including image processing, art creation, Web design, and 3D modeling.","authors":["Charly Reux (UR","IRISA","INSA Rennes","DiverSe)","Mathieu Acher (UR","CNRS","INSA Rennes","IRISA","DiverSe)","Djamel Eddine Khelladi (DiverSe","UR","CNRS","IRISA)","Olivier Barais (UR","IRISA)","Cl\\'ement Quinton (SPIRALS","UR","CNRS","IRISA)"],"url":"https://arxiv.org/abs/2505.04670"}
{"created":"2025-05-09","title":"Reward-SQL: Boosting Text-to-SQL via Stepwise Reasoning and Process-Supervised Rewards","abstract":"Recent advances in large language models (LLMs) have significantly improved performance on the Text-to-SQL task by leveraging their powerful reasoning capabilities. To enhance accuracy during the reasoning process, external Process Reward Models (PRMs) can be introduced during training and inference to provide fine-grained supervision. However, if misused, PRMs may distort the reasoning trajectory and lead to suboptimal or incorrect SQL generation.To address this challenge, we propose Reward-SQL, a framework that systematically explores how to incorporate PRMs into the Text-to-SQL reasoning process effectively. Our approach follows a \"cold start, then PRM supervision\" paradigm. Specifically, we first train the model to decompose SQL queries into structured stepwise reasoning chains using common table expressions (Chain-of-CTEs), establishing a strong and interpretable reasoning baseline. Then, we investigate four strategies for integrating PRMs, and find that combining PRM as an online training signal (GRPO) with PRM-guided inference (e.g., best-of-N sampling) yields the best results. Empirically, on the BIRD benchmark, Reward-SQL enables models supervised by a 7B PRM to achieve a 13.1% performance gain across various guidance strategies. Notably, our GRPO-aligned policy model based on Qwen2.5-Coder-7B-Instruct achieves 68.9% accuracy on the BIRD development set, outperforming all baseline methods under the same model size. These results demonstrate the effectiveness of Reward-SQL in leveraging reward-based supervision for Text-to-SQL reasoning. Our code is publicly available.","authors":["Yuxin Zhang","Meihao Fan","Ju Fan","Mingyang Yi","Yuyu Luo","Jian Tan","Guoliang Li"],"url":"https://arxiv.org/abs/2505.04671"}
{"created":"2025-05-09","title":"Histo-Miner: Deep Learning based Tissue Features Extraction Pipeline from H&E Whole Slide Images of Cutaneous Squamous Cell Carcinoma","abstract":"Recent advancements in digital pathology have enabled comprehensive analysis of Whole-Slide Images (WSI) from tissue samples, leveraging high-resolution microscopy and computational capabilities. Despite this progress, there is a lack of labeled datasets and open source pipelines specifically tailored for analysis of skin tissue. Here we propose Histo-Miner, a deep learning-based pipeline for analysis of skin WSIs and generate two datasets with labeled nuclei and tumor regions. We develop our pipeline for the analysis of patient samples of cutaneous squamous cell carcinoma (cSCC), a frequent non-melanoma skin cancer. Utilizing the two datasets, comprising 47,392 annotated cell nuclei and 144 tumor-segmented WSIs respectively, both from cSCC patients, Histo-Miner employs convolutional neural networks and vision transformers for nucleus segmentation and classification as well as tumor region segmentation. Performance of trained models positively compares to state of the art with multi-class Panoptic Quality (mPQ) of 0.569 for nucleus segmentation, macro-averaged F1 of 0.832 for nucleus classification and mean Intersection over Union (mIoU) of 0.884 for tumor region segmentation. From these predictions we generate a compact feature vector summarizing tissue morphology and cellular interactions, which can be used for various downstream tasks. Here, we use Histo-Miner to predict cSCC patient response to immunotherapy based on pre-treatment WSIs from 45 patients. Histo-Miner identifies percentages of lymphocytes, the granulocyte to lymphocyte ratio in tumor vicinity and the distances between granulocytes and plasma cells in tumors as predictive features for therapy response. This highlights the applicability of Histo-Miner to clinically relevant scenarios, providing direct interpretation of the classification and insights into the underlying biology.","authors":["Lucas Sanc\\'er\\'e","Carina Lorenz","Doris Helbig","Oana-Diana Persa","Sonja Dengler","Alexander Kreuter","Martim Laimer","Anne Fr\\\"ohlich","Jennifer Landsberg","Johannes Br\\\"agelmann","Katarzyna Bozek"],"url":"https://arxiv.org/abs/2505.04672"}
{"created":"2025-05-09","title":"REVEAL: Multi-turn Evaluation of Image-Input Harms for Vision LLM","abstract":"Vision Large Language Models (VLLMs) represent a significant advancement in artificial intelligence by integrating image-processing capabilities with textual understanding, thereby enhancing user interactions and expanding application domains. However, their increased complexity introduces novel safety and ethical challenges, particularly in multi-modal and multi-turn conversations. Traditional safety evaluation frameworks, designed for text-based, single-turn interactions, are inadequate for addressing these complexities. To bridge this gap, we introduce the REVEAL (Responsible Evaluation of Vision-Enabled AI LLMs) Framework, a scalable and automated pipeline for evaluating image-input harms in VLLMs. REVEAL includes automated image mining, synthetic adversarial data generation, multi-turn conversational expansion using crescendo attack strategies, and comprehensive harm assessment through evaluators like GPT-4o.","authors":["Madhur Jindal","Saurabh Deshpande"],"url":"https://arxiv.org/abs/2505.04673"}
{"created":"2025-05-09","title":"Dynamic Location Search for Identifying Maximum Weighted Independent Sets in Complex Networks","abstract":"While Artificial intelligence (AI), including Generative AI, are effective at generating high-quality traffic data and optimization solutions in intelligent transportation systems (ITSs), these techniques often demand significant training time and computational resources, especially in large-scale and complex scenarios. To address this, we introduce a novel and efficient algorithm for solving the maximum weighted independent set (MWIS) problem, which can be used to model many ITSs applications, such as traffic signal control and vehicle routing. Given the NP-hard nature of the MWIS problem, our proposed algorithm, DynLS, incorporates three key innovations to solve it effectively. First, it uses a scores-based adaptive vertex perturbation (SAVP) technique to accelerate convergence, particularly in sparse graphs. Second, it includes a region location mechanism (RLM) to help escape local optima by dynamically adjusting the search space. Finally, it employs a novel variable neighborhood descent strategy, ComLS, which combines vertex exchange strategies with a reward mechanism to guide the search toward high-quality solutions. Our experimental results demonstrate DynLS's superior performance, consistently delivering high-quality solutions within 1000 seconds. DynLS outperformed five leading algorithms across 360 test instances, achieving the best solution for 350 instances and surpassing the second-best algorithm, Cyclic-Fast, by 177 instances. Moreover, DynLS matched Cyclic-Fast's convergence speed, highlighting its efficiency and practicality. This research represents a significant advancement in heuristic algorithms for the MWIS problem, offering a promising approach to aid AI techniques in optimizing intelligent transportation systems.","authors":["Enqiang Zhu","Chenkai Hao","Chanjuan Liu","Yongsheng Rao"],"url":"https://arxiv.org/abs/2505.04674"}
{"created":"2025-05-09","title":"Proceedings The 13th International Workshop on Theorem proving components for Educational software","abstract":"The ThEdu series pursues the smooth transition from an intuitive way of doing mathematics at secondary school to a more formal approach to the subject in STEM education while favoring software support for this transition by exploiting the power of theorem-proving technologies.  What follows is a brief description of how the present volume contributes to this enterprise.  The 13th International Workshop on Theorem Proving Components for Educational Software (ThEdu'24), was a satellite event of the CADE29, part of IJCAR 2024, Nancy, France. ThEdu'24 was a vibrant workshop, with one invited talk by Jeremy Avigad (Carnegie Mellon University) and 14 submitted talks. An open call for papers was then issued and attracted 9 submissions. Eight of those submissions have been accepted by our reviewers. The resulting revised papers are collected in the present volume. The contributions in this volume are a faithful representation of the wide spectrum of ThEdu, ranging from those more focused on the automated deduction research, not losing track of the possible applications in an educational setting, to those focused on the applications, in educational settings, of automated deduction tools and methods. We, the volume editors, hope that this collection of papers will further promote the development of theorem-proving-based software and that it will allow to improve the mutual understanding between computer scientists, mathematicians, and stakeholders in education. While this volume goes to press, the next edition of the ThEdu workshop is being prepared: ThEdu'25 will be a satellite event of the 30th international Conference on Automated DEduction (CADE-30), July 28th - August 2nd, 2025, Stuttgart, Germany.","authors":["Julien Narboux (University Paris Cit\\'e","France)","Walther Neuper (Johannes Kepler University Linz","Austria)","Pedro Quaresma (University of Coimbra","Portugal)"],"url":"https://arxiv.org/abs/2505.04677"}
{"created":"2025-05-09","title":"Advanced Deep Learning Approaches for Automated Recognition of Cuneiform Symbols","abstract":"This paper presents a thoroughly automated method for identifying and interpreting cuneiform characters via advanced deep-learning algorithms. Five distinct deep-learning models were trained on a comprehensive dataset of cuneiform characters and evaluated according to critical performance metrics, including accuracy and precision. Two models demonstrated outstanding performance and were subsequently assessed using cuneiform symbols from the Hammurabi law acquisition, notably Hammurabi Law 1. Each model effectively recognized the relevant Akkadian meanings of the symbols and delivered precise English translations. Future work will investigate ensemble and stacking approaches to optimize performance, utilizing hybrid architectures to improve detection accuracy and reliability. This research explores the linguistic relationships between Akkadian, an ancient Mesopotamian language, and Arabic, emphasizing their historical and cultural linkages. This study demonstrates the capability of deep learning to decipher ancient scripts by merging computational linguistics with archaeology, therefore providing significant insights for the comprehension and conservation of human history.","authors":["Shahad Elshehaby","Alavikunhu Panthakkan","Hussain Al-Ahmad","Mina Al-Saad"],"url":"https://arxiv.org/abs/2505.04678"}
{"created":"2025-05-09","title":"Retrieval Augmented Generation Evaluation for Health Documents","abstract":"Safe and trustworthy use of Large Language Models (LLM) in the processing of healthcare documents and scientific papers could substantially help clinicians, scientists and policymakers in overcoming information overload and focusing on the most relevant information at a given moment. Retrieval Augmented Generation (RAG) is a promising method to leverage the potential of LLMs while enhancing the accuracy of their outcomes. This report assesses the potentials and shortcomings of such approaches in the automatic knowledge synthesis of different types of documents in the health domain. To this end, it describes: (1) an internally developed proof of concept pipeline that employs state-of-the-art practices to deliver safe and trustable analysis for healthcare documents and scientific papers called RAGEv (Retrieval Augmented Generation Evaluation); (2) a set of evaluation tools for LLM-based document retrieval and generation; (3) a benchmark dataset to verify the accuracy and veracity of the results called RAGEv-Bench. It concludes that careful implementations of RAG techniques could minimize most of the common problems in the use of LLMs for document processing in the health domain, obtaining very high scores both on short yes/no answers and long answers. There is a high potential for incorporating it into the day-to-day work of policy support tasks, but additional efforts are required to obtain a consistent and trustworthy tool.","authors":["Mario Ceresa","Lorenzo Bertolini","Valentin Comte","Nicholas Spadaro","Barbara Raffael","Brigitte Toussaint","Sergio Consoli","Amalia Mu\\~noz Pi\\~neiro","Alex Patak","Maddalena Querci","Tobias Wiesenthal"],"url":"https://arxiv.org/abs/2505.04680"}
{"created":"2025-05-09","title":"Exploring Influence Factors on LLM Suitability for No-Code Development of End User IoT Applications","abstract":"With the increasing popularity of IoT applications, end users demand more personalized and intuitive functionality. A major obstacle for this, however, is that custom IoT functionality today still requires at least some coding skills. To address this, no-code development platforms have been proposed as a solution for empowering non-technical users to create applications. However, such platforms still require a certain level of technical expertise for structuring process steps or defining event-action relations. The advent of LLMs can further enhance no-code platforms by enabling natural language-based interaction, automating of complex tasks, and dynamic code generation. By allowing users to describe their requirements in natural language, LLMs can significantly streamline no-code development. As LLMs vary in performance, architecture, training data used, and the use cases they target, it is still unclear which models are best suited and what are the influence factors determining this fit. In particular, no-code development of IoT applications by non-technical users will have completely different demands on LLMs than, e.g., code generation for more open-ended applications or for supporting professional developers. In this paper, we explore the factors influencing the suitability of LLMs to no-code development of IoT applications. We also examine the role of input prompt language on accuracy and quality of generated applications as well as the influence of LLM training data. By conducting comprehensive experiments with a range of LLMs, we provide valuable insights for optimizing LLM-powered no-code platforms, guiding the selection of the suitable LLMs and their effective application. Our findings contribute to improving the accessibility, efficiency, and user experience of no-code IoT development, ultimately enabling broader adoption of IoT technologies among non-expert users.","authors":["Minghe Wang","Alexandra Kapp","Trever Schirmer","Tobias Pfandzelter","David Bermbach"],"url":"https://arxiv.org/abs/2505.04710"}
{"created":"2025-05-09","title":"Investigating the Impact and Student Perceptions of Guided Parsons Problems for Learning Logic with Subgoals","abstract":"Parsons problems (PPs) have shown promise in structured problem solving by providing scaffolding that decomposes the problem and requires learners to reconstruct the solution. However, some students face difficulties when first learning with PPs or solving more complex Parsons problems. This study introduces Guided Parsons problems (GPPs) designed to provide step-specific hints and improve learning outcomes in an intelligent logic tutor. In a controlled experiment with 76 participants, GPP students achieved significantly higher accuracy of rule application in both level-end tests and post-tests, with the strongest gains among students with lower prior knowledge. GPP students initially spent more time in training (1.52 vs. 0.81 hours) but required less time for post-tests, indicating improved problem solving efficiency. Our thematic analysis of GPP student self-explanations revealed task decomposition, better rule understanding, and reduced difficulty as key themes, while some students felt the structured nature of GPPs restricted their own way of reasoning. These findings reinforce that GPPs can effectively combine the benefits of worked examples and problem solving practice, but could be further improved by individual adaptation.","authors":["Sutapa Dey Tithi","Xiaoyi Tian","Min Chi","Tiffany Barnes"],"url":"https://arxiv.org/abs/2505.04712"}
{"created":"2025-05-09","title":"Comparison of Visual Trackers for Biomechanical Analysis of Running","abstract":"Human pose estimation has witnessed significant advancements in recent years, mainly due to the integration of deep learning models, the availability of a vast amount of data, and large computational resources. These developments have led to highly accurate body tracking systems, which have direct applications in sports analysis and performance evaluation.","authors":["Luis F. Gomez","Gonzalo Garrido-Lopez","Julian Fierrez","Aythami Morales","Ruben Tolosana","Javier Rueda","Enrique Navarro"],"url":"https://arxiv.org/abs/2505.04713"}
{"created":"2025-05-09","title":"Big Data Architecture for Large Organizations","abstract":"The exponential growth of big data has transformed how large organisations leverage information to drive innovation, optimise processes, and maintain competitive advantages. However, managing and extracting insights from vast, heterogeneous data sources requires a scalable, secure, and well-integrated big data architecture. This paper proposes a comprehensive big data framework that aligns with organisational objectives while ensuring flexibility, scalability, and governance. The architecture encompasses multiple layers, including data ingestion, transformation, storage, analytics, machine learning, and security, incorporating emerging technologies such as Generative AI (GenAI) and low-code machine learning. Cloud-based implementations across Google Cloud, AWS, and Microsoft Azure are analysed, highlighting their tools and capabilities. Additionally, this study explores advancements in big data architecture, including AI-driven automation, data mesh, and Data Ocean paradigms. By establishing a structured, adaptable framework, this research provides a foundational blueprint for large organisations to harness big data as a strategic asset effectively.","authors":["Fathima Nuzla Ismail","Abira Sengupta","Shanika Amarasoma"],"url":"https://arxiv.org/abs/2505.04717"}
{"created":"2025-05-09","title":"Lay-Your-Scene: Natural Scene Layout Generation with Diffusion Transformers","abstract":"We present Lay-Your-Scene (shorthand LayouSyn), a novel text-to-layout generation pipeline for natural scenes. Prior scene layout generation methods are either closed-vocabulary or use proprietary large language models for open-vocabulary generation, limiting their modeling capabilities and broader applicability in controllable image generation. In this work, we propose to use lightweight open-source language models to obtain scene elements from text prompts and a novel aspect-aware diffusion Transformer architecture trained in an open-vocabulary manner for conditional layout generation. Extensive experiments demonstrate that LayouSyn outperforms existing methods and achieves state-of-the-art performance on challenging spatial and numerical reasoning benchmarks. Additionally, we present two applications of LayouSyn. First, we show that coarse initialization from large language models can be seamlessly combined with our method to achieve better results. Second, we present a pipeline for adding objects to images, demonstrating the potential of LayouSyn in image editing applications.","authors":["Divyansh Srivastava","Xiang Zhang","He Wen","Chenru Wen","Zhuowen Tu"],"url":"https://arxiv.org/abs/2505.04718"}
{"created":"2025-05-09","title":"False Promises in Medical Imaging AI? Assessing Validity of Outperformance Claims","abstract":"Performance comparisons are fundamental in medical imaging Artificial Intelligence (AI) research, often driving claims of superiority based on relative improvements in common performance metrics. However, such claims frequently rely solely on empirical mean performance. In this paper, we investigate whether newly proposed methods genuinely outperform the state of the art by analyzing a representative cohort of medical imaging papers. We quantify the probability of false claims based on a Bayesian approach that leverages reported results alongside empirically estimated model congruence to estimate whether the relative ranking of methods is likely to have occurred by chance. According to our results, the majority (>80%) of papers claims outperformance when introducing a new method. Our analysis further revealed a high probability (>5%) of false outperformance claims in 86% of classification papers and 53% of segmentation papers. These findings highlight a critical flaw in current benchmarking practices: claims of outperformance in medical imaging AI are frequently unsubstantiated, posing a risk of misdirecting future research efforts.","authors":["Evangelia Christodoulou","Annika Reinke","Pascaline Andr\\`e","Patrick Godau","Piotr Kalinowski","Rola Houhou","Selen Erkan","Carole H. Sudre","Ninon Burgos","Sofi\\`ene Boutaj","Sophie Loizillon","Ma\\\"elys Solal","Veronika Cheplygina","Charles Heitz","Michal Kozubek","Michela Antonelli","Nicola Rieke","Antoine Gilson","Leon D. Mayer","Minu D. Tizabi","M. Jorge Cardoso","Amber Simpson","Annette Kopp-Schneider","Ga\\\"el Varoquaux","Olivier Colliot","Lena Maier-Hein"],"url":"https://arxiv.org/abs/2505.04720"}
{"created":"2025-05-09","title":"Fitts' List Revisited: An Empirical Study on Function Allocation in a Two-Agent Physical Human-Robot Collaborative Position/Force Task","abstract":"In this letter, we investigate whether the classical function allocation holds for physical Human-Robot Collaboration, which is important for providing insights for Industry 5.0 to guide how to best augment rather than replace workers. This study empirically tests the applicability of Fitts' List within physical Human-Robot Collaboration, by conducting a user study (N=26, within-subject design) to evaluate four distinct allocations of position/force control between human and robot in an abstract blending task. We hypothesize that the function in which humans control the position achieves better performance and receives higher user ratings. When allocating position control to the human and force control to the robot, compared to the opposite case, we observed a significant improvement in preventing overblending. This was also perceived better in terms of physical demand and overall system acceptance, while participants experienced greater autonomy, more engagement and less frustration. An interesting insight was that the supervisory role (when the robot controls both position and force control) was rated second best in terms of subjective acceptance. Another surprising insight was that if position control was delegated to the robot, the participants perceived much lower autonomy than when the force control was delegated to the robot. These findings empirically support applying Fitts' principles to static function allocation for physical collaboration, while also revealing important nuanced user experience trade-offs, particularly regarding perceived autonomy when delegating position control.","authors":["Nicky Mol","J. Micah Prendergast","David A. Abbink","Luka Peternel"],"url":"https://arxiv.org/abs/2505.04722"}
{"created":"2025-05-09","title":"SOAEsV2-7B/72B: Full-Pipeline Optimization for State-Owned Enterprise LLMs via Continual Pre-Training, Domain-Progressive SFT and Distillation-Enhanced Speculative Decoding","abstract":"This study addresses key challenges in developing domain-specific large language models (LLMs) for Chinese state-owned assets and enterprises (SOAEs), where current approaches face three limitations: 1) constrained model capacity that limits knowledge integration and cross-task adaptability; 2) excessive reliance on domain-specific supervised fine-tuning (SFT) data, which neglects the broader applicability of general language patterns; and 3) inefficient inference acceleration for large models processing long contexts. In this work, we propose SOAEsV2-7B/72B, a specialized LLM series developed via a three-phase framework: 1) continual pre-training integrates domain knowledge while retaining base capabilities; 2) domain-progressive SFT employs curriculum-based learning strategy, transitioning from weakly relevant conversational data to expert-annotated SOAEs datasets to optimize domain-specific tasks; 3) distillation-enhanced speculative decoding accelerates inference via logit distillation between 72B target and 7B draft models, achieving 1.39-1.52$\\times$ speedup without quality loss. Experimental results demonstrate that our domain-specific pre-training phase maintains 99.8% of original general language capabilities while significantly improving domain performance, resulting in a 1.08$\\times$ improvement in Rouge-1 score and a 1.17$\\times$ enhancement in BLEU-4 score. Ablation studies further show that domain-progressive SFT outperforms single-stage training, achieving 1.02$\\times$ improvement in Rouge-1 and 1.06$\\times$ in BLEU-4. Our work introduces a comprehensive, full-pipeline approach for optimizing SOAEs LLMs, bridging the gap between general language capabilities and domain-specific expertise.","authors":["Jingyang Deng","Ran Chen","Jo-Ku Cheng","Jinwen Ma"],"url":"https://arxiv.org/abs/2505.04723"}
{"created":"2025-05-09","title":"Geometric Fault-Tolerant Neural Network Tracking Control of Unknown Systems on Matrix Lie Groups","abstract":"We present a geometric neural network-based tracking controller for systems evolving on matrix Lie groups under unknown dynamics, actuator faults, and bounded disturbances. Leveraging the left-invariance of the tangent bundle of matrix Lie groups, viewed as an embedded submanifold of the vector space $\\R^{N\\times N}$, we propose a set of learning rules for neural network weights that are intrinsically compatible with the Lie group structure and do not require explicit parameterization. Exploiting the geometric properties of Lie groups, this approach circumvents parameterization singularities and enables a global search for optimal weights. The ultimate boundedness of all error signals -- including the neural network weights, the coordinate-free configuration error function, and the tracking velocity error -- is established using Lyapunov's direct method. To validate the effectiveness of the proposed method, we provide illustrative simulation results for decentralized formation control of multi-agent systems on the Special Euclidean group.","authors":["Robin Chhabra","Farzaneh Abdollahi"],"url":"https://arxiv.org/abs/2505.04725"}
{"created":"2025-05-09","title":"Data Standards in Audiology: A Mixed-Methods Exploration of Community Perspectives and Implementation Considerations","abstract":"Objective: The purpose of this study was to explore options for data standardisation in audiology and document the global audiology community's current knowledge and views of data standards, explore their needs and preferences, and develop recommendations for data standardisation as a result.","authors":["Charlotte Vercammen","Antje Heinrich","Christophe Lesimple","Alessia Paglialonga","Jan-Willem A. Wasmann","Mareike Buhl"],"url":"https://arxiv.org/abs/2505.04728"}
{"created":"2025-05-09","title":"QBD-RankedDataGen: Generating Custom Ranked Datasets for Improving Query-By-Document Search Using LLM-Reranking with Reduced Human Effort","abstract":"The Query-By-Document (QBD) problem is an information retrieval problem where the query is a document, and the retrieved candidates are documents that match the query document, often in a domain or query specific manner. This can be crucial for tasks such as patent matching, legal or compliance case retrieval, and academic literature review. Existing retrieval methods, including keyword search and document embeddings, can be optimized with domain-specific datasets to improve QBD search performance. However, creating these domain-specific datasets is often costly and time-consuming. Our work introduces a process to generate custom QBD-search datasets and compares a set of methods to use in this problem, which we refer to as QBD-RankedDatagen. We provide a comparative analysis of our proposed methods in terms of cost, speed, and the human interface with the domain experts. The methods we compare leverage Large Language Models (LLMs) which can incorporate domain expert input to produce document scores and rankings, as well as explanations for human review. The process and methods for it that we present can significantly reduce human effort in dataset creation for custom domains while still obtaining sufficient expert knowledge for tuning retrieval models. We evaluate our methods on QBD datasets from the Text Retrieval Conference (TREC) and finetune the parameters of the BM25 model -- which is used in many industrial-strength search engines like OpenSearch -- using the generated data.","authors":["Sriram Gopalakrishnan","Sunandita Patra"],"url":"https://arxiv.org/abs/2505.04732"}
{"created":"2025-05-09","title":"Conformal Prediction with Corrupted Labels: Uncertain Imputation and Robust Re-weighting","abstract":"We introduce a framework for robust uncertainty quantification in situations where labeled training data are corrupted, through noisy or missing labels. We build on conformal prediction, a statistical tool for generating prediction sets that cover the test label with a pre-specified probability. The validity of conformal prediction, however, holds under the i.i.d assumption, which does not hold in our setting due to the corruptions in the data. To account for this distribution shift, the privileged conformal prediction (PCP) method proposed leveraging privileged information (PI) -- additional features available only during training -- to re-weight the data distribution, yielding valid prediction sets under the assumption that the weights are accurate. In this work, we analyze the robustness of PCP to inaccuracies in the weights. Our analysis indicates that PCP can still yield valid uncertainty estimates even when the weights are poorly estimated. Furthermore, we introduce uncertain imputation (UI), a new conformal method that does not rely on weight estimation. Instead, we impute corrupted labels in a way that preserves their uncertainty. Our approach is supported by theoretical guarantees and validated empirically on both synthetic and real benchmarks. Finally, we show that these techniques can be integrated into a triply robust framework, ensuring statistically valid predictions as long as at least one underlying method is valid.","authors":["Shai Feldman","Stephen Bates","Yaniv Romano"],"url":"https://arxiv.org/abs/2505.04733"}
{"created":"2025-05-09","title":"The Promise and Limits of LLMs in Constructing Proofs and Hints for Logic Problems in Intelligent Tutoring Systems","abstract":"Intelligent tutoring systems have demonstrated effectiveness in teaching formal propositional logic proofs, but their reliance on template-based explanations limits their ability to provide personalized student feedback. While large language models (LLMs) offer promising capabilities for dynamic feedback generation, they risk producing hallucinations or pedagogically unsound explanations. We evaluated the stepwise accuracy of LLMs in constructing multi-step symbolic logic proofs, comparing six prompting techniques across four state-of-the-art LLMs on 358 propositional logic problems. Results show that DeepSeek-V3 achieved superior performance with 84.4% accuracy on stepwise proof construction and excelled particularly in simpler rules. We further used the best-performing LLM to generate explanatory hints for 1,050 unique student problem-solving states from a logic ITS and evaluated them on 4 criteria with both an LLM grader and human expert ratings on a 20% sample. Our analysis finds that LLM-generated hints were 75% accurate and rated highly by human evaluators on consistency and clarity, but did not perform as well explaining why the hint was provided or its larger context. Our results demonstrate that LLMs may be used to augment tutoring systems with logic tutoring hints, but requires additional modifications to ensure accuracy and pedagogical appropriateness.","authors":["Sutapa Dey Tithi","Arun Kumar Ramesh","Clara DiMarco","Xiaoyi Tian","Nazia Alam","Kimia Fazeli","Tiffany Barnes"],"url":"https://arxiv.org/abs/2505.04736"}
{"created":"2025-05-09","title":"SetONet: A Deep Set-based Operator Network for Solving PDEs with permutation invariant variable input sampling","abstract":"Neural operators, particularly the Deep Operator Network (DeepONet), have shown promise in learning mappings between function spaces for solving differential equations. However, standard DeepONet requires input functions to be sampled at fixed locations, limiting its applicability in scenarios with variable sensor configurations, missing data, or irregular grids. We introduce the Set Operator Network (SetONet), a novel architecture that integrates Deep Sets principles into the DeepONet framework to address this limitation. The core innovation lies in the SetONet branch network, which processes the input function as an unordered \\emph{set} of location-value pairs. This design ensures permutation invariance with respect to the input points, making SetONet inherently robust to variations in the number and locations of sensors. SetONet learns richer, spatially-aware input representations by explicitly processing spatial coordinates and function values. We demonstrate SetONet's effectiveness on several benchmark problems, including derivative/anti-derivative operators, 1D Darcy flow, and 2D elasticity. Results show that SetONet successfully learns operators under variable input sampling conditions where standard DeepONet fails. Furthermore, SetONet is architecturally robust to sensor drop-off; unlike standard DeepONet, which requires methods like interpolation to function with missing data. Notably, SetONet can achieve comparable or improved accuracy over DeepONet on fixed grids, particularly for nonlinear problems, likely due to its enhanced input representation. SetONet provides a flexible and robust extension to the neural operator toolkit, significantly broadening the applicability of operator learning to problems with variable or incomplete input data.","authors":["Stepan Tretiakov","Xingjian Li","Krishna Kumar"],"url":"https://arxiv.org/abs/2505.04738"}
{"created":"2025-05-09","title":"Numerical stabilization for a mixture system with kind damping","abstract":"In this paper, we conduct a numerical analysis of the strong stabilization and polynomial decay of solutions for the initial boundary value problem associated with a system that models the dynamics of a mixture of two rigid solids with porosity. This mathematical model accounts for the complex interactions between the rigid components and their porous structure, providing valuable information on the mechanical behavior of such systems. Our primary objective is to establish conditions under which stabilization is ensured and to rigorously quantify the rate of decay of the solutions. Using numerical simulations, we assess the effectiveness of different stabilization mechanisms and analyze the influence of key system parameters on the overall dynamics.","authors":["Kais Ammari","Vilmos Komornik","Mauricio Sep\\'ulveda","Octavio Vera"],"url":"https://arxiv.org/abs/2505.04739"}
{"created":"2025-05-09","title":"Hyb-KAN ViT: Hybrid Kolmogorov-Arnold Networks Augmented Vision Transformer","abstract":"This study addresses the inherent limitations of Multi-Layer Perceptrons (MLPs) in Vision Transformers (ViTs) by introducing Hybrid Kolmogorov-Arnold Network (KAN)-ViT (Hyb-KAN ViT), a novel framework that integrates wavelet-based spectral decomposition and spline-optimized activation functions, prior work has failed to focus on the prebuilt modularity of the ViT architecture and integration of edge detection capabilities of Wavelet functions. We propose two key modules: Efficient-KAN (Eff-KAN), which replaces MLP layers with spline functions and Wavelet-KAN (Wav-KAN), leveraging orthogonal wavelet transforms for multi-resolution feature extraction. These modules are systematically integrated in ViT encoder layers and classification heads to enhance spatial-frequency modeling while mitigating computational bottlenecks. Experiments on ImageNet-1K (Image Recognition), COCO (Object Detection and Instance Segmentation), and ADE20K (Semantic Segmentation) demonstrate state-of-the-art performance with Hyb-KAN ViT. Ablation studies validate the efficacy of wavelet-driven spectral priors in segmentation and spline-based efficiency in detection tasks. The framework establishes a new paradigm for balancing parameter efficiency and multi-scale representation in vision architectures.","authors":["Sainath Dey","Mitul Goswami","Jashika Sethi","Prasant Kumar Pattnaik"],"url":"https://arxiv.org/abs/2505.04740"}
{"created":"2025-05-09","title":"When Bad Data Leads to Good Models","abstract":"In large language model (LLM) pretraining, data quality is believed to determine model quality. In this paper, we re-examine the notion of \"quality\" from the perspective of pre- and post-training co-design. Specifically, we explore the possibility that pre-training on more toxic data can lead to better control in post-training, ultimately decreasing a model's output toxicity. First, we use a toy experiment to study how data composition affects the geometry of features in the representation space. Next, through controlled experiments with Olmo-1B models trained on varying ratios of clean and toxic data, we find that the concept of toxicity enjoys a less entangled linear representation as the proportion of toxic data increases. Furthermore, we show that although toxic data increases the generational toxicity of the base model, it also makes the toxicity easier to remove. Evaluations on Toxigen and Real Toxicity Prompts demonstrate that models trained on toxic data achieve a better trade-off between reducing generational toxicity and preserving general capabilities when detoxifying techniques such as inference-time intervention (ITI) are applied. Our findings suggest that, with post-training taken into account, bad data may lead to good models.","authors":["Kenneth Li","Yida Chen","Fernanda Vi\\'egas","Martin Wattenberg"],"url":"https://arxiv.org/abs/2505.04741"}
{"created":"2025-05-09","title":"Hybrid-Field 6D Movable Antenna for Terahertz Communications: Channel Modeling and Estimation","abstract":"In this work, we study a six-dimensional movable antenna (6DMA)-enhanced Terahertz (THz) network that supports a large number of users with a few antennas by controlling the three-dimensional (3D) positions and 3D rotations of antenna surfaces/subarrays at the base station (BS). However, the short wavelength of THz signals combined with a large 6DMA movement range extends the near-field region. As a result, a user can be in the far-field region relative to the antennas on one 6DMA surface, while simultaneously residing in the near-field region relative to other 6DMA surfaces. Moreover, 6DMA THz channel estimation suffers from increased computational complexity and pilot overhead due to uneven power distribution across the large number of candidate position-rotation pairs, as well as the limited number of radio frequency (RF) chains in THz bands. To address these issues, we propose an efficient hybrid-field generalized 6DMA THz channel model, which accounts for planar wave propagation within individual 6DMA surfaces and spherical waves among different 6DMA surfaces. Furthermore, we propose a low-overhead channel estimation algorithm that leverages directional sparsity to construct a complete channel map for all potential antenna position-rotation pairs.","authors":["Xiaodan Shao","Yixiao Zhang","Shisheng Hu","Zhixuan Tang","Mingcheng He","Xinyu Huang","Weihua Zhuang","Xuemin Shen"],"url":"https://arxiv.org/abs/2505.04753"}
{"created":"2025-05-09","title":"Multiserver-job Response Time under Multilevel Scaling","abstract":"We study the multiserver-job setting in the load-focused multilevel scaling limit, where system load approaches capacity much faster than the growth of the number of servers $n$.","authors":["Isaac Grosof","Hayriye Ayhan"],"url":"https://arxiv.org/abs/2505.04754"}
{"created":"2025-05-09","title":"Primal-dual algorithm for contextual stochastic combinatorial optimization","abstract":"This paper introduces a novel approach to contextual stochastic optimization, integrating operations research and machine learning to address decision-making under uncertainty. Traditional methods often fail to leverage contextual information, which underscores the necessity for new algorithms. In this study, we utilize neural networks with combinatorial optimization layers to encode policies. Our goal is to minimize the empirical risk, which is estimated from past data on uncertain parameters and contexts. To that end, we present a surrogate learning problem and a generic primal-dual algorithm that is applicable to various combinatorial settings in stochastic optimization. Our approach extends classic Fenchel-Young loss results and introduces a new regularization method using sparse perturbations on the distribution simplex. This allows for tractable updates in the original space and can accommodate diverse objective functions. We demonstrate the linear convergence of our algorithm under certain conditions and provide a bound on the non-optimality of the resulting policy in terms of the empirical risk. Experiments on a contextual stochastic minimum weight spanning tree problem show that our algorithm is efficient and scalable, achieving performance comparable to imitation learning of solutions computed using an expensive Lagrangian-based heuristic.","authors":["Louis Bouvier","Thibault Prunet","Vincent Lecl\\`ere","Axel Parmentier"],"url":"https://arxiv.org/abs/2505.04757"}
{"created":"2025-05-09","title":"Lightweight RGB-D Salient Object Detection from a Speed-Accuracy Tradeoff Perspective","abstract":"Current RGB-D methods usually leverage large-scale backbones to improve accuracy but sacrifice efficiency. Meanwhile, several existing lightweight methods are difficult to achieve high-precision performance. To balance the efficiency and performance, we propose a Speed-Accuracy Tradeoff Network (SATNet) for Lightweight RGB-D SOD from three fundamental perspectives: depth quality, modality fusion, and feature representation. Concerning depth quality, we introduce the Depth Anything Model to generate high-quality depth maps,which effectively alleviates the multi-modal gaps in the current datasets. For modality fusion, we propose a Decoupled Attention Module (DAM) to explore the consistency within and between modalities. Here, the multi-modal features are decoupled into dual-view feature vectors to project discriminable information of feature maps. For feature representation, we develop a Dual Information Representation Module (DIRM) with a bi-directional inverted framework to enlarge the limited feature space generated by the lightweight backbones. DIRM models texture features and saliency features to enrich feature space, and employ two-way prediction heads to optimal its parameters through a bi-directional backpropagation. Finally, we design a Dual Feature Aggregation Module (DFAM) in the decoder to aggregate texture and saliency features. Extensive experiments on five public RGB-D SOD datasets indicate that the proposed SATNet excels state-of-the-art (SOTA) CNN-based heavyweight models and achieves a lightweight framework with 5.2 M parameters and 415 FPS.","authors":["Songsong Duan","Xi Yang","Nannan Wang","Xinbo Gao"],"url":"https://arxiv.org/abs/2505.04758"}
{"created":"2025-05-09","title":"Exploring Zero-Shot App Review Classification with ChatGPT: Challenges and Potential","abstract":"App reviews are a critical source of user feedback, offering valuable insights into an app's performance, features, usability, and overall user experience. Effectively analyzing these reviews is essential for guiding app development, prioritizing feature updates, and enhancing user satisfaction. Classifying reviews into functional and non-functional requirements play a pivotal role in distinguishing feedback related to specific app features (functional requirements) from feedback concerning broader quality attributes, such as performance, usability, and reliability (non-functional requirements). Both categories are integral to informed development decisions. Traditional approaches to classifying app reviews are hindered by the need for large, domain-specific datasets, which are often costly and time-consuming to curate. This study explores the potential of zero-shot learning with ChatGPT for classifying app reviews into four categories: functional requirement, non-functional requirement, both, or neither. We evaluate ChatGPT's performance on a benchmark dataset of 1,880 manually annotated reviews from ten diverse apps spanning multiple domains. Our findings demonstrate that ChatGPT achieves a robust F1 score of 0.842 in review classification, despite certain challenges and limitations. Additionally, we examine how factors such as review readability and length impact classification accuracy and conduct a manual analysis to identify review categories more prone to misclassification.","authors":["Mohit Chaudhary","Chirag Jain","Preethu Rose Anish"],"url":"https://arxiv.org/abs/2505.04759"}
{"created":"2025-05-09","title":"Data-Dependent Hidden Markov Model with Off-Road State Determination and Real-Time Viterbi Algorithm for Lane Determination in Autonomous Vehicles","abstract":"Lane determination and lane sequence determination are important components for many Connected and Automated Vehicle (CAV) applications. Lane determination has been solved using Hidden Markov Model (HMM) among other methods. The existing HMM literature for lane sequence determination uses empirical definitions with user-modified parameters to calculate HMM probabilities. The probability definitions in the literature can cause breaks in the HMM due to the inability to directly calculate probabilities of off-road positions, requiring post-processing of data. This paper develops a time-varying HMM using the physical properties of the roadway and vehicle, and the stochastic properties of the sensors. This approach yields emission and transition probability models conditioned on the sensor data without parameter tuning. It also accounts for the probability that the vehicle is not in any roadway lane (e.g., on the shoulder or making a U-turn), which eliminates the need for post-processing to deal with breaks in the HMM processing. This approach requires adapting the Viterbi algorithm and the HMM to be conditioned on the sensor data, which are then used to generate the most-likely sequence of lanes the vehicle has traveled. The proposed approach achieves an average accuracy of 95.9%. Compared to the existing literature, this provides an average increase of 2.25% by implementing the proposed transition probability and an average increase of 5.1% by implementing both the proposed transition and emission probabilities.","authors":["Mike Stas","Wang Hu","Jay A. Farrell"],"url":"https://arxiv.org/abs/2505.04763"}
{"created":"2025-05-09","title":"Vision-Language-Action Models: Concepts, Progress, Applications and Challenges","abstract":"Vision-Language-Action (VLA) models mark a transformative advancement in artificial intelligence, aiming to unify perception, natural language understanding, and embodied action within a single computational framework. This foundational review presents a comprehensive synthesis of recent advancements in Vision-Language-Action models, systematically organized across five thematic pillars that structure the landscape of this rapidly evolving field. We begin by establishing the conceptual foundations of VLA systems, tracing their evolution from cross-modal learning architectures to generalist agents that tightly integrate vision-language models (VLMs), action planners, and hierarchical controllers. Our methodology adopts a rigorous literature review framework, covering over 80 VLA models published in the past three years. Key progress areas include architectural innovations, parameter-efficient training strategies, and real-time inference accelerations. We explore diverse application domains such as humanoid robotics, autonomous vehicles, medical and industrial robotics, precision agriculture, and augmented reality navigation. The review further addresses major challenges across real-time control, multimodal action representation, system scalability, generalization to unseen tasks, and ethical deployment risks. Drawing from the state-of-the-art, we propose targeted solutions including agentic AI adaptation, cross-embodiment generalization, and unified neuro-symbolic planning. In our forward-looking discussion, we outline a future roadmap where VLA models, VLMs, and agentic AI converge to power socially aligned, adaptive, and general-purpose embodied agents. This work serves as a foundational reference for advancing intelligent, real-world robotics and artificial general intelligence. >Vision-language-action, Agentic AI, AI Agents, Vision-language Models","authors":["Ranjan Sapkota","Yang Cao","Konstantinos I. Roumeliotis","Manoj Karkee"],"url":"https://arxiv.org/abs/2505.04769"}
{"created":"2025-05-09","title":"Impact of Weather on Satellite Communication: Evaluating Starlink Resilience","abstract":"Satellite communications have emerged as one of the most feasible solutions to provide global wireless coverage and connect the unconnected. Starlink dominates the market with over 7,000 operational satellites in low Earth orbit (LEO) and offers global high-speed and low-latency Internet service for stationary and mobile use cases, including in-motion connectivity for vehicles, vessels, and aircraft. Starlink terminals are designed to handle extreme weather conditions. Starlink recommends a flat high performance (FHP) terminal for users living in areas with extreme weather conditions. The earlier studies evaluated Starlink's FHP throughput for stationary and in-motion users without providing a detailed analysis of how weather affects its performance. There remains a need to investigate the impact of weather on FHP's throughput. In this paper, we address this shortcoming by analyzing the impact of weather on Starlink's performance in Oulu, Finland, a city located in Northern Europe near the Arctic Circle. Our measurements reveal that rain degrades median uplink and downlink throughput by 52.27% and 37.84%, respectively. On the contrary, there was no noticeable impact on the round-trip time. Additionally, we also examine the impact of cloud cover on the Starlink throughput. The linear regression analysis reveals the negative relationship between throughput and cloud cover. The cloud cover of up to 12.5% has around 20% greater throughput than the cloud cover of 87.5%","authors":["Muhammad Asad Ullah","Antti Heikkinen","Mikko Uitto","Antti Anttonen","Konstantin Mikhaylov"],"url":"https://arxiv.org/abs/2505.04772"}
{"created":"2025-05-09","title":"Prediction via Shapley Value Regression","abstract":"Shapley values have several desirable, theoretically well-supported, properties for explaining black-box model predictions. Traditionally, Shapley values are computed post-hoc, leading to additional computational cost at inference time. To overcome this, a novel method, called ViaSHAP, is proposed, that learns a function to compute Shapley values, from which the predictions can be derived directly by summation. Two approaches to implement the proposed method are explored; one based on the universal approximation theorem and the other on the Kolmogorov-Arnold representation theorem. Results from a large-scale empirical investigation are presented, showing that ViaSHAP using Kolmogorov-Arnold Networks performs on par with state-of-the-art algorithms for tabular data. It is also shown that the explanations of ViaSHAP are significantly more accurate than the popular approximator FastSHAP on both tabular data and images.","authors":["Amr Alkhatib","Roman Bresson","Henrik Bostr\\\"om","Michalis Vazirgiannis"],"url":"https://arxiv.org/abs/2505.04775"}
{"created":"2025-05-09","title":"A Proposal for Evaluating the Operational Risk for ChatBots based on Large Language Models","abstract":"The emergence of Generative AI (Gen AI) and Large Language Models (LLMs) has enabled more advanced chatbots capable of human-like interactions. However, these conversational agents introduce a broader set of operational risks that extend beyond traditional cybersecurity considerations. In this work, we propose a novel, instrumented risk-assessment metric that simultaneously evaluates potential threats to three key stakeholders: the service-providing organization, end users, and third parties. Our approach incorporates the technical complexity required to induce erroneous behaviors in the chatbot--ranging from non-induced failures to advanced prompt-injection attacks--as well as contextual factors such as the target industry, user age range, and vulnerability severity. To validate our metric, we leverage Garak, an open-source framework for LLM vulnerability testing. We further enhance Garak to capture a variety of threat vectors (e.g., misinformation, code hallucinations, social engineering, and malicious code generation). Our methodology is demonstrated in a scenario involving chatbots that employ retrieval-augmented generation (RAG), showing how the aggregated risk scores guide both short-term mitigation and longer-term improvements in model design and deployment. The results underscore the importance of multi-dimensional risk assessments in operationalizing secure, reliable AI-driven conversational systems.","authors":["Pedro Pinacho-Davidson","Fernando Gutierrez","Pablo Zapata","Rodolfo Vergara","Pablo Aqueveque"],"url":"https://arxiv.org/abs/2505.04784"}
{"created":"2025-05-09","title":"Flower Across Time and Media: Sentiment Analysis of Tang Song Poetry and Visual Correspondence","abstract":"The Tang (618 to 907) and Song (960 to 1279) dynasties witnessed an extraordinary flourishing of Chinese cultural expression, where floral motifs served as a dynamic medium for both poetic sentiment and artistic design. While previous scholarship has examined these domains independently, the systematic correlation between evolving literary emotions and visual culture remains underexplored. This study addresses that gap by employing BERT-based sentiment analysis to quantify emotional patterns in floral imagery across Tang Song poetry, then validating these patterns against contemporaneous developments in decorative arts.Our approach builds upon recent advances in computational humanities while remaining grounded in traditional sinological methods. By applying a fine tuned BERT model to analyze peony and plum blossom imagery in classical poetry, we detect measurable shifts in emotional connotations between the Tang and Song periods. These textual patterns are then cross berenced with visual evidence from textiles, ceramics, and other material culture, revealing previously unrecognized synergies between literary expression and artistic representation.","authors":["Shuai Gong","Tiange Zhou"],"url":"https://arxiv.org/abs/2505.04785"}
{"created":"2025-05-09","title":"Replay to Remember (R2R): An Efficient Uncertainty-driven Unsupervised Continual Learning Framework Using Generative Replay","abstract":"Continual Learning entails progressively acquiring knowledge from new data while retaining previously acquired knowledge, thereby mitigating ``Catastrophic Forgetting'' in neural networks. Our work presents a novel uncertainty-driven Unsupervised Continual Learning framework using Generative Replay, namely ``Replay to Remember (R2R)''. The proposed R2R architecture efficiently uses unlabelled and synthetic labelled data in a balanced proportion using a cluster-level uncertainty-driven feedback mechanism and a VLM-powered generative replay module. Unlike traditional memory-buffer methods that depend on pretrained models and pseudo-labels, our R2R framework operates without any prior training. It leverages visual features from unlabeled data and adapts continuously using clustering-based uncertainty estimation coupled with dynamic thresholding. Concurrently, a generative replay mechanism along with DeepSeek-R1 powered CLIP VLM produces labelled synthetic data representative of past experiences, resembling biological visual thinking that replays memory to remember and act in new, unseen tasks. Extensive experimental analyses are carried out in CIFAR-10, CIFAR-100, CINIC-10, SVHN and TinyImageNet datasets. Our proposed R2R approach improves knowledge retention, achieving a state-of-the-art performance of 98.13%, 73.06%, 93.41%, 95.18%, 59.74%, respectively, surpassing state-of-the-art performance by over 4.36%.","authors":["Sriram Mandalika","Harsha Vardhan","Athira Nambiar"],"url":"https://arxiv.org/abs/2505.04787"}
{"created":"2025-05-09","title":"Convex Relaxation for Robust Vanishing Point Estimation in Manhattan World","abstract":"Determining the vanishing points (VPs) in a Manhattan world, as a fundamental task in many 3D vision applications, consists of jointly inferring the line-VP association and locating each VP. Existing methods are, however, either sub-optimal solvers or pursuing global optimality at a significant cost of computing time. In contrast to prior works, we introduce convex relaxation techniques to solve this task for the first time. Specifically, we employ a ``soft'' association scheme, realized via a truncated multi-selection error, that allows for joint estimation of VPs' locations and line-VP associations. This approach leads to a primal problem that can be reformulated into a quadratically constrained quadratic programming (QCQP) problem, which is then relaxed into a convex semidefinite programming (SDP) problem. To solve this SDP problem efficiently, we present a globally optimal outlier-robust iterative solver (called \\textbf{GlobustVP}), which independently searches for one VP and its associated lines in each iteration, treating other lines as outliers. After each independent update of all VPs, the mutual orthogonality between the three VPs in a Manhattan world is reinforced via local refinement. Extensive experiments on both synthetic and real-world data demonstrate that \\textbf{GlobustVP} achieves a favorable balance between efficiency, robustness, and global optimality compared to previous works. The code is publicly available at https://github.com/WU-CVGL/GlobustVP.","authors":["Bangyan Liao","Zhenjun Zhao","Haoang Li","Yi Zhou","Yingping Zeng","Hao Li","Peidong Liu"],"url":"https://arxiv.org/abs/2505.04788"}
{"created":"2025-05-09","title":"DetReIDX: A Stress-Test Dataset for Real-World UAV-Based Person Recognition","abstract":"Person reidentification (ReID) technology has been considered to perform relatively well under controlled, ground-level conditions, but it breaks down when deployed in challenging real-world settings. Evidently, this is due to extreme data variability factors such as resolution, viewpoint changes, scale variations, occlusions, and appearance shifts from clothing or session drifts. Moreover, the publicly available data sets do not realistically incorporate such kinds and magnitudes of variability, which limits the progress of this technology. This paper introduces DetReIDX, a large-scale aerial-ground person dataset, that was explicitly designed as a stress test to ReID under real-world conditions. DetReIDX is a multi-session set that includes over 13 million bounding boxes from 509 identities, collected in seven university campuses from three continents, with drone altitudes between 5.8 and 120 meters. More important, as a key novelty, DetReIDX subjects were recorded in (at least) two sessions on different days, with changes in clothing, daylight and location, making it suitable to actually evaluate long-term person ReID. Plus, data were annotated from 16 soft biometric attributes and multitask labels for detection, tracking, ReID, and action recognition. In order to provide empirical evidence of DetReIDX usefulness, we considered the specific tasks of human detection and ReID, where SOTA methods catastrophically degrade performance (up to 80% in detection accuracy and over 70% in Rank-1 ReID) when exposed to DetReIDXs conditions. The dataset, annotations, and official evaluation protocols are publicly available at https://www.it.ubi.pt/DetReIDX/","authors":["Kailash A. Hambarde","Nzakiese Mbongo","Pavan Kumar MP","Satish Mekewad","Carolina Fernandes","G\\\"okhan Silahtaro\\u{g}lu","Alice Nithya","Pawan Wasnik","MD. Rashidunnabi","Pranita Samale","Hugo Proen\\c{c}a"],"url":"https://arxiv.org/abs/2505.04793"}
{"created":"2025-05-09","title":"Robust ML Auditing using Prior Knowledge","abstract":"The rapid adoption of ML decision-making systems across products and services has led to a set of regulations on how such systems should behave and be built. Among all the technical challenges to enforcing these regulations, one crucial, yet under-explored problem is the risk of manipulation while these systems are being audited for fairness. This manipulation occurs when a platform deliberately alters its answers to a regulator to pass an audit without modifying its answers to other users. In this paper, we introduce a novel approach to manipulation-proof auditing by taking into account the auditor's prior knowledge of the task solved by the platform. We first demonstrate that regulators must not rely on public priors (e.g. a public dataset), as platforms could easily fool the auditor in such cases. We then formally establish the conditions under which an auditor can prevent audit manipulations using prior knowledge about the ground truth. Finally, our experiments with two standard datasets exemplify the maximum level of unfairness a platform can hide before being detected as malicious. Our formalization and generalization of manipulation-proof auditing with a prior opens up new research directions for more robust fairness audits.","authors":["Jade Garcia Bourr\\'ee","Augustin Godinot","Martijn De Vos","Milos Vujasinovic","Sayan Biswas","Gilles Tredan","Erwan Le Merrer","Anne-Marie Kermarrec"],"url":"https://arxiv.org/abs/2505.04796"}
{"created":"2025-05-09","title":"Quantum Artificial Intelligence for Software Engineering: the Road Ahead","abstract":"Artificial Intelligence (AI) has been applied to various areas of software engineering, including requirements engineering, coding, testing, and debugging. This has led to the emergence of AI for Software Engineering as a distinct research area within software engineering. With the development of quantum computing, the field of Quantum AI (QAI) is arising, enhancing the performance of classical AI and holding significant potential for solving classical software engineering problems. Some initial applications of QAI in software engineering have already emerged, such as software test optimization. However, the path ahead remains open, offering ample opportunities to solve complex software engineering problems with QAI cost-effectively. To this end, this paper presents open research opportunities and challenges in QAI for software engineering that need to be addressed.","authors":["Xinyi Wang","Shaukat Ali","Paolo Arcaini"],"url":"https://arxiv.org/abs/2505.04797"}
{"created":"2025-05-09","title":"Safeguard-by-Development: A Privacy-Enhanced Development Paradigm for Multi-Agent Collaboration Systems","abstract":"Multi-agent collaboration systems (MACS), powered by large language models (LLMs), solve complex problems efficiently by leveraging each agent's specialization and communication between agents. However, the inherent exchange of information between agents and their interaction with external environments, such as LLM, tools, and users, inevitably introduces significant risks of sensitive data leakage, including vulnerabilities to attacks like prompt injection and reconnaissance. Existing MACS fail to enable privacy controls, making it challenging to manage sensitive information securely. In this paper, we take the first step to address the MACS's data leakage threat at the system development level through a privacy-enhanced development paradigm, Maris. Maris enables rigorous message flow control within MACS by embedding reference monitors into key multi-agent conversation components. We implemented Maris as an integral part of AutoGen, a widely adopted open-source multi-agent development framework. Then, we evaluate Maris for its effectiveness and performance overhead on privacy-critical MACS use cases, including healthcare, supply chain optimization, and personalized recommendation system. The result shows that Maris achieves satisfactory effectiveness, performance overhead and practicability for adoption.","authors":["Jian Cui","Zichuan Li","Luyi Xing","Xiaojing Liao"],"url":"https://arxiv.org/abs/2505.04799"}
{"created":"2025-05-09","title":"ORBIT-2: Scaling Exascale Vision Foundation Models for Weather and Climate Downscaling","abstract":"Sparse observations and coarse-resolution climate models limit effective regional decision-making, underscoring the need for robust downscaling. However, existing AI methods struggle with generalization across variables and geographies and are constrained by the quadratic complexity of Vision Transformer (ViT) self-attention. We introduce ORBIT-2, a scalable foundation model for global, hyper-resolution climate downscaling. ORBIT-2 incorporates two key innovations: (1) Residual Slim ViT (Reslim), a lightweight architecture with residual learning and Bayesian regularization for efficient, robust prediction; and (2) TILES, a tile-wise sequence scaling algorithm that reduces self-attention complexity from quadratic to linear, enabling long-sequence processing and massive parallelism. ORBIT-2 scales to 10 billion parameters across 32,768 GPUs, achieving up to 1.8 ExaFLOPS sustained throughput and 92-98% strong scaling efficiency. It supports downscaling to 0.9 km global resolution and processes sequences up to 4.2 billion tokens. On 7 km resolution benchmarks, ORBIT-2 achieves high accuracy with R^2 scores in the range of 0.98 to 0.99 against observation data.","authors":["Xiao Wang","Jong-Youl Choi","Takuya Kurihaya","Isaac Lyngaas","Hong-Jun Yoon","Ming Fan","Nasik Muhammad Nafi","Aristeidis Tsaris","Ashwin M. Aji","Maliha Hossain","Mohamed Wahib","Dali Wang","Peter Thornton","Prasanna Balaprakash","Moetasim Ashfaq","Dan Lu"],"url":"https://arxiv.org/abs/2505.04802"}
{"created":"2025-05-09","title":"Red Teaming the Mind of the Machine: A Systematic Evaluation of Prompt Injection and Jailbreak Vulnerabilities in LLMs","abstract":"Large Language Models (LLMs) are increasingly integrated into consumer and enterprise applications. Despite their capabilities, they remain susceptible to adversarial attacks such as prompt injection and jailbreaks that override alignment safeguards. This paper provides a systematic investigation of jailbreak strategies against various state-of-the-art LLMs. We categorize over 1,400 adversarial prompts, analyze their success against GPT-4, Claude 2, Mistral 7B, and Vicuna, and examine their generalizability and construction logic. We further propose layered mitigation strategies and recommend a hybrid red-teaming and sandboxing approach for robust LLM security.","authors":["Chetan Pathade"],"url":"https://arxiv.org/abs/2505.04806"}
{"created":"2025-05-09","title":"Piecewise Constant Spectral Graph Neural Network","abstract":"Graph Neural Networks (GNNs) have achieved significant success across various domains by leveraging graph structures in data. Existing spectral GNNs, which use low-degree polynomial filters to capture graph spectral properties, may not fully identify the graph's spectral characteristics because of the polynomial's small degree. However, increasing the polynomial degree is computationally expensive and beyond certain thresholds leads to performance plateaus or degradation. In this paper, we introduce the Piecewise Constant Spectral Graph Neural Network(PieCoN) to address these challenges. PieCoN combines constant spectral filters with polynomial filters to provide a more flexible way to leverage the graph structure. By adaptively partitioning the spectrum into intervals, our approach increases the range of spectral properties that can be effectively learned. Experiments on nine benchmark datasets, including both homophilic and heterophilic graphs, demonstrate that PieCoN is particularly effective on heterophilic datasets, highlighting its potential for a wide range of applications.","authors":["Vahan Martirosyan","Jhony H. Giraldo","Fragkiskos D. Malliaros"],"url":"https://arxiv.org/abs/2505.04808"}
{"created":"2025-05-09","title":"WIR3D: Visually-Informed and Geometry-Aware 3D Shape Abstraction","abstract":"We present WIR3D, a technique for abstracting 3D shapes through a sparse set of visually meaningful curves in 3D. We optimize the parameters of Bezier curves such that they faithfully represent both the geometry and salient visual features (e.g. texture) of the shape from arbitrary viewpoints. We leverage the intermediate activations of a pre-trained foundation model (CLIP) to guide our optimization process. We divide our optimization into two phases: one for capturing the coarse geometry of the shape, and the other for representing fine-grained features. Our second phase supervision is spatially guided by a novel localized keypoint loss. This spatial guidance enables user control over abstracted features. We ensure fidelity to the original surface through a neural SDF loss, which allows the curves to be used as intuitive deformation handles. We successfully apply our method for shape abstraction over a broad dataset of shapes with varying complexity, geometric structure, and texture, and demonstrate downstream applications for feature control and shape deformation.","authors":["Richard Liu","Daniel Fu","Noah Tan","Itai Lang","Rana Hanocka"],"url":"https://arxiv.org/abs/2505.04813"}
{"created":"2025-05-09","title":"Is there Value in Reinforcement Learning?","abstract":"Action-values play a central role in popular Reinforcement Learing (RL) models of behavior. Yet, the idea that action-values are explicitly represented has been extensively debated. Critics had therefore repeatedly suggested that policy-gradient (PG) models should be favored over value-based (VB) ones, as a potential solution for this dilemma. Here we argue that this solution is unsatisfying. This is because PG methods are not, in fact, \"Value-free\" -- while they do not rely on an explicit representation of Value for acting (stimulus-response mapping), they do require it for learning. Hence, switching to PG models is, per se, insufficient for eliminating Value from models of behavior. More broadly, the requirement for a representation of Value stems from the underlying assumptions regarding the optimization objective posed by the standard RL framework, not from the particular algorithm chosen to solve it. Previous studies mostly took these standard RL assumptions for granted, as part of their conceptualization or problem modeling, while debating the different methods used to optimize it (i.e., PG or VB). We propose that, instead, the focus of the debate should shift to critically evaluating the underlying modeling assumptions. Such evaluation is particularly important from an experimental perspective. Indeed, the very notion of Value must be reconsidered when standard assumptions (e.g., risk neutrality, full-observability, Markovian environment, exponential discounting) are relaxed, as is likely in natural settings. Finally, we use the Value debate as a case study to argue in favor of a more nuanced, algorithmic rather than statistical, view of what constitutes \"a model\" in cognitive sciences. Our analysis suggests that besides \"parametric\" statistical complexity, additional aspects such as computational complexity must also be taken into account when evaluating model complexity.","authors":["Lior Fox","Yonatan Loewenstein"],"url":"https://arxiv.org/abs/2505.04822"}
{"created":"2025-05-09","title":"Guide your favorite protein sequence generative model","abstract":"Generative machine learning models have begun to transform protein engineering, yet no principled framework for conditioning on auxiliary information in a plug-and-play manner exists; one may want to iteratively incorporate experimental feedback, or make use of an existing classifier -- such as for predicting enzyme commission number -- in order to guide the sampling of the generative model to generate sequences with desired properties. Herein, we present ProteinGuide, a rigorous and general framework to achieve just that: through unifying a broad class of protein generative models that includes masked language, (order-agnostic) autoregressive, diffusion and flow-matching models, we provide an approach to statistically condition pre-trained protein generative models. We demonstrate applicability of our approach by guiding each of two commonly used protein generative models, ProteinMPNN and ESM3, to generate amino acid and structure token sequences conditioned on several user-specified properties, namely, enhanced stability and CATH-labeled fold generation.","authors":["Junhao Xiong","Hunter Nisonoff","Ishan Gaur","Jennifer Listgarten"],"url":"https://arxiv.org/abs/2505.04823"}
{"created":"2025-05-09","title":"Joint User Association and Bandwidth Assignment for Digital Twin-Assisted Multi-RAT Networks","abstract":"In this paper, we investigate user equipment (UE)-radio access technology (RAT) association and bandwidth assignment to maximize sum-rates in a multi-RAT network. To this end, we formulate an optimization problem that jointly addresses UE association and bandwidth allocation, adhering to practical constraints. Because of the NP-hard nature of this problem, finding a globally optimal solution is computationally infeasible. To address this challenge, we propose a centralized and computationally efficient heuristic algorithm that aims to maximize sum-rates while enhancing quality of service (QoS). Yet, the proposed approach requires global channel state information (CSI) for near-optimal performance, which incurs substantial overhead and data collection costs in large-scale multi-RAT networks. To alleviate this burden, we use a digital twin (DT) of the multi-RAT network, leveraging its context-awareness to acquire global CSI with reduced overhead. Our numerical results reveal that our approach improves sum-rates by up to 43% over baseline method, with less than a 5% deviation from the theoretical optimal solution, while achieving up to a 43% improvement in QoS. Further analysis reveals that our method not only surpasses the optimal solution in terms of QoS enhancement, but also ensures significant computational efficiency.","authors":["Manobendu Sarker","Md. Zoheb Hassan","Georges Kaddoum"],"url":"https://arxiv.org/abs/2505.04829"}
{"created":"2025-05-09","title":"Steerable Scene Generation with Post Training and Inference-Time Search","abstract":"Training robots in simulation requires diverse 3D scenes that reflect the specific challenges of downstream tasks. However, scenes that satisfy strict task requirements, such as high-clutter environments with plausible spatial arrangement, are rare and costly to curate manually. Instead, we generate large-scale scene data using procedural models that approximate realistic environments for robotic manipulation, and adapt it to task-specific goals. We do this by training a unified diffusion-based generative model that predicts which objects to place from a fixed asset library, along with their SE(3) poses. This model serves as a flexible scene prior that can be adapted using reinforcement learning-based post training, conditional generation, or inference-time search, steering generation toward downstream objectives even when they differ from the original data distribution. Our method enables goal-directed scene synthesis that respects physical feasibility and scales across scene types. We introduce a novel MCTS-based inference-time search strategy for diffusion models, enforce feasibility via projection and simulation, and release a dataset of over 44 million SE(3) scenes spanning five diverse environments. Website with videos, code, data, and model weights: https://steerable-scene-generation.github.io/","authors":["Nicholas Pfaff","Hongkai Dai","Sergey Zakharov","Shun Iwase","Russ Tedrake"],"url":"https://arxiv.org/abs/2505.04831"}
{"created":"2025-05-09","title":"The Design Space of Lockfiles Across Package Managers","abstract":"Software developers reuse third-party packages that are hosted in package registries. At build time, a package manager resolves and fetches the direct and indirect dependencies of a project. Most package managers also generate a lockfile, which records the exact set of resolved dependency versions. Lockfiles are used to reduce build times; to verify the integrity of resolved packages; and to support build reproducibility across environments and time. Despite these beneficial features, developers often struggle with their maintenance, usage, and interpretation. In this study, we unveil the major challenges related to lockfiles, such that future researchers and engineers can address them. We perform the first comprehensive study of lockfiles across 7 popular package managers, npm, pnpm, Cargo, Poetry, Pipenv, Gradle, and Go. First, we highlight how the content and functions of lockfiles differ across package managers and ecosystems. Next, we conduct a qualitative analysis based on semi-structured interviews with 15 developers. We capture first-hand insights about the benefits that developers perceive in lockfiles, as well as the challenges they face to manage these files. Following these observations, we make 4 recommendations to further improve lockfiles, for a better developer experience.","authors":["Yogya Gamage","Deepika Tiwari","Martin Monperrus","Benoit Baudry"],"url":"https://arxiv.org/abs/2505.04834"}
{"created":"2025-05-09","title":"Are Synthetic Corruptions A Reliable Proxy For Real-World Corruptions?","abstract":"Deep learning (DL) models are widely used in real-world applications but remain vulnerable to distribution shifts, especially due to weather and lighting changes. Collecting diverse real-world data for testing the robustness of DL models is resource-intensive, making synthetic corruptions an attractive alternative for robustness testing. However, are synthetic corruptions a reliable proxy for real-world corruptions? To answer this, we conduct the largest benchmarking study on semantic segmentation models, comparing performance on real-world corruptions and synthetic corruptions datasets. Our results reveal a strong correlation in mean performance, supporting the use of synthetic corruptions for robustness evaluation. We further analyze corruption-specific correlations, providing key insights to understand when synthetic corruptions succeed in representing real-world corruptions. Open-source Code: https://github.com/shashankskagnihotri/benchmarking_robustness/tree/segmentation_david/semantic_segmentation","authors":["Shashank Agnihotri","David Schader","Nico Sharei","Mehmet Ege Ka\\c{c}ar","Margret Keuper"],"url":"https://arxiv.org/abs/2505.04835"}
{"created":"2025-05-09","title":"Seeing Cells Clearly: Evaluating Machine Vision Strategies for Microglia Centroid Detection in 3D Images","abstract":"Microglia are important cells in the brain, and their shape can tell us a lot about brain health. In this project, I test three different tools for finding the center points of microglia in 3D microscope images. The tools include ilastik, 3D Morph, and Omnipose. I look at how well each one finds the cells and how their results compare. My findings show that each tool sees the cells in its own way, and this can affect the kind of information we get from the images.","authors":["Youjia Zhang"],"url":"https://arxiv.org/abs/2505.04838"}
{"created":"2025-05-09","title":"Putting the Value Back in RL: Better Test-Time Scaling by Unifying LLM Reasoners With Verifiers","abstract":"Prevalent reinforcement learning~(RL) methods for fine-tuning LLM reasoners, such as GRPO or Leave-one-out PPO, abandon the learned value function in favor of empirically estimated returns. This hinders test-time compute scaling that relies on using the value-function for verification. In this work, we propose RL$^V$ that augments any ``value-free'' RL method by jointly training the LLM as both a reasoner and a generative verifier using RL-generated data, adding verification capabilities without significant overhead. Empirically, RL$^V$ boosts MATH accuracy by over 20\\% with parallel sampling and enables $8-32\\times$ efficient test-time compute scaling compared to the base RL method. RL$^V$ also exhibits strong generalization capabilities for both easy-to-hard and out-of-domain tasks. Furthermore, RL$^V$ achieves $1.2-1.6\\times$ higher performance when jointly scaling parallel and sequential test-time compute with a long reasoning R1 model.","authors":["Kusha Sareen","Morgane M Moss","Alessandro Sordoni","Rishabh Agarwal","Arian Hosseini"],"url":"https://arxiv.org/abs/2505.04842"}
{"created":"2025-05-09","title":"Large Language Models are Autonomous Cyber Defenders","abstract":"Fast and effective incident response is essential to prevent adversarial cyberattacks. Autonomous Cyber Defense (ACD) aims to automate incident response through Artificial Intelligence (AI) agents that plan and execute actions. Most ACD approaches focus on single-agent scenarios and leverage Reinforcement Learning (RL). However, ACD RL-trained agents depend on costly training, and their reasoning is not always explainable or transferable. Large Language Models (LLMs) can address these concerns by providing explainable actions in general security contexts. Researchers have explored LLM agents for ACD but have not evaluated them on multi-agent scenarios or interacting with other ACD agents. In this paper, we show the first study on how LLMs perform in multi-agent ACD environments by proposing a new integration to the CybORG CAGE 4 environment. We examine how ACD teams of LLM and RL agents can interact by proposing a novel communication protocol. Our results highlight the strengths and weaknesses of LLMs and RL and help us identify promising research directions to create, train, and deploy future teams of ACD agents.","authors":["Sebasti\\'an R. Castro","Roberto Campbell","Nancy Lau","Octavio Villalobos","Jiaqi Duan","Alvaro A. Cardenas"],"url":"https://arxiv.org/abs/2505.04843"}
{"created":"2025-05-09","title":"Osiris: A Lightweight Open-Source Hallucination Detection System","abstract":"Retrieval-Augmented Generation (RAG) systems have gained widespread adoption by application builders because they leverage sources of truth to enable Large Language Models (LLMs) to generate more factually sound responses. However, hallucinations, instances of LLM responses that are unfaithful to the provided context, often prevent these systems from being deployed in production environments. Current hallucination detection methods typically involve human evaluation or the use of closed-source models to review RAG system outputs for hallucinations. Both human evaluators and closed-source models suffer from scaling issues due to their high costs and slow inference speeds. In this work, we introduce a perturbed multi-hop QA dataset with induced hallucinations. Via supervised fine-tuning on our dataset, we achieve better recall with a 7B model than GPT-4o on the RAGTruth hallucination detection benchmark and offer competitive performance on precision and accuracy, all while using a fraction of the parameters. Code is released at our repository.","authors":["Alex Shan","John Bauer","Christopher D. Manning"],"url":"https://arxiv.org/abs/2505.04844"}
{"created":"2025-05-09","title":"HiPerRAG: High-Performance Retrieval Augmented Generation for Scientific Insights","abstract":"The volume of scientific literature is growing exponentially, leading to underutilized discoveries, duplicated efforts, and limited cross-disciplinary collaboration. Retrieval Augmented Generation (RAG) offers a way to assist scientists by improving the factuality of Large Language Models (LLMs) in processing this influx of information. However, scaling RAG to handle millions of articles introduces significant challenges, including the high computational costs associated with parsing documents and embedding scientific knowledge, as well as the algorithmic complexity of aligning these representations with the nuanced semantics of scientific content. To address these issues, we introduce HiPerRAG, a RAG workflow powered by high performance computing (HPC) to index and retrieve knowledge from more than 3.6 million scientific articles. At its core are Oreo, a high-throughput model for multimodal document parsing, and ColTrast, a query-aware encoder fine-tuning algorithm that enhances retrieval accuracy by using contrastive learning and late-interaction techniques. HiPerRAG delivers robust performance on existing scientific question answering benchmarks and two new benchmarks introduced in this work, achieving 90% accuracy on SciQ and 76% on PubMedQA-outperforming both domain-specific models like PubMedGPT and commercial LLMs such as GPT-4. Scaling to thousands of GPUs on the Polaris, Sunspot, and Frontier supercomputers, HiPerRAG delivers million document-scale RAG workflows for unifying scientific knowledge and fostering interdisciplinary innovation.","authors":["Ozan Gokdemir","Carlo Siebenschuh","Alexander Brace","Azton Wells","Brian Hsu","Kyle Hippe","Priyanka V. Setty","Aswathy Ajith","J. Gregory Pauloski","Varuni Sastry","Sam Foreman","Huihuo Zheng","Heng Ma","Bharat Kale","Nicholas Chia","Thomas Gibbs","Michael E. Papka","Thomas Brettin","Francis J. Alexander","Anima Anandkumar","Ian Foster","Rick Stevens","Venkatram Vishwanath","Arvind Ramanathan"],"url":"https://arxiv.org/abs/2505.04846"}
{"created":"2025-05-09","title":"Benchmarking LLM Faithfulness in RAG with Evolving Leaderboards","abstract":"Hallucinations remain a persistent challenge for LLMs. RAG aims to reduce hallucinations by grounding responses in contexts. However, even when provided context, LLMs still frequently introduce unsupported information or contradictions. This paper presents our efforts to measure LLM hallucinations with a focus on summarization tasks, assessing how often various LLMs introduce hallucinations when summarizing documents. We discuss Vectara's existing LLM hallucination leaderboard, based on the Hughes Hallucination Evaluation Model (HHEM). While HHEM and Vectara's Hallucination Leaderboard have garnered great research interest, we examine challenges faced by HHEM and current hallucination detection methods by analyzing the effectiveness of these methods on existing hallucination datasets. To address these limitations, we propose FaithJudge, an LLM-as-a-judge approach guided by few-shot human hallucination annotations, which substantially improves automated LLM hallucination evaluation over current methods. We introduce an enhanced hallucination leaderboard centered on FaithJudge, alongside our current hallucination leaderboard, enabling more reliable benchmarking of LLMs for hallucinations in RAG.","authors":["Manveer Singh Tamber","Forrest Sheng Bao","Chenyu Xu","Ge Luo","Suleman Kazi","Minseok Bae","Miaoran Li","Ofer Mendelevitch","Renyi Qu","Jimmy Lin"],"url":"https://arxiv.org/abs/2505.04847"}
{"created":"2025-05-09","title":"ORXE: Orchestrating Experts for Dynamically Configurable Efficiency","abstract":"This paper presents ORXE, a modular and adaptable framework for achieving real-time configurable efficiency in AI models. By leveraging a collection of pre-trained experts with diverse computational costs and performance levels, ORXE dynamically adjusts inference pathways based on the complexity of input samples. Unlike conventional approaches that require complex metamodel training, ORXE achieves high efficiency and flexibility without complicating the development process. The proposed system utilizes a confidence-based gating mechanism to allocate appropriate computational resources for each input. ORXE also supports adjustments to the preference between inference cost and prediction performance across a wide range during runtime. We implemented a training-free ORXE system for image classification tasks, evaluating its efficiency and accuracy across various devices. The results demonstrate that ORXE achieves superior performance compared to individual experts and other dynamic models in most cases. This approach can be extended to other applications, providing a scalable solution for diverse real-world deployment scenarios.","authors":["Qingyuan Wang","Guoxin Wang","Barry Cardiff","Deepu John"],"url":"https://arxiv.org/abs/2505.04850"}
{"created":"2025-05-09","title":"CRAFT: Cultural Russian-Oriented Dataset Adaptation for Focused Text-to-Image Generation","abstract":"Despite the fact that popular text-to-image generation models cope well with international and general cultural queries, they have a significant knowledge gap regarding individual cultures. This is due to the content of existing large training datasets collected on the Internet, which are predominantly based on Western European or American popular culture. Meanwhile, the lack of cultural adaptation of the model can lead to incorrect results, a decrease in the generation quality, and the spread of stereotypes and offensive content. In an effort to address this issue, we examine the concept of cultural code and recognize the critical importance of its understanding by modern image generation models, an issue that has not been sufficiently addressed in the research community to date. We propose the methodology for collecting and processing the data necessary to form a dataset based on the cultural code, in particular the Russian one. We explore how the collected data affects the quality of generations in the national domain and analyze the effectiveness of our approach using the Kandinsky 3.1 text-to-image model. Human evaluation results demonstrate an increase in the level of awareness of Russian culture in the model.","authors":["Viacheslav Vasilev","Vladimir Arkhipkin","Julia Agafonova","Tatiana Nikulina","Evelina Mironova","Alisa Shichanina","Nikolai Gerasimenko","Mikhail Shoytov","Denis Dimitrov"],"url":"https://arxiv.org/abs/2505.04851"}
{"created":"2025-05-09","title":"PR2: Peephole Raw Pointer Rewriting with LLMs for Translating C to Safer Rust","abstract":"There has been a growing interest in translating C code to Rust due to Rust's robust memory and thread safety guarantees. Tools such as C2RUST enable syntax-guided transpilation from C to semantically equivalent Rust code. However, the resulting Rust programs often rely heavily on unsafe constructs--particularly raw pointers--which undermines Rust's safety guarantees. This paper aims to improve the memory safety of Rust programs generated by C2RUST by eliminating raw pointers. Specifically, we propose a peephole raw pointer rewriting technique that lifts raw pointers in individual functions to appropriate Rust data structures. Technically, PR2 employs decision-tree-based prompting to guide the pointer lifting process. Additionally, it leverages code change analysis to guide the repair of errors introduced during rewriting, effectively addressing errors encountered during compilation and test case execution. We implement PR2 as a prototype and evaluate it using gpt-4o-mini on 28 real-world C projects. The results show that PR2 successfully eliminates 13.22% of local raw pointers across these projects, significantly enhancing the safety of the translated Rust code. On average, PR2 completes the transformation of a project in 5.44 hours, at an average cost of $1.46.","authors":["Yifei Gao","Chengpeng Wang","Pengxiang Huang","Xuwei Liu","Mingwei Zheng","Xiangyu Zhang"],"url":"https://arxiv.org/abs/2505.04852"}
{"created":"2025-05-09","title":"D-CODA: Diffusion for Coordinated Dual-Arm Data Augmentation","abstract":"Learning bimanual manipulation is challenging due to its high dimensionality and tight coordination required between two arms. Eye-in-hand imitation learning, which uses wrist-mounted cameras, simplifies perception by focusing on task-relevant views. However, collecting diverse demonstrations remains costly, motivating the need for scalable data augmentation. While prior work has explored visual augmentation in single-arm settings, extending these approaches to bimanual manipulation requires generating viewpoint-consistent observations across both arms and producing corresponding action labels that are both valid and feasible. In this work, we propose Diffusion for COordinated Dual-arm Data Augmentation (D-CODA), a method for offline data augmentation tailored to eye-in-hand bimanual imitation learning that trains a diffusion model to synthesize novel, viewpoint-consistent wrist-camera images for both arms while simultaneously generating joint-space action labels. It employs constrained optimization to ensure that augmented states involving gripper-to-object contacts adhere to constraints suitable for bimanual coordination. We evaluate D-CODA on 5 simulated and 3 real-world tasks. Our results across 2250 simulation trials and 300 real-world trials demonstrate that it outperforms baselines and ablations, showing its potential for scalable data augmentation in eye-in-hand bimanual manipulation. Our project website is at: https://dcodaaug.github.io/D-CODA/.","authors":["I-Chun Arthur Liu","Jason Chen","Gaurav Sukhatme","Daniel Seita"],"url":"https://arxiv.org/abs/2505.04860"}
{"created":"2025-05-09","title":"Mix-QSAM: Mixed-Precision Quantization of the Segment Anything Model","abstract":"The Segment Anything Model (SAM) is a popular vision foundation model; however, its high computational and memory demands make deployment on resource-constrained devices challenging. While Post-Training Quantization (PTQ) is a practical approach for reducing computational overhead, existing PTQ methods rely on fixed bit-width quantization, leading to suboptimal accuracy and efficiency. To address this limitation, we propose Mix-QSAM, a mixed-precision PTQ framework for SAM. First, we introduce a layer-wise importance score, derived using Kullback-Leibler (KL) divergence, to quantify each layer's contribution to the model's output. Second, we introduce cross-layer synergy, a novel metric based on causal mutual information, to capture dependencies between adjacent layers. This ensures that highly interdependent layers maintain similar bit-widths, preventing abrupt precision mismatches that degrade feature propagation and numerical stability. Using these metrics, we formulate an Integer Quadratic Programming (IQP) problem to determine optimal bit-width allocation under model size and bit-operation constraints, assigning higher precision to critical layers while minimizing bit-width in less influential layers. Experimental results demonstrate that Mix-QSAM consistently outperforms existing PTQ methods on instance segmentation and object detection tasks, achieving up to 20% higher average precision under 6-bit and 4-bit mixed-precision settings, while maintaining computational efficiency.","authors":["Navin Ranjan","Andreas Savakis"],"url":"https://arxiv.org/abs/2505.04861"}
{"created":"2025-05-09","title":"Auto-regressive transformation for image alignment","abstract":"Existing methods for image alignment struggle in cases involving feature-sparse regions, extreme scale and field-of-view differences, and large deformations, often resulting in suboptimal accuracy. Robustness to these challenges improves through iterative refinement of the transformation field while focusing on critical regions in multi-scale image representations. We thus propose Auto-Regressive Transformation (ART), a novel method that iteratively estimates the coarse-to-fine transformations within an auto-regressive framework. Leveraging hierarchical multi-scale features, our network refines the transformations using randomly sampled points at each scale. By incorporating guidance from the cross-attention layer, the model focuses on critical regions, ensuring accurate alignment even in challenging, feature-limited conditions. Extensive experiments across diverse datasets demonstrate that ART significantly outperforms state-of-the-art methods, establishing it as a powerful new method for precise image alignment with broad applicability.","authors":["Kanggeon Lee","Soochahn Lee","Kyoung Mu Lee"],"url":"https://arxiv.org/abs/2505.04864"}
{"created":"2025-05-09","title":"A mixed finite element method for a class of fourth-order stochastic evolution equations with multiplicative noise","abstract":"We develop a fully discrete, semi-implicit mixed finite element method for approximating solutions to a class of fourth-order stochastic partial differential equations (SPDEs) with non-globally Lipschitz and non-monotone nonlinearities, perturbed by spatially smooth multiplicative Gaussian noise. The proposed scheme is applicable to a range of physically relevant nonlinear models, including the stochastic Landau--Lifshitz--Baryakhtar (sLLBar) equation, the stochastic convective Cahn--Hilliard equation with mass source, and the stochastic regularised Landau--Lifshitz--Bloch (sLLB) equation, among others. To overcome the difficulties posed by the interplay between the nonlinearities and the stochastic forcing, we adopt a `truncate-then-discretise' strategy: the nonlinear term is first truncated before discretising the resulting modified problem. We show that the strong solution to the truncated problem converges in probability to that of the original problem. A fully discrete numerical scheme is then proposed for the truncated system, and we establish both convergence in probability and strong convergence (with quantitative rates) for the two fields used in the mixed formulation.","authors":["Beniamin Goldys","Agus L. Soenjaya","Thanh Tran"],"url":"https://arxiv.org/abs/2505.04866"}
{"created":"2025-05-09","title":"From First Draft to Final Insight: A Multi-Agent Approach for Feedback Generation","abstract":"Producing large volumes of high-quality, timely feedback poses significant challenges to instructors. To address this issue, automation technologies-particularly Large Language Models (LLMs)-show great potential. However, current LLM-based research still shows room for improvement in terms of feedback quality. Our study proposed a multi-agent approach performing \"generation, evaluation, and regeneration\" (G-E-RG) to further enhance feedback quality. In the first-generation phase, six methods were adopted, combining three feedback theoretical frameworks and two prompt methods: zero-shot and retrieval-augmented generation with chain-of-thought (RAG_CoT). The results indicated that, compared to first-round feedback, G-E-RG significantly improved final feedback across six methods for most dimensions. Specifically:(1) Evaluation accuracy for six methods increased by 3.36% to 12.98% (p<0.001); (2) The proportion of feedback containing four effective components rose from an average of 27.72% to an average of 98.49% among six methods, sub-dimensions of providing critiques, highlighting strengths, encouraging agency, and cultivating dialogue also showed great enhancement (p<0.001); (3) There was a significant improvement in most of the feature values (p<0.001), although some sub-dimensions (e.g., strengthening the teacher-student relationship) still require further enhancement; (4) The simplicity of feedback was effectively enhanced (p<0.001) for three methods.","authors":["Jie Cao","Chloe Qianhui Zhao","Xian Chen","Shuman Wang","Christian Schunn","Kenneth R. Koedinger","Jionghao Lin"],"url":"https://arxiv.org/abs/2505.04869"}
{"created":"2025-05-09","title":"Being polite is not enough (and other limits of theory combination)","abstract":"In the Nelson-Oppen combination method for satisfiability modulo theories, the combined theories must be stably infinite; in gentle combination, one theory has to be gentle, and the other has to satisfy a similar yet weaker property; in shiny combination, only one has to be shiny (smooth, with a computable minimal model function and the finite model property); and for polite combination, only one has to be strongly polite (smooth and strongly finitely witnessable). For each combination method, we prove that if any of its assumptions are removed, then there is no general method to combine an arbitrary pair of theories satisfying the remaining assumptions. We also prove new theory combination results that weaken the assumptions of gentle and shiny combination.","authors":["Guilherme V. Toledo","Benjamin Przybocki","Yoni Zohar"],"url":"https://arxiv.org/abs/2505.04870"}
{"created":"2025-05-09","title":"SatAOI: Delimitating Area of Interest for Swing-Arm Troweling Robot for Construction","abstract":"In concrete troweling for building construction, robots can significantly reduce workload and improve automation level. However, as a primary task of coverage path planning (CPP) for troweling, delimitating area of interest (AOI) in complex scenes is still challenging, especially for swing-arm robots with more complex working modes. Thus, this research proposes an algorithm to delimitate AOI for swing-arm troweling robot (SatAOI algorithm). By analyzing characteristics of the robot and obstacle maps, mathematical models and collision principles are established. On this basis, SatAOI algorithm achieves AOI delimitation by global search and collision detection. Experiments on different obstacle maps indicate that AOI can be effectively delimitated in scenes under different complexity, and the algorithm can fully consider the connectivity of obstacle maps. This research serves as a foundation for CPP algorithm and full process simulation of swing-arm troweling robots.","authors":["Jia-Rui Lin","Shaojie Zhou","Peng Pan","Ruijia Cai","Gang Chen"],"url":"https://arxiv.org/abs/2505.04871"}
{"created":"2025-05-09","title":"Federated Learning for Cyber Physical Systems: A Comprehensive Survey","abstract":"The integration of machine learning (ML) in cyber physical systems (CPS) is a complex task due to the challenges that arise in terms of real-time decision making, safety, reliability, device heterogeneity, and data privacy. There are also open research questions that must be addressed in order to fully realize the potential of ML in CPS. Federated learning (FL), a distributed approach to ML, has become increasingly popular in recent years. It allows models to be trained using data from decentralized sources. This approach has been gaining popularity in the CPS field, as it integrates computer, communication, and physical processes. Therefore, the purpose of this work is to provide a comprehensive analysis of the most recent developments of FL-CPS, including the numerous application areas, system topologies, and algorithms developed in recent years. The paper starts by discussing recent advances in both FL and CPS, followed by their integration. Then, the paper compares the application of FL in CPS with its applications in the internet of things (IoT) in further depth to show their connections and distinctions. Furthermore, the article scrutinizes how FL is utilized in critical CPS applications, e.g., intelligent transportation systems, cybersecurity services, smart cities, and smart healthcare solutions. The study also includes critical insights and lessons learned from various FL-CPS implementations. The paper's concluding section delves into significant concerns and suggests avenues for further research in this fast-paced and dynamic era.","authors":["Minh K. Quan","Pubudu N. Pathirana","Mayuri Wijayasundara","Sujeeva Setunge","Dinh C. Nguyen","Christopher G. Brinton","David J. Love","H. Vincent Poor"],"url":"https://arxiv.org/abs/2505.04873"}
{"created":"2025-05-09","title":"Physics-informed solution reconstruction in elasticity and heat transfer using the explicit constraint force method","abstract":"One use case of ``physics-informed neural networks'' (PINNs) is solution reconstruction, which aims to estimate the full-field state of a physical system from sparse measurements. Parameterized governing equations of the system are used in tandem with the measurements to regularize the regression problem. However, in real-world solution reconstruction problems, the parameterized governing equation may be inconsistent with the physical phenomena that give rise to the measurement data. We show that due to assuming consistency between the true and parameterized physics, PINNs-based approaches may fail to satisfy three basic criteria of interpretability, robustness, and data consistency. As we argue, these criteria ensure that (i) the quality of the reconstruction can be assessed, (ii) the reconstruction does not depend strongly on the choice of physics loss, and (iii) that in certain situations, the physics parameters can be uniquely recovered. In the context of elasticity and heat transfer, we demonstrate how standard formulations of the physics loss and techniques for constraining the solution to respect the measurement data lead to different ``constraint forces\" -- which we define as additional source terms arising from the constraints -- and that these constraint forces can significantly influence the reconstructed solution. To avoid the potentially substantial influence of the choice of physics loss and method of constraint enforcement on the reconstructed solution, we propose the ``explicit constraint force method'' (ECFM) to gain control of the source term introduced by the constraint. We then show that by satisfying the criteria of interpretability, robustness, and data consistency, this approach leads to more predictable and customizable reconstructions from noisy measurement data, even when the parameterization of the missing physics is inconsistent with the measured system.","authors":["Conor Rowan","Kurt Maute","Alireza Doostan"],"url":"https://arxiv.org/abs/2505.04875"}
{"created":"2025-05-09","title":"Learning from Loss Landscape: Generalizable Mixed-Precision Quantization via Adaptive Sharpness-Aware Gradient Aligning","abstract":"Mixed Precision Quantization (MPQ) has become an essential technique for optimizing neural network by determining the optimal bitwidth per layer. Existing MPQ methods, however, face a major hurdle: they require a computationally expensive search for quantization policies on large-scale datasets. To resolve this issue, we introduce a novel approach that first searches for quantization policies on small datasets and then generalizes them to large-scale datasets. This approach simplifies the process, eliminating the need for large-scale quantization fine-tuning and only necessitating model weight adjustment. Our method is characterized by three key techniques: sharpness-aware minimization for enhanced quantization generalization, implicit gradient direction alignment to handle gradient conflicts among different optimization objectives, and an adaptive perturbation radius to accelerate optimization. Both theoretical analysis and experimental results validate our approach. Using the CIFAR10 dataset (just 0.5\\% the size of ImageNet training data) for MPQ policy search, we achieved equivalent accuracy on ImageNet with a significantly lower computational cost, while improving efficiency by up to 150% over the baselines.","authors":["Lianbo Ma","Jianlun Ma","Yuee Zhou","Guoyang Xie","Qiang He","Zhichao Lu"],"url":"https://arxiv.org/abs/2505.04877"}
{"created":"2025-05-09","title":"Network Digital Twin for Route Optimization in 5G/B5G Transport Slicing with What-If Analysis","abstract":"The advent of fifth-generation (5G) and Beyond 5G (B5G) networks introduces diverse service requirements, from ultra-low latency to high bandwidth, demanding dynamic monitoring and advanced solutions to ensure Quality of Service (QoS). The transport network - responsible for interconnecting the radio access network and core networks - will increasingly face challenges in efficiently managing complex traffic patterns. The Network Digital Twin (NDT) concept emerges as a promising solution for testing configurations and algorithms in a virtual network before real-world deployment. In this context, this work designs an experimental platform with NDT in a transport network domain, synchronizing with the virtual counterpart and a recommendation system for what-if analysis, enabling intelligent decision-making for dynamic route optimization problems in 5G/B5G scenarios. Our NDT, composed of a Graph Neural Network (GNN), was evaluated across three different network topologies consisting of 8, 16, and 30 nodes. It achieved lower MAPE values for URLLC and eMBB slices, comparing latency predictions with actual latency after the solution implementation. These values indicate high accuracy, demonstrating the solution's effectiveness in generating precise insights into network performance if a particular solution were implemented.","authors":["Rebecca Aben-Athar","Heitor Anglada","Lucas Costa","Jo\\~ao Albuquerque","Abrah\\~ao Ferreira","Cristiano Bonato Both","Kleber Cardoso","Silvia Lins","Andrey Silva","Glauco Gon\\c{c}alves","Ilan Correa","Aldebaro Klautau"],"url":"https://arxiv.org/abs/2505.04879"}
{"created":"2025-05-09","title":"ConCISE: Confidence-guided Compression in Step-by-step Efficient Reasoning","abstract":"Large Reasoning Models (LRMs) perform strongly in complex reasoning tasks via Chain-of-Thought (CoT) prompting, but often suffer from verbose outputs caused by redundant content, increasing computational overhead, and degrading user experience. Existing compression methods either operate post-hoc pruning, risking disruption to reasoning coherence, or rely on sampling-based selection, which fails to intervene effectively during generation. In this work, we introduce a confidence-guided perspective to explain the emergence of redundant reflection in LRMs, identifying two key patterns: Confidence Deficit, where the model reconsiders correct steps due to low internal confidence, and Termination Delay, where reasoning continues even after reaching a confident answer. Based on this analysis, we propose ConCISE (Confidence-guided Compression In Step-by-step Efficient Reasoning), a framework that simplifies reasoning chains by reinforcing the model's confidence during inference, thus preventing the generation of redundant reflection steps. It integrates Confidence Injection to stabilize intermediate steps and Early Stopping to terminate reasoning when confidence is sufficient. Extensive experiments demonstrate that fine-tuning LRMs on ConCISE-generated data yields significantly shorter outputs, reducing length by up to approximately 50% under SimPO, while maintaining high task accuracy. ConCISE consistently outperforms existing baselines across multiple reasoning benchmarks.","authors":["Ziqing Qiao","Yongheng Deng","Jiali Zeng","Dong Wang","Lai Wei","Fandong Meng","Jie Zhou","Ju Ren","Yaoxue Zhang"],"url":"https://arxiv.org/abs/2505.04881"}
{"created":"2025-05-09","title":"QBR: A Question-Bank-Based Approach to Fine-Grained Legal Knowledge Retrieval for the General Public","abstract":"Retrieval of legal knowledge by the general public is a challenging problem due to the technicality of the professional knowledge and the lack of fundamental understanding by laypersons on the subject. Traditional information retrieval techniques assume that users are capable of formulating succinct and precise queries for effective document retrieval. In practice, however, the wide gap between the highly technical contents and untrained users makes legal knowledge retrieval very difficult. We propose a methodology, called QBR, which employs a Questions Bank (QB) as an effective medium for bridging the knowledge gap. We show how the QB is used to derive training samples to enhance the embedding of knowledge units within documents, which leads to effective fine-grained knowledge retrieval. We discuss and evaluate through experiments various advantages of QBR over traditional methods. These include more accurate, efficient, and explainable document retrieval, better comprehension of retrieval results, and highly effective fine-grained knowledge retrieval. We also present some case studies and show that QBR achieves social impact by assisting citizens to resolve everyday legal concerns.","authors":["Mingruo Yuan","Ben Kao","Tien-Hsuan Wu"],"url":"https://arxiv.org/abs/2505.04883"}
{"created":"2025-05-09","title":"A Multi-Agent AI Framework for Immersive Audiobook Production through Spatial Audio and Neural Narration","abstract":"This research introduces an innovative AI-driven multi-agent framework specifically designed for creating immersive audiobooks. Leveraging neural text-to-speech synthesis with FastSpeech 2 and VALL-E for expressive narration and character-specific voices, the framework employs advanced language models to automatically interpret textual narratives and generate realistic spatial audio effects. These sound effects are dynamically synchronized with the storyline through sophisticated temporal integration methods, including Dynamic Time Warping (DTW) and recurrent neural networks (RNNs). Diffusion-based generative models combined with higher-order ambisonics (HOA) and scattering delay networks (SDN) enable highly realistic 3D soundscapes, substantially enhancing listener immersion and narrative realism. This technology significantly advances audiobook applications, providing richer experiences for educational content, storytelling platforms, and accessibility solutions for visually impaired audiences. Future work will address personalization, ethical management of synthesized voices, and integration with multi-sensory platforms.","authors":["Shaja Arul Selvamani","Nia D'Souza Ganapathy"],"url":"https://arxiv.org/abs/2505.04885"}
{"created":"2025-05-09","title":"Fairness Perceptions in Regression-based Predictive Models","abstract":"Regression-based predictive analytics used in modern kidney transplantation is known to inherit biases from training data. This leads to social discrimination and inefficient organ utilization, particularly in the context of a few social groups. Despite this concern, there is limited research on fairness in regression and its impact on organ utilization and placement. This paper introduces three novel divergence-based group fairness notions: (i) independence, (ii) separation, and (iii) sufficiency to assess the fairness of regression-based analytics tools. In addition, fairness preferences are investigated from crowd feedback, in order to identify a socially accepted group fairness criterion for evaluating these tools. A total of 85 participants were recruited from the Prolific crowdsourcing platform, and a Mixed-Logit discrete choice model was used to model fairness feedback and estimate social fairness preferences. The findings clearly depict a strong preference towards the separation and sufficiency fairness notions, and that the predictive analytics is deemed fair with respect to gender and race groups, but unfair in terms of age groups.","authors":["Mukund Telukunta","Venkata Sriram Siddhardh Nadendla","Morgan Stuart","Casey Canfield"],"url":"https://arxiv.org/abs/2505.04886"}
{"created":"2025-05-09","title":"Cross-Branch Orthogonality for Improved Generalization in Face Deepfake Detection","abstract":"Remarkable advancements in generative AI technology have given rise to a spectrum of novel deepfake categories with unprecedented leaps in their realism, and deepfakes are increasingly becoming a nuisance to law enforcement authorities and the general public. In particular, we observe alarming levels of confusion, deception, and loss of faith regarding multimedia content within society caused by face deepfakes, and existing deepfake detectors are struggling to keep up with the pace of improvements in deepfake generation. This is primarily due to their reliance on specific forgery artifacts, which limits their ability to generalise and detect novel deepfake types. To combat the spread of malicious face deepfakes, this paper proposes a new strategy that leverages coarse-to-fine spatial information, semantic information, and their interactions while ensuring feature distinctiveness and reducing the redundancy of the modelled features. A novel feature orthogonality-based disentanglement strategy is introduced to ensure branch-level and cross-branch feature disentanglement, which allows us to integrate multiple feature vectors without adding complexity to the feature space or compromising generalisation. Comprehensive experiments on three public benchmarks: FaceForensics++, Celeb-DF, and the Deepfake Detection Challenge (DFDC) show that these design choices enable the proposed approach to outperform current state-of-the-art methods by 5% on the Celeb-DF dataset and 7% on the DFDC dataset in a cross-dataset evaluation setting.","authors":["Tharindu Fernando","Clinton Fookes","Sridha Sridharan","Simon Denman"],"url":"https://arxiv.org/abs/2505.04888"}
{"created":"2025-05-09","title":"FedRE: Robust and Effective Federated Learning with Privacy Preference","abstract":"Despite Federated Learning (FL) employing gradient aggregation at the server for distributed training to prevent the privacy leakage of raw data, private information can still be divulged through the analysis of uploaded gradients from clients. Substantial efforts have been made to integrate local differential privacy (LDP) into the system to achieve a strict privacy guarantee. However, existing methods fail to take practical issues into account by merely perturbing each sample with the same mechanism while each client may have their own privacy preferences on privacy-sensitive information (PSI), which is not uniformly distributed across the raw data. In such a case, excessive privacy protection from private-insensitive information can additionally introduce unnecessary noise, which may degrade the model performance. In this work, we study the PSI within data and develop FedRE, that can simultaneously achieve robustness and effectiveness benefits with LDP protection. More specifically, we first define PSI with regard to the privacy preferences of each client. Then, we optimize the LDP by allocating less privacy budget to gradients with higher PSI in a layer-wise manner, thus providing a stricter privacy guarantee for PSI. Furthermore, to mitigate the performance degradation caused by LDP, we design a parameter aggregation mechanism based on the distribution of the perturbed information. We conducted experiments with text tamper detection on T-SROIE and DocTamper datasets, and FedRE achieves competitive performance compared to state-of-the-art methods.","authors":["Tianzhe Xiao","Yichen Li","Yu Zhou","Yining Qi","Yi Liu","Wei Wang","Haozhao Wang","Yi Wang","Ruixuan Li"],"url":"https://arxiv.org/abs/2505.04889"}
{"created":"2025-05-09","title":"Theatrical Language Processing: Exploring AI-Augmented Improvisational Acting and Scriptwriting with LLMs","abstract":"The increasing convergence of artificial intelligence has opened new avenues, including its emerging role in enhancing creativity. It is reshaping traditional creative practices such as actor improvisation, which often struggles with predictable patterns, limited interaction, and a lack of engaging stimuli. In this paper, we introduce a new concept, Theatrical Language Processing (TLP), and an AI-driven creativity support tool, Scribble.ai, designed to augment actors' creative expression and spontaneity through interactive practice. We conducted a user study involving tests and interviews with fourteen participants. Our findings indicate that: (1) Actors expanded their creativity when faced with AI-produced irregular scenarios; (2) The AI's unpredictability heightened their problem-solving skills, specifically in interpreting unfamiliar situations; (3) However, AI often generated excessively detailed scripts, which limited interpretive freedom and hindered subtext exploration. Based on these findings, we discuss the new potential in enhancing creative expressions in film and theater studies through an AI-driven tool.","authors":["Sora Kang","Joonhwan Lee"],"url":"https://arxiv.org/abs/2505.04890"}
{"created":"2025-05-09","title":"Clustering with Communication: A Variational Framework for Single Cell Representation Learning","abstract":"Single-cell RNA sequencing (scRNA-seq) has revealed complex cellular heterogeneity, but recent studies emphasize that understanding biological function also requires modeling cell-cell communication (CCC), the signaling interactions mediated by ligand-receptor pairs that coordinate cellular behavior. Tools like CellChat have demonstrated that CCC plays a critical role in processes such as cell differentiation, tissue regeneration, and immune response, and that transcriptomic data inherently encodes rich information about intercellular signaling. We propose CCCVAE, a novel variational autoencoder framework that incorporates CCC signals into single-cell representation learning. By leveraging a communication-aware kernel derived from ligand-receptor interactions and a sparse Gaussian process, CCCVAE encodes biologically informed priors into the latent space. Unlike conventional VAEs that treat each cell independently, CCCVAE encourages latent embeddings to reflect both transcriptional similarity and intercellular signaling context. Empirical results across four scRNA-seq datasets show that CCCVAE improves clustering performance, achieving higher evaluation scores than standard VAE baselines. This work demonstrates the value of embedding biological priors into deep generative models for unsupervised single-cell analysis.","authors":["Cong Qi","Yeqing Chen","Jie Zhang","Wei Zhi"],"url":"https://arxiv.org/abs/2505.04891"}
{"created":"2025-05-09","title":"PSSketch: Finding Persistent and Sparse Flow with High Accuracy and Efficiency","abstract":"Finding persistent sparse (PS) flow is critical to early warning of many threats. Previous works have predominantly focused on either heavy or persistent flows, with limited attention given to PS flows. Although some recent studies pay attention to PS flows, they struggle to establish an objective criterion due to insufficient data-driven observations, resulting in reduced accuracy. In this paper, we define a new criterion \"anomaly boundary\" to distinguish PS flows from regular flows. Specifically, a flow whose persistence exceeds a threshold will be protected, while a protected flow with a density lower than a threshold is reported as a PS flow. We then introduce PSSketch, a high-precision layered sketch to find PS flows. PSSketch employs variable-length bitwise counters, where the first layer tracks the frequency and persistence of all flows, and the second layer protects potential PS flows and records overflow counts from the first layer. Some optimizations have also been implemented to reduce memory consumption further and improve accuracy. The experiments show that PSSketch reduces memory consumption by an order of magnitude compared to the strawman solution combined with existing work. Compared with SOTA solutions for finding PS flows, it outperforms up to 2.94x in F1 score and reduces ARE by 1-2 orders of magnitude. Meanwhile, PSSketch achieves a higher throughput than these solutions.","authors":["Jiayao Wang","Qilong Shi","Xiyan Liang","Han Wang","Wenjun Li","Ziling Wei","Weizhe Zhang","Shuhui Chen"],"url":"https://arxiv.org/abs/2505.04892"}
{"created":"2025-05-09","title":"Max-Min Secrecy Rate and Secrecy Energy Efficiency Optimization for RIS-Aided VLC Systems: RSMA Versus NOMA","abstract":"Integrating VLC with the RIS significantly enhances physical layer security by enabling precise directional signal control and dynamic adaptation to the communication environment. These capabilities strengthen the confidentiality and security of VLC systems. This paper presents a comprehensive study on the joint optimization of VLC AP power allocation, RIS association, and RIS elements orientation angles for secure VLC systems, while considering RSMA and power-domain NOMA schemes. Specifically, two frameworks are proposed to maximize both the minimum secrecy rate (SR) and the minimum secrecy energy efficiency (SEE) by jointly optimizing power allocation, RIS association, and RIS elements orientation angles for both power-domain NOMA and RSMA-based VLC systems. The proposed frameworks consider random device orientation and guarantee the minimum user-rate requirement. The proposed optimization frameworks belong to the class of mixed integer nonlinear programming, which has no known feasible solution methodology to guarantee the optimal solution. Moreover, the increased degree of freedom and flexibility from the joint consideration of power control, RIS association and element orientation results in a large set of decision variables and constraints, which further complicates the optimization problem. To that end, we utilize a genetic algorithm-based solution method, which through its exploration and exploitation capabilities can obtain a good quality solution. Additionally, comprehensive simulations show that the RSMA scheme outperforms the power-domain NOMA scheme across both the SR and SEE metrics over various network parameters. Furthermore, useful insights on the impact of minimum user rate requirement, number of RIS elements, and maximum VLC AP transmit power on the minimum SR and SEE performances are provided.","authors":["Omar Maraqa","Sylvester Aboagye","Majid H. Khoshafa","Telex M. N. Ngatched"],"url":"https://arxiv.org/abs/2505.04893"}
{"created":"2025-05-09","title":"GCN-Based Throughput-Oriented Handover Management in Dense 5G Vehicular Networks","abstract":"The rapid advancement of 5G has transformed vehicular networks, offering high bandwidth, low latency, and fast data rates essential for real-time applications in smart cities and vehicles. These improvements enhance traffic safety and entertainment services. However, the limited coverage and frequent handovers in 5G networks cause network instability, especially in high-mobility environments due to the ping-pong effect. This paper presents TH-GCN (Throughput-oriented Graph Convolutional Network), a novel approach for optimizing handover management in dense 5G networks. Using graph neural networks (GNNs), TH-GCN models vehicles and base stations as nodes in a dynamic graph enriched with features such as signal quality, throughput, vehicle speed, and base station load. By integrating both user equipment and base station perspectives, this dual-centric approach enables adaptive, real-time handover decisions that improve network stability. Simulation results show that TH-GCN reduces handovers by up to 78 percent and improves signal quality by 10 percent, outperforming existing methods.","authors":["Nazanin Mehregan","Robson E. De Grande"],"url":"https://arxiv.org/abs/2505.04894"}
{"created":"2025-05-09","title":"Memory Under Siege: A Comprehensive Survey of Side-Channel Attacks on Memory","abstract":"Side-channel attacks on memory (SCAM) exploit unintended data leaks from memory subsystems to infer sensitive information, posing significant threats to system security. These attacks exploit vulnerabilities in memory access patterns, cache behaviors, and other microarchitectural features to bypass traditional security measures. The purpose of this research is to examine SCAM, classify various attack techniques, and evaluate existing defense mechanisms. It guides researchers and industry professionals in improving memory security and mitigating emerging threats. We begin by identifying the major vulnerabilities in the memory system that are frequently exploited in SCAM, such as cache timing, speculative execution, \\textit{Rowhammer}, and other sophisticated approaches. Next, we outline a comprehensive taxonomy that systematically classifies these attacks based on their types, target systems, attack vectors, and adversarial capabilities required to execute them. In addition, we review the current landscape of mitigation strategies, emphasizing their strengths and limitations. This work aims to provide a comprehensive overview of memory-based side-channel attacks with the goal of providing significant insights for researchers and practitioners to better understand, detect, and mitigate SCAM risks.","authors":["MD Mahady Hassan","Shanto Roy","Reza Rahaeimehr"],"url":"https://arxiv.org/abs/2505.04896"}
{"created":"2025-05-09","title":"CubeDAgger: Improved Robustness of Interactive Imitation Learning without Violation of Dynamic Stability","abstract":"Interactive imitation learning makes an agent's control policy robust by stepwise supervisions from an expert. The recent algorithms mostly employ expert-agent switching systems to reduce the expert's burden by limitedly selecting the supervision timing. However, the precise selection is difficult and such a switching causes abrupt changes in actions, damaging the dynamic stability. This paper therefore proposes a novel method, so-called CubeDAgger, which improves robustness while reducing dynamic stability violations by making three improvements to a baseline method, EnsembleDAgger. The first improvement adds a regularization to explicitly activate the threshold for deciding the supervision timing. The second transforms the expert-agent switching system to an optimal consensus system of multiple action candidates. Third, autoregressive colored noise to the actions is introduced to make the stochastic exploration consistent over time. These improvements are verified by simulations, showing that the learned policies are sufficiently robust while maintaining dynamic stability during interaction.","authors":["Taisuke Kobayashi"],"url":"https://arxiv.org/abs/2505.04897"}
{"created":"2025-05-09","title":"Precise gradient descent training dynamics for finite-width multi-layer neural networks","abstract":"In this paper, we provide the first precise distributional characterization of gradient descent iterates for general multi-layer neural networks under the canonical single-index regression model, in the `finite-width proportional regime' where the sample size and feature dimension grow proportionally while the network width and depth remain bounded. Our non-asymptotic state evolution theory captures Gaussian fluctuations in first-layer weights and concentration in deeper-layer weights, and remains valid for non-Gaussian features.","authors":["Qiyang Han","Masaaki Imaizumi"],"url":"https://arxiv.org/abs/2505.04898"}
{"created":"2025-05-09","title":"OWT: A Foundational Organ-Wise Tokenization Framework for Medical Imaging","abstract":"Recent advances in representation learning often rely on holistic, black-box embeddings that entangle multiple semantic components, limiting interpretability and generalization. These issues are especially critical in medical imaging. To address these limitations, we propose an Organ-Wise Tokenization (OWT) framework with a Token Group-based Reconstruction (TGR) training paradigm. Unlike conventional approaches that produce holistic features, OWT explicitly disentangles an image into separable token groups, each corresponding to a distinct organ or semantic entity. Our design ensures each token group encapsulates organ-specific information, boosting interpretability, generalization, and efficiency while allowing fine-grained control in downstream tasks. Experiments on CT and MRI datasets demonstrate the effectiveness of OWT in not only achieving strong image reconstruction and segmentation performance, but also enabling novel semantic-level generation and retrieval applications that are out of reach for standard holistic embedding methods. These findings underscore the potential of OWT as a foundational framework for semantically disentangled representation learning, offering broad scalability and applicability to real-world medical imaging scenarios and beyond.","authors":["Sifan Song","Siyeop Yoon","Pengfei Jin","Sekeun Kim","Matthew Tivnan","Yujin Oh","Runqi Meng","Ling Chen","Zhiliang Lyu","Dufan Wu","Ning Guo","Xiang Li","Quanzheng Li"],"url":"https://arxiv.org/abs/2505.04899"}
{"created":"2025-05-09","title":"Learning Economic Model Predictive Control via Clustering and Kernel-Based Lipschitz Regression","abstract":"This paper presents a novel learning economic model predictive control scheme for uncertain nonlinear systems subject to input and state constraints and unknown dynamics. We design a fast and accurate Lipschitz regression method using input and output data that combines clustering and kernel regression to learn the unknown dynamics. In each cluster, the parallel convex optimization problems are solved to estimate the kernel weights and reduce the Lipschitz constant of the predictor, hence limiting the error propagation in the prediction horizon. We derive the two different bounds of learning errors in deterministic and probabilistic forms and customize a new robust constraint-tightening strategy for the discontinuous predictor. Then, the learning economic model predictive control algorithm is formulated by introducing a stabilized optimization problem to construct a Lyapunov function. Sufficient conditions are derived to ensure the recursive feasibility and input-to-state stability of the closed-loop system. The effectiveness of the proposed algorithm is verified by simulations of a numerical example and a continuously stirred tank reactor.","authors":["Weiliang Xiong","Defeng He","Haiping Du"],"url":"https://arxiv.org/abs/2505.04904"}
{"created":"2025-05-09","title":"Pro2SAM: Mask Prompt to SAM with Grid Points for Weakly Supervised Object Localization","abstract":"Weakly Supervised Object Localization (WSOL), which aims to localize objects by only using image-level labels, has attracted much attention because of its low annotation cost in real applications. Current studies focus on the Class Activation Map (CAM) of CNN and the self-attention map of transformer to identify the region of objects. However, both CAM and self-attention maps can not learn pixel-level fine-grained information on the foreground objects, which hinders the further advance of WSOL. To address this problem, we initiatively leverage the capability of zero-shot generalization and fine-grained segmentation in Segment Anything Model (SAM) to boost the activation of integral object regions. Further, to alleviate the semantic ambiguity issue accrued in single point prompt-based SAM, we propose an innovative mask prompt to SAM (Pro2SAM) network with grid points for WSOL task. First, we devise a Global Token Transformer (GTFormer) to generate a coarse-grained foreground map as a flexible mask prompt, where the GTFormer jointly embeds patch tokens and novel global tokens to learn foreground semantics. Secondly, we deliver grid points as dense prompts into SAM to maximize the probability of foreground mask, which avoids the lack of objects caused by a single point/box prompt. Finally, we propose a pixel-level similarity metric to come true the mask matching from mask prompt to SAM, where the mask with the highest score is viewed as the final localization map. Experiments show that the proposed Pro2SAM achieves state-of-the-art performance on both CUB-200-2011 and ILSVRC, with 84.03\\% and 66.85\\% Top-1 Loc, respectively.","authors":["Xi Yang","Songsong Duan","Nannan Wang","Xinbo Gao"],"url":"https://arxiv.org/abs/2505.04905"}
{"created":"2025-05-09","title":"VaCDA: Variational Contrastive Alignment-based Scalable Human Activity Recognition","abstract":"Technological advancements have led to the rise of wearable devices with sensors that continuously monitor user activities, generating vast amounts of unlabeled data. This data is challenging to interpret, and manual annotation is labor-intensive and error-prone. Additionally, data distribution is often heterogeneous due to device placement, type, and user behavior variations. As a result, traditional transfer learning methods perform suboptimally, making it difficult to recognize daily activities. To address these challenges, we use a variational autoencoder (VAE) to learn a shared, low-dimensional latent space from available sensor data. This space generalizes data across diverse sensors, mitigating heterogeneity and aiding robust adaptation to the target domain. We integrate contrastive learning to enhance feature representation by aligning instances of the same class across domains while separating different classes. We propose Variational Contrastive Domain Adaptation (VaCDA), a multi-source domain adaptation framework combining VAEs and contrastive learning to improve feature representation and reduce heterogeneity between source and target domains. We evaluate VaCDA on multiple publicly available datasets across three heterogeneity scenarios: cross-person, cross-position, and cross-device. VaCDA outperforms the baselines in cross-position and cross-device scenarios.","authors":["Soham Khisa","Avijoy Chakma"],"url":"https://arxiv.org/abs/2505.04907"}
{"created":"2025-05-09","title":"SpatialPrompting: Keyframe-driven Zero-Shot Spatial Reasoning with Off-the-Shelf Multimodal Large Language Models","abstract":"This study introduces SpatialPrompting, a novel framework that harnesses the emergent reasoning capabilities of off-the-shelf multimodal large language models to achieve zero-shot spatial reasoning in three-dimensional (3D) environments. Unlike existing methods that rely on expensive 3D-specific fine-tuning with specialized 3D inputs such as point clouds or voxel-based features, SpatialPrompting employs a keyframe-driven prompt generation strategy. This framework uses metrics such as vision-language similarity, Mahalanobis distance, field of view, and image sharpness to select a diverse and informative set of keyframes from image sequences and then integrates them with corresponding camera pose data to effectively abstract spatial relationships and infer complex 3D structures. The proposed framework not only establishes a new paradigm for flexible spatial reasoning that utilizes intuitive visual and positional cues but also achieves state-of-the-art zero-shot performance on benchmark datasets, such as ScanQA and SQA3D, across several metrics. The proposed method effectively eliminates the need for specialized 3D inputs and fine-tuning, offering a simpler and more scalable alternative to conventional approaches.","authors":["Shun Taguchi","Hideki Deguchi","Takumi Hamazaki","Hiroyuki Sakai"],"url":"https://arxiv.org/abs/2505.04911"}
{"created":"2025-05-09","title":"Enigme: Generative Text Puzzles for Evaluating Reasoning in Language Models","abstract":"Transformer-decoder language models are a core innovation in text based generative artificial intelligence. These models are being deployed as general-purpose intelligence systems in many applications. Central to their utility is the capacity to understand natural language commands and exploit the reasoning embedded in human text corpora to apply some form of reasoning process to a wide variety of novel tasks. To understand the limitations of this approach to generating reasoning we argue that we need to consider the architectural constraints of these systems. Consideration of the latent variable structure of transformer-decoder models allows us to design reasoning tasks that should probe the boundary of their capacity to reason. We present enigme, an open-source library for generating text-based puzzles to be used in training and evaluating reasoning skills within transformer-decoder models and future AI architectures.","authors":["John Hawkins"],"url":"https://arxiv.org/abs/2505.04914"}
{"created":"2025-05-09","title":"GlyphMastero: A Glyph Encoder for High-Fidelity Scene Text Editing","abstract":"Scene text editing, a subfield of image editing, requires modifying texts in images while preserving style consistency and visual coherence with the surrounding environment. While diffusion-based methods have shown promise in text generation, they still struggle to produce high-quality results. These methods often generate distorted or unrecognizable characters, particularly when dealing with complex characters like Chinese. In such systems, characters are composed of intricate stroke patterns and spatial relationships that must be precisely maintained. We present GlyphMastero, a specialized glyph encoder designed to guide the latent diffusion model for generating texts with stroke-level precision. Our key insight is that existing methods, despite using pretrained OCR models for feature extraction, fail to capture the hierarchical nature of text structures - from individual strokes to stroke-level interactions to overall character-level structure. To address this, our glyph encoder explicitly models and captures the cross-level interactions between local-level individual characters and global-level text lines through our novel glyph attention module. Meanwhile, our model implements a feature pyramid network to fuse the multi-scale OCR backbone features at the global-level. Through these cross-level and multi-scale fusions, we obtain more detailed glyph-aware guidance, enabling precise control over the scene text generation process. Our method achieves an 18.02\\% improvement in sentence accuracy over the state-of-the-art multi-lingual scene text editing baseline, while simultaneously reducing the text-region Fr\\'echet inception distance by 53.28\\%.","authors":["Tong Wang","Ting Liu","Xiaochao Qu","Chengjing Wu","Luoqi Liu","Xiaolin Hu"],"url":"https://arxiv.org/abs/2505.04915"}
{"created":"2025-05-09","title":"An Open-Source Dual-Loss Embedding Model for Semantic Retrieval in Higher Education","abstract":"Recent advances in AI have catalyzed the adoption of intelligent educational tools, yet many semantic retrieval systems remain ill-suited to the unique linguistic and structural characteristics of academic content. This study presents two open-source embedding models fine-tuned for educational question answering, particularly in the context of course syllabi. A synthetic dataset of 3,197 sentence pairs, spanning synonymous terminology, paraphrased questions, and implicit-explicit mappings, was constructed through a combination of manual curation and large language model (LLM)-assisted generation. Two training strategies were evaluated: (1) a baseline model fine-tuned using MultipleNegativesRankingLoss (MNRL), and (2) a dual-loss model that combines MNRL with CosineSimilarityLoss to improve both semantic ranking and similarity calibration. Evaluations were conducted on 28 university course syllabi using a fixed set of natural language questions categorized into course, faculty, and teaching assistant information. Results demonstrate that both fine-tuned models outperform strong open-source baselines, including all-MiniLM-L6-v2 and multi-qa-MiniLM-L6-cos-v1, and that the dual-loss model narrows the performance gap with high-performing proprietary embeddings such as OpenAI's text-embedding-3 series. This work contributes reusable, domain-aligned embedding models and provides a replicable framework for educational semantic retrieval, supporting downstream applications such as academic chatbots, retrieval-augmented generation (RAG) systems, and learning management system (LMS) integrations.","authors":["Ramteja Sajja","Yusuf Sermet","Ibrahim Demir"],"url":"https://arxiv.org/abs/2505.04916"}
{"created":"2025-05-09","title":"A Simple Detector with Frame Dynamics is a Strong Tracker","abstract":"Infrared object tracking plays a crucial role in Anti-Unmanned Aerial Vehicle (Anti-UAV) applications. Existing trackers often depend on cropped template regions and have limited motion modeling capabilities, which pose challenges when dealing with tiny targets. To address this, we propose a simple yet effective infrared tiny-object tracker that enhances tracking performance by integrating global detection and motion-aware learning with temporal priors. Our method is based on object detection and achieves significant improvements through two key innovations. First, we introduce frame dynamics, leveraging frame difference and optical flow to encode both prior target features and motion characteristics at the input level, enabling the model to better distinguish the target from background clutter. Second, we propose a trajectory constraint filtering strategy in the post-processing stage, utilizing spatio-temporal priors to suppress false positives and enhance tracking robustness. Extensive experiments show that our method consistently outperforms existing approaches across multiple metrics in challenging infrared UAV tracking scenarios. Notably, we achieve state-of-the-art performance in the 4th Anti-UAV Challenge, securing 1st place in Track 1 and 2nd place in Track 2.","authors":["Chenxu Peng","Chenxu Wang","Minrui Zou","Danyang Li","Zhengpeng Yang","Yimian Dai","Ming-Ming Cheng","Xiang Li"],"url":"https://arxiv.org/abs/2505.04917"}
{"created":"2025-05-09","title":"Physics-Assisted and Topology-Informed Deep Learning for Weather Prediction","abstract":"Although deep learning models have demonstrated remarkable potential in weather prediction, most of them overlook either the \\textbf{physics} of the underlying weather evolution or the \\textbf{topology} of the Earth's surface. In light of these disadvantages, we develop PASSAT, a novel Physics-ASSisted And Topology-informed deep learning model for weather prediction. PASSAT attributes the weather evolution to two key factors: (i) the advection process that can be characterized by the advection equation and the Navier-Stokes equation; (ii) the Earth-atmosphere interaction that is difficult to both model and calculate. PASSAT also takes the topology of the Earth's surface into consideration, other than simply treating it as a plane. With these considerations, PASSAT numerically solves the advection equation and the Navier-Stokes equation on the spherical manifold, utilizes a spherical graph neural network to capture the Earth-atmosphere interaction, and generates the initial velocity fields that are critical to solving the advection equation from the same spherical graph neural network. In the $5.625^\\circ$-resolution ERA5 data set, PASSAT outperforms both the state-of-the-art deep learning-based weather prediction models and the operational numerical weather prediction model IFS T42. Code and checkpoint are available at https://github.com/Yumenomae/PASSAT_5p625.","authors":["Jiaqi Zheng","Qing Ling","Yerong Feng"],"url":"https://arxiv.org/abs/2505.04918"}
{"created":"2025-05-09","title":"Perception, Reason, Think, and Plan: A Survey on Large Multimodal Reasoning Models","abstract":"Reasoning lies at the heart of intelligence, shaping the ability to make decisions, draw conclusions, and generalize across domains. In artificial intelligence, as systems increasingly operate in open, uncertain, and multimodal environments, reasoning becomes essential for enabling robust and adaptive behavior. Large Multimodal Reasoning Models (LMRMs) have emerged as a promising paradigm, integrating modalities such as text, images, audio, and video to support complex reasoning capabilities and aiming to achieve comprehensive perception, precise understanding, and deep reasoning. As research advances, multimodal reasoning has rapidly evolved from modular, perception-driven pipelines to unified, language-centric frameworks that offer more coherent cross-modal understanding. While instruction tuning and reinforcement learning have improved model reasoning, significant challenges remain in omni-modal generalization, reasoning depth, and agentic behavior. To address these issues, we present a comprehensive and structured survey of multimodal reasoning research, organized around a four-stage developmental roadmap that reflects the field's shifting design philosophies and emerging capabilities. First, we review early efforts based on task-specific modules, where reasoning was implicitly embedded across stages of representation, alignment, and fusion. Next, we examine recent approaches that unify reasoning into multimodal LLMs, with advances such as Multimodal Chain-of-Thought (MCoT) and multimodal reinforcement learning enabling richer and more structured reasoning chains. Finally, drawing on empirical insights from challenging benchmarks and experimental cases of OpenAI O3 and O4-mini, we discuss the conceptual direction of native large multimodal reasoning models (N-LMRMs), which aim to support scalable, agentic, and adaptive reasoning and planning in complex, real-world environments.","authors":["Yunxin Li","Zhenyu Liu","Zitao Li","Xuanyu Zhang","Zhenran Xu","Xinyu Chen","Haoyuan Shi","Shenyuan Jiang","Xintong Wang","Jifang Wang","Shouzheng Huang","Xinping Zhao","Borui Jiang","Lanqing Hong","Longyue Wang","Zhuotao Tian","Baoxing Huai","Wenhan Luo","Weihua Luo","Zheng Zhang","Baotian Hu","Min Zhang"],"url":"https://arxiv.org/abs/2505.04921"}
{"created":"2025-05-09","title":"Canny2Palm: Realistic and Controllable Palmprint Generation for Large-scale Pre-training","abstract":"Palmprint recognition is a secure and privacy-friendly method of biometric identification. One of the major challenges to improve palmprint recognition accuracy is the scarcity of palmprint data. Recently, a popular line of research revolves around the synthesis of virtual palmprints for large-scale pre-training purposes. In this paper, we propose a novel synthesis method named Canny2Palm that extracts palm textures with Canny edge detector and uses them to condition a Pix2Pix network for realistic palmprint generation. By re-assembling palmprint textures from different identities, we are able to create new identities by seeding the generator with new assemblies. Canny2Palm not only synthesizes realistic data following the distribution of real palmprints but also enables controllable diversity to generate large-scale new identities. On open-set palmprint recognition benchmarks, models pre-trained with Canny2Palm synthetic data outperform the state-of-the-art with up to 7.2% higher identification accuracy. Moreover, the performance of models pre-trained with Canny2Palm continues to improve given 10,000 synthetic IDs while those with existing methods already saturate, demonstrating the potential of our method for large-scale pre-training.","authors":["Xingzeng Lan","Xing Duan","Chen Chen","Weiyu Lin","Bo Wang"],"url":"https://arxiv.org/abs/2505.04922"}
{"created":"2025-05-09","title":"Numerical analysis for subdiffusion problem with non-positive memory","abstract":"This work considers the subdiffusion problem with non-positive memory, which not only arises from physical laws with memory, but could be transformed from sophisticated models such as subdiffusion or subdiffusive Fokker-Planck equation with variable exponent. We apply the non-uniform L1 formula and interpolation quadrature to discretize the fractional derivative and the memory term, respectively, and then adopt the complementary discrete convolution kernel approach to prove the stability and first-order temporal accuracy of the scheme. The main difficulty in numerical analysis lies in the non-positivity of the kernel and its coupling with the complementary discrete convolution kernel (such that different model exponents are also coupled), and the results extend those in [Chen, Thom\\'ee and Wahlbin, Math. Comp. 1992] to the subdiffusive case. Numerical experiments are performed to substantiate the theoretical results.","authors":["Wenlin Qiu","Xiangcheng Zheng"],"url":"https://arxiv.org/abs/2505.04924"}
{"created":"2025-05-09","title":"Belief Filtering for Epistemic Control in Linguistic State Space","abstract":"We examine belief filtering as a mechanism for the epistemic control of artificial agents, focusing on the regulation of internal cognitive states represented as linguistic expressions. This mechanism is developed within the Semantic Manifold framework, where belief states are dynamic, structured ensembles of natural language fragments. Belief filters act as content-aware operations on these fragments across various cognitive transitions. This paper illustrates how the inherent interpretability and modularity of such a linguistically-grounded cognitive architecture directly enable belief filtering, offering a principled approach to agent regulation. The study highlights the potential for enhancing AI safety and alignment through structured interventions in an agent's internal semantic space and points to new directions for architecturally embedded cognitive governance.","authors":["Sebastian Dumbrava"],"url":"https://arxiv.org/abs/2505.04927"}
{"created":"2025-05-09","title":"Accurate and Fast Channel Estimation for Fluid Antenna Systems with Diffusion Models","abstract":"Fluid antenna systems (FAS) offer enhanced spatial diversity for next-generation wireless systems. However, acquiring accurate channel state information (CSI) remains challenging due to the large number of reconfigurable ports and the limited availability of radio-frequency (RF) chains -- particularly in high-dimensional FAS scenarios. To address this challenge, we propose an efficient posterior sampling-based channel estimator that leverages a diffusion model (DM) with a simplified U-Net architecture to capture the spatial correlation structure of two-dimensional FAS channels. The DM is initially trained offline in an unsupervised way and then applied online as a learned implicit prior to reconstruct CSI from partial observations via posterior sampling through a denoising diffusion restoration model (DDRM). To accelerate the online inference, we introduce a skipped sampling strategy that updates only a subset of latent variables during the sampling process, thereby reducing the computational cost with minimal accuracy degradation. Simulation results demonstrate that the proposed approach achieves significantly higher estimation accuracy and over 20x speedup compared to state-of-the-art compressed sensing-based methods, highlighting its potential for practical deployment in high-dimensional FAS.","authors":["Erqiang Tang","Wei Guo","Hengtao He","Shenghui Song","Jun Zhang","Khaled B. Letaief"],"url":"https://arxiv.org/abs/2505.04930"}
{"created":"2025-05-09","title":"Fair Uncertainty Quantification for Depression Prediction","abstract":"Trustworthy depression prediction based on deep learning, incorporating both predictive reliability and algorithmic fairness across diverse demographic groups, is crucial for clinical application. Recently, achieving reliable depression predictions through uncertainty quantification has attracted increasing attention. However, few studies have focused on the fairness of uncertainty quantification (UQ) in depression prediction. In this work, we investigate the algorithmic fairness of UQ, namely Equal Opportunity Coverage (EOC) fairness, and propose Fair Uncertainty Quantification (FUQ) for depression prediction. FUQ pursues reliable and fair depression predictions through group-based analysis. Specifically, we first group all the participants by different sensitive attributes and leverage conformal prediction to quantify uncertainty within each demographic group, which provides a theoretically guaranteed and valid way to quantify uncertainty for depression prediction and facilitates the investigation of fairness across different demographic groups. Furthermore, we propose a fairness-aware optimization strategy that formulates fairness as a constrained optimization problem under EOC constraints. This enables the model to preserve predictive reliability while adapting to the heterogeneous uncertainty levels across demographic groups, thereby achieving optimal fairness. Through extensive evaluations on several visual and audio depression datasets, our approach demonstrates its effectiveness.","authors":["Yonghong Li","Xiuzhuang Zhou"],"url":"https://arxiv.org/abs/2505.04931"}
{"created":"2025-05-09","title":"Massive MIMO-OFDM Channel Acquisition with Time-Frequency Phase-Shifted Pilots","abstract":"In this paper, we propose a channel acquisition approach with time-frequency phase-shifted pilots (TFPSPs) for massive multi-input multi-output orthogonal frequency division multiplexing (MIMO-OFDM) systems. We first present a triple-beam (TB) based channel tensor model, allowing for the representation of the space-frequency-time (SFT) domain channel as the product of beam matrices and the TB domain channel tensor. By leveraging the specific characteristics of TB domain channels, we develop TFPSPs, where distinct pilot signals are simultaneously transmitted in the frequency and time domains. Then, we present the optimal TFPSP design and provide the corresponding pilot scheduling algorithm. Further, we propose a tensor-based information geometry approach (IGA) to estimate the TB domain channel tensors. Leveraging the specific structure of beam matrices and the properties of TFPSPs, we propose a low-complexity implementation of the tensor-based IGA. We validate the efficiency of our proposed channel acquisition approach through extensive simulations. Simulation results demonstrate the superior performance of our approach. The proposed approach can effectively suppress inter-UT interference with low complexity and limited pilot overhead, thereby enhancing channel estimation performance. Particularly in scenarios with a large number of UTs, the channel acquisition method outperforms existing approaches by reducing the normalized mean square error (NMSE) by more than 8 dB.","authors":["Jinke Tang","Xiqi Gao","Li You","Ding Shi","Jiyuan Yang","Xiang-Gen Xia","Xinwei Zhao","Peigang Jiang"],"url":"https://arxiv.org/abs/2505.04933"}
{"created":"2025-05-09","title":"Enhancing Blockchain Cross Chain Interoperability: A Comprehensive Survey","abstract":"Blockchain technology, introduced in 2008, has revolutionized data storage and transfer across sectors such as finance, healthcare, intelligent transportation, and the metaverse. However, the proliferation of blockchain systems has led to discrepancies in architectures, consensus mechanisms, and data standards, creating data and value silos that hinder the development of an integrated multi chain ecosystem. Blockchain interoperability (a.k.a cross chain interoperability) has thus emerged as a solution to enable seamless data and asset exchange across disparate blockchains. In this survey, we systematically analyze over 150 high impact sources from academic journals, digital libraries, and grey literature to provide an in depth examination of blockchain interoperability. By exploring the existing methods, technologies, and architectures, we offer a classification of interoperability approaches including Atomic Swaps, Sidechains, Light Clients, and so on, which represent the most comprehensive overview to date. Furthermore, we investigate the convergence of academic research with industry practices, underscoring the importance of collaborative efforts in advancing blockchain innovation. Finally, we identify key strategic insights, challenges, and future research trajectories in this field. Our findings aim to support researchers, policymakers, and industry leaders in understanding and harnessing the transformative potential of blockchain interoperability to address current challenges and drive forward a cohesive multi-chain ecosystem.","authors":["Zhihong Deng","Chunming Tang","Taotao Li","Parhat Abla","Qi Chen","Wei Liang","Debiao He"],"url":"https://arxiv.org/abs/2505.04934"}
{"created":"2025-05-09","title":"Real-Time Model Predictive Control of Vehicles with Convex-Polygon-Aware Collision Avoidance in Tight Spaces","abstract":"This paper proposes vehicle motion planning methods with obstacle avoidance in tight spaces by incorporating polygonal approximations of both the vehicle and obstacles into a model predictive control (MPC) framework. Representing these shapes is crucial for navigation in tight spaces to ensure accurate collision detection. However, incorporating polygonal approximations leads to disjunctive OR constraints in the MPC formulation, which require a mixed integer programming and cause significant computational cost. To overcome this, we propose two different collision-avoidance constraints that reformulate the disjunctive OR constraints as tractable conjunctive AND constraints: (1) a Support Vector Machine (SVM)-based formulation that recasts collision avoidance as a SVM optimization problem, and (2) a Minimum Signed Distance to Edges (MSDE) formulation that leverages minimum signed-distance metrics. We validate both methods through extensive simulations, including tight-space parking scenarios and varied-shape obstacle courses, as well as hardware experiments on an RC-car platform. Our results demonstrate that the SVM-based approach achieves superior navigation accuracy in constrained environments; the MSDE approach, by contrast, runs in real time with only a modest reduction in collision-avoidance performance.","authors":["Haruki Kojima","Kohei Honda","Hiroyuki Okuda","Tatsuya Suzuki"],"url":"https://arxiv.org/abs/2505.04935"}
{"created":"2025-05-09","title":"Fluid Antenna-Assisted MU-MIMO Systems with Decentralized Baseband Processing","abstract":"The fluid antenna system (FAS) has emerged as a disruptive technology, offering unprecedented degrees of freedom (DoF) for wireless communication systems. However, optimizing fluid antenna (FA) positions entails significant computational costs, especially when the number of FAs is large. To address this challenge, we introduce a decentralized baseband processing (DBP) architecture to FAS, which partitions the FA array into clusters and enables parallel processing. Based on the DBP architecture, we formulate a weighted sum rate (WSR) maximization problem through joint beamforming and FA position design for FA-assisted multiuser multiple-input multiple-output (MU-MIMO) systems. To solve the WSR maximization problem, we propose a novel decentralized block coordinate ascent (BCA)-based algorithm that leverages matrix fractional programming (FP) and majorization-minimization (MM) methods. The proposed decentralized algorithm achieves low computational, communication, and storage costs, thus unleashing the potential of the DBP architecture. Simulation results show that our proposed algorithm under the DBP architecture reduces computational time by over 70% compared to centralized architectures with negligible WSR performance loss.","authors":["Tianyi Liao","Wei Guo","Hengtao He","Shenghui Song","Jun Zhang","Khaled B. Letaief"],"url":"https://arxiv.org/abs/2505.04936"}
{"created":"2025-05-09","title":"FF-PNet: A Pyramid Network Based on Feature and Field for Brain Image Registration","abstract":"In recent years, deformable medical image registration techniques have made significant progress. However, existing models still lack efficiency in parallel extraction of coarse and fine-grained features. To address this, we construct a new pyramid registration network based on feature and deformation field (FF-PNet). For coarse-grained feature extraction, we design a Residual Feature Fusion Module (RFFM), for fine-grained image deformation, we propose a Residual Deformation Field Fusion Module (RDFFM). Through the parallel operation of these two modules, the model can effectively handle complex image deformations. It is worth emphasizing that the encoding stage of FF-PNet only employs traditional convolutional neural networks without any attention mechanisms or multilayer perceptrons, yet it still achieves remarkable improvements in registration accuracy, fully demonstrating the superior feature decoding capabilities of RFFM and RDFFM. We conducted extensive experiments on the LPBA and OASIS datasets. The results show our network consistently outperforms popular methods in metrics like the Dice Similarity Coefficient.","authors":["Ying Zhang","Shuai Guo","Chenxi Sun","Yuchen Zhu","Jinhai Xiang"],"url":"https://arxiv.org/abs/2505.04938"}
{"created":"2025-05-09","title":"Structural Alignment in Link Prediction","abstract":"While Knowledge Graphs (KGs) have become increasingly popular across various scientific disciplines for their ability to model and interlink huge quantities of data, essentially all real-world KGs are known to be incomplete. As such, with the growth of KG use has been a concurrent development of machine learning tools designed to predict missing information in KGs, which is referred to as the Link Prediction Task. The majority of state-of-the-art link predictors to date have followed an embedding-based paradigm. In this paradigm, it is assumed that the information content of a KG is best represented by the (individual) vector representations of its nodes and edges, and that therefore node and edge embeddings are particularly well-suited to performing link prediction.","authors":["Jeffrey Seathr\\'un Sardina"],"url":"https://arxiv.org/abs/2505.04939"}
{"created":"2025-05-09","title":"Building-Guided Pseudo-Label Learning for Cross-Modal Building Damage Mapping","abstract":"Accurate building damage assessment using bi-temporal multi-modal remote sensing images is essential for effective disaster response and recovery planning. This study proposes a novel Building-Guided Pseudo-Label Learning Framework to address the challenges of mapping building damage from pre-disaster optical and post-disaster SAR images. First, we train a series of building extraction models using pre-disaster optical images and building labels. To enhance building segmentation, we employ multi-model fusion and test-time augmentation strategies to generate pseudo-probabilities, followed by a low-uncertainty pseudo-label training method for further refinement. Next, a change detection model is trained on bi-temporal cross-modal images and damaged building labels. To improve damage classification accuracy, we introduce a building-guided low-uncertainty pseudo-label refinement strategy, which leverages building priors from the previous step to guide pseudo-label generation for damaged buildings, reducing uncertainty and enhancing reliability. Experimental results on the 2025 IEEE GRSS Data Fusion Contest dataset demonstrate the effectiveness of our approach, which achieved the highest mIoU score (54.28%) and secured first place in the competition.","authors":["Jiepan Li","He Huang","Yu Sheng","Yujun Guo","Wei He"],"url":"https://arxiv.org/abs/2505.04941"}
{"created":"2025-05-09","title":"T2VTextBench: A Human Evaluation Benchmark for Textual Control in Video Generation Models","abstract":"Thanks to recent advancements in scalable deep architectures and large-scale pretraining, text-to-video generation has achieved unprecedented capabilities in producing high-fidelity, instruction-following content across a wide range of styles, enabling applications in advertising, entertainment, and education. However, these models' ability to render precise on-screen text, such as captions or mathematical formulas, remains largely untested, posing significant challenges for applications requiring exact textual accuracy. In this work, we introduce T2VTextBench, the first human-evaluation benchmark dedicated to evaluating on-screen text fidelity and temporal consistency in text-to-video models. Our suite of prompts integrates complex text strings with dynamic scene changes, testing each model's ability to maintain detailed instructions across frames. We evaluate ten state-of-the-art systems, ranging from open-source solutions to commercial offerings, and find that most struggle to generate legible, consistent text. These results highlight a critical gap in current video generators and provide a clear direction for future research aimed at enhancing textual manipulation in video synthesis.","authors":["Xuyang Guo","Jiayan Huo","Zhenmei Shi","Zhao Song","Jiahao Zhang","Jiale Zhao"],"url":"https://arxiv.org/abs/2505.04946"}
{"created":"2025-05-09","title":"DFPL: Decentralized Federated Prototype Learning Across Heterogeneous Data Distributions","abstract":"Federated learning is a distributed machine learning paradigm that enables the collaborative training of multiple clients through centralized model aggregation. However, standard federated learning relies on a centralized server, making it vulnerable to server failures. While existing solutions utilize blockchain technology to implement Decentralized Federated Learning (DFL), the statistical heterogeneity of data distributions among clients severely degrades the DFL's performance. Driven by this issue, this paper proposes a decentralized federated prototype learning framework, named DFPL, which significantly improves the performance of distributed machine learning across heterogeneous data distributions. Specifically, our framework introduces prototype learning into DFL to address statistical heterogeneity, which greatly reduces the number of parameters exchanged between clients. Additionally, blockchain is embedded into our framework, enabling the training and mining processes to be implemented at each client. From a theoretical perspective, we provide convergence guarantee of DFPL by combining resource allocation for training and mining. The experiments highlight the superiority of our DFPL framework in communication efficiency and test performance across three benchmark datasets with heterogeneous data distributions.","authors":["Hongliang Zhang","Fenghua Xu","Zhongyuan Yu","Chunqiang Hu","Shanchen Pang","Xiaofen Wang","Jiguo Yu"],"url":"https://arxiv.org/abs/2505.04947"}
{"created":"2025-05-09","title":"Prompt-Based LLMs for Position Bias-Aware Reranking in Personalized Recommendations","abstract":"Recommender systems are essential for delivering personalized content across digital platforms by modeling user preferences and behaviors. Recently, large language models (LLMs) have been adopted for prompt-based recommendation due to their ability to generate personalized outputs without task-specific training. However, LLM-based methods face limitations such as limited context window size, inefficient pointwise and pairwise prompting, and difficulty handling listwise ranking due to token constraints. LLMs can also be sensitive to position bias, as they may overemphasize earlier items in the prompt regardless of their true relevance. To address and investigate these issues, we propose a hybrid framework that combines a traditional recommendation model with an LLM for reranking top-k items using structured prompts. We evaluate the effects of user history reordering and instructional prompts for mitigating position bias. Experiments on MovieLens-100K show that randomizing user history improves ranking quality, but LLM-based reranking does not outperform the base model. Explicit instructions to reduce position bias are also ineffective. Our evaluations reveal limitations in LLMs' ability to model ranking context and mitigate bias. Our code is publicly available at https://github.com/aminul7506/LLMForReRanking.","authors":["Md Aminul Islam","Ahmed Sayeed Faruk"],"url":"https://arxiv.org/abs/2505.04948"}
{"created":"2025-05-09","title":"With a Little Help From My Friends: Exploiting Probability Distribution Advice in Algorithm Design","abstract":"We study online algorithms with predictions using distributional advice, a type of prediction that arises when leveraging expert knowledge or historical data. To demonstrate the usefulness and versatility of this framework, we focus on two fundamental problems: first, the prophet inequality problem, for which we provide an algorithm achieving $\\max\\{\\frac{1}{2}-\\eta-o(1),\\frac{1}{e}\\}$-competitive ratio, where $\\eta$ quantifies the quality of the prediction. Second, we turn to the online metric matching problem under random arrivals, for which our main positive result is an algorithm achieving the optimal cost under perfect advice, while smoothly defaulting to competitive ratios comparable to advice-free algorithms as the prediction's quality degrades.","authors":["Cl\\'ement L. Canonne","Kenny Chen","Juli\\'an Mestre"],"url":"https://arxiv.org/abs/2505.04949"}
{"created":"2025-05-09","title":"Position: Epistemic Artificial Intelligence is Essential for Machine Learning Models to Know When They Do Not Know","abstract":"Despite the impressive achievements of AI, including advancements in generative models and large language models, there remains a significant gap in the ability of AI to handle uncertainty and generalize beyond the training data. We argue that AI models, especially in autonomous systems, fail to make robust predictions when faced with unfamiliar or adversarial data, as evidenced by incidents with autonomous vehicles. Traditional machine learning approaches struggle to address these issues due to an overemphasis on data fitting and domain adaptation. This position paper posits a paradigm shift towards epistemic artificial intelligence, emphasizing the need for models to learn not only from what they know but also from their ignorance. This approach, which focuses on recognizing and managing uncertainty, offers a potential solution to improve the resilience and robustness of AI systems, ensuring that they can better handle unpredictable real-world environments.","authors":["Shireen Kudukkil Manchingal","Fabio Cuzzolin"],"url":"https://arxiv.org/abs/2505.04950"}
{"created":"2025-05-09","title":"Zip-Tries: Simple Dynamic Data Structures for Strings","abstract":"In this paper, we introduce zip-tries, which are simple, dynamic, memory-efficient data structures for strings. Zip-tries support search and update operations for $k$-length strings in $\\mathcal{O}(k+\\log n)$ time in the standard RAM model or in $\\mathcal{O}(k/\\alpha+\\log n)$ time in the word RAM model, where $\\alpha$ is the length of the longest string that can fit in a memory word, and $n$ is the number of strings in the trie. Importantly, we show how zip-tries can achieve this while only requiring $\\mathcal{O}(\\log{\\log{n}} + \\log{\\log{\\frac{k}{\\alpha}}})$ bits of metadata per node w.h.p., which is an exponential improvement over previous results for long strings. Despite being considerably simpler and more memory efficient, we show how zip-tries perform competitively with state-of-the-art data structures on large datasets of long strings.","authors":["David Eppstein (University of California","Irvine)","Ofek Gila (University of California","Irvine)","Michael T. Goodrich (University of California","Irvine)","Ryuto Kitagawa (University of California","Irvine)"],"url":"https://arxiv.org/abs/2505.04953"}
{"created":"2025-05-09","title":"Chain-of-Thought Tokens are Computer Program Variables","abstract":"Chain-of-thoughts (CoT) requires large language models (LLMs) to generate intermediate steps before reaching the final answer, and has been proven effective to help LLMs solve complex reasoning tasks. However, the inner mechanism of CoT still remains largely unclear. In this paper, we empirically study the role of CoT tokens in LLMs on two compositional tasks: multi-digit multiplication and dynamic programming. While CoT is essential for solving these problems, we find that preserving only tokens that store intermediate results would achieve comparable performance. Furthermore, we observe that storing intermediate results in an alternative latent form will not affect model performance. We also randomly intervene some values in CoT, and notice that subsequent CoT tokens and the final answer would change correspondingly. These findings suggest that CoT tokens may function like variables in computer programs but with potential drawbacks like unintended shortcuts and computational complexity limits between tokens. The code and data are available at https://github.com/solitaryzero/CoTs_are_Variables.","authors":["Fangwei Zhu","Peiyi Wang","Zhifang Sui"],"url":"https://arxiv.org/abs/2505.04955"}
{"created":"2025-05-09","title":"Graffe: Graph Representation Learning via Diffusion Probabilistic Models","abstract":"Diffusion probabilistic models (DPMs), widely recognized for their potential to generate high-quality samples, tend to go unnoticed in representation learning. While recent progress has highlighted their potential for capturing visual semantics, adapting DPMs to graph representation learning remains in its infancy. In this paper, we introduce Graffe, a self-supervised diffusion model proposed for graph representation learning. It features a graph encoder that distills a source graph into a compact representation, which, in turn, serves as the condition to guide the denoising process of the diffusion decoder. To evaluate the effectiveness of our model, we first explore the theoretical foundations of applying diffusion models to representation learning, proving that the denoising objective implicitly maximizes the conditional mutual information between data and its representation. Specifically, we prove that the negative logarithm of the denoising score matching loss is a tractable lower bound for the conditional mutual information. Empirically, we conduct a series of case studies to validate our theoretical insights. In addition, Graffe delivers competitive results under the linear probing setting on node and graph classification tasks, achieving state-of-the-art performance on 9 of the 11 real-world datasets. These findings indicate that powerful generative models, especially diffusion models, serve as an effective tool for graph representation learning.","authors":["Dingshuo Chen","Shuchen Xue","Liuji Chen","Yingheng Wang","Qiang Liu","Shu Wu","Zhi-Ming Ma","Liang Wang"],"url":"https://arxiv.org/abs/2505.04956"}
{"created":"2025-05-09","title":"Learning Item Representations Directly from Multimodal Features for Effective Recommendation","abstract":"Conventional multimodal recommender systems predominantly leverage Bayesian Personalized Ranking (BPR) optimization to learn item representations by amalgamating item identity (ID) embeddings with multimodal features. Nevertheless, our empirical and theoretical findings unequivocally demonstrate a pronounced optimization gradient bias in favor of acquiring representations from multimodal features over item ID embeddings. As a consequence, item ID embeddings frequently exhibit suboptimal characteristics despite the convergence of multimodal feature parameters. Given the rich informational content inherent in multimodal features, in this paper, we propose a novel model (i.e., LIRDRec) that learns item representations directly from these features to augment recommendation performance. Recognizing that features derived from each modality may capture disparate yet correlated aspects of items, we propose a multimodal transformation mechanism, integrated with modality-specific encoders, to effectively fuse features from all modalities. Moreover, to differentiate the influence of diverse modality types, we devise a progressive weight copying fusion module within LIRDRec. This module incrementally learns the weight assigned to each modality in synthesizing the final user or item representations. Finally, we utilize the powerful visual understanding of Multimodal Large Language Models (MLLMs) to convert the item images into texts and extract semantics embeddings upon the texts via LLMs. Empirical evaluations conducted on five real-world datasets validate the superiority of our approach relative to competing baselines. It is worth noting the proposed model, equipped with embeddings extracted from MLLMs and LLMs, can further improve the recommendation accuracy of NDCG@20 by an average of 4.21% compared to the original embeddings.","authors":["Xin Zhou","Xiaoxiong Zhang","Dusit Niyato","Zhiqi Shen"],"url":"https://arxiv.org/abs/2505.04960"}
{"created":"2025-05-09","title":"ADD: Physics-Based Motion Imitation with Adversarial Differential Discriminators","abstract":"Multi-objective optimization problems, which require the simultaneous optimization of multiple terms, are prevalent across numerous applications. Existing multi-objective optimization methods often rely on manually tuned aggregation functions to formulate a joint optimization target. The performance of such hand-tuned methods is heavily dependent on careful weight selection, a time-consuming and laborious process. These limitations also arise in the setting of reinforcement-learning-based motion tracking for physically simulated characters, where intricately crafted reward functions are typically used to achieve high-fidelity results. Such solutions not only require domain expertise and significant manual adjustment, but also limit the applicability of the resulting reward function across diverse skills. To bridge this gap, we present a novel adversarial multi-objective optimization technique that is broadly applicable to a range of multi-objective optimization problems, including motion tracking. The proposed adversarial differential discriminator receives a single positive sample, yet is still effective at guiding the optimization process. We demonstrate that our technique can enable characters to closely replicate a variety of acrobatic and agile behaviors, achieving comparable quality to state-of-the-art motion-tracking methods, without relying on manually tuned reward functions. Results are best visualized through https://youtu.be/rz8BYCE9E2w.","authors":["Ziyu Zhang","Sergey Bashkirov","Dun Yang","Michael Taylor","Xue Bin Peng"],"url":"https://arxiv.org/abs/2505.04961"}
{"created":"2025-05-09","title":"An Efficient Method for Accurate Pose Estimation and Error Correction of Cuboidal Objects","abstract":"The proposed system outlined in this paper is a solution to a use case that requires the autonomous picking of cuboidal objects from an organized or unorganized pile with high precision. This paper presents an efficient method for precise pose estimation of cuboid-shaped objects, which aims to reduce errors in target pose in a time-efficient manner. Typical pose estimation methods like global point cloud registrations are prone to minor pose errors for which local registration algorithms are generally used to improve pose accuracy. However, due to the execution time overhead and uncertainty in the error of the final achieved pose, an alternate, linear time approach is proposed for pose error estimation and correction. This paper presents an overview of the solution followed by a detailed description of individual modules of the proposed algorithm.","authors":["Utsav Rai","Hardik Mehta","Vismay Vakharia","Aditya Choudhary","Amit Parmar","Rolif Lima","Kaushik Das"],"url":"https://arxiv.org/abs/2505.04962"}
{"created":"2025-05-09","title":"ViCTr: Vital Consistency Transfer for Pathology Aware Image Synthesis","abstract":"Synthesizing medical images remains challenging due to limited annotated pathological data, modality domain gaps, and the complexity of representing diffuse pathologies such as liver cirrhosis. Existing methods often struggle to maintain anatomical fidelity while accurately modeling pathological features, frequently relying on priors derived from natural images or inefficient multi-step sampling. In this work, we introduce ViCTr (Vital Consistency Transfer), a novel two-stage framework that combines a rectified flow trajectory with a Tweedie-corrected diffusion process to achieve high-fidelity, pathology-aware image synthesis. First, we pretrain ViCTr on the ATLAS-8k dataset using Elastic Weight Consolidation (EWC) to preserve critical anatomical structures. We then fine-tune the model adversarially with Low-Rank Adaptation (LoRA) modules for precise control over pathology severity. By reformulating Tweedie's formula within a linear trajectory framework, ViCTr supports one-step sampling, reducing inference from 50 steps to just 4, without sacrificing anatomical realism. We evaluate ViCTr on BTCV (CT), AMOS (MRI), and CirrMRI600+ (cirrhosis) datasets. Results demonstrate state-of-the-art performance, achieving a Medical Frechet Inception Distance (MFID) of 17.01 for cirrhosis synthesis 28% lower than existing approaches and improving nnUNet segmentation by +3.8% mDSC when used for data augmentation. Radiologist reviews indicate that ViCTr-generated liver cirrhosis MRIs are clinically indistinguishable from real scans. To our knowledge, ViCTr is the first method to provide fine-grained, pathology-aware MRI synthesis with graded severity control, closing a critical gap in AI-driven medical imaging research.","authors":["Onkar Susladkar","Gayatri Deshmukh","Yalcin Tur","Ulas Bagci"],"url":"https://arxiv.org/abs/2505.04963"}
{"created":"2025-05-09","title":"CAG-VLM: Fine-Tuning of a Large-Scale Model to Recognize Angiographic Images for Next-Generation Diagnostic Systems","abstract":"Coronary angiography (CAG) is the gold-standard imaging modality for evaluating coronary artery disease, but its interpretation and subsequent treatment planning rely heavily on expert cardiologists. To enable AI-based decision support, we introduce a two-stage, physician-curated pipeline and a bilingual (Japanese/English) CAG image-report dataset. First, we sample 14,686 frames from 539 exams and annotate them for key-frame detection and left/right laterality; a ConvNeXt-Base CNN trained on this data achieves 0.96 F1 on laterality classification, even on low-contrast frames. Second, we apply the CNN to 243 independent exams, extract 1,114 key frames, and pair each with its pre-procedure report and expert-validated diagnostic and treatment summary, yielding a parallel corpus. We then fine-tune three open-source VLMs (PaliGemma2, Gemma3, and ConceptCLIP-enhanced Gemma3) via LoRA and evaluate them using VLScore and cardiologist review. Although PaliGemma2 w/LoRA attains the highest VLScore, Gemma3 w/LoRA achieves the top clinician rating (mean 7.20/10); we designate this best-performing model as CAG-VLM. These results demonstrate that specialized, fine-tuned VLMs can effectively assist cardiologists in generating clinical reports and treatment recommendations from CAG images.","authors":["Yuto Nakamura","Satoshi Kodera","Haruki Settai","Hiroki Shinohara","Masatsugu Tamura","Tomohiro Noguchi","Tatsuki Furusawa","Ryo Takizawa","Tempei Kabayama","Norihiko Takeda"],"url":"https://arxiv.org/abs/2505.04964"}
{"created":"2025-05-09","title":"DenseGrounding: Improving Dense Language-Vision Semantics for Ego-Centric 3D Visual Grounding","abstract":"Enabling intelligent agents to comprehend and interact with 3D environments through natural language is crucial for advancing robotics and human-computer interaction. A fundamental task in this field is ego-centric 3D visual grounding, where agents locate target objects in real-world 3D spaces based on verbal descriptions. However, this task faces two significant challenges: (1) loss of fine-grained visual semantics due to sparse fusion of point clouds with ego-centric multi-view images, (2) limited textual semantic context due to arbitrary language descriptions. We propose DenseGrounding, a novel approach designed to address these issues by enhancing both visual and textual semantics. For visual features, we introduce the Hierarchical Scene Semantic Enhancer, which retains dense semantics by capturing fine-grained global scene features and facilitating cross-modal alignment. For text descriptions, we propose a Language Semantic Enhancer that leverages large language models to provide rich context and diverse language descriptions with additional context during model training. Extensive experiments show that DenseGrounding significantly outperforms existing methods in overall accuracy, with improvements of 5.81% and 7.56% when trained on the comprehensive full dataset and smaller mini subset, respectively, further advancing the SOTA in egocentric 3D visual grounding. Our method also achieves 1st place and receives the Innovation Award in the CVPR 2024 Autonomous Grand Challenge Multi-view 3D Visual Grounding Track, validating its effectiveness and robustness.","authors":["Henry Zheng","Hao Shi","Qihang Peng","Yong Xien Chng","Rui Huang","Yepeng Weng","Zhongchao Shi","Gao Huang"],"url":"https://arxiv.org/abs/2505.04965"}
{"created":"2025-05-09","title":"Position: The AI Conference Peer Review Crisis Demands Author Feedback and Reviewer Rewards","abstract":"The peer review process in major artificial intelligence (AI) conferences faces unprecedented challenges with the surge of paper submissions (exceeding 10,000 submissions per venue), accompanied by growing concerns over review quality and reviewer responsibility. This position paper argues for the need to transform the traditional one-way review system into a bi-directional feedback loop where authors evaluate review quality and reviewers earn formal accreditation, creating an accountability framework that promotes a sustainable, high-quality peer review system. The current review system can be viewed as an interaction between three parties: the authors, reviewers, and system (i.e., conference), where we posit that all three parties share responsibility for the current problems. However, issues with authors can only be addressed through policy enforcement and detection tools, and ethical concerns can only be corrected through self-reflection. As such, this paper focuses on reforming reviewer accountability with systematic rewards through two key mechanisms: (1) a two-stage bi-directional review system that allows authors to evaluate reviews while minimizing retaliatory behavior, (2)a systematic reviewer reward system that incentivizes quality reviewing. We ask for the community's strong interest in these problems and the reforms that are needed to enhance the peer review process.","authors":["Jaeho Kim","Yunseok Lee","Seulki Lee"],"url":"https://arxiv.org/abs/2505.04966"}
{"created":"2025-05-09","title":"Community and hyperedge inference in multiple hypergraphs","abstract":"Hypergraphs, capable of representing high-order interactions via hyperedges, have become a powerful tool for modeling real-world biological and social systems. Inherent relationships within these real-world systems, such as the encoding relationship between genes and their protein products, drive the establishment of interconnections between multiple hypergraphs. Here, we demonstrate how to utilize those interconnections between multiple hypergraphs to synthesize integrated information from multiple higher-order systems, thereby enhancing understanding of underlying structures. We propose a model based on the stochastic block model, which integrates information from multiple hypergraphs to reveal latent high-order structures. Real-world hyperedges exhibit preferential attachment, where certain nodes dominate hyperedge formation. To characterize this phenomenon, our model introduces hyperedge internal degree to quantify nodes' contributions to hyperedge formation. This model is capable of mining communities, predicting missing hyperedges of arbitrary sizes within hypergraphs, and inferring inter-hypergraph edges between hypergraphs. We apply our model to high-order datasets to evaluate its performance. Experimental results demonstrate strong performance of our model in community detection, hyperedge prediction, and inter-hypergraph edge prediction tasks. Moreover, we show that our model enables analysis of multiple hypergraphs of different types and supports the analysis of a single hypergraph in the absence of inter-hypergraph edges. Our work provides a practical and flexible tool for analyzing multiple hypergraphs, greatly advancing the understanding of the organization in real-world high-order systems.","authors":["Li Ni","Ziqi Deng","Lin Mu","Lei Zhang","Wenjian Luo","Yiwen Zhang"],"url":"https://arxiv.org/abs/2505.04967"}
{"created":"2025-05-09","title":"Dynamic Precoding for Near-Field Secure Communications: Implementation and Performance Analysis","abstract":"The increase in antenna apertures and transmission frequencies in next-generation wireless networks is catalyzing advancements in near-field communications (NFC). In this paper, we investigate secure transmission in near-field multi-user multiple-input single-output (MU-MISO) scenarios. Specifically, with the advent of extremely large-scale antenna arrays (ELAA) applied in the NFC regime, the spatial degrees of freedom in the channel matrix are significantly enhanced. This creates an expanded null space that can be exploited for designing secure communication schemes. Motivated by this observation, we propose a near-field dynamic hybrid beamforming architecture incorporating artificial noise, which effectively disrupts eavesdroppers at any undesired positions, even in the absence of their channel state information (CSI). Furthermore, we comprehensively analyze the dynamic precoder's performance in terms of the average signal-to-interference-plus-noise ratio, achievable rate, secrecy capacity, secrecy outage probability, and the size of the secrecy zone. In contrast to far-field secure transmission techniques that only enhance security in the angular dimension, the proposed algorithm exploits the unique properties of spherical wave characteristics in NFC to achieve secure transmission in both the angular and distance dimensions. Remarkably, the proposed algorithm is applicable to arbitrary modulation types and array configurations. Numerical results demonstrate that the proposed method achieves approximately 20\\% higher rate capacity compared to zero-forcing and the weighted minimum mean squared error precoders.","authors":["Zihao Teng","Jiancheng An","Christos Masouros","Hongbin Li","Lu Gan","Derrick Wing Kwan Ng"],"url":"https://arxiv.org/abs/2505.04968"}
{"created":"2025-05-09","title":"General Transform: A Unified Framework for Adaptive Transform to Enhance Representations","abstract":"Discrete transforms, such as the discrete Fourier transform, are widely used in machine learning to improve model performance by extracting meaningful features. However, with numerous transforms available, selecting an appropriate one often depends on understanding the dataset's properties, making the approach less effective when such knowledge is unavailable. In this work, we propose General Transform (GT), an adaptive transform-based representation designed for machine learning applications. Unlike conventional transforms, GT learns data-driven mapping tailored to the dataset and task of interest. Here, we demonstrate that models incorporating GT outperform conventional transform-based approaches across computer vision and natural language processing tasks, highlighting its effectiveness in diverse learning scenarios.","authors":["Gekko Budiutama","Shunsuke Daimon","Hirofumi Nishi","Yu-ichiro Matsushita"],"url":"https://arxiv.org/abs/2505.04969"}
{"created":"2025-05-09","title":"AI and Vision based Autonomous Navigation of Nano-Drones in Partially-Known Environments","abstract":"The miniaturisation of sensors and processors, the advancements in connected edge intelligence, and the exponential interest in Artificial Intelligence are boosting the affirmation of autonomous nano-size drones in the Internet of Robotic Things ecosystem. However, achieving safe autonomous navigation and high-level tasks such as exploration and surveillance with these tiny platforms is extremely challenging due to their limited resources. This work focuses on enabling the safe and autonomous flight of a pocket-size, 30-gram platform called Crazyflie 2.1 in a partially known environment. We propose a novel AI-aided, vision-based reactive planning method for obstacle avoidance under the ambit of Integrated Sensing, Computing and Communication paradigm. We deal with the constraints of the nano-drone by splitting the navigation task into two parts: a deep learning-based object detector runs on the edge (external hardware) while the planning algorithm is executed onboard. The results show the ability to command the drone at $\\sim8$ frames-per-second and a model performance reaching a COCO mean-average-precision of $60.8$. Field experiments demonstrate the feasibility of the solution with the drone flying at a top speed of $1$ m/s while steering away from an obstacle placed in an unknown position and reaching the target destination. The outcome highlights the compatibility of the communication delay and the model performance with the requirements of the real-time navigation task. We provide a feasible alternative to a fully onboard implementation that can be extended to autonomous exploration with nano-drones.","authors":["Mattia Sartori","Chetna Singhal","Neelabhro Roy","Davide Brunelli","James Gross"],"url":"https://arxiv.org/abs/2505.04972"}
{"created":"2025-05-09","title":"ReAlign: Bilingual Text-to-Motion Generation via Step-Aware Reward-Guided Alignment","abstract":"Bilingual text-to-motion generation, which synthesizes 3D human motions from bilingual text inputs, holds immense potential for cross-linguistic applications in gaming, film, and robotics. However, this task faces critical challenges: the absence of bilingual motion-language datasets and the misalignment between text and motion distributions in diffusion models, leading to semantically inconsistent or low-quality motions. To address these challenges, we propose BiHumanML3D, a novel bilingual human motion dataset, which establishes a crucial benchmark for bilingual text-to-motion generation models. Furthermore, we propose a Bilingual Motion Diffusion model (BiMD), which leverages cross-lingual aligned representations to capture semantics, thereby achieving a unified bilingual model. Building upon this, we propose Reward-guided sampling Alignment (ReAlign) method, comprising a step-aware reward model to assess alignment quality during sampling and a reward-guided strategy that directs the diffusion process toward an optimally aligned distribution. This reward model integrates step-aware tokens and combines a text-aligned module for semantic consistency and a motion-aligned module for realism, refining noisy motions at each timestep to balance probability density and alignment. Experiments demonstrate that our approach significantly improves text-motion alignment and motion quality compared to existing state-of-the-art methods. Project page: https://wengwanjiang.github.io/ReAlign-page/.","authors":["Wanjiang Weng","Xiaofeng Tan","Hongsong Wang","Pan Zhou"],"url":"https://arxiv.org/abs/2505.04974"}
{"created":"2025-05-09","title":"ChainMarks: Securing DNN Watermark with Cryptographic Chain","abstract":"With the widespread deployment of deep neural network (DNN) models, dynamic watermarking techniques are being used to protect the intellectual property of model owners. However, recent studies have shown that existing watermarking schemes are vulnerable to watermark removal and ambiguity attacks. Besides, the vague criteria for determining watermark presence further increase the likelihood of such attacks. In this paper, we propose a secure DNN watermarking scheme named ChainMarks, which generates secure and robust watermarks by introducing a cryptographic chain into the trigger inputs and utilizes a two-phase Monte Carlo method for determining watermark presence. First, ChainMarks generates trigger inputs as a watermark dataset by repeatedly applying a hash function over a secret key, where the target labels associated with trigger inputs are generated from the digital signature of model owner. Then, the watermarked model is produced by training a DNN over both the original and watermark datasets. To verify watermarks, we compare the predicted labels of trigger inputs with the target labels and determine ownership with a more accurate decision threshold that considers the classification probability of specific models. Experimental results show that ChainMarks exhibits higher levels of robustness and security compared to state-of-the-art watermarking schemes. With a better marginal utility, ChainMarks provides a higher probability guarantee of watermark presence in DNN models with the same level of watermark accuracy.","authors":["Brian Choi","Shu Wang","Isabelle Choi","Kun Sun"],"url":"https://arxiv.org/abs/2505.04977"}
{"created":"2025-05-09","title":"Robust Model-Based In-Hand Manipulation with Integrated Real-Time Motion-Contact Planning and Tracking","abstract":"Robotic dexterous in-hand manipulation, where multiple fingers dynamically make and break contact, represents a step toward human-like dexterity in real-world robotic applications. Unlike learning-based approaches that rely on large-scale training or extensive data collection for each specific task, model-based methods offer an efficient alternative. Their online computing nature allows for ready application to new tasks without extensive retraining. However, due to the complexity of physical contacts, existing model-based methods encounter challenges in efficient online planning and handling modeling errors, which limit their practical applications. To advance the effectiveness and robustness of model-based contact-rich in-hand manipulation, this paper proposes a novel integrated framework that mitigates these limitations. The integration involves two key aspects: 1) integrated real-time planning and tracking achieved by a hierarchical structure; and 2) joint optimization of motions and contacts achieved by integrated motion-contact modeling. Specifically, at the high level, finger motion and contact force references are jointly generated using contact-implicit model predictive control. The high-level module facilitates real-time planning and disturbance recovery. At the low level, these integrated references are concurrently tracked using a hand force-motion model and actual tactile feedback. The low-level module compensates for modeling errors and enhances the robustness of manipulation. Extensive experiments demonstrate that our approach outperforms existing model-based methods in terms of accuracy, robustness, and real-time performance. Our method successfully completes five challenging tasks in real-world environments, even under appreciable external disturbances.","authors":["Yongpeng Jiang","Mingrui Yu","Xinghao Zhu","Masayoshi Tomizuka","Xiang Li"],"url":"https://arxiv.org/abs/2505.04978"}
{"created":"2025-05-09","title":"Federated Deconfounding and Debiasing Learning for Out-of-Distribution Generalization","abstract":"Attribute bias in federated learning (FL) typically leads local models to optimize inconsistently due to the learning of non-causal associations, resulting degraded performance. Existing methods either use data augmentation for increasing sample diversity or knowledge distillation for learning invariant representations to address this problem. However, they lack a comprehensive analysis of the inference paths, and the interference from confounding factors limits their performance. To address these limitations, we propose the \\underline{Fed}erated \\underline{D}econfounding and \\underline{D}ebiasing \\underline{L}earning (FedDDL) method. It constructs a structured causal graph to analyze the model inference process, and performs backdoor adjustment to eliminate confounding paths. Specifically, we design an intra-client deconfounding learning module for computer vision tasks to decouple background and objects, generating counterfactual samples that establish a connection between the background and any label, which stops the model from using the background to infer the label. Moreover, we design an inter-client debiasing learning module to construct causal prototypes to reduce the proportion of the background in prototype components. Notably, it bridges the gap between heterogeneous representations via causal prototypical regularization. Extensive experiments on 2 benchmarking datasets demonstrate that \\methodname{} significantly enhances the model capability to focus on main objects in unseen data, leading to 4.5\\% higher Top-1 Accuracy on average over 9 state-of-the-art existing methods.","authors":["Zhuang Qi","Sijin Zhou","Lei Meng","Han Hu","Han Yu","Xiangxu Meng"],"url":"https://arxiv.org/abs/2505.04979"}
{"created":"2025-05-09","title":"LVLM-MPC Collaboration for Autonomous Driving: A Safety-Aware and Task-Scalable Control Architecture","abstract":"This paper proposes a novel Large Vision-Language Model (LVLM) and Model Predictive Control (MPC) integration framework that delivers both task scalability and safety for Autonomous Driving (AD). LVLMs excel at high-level task planning across diverse driving scenarios. However, since these foundation models are not specifically designed for driving and their reasoning is not consistent with the feasibility of low-level motion planning, concerns remain regarding safety and smooth task switching. This paper integrates LVLMs with MPC Builder, which automatically generates MPCs on demand, based on symbolic task commands generated by the LVLM, while ensuring optimality and safety. The generated MPCs can strongly assist the execution or rejection of LVLM-driven task switching by providing feedback on the feasibility of the given tasks and generating task-switching-aware MPCs. Our approach provides a safe, flexible, and adaptable control framework, bridging the gap between cutting-edge foundation models and reliable vehicle operation. We demonstrate the effectiveness of our approach through a simulation experiment, showing that our system can safely and effectively handle highway driving while maintaining the flexibility and adaptability of LVLMs.","authors":["Kazuki Atsuta","Kohei Honda","Hiroyuki Okuda","Tatsuya Suzuki"],"url":"https://arxiv.org/abs/2505.04980"}
{"created":"2025-05-09","title":"Graph Neural Network Aided Deep Reinforcement Learning for Resource Allocation in Dynamic Terahertz UAV Networks","abstract":"Terahertz (THz) unmanned aerial vehicle (UAV) networks with flexible topologies and ultra-high data rates are expected to empower numerous applications in security surveillance, disaster response, and environmental monitoring, among others. However, the dynamic topologies hinder the efficient long-term joint power and antenna array resource allocation for THz links among UAVs. Furthermore, the continuous nature of power and the discrete nature of antennas cause this joint resource allocation problem to be a mixed-integer nonlinear programming (MINLP) problem with non-convexity and NP-hardness. Inspired by recent rapid advancements in deep reinforcement learning (DRL), a graph neural network (GNN) aided DRL algorithm for resource allocation in the dynamic THz UAV network with an emphasis on self-node features (GLOVE) is proposed in this paper, with the aim of resource efficiency (RE) maximization. When training the allocation policy for each UAV, GLOVE learns the relationship between this UAV and its neighboring UAVs via GNN, while also emphasizing the important self-node features of this UAV. In addition, a multi-task structure is leveraged by GLOVE to cooperatively train resource allocation decisions for the power and sub-arrays of all UAVs. Experimental results illustrate that GLOVE outperforms benchmark schemes in terms of the highest RE and the lowest latency. Moreover, unlike the benchmark methods with severe packet loss, GLOVE maintains zero packet loss during the entire training process, demonstrating its better robustness under the highly dynamic THz UAV network.","authors":["Zhifeng Hu","Chong Han"],"url":"https://arxiv.org/abs/2505.04981"}
{"created":"2025-05-09","title":"A Vehicle System for Navigating Among Vulnerable Road Users Including Remote Operation","abstract":"We present a vehicle system capable of navigating safely and efficiently around Vulnerable Road Users (VRUs), such as pedestrians and cyclists. The system comprises key modules for environment perception, localization and mapping, motion planning, and control, integrated into a prototype vehicle. A key innovation is a motion planner based on Topology-driven Model Predictive Control (T-MPC). The guidance layer generates multiple trajectories in parallel, each representing a distinct strategy for obstacle avoidance or non-passing. The underlying trajectory optimization constrains the joint probability of collision with VRUs under generic uncertainties. To address extraordinary situations (\"edge cases\") that go beyond the autonomous capabilities - such as construction zones or encounters with emergency responders - the system includes an option for remote human operation, supported by visual and haptic guidance. In simulation, our motion planner outperforms three baseline approaches in terms of safety and efficiency. We also demonstrate the full system in prototype vehicle tests on a closed track, both in autonomous and remotely operated modes.","authors":["Oscar de Groot","Alberto Bertipaglia","Hidde Boekema","Vishrut Jain","Marcell Kegl","Varun Kotian","Ted Lentsch","Yancong Lin","Chrysovalanto Messiou","Emma Schippers","Farzam Tajdari","Shiming Wang","Zimin Xia","Mubariz Zaffar","Ronald Ensing","Mario Garzon","Javier Alonso-Mora","Holger Caesar","Laura Ferranti","Riender Happee","Julian F. P. Kooij","Georgios Papaioannou","Barys Shyrokau","Dariu M. Gavrila"],"url":"https://arxiv.org/abs/2505.04982"}
{"created":"2025-05-09","title":"Rethinking the Relationship between the Power Law and Hierarchical Structures","abstract":"Statistical analysis of corpora provides an approach to quantitatively investigate natural languages. This approach has revealed that several power laws consistently emerge across different corpora and languages, suggesting the universal principles underlying languages. Particularly, the power-law decay of correlation has been interpreted as evidence for underlying hierarchical structures in syntax, semantics, and discourse. This perspective has also been extended to child languages and animal signals. However, the argument supporting this interpretation has not been empirically tested. To address this problem, this study examines the validity of the argument for syntactic structures. Specifically, we test whether the statistical properties of parse trees align with the implicit assumptions in the argument. Using English corpora, we analyze the mutual information, deviations from probabilistic context-free grammars (PCFGs), and other properties in parse trees, as well as in the PCFG that approximates these trees. Our results indicate that the assumptions do not hold for syntactic structures and that it is difficult to apply the proposed argument to child languages and animal signals, highlighting the need to reconsider the relationship between the power law and hierarchical structures.","authors":["Kai Nakaishi","Ryo Yoshida","Kohei Kajikawa","Koji Hukushima","Yohei Oseki"],"url":"https://arxiv.org/abs/2505.04984"}
{"created":"2025-05-09","title":"CPP-DIP: Multi-objective Coverage Path Planning for MAVs in Dispersed and Irregular Plantations","abstract":"Coverage Path Planning (CPP) is vital in precision agriculture to improve efficiency and resource utilization. In irregular and dispersed plantations, traditional grid-based CPP often causes redundant coverage over non-vegetated areas, leading to waste and pollution. To overcome these limitations, we propose CPP-DIP, a multi-objective CPP framework designed for Micro Air Vehicles (MAVs). The framework transforms the CPP task into a Traveling Salesman Problem (TSP) and optimizes flight paths by minimizing travel distance, turning angles, and intersection counts. Unlike conventional approaches, our method does not rely on GPS-based environmental modeling. Instead, it uses aerial imagery and a Histogram of Oriented Gradients (HOG)-based approach to detect trees and extract image coordinates. A density-aware waypoint strategy is applied: Kernel Density Estimation (KDE) is used to reduce redundant waypoints in dense regions, while a greedy algorithm ensures complete coverage in sparse areas. To verify the generality of the framework, we solve the resulting TSP using three different methods: Greedy Heuristic Insertion (GHI), Ant Colony Optimization (ACO), and Monte Carlo Reinforcement Learning (MCRL). Then an object-based optimization is applied to further refine the resulting path. Additionally, CPP-DIP integrates ForaNav, our insect-inspired navigation method, for accurate tree localization and tracking. The experimental results show that MCRL offers a balanced solution, reducing the travel distance by 16.9 % compared to ACO while maintaining a similar performance to GHI. It also improves path smoothness by reducing turning angles by 28.3 % and 59.9 % relative to ACO and GHI, respectively, and effectively eliminates intersections. These results confirm the robustness and effectiveness of CPP-DIP in different TSP solvers.","authors":["Weijie Kuang","Hann Woei Ho","Ye Zhou"],"url":"https://arxiv.org/abs/2505.04989"}
{"created":"2025-05-09","title":"Latent Preference Coding: Aligning Large Language Models via Discrete Latent Codes","abstract":"Large language models (LLMs) have achieved remarkable success, yet aligning their generations with human preferences remains a critical challenge. Existing approaches to preference modeling often rely on an explicit or implicit reward function, overlooking the intricate and multifaceted nature of human preferences that may encompass conflicting factors across diverse tasks and populations. To address this limitation, we introduce Latent Preference Coding (LPC), a novel framework that models the implicit factors as well as their combinations behind holistic preferences using discrete latent codes. LPC seamlessly integrates with various offline alignment algorithms, automatically inferring the underlying factors and their importance from data without relying on pre-defined reward functions and hand-crafted combination weights. Extensive experiments on multiple benchmarks demonstrate that LPC consistently improves upon three alignment algorithms (DPO, SimPO, and IPO) using three base models (Mistral-7B, Llama3-8B, and Llama3-8B-Instruct). Furthermore, deeper analysis reveals that the learned latent codes effectively capture the differences in the distribution of human preferences and significantly enhance the robustness of alignment against noise in data. By providing a unified representation for the multifarious preference factors, LPC paves the way towards developing more robust and versatile alignment techniques for the responsible deployment of powerful LLMs.","authors":["Zhuocheng Gong","Jian Guan","Wei Wu","Huishuai Zhang","Dongyan Zhao"],"url":"https://arxiv.org/abs/2505.04993"}
{"created":"2025-05-09","title":"Rethinking Invariance in In-context Learning","abstract":"In-Context Learning (ICL) has emerged as a pivotal capability of auto-regressive large language models, yet it is hindered by a notable sensitivity to the ordering of context examples regardless of their mutual independence. To address this issue, recent studies have introduced several variant algorithms of ICL that achieve permutation invariance. However, many of these do not exhibit comparable performance with the standard auto-regressive ICL algorithm. In this work, we identify two crucial elements in the design of an invariant ICL algorithm: information non-leakage and context interdependence, which are not simultaneously achieved by any of the existing methods. These investigations lead us to the proposed Invariant ICL (InvICL), a methodology designed to achieve invariance in ICL while ensuring the two properties. Empirically, our findings reveal that InvICL surpasses previous models, both invariant and non-invariant, in most benchmark datasets, showcasing superior generalization capabilities across varying input lengths. Code is available at https://github.com/PKU-ML/InvICL.","authors":["Lizhe Fang","Yifei Wang","Khashayar Gatmiry","Lei Fang","Yisen Wang"],"url":"https://arxiv.org/abs/2505.04994"}
{"created":"2025-05-09","title":"Inter-Diffusion Generation Model of Speakers and Listeners for Effective Communication","abstract":"Full-body gestures play a pivotal role in natural interactions and are crucial for achieving effective communication. Nevertheless, most existing studies primarily focus on the gesture generation of speakers, overlooking the vital role of listeners in the interaction process and failing to fully explore the dynamic interaction between them. This paper innovatively proposes an Inter-Diffusion Generation Model of Speakers and Listeners for Effective Communication. For the first time, we integrate the full-body gestures of listeners into the generation framework. By devising a novel inter-diffusion mechanism, this model can accurately capture the complex interaction patterns between speakers and listeners during communication. In the model construction process, based on the advanced diffusion model architecture, we innovatively introduce interaction conditions and the GAN model to increase the denoising step size. As a result, when generating gesture sequences, the model can not only dynamically generate based on the speaker's speech information but also respond in realtime to the listener's feedback, enabling synergistic interaction between the two. Abundant experimental results demonstrate that compared with the current state-of-the-art gesture generation methods, the model we proposed has achieved remarkable improvements in the naturalness, coherence, and speech-gesture synchronization of the generated gestures. In the subjective evaluation experiments, users highly praised the generated interaction scenarios, believing that they are closer to real life human communication situations. Objective index evaluations also show that our model outperforms the baseline methods in multiple key indicators, providing more powerful support for effective communication.","authors":["Jinhe Huang","Yongkang Cheng","Yuming Hang","Gaoge Han","Jinewei Li","Jing Zhang","Xingjian Gu"],"url":"https://arxiv.org/abs/2505.04996"}
{"created":"2025-05-09","title":"Foam-Agent: Towards Automated Intelligent CFD Workflows","abstract":"Computational Fluid Dynamics (CFD) is an essential simulation tool in various engineering disciplines, but it often requires substantial domain expertise and manual configuration, creating barriers to entry. We present Foam-Agent, a multi-agent framework that automates complex OpenFOAM-based CFD simulation workflows from natural language inputs. Our innovation includes (1) a hierarchical multi-index retrieval system with specialized indices for different simulation aspects, (2) a dependency-aware file generation system that provides consistency management across configuration files, and (3) an iterative error correction mechanism that diagnoses and resolves simulation failures without human intervention. Through comprehensive evaluation on the dataset of 110 simulation tasks, Foam-Agent achieves an 83.6% success rate with Claude 3.5 Sonnet, significantly outperforming existing frameworks (55.5% for MetaOpenFOAM and 37.3% for OpenFOAM-GPT). Ablation studies demonstrate the critical contribution of each system component, with the specialized error correction mechanism providing a 36.4% performance improvement. Foam-Agent substantially lowers the CFD expertise threshold while maintaining modeling accuracy, demonstrating the potential of specialized multi-agent systems to democratize access to complex scientific simulation tools. The code is public at https://github.com/csml-rpi/Foam-Agent","authors":["Ling Yue","Nithin Somasekharan","Yadi Cao","Shaowu Pan"],"url":"https://arxiv.org/abs/2505.04997"}
{"created":"2025-05-09","title":"CLAM: Continuous Latent Action Models for Robot Learning from Unlabeled Demonstrations","abstract":"Learning robot policies using imitation learning requires collecting large amounts of costly action-labeled expert demonstrations, which fundamentally limits the scale of training data. A promising approach to address this bottleneck is to harness the abundance of unlabeled observations-e.g., from video demonstrations-to learn latent action labels in an unsupervised way. However, we find that existing methods struggle when applied to complex robot tasks requiring fine-grained motions. We design continuous latent action models (CLAM) which incorporate two key ingredients we find necessary for learning to solve complex continuous control tasks from unlabeled observation data: (a) using continuous latent action labels instead of discrete representations, and (b) jointly training an action decoder to ensure that the latent action space can be easily grounded to real actions with relatively few labeled examples. Importantly, the labeled examples can be collected from non-optimal play data, enabling CLAM to learn performant policies without access to any action-labeled expert data. We demonstrate on continuous control benchmarks in DMControl (locomotion) and MetaWorld (manipulation), as well as on a real WidowX robot arm that CLAM significantly outperforms prior state-of-the-art methods, remarkably with a 2-3x improvement in task success rate compared to the best baseline. Videos and code can be found at clamrobot.github.io.","authors":["Anthony Liang","Pavel Czempin","Matthew Hong","Yutai Zhou","Erdem Biyik","Stephen Tu"],"url":"https://arxiv.org/abs/2505.04999"}
{"created":"2025-05-09","title":"StabStitch++: Unsupervised Online Video Stitching with Spatiotemporal Bidirectional Warps","abstract":"We retarget video stitching to an emerging issue, named warping shake, which unveils the temporal content shakes induced by sequentially unsmooth warps when extending image stitching to video stitching. Even if the input videos are stable, the stitched video can inevitably cause undesired warping shakes and affect the visual experience. To address this issue, we propose StabStitch++, a novel video stitching framework to realize spatial stitching and temporal stabilization with unsupervised learning simultaneously. First, different from existing learning-based image stitching solutions that typically warp one image to align with another, we suppose a virtual midplane between original image planes and project them onto it. Concretely, we design a differentiable bidirectional decomposition module to disentangle the homography transformation and incorporate it into our spatial warp, evenly spreading alignment burdens and projective distortions across two views. Then, inspired by camera paths in video stabilization, we derive the mathematical expression of stitching trajectories in video stitching by elaborately integrating spatial and temporal warps. Finally, a warp smoothing model is presented to produce stable stitched videos with a hybrid loss to simultaneously encourage content alignment, trajectory smoothness, and online collaboration. Compared with StabStitch that sacrifices alignment for stabilization, StabStitch++ makes no compromise and optimizes both of them simultaneously, especially in the online mode. To establish an evaluation benchmark and train the learning framework, we build a video stitching dataset with a rich diversity in camera motions and scenes. Experiments exhibit that StabStitch++ surpasses current solutions in stitching performance, robustness, and efficiency, offering compelling advancements in this field by building a real-time online video stitching system.","authors":["Lang Nie","Chunyu Lin","Kang Liao","Yun Zhang","Shuaicheng Liu","Yao Zhao"],"url":"https://arxiv.org/abs/2505.05001"}
{"created":"2025-05-09","title":"Automated Thoracolumbar Stump Rib Detection and Analysis in a Large CT Cohort","abstract":"Thoracolumbar stump ribs are one of the essential indicators of thoracolumbar transitional vertebrae or enumeration anomalies. While some studies manually assess these anomalies and describe the ribs qualitatively, this study aims to automate thoracolumbar stump rib detection and analyze their morphology quantitatively. To this end, we train a high-resolution deep-learning model for rib segmentation and show significant improvements compared to existing models (Dice score 0.997 vs. 0.779, p-value < 0.01). In addition, we use an iterative algorithm and piece-wise linear interpolation to assess the length of the ribs, showing a success rate of 98.2%. When analyzing morphological features, we show that stump ribs articulate more posteriorly at the vertebrae (-19.2 +- 3.8 vs -13.8 +- 2.5, p-value < 0.01), are thinner (260.6 +- 103.4 vs. 563.6 +- 127.1, p-value < 0.01), and are oriented more downwards and sideways within the first centimeters in contrast to full-length ribs. We show that with partially visible ribs, these features can achieve an F1-score of 0.84 in differentiating stump ribs from regular ones. We publish the model weights and masks for public use.","authors":["Hendrik M\\\"oller","Hanna Sch\\\"on","Alina Dima","Benjamin Keinert-Weth","Robert Graf","Matan Atad","Johannes Paetzold","Friederike Jungmann","Rickmer Braren","Florian Kofler","Bjoern Menze","Daniel Rueckert","Jan S. Kirschke"],"url":"https://arxiv.org/abs/2505.05004"}
{"created":"2025-05-09","title":"Driving with Context: Online Map Matching for Complex Roads Using Lane Markings and Scenario Recognition","abstract":"Accurate online map matching is fundamental to vehicle navigation and the activation of intelligent driving functions. Current online map matching methods are prone to errors in complex road networks, especially in multilevel road area. To address this challenge, we propose an online Standard Definition (SD) map matching method by constructing a Hidden Markov Model (HMM) with multiple probability factors. Our proposed method can achieve accurate map matching even in complex road networks by carefully leveraging lane markings and scenario recognition in the designing of the probability factors. First, the lane markings are generated by a multi-lane tracking method and associated with the SD map using HMM to build an enriched SD map. In areas covered by the enriched SD map, the vehicle can re-localize itself by performing Iterative Closest Point (ICP) registration for the lane markings. Then, the probability factor accounting for the lane marking detection can be obtained using the association probability between adjacent lanes and roads. Second, the driving scenario recognition model is applied to generate the emission probability factor of scenario recognition, which improves the performance of map matching on elevated roads and ordinary urban roads underneath them. We validate our method through extensive road tests in Europe and China, and the experimental results show that our proposed method effectively improves the online map matching accuracy as compared to other existing methods, especially in multilevel road area. Specifically, the experiments show that our proposed method achieves $F_1$ scores of 98.04% and 94.60% on the Zenseact Open Dataset and test data of multilevel road areas in Shanghai respectively, significantly outperforming benchmark methods. The implementation is available at https://github.com/TRV-Lab/LMSR-OMM.","authors":["Xin Bi","Zhichao Li","Yuxuan Xia","Panpan Tong","Lijuan Zhang","Yang Chen","Junsheng Fu"],"url":"https://arxiv.org/abs/2505.05007"}
{"created":"2025-05-09","title":"Adaptive Contextual Embedding for Robust Far-View Borehole Detection","abstract":"In controlled blasting operations, accurately detecting densely distributed tiny boreholes from far-view imagery is critical for operational safety and efficiency. However, existing detection methods often struggle due to small object scales, highly dense arrangements, and limited distinctive visual features of boreholes. To address these challenges, we propose an adaptive detection approach that builds upon existing architectures (e.g., YOLO) by explicitly leveraging consistent embedding representations derived through exponential moving average (EMA)-based statistical updates.","authors":["Xuesong Liu","Tianyu Hao","Emmett J. Ientilucci"],"url":"https://arxiv.org/abs/2505.05008"}
{"created":"2025-05-09","title":"Learning Partitions with Optimal Query and Round Complexities","abstract":"We consider the basic problem of learning an unknown partition of $n$ elements into at most $k$ sets using simple queries that reveal information about a small subset of elements. Our starting point is the well-studied pairwise same-set queries which ask if a pair of elements belong to the same class. It is known that non-adaptive algorithms require $\\Theta(n^2)$ queries, while adaptive algorithms require $\\Theta(nk)$ queries, and the best known algorithm uses $k-1$ rounds. This problem has been studied extensively over the last two decades in multiple communities due to its fundamental nature and relevance to clustering, active learning, and crowd sourcing. In many applications, it is of high interest to reduce adaptivity while minimizing query complexity. We give a complete characterization of the deterministic query complexity of this problem as a function of the number of rounds, $r$, interpolating between the non-adaptive and adaptive settings: for any constant $r$, the query complexity is $\\Theta(n^{1+\\frac{1}{2^r-1}}k^{1-\\frac{1}{2^r-1}})$. Our algorithm only needs $O(\\log \\log n)$ rounds to attain the optimal $O(nk)$ query complexity.","authors":["Hadley Black","Arya Mazumdar","Barna Saha"],"url":"https://arxiv.org/abs/2505.05009"}
{"created":"2025-05-09","title":"Improving Global Motion Estimation in Sparse IMU-based Motion Capture with Physics","abstract":"By learning human motion priors, motion capture can be achieved by 6 inertial measurement units (IMUs) in recent years with the development of deep learning techniques, even though the sensor inputs are sparse and noisy. However, human global motions are still challenging to be reconstructed by IMUs. This paper aims to solve this problem by involving physics. It proposes a physical optimization scheme based on multiple contacts to enable physically plausible translation estimation in the full 3D space where the z-directional motion is usually challenging for previous works. It also considers gravity in local pose estimation which well constrains human global orientations and refines local pose estimation in a joint estimation manner. Experiments demonstrate that our method achieves more accurate motion capture for both local poses and global motions. Furthermore, by deeply integrating physics, we can also estimate 3D contact, contact forces, joint torques, and interacting proxy surfaces.","authors":["Xinyu Yi","Shaohua Pan","Feng Xu"],"url":"https://arxiv.org/abs/2505.05010"}
{"created":"2025-05-09","title":"Sample Complexity of Identifying the Nonredundancy of Nontransitive Games in Dueling Bandits","abstract":"Dueling bandit is a variant of the Multi-armed bandit to learn the binary relation by comparisons. Most work on the dueling bandit has targeted transitive relations, that is, totally/partially ordered sets, or assumed at least the existence of a champion such as Condorcet winner and Copeland winner. This work develops an analysis of dueling bandits for non-transitive relations. Jan-ken (a.k.a. rock-paper-scissors) is a typical example of a non-transitive relation. It is known that a rational player chooses one of three items uniformly at random, which is known to be Nash equilibrium in game theory. Interestingly, any variant of Jan-ken with four items (e.g., rock, paper, scissors, and well) contains at least one useless item, which is never selected by a rational player. This work investigates a dueling bandit problem to identify whether all $n$ items are indispensable in a given win-lose relation. Then, we provide upper and lower bounds of the sample complexity of the identification problem in terms of the determinant of $A$ and a solution of $\\mathbf{x}^{\\top} A = \\mathbf{0}^{\\top}$ where $A$ is an $n \\times n$ pay-off matrix that every duel follows.","authors":["Shang Lu","Shuji Kijima"],"url":"https://arxiv.org/abs/2505.05014"}
{"created":"2025-05-09","title":"An Agent-Based Modeling Approach to Free-Text Keyboard Dynamics for Continuous Authentication","abstract":"Continuous authentication systems leveraging free-text keyboard dynamics offer a promising additional layer of security in a multifactor authentication setup that can be used in a transparent way with no impact on user experience. This study investigates the efficacy of behavioral biometrics by employing an Agent-Based Model (ABM) to simulate diverse typing profiles across mechanical and membrane keyboards. Specifically, we generated synthetic keystroke data from five unique agents, capturing features related to dwell time, flight time, and error rates within sliding 5-second windows updated every second. Two machine learning approaches, One-Class Support Vector Machine (OC-SVM) and Random Forest (RF), were evaluated for user verification. Results revealed a stark contrast in performance: while One-Class SVM failed to differentiate individual users within each group, Random Forest achieved robust intra-keyboard user recognition (Accuracy > 0.7) but struggled to generalize across keyboards for the same user, highlighting the significant impact of keyboard hardware on typing behavior. These findings suggest that: (1) keyboard-specific user profiles may be necessary for reliable authentication, and (2) ensemble methods like RF outperform One-Class SVM in capturing fine-grained user-specific patterns.","authors":["Roberto Dillon","Arushi"],"url":"https://arxiv.org/abs/2505.05015"}
{"created":"2025-05-09","title":"The Pitfalls of Growing Group Complexity: LLMs and Social Choice-Based Aggregation for Group Recommendations","abstract":"Large Language Models (LLMs) are increasingly applied in recommender systems aimed at both individuals and groups. Previously, Group Recommender Systems (GRS) often used social choice-based aggregation strategies to derive a single recommendation based on the preferences of multiple people. In this paper, we investigate under which conditions language models can perform these strategies correctly based on zero-shot learning and analyse whether the formatting of the group scenario in the prompt affects accuracy. We specifically focused on the impact of group complexity (number of users and items), different LLMs, different prompting conditions, including In-Context learning or generating explanations, and the formatting of group preferences. Our results show that performance starts to deteriorate when considering more than 100 ratings. However, not all language models were equally sensitive to growing group complexity. Additionally, we showed that In-Context Learning (ICL) can significantly increase the performance at higher degrees of group complexity, while adding other prompt modifications, specifying domain cues or prompting for explanations, did not impact accuracy. We conclude that future research should include group complexity as a factor in GRS evaluation due to its effect on LLM performance. Furthermore, we showed that formatting the group scenarios differently, such as rating lists per user or per item, affected accuracy. All in all, our study implies that smaller LLMs are capable of generating group recommendations under the right conditions, making the case for using smaller models that require less computing power and costs.","authors":["Cedric Waterschoot","Nava Tintarev","Francesco Barile"],"url":"https://arxiv.org/abs/2505.05016"}
{"created":"2025-05-09","title":"Scalable Multi-Stage Influence Function for Large Language Models via Eigenvalue-Corrected Kronecker-Factored Parameterization","abstract":"Pre-trained large language models (LLMs) are commonly fine-tuned to adapt to downstream tasks. Since the majority of knowledge is acquired during pre-training, attributing the predictions of fine-tuned LLMs to their pre-training data may provide valuable insights. Influence functions have been proposed as a means to explain model predictions based on training data. However, existing approaches fail to compute ``multi-stage'' influence and lack scalability to billion-scale LLMs.","authors":["Yuntai Bao","Xuhong Zhang","Tianyu Du","Xinkui Zhao","Jiang Zong","Hao Peng","Jianwei Yin"],"url":"https://arxiv.org/abs/2505.05017"}
{"created":"2025-05-09","title":"Diffusion-enabled Secure Semantic Communication Against Eavesdropping","abstract":"In this paper, AN is introduced into semantic communication systems for the first time to prevent semantic eavesdropping. However, the introduction of AN also poses challenges for the legitimate receiver in extracting semantic information. Recently, denoising diffusion probabilistic models (DDPM) have demonstrated their powerful capabilities in generating multimedia content. Here, the paired pluggable modules are carefully designed using DDPM. Specifically, the pluggable encryption module generates AN and adds it to the output of the semantic transmitter, while the pluggable decryption module before semantic receiver uses DDPM to generate the detailed semantic information by removing both AN and the channel noise. In the scenario where the transmitter lacks eavesdropper's knowledge, the artificial Gaussian noise (AGN) is used as AN. We first model a power allocation optimization problem to determine the power of AGN, in which the objective is to minimize the weighted sum of data reconstruction error of legal link, the mutual information of illegal link, and the channel input distortion. Then, a deep reinforcement learning framework using deep deterministic policy gradient is proposed to solve the optimization problem. In the scenario where the transmitter is aware of the eavesdropper's knowledge, we propose an AN generation method based on adversarial residual networks (ARN). Unlike the previous scenario, the mutual information term in the objective function is replaced by the confidence of eavesdropper correctly","authors":["Boxiang He","Zihan Chen","Fanggang Wang","Shilian Wang","Zhijin Qin","Tony Q. S. Quek"],"url":"https://arxiv.org/abs/2505.05018"}
{"created":"2025-05-09","title":"Generating Reliable Synthetic Clinical Trial Data: The Role of Hyperparameter Optimization and Domain Constraints","abstract":"The generation of synthetic clinical trial data offers a promising approach to mitigating privacy concerns and data accessibility limitations in medical research. However, ensuring that synthetic datasets maintain high fidelity, utility, and adherence to domain-specific constraints remains a key challenge. While hyperparameter optimization (HPO) has been shown to improve generative model performance, the effectiveness of different optimization strategies for synthetic clinical data remains unclear. This study systematically evaluates four HPO strategies across eight generative models, comparing single-metric optimization against compound metric optimization approaches. Our results demonstrate that HPO consistently improves synthetic data quality, with TVAE, CTGAN, and CTAB-GAN+ achieving improvements of up to 60%, 39%, and 38%, respectively. Compound metric optimization outperformed single-metric strategies, producing more balanced and generalizable synthetic datasets. Interestingly, HPO alone is insufficient to ensure clinically valid synthetic data, as all models exhibited violations of fundamental survival constraints. Preprocessing and postprocessing played a crucial role in reducing these violations, as models lacking robust processing steps produced invalid data in up to 61% of cases. These findings underscore the necessity of integrating explicit domain knowledge alongside HPO to create high quality synthetic datasets. Our study provides actionable recommendations for improving synthetic data generation, with future research needed to refine metric selection and validate these findings on larger datasets to enhance clinical applicability.","authors":["Waldemar Hahn","Jan-Niklas Eckardt","Christoph R\\\"ollig","Martin Sedlmayr","Jan Moritz Middeke","Markus Wolfien"],"url":"https://arxiv.org/abs/2505.05019"}
{"created":"2025-05-09","title":"Generative Models for Long Time Series: Approximately Equivariant Recurrent Network Structures for an Adjusted Training Scheme","abstract":"We present a simple yet effective generative model for time series data based on a Variational Autoencoder (VAE) with recurrent layers, referred to as the Recurrent Variational Autoencoder with Subsequent Training (RVAE-ST). Our method introduces an adapted training scheme that progressively increases the sequence length, addressing the challenge recurrent layers typically face when modeling long sequences. By leveraging the recurrent architecture, the model maintains a constant number of parameters regardless of sequence length. This design encourages approximate time-shift equivariance and enables efficient modeling of long-range temporal dependencies. Rather than introducing a fundamentally new architecture, we show that a carefully composed combination of known components can match or outperform state-of-the-art generative models on several benchmark datasets. Our model performs particularly well on time series that exhibit quasi-periodic structure,while remaining competitive on datasets with more irregular or partially non-stationary behavior. We evaluate its performance using ELBO, Fr\\'echet Distance, discriminative scores, and visualizations of the learned embeddings.","authors":["Ruwen Fulek","Markus Lange-Hegermann"],"url":"https://arxiv.org/abs/2505.05020"}
{"created":"2025-05-09","title":"SOAP: Style-Omniscient Animatable Portraits","abstract":"Creating animatable 3D avatars from a single image remains challenging due to style limitations (realistic, cartoon, anime) and difficulties in handling accessories or hairstyles. While 3D diffusion models advance single-view reconstruction for general objects, outputs often lack animation controls or suffer from artifacts because of the domain gap. We propose SOAP, a style-omniscient framework to generate rigged, topology-consistent avatars from any portrait. Our method leverages a multiview diffusion model trained on 24K 3D heads with multiple styles and an adaptive optimization pipeline to deform the FLAME mesh while maintaining topology and rigging via differentiable rendering. The resulting textured avatars support FACS-based animation, integrate with eyeballs and teeth, and preserve details like braided hair or accessories. Extensive experiments demonstrate the superiority of our method over state-of-the-art techniques for both single-view head modeling and diffusion-based generation of Image-to-3D. Our code and data are publicly available for research purposes at https://github.com/TingtingLiao/soap.","authors":["Tingting Liao","Yujian Zheng","Adilbek Karmanov","Liwen Hu","Leyang Jin","Yuliang Xiu","Hao Li"],"url":"https://arxiv.org/abs/2505.05022"}
{"created":"2025-05-09","title":"Split Matching for Inductive Zero-shot Semantic Segmentation","abstract":"Zero-shot Semantic Segmentation (ZSS) aims to segment categories that are not annotated during training. While fine-tuning vision-language models has achieved promising results, these models often overfit to seen categories due to the lack of supervision for unseen classes. As an alternative to fully supervised approaches, query-based segmentation has shown great latent in ZSS, as it enables object localization without relying on explicit labels. However, conventional Hungarian matching, a core component in query-based frameworks, needs full supervision and often misclassifies unseen categories as background in the setting of ZSS. To address this issue, we propose Split Matching (SM), a novel assignment strategy that decouples Hungarian matching into two components: one for seen classes in annotated regions and another for latent classes in unannotated regions (referred to as unseen candidates). Specifically, we partition the queries into seen and candidate groups, enabling each to be optimized independently according to its available supervision. To discover unseen candidates, we cluster CLIP dense features to generate pseudo masks and extract region-level embeddings using CLS tokens. Matching is then conducted separately for the two groups based on both class-level similarity and mask-level consistency. Additionally, we introduce a Multi-scale Feature Enhancement (MFE) module that refines decoder features through residual multi-scale aggregation, improving the model's ability to capture spatial details across resolutions. SM is the first to introduce decoupled Hungarian matching under the inductive ZSS setting, and achieves state-of-the-art performance on two standard benchmarks.","authors":["Jialei Chen","Xu Zheng","Dongyue Li","Chong Yi","Seigo Ito","Danda Pani Paudel","Luc Van Gool","Hiroshi Murase","Daisuke Deguchi"],"url":"https://arxiv.org/abs/2505.05023"}
{"created":"2025-05-09","title":"G-FOCUS: Towards a Robust Method for Assessing UI Design Persuasiveness","abstract":"Evaluating user interface (UI) design effectiveness extends beyond aesthetics to influencing user behavior, a principle central to Design Persuasiveness. A/B testing is the predominant method for determining which UI variations drive higher user engagement, but it is costly and time-consuming. While recent Vision-Language Models (VLMs) can process automated UI analysis, current approaches focus on isolated design attributes rather than comparative persuasiveness-the key factor in optimizing user interactions. To address this, we introduce WiserUI-Bench, a benchmark designed for Pairwise UI Design Persuasiveness Assessment task, featuring 300 real-world UI image pairs labeled with A/B test results and expert rationales. Additionally, we propose G-FOCUS, a novel inference-time reasoning strategy that enhances VLM-based persuasiveness assessment by reducing position bias and improving evaluation accuracy. Experimental results show that G-FOCUS surpasses existing inference strategies in consistency and accuracy for pairwise UI evaluation. Through promoting VLM-driven evaluation of UI persuasiveness, our work offers an approach to complement A/B testing, propelling progress in scalable UI preference modeling and design optimization. Code and data will be released publicly.","authors":["Jaehyun Jeon","Janghan Yoon","Minsoo Kim","Sumin Shim","Yejin Choi","Hanbin Kim","Youngjae Yu"],"url":"https://arxiv.org/abs/2505.05026"}
{"created":"2025-05-09","title":"A Reputation System for Large Language Model-based Multi-agent Systems to Avoid the Tragedy of the Commons","abstract":"The tragedy of the commons, where individual self-interest leads to collectively disastrous outcomes, is a pervasive challenge in human society. Recent studies have demonstrated that similar phenomena can arise in generative multi-agent systems (MASs). To address this challenge, this paper explores the use of reputation systems as a remedy. We propose RepuNet, a dynamic, dual-level reputation framework that models both agent-level reputation dynamics and system-level network evolution. Specifically, driven by direct interactions and indirect gossip, agents form reputations for both themselves and their peers, and decide whether to connect or disconnect other agents for future interactions. Through two distinct scenarios, we show that RepuNet effectively mitigates the 'tragedy of the commons', promoting and sustaining cooperation in generative MASs. Moreover, we find that reputation systems can give rise to rich emergent behaviors in generative MASs, such as the formation of cooperative clusters, the social isolation of exploitative agents, and the preference for sharing positive gossip rather than negative ones.","authors":["Siyue Ren","Wanli Fu","Xinkun Zou","Chen Shen","Yi Cai","Chen Chu","Zhen Wang","Shuyue Hu"],"url":"https://arxiv.org/abs/2505.05029"}
{"created":"2025-05-09","title":"LSRP: A Leader-Subordinate Retrieval Framework for Privacy-Preserving Cloud-Device Collaboration","abstract":"Cloud-device collaboration leverages on-cloud Large Language Models (LLMs) for handling public user queries and on-device Small Language Models (SLMs) for processing private user data, collectively forming a powerful and privacy-preserving solution. However, existing approaches often fail to fully leverage the scalable problem-solving capabilities of on-cloud LLMs while underutilizing the advantage of on-device SLMs in accessing and processing personalized data. This leads to two interconnected issues: 1) Limited utilization of the problem-solving capabilities of on-cloud LLMs, which fail to align with personalized user-task needs, and 2) Inadequate integration of user data into on-device SLM responses, resulting in mismatches in contextual user information.","authors":["Yingyi Zhang","Pengyue Jia","Xianneng Li","Derong Xu","Maolin Wang","Yichao Wang","Zhaocheng Du","Huifeng Guo","Yong Liu","Ruiming Tang","Xiangyu Zhao"],"url":"https://arxiv.org/abs/2505.05031"}
{"created":"2025-05-09","title":"Dequantified Diffusion Schr\\\"odinger Bridge for Density Ratio Estimation","abstract":"Density ratio estimation is fundamental to tasks involving $f$-divergences, yet existing methods often fail under significantly different distributions or inadequately overlap supports, suffering from the \\textit{density-chasm} and the \\textit{support-chasm} problems. Additionally, prior approaches yield divergent time scores near boundaries, leading to instability. We propose $\\text{D}^3\\text{RE}$, a unified framework for robust and efficient density ratio estimation. It introduces the Dequantified Diffusion-Bridge Interpolant (DDBI), which expands support coverage and stabilizes time scores via diffusion bridges and Gaussian dequantization. Building on DDBI, the Dequantified Schr\\\"odinger-Bridge Interpolant (DSBI) incorporates optimal transport to solve the Schr\\\"odinger bridge problem, enhancing accuracy and efficiency. Our method offers uniform approximation and bounded time scores in theory, and outperforms baselines empirically in mutual information and density estimation tasks.","authors":["Wei Chen","Shigui Li","Jiacheng Li","Junmei Yang","John Paisley","Delu Zeng"],"url":"https://arxiv.org/abs/2505.05034"}
{"created":"2025-05-09","title":"Divide-and-Conquer: Cold-Start Bundle Recommendation via Mixture of Diffusion Experts","abstract":"Cold-start bundle recommendation focuses on modeling new bundles with insufficient information to provide recommendations. Advanced bundle recommendation models usually learn bundle representations from multiple views (e.g., interaction view) at both the bundle and item levels. Consequently, the cold-start problem for bundles is more challenging than that for traditional items due to the dual-level multi-view complexity. In this paper, we propose a novel Mixture of Diffusion Experts (MoDiffE) framework, which employs a divide-and-conquer strategy for cold-start bundle recommendation and follows three steps:(1) Divide: The bundle cold-start problem is divided into independent but similar sub-problems sequentially by level and view, which can be summarized as the poor representation of feature-missing bundles in prior-embedding models. (2) Conquer: Beyond prior-embedding models that fundamentally provide the embedded representations, we introduce a diffusion-based method to solve all sub-problems in a unified way, which directly generates diffusion representations using diffusion models without depending on specific features. (3) Combine: A cold-aware hierarchical Mixture of Experts (MoE) is employed to combine results of the sub-problems for final recommendations, where the two models for each view serve as experts and are adaptively fused for different bundles in a multi-layer manner. Additionally, MoDiffE adopts a multi-stage decoupled training pipeline and introduces a cold-start gating augmentation method to enable the training of gating for cold bundles. Through extensive experiments on three real-world datasets, we demonstrate that MoDiffE significantly outperforms existing solutions in handling cold-start bundle recommendation. It achieves up to a 0.1027 absolute gain in Recall@20 in cold-start scenarios and up to a 47.43\\% relative improvement in all-bundle scenarios.","authors":["Ming Li","Lin Li","Xiaohui Tao","Dong Zhang","Jimmy Xiangji Huang"],"url":"https://arxiv.org/abs/2505.05035"}
{"created":"2025-05-09","title":"Enhanced Robust Tracking Control: An Online Learning Approach","abstract":"This work focuses the tracking control problem for nonlinear systems subjected to unknown external disturbances. Inspired by contraction theory, a neural network-dirven CCM synthesis is adopted to obtain a feedback controller that could track any feasible trajectory. Based on the observation that the system states under continuous control input inherently contain embedded information about unknown external disturbances, we propose an online learning scheme that captures the disturbances dyanmics from online historical data and embeds the compensation within the CCM controller. The proposed scheme operates as a plug-and-play module that intrinsically enhances the tracking performance of CCM synthesis. The numerical simulations on tethered space robot and PVTOL demonstrate the effectiveness of proposed scheme. The source code of the proposed online learning scheme can be found at https://github.com/NPU-RCIR/Online_CCM.git.","authors":["Ao Jin","Weijian Zhao","Yifeng Ma","Panfeng Huang","Fan Zhang"],"url":"https://arxiv.org/abs/2505.05036"}
{"created":"2025-05-09","title":"Enhanced convergence rates of Adaptive Importance Sampling with recycling schemes via quasi-Monte Carlo methods","abstract":"This article investigates the integration of quasi-Monte Carlo (QMC) methods using the Adaptive Multiple Importance Sampling (AMIS). Traditional Importance Sampling (IS) often suffers from poor performance since it heavily relies on the choice of the proposal distributions. The AMIS and the Modified version of AMIS (MAMIS) address this by iteratively refining proposal distributions and reusing all past samples through a recycling strategy. We introduce the RQMC methods into the MAMIS, achieving higher convergence rates compared to the Monte Carlo (MC) methods. Our main contributions include a detailed convergence analysis of the MAMIS estimator under randomized QMC (RQMC) sampling. Specifically, we establish the $L^q$ $(q \\geq 2)$ error bound for the RQMC-based estimator using a smoothed projection method, which enables us to apply the H\\\"older's inequality in the error analysis of the RQMC-based MAMIS estimator. As a result, we prove that the root mean square error of the RQMC-based MAMIS estimator converges at a rate of $\\mathcal{O}(\\bar{N}_T^{-1+\\epsilon})$, where $\\bar{N}_T$ is the average number of samples used in each step over $T$ iterations, and $\\epsilon > 0$ is arbitrarily small. Numerical experiments validate the effectiveness of our method, including mixtures of Gaussians, a banana-shaped model, and Bayesian Logistic regression.","authors":["Chen Jianlong","Du Jiarui","Wang Xiaoqun","He Zhijian"],"url":"https://arxiv.org/abs/2505.05037"}
{"created":"2025-05-09","title":"Uncertainty-Aware Scarf Plots","abstract":"Multiple challenges emerge when analyzing eye-tracking data with areas of interest (AOIs) because recordings are subject to different sources of uncertainties. Previous work often presents gaze data without considering those inaccuracies in the data. To address this issue, we developed uncertainty-aware scarf plot visualizations that aim to make analysts aware of uncertainties with respect to the position-based mapping of gaze to AOIs and depth dependency in 3D scenes. Additionally, we also consider uncertainties in automatic AOI annotation. We showcase our approach in comparison to standard scarf plots in an augmented reality scenario.","authors":["Nelusa Pathmanathan","Seyda \\\"Oney","Maurice Koch","Daniel Weiskopf","Kuno Kurzhals"],"url":"https://arxiv.org/abs/2505.05038"}
{"created":"2025-05-09","title":"Image-Text Relation Prediction for Multilingual Tweets","abstract":"Various social networks have been allowing media uploads for over a decade now. Still, it has not always been clear what is their relation with the posted text or even if there is any at all. In this work, we explore how multilingual vision-language models tackle the task of image-text relation prediction in different languages, and construct a dedicated balanced benchmark data set from Twitter posts in Latvian along with their manual translations into English. We compare our results to previous work and show that the more recently released vision-language model checkpoints are becoming increasingly capable at this task, but there is still much room for further improvement.","authors":["Mat\\=iss Rikters","Edison Marrese-Taylor"],"url":"https://arxiv.org/abs/2505.05040"}
{"created":"2025-05-09","title":"xTrace: A Facial Expressive Behaviour Analysis Tool for Continuous Affect Recognition","abstract":"Recognising expressive behaviours in face videos is a long-standing challenge in Affective Computing. Despite significant advancements in recent years, it still remains a challenge to build a robust and reliable system for naturalistic and in-the-wild facial expressive behaviour analysis in real time. This paper addresses two key challenges in building such a system: (1). The paucity of large-scale labelled facial affect video datasets with extensive coverage of the 2D emotion space, and (2). The difficulty of extracting facial video features that are discriminative, interpretable, robust, and computationally efficient. Toward addressing these challenges, we introduce xTrace, a robust tool for facial expressive behaviour analysis and predicting continuous values of dimensional emotions, namely valence and arousal, from in-the-wild face videos.","authors":["Mani Kumar Tellamekala","Shashank Jaiswal","Thomas Smith","Timur Alamev","Gary McKeown","Anthony Brown","Michel Valstar"],"url":"https://arxiv.org/abs/2505.05043"}
{"created":"2025-05-09","title":"Neural Pathways to Program Success: Hopfield Networks for PERT Analysis","abstract":"Project and task scheduling under uncertainty remains a fundamental challenge in program and project management, where accurate estimation of task durations and dependencies is critical for delivering complex, multi project systems. The Program Evaluation and Review Technique provides a probabilistic framework to model task variability and critical paths. In this paper, the author presents a novel formulation of PERT scheduling as an energy minimization problem within a Hopfield neural network architecture. By mapping task start times and precedence constraints into a neural computation framework, the networks inherent optimization dynamics is exploited to approximate globally consistent schedules. The author addresses key theoretical issues related to energy function differentiability, constraint encoding, and convergence, and extends the Hopfield model for structured precedence graphs. Numerical simulations on synthetic project networks comprising up to 1000 tasks demonstrate the viability of this approach, achieving near optimal makespans with minimal constraint violations. The findings suggest that neural optimization models offer a promising direction for scalable and adaptive project tasks scheduling under uncertainty in areas such as the agentic AI workflows, microservice based applications that the modern AI systems are being built upon.","authors":["Azgar Ali Noor Ahamed"],"url":"https://arxiv.org/abs/2505.05047"}
{"created":"2025-05-09","title":"UncertainSAM: Fast and Efficient Uncertainty Quantification of the Segment Anything Model","abstract":"The introduction of the Segment Anything Model (SAM) has paved the way for numerous semantic segmentation applications. For several tasks, quantifying the uncertainty of SAM is of particular interest. However, the ambiguous nature of the class-agnostic foundation model SAM challenges current uncertainty quantification (UQ) approaches. This paper presents a theoretically motivated uncertainty quantification model based on a Bayesian entropy formulation jointly respecting aleatoric, epistemic, and the newly introduced task uncertainty. We use this formulation to train USAM, a lightweight post-hoc UQ method. Our model traces the root of uncertainty back to under-parameterised models, insufficient prompts or image ambiguities. Our proposed deterministic USAM demonstrates superior predictive capabilities on the SA-V, MOSE, ADE20k, DAVIS, and COCO datasets, offering a computationally cheap and easy-to-use UQ alternative that can support user-prompting, enhance semi-supervised pipelines, or balance the tradeoff between accuracy and cost efficiency.","authors":["Timo Kaiser","Thomas Norrenbrock","Bodo Rosenhahn"],"url":"https://arxiv.org/abs/2505.05049"}
{"created":"2025-05-09","title":"How to Infer Repeat Structures in MIDI Performances","abstract":"MIDI performances are generally expedient in performance research and music information retrieval, and even more so if they can be connected to a score. This connection is usually established by means of alignment, linking either notes or time points between the score and the performance. The first obstacle when trying to establish such an alignment is that a performance realizes one (out of many) structural versions of the score that can plausibly result from instructions such as repeats, variations, and navigation markers like 'dal segno/da capo al coda'. A score needs to be unfolded, that is, its repeats and navigation markers need to be explicitly written out to create a single timeline without jumps matching the performance, before alignment algorithms can be applied. In the curation of large performance corpora this process is carried out manually, as no tools are available to infer the repeat structure of the performance. To ease this process, we develop a method to automatically infer the repeat structure of a MIDI performance, given a symbolically encoded score including repeat and navigation markers. The intuition guiding our design is: 1) local alignment of every contiguous section of the score with a section of a performance containing the same material should receive high alignment gain, whereas local alignment with any other performance section should accrue a low or zero gain. And 2) stitching local alignments together according to a valid structural version of the score should result in an approximate full alignment and correspondingly high global accumulated gain if the structural version corresponds to the performance, and low gain for all other, ill-fitting structural versions.","authors":["Silvan Peter","Patricia Hu","Gerhard Widmer"],"url":"https://arxiv.org/abs/2505.05055"}
{"created":"2025-05-09","title":"Teochew-Wild: The First In-the-wild Teochew Dataset with Orthographic Annotations","abstract":"This paper reports the construction of the Teochew-Wild, a speech corpus of the Teochew dialect. The corpus includes 18.9 hours of in-the-wild Teochew speech data from multiple speakers, covering both formal and colloquial expressions, with precise orthographic and pinyin annotations. Additionally, we provide supplementary text processing tools and resources to propel research and applications in speech tasks for this low-resource language, such as automatic speech recognition (ASR) and text-to-speech (TTS). To the best of our knowledge, this is the first publicly available Teochew dataset with accurate orthographic annotations. We conduct experiments on the corpus, and the results validate its effectiveness in ASR and TTS tasks.","authors":["Linrong Pan","Chenglong Jiang","Gaoze Hou","Ying Gao"],"url":"https://arxiv.org/abs/2505.05056"}
{"created":"2025-05-09","title":"Towards Mitigating API Hallucination in Code Generated by LLMs with Hierarchical Dependency Aware","abstract":"Application Programming Interfaces (APIs) are crucial in modern software development. Large Language Models (LLMs) assist in automated code generation but often struggle with API hallucination, including invoking non-existent APIs and misusing existing ones in practical development scenarios. Existing studies resort to Retrieval-Augmented Generation (RAG) methods for mitigating the hallucination issue, but tend to fail since they generally ignore the structural dependencies in practical projects and do not indeed validate whether the generated APIs are available or not. To address these limitations, we propose MARIN, a framework for mitigating API hallucination in code generated by LLMs with hierarchical dependency aware. MARIN consists of two phases: Hierarchical Dependency Mining, which analyzes local and global dependencies of the current function, aiming to supplement comprehensive project context in LLMs input, and Dependency Constrained Decoding, which utilizes mined dependencies to adaptively constrain the generation process, aiming to ensure the generated APIs align with the projects specifications. To facilitate the evaluation of the degree of API hallucination, we introduce a new benchmark APIHulBench and two new metrics including Micro Hallucination Number (MiHN) and Macro Hallucination Rate (MaHR). Experiments on six state-of-the-art LLMs demonstrate that MARIN effectively reduces API hallucinations, achieving an average decrease of 67.52% in MiHN and 73.56% in MaHR compared to the RAG approach. Applied to Huaweis internal projects and two proprietary LLMs, MARIN achieves average decreases of 57.33% in MiHN and 59.41% in MaHR.","authors":["Yujia Chen","Mingyu Chen","Cuiyun Gao","Zhihan Jiang","Zhongqi Li","Yuchi Ma"],"url":"https://arxiv.org/abs/2505.05057"}
{"created":"2025-05-09","title":"Enhancing Reinforcement Learning for the Floorplanning of Analog ICs with Beam Search","abstract":"The layout of analog ICs requires making complex trade-offs, while addressing device physics and variability of the circuits. This makes full automation with learning-based solutions hard to achieve. However, reinforcement learning (RL) has recently reached significant results, particularly in solving the floorplanning problem. This paper presents a hybrid method that combines RL with a beam (BS) strategy. The BS algorithm enhances the agent's inference process, allowing for the generation of flexible floorplans by accomodating various objective weightings, and addressing congestion without without the need for policy retraining or fine-tuning. Moreover, the RL agent's generalization ability stays intact, along with its efficient handling of circuit features and constraints. Experimental results show approx. 5-85% improvement in area, dead space and half-perimeter wire length compared to a standard RL application, along with higher rewards for the agent. Moreover, performance and efficiency align closely with those of existing state-of-the-art techniques.","authors":["Sandro Junior Della Rovere","Davide Basso","Luca Bortolussi","Mirjana Videnovic-Misic","Husni Habal"],"url":"https://arxiv.org/abs/2505.05059"}
{"created":"2025-05-09","title":"ULFine: Unbiased Lightweight Fine-tuning for Foundation-Model-Assisted Long-Tailed Semi-Supervised Learning","abstract":"Based on the success of large-scale visual foundation models like CLIP in various downstream tasks, this paper initially attempts to explore their impact on Long-Tailed Semi-Supervised Learning (LTSSL) by employing the foundation model with three strategies: Linear Probing (LP), Lightweight Fine-Tuning (LFT), and Full Fine-Tuning (FFT). Our analysis presents the following insights: i) Compared to LTSSL algorithms trained from scratch, FFT results in a decline in model performance, whereas LP and LFT, although boosting overall model performance, exhibit negligible benefits to tail classes. ii) LP produces numerous false pseudo-labels due to \\textit{underlearned} training data, while LFT can reduce the number of these false labels but becomes overconfident about them owing to \\textit{biased fitting} training data. This exacerbates the pseudo-labeled and classifier biases inherent in LTSSL, limiting performance improvement in the tail classes. With these insights, we propose a Unbiased Lightweight Fine-tuning strategy, \\textbf{ULFine}, which mitigates the overconfidence via confidence-aware adaptive fitting of textual prototypes and counteracts the pseudo-labeled and classifier biases via complementary fusion of dual logits. Extensive experiments demonstrate that ULFine markedly decreases training costs by over ten times and substantially increases prediction accuracies compared to state-of-the-art methods.","authors":["Enhao Zhang","Chaohua Li","Chuanxing Geng","Songcan Chen"],"url":"https://arxiv.org/abs/2505.05062"}
{"created":"2025-05-09","title":"CodeMixBench: Evaluating Large Language Models on Code Generation with Code-Mixed Prompts","abstract":"Large Language Models (LLMs) have achieved remarkable success in code generation tasks, powering various applications like code completion, debugging, and programming assistance. However, existing benchmarks such as HumanEval, MBPP, and BigCodeBench primarily evaluate LLMs on English-only prompts, overlooking the real-world scenario where multilingual developers often use code-mixed language while interacting with LLMs. To address this gap, we introduce CodeMixBench, a novel benchmark designed to evaluate the robustness of LLMs on code generation from code-mixed prompts. Built upon BigCodeBench, CodeMixBench introduces controlled code-mixing (CMD) into the natural language parts of prompts across three language pairs: Hinglish (Hindi-English), Spanish-English, and Chinese Pinyin-English. We comprehensively evaluate a diverse set of open-source code generation models ranging from 1.5B to 15B parameters. Our results show that code-mixed prompts consistently degrade Pass@1 performance compared to their English-only counterparts, with performance drops increasing under higher CMD levels for smaller models. CodeMixBench provides a realistic evaluation framework for studying multilingual code generation and highlights new challenges and directions for building robust code generation models that generalize well across diverse linguistic settings.","authors":["Manik Sheokand","Parth Sawant"],"url":"https://arxiv.org/abs/2505.05063"}
{"created":"2025-05-09","title":"WaterDrum: Watermarking for Data-centric Unlearning Metric","abstract":"Large language model (LLM) unlearning is critical in real-world applications where it is necessary to efficiently remove the influence of private, copyrighted, or harmful data from some users. However, existing utility-centric unlearning metrics (based on model utility) may fail to accurately evaluate the extent of unlearning in realistic settings such as when (a) the forget and retain set have semantically similar content, (b) retraining the model from scratch on the retain set is impractical, and/or (c) the model owner can improve the unlearning metric without directly performing unlearning on the LLM. This paper presents the first data-centric unlearning metric for LLMs called WaterDrum that exploits robust text watermarking for overcoming these limitations. We also introduce new benchmark datasets for LLM unlearning that contain varying levels of similar data points and can be used to rigorously evaluate unlearning algorithms using WaterDrum. Our code is available at https://github.com/lululu008/WaterDrum and our new benchmark datasets are released at https://huggingface.co/datasets/Glow-AI/WaterDrum-Ax.","authors":["Xinyang Lu","Xinyuan Niu","Gregory Kang Ruey Lau","Bui Thi Cam Nhung","Rachael Hwee Ling Sim","Fanyu Wen","Chuan-Sheng Foo","See-Kiong Ng","Bryan Kian Hsiang Low"],"url":"https://arxiv.org/abs/2505.05064"}
{"created":"2025-05-09","title":"Cross-Problem Solving for Network Optimization: Is Problem-Aware Learning the Key?","abstract":"As intelligent network services continue to diversify, ensuring efficient and adaptive resource allocation in edge networks has become increasingly critical. Yet the wide functional variations across services often give rise to new and unforeseen optimization problems, rendering traditional manual modeling and solver design both time-consuming and inflexible. This limitation reveals a key gap between current methods and human solving - the inability to recognize and understand problem characteristics. It raises the question of whether problem-aware learning can bridge this gap and support effective cross-problem generalization. To answer this question, we propose a problem-aware diffusion (PAD) model, which leverages a problem-aware learning framework to enable cross-problem generalization. By explicitly encoding the mathematical formulations of optimization problems into token-level embeddings, PAD empowers the model to understand and adapt to problem structures. Extensive experiments across six diverse network optimization problems show that PAD generalizes well to unseen problems while significantly improving solution quality and feasibility. Meanwhile, an auxiliary constraint-aware module is designed to enforce solution validity further. The experiments reveal that problem-aware learning is promising for building general-purpose solvers for intelligent network operation and resource management. Our code is open source at https://github.com/qiyu3816/PAD.","authors":["Ruihuai Liang","Bo Yang","Pengyu Chen","Xuelin Cao","Zhiwen Yu","H. Vincent Poor","Chau Yuen"],"url":"https://arxiv.org/abs/2505.05067"}
{"created":"2025-05-09","title":"Performance Evaluation of Large Language Models in Bangla Consumer Health Query Summarization","abstract":"Consumer Health Queries (CHQs) in Bengali (Bangla), a low-resource language, often contain extraneous details, complicating efficient medical responses. This study investigates the zero-shot performance of nine advanced large language models (LLMs): GPT-3.5-Turbo, GPT-4, Claude-3.5-Sonnet, Llama3-70b-Instruct, Mixtral-8x22b-Instruct, Gemini-1.5-Pro, Qwen2-72b-Instruct, Gemma-2-27b, and Athene-70B, in summarizing Bangla CHQs. Using the BanglaCHQ-Summ dataset comprising 2,350 annotated query-summary pairs, we benchmarked these LLMs using ROUGE metrics against Bangla T5, a fine-tuned state-of-the-art model. Mixtral-8x22b-Instruct emerged as the top performing model in ROUGE-1 and ROUGE-L, while Bangla T5 excelled in ROUGE-2. The results demonstrate that zero-shot LLMs can rival fine-tuned models, achieving high-quality summaries even without task-specific training. This work underscores the potential of LLMs in addressing challenges in low-resource languages, providing scalable solutions for healthcare query summarization.","authors":["Ajwad Abrar","Farzana Tabassum","Sabbir Ahmed"],"url":"https://arxiv.org/abs/2505.05070"}
{"created":"2025-05-09","title":"FG-CLIP: Fine-Grained Visual and Textual Alignment","abstract":"Contrastive Language-Image Pre-training (CLIP) excels in multimodal tasks such as image-text retrieval and zero-shot classification but struggles with fine-grained understanding due to its focus on coarse-grained short captions. To address this, we propose Fine-Grained CLIP (FG-CLIP), which enhances fine-grained understanding through three key innovations. First, we leverage large multimodal models to generate 1.6 billion long caption-image pairs for capturing global-level semantic details. Second, a high-quality dataset is constructed with 12 million images and 40 million region-specific bounding boxes aligned with detailed captions to ensure precise, context-rich representations. Third, 10 million hard fine-grained negative samples are incorporated to improve the model's ability to distinguish subtle semantic differences. Corresponding training methods are meticulously designed for these data. Extensive experiments demonstrate that FG-CLIP outperforms the original CLIP and other state-of-the-art methods across various downstream tasks, including fine-grained understanding, open-vocabulary object detection, image-text retrieval, and general multimodal benchmarks. These results highlight FG-CLIP's effectiveness in capturing fine-grained image details and improving overall model performance. The related data, code, and models are available at https://github.com/360CVGroup/FG-CLIP.","authors":["Chunyu Xie","Bin Wang","Fanjing Kong","Jincheng Li","Dawei Liang","Gengshen Zhang","Dawei Leng","Yuhui Yin"],"url":"https://arxiv.org/abs/2505.05071"}
{"created":"2025-05-09","title":"Visual Affordances: Enabling Robots to Understand Object Functionality","abstract":"Human-robot interaction for assistive technologies relies on the prediction of affordances, which are the potential actions a robot can perform on objects. Predicting object affordances from visual perception is formulated differently for tasks such as grasping detection, affordance classification, affordance segmentation, and hand-object interaction synthesis. In this work, we highlight the reproducibility issue in these redefinitions, making comparative benchmarks unfair and unreliable. To address this problem, we propose a unified formulation for visual affordance prediction, provide a comprehensive and systematic review of previous works highlighting strengths and limitations of methods and datasets, and analyse what challenges reproducibility. To favour transparency, we introduce the Affordance Sheet, a document to detail the proposed solution, the datasets, and the validation. As the physical properties of an object influence the interaction with the robot, we present a generic framework that links visual affordance prediction to the physical world. Using the weight of an object as an example for this framework, we discuss how estimating object mass can affect the affordance prediction. Our approach bridges the gap between affordance perception and robot actuation, and accounts for the complete information about objects of interest and how the robot interacts with them to accomplish its task.","authors":["Tommaso Apicella","Alessio Xompero","Andrea Cavallaro"],"url":"https://arxiv.org/abs/2505.05074"}
{"created":"2025-05-09","title":"The City that Never Settles: Simulation-based LiDAR Dataset for Long-Term Place Recognition Under Extreme Structural Changes","abstract":"Large-scale construction and demolition significantly challenge long-term place recognition (PR) by drastically reshaping urban and suburban environments. Existing datasets predominantly reflect limited or indoor-focused changes, failing to adequately represent extensive outdoor transformations. To bridge this gap, we introduce the City that Never Settles (CNS) dataset, a simulation-based dataset created using the CARLA simulator, capturing major structural changes-such as building construction and demolition-across diverse maps and sequences. Additionally, we propose TCR_sym, a symmetric version of the original TCR metric, enabling consistent measurement of structural changes irrespective of source-target ordering. Quantitative comparisons demonstrate that CNS encompasses more extensive transformations than current real-world benchmarks. Evaluations of state-of-the-art LiDAR-based PR methods on CNS reveal substantial performance degradation, underscoring the need for robust algorithms capable of handling significant environmental changes. Our dataset is available at https://github.com/Hyunho111/CNS_dataset.","authors":["Hyunho Song","Dongjae Lee","Seunghun Oh","Minwoo Jung","Ayoung Kim"],"url":"https://arxiv.org/abs/2505.05076"}
{"created":"2025-05-09","title":"ReverbMiipher: Generative Speech Restoration meets Reverberation Characteristics Controllability","abstract":"Reverberation encodes spatial information regarding the acoustic source environment, yet traditional Speech Restoration (SR) usually completely removes reverberation. We propose ReverbMiipher, an SR model extending parametric resynthesis framework, designed to denoise speech while preserving and enabling control over reverberation. ReverbMiipher incorporates a dedicated ReverbEncoder to extract a reverb feature vector from noisy input. This feature conditions a vocoder to reconstruct the speech signal, removing noise while retaining the original reverberation characteristics. A stochastic zero-vector replacement strategy during training ensures the feature specifically encodes reverberation, disentangling it from other speech attributes. This learned representation facilitates reverberation control via techniques such as interpolation between features, replacement with features from other utterances, or sampling from a latent space. Objective and subjective evaluations confirm ReverbMiipher effectively preserves reverberation, removes other artifacts, and outperforms the conventional two-stage SR and convolving simulated room impulse response approach. We further demonstrate its ability to generate novel reverberation effects through feature manipulation.","authors":["Wataru Nakata","Yuma Koizumi","Shigeki Karita","Robin Scheibler","Haruko Ishikawa","Adriana Guevara-Rukoz","Heiga Zen","Michiel Bacchiani"],"url":"https://arxiv.org/abs/2505.05077"}
{"created":"2025-05-09","title":"Pairing Real-Time Piano Transcription with Symbol-level Tracking for Precise and Robust Score Following","abstract":"Real-time music tracking systems follow a musical performance and at any time report the current position in a corresponding score. Most existing methods approach this problem exclusively in the audio domain, typically using online time warping (OLTW) techniques on incoming audio and an audio representation of the score. Audio OLTW techniques have seen incremental improvements both in features and model heuristics which reached a performance plateau in the past ten years. We argue that converting and representing the performance in the symbolic domain -- thereby transforming music tracking into a symbolic task -- can be a more effective approach, even when the domain transformation is imperfect. Our music tracking system combines two real-time components: one handling audio-to-note transcription and the other a novel symbol-level tracker between transcribed input and score. We compare the performance of this mixed audio-symbolic approach with its equivalent audio-only counterpart, and demonstrate that our method outperforms the latter in terms of both precision, i.e., absolute tracking error, and robustness, i.e., tracking success.","authors":["Silvan Peter","Patricia Hu","Gerhard Widmer"],"url":"https://arxiv.org/abs/2505.05078"}
{"created":"2025-05-09","title":"PIDiff: Image Customization for Personalized Identities with Diffusion Models","abstract":"Text-to-image generation for personalized identities aims at incorporating the specific identity into images using a text prompt and an identity image. Based on the powerful generative capabilities of DDPMs, many previous works adopt additional prompts, such as text embeddings and CLIP image embeddings, to represent the identity information, while they fail to disentangle the identity information and background information. As a result, the generated images not only lose key identity characteristics but also suffer from significantly reduced diversity. To address this issue, previous works have combined the W+ space from StyleGAN with diffusion models, leveraging this space to provide a more accurate and comprehensive representation of identity features through multi-level feature extraction. However, the entanglement of identity and background information in in-the-wild images during training prevents accurate identity localization, resulting in severe semantic interference between identity and background. In this paper, we propose a novel fine-tuning-based diffusion model for personalized identities text-to-image generation, named PIDiff, which leverages the W+ space and an identity-tailored fine-tuning strategy to avoid semantic entanglement and achieves accurate feature extraction and localization. Style editing can also be achieved by PIDiff through preserving the characteristics of identity features in the W+ space, which vary from coarse to fine. Through the combination of the proposed cross-attention block and parameter optimization strategy, PIDiff preserves the identity information and maintains the generation capability for in-the-wild images of the pre-trained model during inference. Our experimental results validate the effectiveness of our method in this task.","authors":["Jinyu Gu","Haipeng Liu","Meng Wang","Yang Wang"],"url":"https://arxiv.org/abs/2505.05081"}
{"created":"2025-05-09","title":"ItDPDM: Information-Theoretic Discrete Poisson Diffusion Model","abstract":"Existing methods for generative modeling of discrete data, such as symbolic music tokens, face two primary challenges: (1) they either embed discrete inputs into continuous state-spaces or (2) rely on variational losses that only approximate the true negative log-likelihood. Previous efforts have individually targeted these limitations. While information-theoretic Gaussian diffusion models alleviate the suboptimality of variational losses, they still perform modeling in continuous domains. In this work, we introduce the Information-Theoretic Discrete Poisson Diffusion Model (ItDPDM), which simultaneously addresses both limitations by directly operating in a discrete state-space via a Poisson diffusion process inspired by photon arrival processes in camera sensors. We introduce a novel Poisson Reconstruction Loss (PRL) and derive an exact relationship between PRL and the true negative log-likelihood, thereby eliminating the need for approximate evidence lower bounds. Experiments conducted on the Lakh MIDI symbolic music dataset and the CIFAR-10 image benchmark demonstrate that ItDPDM delivers significant improvements, reducing test NLL by up to 80% compared to prior baselines, while also achieving faster convergence.","authors":["Sagnik Bhattacharya","Abhiram R. Gorle","Ahmed Mohsin","Ahsan Bilal","Connor Ding","Amit Kumar Singh Yadav","Tsachy Weissman"],"url":"https://arxiv.org/abs/2505.05082"}
{"created":"2025-05-09","title":"Hybrid Personalization Using Declarative and Procedural Memory Modules of the Cognitive Architecture ACT-R","abstract":"Recommender systems often rely on sub-symbolic machine learning approaches that operate as opaque black boxes. These approaches typically fail to account for the cognitive processes that shape user preferences and decision-making. In this vision paper, we propose a hybrid user modeling framework based on the cognitive architecture ACT-R that integrates symbolic and sub-symbolic representations of human memory. Our goal is to combine ACT-R's declarative memory, which is responsible for storing symbolic chunks along sub-symbolic activations, with its procedural memory, which contains symbolic production rules. This integration will help simulate how users retrieve past experiences and apply decision-making strategies. With this approach, we aim to provide more transparent recommendations, enable rule-based explanations, and facilitate the modeling of cognitive biases. We argue that our approach has the potential to inform the design of a new generation of human-centered, psychology-informed recommender systems.","authors":["Kevin Innerebner","Dominik Kowald","Markus Schedl","Elisabeth Lex"],"url":"https://arxiv.org/abs/2505.05083"}
{"created":"2025-05-09","title":"Reliably Bounding False Positives: A Zero-Shot Machine-Generated Text Detection Framework via Multiscaled Conformal Prediction","abstract":"The rapid advancement of large language models has raised significant concerns regarding their potential misuse by malicious actors. As a result, developing effective detectors to mitigate these risks has become a critical priority. However, most existing detection methods focus excessively on detection accuracy, often neglecting the societal risks posed by high false positive rates (FPRs). This paper addresses this issue by leveraging Conformal Prediction (CP), which effectively constrains the upper bound of FPRs. While directly applying CP constrains FPRs, it also leads to a significant reduction in detection performance. To overcome this trade-off, this paper proposes a Zero-Shot Machine-Generated Text Detection Framework via Multiscaled Conformal Prediction (MCP), which both enforces the FPR constraint and improves detection performance. This paper also introduces RealDet, a high-quality dataset that spans a wide range of domains, ensuring realistic calibration and enabling superior detection performance when combined with MCP. Empirical evaluations demonstrate that MCP effectively constrains FPRs, significantly enhances detection performance, and increases robustness against adversarial attacks across multiple detectors and datasets.","authors":["Xiaowei Zhu","Yubing Ren","Yanan Cao","Xixun Lin","Fang Fang","Yangxi Li"],"url":"https://arxiv.org/abs/2505.05084"}
{"created":"2025-05-09","title":"Beyond Low-rank Decomposition: A Shortcut Approach for Efficient On-Device Learning","abstract":"On-device learning has emerged as a promising direction for AI development, particularly because of its potential to reduce latency issues and mitigate privacy risks associated with device-server communication, while improving energy efficiency. Despite these advantages, significant memory and computational constraints still represent major challenges for its deployment. Drawing on previous studies on low-rank decomposition methods that address activation memory bottlenecks in backpropagation, we propose a novel shortcut approach as an alternative. Our analysis and experiments demonstrate that our method can reduce activation memory usage, even up to $120.09\\times$ compared to vanilla training, while also reducing overall training FLOPs up to $1.86\\times$ when evaluated on traditional benchmarks.","authors":["Le-Trung Nguyen","Ael Quelennec","Van-Tam Nguyen","Enzo Tartaglione"],"url":"https://arxiv.org/abs/2505.05086"}
{"created":"2025-05-09","title":"Predictive Control of EV Overnight Charging with Multi-Session Flexibility","abstract":"The majority of electric vehicles (EVs) are charged domestically overnight, where the precise timing of power allocation is not important to the user, thus representing a source of flexibility that can be leveraged by charging control algorithms. In this paper, we relax the common assumption, that EVs require full charge every morning, enabling additional flexibility to defer charging of surplus energy to subsequent nights, which can enhance the performance of controlled charging. In particular, we consider a simple domestic smart plug, scheduling power delivery with the objective to minimize CO$_2$ emissions over prediction horizons of multiple sessions -- up to seven days ahead -- utilising model predictive control (MPC). Based on carbon intensity data from the UK National Grid, we demonstrate significant potential for emission reductions with multi-session planning of 40 to 46\\% compared to uncontrolled charging and 19 to 26\\% compared to single-session planning. Furthermore, we assess, how the driving and charging behaviour of EV users affects the available flexibility and consequentially the potential for emission reductions. Finally, using grid carbon intensity data from 14 different UK regions, we report significant variations in absolute emission reductions based on the local energy mix.","authors":["Felix Wieberneit","Emanuele Crisostomi","Anthony Quinn","Robert Shorten"],"url":"https://arxiv.org/abs/2505.05087"}
{"created":"2025-05-09","title":"SSH-Net: A Self-Supervised and Hybrid Network for Noisy Image Watermark Removal","abstract":"Visible watermark removal is challenging due to its inherent complexities and the noise carried within images. Existing methods primarily rely on supervised learning approaches that require paired datasets of watermarked and watermark-free images, which are often impractical to obtain in real-world scenarios. To address this challenge, we propose SSH-Net, a Self-Supervised and Hybrid Network specifically designed for noisy image watermark removal. SSH-Net synthesizes reference watermark-free images using the watermark distribution in a self-supervised manner and adopts a dual-network design to address the task. The upper network, focused on the simpler task of noise removal, employs a lightweight CNN-based architecture, while the lower network, designed to handle the more complex task of simultaneously removing watermarks and noise, incorporates Transformer blocks to model long-range dependencies and capture intricate image features. To enhance the model's effectiveness, a shared CNN-based feature encoder is introduced before dual networks to extract common features that both networks can leverage. Our code will be available at https://github.com/wenyang001/SSH-Net.","authors":["Wenyang Liu","Jianjun Gao","Kim-Hui Yap"],"url":"https://arxiv.org/abs/2505.05088"}
{"created":"2025-05-09","title":"Nonlinear Motion-Guided and Spatio-Temporal Aware Network for Unsupervised Event-Based Optical Flow","abstract":"Event cameras have the potential to capture continuous motion information over time and space, making them well-suited for optical flow estimation. However, most existing learning-based methods for event-based optical flow adopt frame-based techniques, ignoring the spatio-temporal characteristics of events. Additionally, these methods assume linear motion between consecutive events within the loss time window, which increases optical flow errors in long-time sequences. In this work, we observe that rich spatio-temporal information and accurate nonlinear motion between events are crucial for event-based optical flow estimation. Therefore, we propose E-NMSTFlow, a novel unsupervised event-based optical flow network focusing on long-time sequences. We propose a Spatio-Temporal Motion Feature Aware (STMFA) module and an Adaptive Motion Feature Enhancement (AMFE) module, both of which utilize rich spatio-temporal information to learn spatio-temporal data associations. Meanwhile, we propose a nonlinear motion compensation loss that utilizes the accurate nonlinear motion between events to improve the unsupervised learning of our network. Extensive experiments demonstrate the effectiveness and superiority of our method. Remarkably, our method ranks first among unsupervised learning methods on the MVSEC and DSEC-Flow datasets. Our project page is available at https://wynelio.github.io/E-NMSTFlow.","authors":["Zuntao Liu","Hao Zhuang","Junjie Jiang","Yuhang Song","Zheng Fang"],"url":"https://arxiv.org/abs/2505.05089"}
{"created":"2025-05-09","title":"Integrating Communication, Sensing, and Security: Progress and Prospects of PLS in ISAC Systems","abstract":"The sixth generation of wireless networks defined several key performance indicators (KPIs) for assessing its networks, mainly in terms of reliability, coverage, and sensing. In this regard, remarkable attention has been paid recently to the integrated sensing and communication (ISAC) paradigm as an enabler for efficiently and jointly performing communication and sensing using the same spectrum and hardware resources. On the other hand, ensuring communication and data security has been an imperative requirement for wireless networks throughout their evolution. The physical-layer security (PLS) concept paved the way to catering to the security needs in wireless networks in a sustainable way while guaranteeing theoretically secure transmissions, independently of the computational capacity of adversaries. Therefore, it is of paramount importance to consider a balanced trade-off between communication reliability, sensing, and security in future networks, such as the 5G and beyond, and the 6G. In this paper, we provide a comprehensive and system-wise review of designed secure ISAC systems from a PLS point of view. In particular, the impact of various physical-layer techniques, schemes, and wireless technologies to ensure the sensing-security trade-off is studied from the surveyed work. Furthermore, the amalgamation of PLS and ISAC is analyzed in a broader impact by considering attacks targeting data confidentiality, communication covertness, and sensing spoofing. The paper also serves as a tutorial by presenting several theoretical foundations on ISAC and PLS, which represent a practical guide for readers to develop novel secure ISAC network designs.","authors":["Waqas Aman","El-Mehdi Illi","Marwa Qaraqe","Saif Al-Kuwari"],"url":"https://arxiv.org/abs/2505.05090"}
{"created":"2025-05-09","title":"DispBench: Benchmarking Disparity Estimation to Synthetic Corruptions","abstract":"Deep learning (DL) has surpassed human performance on standard benchmarks, driving its widespread adoption in computer vision tasks. One such task is disparity estimation, estimating the disparity between matching pixels in stereo image pairs, which is crucial for safety-critical applications like medical surgeries and autonomous navigation. However, DL-based disparity estimation methods are highly susceptible to distribution shifts and adversarial attacks, raising concerns about their reliability and generalization. Despite these concerns, a standardized benchmark for evaluating the robustness of disparity estimation methods remains absent, hindering progress in the field.","authors":["Shashank Agnihotri","Amaan Ansari","Annika Dackermann","Fabian R\\\"osch","Margret Keuper"],"url":"https://arxiv.org/abs/2505.05091"}
{"created":"2025-05-09","title":"A Conjoint Graph Representation Learning Framework for Hypertension Comorbidity Risk Prediction","abstract":"The comorbidities of hypertension impose a heavy burden on patients and society. Early identification is necessary to prompt intervention, but it remains a challenging task. This study aims to address this challenge by combining joint graph learning with network analysis. Motivated by this discovery, we develop a Conjoint Graph Representation Learning (CGRL) framework that: a) constructs two networks based on disease coding, including the patient network and the disease difference network. Three comorbidity network features were generated based on the basic difference network to capture the potential relationship between comorbidities and risk diseases; b) incorporates computational structure intervention and learning feature representation, CGRL was developed to predict the risks of diabetes and coronary heart disease in patients; and c) analysis the comorbidity patterns and exploring the pathways of disease progression, the pathological pathogenesis of diabetes and coronary heart disease may be revealed. The results show that the network features extracted based on the difference network are important, and the framework we proposed provides more accurate predictions than other strong models in terms of accuracy.","authors":["Leming Zhou","Zuo Wang","Zhixuan Duan"],"url":"https://arxiv.org/abs/2505.05094"}
{"created":"2025-05-09","title":"X-Driver: Explainable Autonomous Driving with Vision-Language Models","abstract":"End-to-end autonomous driving has advanced significantly, offering benefits such as system simplicity and stronger driving performance in both open-loop and closed-loop settings than conventional pipelines. However, existing frameworks still suffer from low success rates in closed-loop evaluations, highlighting their limitations in real-world deployment. In this paper, we introduce X-Driver, a unified multi-modal large language models(MLLMs) framework designed for closed-loop autonomous driving, leveraging Chain-of-Thought(CoT) and autoregressive modeling to enhance perception and decision-making. We validate X-Driver across multiple autonomous driving tasks using public benchmarks in CARLA simulation environment, including Bench2Drive[6]. Our experimental results demonstrate superior closed-loop performance, surpassing the current state-of-the-art(SOTA) while improving the interpretability of driving decisions. These findings underscore the importance of structured reasoning in end-to-end driving and establish X-Driver as a strong baseline for future research in closed-loop autonomous driving.","authors":["Wei Liu","Jiyuan Zhang","Binxiong Zheng","Yufeng Hu","Yingzhan Lin","Zengfeng Zeng"],"url":"https://arxiv.org/abs/2505.05098"}
{"created":"2025-05-09","title":"Balancing Client Participation in Federated Learning Using AoI","abstract":"Federated Learning (FL) offers a decentralized framework that preserves data privacy while enabling collaborative model training across distributed clients. However, FL faces significant challenges due to limited communication resources, statistical heterogeneity, and the need for balanced client participation. This paper proposes an Age of Information (AoI)-based client selection policy that addresses these challenges by minimizing load imbalance through controlled selection intervals. Our method employs a decentralized Markov scheduling policy, allowing clients to independently manage participation based on age-dependent selection probabilities, which balances client updates across training rounds with minimal central oversight. We provide a convergence proof for our method, demonstrating that it ensures stable and efficient model convergence. Specifically, we derive optimal parameters for the Markov selection model to achieve balanced and consistent client participation, highlighting the benefits of AoI in enhancing convergence stability. Through extensive simulations, we demonstrate that our AoI-based method, particularly the optimal Markov variant, improves convergence over the FedAvg selection approach across both IID and non-IID data settings by $7.5\\%$ and up to $20\\%$. Our findings underscore the effectiveness of AoI-based scheduling for scalable, fair, and efficient FL systems across diverse learning environments.","authors":["Alireza Javani","Zhiying Wang"],"url":"https://arxiv.org/abs/2505.05099"}
{"created":"2025-05-09","title":"SoK: A Taxonomy for Distributed-Ledger-Based Identity Management","abstract":"The intersection of blockchain (distributed ledger) and identity management lacks a comprehensive framework for classifying distributed-ledger-based identity solutions. This paper introduces a methodologically developed taxonomy derived from the analysis of 390 scientific papers and expert discussions.","authors":["Awid Vaziry","Sandro Rodriguez Garzon","Patrick Herbke","Carlo Segat","Axel Kupper"],"url":"https://arxiv.org/abs/2505.05100"}
{"created":"2025-05-09","title":"MDE-Edit: Masked Dual-Editing for Multi-Object Image Editing via Diffusion Models","abstract":"Multi-object editing aims to modify multiple objects or regions in complex scenes while preserving structural coherence. This task faces significant challenges in scenarios involving overlapping or interacting objects: (1) Inaccurate localization of target objects due to attention misalignment, leading to incomplete or misplaced edits; (2) Attribute-object mismatch, where color or texture changes fail to align with intended regions due to cross-attention leakage, creating semantic conflicts (\\textit{e.g.}, color bleeding into non-target areas). Existing methods struggle with these challenges: approaches relying on global cross-attention mechanisms suffer from attention dilution and spatial interference between objects, while mask-based methods fail to bind attributes to geometrically accurate regions due to feature entanglement in multi-object scenarios. To address these limitations, we propose a training-free, inference-stage optimization approach that enables precise localized image manipulation in complex multi-object scenes, named MDE-Edit. MDE-Edit optimizes the noise latent feature in diffusion models via two key losses: Object Alignment Loss (OAL) aligns multi-layer cross-attention with segmentation masks for precise object positioning, and Color Consistency Loss (CCL) amplifies target attribute attention within masks while suppressing leakage to adjacent regions. This dual-loss design ensures localized and coherent multi-object edits. Extensive experiments demonstrate that MDE-Edit outperforms state-of-the-art methods in editing accuracy and visual quality, offering a robust solution for complex multi-object image manipulation tasks.","authors":["Hongyang Zhu","Haipeng Liu","Bo Fu","Yang Wang"],"url":"https://arxiv.org/abs/2505.05101"}
{"created":"2025-05-09","title":"A Weighted Byzantine Fault Tolerance Consensus Driven Trusted Multiple Large Language Models Network","abstract":"Large Language Models (LLMs) have achieved remarkable success across a wide range of applications. However, individual LLMs often produce inconsistent, biased, or hallucinated outputs due to limitations in their training corpora and model architectures. Recently, collaborative frameworks such as the Multi-LLM Network (MultiLLMN) have been introduced, enabling multiple LLMs to interact and jointly respond to user queries. Nevertheless, MultiLLMN architectures raise critical concerns regarding the reliability and security of the generated content, particularly in open environments where malicious or compromised LLMs may be present. Moreover, reliance on centralized coordination undermines system efficiency and introduces single points of failure. In this paper, we propose a novel Trusted MultiLLMN framework, driven by a Weighted Byzantine Fault Tolerance (WBFT) blockchain consensus mechanism, to ensure the reliability, security, and efficiency of multi-LLM collaboration. In WBFT, voting weights are adaptively assigned to each LLM based on its response quality and trustworthiness, incentivizing reliable behavior, and reducing the impact of malicious nodes. Extensive simulations demonstrate that WBFT significantly improves both consensus security and efficiency compared to classical and modern consensus mechanisms, particularly under wireless network conditions. Furthermore, our evaluations reveal that Trusted MultiLLMN supported by WBFT can deliver higher-quality and more credible responses than both single LLMs and conventional MultiLLMNs, thereby providing a promising path toward building robust, decentralized AI collaboration networks.","authors":["Haoxiang Luo","Gang Sun","Yinqiu Liu","Dongcheng Zhao","Dusit Niyato","Hongfang Yu","Schahram Dustdar"],"url":"https://arxiv.org/abs/2505.05103"}
{"created":"2025-05-09","title":"Multigrid methods for the ghost finite element approximation of elliptic problems","abstract":"We present multigrid methods for solving elliptic partial differential equations on arbitrary domains using the nodal ghost finite element method, an unfitted boundary approach where the domain is implicitly defined by a level-set function. This method achieves second-order accuracy and offers substantial computational advantages over both direct solvers and finite-difference-based multigrid methods. A key strength of the ghost finite element framework is its variational formulation, which naturally enables consistent transfer operators and avoids residual splitting across grid levels. We provide a detailed construction of the multigrid components in both one and two spatial dimensions, including smoothers, transfer operators, and coarse grid operators. The choice of the stabilization parameter plays a crucial role in ensuring well-posedness and optimal convergence of the multigrid method. We derive explicit algebraic expressions for this parameter based on the geometry of cut cells. In the two-dimensional setting, we further improve efficiency by performing additional smoothing exclusively on cut cells, reducing computational cost without compromising convergence. Numerical results validate the proposed method across a range of geometries and confirm its robustness and scalability.","authors":["Hridya Dilip","Armando Coco"],"url":"https://arxiv.org/abs/2505.05105"}
{"created":"2025-05-09","title":"A Neuro-Symbolic Framework for Sequence Classification with Relational and Temporal Knowledge","abstract":"One of the goals of neuro-symbolic artificial intelligence is to exploit background knowledge to improve the performance of learning tasks. However, most of the existing frameworks focus on the simplified scenario where knowledge does not change over time and does not cover the temporal dimension. In this work we consider the much more challenging problem of knowledge-driven sequence classification where different portions of knowledge must be employed at different timesteps, and temporal relations are available. Our experimental evaluation compares multi-stage neuro-symbolic and neural-only architectures, and it is conducted on a newly-introduced benchmarking framework. Results demonstrate the challenging nature of this novel setting, and also highlight under-explored shortcomings of neuro-symbolic methods, representing a precious reference for future research.","authors":["Luca Salvatore Lorello","Marco Lippi","Stefano Melacci"],"url":"https://arxiv.org/abs/2505.05106"}
{"created":"2025-05-09","title":"Multi-agent Embodied AI: Advances and Future Directions","abstract":"Embodied artificial intelligence (Embodied AI) plays a pivotal role in the application of advanced technologies in the intelligent era, where AI systems are integrated with physical bodies that enable them to perceive, reason, and interact with their environments. Through the use of sensors for input and actuators for action, these systems can learn and adapt based on real-world feedback, allowing them to perform tasks effectively in dynamic and unpredictable environments. As techniques such as deep learning (DL), reinforcement learning (RL), and large language models (LLMs) mature, embodied AI has become a leading field in both academia and industry, with applications spanning robotics, healthcare, transportation, and manufacturing. However, most research has focused on single-agent systems that often assume static, closed environments, whereas real-world embodied AI must navigate far more complex scenarios. In such settings, agents must not only interact with their surroundings but also collaborate with other agents, necessitating sophisticated mechanisms for adaptation, real-time learning, and collaborative problem-solving. Despite increasing interest in multi-agent systems, existing research remains narrow in scope, often relying on simplified models that fail to capture the full complexity of dynamic, open environments for multi-agent embodied AI. Moreover, no comprehensive survey has systematically reviewed the advancements in this area. As embodied AI rapidly evolves, it is crucial to deepen our understanding of multi-agent embodied AI to address the challenges presented by real-world applications. To fill this gap and foster further development in the field, this paper reviews the current state of research, analyzes key contributions, and identifies challenges and future directions, providing insights to guide innovation and progress in this field.","authors":["Zhaohan Feng","Ruiqi Xue","Lei Yuan","Yang Yu","Ning Ding","Meiqin Liu","Bingzhao Gao","Jian Sun","Gang Wang"],"url":"https://arxiv.org/abs/2505.05108"}
{"created":"2025-05-09","title":"p-complete square-free Word-representation of Word-representable Graphs","abstract":"A graph $G = (V,E)$ is word-representable, if there exists a word $w$ over the alphabet $V$ such that for letters ${x,y} \\in V$ , $x$ and $y$ alternate in $w$ if and only if $xy$ is an edge in the graph $G$. In this paper, we introduce the concept of $p$-complete square-free word-representable graph $G(V,E)$. A word $w$ defined over alphabet $V$ is called $p$-complete square-free word if there does not exist any subset $S\\subseteq \\Sigma$ such that the word $w_{S}$ contains a square $XX$ where $|X| \\ge p$ and $1\\le p \\le |w|/2$. A word-representable graph is considered $p$-complete square-free word-representable if there exists a $p$-complete square-free word-representant of that graph. This pattern is significant as it proves the existence of patterns that do not depend on graph labelling and cannot be avoided by certain classes of word-representable graphs. The class of word-representable graphs includes both $p$-complete square-free word-representable graphs and non-$p$-complete square-free word-representable graphs. Additionally, this concept generalises the square pattern found in the words. A word-representable graph is $p$-complete square-free uniform word-representable if its $p$-complete square-free word-representant is a uniform word. We analyse the properties of $p$-complete square-free uniform words and find that the graphs represented by these words avoid having $K_p$ (the complete graph on $p$ vertices) as an induced subgraph. We provide classifications for small values of $p$: for $p=1$, only complete graphs and for $p=2$, only complete and edgeless graphs satisfy the condition. We find that $K_3$-free circle graphs are 3-complete square-free uniform word-representable. Furthermore, we establish that only graphs with representation number at most 3 can be 3-complete square-free uniform word-representable and provide a constructive method to generate such graphs.","authors":["Biswajit Das","Ramesh Hariharasubramanian"],"url":"https://arxiv.org/abs/2505.05110"}
{"created":"2025-05-09","title":"Unveiling Language-Specific Features in Large Language Models via Sparse Autoencoders","abstract":"The mechanisms behind multilingual capabilities in Large Language Models (LLMs) have been examined using neuron-based or internal-activation-based methods. However, these methods often face challenges such as superposition and layer-wise activation variance, which limit their reliability. Sparse Autoencoders (SAEs) offer a more nuanced analysis by decomposing the activations of LLMs into sparse linear combination of SAE features. We introduce a novel metric to assess the monolinguality of features obtained from SAEs, discovering that some features are strongly related to specific languages. Additionally, we show that ablating these SAE features only significantly reduces abilities in one language of LLMs, leaving others almost unaffected. Interestingly, we find some languages have multiple synergistic SAE features, and ablating them together yields greater improvement than ablating individually. Moreover, we leverage these SAE-derived language-specific features to enhance steering vectors, achieving control over the language generated by LLMs.","authors":["Boyi Deng","Yu Wan","Yidan Zhang","Baosong Yang","Fuli Feng"],"url":"https://arxiv.org/abs/2505.05111"}
{"created":"2025-05-09","title":"Is there a half-life for the success rates of AI agents?","abstract":"Building on the recent empirical work of Kwa et al. (2025), I show that within their suite of research-engineering tasks the performance of AI agents on longer-duration tasks can be explained by an extremely simple mathematical model -- a constant rate of failing during each minute a human would take to do the task. This implies an exponentially declining success rate with the length of the task and that each agent could be characterised by its own half-life. This empirical regularity allows us to estimate the success rate for an agent at different task lengths. And the fact that this model is a good fit for the data is suggestive of the underlying causes of failure on longer tasks -- that they involve increasingly large sets of subtasks where failing any one fails the task. Whether this model applies more generally on other suites of tasks is unknown and an important subject for further work.","authors":["Toby Ord"],"url":"https://arxiv.org/abs/2505.05115"}
{"created":"2025-05-09","title":"Enhancing Text2Cypher with Schema Filtering","abstract":"Knowledge graphs represent complex data using nodes, relationships, and properties. Cypher, a powerful query language for graph databases, enables efficient modeling and querying. Recent advancements in large language models allow translation of natural language questions into Cypher queries - Text2Cypher. A common approach is incorporating database schema into prompts. However, complex schemas can introduce noise, increase hallucinations, and raise computational costs. Schema filtering addresses these challenges by including only relevant schema elements, improving query generation while reducing token costs. This work explores various schema filtering methods for Text2Cypher task and analyzes their impact on token length, performance, and cost. Results show that schema filtering effectively optimizes Text2Cypher, especially for smaller models. Consistent with prior research, we find that larger models benefit less from schema filtering due to their longer context capabilities. However, schema filtering remains valuable for both larger and smaller models in cost reduction.","authors":["Makbule Gulcin Ozsoy"],"url":"https://arxiv.org/abs/2505.05118"}
{"created":"2025-05-09","title":"USPR: Learning a Unified Solver for Profiled Routing","abstract":"The Profiled Vehicle Routing Problem (PVRP) extends the classical VRP by incorporating vehicle-client-specific preferences and constraints, reflecting real-world requirements such as zone restrictions and service-level preferences. While recent reinforcement learning (RL) solvers have shown promise, they require retraining for each new profile distribution, suffer from poor representation ability, and struggle to generalize to out-of-distribution instances. In this paper, we address these limitations by introducing USPR (Unified Solver for Profiled Routing), a novel framework that natively handles arbitrary profile types. USPR introduces three key innovations: (i) Profile Embeddings (PE) to encode any combination of profile types; (ii) Multi-Head Profiled Attention (MHPA), an attention mechanism that models rich interactions between vehicles and clients; (iii) Profile-aware Score Reshaping (PSR), which dynamically adjusts decoder logits using profile scores to improve generalization. Empirical results on diverse PVRP benchmarks demonstrate that USPR achieves state-of-the-art results among learning-based methods while offering significant gains in flexibility and computational efficiency. We make our source code publicly available to foster future research at https://github.com/ai4co/uspr.","authors":["Chuanbo Hua","Federico Berto","Zhikai Zhao","Jiwoo Son","Changhyun Kwon","Jinkyoo Park"],"url":"https://arxiv.org/abs/2505.05119"}
{"created":"2025-05-09","title":"Text2Cypher: Data Pruning using Hard Example Selection","abstract":"Database query languages such as SQL for relational databases and Cypher for graph databases have been widely adopted. Recent advancements in large language models (LLMs) enable natural language interactions with databases through models like Text2SQL and Text2Cypher. Fine-tuning these models typically requires large, diverse datasets containing non-trivial examples. However, as dataset size increases, the cost of fine-tuning also rises. This makes smaller, high-quality datasets essential for reducing costs for the same or better performance. In this paper, we propose five hard-example selection techniques for pruning the Text2Cypher dataset, aiming to preserve or improve performance while reducing resource usage. Our results show that these hard-example selection approaches can halve training time and costs with minimal impact on performance, and demonstrates that hard-example selection provides a cost-effective solution.","authors":["Makbule Gulcin Ozsoy"],"url":"https://arxiv.org/abs/2505.05122"}
{"created":"2025-05-09","title":"Taming OOD Actions for Offline Reinforcement Learning: An Advantage-Based Approach","abstract":"Offline reinforcement learning (RL) aims to learn decision-making policies from fixed datasets without online interactions, providing a practical solution where online data collection is expensive or risky. However, offline RL often suffers from distribution shift, resulting in inaccurate evaluation and substantial overestimation on out-of-distribution (OOD) actions. To address this, existing approaches incorporate conservatism by indiscriminately discouraging all OOD actions, thereby hindering the agent's ability to generalize and exploit beneficial ones. In this paper, we propose Advantage-based Diffusion Actor-Critic (ADAC), a novel method that systematically evaluates OOD actions using the batch-optimal value function. Based on this evaluation, ADAC defines an advantage function to modulate the Q-function update, enabling more precise assessment of OOD action quality. We design a custom PointMaze environment and collect datasets to visually reveal that advantage modulation can effectively identify and select superior OOD actions. Extensive experiments show that ADAC achieves state-of-the-art performance on almost all tasks in the D4RL benchmark, with particularly clear margins on the more challenging tasks.","authors":["Xuyang Chen","Keyu Yan","Lin Zhao"],"url":"https://arxiv.org/abs/2505.05126"}
{"created":"2025-05-09","title":"Constraints Preserving Lax-Wendroff Flux Reconstruction for Relativistic Hydrodynamics with General Equations of State","abstract":"In the realm of relativistic astrophysics, the ideal equation of state with a constant adiabatic index provides a poor approximation due to its inconsistency with relativistic kinetic theory. However, it is a common practice to use it for relativistic fluid flow equations due to its simplicity. Here we develop a high-order Lax-Wendroff flux reconstruction method on Cartesian grids for solving special relativistic hydrodynamics equations with several general equations of state available in the literature. We also study the conversion from conservative to primitive variables, which depends on the equation of state in use, and provide an alternative method of conversion when the existing approach does not succeed. For the admissibility of the solution, we blend the high-order method with a low-order method on sub-cells and prove its physical admissible property in the case of all the equations of state used here. Lastly, we validate the scheme by several test cases having strong discontinuities, large Lorentz factor, and low density or pressure in one and two dimensions.","authors":["Sujoy Basak","Arpit Babbar","Harish Kumar","Praveen Chandrashekar"],"url":"https://arxiv.org/abs/2505.05128"}
{"created":"2025-05-09","title":"CacheFL: Efficient Federated Cache Model Fine-Tuning for Vision-Language Models","abstract":"Large pre-trained Vision-Language Models (VLMs), such as Contrastive Language-Image Pre-training (CLIP), have exhibited remarkable zero-shot performance across various image classification tasks. Fine-tuning these models on domain-specific datasets further enhances their effectiveness for downstream applications. However, fine-tuning in cloud environments raises significant concerns regarding data security and privacy. Federated Learning (FL) offers a decentralized solution by enabling model training across local clients without centralizing sensitive data, but the high communication and computation costs of transmitting full pre-trained models during training limit its scalability. Additionally, non-Independent and Identically Distributed (non-IID) data across local clients can negatively impact model convergence and performance. To address these challenges, we propose CacheFL, a novel federated learning method that replaces traditional full model fine-tuning with lightweight cache model fine-tuning. The cache model is initialized using a class-balanced dataset generated by a generative pre-trained model, effectively mitigating the impact of non-IID data. This cache model is then distributed to local clients for fine-tuning, and the updated parameters from each client are aggregated on the server and redistributed. With the updated cache model, the classification performance of CLIP is improved after just a few epochs. By limiting the training and communication to the cache model, CacheFL significantly reduces resource demands while ensuring data privacy and security. Extensive experiments conducted on ImageNet and 10 additional datasets demonstrate that CacheFL outperforms traditional approaches in terms of classification accuracy, resource efficiency, and privacy preservation.","authors":["Mengjun Yi","Hanwen Zhang","Hui Dou","Jian Zhao","Furao Shen"],"url":"https://arxiv.org/abs/2505.05130"}
{"created":"2025-05-09","title":"An Active Contour Model for Silhouette Vectorization using B\\'ezier Curves","abstract":"In this paper, we propose an active contour model for silhouette vectorization using cubic B\\'ezier curves. Among the end points of the B\\'ezier curves, we distinguish between corner and regular points where the orientation of the tangent vector is prescribed. By minimizing the distance of the B\\'ezier curves to the silhouette boundary, the active contour model optimizes the location of the B\\'ezier curves end points, the orientation of the tangent vectors in the regular points, and the estimation of the B\\'ezier curve parameters. This active contour model can use the silhouette vectorization obtained by any method as an initial guess. The proposed method significantly reduces the average distance between the silhouette boundary and its vectorization obtained by the world-class graphic software Inkscape, Adobe Illustrator, and a curvature-based vectorization method, which we introduce for comparison. Our method also allows us to impose additional regularity on the B\\'ezier curves by reducing their lengths.","authors":["Luis Alvarez","Jean-Michel Morel"],"url":"https://arxiv.org/abs/2505.05132"}
{"created":"2025-05-09","title":"Matrices over a Hilbert space and their low-rank approximation","abstract":"Matrices are typically considered over fields or rings. Motivated by applications in parametric differential equations and data-driven modeling, we suggest to study matrices with entries from a Hilbert space and present an elementary theory of them: from basic properties to low-rank approximation. Specifically, we extend the idea of cross approximation to such matrices and propose an analogue of the adaptive cross approximation algorithm. Our numerical experiments show that this approach can achieve quasioptimal approximation and be integrated with the existing computational software for partial differential equations.","authors":["Stanislav Budzinskiy"],"url":"https://arxiv.org/abs/2505.05134"}
{"created":"2025-05-09","title":"Automated vision-based assistance tools in bronchoscopy: stenosis severity estimation","abstract":"Purpose: Subglottic stenosis refers to the narrowing of the subglottis, the airway between the vocal cords and the trachea. Its severity is typically evaluated by estimating the percentage of obstructed airway. This estimation can be obtained from CT data or through visual inspection by experts exploring the region. However, visual inspections are inherently subjective, leading to less consistent and robust diagnoses. No public methods or datasets are currently available for automated evaluation of this condition from bronchoscopy video.","authors":["Clara Tomasini","Javier Rodriguez-Puigvert","Dinora Polanco","Manuel Vi\\~nuales","Luis Riazuelo","Ana Cristina Murillo"],"url":"https://arxiv.org/abs/2505.05136"}
{"created":"2025-05-09","title":"Research on Anomaly Detection Methods Based on Diffusion Models","abstract":"Anomaly detection is a fundamental task in machine learning and data mining, with significant applications in cybersecurity, industrial fault diagnosis, and clinical disease monitoring. Traditional methods, such as statistical modeling and machine learning-based approaches, often face challenges in handling complex, high-dimensional data distributions. In this study, we explore the potential of diffusion models for anomaly detection, proposing a novel framework that leverages the strengths of diffusion probabilistic models (DPMs) to effectively identify anomalies in both image and audio data. The proposed method models the distribution of normal data through a diffusion process and reconstructs input data via reverse diffusion, using a combination of reconstruction errors and semantic discrepancies as anomaly indicators. To enhance the framework's performance, we introduce multi-scale feature extraction, attention mechanisms, and wavelet-domain representations, enabling the model to capture fine-grained structures and global dependencies in the data. Extensive experiments on benchmark datasets, including MVTec AD and UrbanSound8K, demonstrate that our method outperforms state-of-the-art anomaly detection techniques, achieving superior accuracy and robustness across diverse data modalities. This research highlights the effectiveness of diffusion models in anomaly detection and provides a robust and efficient solution for real-world applications.","authors":["Yi Chen"],"url":"https://arxiv.org/abs/2505.05137"}
{"created":"2025-05-09","title":"Guiding Evolutionary AutoEncoder Training with Activation-Based Pruning Operators","abstract":"This study explores a novel approach to neural network pruning using evolutionary computation, focusing on simultaneously pruning the encoder and decoder of an autoencoder. We introduce two new mutation operators that use layer activations to guide weight pruning. Our findings reveal that one of these activation-informed operators outperforms random pruning, resulting in more efficient autoencoders with comparable performance to canonically trained models. Prior work has established that autoencoder training is effective and scalable with a spatial coevolutionary algorithm that cooperatively coevolves a population of encoders with a population of decoders, rather than one autoencoder. We evaluate how the same activity-guided mutation operators transfer to this context. We find that random pruning is better than guided pruning, in the coevolutionary setting. This suggests activation-based guidance proves more effective in low-dimensional pruning environments, where constrained sample spaces can lead to deviations from true uniformity in randomization. Conversely, population-driven strategies enhance robustness by expanding the total pruning dimensionality, achieving statistically uniform randomness that better preserves system dynamics. We experiment with pruning according to different schedules and present best combinations of operator and schedule for the canonical and coevolving populations cases.","authors":["Steven Jorgensen","Erik Hemberg","Jamal Toutouh","Una-May O'Reilly"],"url":"https://arxiv.org/abs/2505.05138"}
{"created":"2025-05-09","title":"Spatially Disaggregated Energy Consumption and Emissions in End-use Sectors for Germany and Spain","abstract":"High-resolution energy consumption and emissions datasets are essential for localized policy-making, resource optimization, and climate action planning. They enable municipalities to monitor mitigation strategies and foster engagement among governments, businesses, and communities. However, smaller municipalities often face data limitations that hinder tailored climate strategies. This study generates detailed final energy consumption and emissions data at the local administrative level for Germany and Spain. Using national datasets, we apply spatial disaggregation techniques with open data sources. A key innovation is the application of XGBoost for imputing missing data, combined with a stepwise spatial disaggregation process incorporating district- and province-level statistics. Prioritizing reproducibility, our open-data approach provides a scalable framework for municipalities to develop actionable climate plans. To ensure transparency, we assess the reliability of imputed values and assign confidence ratings to the disaggregated data.","authors":["Shruthi Patil","Noah Pflugradt","Jann M. Weinand","J\\\"urgen Kropp","Detlef Stolten"],"url":"https://arxiv.org/abs/2505.05139"}
{"created":"2025-05-09","title":"Sparse Training from Random Initialization: Aligning Lottery Ticket Masks using Weight Symmetry","abstract":"The Lottery Ticket Hypothesis (LTH) suggests there exists a sparse LTH mask and weights that achieve the same generalization performance as the dense model while using significantly fewer parameters. However, finding a LTH solution is computationally expensive, and a LTH sparsity mask does not generalize to other random weight initializations. Recent work has suggested that neural networks trained from random initialization find solutions within the same basin modulo permutation, and proposes a method to align trained models within the same loss basin. We hypothesize that misalignment of basins is the reason why LTH masks do not generalize to new random initializations and propose permuting the LTH mask to align with the new optimization basin when performing sparse training from a different random init. We empirically show a significant increase in generalization when sparse training from random initialization with the permuted mask as compared to using the non-permuted LTH mask, on multiple datasets (CIFAR-10, CIFAR-100 and ImageNet) and models (VGG11, ResNet20 and ResNet50).","authors":["Mohammed Adnan","Rohan Jain","Ekansh Sharma","Rahul Krishnan","Yani Ioannou"],"url":"https://arxiv.org/abs/2505.05143"}
{"created":"2025-05-09","title":"Understanding In-context Learning of Addition via Activation Subspaces","abstract":"To perform in-context learning, language models must extract signals from individual few-shot examples, aggregate these into a learned prediction rule, and then apply this rule to new examples. How is this implemented in the forward pass of modern transformer models? To study this, we consider a structured family of few-shot learning tasks for which the true prediction rule is to add an integer $k$ to the input. We find that Llama-3-8B attains high accuracy on this task for a range of $k$, and localize its few-shot ability to just three attention heads via a novel optimization approach. We further show the extracted signals lie in a six-dimensional subspace, where four of the dimensions track the unit digit and the other two dimensions track overall magnitude. We finally examine how these heads extract information from individual few-shot examples, identifying a self-correction mechanism in which mistakes from earlier examples are suppressed by later examples. Our results demonstrate how tracking low-dimensional subspaces across a forward pass can provide insight into fine-grained computational structures.","authors":["Xinyan Hu","Kayo Yin","Michael I. Jordan","Jacob Steinhardt","Lijie Chen"],"url":"https://arxiv.org/abs/2505.05145"}
{"created":"2025-05-09","title":"A Benchmark Dataset and a Framework for Urdu Multimodal Named Entity Recognition","abstract":"The emergence of multimodal content, particularly text and images on social media, has positioned Multimodal Named Entity Recognition (MNER) as an increasingly important area of research within Natural Language Processing. Despite progress in high-resource languages such as English, MNER remains underexplored for low-resource languages like Urdu. The primary challenges include the scarcity of annotated multimodal datasets and the lack of standardized baselines. To address these challenges, we introduce the U-MNER framework and release the Twitter2015-Urdu dataset, a pioneering resource for Urdu MNER. Adapted from the widely used Twitter2015 dataset, it is annotated with Urdu-specific grammar rules. We establish benchmark baselines by evaluating both text-based and multimodal models on this dataset, providing comparative analyses to support future research on Urdu MNER. The U-MNER framework integrates textual and visual context using Urdu-BERT for text embeddings and ResNet for visual feature extraction, with a Cross-Modal Fusion Module to align and fuse information. Our model achieves state-of-the-art performance on the Twitter2015-Urdu dataset, laying the groundwork for further MNER research in low-resource languages.","authors":["Hussain Ahmad","Qingyang Zeng","Jing Wan"],"url":"https://arxiv.org/abs/2505.05148"}
{"created":"2025-05-09","title":"Temporal Spectrum Analysis for Multi-Constellation Space Domain Awareness","abstract":"Space Domain Awareness (SDA) system has different major aspects including continues and robust awareness from the network that is crucial for an efficient control over all actors in space. The observability of the space assets on the other hand requires efficient analysis on when and how observed space objects can be controlled. This becomes crucial when real-world spatial dynamics are taken into account as it introduces complexities into the system. The real-world dynamics can reveal the structure of the network including isolated and dominant stations. We propose a Temporal Spectrum Analysis (TSA) scheme that takes into account a set of real-world parameters including actual dynamics of the objects in space to analyze the structure of a ground-space network that inherits temporal spectrum as the key element of design. We study the potential interactions between multiple constellations using TSA and conduct a comprehensive real-world simulations to quantify the structure of the network. Numerical results show how the temporal spectrum of each satellite affects the intra- and inter-constellation network structure including interactions between ground stations and constellations.","authors":["Mansour Naslcheraghi","Gunes Karabulut-Kurt"],"url":"https://arxiv.org/abs/2505.05149"}
{"created":"2025-05-09","title":"Day-Ahead Bidding Strategies for Wind Farm Operators under a One-Price Balancing Scheme","abstract":"We study day-ahead bidding strategies for wind farm operators under a one-price balancing scheme, prevalent in European electricity markets. In this setting, the profit-maximising strategy becomes an all-or-nothing strategy, aiming to take advantage of open positions in the balancing market. However, balancing prices are difficult, if not impossible, to forecast in the day-ahead stage and large open positions can affect the balancing price by changing the direction of the system imbalance. This paper addresses day-ahead bidding as a decision-making problem under uncertainty, with the objective of maximising the expected profit while reducing the imbalance risk related to the strategy. To this end, we develop a stochastic optimisation problem with explicit constraints on the positions in the balancing market, providing risk certificates, and derive an analytical solution to this problem. Moreover, we show how the price-impact of the trading strategy on the balancing market can be included in the ex-post evaluation. Using real data from the Belgian electricity market and an offshore wind farm in the North Sea, we demonstrate that the all-or-nothing strategy negatively impacts the balancing price, resulting in long-term losses for the wind farm. Our risk-constrained strategy, however, can still significantly enhance operational profit compared to traditional point-forecast bidding.","authors":["Max Bruninx","Timothy Verstraeten","Jalal Kazempour","Jan Helsen"],"url":"https://arxiv.org/abs/2505.05153"}
{"created":"2025-05-09","title":"FedTDP: A Privacy-Preserving and Unified Framework for Trajectory Data Preparation via Federated Learning","abstract":"Trajectory data, which capture the movement patterns of people and vehicles over time and space, are crucial for applications like traffic optimization and urban planning. However, issues such as noise and incompleteness often compromise data quality, leading to inaccurate trajectory analyses and limiting the potential of these applications. While Trajectory Data Preparation (TDP) can enhance data quality, existing methods suffer from two key limitations: (i) they do not address data privacy concerns, particularly in federated settings where trajectory data sharing is prohibited, and (ii) they typically design task-specific models that lack generalizability across diverse TDP scenarios. To overcome these challenges, we propose FedTDP, a privacy-preserving and unified framework that leverages the capabilities of Large Language Models (LLMs) for TDP in federated environments. Specifically, we: (i) design a trajectory privacy autoencoder to secure data transmission and protect privacy, (ii) introduce a trajectory knowledge enhancer to improve model learning of TDP-related knowledge, enabling the development of TDP-oriented LLMs, and (iii) propose federated parallel optimization to enhance training efficiency by reducing data transmission and enabling parallel model training. Experiments on 6 real datasets and 10 mainstream TDP tasks demonstrate that FedTDP consistently outperforms 13 state-of-the-art baselines.","authors":["Zhihao Zeng","Ziquan Fang","Wei Shao","Lu Chen","Yunjun Gao"],"url":"https://arxiv.org/abs/2505.05155"}
{"created":"2025-05-09","title":"Online Velocity Profile Generation and Tracking for Sampling-Based Local Planning Algorithms in Autonomous Racing Environments","abstract":"This work presents an online velocity planner for autonomous racing that adapts to changing dynamic constraints, such as grip variations from tire temperature changes and rubber accumulation. The method combines a forward-backward solver for online velocity optimization with a novel spatial sampling strategy for local trajectory planning, utilizing a three-dimensional track representation. The computed velocity profile serves as a reference for the local planner, ensuring adaptability to environmental and vehicle dynamics. We demonstrate the approach's robust performance and computational efficiency in racing scenarios and discuss its limitations, including sensitivity to deviations from the predefined racing line and high jerk characteristics of the velocity profile.","authors":["Alexander Langmann","Levent \\\"Ogretmen","Frederik Werner","Johannes Betz"],"url":"https://arxiv.org/abs/2505.05157"}
{"created":"2025-05-09","title":"Testing Message-Passing Concurrency","abstract":"A key computational question underpinning the automated testing and verification of concurrent programs is the \\emph{consistency question} -- \\emph{given a partial execution history, can it be completed in a consistent manner?} Due to its importance, consistency testing has been studied extensively for memory models, as well as for database isolation levels. A common theme in all these settings is the use of shared-memory as the primal mode of interthread communication. On the other hand, modern programming languages, such as Go, Rust and Kotlin, advocate a paradigm shift towards channel-based (i.e., message-passing) communication. However, the consistency question for channel-based concurrency is currently poorly understood.","authors":["Zheng Shi","Lasse M{\\O}ldrup","Umang Mathur","Andreas Pavlogiannis"],"url":"https://arxiv.org/abs/2505.05162"}
{"created":"2025-05-09","title":"Probabilistic Embeddings for Frozen Vision-Language Models: Uncertainty Quantification with Gaussian Process Latent Variable Models","abstract":"Vision-Language Models (VLMs) learn joint representations by mapping images and text into a shared latent space. However, recent research highlights that deterministic embeddings from standard VLMs often struggle to capture the uncertainties arising from the ambiguities in visual and textual descriptions and the multiple possible correspondences between images and texts. Existing approaches tackle this by learning probabilistic embeddings during VLM training, which demands large datasets and does not leverage the powerful representations already learned by large-scale VLMs like CLIP. In this paper, we propose GroVE, a post-hoc approach to obtaining probabilistic embeddings from frozen VLMs. GroVE builds on Gaussian Process Latent Variable Model (GPLVM) to learn a shared low-dimensional latent space where image and text inputs are mapped to a unified representation, optimized through single-modal embedding reconstruction and cross-modal alignment objectives. Once trained, the Gaussian Process model generates uncertainty-aware probabilistic embeddings. Evaluation shows that GroVE achieves state-of-the-art uncertainty calibration across multiple downstream tasks, including cross-modal retrieval, visual question answering, and active learning.","authors":["Aishwarya Venkataramanan","Paul Bodesheim","Joachim Denzler"],"url":"https://arxiv.org/abs/2505.05163"}
{"created":"2025-05-09","title":"Bandit Max-Min Fair Allocation","abstract":"In this paper, we study a new decision-making problem called the bandit max-min fair allocation (BMMFA) problem. The goal of this problem is to maximize the minimum utility among agents with additive valuations by repeatedly assigning indivisible goods to them. One key feature of this problem is that each agent's valuation for each item can only be observed through the semi-bandit feedback, while existing work supposes that the item values are provided at the beginning of each round. Another key feature is that the algorithm's reward function is not additive with respect to rounds, unlike most bandit-setting problems.","authors":["Tsubasa Harada","Shinji Ito","Hanna Sumita"],"url":"https://arxiv.org/abs/2505.05169"}
{"created":"2025-05-09","title":"Dukawalla: Voice Interfaces for Small Businesses in Africa","abstract":"Small and medium sized businesses often struggle with data driven decision making do to a lack of advanced analytics tools, especially in African countries where they make up a majority of the workforce. Though many tools exist they are not designed to fit into the ways of working of SMB workers who are mobile first, have limited time to learn new workflows, and for whom social and business are tightly coupled. To address this, the Dukawalla prototype was created. This intelligent assistant bridges the gap between raw business data, and actionable insights by leveraging voice interaction and the power of generative AI. Dukawalla provides an intuitive way for business owners to interact with their data, aiding in informed decision making. This paper examines Dukawalla's deployment across SMBs in Nairobi, focusing on their experiences using this voice based assistant to streamline data collection and provide business insights","authors":["Elizabeth Ankrah","Stephanie Nyairo","Mercy Muchai","Kagonya Awori","Millicent Ochieng","Mark Kariuki","Jacki O'Neill"],"url":"https://arxiv.org/abs/2505.05170"}
{"created":"2025-05-09","title":"MARK: Memory Augmented Refinement of Knowledge","abstract":"Large Language Models (LLMs) assist in specialized tasks but struggle to align with evolving domain knowledge without costly fine-tuning. Domain knowledge consists of: Knowledge: Immutable facts (e.g., 'A stone is solid') and generally accepted principles (e.g., ethical standards); Refined Memory: Evolving insights shaped by business needs and real-world changes. However, a significant gap often exists between a domain expert's deep, nuanced understanding and the system's domain knowledge, which can hinder accurate information retrieval and application. Our Memory-Augmented Refinement of Knowledge (MARK) framework enables LLMs to continuously learn without retraining by leveraging structured refined memory, inspired by the Society of Mind. MARK operates through specialized agents, each serving a distinct role: Residual Refined Memory Agent: Stores and retrieves domain-specific insights to maintain context over time; User Question Refined Memory Agent: Captures user-provided facts, abbreviations, and terminology for better comprehension; LLM Response Refined Memory Agent: Extracts key elements from responses for refinement and personalization. These agents analyse stored refined memory, detect patterns, resolve contradictions, and improve response accuracy. Temporal factors like recency and frequency prioritize relevant information while discarding outdated insights. MARK enhances LLMs in multiple ways: Ground Truth Strategy: Reduces hallucinations by establishing a structured reference; Domain-Specific Adaptation: Essential for fields like healthcare, law, and manufacturing, where proprietary insights are absent from public datasets; Personalized AI Assistants: Improves virtual assistants by remembering user preferences, ensuring coherent responses over time.","authors":["Anish Ganguli","Prabal Deb","Debleena Banerjee"],"url":"https://arxiv.org/abs/2505.05177"}
{"created":"2025-05-09","title":"OpenworldAUC: Towards Unified Evaluation and Optimization for Open-world Prompt Tuning","abstract":"Prompt tuning adapts Vision-Language Models like CLIP to open-world tasks with minimal training costs. In this direction, one typical paradigm evaluates model performance separately on known classes (i.e., base domain) and unseen classes (i.e., new domain). However, real-world scenarios require models to handle inputs without prior domain knowledge. This practical challenge has spurred the development of open-world prompt tuning, which demands a unified evaluation of two stages: 1) detecting whether an input belongs to the base or new domain (P1), and 2) classifying the sample into its correct class (P2). What's more, as domain distributions are generally unknown, a proper metric should be insensitive to varying base/new sample ratios (P3). However, we find that current metrics, including HM, overall accuracy, and AUROC, fail to satisfy these three properties simultaneously. To bridge this gap, we propose OpenworldAUC, a unified metric that jointly assesses detection and classification through pairwise instance comparisons. To optimize OpenworldAUC effectively, we introduce Gated Mixture-of-Prompts (GMoP), which employs domain-specific prompts and a gating mechanism to dynamically balance detection and classification. Theoretical guarantees ensure generalization of GMoP under practical conditions. Experiments on 15 benchmarks in open-world scenarios show GMoP achieves SOTA performance on OpenworldAUC and other metrics. We release the code at https://github.com/huacong/OpenworldAUC","authors":["Cong Hua","Qianqian Xu","Zhiyong Yang","Zitai Wang","Shilong Bao","Qingming Huang"],"url":"https://arxiv.org/abs/2505.05180"}
{"created":"2025-05-09","title":"Stochastic Variational Propagation: Local, Scalable and Efficient Alternative to Backpropagation","abstract":"Backpropagation (BP) is the cornerstone of deep learning, but its reliance on global gradient synchronization limits scalability and imposes significant memory overhead. We propose Stochastic Variational Propagation (SVP), a scalable alternative that reframes training as hierarchical variational inference. SVP treats layer activations as latent variables and optimizes local Evidence Lower Bounds (ELBOs), enabling independent, local updates while preserving global coherence. However, directly applying KL divergence in layer-wise ELBOs risks inter-layer's representation collapse due to excessive compression. To prevent this, SVP projects activations into low-dimensional spaces via fixed random matrices, ensuring information preservation and representational diversity. Combined with a feature alignment loss for inter-layer consistency, SVP achieves competitive accuracy with BP across diverse architectures (MLPs, CNNs, Transformers) and datasets (MNIST to ImageNet), reduces memory usage by up to 4x, and significantly improves scalability. More broadly, SVP introduces a probabilistic perspective to deep representation learning, opening pathways toward more modular and interpretable neural network design.","authors":["Bojian Yin","Federico Corradi"],"url":"https://arxiv.org/abs/2505.05181"}
{"created":"2025-05-09","title":"PaniCar: Securing the Perception of Advanced Driving Assistance Systems Against Emergency Vehicle Lighting","abstract":"The safety of autonomous cars has come under scrutiny in recent years, especially after 16 documented incidents involving Teslas (with autopilot engaged) crashing into parked emergency vehicles (police cars, ambulances, and firetrucks). While previous studies have revealed that strong light sources often introduce flare artifacts in the captured image, which degrade the image quality, the impact of flare on object detection performance remains unclear. In this research, we unveil PaniCar, a digital phenomenon that causes an object detector's confidence score to fluctuate below detection thresholds when exposed to activated emergency vehicle lighting. This vulnerability poses a significant safety risk, and can cause autonomous vehicles to fail to detect objects near emergency vehicles. In addition, this vulnerability could be exploited by adversaries to compromise the security of advanced driving assistance systems (ADASs). We assess seven commercial ADASs (Tesla Model 3, \"manufacturer C\", HP, Pelsee, AZDOME, Imagebon, Rexing), four object detectors (YOLO, SSD, RetinaNet, Faster R-CNN), and 14 patterns of emergency vehicle lighting to understand the influence of various technical and environmental factors. We also evaluate four SOTA flare removal methods and show that their performance and latency are insufficient for real-time driving constraints. To mitigate this risk, we propose Caracetamol, a robust framework designed to enhance the resilience of object detectors against the effects of activated emergency vehicle lighting. Our evaluation shows that on YOLOv3 and Faster RCNN, Caracetamol improves the models' average confidence of car detection by 0.20, the lower confidence bound by 0.33, and reduces the fluctuation range by 0.33. In addition, Caracetamol is capable of processing frames at a rate of between 30-50 FPS, enabling real-time ADAS car detection.","authors":["Elad Feldman","Jacob Shams","Dudi Biton","Alfred Chen","Shaoyuan Xie","Satoru Koda","Yisroel Mirsky","Asaf Shabtai","Yuval Elovici","Ben Nassi"],"url":"https://arxiv.org/abs/2505.05183"}
{"created":"2025-05-09","title":"In-Situ Model Validation for Continuous Processes Using In-Network Computing","abstract":"The advancing industrial digitalization enables evolved process control schemes that rely on accurate models learned through data-driven approaches. While they provide high control performance and are robust to smaller deviations, a larger change in process behavior can pose significant challenges, in the worst case even leading to a damaged process plant. Hence, it is important to frequently assess the fit between the model and the actual process behavior. As the number of controlled processes and associated data volumes increase, the need for lightweight and fast reacting assessment solutions also increases. In this paper, we propose CIVIC, an in-network computing-based solution for Continuous In-situ Validation of Industrial Control models. In short, CIVIC monitors relevant process variables and detects different process states through comparison with a priori knowledge about the desired process behavior. This detection can then be leveraged to, e.g., shut down the process or trigger a reconfiguration. We prototype CIVIC on an Intel Tofino-based switch and apply it to a lab-scale water treatment plant. Our results show that we can achieve a high detection accuracy, proving that such monitoring systems are feasible and sensible.","authors":["Ike Kunze","Dominik Scheurenberg","Liam Tirpitz","Sandra Geisler","Klaus Wehrle"],"url":"https://arxiv.org/abs/2505.05184"}
{"created":"2025-05-09","title":"Efficient Parallel Ising Samplers via Localization Schemes","abstract":"We introduce efficient parallel algorithms for sampling from the Gibbs distribution and estimating the partition function of Ising models. These algorithms achieve parallel efficiency, with polylogarithmic depth and polynomial total work, and are applicable to Ising models in the following regimes: (1) Ferromagnetic Ising models with external fields; (2) Ising models with interaction matrix $J$ of operator norm $\\|J\\|_2<1$.","authors":["Xiaoyu Chen","Hongyang Liu","Yitong Yin","Xinyuan Zhang"],"url":"https://arxiv.org/abs/2505.05185"}
{"created":"2025-05-09","title":"Biomed-DPT: Dual Modality Prompt Tuning for Biomedical Vision-Language Models","abstract":"Prompt learning is one of the most effective paradigms for adapting pre-trained vision-language models (VLMs) to the biomedical image classification tasks in few shot scenarios. However, most of the current prompt learning methods only used the text prompts and ignored the particular structures (such as the complex anatomical structures and subtle pathological features) in the biomedical images. In this work, we propose Biomed-DPT, a knowledge-enhanced dual modality prompt tuning technique. In designing the text prompt, Biomed-DPT constructs a dual prompt including the template-driven clinical prompts and the large language model (LLM)-driven domain-adapted prompts, then extracts the clinical knowledge from the domain-adapted prompts through the knowledge distillation technique. In designing the vision prompt, Biomed-DPT introduces the zero vector as a soft prompt to leverage attention re-weighting so that the focus on non-diagnostic regions and the recognition of non-critical pathological features are avoided. Biomed-DPT achieves an average classification accuracy of 66.14\\% across 11 biomedical image datasets covering 9 modalities and 10 organs, with performance reaching 78.06\\% in base classes and 75.97\\% in novel classes, surpassing the Context Optimization (CoOp) method by 6.20\\%, 3.78\\%, and 8.04\\%, respectively. Our code are available at \\underline{https://github.com/Kanyooo/Biomed-DPT}.","authors":["Wei Peng","Kang Liu","Jianchen Hu","Meng Zhang"],"url":"https://arxiv.org/abs/2505.05189"}
{"created":"2025-05-09","title":"Revealing Weaknesses in Text Watermarking Through Self-Information Rewrite Attacks","abstract":"Text watermarking aims to subtly embed statistical signals into text by controlling the Large Language Model (LLM)'s sampling process, enabling watermark detectors to verify that the output was generated by the specified model. The robustness of these watermarking algorithms has become a key factor in evaluating their effectiveness. Current text watermarking algorithms embed watermarks in high-entropy tokens to ensure text quality. In this paper, we reveal that this seemingly benign design can be exploited by attackers, posing a significant risk to the robustness of the watermark. We introduce a generic efficient paraphrasing attack, the Self-Information Rewrite Attack (SIRA), which leverages the vulnerability by calculating the self-information of each token to identify potential pattern tokens and perform targeted attack. Our work exposes a widely prevalent vulnerability in current watermarking algorithms. The experimental results show SIRA achieves nearly 100% attack success rates on seven recent watermarking methods with only 0.88 USD per million tokens cost. Our approach does not require any access to the watermark algorithms or the watermarked LLM and can seamlessly transfer to any LLM as the attack model, even mobile-level models. Our findings highlight the urgent need for more robust watermarking.","authors":["Yixin Cheng","Hongcheng Guo","Yangming Li","Leonid Sigal"],"url":"https://arxiv.org/abs/2505.05190"}
{"created":"2025-05-09","title":"Long-Term Individual Causal Effect Estimation via Identifiable Latent Representation Learning","abstract":"Estimating long-term causal effects by combining long-term observational and short-term experimental data is a crucial but challenging problem in many real-world scenarios. In existing methods, several ideal assumptions, e.g. latent unconfoundedness assumption or additive equi-confounding bias assumption, are proposed to address the latent confounder problem raised by the observational data. However, in real-world applications, these assumptions are typically violated which limits their practical effectiveness. In this paper, we tackle the problem of estimating the long-term individual causal effects without the aforementioned assumptions. Specifically, we propose to utilize the natural heterogeneity of data, such as data from multiple sources, to identify latent confounders, thereby significantly avoiding reliance on idealized assumptions. Practically, we devise a latent representation learning-based estimator of long-term causal effects. Theoretically, we establish the identifiability of latent confounders, with which we further achieve long-term effect identification. Extensive experimental studies, conducted on multiple synthetic and semi-synthetic datasets, demonstrate the effectiveness of our proposed method.","authors":["Ruichu Cai","Junjie Wan","Weilin Chen","Zeqin Yang","Zijian Li","Peng Zhen","Jiecheng Guo"],"url":"https://arxiv.org/abs/2505.05192"}
{"created":"2025-05-09","title":"Concept-Based Unsupervised Domain Adaptation","abstract":"Concept Bottleneck Models (CBMs) enhance interpretability by explaining predictions through human-understandable concepts but typically assume that training and test data share the same distribution. This assumption often fails under domain shifts, leading to degraded performance and poor generalization. To address these limitations and improve the robustness of CBMs, we propose the Concept-based Unsupervised Domain Adaptation (CUDA) framework. CUDA is designed to: (1) align concept representations across domains using adversarial training, (2) introduce a relaxation threshold to allow minor domain-specific differences in concept distributions, thereby preventing performance drop due to over-constraints of these distributions, (3) infer concepts directly in the target domain without requiring labeled concept data, enabling CBMs to adapt to diverse domains, and (4) integrate concept learning into conventional domain adaptation (DA) with theoretical guarantees, improving interpretability and establishing new benchmarks for DA. Experiments demonstrate that our approach significantly outperforms the state-of-the-art CBM and DA methods on real-world datasets.","authors":["Xinyue Xu","Yueying Hu","Hui Tang","Yi Qin","Lu Mi","Hao Wang","Xiaomeng Li"],"url":"https://arxiv.org/abs/2505.05195"}
{"created":"2025-05-09","title":"Stealthy LLM-Driven Data Poisoning Attacks Against Embedding-Based Retrieval-Augmented Recommender Systems","abstract":"We present a systematic study of provider-side data poisoning in retrieval-augmented recommender systems (RAG-based). By modifying only a small fraction of tokens within item descriptions -- for instance, adding emotional keywords or borrowing phrases from semantically related items -- an attacker can significantly promote or demote targeted items. We formalize these attacks under token-edit and semantic-similarity constraints, and we examine their effectiveness in both promotion (long-tail items) and demotion (short-head items) scenarios. Our experiments on MovieLens, using two large language model (LLM) retrieval modules, show that even subtle attacks shift final rankings and item exposures while eluding naive detection. The results underscore the vulnerability of RAG-based pipelines to small-scale metadata rewrites and emphasize the need for robust textual consistency checks and provenance tracking to thwart stealthy provider-side poisoning.","authors":["Fatemeh Nazary","Yashar Deldjoo","Tommaso Di Noia","Eugenio Di Sciascio"],"url":"https://arxiv.org/abs/2505.05196"}
{"created":"2025-05-09","title":"Societal and technological progress as sewing an ever-growing, ever-changing, patchy, and polychrome quilt","abstract":"Artificial Intelligence (AI) systems are increasingly placed in positions where their decisions have real consequences, e.g., moderating online spaces, conducting research, and advising on policy. Ensuring they operate in a safe and ethically acceptable fashion is thus critical. However, most solutions have been a form of one-size-fits-all \"alignment\". We are worried that such systems, which overlook enduring moral diversity, will spark resistance, erode trust, and destabilize our institutions. This paper traces the underlying problem to an often-unstated Axiom of Rational Convergence: the idea that under ideal conditions, rational agents will converge in the limit of conversation on a single ethics. Treating that premise as both optional and doubtful, we propose what we call the appropriateness framework: an alternative approach grounded in conflict theory, cultural evolution, multi-agent systems, and institutional economics. The appropriateness framework treats persistent disagreement as the normal case and designs for it by applying four principles: (1) contextual grounding, (2) community customization, (3) continual adaptation, and (4) polycentric governance. We argue here that adopting these design principles is a good way to shift the main alignment metaphor from moral unification to a more productive metaphor of conflict management, and that taking this step is both desirable and urgent.","authors":["Joel Z. Leibo","Alexander Sasha Vezhnevets","William A. Cunningham","S\\'ebastien Krier","Manfred Diaz","Simon Osindero"],"url":"https://arxiv.org/abs/2505.05197"}
{"created":"2025-05-09","title":"LAPSO: A Unified Optimization View for Learning-Augmented Power System Operations","abstract":"With the high penetration of renewables, traditional model-based power system operation is challenged to deliver economic, stable, and robust decisions. Machine learning has emerged as a powerful modeling tool for capturing complex dynamics to address these challenges. However, its separate design often lacks systematic integration with existing methods. To fill the gap, this paper proposes a holistic framework of Learning-Augmented Power System Operations (LAPSO, pronounced as Lap-So). Adopting a native optimization perspective, LAPSO is centered on the operation stage and aims to break the boundary between temporally siloed power system tasks, such as forecast, operation and control, while unifying the objectives of machine learning and model-based optimizations at both training and inference stages. Systematic analysis and simulations demonstrate the effectiveness of applying LAPSO in designing new integrated algorithms, such as stability-constrained optimization (SCO) and objective-based forecasting (OBF), while enabling end-to-end tracing of different sources of uncertainties. In addition, a dedicated Python package-lapso is introduced to automatically augment existing power system optimization models with learnable components. All code and data are available at https://github.com/xuwkk/lapso_exp.","authors":["Wangkun Xu","Zhongda Chu","Fei Teng"],"url":"https://arxiv.org/abs/2505.05203"}
{"created":"2025-05-09","title":"EAM: Enhancing Anything with Diffusion Transformers for Blind Super-Resolution","abstract":"Utilizing pre-trained Text-to-Image (T2I) diffusion models to guide Blind Super-Resolution (BSR) has become a predominant approach in the field. While T2I models have traditionally relied on U-Net architectures, recent advancements have demonstrated that Diffusion Transformers (DiT) achieve significantly higher performance in this domain. In this work, we introduce Enhancing Anything Model (EAM), a novel BSR method that leverages DiT and outperforms previous U-Net-based approaches. We introduce a novel block, $\\Psi$-DiT, which effectively guides the DiT to enhance image restoration. This block employs a low-resolution latent as a separable flow injection control, forming a triple-flow architecture that effectively leverages the prior knowledge embedded in the pre-trained DiT. To fully exploit the prior guidance capabilities of T2I models and enhance their generalization in BSR, we introduce a progressive Masked Image Modeling strategy, which also reduces training costs. Additionally, we propose a subject-aware prompt generation strategy that employs a robust multi-modal model in an in-context learning framework. This strategy automatically identifies key image areas, provides detailed descriptions, and optimizes the utilization of T2I diffusion priors. Our experiments demonstrate that EAM achieves state-of-the-art results across multiple datasets, outperforming existing methods in both quantitative metrics and visual quality.","authors":["Haizhen Xie","Kunpeng Du","Qiangyu Yan","Sen Lu","Jianhong Han","Hanting Chen","Hailin Hu","Jie Hu"],"url":"https://arxiv.org/abs/2505.05209"}
{"created":"2025-05-09","title":"Incentive-Aware Machine Learning; Robustness, Fairness, Improvement & Causality","abstract":"The article explores the emerging domain of incentive-aware machine learning (ML), which focuses on algorithmic decision-making in contexts where individuals can strategically modify their inputs to influence outcomes. It categorizes the research into three perspectives: robustness, aiming to design models resilient to \"gaming\"; fairness, analyzing the societal impacts of such systems; and improvement/causality, recognizing situations where strategic actions lead to genuine personal or societal improvement. The paper introduces a unified framework encapsulating models for these perspectives, including offline, online, and causal settings, and highlights key challenges such as differentiating between gaming and improvement and addressing heterogeneity among agents. By synthesizing findings from diverse works, we outline theoretical advancements and practical solutions for robust, fair, and causally-informed incentive-aware ML systems.","authors":["Chara Podimata"],"url":"https://arxiv.org/abs/2505.05211"}
{"created":"2025-05-09","title":"HQC-NBV: A Hybrid Quantum-Classical View Planning Approach","abstract":"Efficient view planning is a fundamental challenge in computer vision and robotic perception, critical for tasks ranging from search and rescue operations to autonomous navigation. While classical approaches, including sampling-based and deterministic methods, have shown promise in planning camera viewpoints for scene exploration, they often struggle with computational scalability and solution optimality in complex settings. This study introduces HQC-NBV, a hybrid quantum-classical framework for view planning that leverages quantum properties to efficiently explore the parameter space while maintaining robustness and scalability. We propose a specific Hamiltonian formulation with multi-component cost terms and a parameter-centric variational ansatz with bidirectional alternating entanglement patterns that capture the hierarchical dependencies between viewpoint parameters. Comprehensive experiments demonstrate that quantum-specific components provide measurable performance advantages. Compared to the classical methods, our approach achieves up to 49.2% higher exploration efficiency across diverse environments. Our analysis of entanglement architecture and coherence-preserving terms provides insights into the mechanisms of quantum advantage in robotic exploration tasks. This work represents a significant advancement in integrating quantum computing into robotic perception systems, offering a paradigm-shifting solution for various robot vision tasks.","authors":["Xiaotong Yu","Chang Wen Chen"],"url":"https://arxiv.org/abs/2505.05212"}
{"created":"2025-05-09","title":"Overlapping Biclustering","abstract":"In this paper, we introduce Bicluster Editing with Vertex Splitting, a variant of the Bicluster Editing problem, which aims to transform a given graph into a bicluster graph using a minimum number of operations. In Bicluster Editing, the allowed operations are the insertion and deletion of edges. In Bicluster Editing with Vertex Splitting we additionally allow overlapping clusters, which we model by allowing vertex splits. We prove that Bicluster Editing with Vertex Splitting is NP-complete. On the positive side, we show that it admits a polynomial kernel with respect to the number k of allowed edit operations and present an algorithm running in O(k^{11k} + n + m) time, where n and m denote the number of vertices and edges in the input graph, respectively.","authors":["Matthias Bentert","P{\\aa}l Gr{\\o}n{\\aa}s Drange","Erlend Haugen"],"url":"https://arxiv.org/abs/2505.05213"}
{"created":"2025-05-09","title":"Overcoming the hurdle of legal expertise: A reusable model for smartwatch privacy policies","abstract":"Regulations for privacy protection aim to protect individuals from the unauthorized storage, processing, and transfer of their personal data but oftentimes fail in providing helpful support for understanding these regulations. To better communicate privacy policies for smartwatches, we need an in-depth understanding of their concepts and provide better ways to enable developers to integrate them when engineering systems. Up to now, no conceptual model exists covering privacy statements from different smartwatch manufacturers that is reusable for developers. This paper introduces such a conceptual model for privacy policies of smartwatches and shows its use in a model-driven software engineering approach to create a platform for data visualization of wearable privacy policies from different smartwatch manufacturers. We have analyzed the privacy policies of various manufacturers and extracted the relevant concepts. Moreover, we have checked the model with lawyers for its correctness, instantiated it with concrete data, and used it in a model-driven software engineering approach to create a platform for data visualization. This reusable privacy policy model can enable developers to easily represent privacy policies in their systems. This provides a foundation for more structured and understandable privacy policies which, in the long run, can increase the data sovereignty of application users.","authors":["Constantin Buschhaus","Arvid Butting","Judith Michael","Verena Nitsch","Sebastian P\\\"utz","Bernhard Rumpe","Carolin Stellmacher","Sabine Theis"],"url":"https://arxiv.org/abs/2505.05214"}
{"created":"2025-05-09","title":"Diffusion Model Quantization: A Review","abstract":"Recent success of large text-to-image models has empirically underscored the exceptional performance of diffusion models in generative tasks. To facilitate their efficient deployment on resource-constrained edge devices, model quantization has emerged as a pivotal technique for both compression and acceleration. This survey offers a thorough review of the latest advancements in diffusion model quantization, encapsulating and analyzing the current state of the art in this rapidly advancing domain. First, we provide an overview of the key challenges encountered in the quantization of diffusion models, including those based on U-Net architectures and Diffusion Transformers (DiT). We then present a comprehensive taxonomy of prevalent quantization techniques, engaging in an in-depth discussion of their underlying principles. Subsequently, we perform a meticulous analysis of representative diffusion model quantization schemes from both qualitative and quantitative perspectives. From a quantitative standpoint, we rigorously benchmark a variety of methods using widely recognized datasets, delivering an extensive evaluation of the most recent and impactful research in the field. From a qualitative standpoint, we categorize and synthesize the effects of quantization errors, elucidating these impacts through both visual analysis and trajectory examination. In conclusion, we outline prospective avenues for future research, proposing novel directions for the quantization of generative models in practical applications. The list of related papers, corresponding codes, pre-trained models and comparison results are publicly available at the survey project homepage https://github.com/TaylorJocelyn/Diffusion-Model-Quantization.","authors":["Qian Zeng","Chenggong Hu","Mingli Song","Jie Song"],"url":"https://arxiv.org/abs/2505.05215"}
{"created":"2025-05-09","title":"Multi-Objective Reinforcement Learning for Adaptive Personalized Autonomous Driving","abstract":"Human drivers exhibit individual preferences regarding driving style. Adapting autonomous vehicles to these preferences is essential for user trust and satisfaction. However, existing end-to-end driving approaches often rely on predefined driving styles or require continuous user feedback for adaptation, limiting their ability to support dynamic, context-dependent preferences. We propose a novel approach using multi-objective reinforcement learning (MORL) with preference-driven optimization for end-to-end autonomous driving that enables runtime adaptation to driving style preferences. Preferences are encoded as continuous weight vectors to modulate behavior along interpretable style objectives$\\unicode{x2013}$including efficiency, comfort, speed, and aggressiveness$\\unicode{x2013}$without requiring policy retraining. Our single-policy agent integrates vision-based perception in complex mixed-traffic scenarios and is evaluated in diverse urban environments using the CARLA simulator. Experimental results demonstrate that the agent dynamically adapts its driving behavior according to changing preferences while maintaining performance in terms of collision avoidance and route completion.","authors":["Hendrik Surmann","Jorge de Heuvel","Maren Bennewitz"],"url":"https://arxiv.org/abs/2505.05223"}
{"created":"2025-05-09","title":"GFlowNets for Active Learning Based Resource Allocation in Next Generation Wireless Networks","abstract":"In this work, we consider the radio resource allocation problem in a wireless system with various integrated functionalities, such as communication, sensing and computing. We design suitable resource management techniques that can simultaneously cater to those heterogeneous requirements, and scale appropriately with the high-dimensional and discrete nature of the problem. We propose a novel active learning framework where resource allocation patterns are drawn sequentially, evaluated in the environment, and then used to iteratively update a surrogate model of the environment. Our method leverages a generative flow network (GFlowNet) to sample favorable solutions, as such models are trained to generate compositional objects proportionally to their training reward, hence providing an appropriate coverage of its modes. As such, GFlowNet generates diverse and high return resource management designs that update the surrogate model and swiftly discover suitable solutions. We provide simulation results showing that our method can allocate radio resources achieving 20% performance gains against benchmarks, while requiring less than half of the number of acquisition rounds.","authors":["Charbel Bou Chaaya","Mehdi Bennis"],"url":"https://arxiv.org/abs/2505.05224"}
{"created":"2025-05-09","title":"QualBench: Benchmarking Chinese LLMs with Localized Professional Qualifications for Vertical Domain Evaluation","abstract":"The rapid advancement of Chinese large language models (LLMs) underscores the need for domain-specific evaluations to ensure reliable applications. However, existing benchmarks often lack coverage in vertical domains and offer limited insights into the Chinese working context. Leveraging qualification exams as a unified framework for human expertise evaluation, we introduce QualBench, the first multi-domain Chinese QA benchmark dedicated to localized assessment of Chinese LLMs. The dataset includes over 17,000 questions across six vertical domains, with data selections grounded in 24 Chinese qualifications to closely align with national policies and working standards. Through comprehensive evaluation, the Qwen2.5 model outperformed the more advanced GPT-4o, with Chinese LLMs consistently surpassing non-Chinese models, highlighting the importance of localized domain knowledge in meeting qualification requirements. The best performance of 75.26% reveals the current gaps in domain coverage within model capabilities. Furthermore, we present the failure of LLM collaboration with crowdsourcing mechanisms and suggest the opportunities for multi-domain RAG knowledge enhancement and vertical domain LLM training with Federated Learning.","authors":["Mengze Hong","Wailing Ng","Di Jiang","Chen Jason Zhang"],"url":"https://arxiv.org/abs/2505.05225"}
{"created":"2025-05-09","title":"Put CASH on Bandits: A Max K-Armed Problem for Automated Machine Learning","abstract":"The Combined Algorithm Selection and Hyperparameter optimization (CASH) is a challenging resource allocation problem in the field of AutoML. We propose MaxUCB, a max $k$-armed bandit method to trade off exploring different model classes and conducting hyperparameter optimization. MaxUCB is specifically designed for the light-tailed and bounded reward distributions arising in this setting and, thus, provides an efficient alternative compared to classic max $k$-armed bandit methods assuming heavy-tailed reward distributions. We theoretically and empirically evaluate our method on four standard AutoML benchmarks, demonstrating superior performance over prior approaches.","authors":["Amir Rezaei Balef","Claire Vernade","Katharina Eggensperger"],"url":"https://arxiv.org/abs/2505.05226"}
{"created":"2025-05-09","title":"On the stability and conditioning of a fictitious domain formulation for fluid-structure interaction problems","abstract":"We consider a distributed Lagrange multiplier formulation for fluid-structure interaction problems in the spirit of the fictitious domain approach. Our previous studies showed that the formulation is unconditionally stable in time and that its mixed finite element discretization is well-posed. In this paper, we analyze the behavior of the condition number with respect to mesh refinement. Moreover, we observe that our formulation does not need any stabilization term in presence of small cut cells and conditioning is not affected by the interface position.","authors":["Daniele Boffi","Fabio Credali","Lucia Gastaldi"],"url":"https://arxiv.org/abs/2505.05228"}
{"created":"2025-05-09","title":"Does CLIP perceive art the same way we do?","abstract":"CLIP has emerged as a powerful multimodal model capable of connecting images and text through joint embeddings, but to what extent does it \"see\" the same way humans do - especially when interpreting artworks? In this paper, we investigate CLIP's ability to extract high-level semantic and stylistic information from paintings, including both human-created and AI-generated imagery. We evaluate its perception across multiple dimensions: content, scene understanding, artistic style, historical period, and the presence of visual deformations or artifacts. By designing targeted probing tasks and comparing CLIP's responses to human annotations and expert benchmarks, we explore its alignment with human perceptual and contextual understanding. Our findings reveal both strengths and limitations in CLIP's visual representations, particularly in relation to aesthetic cues and artistic intent. We further discuss the implications of these insights for using CLIP as a guidance mechanism during generative processes, such as style transfer or prompt-based image synthesis. Our work highlights the need for deeper interpretability in multimodal systems, especially when applied to creative domains where nuance and subjectivity play a central role.","authors":["Andrea Asperti","Leonardo Dess\\`i","Maria Chiara Tonetti","Nico Wu"],"url":"https://arxiv.org/abs/2505.05229"}
{"created":"2025-05-09","title":"Adaptive Biased User Scheduling for Heterogeneous Wireless Federate Learning Network","abstract":"Federated Learning (FL) has revolutionized collaborative model training in distributed networks, prioritizing data privacy and communication efficiency. This paper investigates efficient deployment of FL in wireless heterogeneous networks, focusing on strategies to accelerate convergence despite stragglers. The primary objective is to minimize long-term convergence wall-clock time through optimized user scheduling and resource allocation. While stragglers may introduce delays in a single round, their inclusion can expedite subsequent rounds, particularly when they possess critical information. Moreover, balancing single-round duration with the number of cumulative rounds, compounded by dynamic training and transmission conditions, necessitates a novel approach beyond conventional optimization solutions. To tackle these challenges, convergence analysis with respect to adaptive and biased scheduling is derived. Then, by factoring in real-time system and statistical information, including diverse energy constraints and users' energy harvesting capabilities, a deep reinforcement learning approach, empowered by proximal policy optimization, is employed to adaptively select user sets. For the scheduled users, Lagrangian decomposition is applied to optimize local resource utilization, further enhancing system efficiency. Simulation results validate the effectiveness and robustness of the proposed framework for various FL tasks, demonstrating reduced task time compared to existing benchmarks under various settings.","authors":["Changxiang Wu","Yijing Ren","Daniel K. C. So","Jie Tang"],"url":"https://arxiv.org/abs/2505.05231"}
{"created":"2025-05-09","title":"ChemRxivQuest: A Curated Chemistry Question-Answer Database Extracted from ChemRxiv Preprints","abstract":"The rapid expansion of chemistry literature poses significant challenges for researchers seeking to efficiently access domain-specific knowledge. To support advancements in chemistry-focused natural language processing (NLP), we present ChemRxivQuest, a curated dataset of 970 high-quality question-answer (QA) pairs derived from 155 ChemRxiv preprints across 17 subfields of chemistry. Each QA pair is explicitly linked to its source text segment to ensure traceability and contextual accuracy. ChemRxivQuest was constructed using an automated pipeline that combines optical character recognition (OCR), GPT-4o-based QA generation, and a fuzzy matching technique for answer verification. The dataset emphasizes conceptual, mechanistic, applied, and experimental questions, enabling applications in retrieval-based QA systems, search engine development, and fine-tuning of domain-adapted large language models. We analyze the dataset's structure, coverage, and limitations, and outline future directions for expansion and expert validation. ChemRxivQuest provides a foundational resource for chemistry NLP research, education, and tool development.","authors":["Mahmoud Amiri","Thomas Bocklitz"],"url":"https://arxiv.org/abs/2505.05232"}
{"created":"2025-05-09","title":"Weighting operators for sparsity regularization","abstract":"Standard regularization methods typically favor solutions which are in, or close to, the orthogonal complement of the null space of the forward operator/matrix $\\mathsf{A}$. This particular biasedness might not be desirable in applications and can lead to severe challenges when $\\mathsf{A}$ is non-injective.","authors":["Ole L{\\o}seth Elvetun","Bj{\\o}rn Fredrik Nielsen","Niranjana Sudheer"],"url":"https://arxiv.org/abs/2505.05234"}
{"created":"2025-05-09","title":"Advancing Neural Network Verification through Hierarchical Safety Abstract Interpretation","abstract":"Traditional methods for formal verification (FV) of deep neural networks (DNNs) are constrained by a binary encoding of safety properties, where a model is classified as either safe or unsafe (robust or not robust). This binary encoding fails to capture the nuanced safety levels within a model, often resulting in either overly restrictive or too permissive requirements. In this paper, we introduce a novel problem formulation called Abstract DNN-Verification, which verifies a hierarchical structure of unsafe outputs, providing a more granular analysis of the safety aspect for a given DNN. Crucially, by leveraging abstract interpretation and reasoning about output reachable sets, our approach enables assessing multiple safety levels during the FV process, requiring the same (in the worst case) or even potentially less computational effort than the traditional binary verification approach. Specifically, we demonstrate how this formulation allows rank adversarial inputs according to their abstract safety level violation, offering a more detailed evaluation of the model's safety and robustness. Our contributions include a theoretical exploration of the relationship between our novel abstract safety formulation and existing approaches that employ abstract interpretation for robustness verification, complexity analysis of the novel problem introduced, and an empirical evaluation considering both a complex deep reinforcement learning task (based on Habitat 3.0) and standard DNN-Verification benchmarks.","authors":["Luca Marzari","Isabella Mastroeni","Alessandro Farinelli"],"url":"https://arxiv.org/abs/2505.05235"}
{"created":"2025-05-09","title":"Thermoelastic Kirchhoff Plate: A Novel Model for Shot Peen Forming Metal Panels","abstract":"A common technique used in factories to shape metal panels is shot peen forming, where the panel is sprayed with a high-velocity stream of small steel pellets called shot. The impacts between the hard steel shot and softer aluminum panel cause localized plastic deformation, both improving the fatigue properties of the material's surface and imparting a residual stress distribution that results in bending. Thus, a torque is associated with the through-thickness shot peen stress distribution. We conceptualize shot peen forming as the application of spatially varying torques, which are modeled with the input of applied temperatures. In this paper, we derive the bending equations for a thermally loaded homogeneous Kirchhoff plate in order to predict the effects of shot peen forming. A simple test is devised to extract the value of an equivalent applied torque from the bending response of uniformly shot peened plates, which circumvents the difficulty of accounting for surface plasticity. This torque can be used as an input to a model which predicts the shape of rectangular plates under more complicated shot peen conditions. An experiment is designed and carried out which investigates the agreement between the model and real shot peen operations. The effect of uncertainty in the experiment is estimated with Monte Carlo methods.","authors":["Conor Rowan"],"url":"https://arxiv.org/abs/2505.05236"}
{"created":"2025-05-09","title":"Latte: Transfering LLMs` Latent-level Knowledge for Few-shot Tabular Learning","abstract":"Few-shot tabular learning, in which machine learning models are trained with a limited amount of labeled data, provides a cost-effective approach to addressing real-world challenges. The advent of Large Language Models (LLMs) has sparked interest in leveraging their pre-trained knowledge for few-shot tabular learning. Despite promising results, existing approaches either rely on test-time knowledge extraction, which introduces undesirable latency, or text-level knowledge, which leads to unreliable feature engineering. To overcome these limitations, we propose Latte, a training-time knowledge extraction framework that transfers the latent prior knowledge within LLMs to optimize a more generalized downstream model. Latte enables general knowledge-guided downstream tabular learning, facilitating the weighted fusion of information across different feature values while reducing the risk of overfitting to limited labeled data. Furthermore, Latte is compatible with existing unsupervised pre-training paradigms and effectively utilizes available unlabeled samples to overcome the performance limitations imposed by an extremely small labeled dataset. Extensive experiments on various few-shot tabular learning benchmarks demonstrate the superior performance of Latte, establishing it as a state-of-the-art approach in this domain","authors":["Ruxue Shi","Hengrui Gu","Hangting Ye","Yiwei Dai","Xu Shen","Xin Wang"],"url":"https://arxiv.org/abs/2505.05237"}
{"created":"2025-05-09","title":"Bounds on $k$-hash distances and rates of linear codes","abstract":"In this paper, we bound the rate of linear codes in $\\mathbb{F}_q^n$ with the property that any $k \\leq q$ codewords are all simultaneously distinct in at least $d_k$ coordinates. For the particular case $d_k=1$, this leads to bounds on the rate of linear $q$-ary $k$-hash codes which generalize, with a simpler proof, results recently obtained for the case $q=k=3$ by Pohoata and Zakharov and by Bishnoi D'haeseleeer and Gijswijt. We finally discuss some related open problems on the list-decoding zero-error capacity of discrete memoryless channels.","authors":["Stefano Della Fiore","Marco Dalai"],"url":"https://arxiv.org/abs/2505.05239"}
{"created":"2025-05-09","title":"PADriver: Towards Personalized Autonomous Driving","abstract":"In this paper, we propose PADriver, a novel closed-loop framework for personalized autonomous driving (PAD). Built upon Multi-modal Large Language Model (MLLM), PADriver takes streaming frames and personalized textual prompts as inputs. It autoaggressively performs scene understanding, danger level estimation and action decision. The predicted danger level reflects the risk of the potential action and provides an explicit reference for the final action, which corresponds to the preset personalized prompt. Moreover, we construct a closed-loop benchmark named PAD-Highway based on Highway-Env simulator to comprehensively evaluate the decision performance under traffic rules. The dataset contains 250 hours videos with high-quality annotation to facilitate the development of PAD behavior analysis. Experimental results on the constructed benchmark show that PADriver outperforms state-of-the-art approaches on different evaluation metrics, and enables various driving modes.","authors":["Genghua Kou","Fan Jia","Weixin Mao","Yingfei Liu","Yucheng Zhao","Ziheng Zhang","Osamu Yoshie","Tiancai Wang","Ying Li","Xiangyu Zhang"],"url":"https://arxiv.org/abs/2505.05240"}
{"created":"2025-05-09","title":"Enhancing Treatment Effect Estimation via Active Learning: A Counterfactual Covering Perspective","abstract":"Although numerous complex algorithms for treatment effect estimation have been developed in recent years, their effectiveness remains limited when handling insufficiently labeled training sets due to the high cost of labeling the effect after treatment, e.g., expensive tumor imaging or biopsy procedures needed to evaluate treatment effects. Therefore, it becomes essential to actively incorporate more high-quality labeled data, all while adhering to a constrained labeling budget. To enable data-efficient treatment effect estimation, we formalize the problem through rigorous theoretical analysis within the active learning context, where the derived key measures -- \\textit{factual} and \\textit{counterfactual covering radius} determine the risk upper bound. To reduce the bound, we propose a greedy radius reduction algorithm, which excels under an idealized, balanced data distribution. To generalize to more realistic data distributions, we further propose FCCM, which transforms the optimization objective into the \\textit{Factual} and \\textit{Counterfactual Coverage Maximization} to ensure effective radius reduction during data acquisition. Furthermore, benchmarking FCCM against other baselines demonstrates its superiority across both fully synthetic and semi-synthetic datasets.","authors":["Hechuan Wen","Tong Chen","Mingming Gong","Li Kheng Chai","Shazia Sadiq","Hongzhi Yin"],"url":"https://arxiv.org/abs/2505.05242"}
{"created":"2025-05-09","title":"Three dimensional seepage analysis using a polyhedral scaled boundary finite element method","abstract":"This paper presents a novel polyhedral scaled boundary finite element method (PSBFEM) for three-dimensional seepage analysis. The proposed method combines the semi-analytical capabilities of the SBFEM with the geometric flexibility of polyhedral and octree meshes, making it well-suited for complex seepage problems. Wachspress shape functions are employed to construct shape functions over arbitrary polyhedral elements, enabling accurate approximation along complex boundaries. The method is implemented within the ABAQUS UEL framework to support steady-state, transient, and free-surface seepage simulations. A series of numerical examples are provided to verify the accuracy, efficiency, and convergence of the proposed method, including benchmark problems and geometrically complex domains. The results demonstrate that the PSBFEM achieves higher accuracy and faster convergence compared to conventional FEM, particularly when using hybrid octree meshes with localized refinement. This framework provides a robust and efficient tool for 3D seepage analysis in geotechnical and hydraulic engineering applications.","authors":["Mingjiao Yan","Yang Yang","Dengmiao Hao","Chao Su","Zongliang Zhang"],"url":"https://arxiv.org/abs/2505.05244"}
{"created":"2025-05-09","title":"High Altitude Platform-Based Caching and Multicasting for Rural Connectivity","abstract":"Providing efficient and reliable content delivery in rural areas remains a significant challenge due to the lack of communication infrastructure. To bridge the digital divide, this paper investigates the potential of leveraging multiple high-altitude platforms (HAPs) for energy-efficient content delivery in wide rural regions. Each caching-enabled HAP is equipped with both Free-Space Optical (FSO) transceivers for backhaul links and Radio Frequency (RF) antenna arrays for access links. To further enhance network efficiency, we consider a network coding-based multicasting scheme, where different types of content are treated as distinct multicast sessions. With the objective of minimizing long-term power cost, we propose a hierarchical framework that integrates deep reinforcement learn-ing (DRL) and convex optimization to jointly optimize dynamic caching strategies and resource allocation across the network. Simulation results demonstrate that our approach significantly reduces power cost compared to several baseline approaches, providing a practical solution for improving rural connectivity.","authors":["Yongqiang Zhang","Mustafa A. Kishk","Mohamed-Slim Alouini"],"url":"https://arxiv.org/abs/2505.05251"}
{"created":"2025-05-09","title":"CV-MP: Max-Pressure Control in Heterogeneously Distributed and Partially Connected Vehicle Environments","abstract":"Max-pressure (MP) control has emerged as a prominent real-time network traffic signal control strategy due to its simplicity, decentralized structure, and theoretical guarantees of network queue stability. Meanwhile, advances in connected vehicle (CV) technology have sparked extensive research into CV-based traffic signal control. Despite these developments, few studies have investigated MP control in heterogeneously distributed and partially CV environments while ensuring network queue stability. To address these research gaps, we propose a CV-based MP control (CV-MP) method that leverages real-time CV travel time information to compute the pressure, thereby incorporating both the spatial distribution and temporal delays of vehicles, unlike existing approaches that utilized only spatial distribution or temporal delays. In particular, we establish sufficient conditions for road network queue stability that are compatible with most existing MP control methods. Moreover, we pioneered the proof of network queue stability even if the vehicles are only partially connected and heterogeneously distributed, and gave a necessary condition of CV observation for maintaining the stability. Evaluation results on an Amsterdam corridor show that CV-MP significantly reduces vehicle delays compared to both actuated control and conventional MP control across various CV penetration rates. Moreover, in scenarios with dynamic traffic demand, CV-MP achieves lower spillover peaks even with low and heterogeneous CV penetration rates, further highlighting its effectiveness and robustness.","authors":["Chaopeng Tan","Dingshan Sun","Hao Liu","Marco Rinaldi","Hans van Lint"],"url":"https://arxiv.org/abs/2505.05258"}
{"created":"2025-05-09","title":"Enhancing Cooperative Multi-Agent Reinforcement Learning with State Modelling and Adversarial Exploration","abstract":"Learning to cooperate in distributed partially observable environments with no communication abilities poses significant challenges for multi-agent deep reinforcement learning (MARL). This paper addresses key concerns in this domain, focusing on inferring state representations from individual agent observations and leveraging these representations to enhance agents' exploration and collaborative task execution policies. To this end, we propose a novel state modelling framework for cooperative MARL, where agents infer meaningful belief representations of the non-observable state, with respect to optimizing their own policies, while filtering redundant and less informative joint state information. Building upon this framework, we propose the MARL SMPE algorithm. In SMPE, agents enhance their own policy's discriminative abilities under partial observability, explicitly by incorporating their beliefs into the policy network, and implicitly by adopting an adversarial type of exploration policies which encourages agents to discover novel, high-value states while improving the discriminative abilities of others. Experimentally, we show that SMPE outperforms state-of-the-art MARL algorithms in complex fully cooperative tasks from the MPE, LBF, and RWARE benchmarks.","authors":["Andreas Kontogiannis","Konstantinos Papathanasiou","Yi Shen","Giorgos Stamou","Michael M. Zavlanos","George Vouros"],"url":"https://arxiv.org/abs/2505.05262"}
{"created":"2025-05-09","title":"PUDTune: Multi-Level Charging for High-Precision Calibration in Processing-Using-DRAM","abstract":"Recently, practical analog in-memory computing has been realized using unmodified commercial DRAM modules. The underlying Processing-Using-DRAM (PUD) techniques enable high-throughput bitwise operations directly within DRAM arrays. However, the presence of inherent error-prone columns hinders PUD's practical adoption. While selectively using only error-free columns would ensure reliability, this approach significantly reduces PUD's computational throughput.","authors":["Tatsuya Kubo","Daichi Tokuda","Lei Qu","Ting Cao","Shinya Takamaeda-Yamazaki"],"url":"https://arxiv.org/abs/2505.05266"}
{"created":"2025-05-09","title":"T-T: Table Transformer for Tagging-based Aspect Sentiment Triplet Extraction","abstract":"Aspect sentiment triplet extraction (ASTE) aims to extract triplets composed of aspect terms, opinion terms, and sentiment polarities from given sentences. The table tagging method is a popular approach to addressing this task, which encodes a sentence into a 2-dimensional table, allowing for the tagging of relations between any two words. Previous efforts have focused on designing various downstream relation learning modules to better capture interactions between tokens in the table, revealing that a stronger capability to capture relations can lead to greater improvements in the model. Motivated by this, we attempt to directly utilize transformer layers as downstream relation learning modules. Due to the powerful semantic modeling capability of transformers, it is foreseeable that this will lead to excellent improvement. However, owing to the quadratic relation between the length of the table and the length of the input sentence sequence, using transformers directly faces two challenges: overly long table sequences and unfair local attention interaction. To address these challenges, we propose a novel Table-Transformer (T-T) for the tagging-based ASTE method. Specifically, we introduce a stripe attention mechanism with a loop-shift strategy to tackle these challenges. The former modifies the global attention mechanism to only attend to a 2-dimensional local attention window, while the latter facilitates interaction between different attention windows. Extensive and comprehensive experiments demonstrate that the T-T, as a downstream relation learning module, achieves state-of-the-art performance with lower computational costs.","authors":["Kun Peng","Chaodong Tong","Cong Cao","Hao Peng","Qian Li","Guanlin Wu","Lei Jiang","Yanbing Liu","Philip S. Yu"],"url":"https://arxiv.org/abs/2505.05271"}
{"created":"2025-05-09","title":"MTL-UE: Learning to Learn Nothing for Multi-Task Learning","abstract":"Most existing unlearnable strategies focus on preventing unauthorized users from training single-task learning (STL) models with personal data. Nevertheless, the paradigm has recently shifted towards multi-task data and multi-task learning (MTL), targeting generalist and foundation models that can handle multiple tasks simultaneously. Despite their growing importance, MTL data and models have been largely neglected while pursuing unlearnable strategies. This paper presents MTL-UE, the first unified framework for generating unlearnable examples for multi-task data and MTL models. Instead of optimizing perturbations for each sample, we design a generator-based structure that introduces label priors and class-wise feature embeddings which leads to much better attacking performance. In addition, MTL-UE incorporates intra-task and inter-task embedding regularization to increase inter-class separation and suppress intra-class variance which enhances the attack robustness greatly. Furthermore, MTL-UE is versatile with good supports for dense prediction tasks in MTL. It is also plug-and-play allowing integrating existing surrogate-dependent unlearnable methods with little adaptation. Extensive experiments show that MTL-UE achieves superior attacking performance consistently across 4 MTL datasets, 3 base UE methods, 5 model backbones, and 5 MTL task-weighting strategies.","authors":["Yi Yu","Song Xia","Siyuan Yang","Chenqi Kong","Wenhan Yang","Shijian Lu","Yap-Peng Tan","Alex C. Kot"],"url":"https://arxiv.org/abs/2505.05279"}
{"created":"2025-05-09","title":"Software Development Life Cycle Perspective: A Survey of Benchmarks for CodeLLMs and Agents","abstract":"Code large language models (CodeLLMs) and agents have shown great promise in tackling complex software engineering tasks.Compared to traditional software engineering methods, CodeLLMs and agents offer stronger abilities, and can flexibly process inputs and outputs in both natural and code. Benchmarking plays a crucial role in evaluating the capabilities of CodeLLMs and agents, guiding their development and deployment. However, despite their growing significance, there remains a lack of comprehensive reviews of benchmarks for CodeLLMs and agents. To bridge this gap, this paper provides a comprehensive review of existing benchmarks for CodeLLMs and agents, studying and analyzing 181 benchmarks from 461 relevant papers, covering the different phases of the software development life cycle (SDLC). Our findings reveal a notable imbalance in the coverage of current benchmarks, with approximately 60% focused on the software development phase in SDLC, while requirements engineering and software design phases receive minimal attention at only 5% and 3%, respectively. Additionally, Python emerges as the dominant programming language across the reviewed benchmarks. Finally, this paper highlights the challenges of current research and proposes future directions, aiming to narrow the gap between the theoretical capabilities of CodeLLMs and agents and their application in real-world scenarios.","authors":["Kaixin Wang","Tianlin Li","Xiaoyu Zhang","Chong Wang","Weisong Sun","Yang Liu","Bin Shi"],"url":"https://arxiv.org/abs/2505.05283"}
{"created":"2025-05-09","title":"HEXGEN-TEXT2SQL: Optimizing LLM Inference Request Scheduling for Agentic Text-to-SQL Workflow","abstract":"Recent advances in leveraging the agentic paradigm of large language models (LLMs) utilization have significantly enhanced Text-to-SQL capabilities, enabling users without specialized database expertise to query data intuitively. However, deploying these agentic LLM-based Text-to-SQL systems in production poses substantial challenges due to their inherently multi-stage workflows, stringent latency constraints, and potentially heterogeneous GPU infrastructure in enterprise environments. Current LLM serving frameworks lack effective mechanisms for handling interdependent inference tasks, dynamic latency variability, and resource heterogeneity, leading to suboptimal performance and frequent service-level objective (SLO) violations. In this paper, we introduce HEXGEN-TEXT2SQL, a novel framework designed explicitly to schedule and execute agentic multi-stage LLM-based Text-to-SQL workflows on heterogeneous GPU clusters that handle multi-tenant end-to-end queries. HEXGEN-TEXT2SQL introduce a hierarchical scheduling approach combining global workload-balanced task dispatching and local adaptive urgency-guided prioritization, guided by a systematic analysis of agentic Text-to-SQL workflows. Additionally, we propose a lightweight simulation-based method for tuning critical scheduling hyperparameters, further enhancing robustness and adaptability. Our extensive evaluation on realistic Text-to-SQL benchmarks demonstrates that HEXGEN-TEXT2SQL significantly outperforms state-of-the-art LLM serving frameworks. Specifically, HEXGEN-TEXT2SQL reduces latency deadlines by up to 1.67$\\times$ (average: 1.41$\\times$) and improves system throughput by up to 1.75$\\times$ (average: 1.65$\\times$) compared to vLLM under diverse, realistic workload conditions. Our code is available at https://github.com/Relaxed-System-Lab/Hexgen-Flow.","authors":["You Peng","Youhe Jiang","Chen Wang","Binhang Yuan"],"url":"https://arxiv.org/abs/2505.05286"}
{"created":"2025-05-09","title":"Morphologically Symmetric Reinforcement Learning for Ambidextrous Bimanual Manipulation","abstract":"Humans naturally exhibit bilateral symmetry in their gross manipulation skills, effortlessly mirroring simple actions between left and right hands. Bimanual robots-which also feature bilateral symmetry-should similarly exploit this property to perform tasks with either hand. Unlike humans, who often favor a dominant hand for fine dexterous skills, robots should ideally execute ambidextrous manipulation with equal proficiency. To this end, we introduce SYMDEX (SYMmetric DEXterity), a reinforcement learning framework for ambidextrous bi-manipulation that leverages the robot's inherent bilateral symmetry as an inductive bias. SYMDEX decomposes complex bimanual manipulation tasks into per-hand subtasks and trains dedicated policies for each. By exploiting bilateral symmetry via equivariant neural networks, experience from one arm is inherently leveraged by the opposite arm. We then distill the subtask policies into a global ambidextrous policy that is independent of the hand-task assignment. We evaluate SYMDEX on six challenging simulated manipulation tasks and demonstrate successful real-world deployment on two of them. Our approach strongly outperforms baselines on complex task in which the left and right hands perform different roles. We further demonstrate SYMDEX's scalability by extending it to a four-arm manipulation setup, where our symmetry-aware policies enable effective multi-arm collaboration and coordination. Our results highlight how structural symmetry as inductive bias in policy learning enhances sample efficiency, robustness, and generalization across diverse dexterous manipulation tasks.","authors":["Zechu Li","Yufeng Jin","Daniel Ordonez Apraez","Claudio Semini","Puze Liu","Georgia Chalvatzaki"],"url":"https://arxiv.org/abs/2505.05287"}
{"created":"2025-05-09","title":"PlaceIt3D: Language-Guided Object Placement in Real 3D Scenes","abstract":"We introduce the novel task of Language-Guided Object Placement in Real 3D Scenes. Our model is given a 3D scene's point cloud, a 3D asset, and a textual prompt broadly describing where the 3D asset should be placed. The task here is to find a valid placement for the 3D asset that respects the prompt. Compared with other language-guided localization tasks in 3D scenes such as grounding, this task has specific challenges: it is ambiguous because it has multiple valid solutions, and it requires reasoning about 3D geometric relationships and free space. We inaugurate this task by proposing a new benchmark and evaluation protocol. We also introduce a new dataset for training 3D LLMs on this task, as well as the first method to serve as a non-trivial baseline. We believe that this challenging task and our new benchmark could become part of the suite of benchmarks used to evaluate and compare generalist 3D LLM models.","authors":["Ahmed Abdelreheem","Filippo Aleotti","Jamie Watson","Zawar Qureshi","Abdelrahman Eldesokey","Peter Wonka","Gabriel Brostow","Sara Vicente","Guillermo Garcia-Hernando"],"url":"https://arxiv.org/abs/2505.05288"}
{"created":"2025-05-09","title":"QUIC-Exfil: Exploiting QUIC's Server Preferred Address Feature to Perform Data Exfiltration Attacks","abstract":"The QUIC protocol is now widely adopted by major tech companies and accounts for a significant fraction of today's Internet traffic. QUIC's multiplexing capabilities, encrypted headers, dynamic IP address changes, and encrypted parameter negotiations make the protocol not only more efficient, secure, and censorship-resistant, but also practically unmanageable by firewalls. This opens doors for attackers who may exploit certain traits of the QUIC protocol to perform targeted attacks, such as data exfiltration attacks. Whereas existing data exfiltration techniques, such as TLS and DNS-based exfiltration, can be detected on a firewall level, QUIC-based data exfiltration is more difficult to detect, since changes in IP addresses and ports are inherent to the protocol's normal behavior. To show the feasibility of a QUIC-based data exfiltration attack, we introduce a novel method leveraging the server preferred address feature of the QUIC protocol and, thus, allows an attacker to exfiltrate sensitive data from an infected machine to a malicious server, disguised as a server-side connection migration. The attack is implemented as a proof of concept tool in Rust. We evaluated the performance of five anomaly detection classifiers - Random Forest, Multi-Layer Perceptron, Support Vector Machine, Autoencoder, and Isolation Forest - trained on datasets collected from three network traffic scenarios. The classifiers were trained on over 700K benign and malicious QUIC packets and 786 connection migration events, but were unable to detect the data exfiltration attempts. Furthermore, post-analysis of the traffic captures did not reveal any identifiable fingerprint. As part of our evaluation, we also interviewed five leading firewall vendors and found that, as of today, no major firewall vendor implements functionality capable of distinguishing between benign and malicious QUIC connection migrations.","authors":["Thomas Gr\\\"ubl","Weijie Niu","Jan von der Assen","Burkhard Stiller"],"url":"https://arxiv.org/abs/2505.05292"}
{"created":"2025-05-09","title":"Performance Estimation in Binary Classification Using Calibrated Confidence","abstract":"Model monitoring is a critical component of the machine learning lifecycle, safeguarding against undetected drops in the model's performance after deployment. Traditionally, performance monitoring has required access to ground truth labels, which are not always readily available. This can result in unacceptable latency or render performance monitoring altogether impossible. Recently, methods designed to estimate the accuracy of classifier models without access to labels have shown promising results. However, there are various other metrics that might be more suitable for assessing model performance in many cases. Until now, none of these important metrics has received similar interest from the scientific community. In this work, we address this gap by presenting CBPE, a novel method that can estimate any binary classification metric defined using the confusion matrix. In particular, we choose four metrics from this large family: accuracy, precision, recall, and F$_1$, to demonstrate our method. CBPE treats the elements of the confusion matrix as random variables and leverages calibrated confidence scores of the model to estimate their distributions. The desired metric is then also treated as a random variable, whose full probability distribution can be derived from the estimated confusion matrix. CBPE is shown to produce estimates that come with strong theoretical guarantees and valid confidence intervals.","authors":["Juhani Kivim\\\"aki","Jakub Bia{\\l}ek","Wojtek Kuberski","Jukka K. Nurminen"],"url":"https://arxiv.org/abs/2505.05295"}
{"created":"2025-05-09","title":"Toward Reasonable Parrots: Why Large Language Models Should Argue with Us by Design","abstract":"In this position paper, we advocate for the development of conversational technology that is inherently designed to support and facilitate argumentative processes. We argue that, at present, large language models (LLMs) are inadequate for this purpose, and we propose an ideal technology design aimed at enhancing argumentative skills. This involves re-framing LLMs as tools to exercise our critical thinking rather than replacing them. We introduce the concept of 'reasonable parrots' that embody the fundamental principles of relevance, responsibility, and freedom, and that interact through argumentative dialogical moves. These principles and moves arise out of millennia of work in argumentation theory and should serve as the starting point for LLM-based technology that incorporates basic principles of argumentation.","authors":["Elena Musi","Nadin Kokciyan","Khalid Al-Khatib","Davide Ceolin","Emmanuelle Dietz","Klara Gutekunst","Annette Hautli-Janisz","Cristian Manuel Santiba\\~nez Ya\\~nez","Jodi Schneider","Jonas Scholz","Cor Steging","Jacky Visser","Henning Wachsmuth"],"url":"https://arxiv.org/abs/2505.05298"}
{"created":"2025-05-09","title":"Optimal Microgrid Sizing of Offshore Renewable Energy Sources for Offshore Platforms and Coastal Communities","abstract":"The global energy landscape is undergoing a transformative shift towards renewable energy and advanced storage solutions, driven by the urgent need for sustainable and resilient power systems. Isolated offshore communities, such as islands and offshore platforms, which traditionally rely on mainland grids or diesel generators, stand to gain significantly from renewable energy integration. Promising offshore renewable technologies include wind turbines, wave and tidal energy converters, and floating photovoltaic systems, paired with a storage solution like battery energy storage systems. This paper introduces a renewable energy microgrid optimizer (REMO), a tool designed to identify the optimal sizes of renewable generation and storage resources for offshore microgrids. A key challenge in such models is accurately accounting for battery degradation costs. To address this, the REMO model integrates a deep neural network-based battery degradation (DNN-BD) module, which factors in variables like ambient temperature, charge/discharge rates, state of charge, depth of discharge and battery health. Simulations on six test regions demonstrate that the REMO-DNN-BD approach minimizes lifetime energy costs while maintaining high reliability and sustainability, making it a viable design solution for offshore microgrid systems.","authors":["Ann Mary Toms","Xingpeng Li","Kaushik Rajashekara"],"url":"https://arxiv.org/abs/2505.05305"}
{"created":"2025-05-09","title":"The calculus of neo-Peircean relations","abstract":"The calculus of relations was introduced by De Morgan and Peirce during the second half of the 19th century. Later developments on quantification theory by Frege and Peirce himself, paved the way to what is known today as first-order logic, causing the calculus of relations to be long forgotten. This was until 1941, when Tarski raised the question on the existence of a complete axiomatisation for it. This question found only negative answers: there is no finite axiomatisation for the calculus of relations and many of its fragments, as shown later by several no-go theorems. In this paper we show that -- by moving from traditional syntax (cartesian) to a diagrammatic one (monoidal) -- it is possible to have complete axiomatisations for the full calculus. The no-go theorems are circumvented by the fact that our calculus, named the calculus of neo-Peircean relations, is more expressive than the calculus of relations and, actually, as expressive as first-order logic. The axioms are obtained by combining two well known categorical structures: cartesian and linear bicategories.","authors":["Filippo Bonchi","Alessandro Di Giorgio","Nathan Haydon","Pawel Sobocinski"],"url":"https://arxiv.org/abs/2505.05306"}
{"created":"2025-05-09","title":"PRE-Mamba: A 4D State Space Model for Ultra-High-Frequent Event Camera Deraining","abstract":"Event cameras excel in high temporal resolution and dynamic range but suffer from dense noise in rainy conditions. Existing event deraining methods face trade-offs between temporal precision, deraining effectiveness, and computational efficiency. In this paper, we propose PRE-Mamba, a novel point-based event camera deraining framework that fully exploits the spatiotemporal characteristics of raw event and rain. Our framework introduces a 4D event cloud representation that integrates dual temporal scales to preserve high temporal precision, a Spatio-Temporal Decoupling and Fusion module (STDF) that enhances deraining capability by enabling shallow decoupling and interaction of temporal and spatial information, and a Multi-Scale State Space Model (MS3M) that captures deeper rain dynamics across dual-temporal and multi-spatial scales with linear computational complexity. Enhanced by frequency-domain regularization, PRE-Mamba achieves superior performance (0.95 SR, 0.91 NR, and 0.4s/M events) with only 0.26M parameters on EventRain-27K, a comprehensive dataset with labeled synthetic and real-world sequences. Moreover, our method generalizes well across varying rain intensities, viewpoints, and even snowy conditions.","authors":["Ciyu Ruan","Ruishan Guo","Zihang Gong","Jingao Xu","Wenhan Yang","Xinlei Chen"],"url":"https://arxiv.org/abs/2505.05307"}
{"created":"2025-05-09","title":"Localization and path following for an autonomous e-scooter","abstract":"In order to mitigate economical, ecological, and societal challenges in electric scooter (e-scooter) sharing systems, we develop an autonomous e-scooter prototype. Our vision is to design a fully autonomous prototype that can find its way to the next parking spot, high-demand area, or charging station. In this work, we propose a path following solution to enable localization and navigation in an urban environment with a provided path to follow. We design a closed-loop architecture that solves the localization and path following problem while allowing the e-scooter to maintain its balance with a previously developed reaction wheel mechanism. Our approach facilitates state and input constraints, e.g., adhering to the path width, while remaining executable on a Raspberry Pi 5. We demonstrate the efficacy of our approach in a real-world experiment on our prototype.","authors":["David Meister","Robin Str\\\"asser","Felix Br\\\"andle","Marc Seidel","Benno Bassler","Nathan Gerber","Jan Kautz","Elena Rommel","Frank Allg\\\"ower"],"url":"https://arxiv.org/abs/2505.05314"}
{"created":"2025-05-09","title":"Scalable Chain of Thoughts via Elastic Reasoning","abstract":"Large reasoning models (LRMs) have achieved remarkable progress on complex tasks by generating extended chains of thought (CoT). However, their uncontrolled output lengths pose significant challenges for real-world deployment, where inference-time budgets on tokens, latency, or compute are strictly constrained. We propose Elastic Reasoning, a novel framework for scalable chain of thoughts that explicitly separates reasoning into two phases--thinking and solution--with independently allocated budgets. At test time, Elastic Reasoning prioritize that completeness of solution segments, significantly improving reliability under tight resource constraints. To train models that are robust to truncated thinking, we introduce a lightweight budget-constrained rollout strategy, integrated into GRPO, which teaches the model to reason adaptively when the thinking process is cut short and generalizes effectively to unseen budget constraints without additional training. Empirical results on mathematical (AIME, MATH500) and programming (LiveCodeBench, Codeforces) benchmarks demonstrate that Elastic Reasoning performs robustly under strict budget constraints, while incurring significantly lower training cost than baseline methods. Remarkably, our approach also produces more concise and efficient reasoning even in unconstrained settings. Elastic Reasoning offers a principled and practical solution to the pressing challenge of controllable reasoning at scale.","authors":["Yuhui Xu","Hanze Dong","Lei Wang","Doyen Sahoo","Junnan Li","Caiming Xiong"],"url":"https://arxiv.org/abs/2505.05315"}
{"created":"2025-05-09","title":"CottonSim: Development of an autonomous visual-guided robotic cotton-picking system in the Gazebo","abstract":"In this study, an autonomous visual-guided robotic cotton-picking system, built on a Clearpath's Husky robot platform and the Cotton-Eye perception system, was developed in the Gazebo robotic simulator. Furthermore, a virtual cotton farm was designed and developed as a Robot Operating System (ROS 1) package to deploy the robotic cotton picker in the Gazebo environment for simulating autonomous field navigation. The navigation was assisted by the map coordinates and an RGB-depth camera, while the ROS navigation algorithm utilized a trained YOLOv8n-seg model for instance segmentation. The model achieved a desired mean Average Precision (mAP) of 85.2%, a recall of 88.9%, and a precision of 93.0% for scene segmentation. The developed ROS navigation packages enabled our robotic cotton-picking system to autonomously navigate through the cotton field using map-based and GPS-based approaches, visually aided by a deep learning-based perception system. The GPS-based navigation approach achieved a 100% completion rate (CR) with a threshold of 5 x 10^-6 degrees, while the map-based navigation approach attained a 96.7% CR with a threshold of 0.25 m. This study establishes a fundamental baseline of simulation for future agricultural robotics and autonomous vehicles in cotton farming and beyond. CottonSim code and data are released to the research community via GitHub: https://github.com/imtheva/CottonSim","authors":["Thevathayarajh Thayananthan","Xin Zhang","Yanbo Huang","Jingdao Chen","Nuwan K. Wijewardane","Vitor S. Martins","Gary D. Chesser","Christopher T. Goodin"],"url":"https://arxiv.org/abs/2505.05317"}
{"created":"2025-05-09","title":"Mapping User Trust in Vision Language Models: Research Landscape, Challenges, and Prospects","abstract":"The rapid adoption of Vision Language Models (VLMs), pre-trained on large image-text and video-text datasets, calls for protecting and informing users about when to trust these systems. This survey reviews studies on trust dynamics in user-VLM interactions, through a multi-disciplinary taxonomy encompassing different cognitive science capabilities, collaboration modes, and agent behaviours. Literature insights and findings from a workshop with prospective VLM users inform preliminary requirements for future VLM trust studies.","authors":["Agnese Chiatti","Sara Bernardini","Lara Shibelski Godoy Piccolo","Viola Schiaffonati","Matteo Matteucci"],"url":"https://arxiv.org/abs/2505.05318"}
{"created":"2025-05-09","title":"Feature-Augmented Deep Networks for Multiscale Building Segmentation in High-Resolution UAV and Satellite Imagery","abstract":"Accurate building segmentation from high-resolution RGB imagery remains challenging due to spectral similarity with non-building features, shadows, and irregular building geometries. In this study, we present a comprehensive deep learning framework for multiscale building segmentation using RGB aerial and satellite imagery with spatial resolutions ranging from 0.4m to 2.7m. We curate a diverse, multi-sensor dataset and introduce feature-augmented inputs by deriving secondary representations including Principal Component Analysis (PCA), Visible Difference Vegetation Index (VDVI), Morphological Building Index (MBI), and Sobel edge filters from RGB channels. These features guide a Res-U-Net architecture in learning complex spatial patterns more effectively. We also propose training policies incorporating layer freezing, cyclical learning rates, and SuperConvergence to reduce training time and resource usage. Evaluated on a held-out WorldView-3 image, our model achieves an overall accuracy of 96.5%, an F1-score of 0.86, and an Intersection over Union (IoU) of 0.80, outperforming existing RGB-based benchmarks. This study demonstrates the effectiveness of combining multi-resolution imagery, feature augmentation, and optimized training strategies for robust building segmentation in remote sensing applications.","authors":["Chintan B. Maniyar","Minakshi Kumar","Gengchen Mai"],"url":"https://arxiv.org/abs/2505.05321"}
{"created":"2025-05-09","title":"Approximation-free Control for Signal Temporal Logic Specifications using Spatiotemporal Tubes","abstract":"This paper presents a spatiotemporal tube (STT)-based control framework for satisfying Signal Temporal Logic (STL) specifications in unknown control-affine systems. We formulate STL constraints as a robust optimization problem (ROP) and recast it as a scenario optimization program (SOP) to construct STTs with formal correctness guarantees. We also propose a closed-form control law that operates independently of the system dynamics, and ensures the system trajectory evolves within the STTs, thereby satisfying the STL specifications. The proposed approach is validated through case studies and comparisons with state-of-the-art methods, demonstrating superior computational efficiency, trajectory quality, and applicability to complex STL tasks.","authors":["Ratnangshu Das","Subhodeep Choudhury","Pushpak Jagtap"],"url":"https://arxiv.org/abs/2505.05323"}
{"created":"2025-05-09","title":"Advanced Stock Market Prediction Using Long Short-Term Memory Networks: A Comprehensive Deep Learning Framework","abstract":"Predicting stock market movements remains a persistent challenge due to the inherently volatile, non-linear, and stochastic nature of financial time series data. This paper introduces a deep learning-based framework employing Long Short-Term Memory (LSTM) networks to forecast the closing stock prices of major technology firms: Apple, Google, Microsoft, and Amazon, listed on NASDAQ. Historical data was sourced from Yahoo Finance and processed using normalization and feature engineering techniques. The proposed model achieves a Mean Absolute Percentage Error (MAPE) of 2.72 on unseen test data, significantly outperforming traditional models like ARIMA. To further enhance predictive accuracy, sentiment scores were integrated using real-time news articles and social media data, analyzed through the VADER sentiment analysis tool. A web application was also developed to provide real-time visualizations of stock price forecasts, offering practical utility for both individual and institutional investors. This research demonstrates the strength of LSTM networks in modeling complex financial sequences and presents a novel hybrid approach combining time series modeling with sentiment analysis.","authors":["Rajneesh Chaudhary"],"url":"https://arxiv.org/abs/2505.05325"}
{"created":"2025-05-09","title":"TS-Detector : Detecting Feature Toggle Usage Patterns","abstract":"Feature toggles enable developers to control feature states, allowing the features to be released to a limited group of users while preserving overall software functionality. The absence of comprehensive best practices for feature toggle usage often results in improper implementation, causing code quality issues. Although certain feature toggle usage patterns are prone to toggle smells, there is no tool as of today for software engineers to detect toggle usage patterns from the source code. This paper presents a tool TS-Detector to detect five different toggle usage patterns across ten open-source software projects in six different programming languages. We conducted a manual evaluation and results show that the true positive rates of detecting Spread, Nested, and Dead toggles are 80%, 86.4%, and 66.6% respectively, and the true negative rate of Mixed and Enum usages was 100%. The tool can be downloaded from its GitHub repository and can be used following the instructions provided there.","authors":["Tajmilur Rahman","Mengzhe Fei","Tushar Sharma","Chanchal Roy"],"url":"https://arxiv.org/abs/2505.05326"}
{"created":"2025-05-09","title":"ICon: In-Context Contribution for Automatic Data Selection","abstract":"Data selection for instruction tuning is essential for improving the performance of Large Language Models (LLMs) and reducing training cost. However, existing automated selection methods either depend on computationally expensive gradient-based measures or manually designed heuristics, which may fail to fully exploit the intrinsic attributes of data. In this paper, we propose In-context Learning for Contribution Measurement (ICon), a novel gradient-free method that takes advantage of the implicit fine-tuning nature of in-context learning (ICL) to measure sample contribution without gradient computation or manual indicators engineering. ICon offers a computationally efficient alternative to gradient-based methods and reduces human inductive bias inherent in heuristic-based approaches. ICon comprises three components and identifies high-contribution data by assessing performance shifts under implicit learning through ICL. Extensive experiments on three LLMs across 12 benchmarks and 5 pairwise evaluation sets demonstrate the effectiveness of ICon. Remarkably, on LLaMA3.1-8B, models trained on 15% of ICon-selected data outperform full datasets by 5.42% points and exceed the best performance of widely used selection methods by 2.06% points. We further analyze high-contribution samples selected by ICon, which show both diverse tasks and appropriate difficulty levels, rather than just the hardest ones.","authors":["Yixin Yang","Qingxiu Dong","Linli Yao","Fangwei Zhu","Zhifang Sui"],"url":"https://arxiv.org/abs/2505.05327"}
{"created":"2025-05-09","title":"SUUM: Timestamp-based Nakamoto-style Blockchains are Vulnerable","abstract":"We introduce two advanced attack strategies, the Unrestricted Uncle Maker (UUM) Attack and the Staircase-Unrestricted Uncle Maker (SUUM) Attack, which fundamentally threaten the security of timestamp-based Nakamoto-style blockchains by inflicting permanent systemic harm. Unlike prior work that merely enhances adversarial rewards, these attacks exploit vulnerabilities in timestamp manipulation and fork selection rules to irreversibly destabilize blockchain fairness and incentive mechanisms. Specifically, the SUUM attack enables adversaries to persistently launch attacks at zero cost, eliminating constraints on block withholding and risk-free conditions, while systematically maximizing rewards through coordinated timestamp adjustments and strategic block release.","authors":["Junjie Hu","Na Ruan"],"url":"https://arxiv.org/abs/2505.05328"}
{"created":"2025-05-09","title":"Aesthetics Without Semantics","abstract":"While it is easy for human observers to judge an image as beautiful or ugly, aesthetic decisions result from a combination of entangled perceptual and cognitive (semantic) factors, making the understanding of aesthetic judgements particularly challenging from a scientific point of view. Furthermore, our research shows a prevailing bias in current databases, which include mostly beautiful images, further complicating the study and prediction of aesthetic responses. We address these limitations by creating a database of images with minimal semantic content and devising, and next exploiting, a method to generate images on the ugly side of aesthetic valuations. The resulting Minimum Semantic Content (MSC) database consists of a large and balanced collection of 10,426 images, each evaluated by 100 observers. We next use established image metrics to demonstrate how augmenting an image set biased towards beautiful images with ugly images can modify, or even invert, an observed relationship between image features and aesthetics valuation. Taken together, our study reveals that works in empirical aesthetics attempting to link image content and aesthetic judgements may magnify, underestimate, or simply miss interesting effects due to a limitation of the range of aesthetic values they consider.","authors":["C. Alejandro Parraga (Comp. Sci. Dept.","Engineering School","Universitat Aut\\`onoma de Barcelona","Computer Vision Centre","Campus UAB","Bellaterra","08193","Barcelona","Spain)","Olivier Penacchio (Comp. Sci. Dept.","Engineering School","Universitat Aut\\`onoma de Barcelona","School of Psychology and Neuroscience","University of St Andrews","St Andrews","Fife KY16 9JP","United Kingdom)","Marcos Mu\\v{n}oz Gonzalez (Comp. Sci. Dept.","Engineering School","Universitat Aut\\`onoma de Barcelona)","Bogdan Raducanu (Computer Vision Centre","Campus UAB","Bellaterra","08193","Barcelona","Spain)","Xavier Otazu (Comp. Sci. Dept.","Engineering School","Universitat Aut\\`onoma de Barcelona","Computer Vision Centre","Campus UAB","Bellaterra","08193","Barcelona","Spain)"],"url":"https://arxiv.org/abs/2505.05331"}
{"created":"2025-05-09","title":"FLAM: Frame-Wise Language-Audio Modeling","abstract":"Recent multi-modal audio-language models (ALMs) excel at text-audio retrieval but struggle with frame-wise audio understanding. Prior works use temporal-aware labels or unsupervised training to improve frame-wise capabilities, but they still lack fine-grained labeling capability to pinpoint when an event occurs. While traditional sound event detection models can precisely localize events, they are limited to pre-defined categories, making them ineffective for real-world scenarios with out-of-distribution events. In this work, we introduce FLAM, an open-vocabulary contrastive audio-language model capable of localizing specific sound events. FLAM employs a memory-efficient and calibrated frame-wise objective with logit adjustment to address spurious correlations, such as event dependencies and label imbalances during training. To enable frame-wise supervision, we leverage a large-scale dataset with diverse audio events, LLM-generated captions and simulation. Experimental results and case studies demonstrate that FLAM significantly improves the open-vocabulary localization capability while maintaining strong performance in global retrieval and downstream tasks.","authors":["Yusong Wu","Christos Tsirigotis","Ke Chen","Cheng-Zhi Anna Huang","Aaron Courville","Oriol Nieto","Prem Seetharaman","Justin Salamon"],"url":"https://arxiv.org/abs/2505.05335"}
{"created":"2025-05-09","title":"Progressive Inertial Poser: Progressive Real-Time Kinematic Chain Estimation for 3D Full-Body Pose from Three IMU Sensors","abstract":"The motion capture system that supports full-body virtual representation is of key significance for virtual reality. Compared to vision-based systems, full-body pose estimation from sparse tracking signals is not limited by environmental conditions or recording range. However, previous works either face the challenge of wearing additional sensors on the pelvis and lower-body or rely on external visual sensors to obtain global positions of key joints. To improve the practicality of the technology for virtual reality applications, we estimate full-body poses using only inertial data obtained from three Inertial Measurement Unit (IMU) sensors worn on the head and wrists, thereby reducing the complexity of the hardware system. In this work, we propose a method called Progressive Inertial Poser (ProgIP) for human pose estimation, which combines neural network estimation with a human dynamics model, considers the hierarchical structure of the kinematic chain, and employs a multi-stage progressive network estimation with increased depth to reconstruct full-body motion in real time. The encoder combines Transformer Encoder and bidirectional LSTM (TE-biLSTM) to flexibly capture the temporal dependencies of the inertial sequence, while the decoder based on multi-layer perceptrons (MLPs) transforms high-dimensional features and accurately projects them onto Skinned Multi-Person Linear (SMPL) model parameters. Quantitative and qualitative experimental results on multiple public datasets show that our method outperforms state-of-the-art methods with the same inputs, and is comparable to recent works using six IMU sensors.","authors":["Zunjie Zhu","Yan Zhao","Yihan Hu","Guoxiang Wang","Hai Qiu","Bolun Zheng","Chenggang Yan","Feng Xu"],"url":"https://arxiv.org/abs/2505.05336"}
{"created":"2025-05-09","title":"Hearing and Seeing Through CLIP: A Framework for Self-Supervised Sound Source Localization","abstract":"Large-scale vision-language models demonstrate strong multimodal alignment and generalization across diverse tasks. Among them, CLIP stands out as one of the most successful approaches. In this work, we extend the application of CLIP to sound source localization, proposing a self-supervised method operates without explicit text input. We introduce a framework that maps audios into tokens compatible with CLIP's text encoder, producing audio-driven embeddings. These embeddings are used to generate sounding region masks, from which visual features are extracted and aligned with the audio embeddings through a contrastive audio-visual correspondence objective. Our findings show that alignment knowledge of pre-trained multimodal foundation model enables our method to generate more complete and compact localization for sounding objects. We further propose an LLM-guided extension that distills object-aware audio-visual scene understanding into the model during training to enhance alignment. Extensive experiments across five diverse tasks demonstrate that our method, in all variants, outperforms state-of-the-art approaches and achieves strong generalization in zero-shot settings.","authors":["Sooyoung Park","Arda Senocak","Joon Son Chung"],"url":"https://arxiv.org/abs/2505.05343"}
{"created":"2025-05-09","title":"Creative Telescoping","abstract":"These notes on creative telescoping are based on a series of lectures at the Institut Henri Poincare in November and December 2023.","authors":["Shaoshi Chen","Manuel Kauers","Christoph Koutschan"],"url":"https://arxiv.org/abs/2505.05345"}
{"created":"2025-05-09","title":"InfTDA: A Simple TopDown Mechanism for Hierarchical Differentially Private Counting Queries","abstract":"This paper extends $\\texttt{InfTDA}$, a mechanism proposed in (Boninsegna, Silvestri, PETS 2025) for mobility datasets with origin and destination trips, in a general setting. The algorithm presented in this paper works for any dataset of $d$ categorical features and produces a differentially private synthetic dataset that answers all hierarchical queries, a special case of marginals, each with bounded maximum absolute error. The algorithm builds upon the TopDown mechanism developed for the 2020 US Census.","authors":["Fabrizio Boninsegna"],"url":"https://arxiv.org/abs/2505.05347"}
{"created":"2025-05-09","title":"Weighted Envy-Freeness Revisited: Indivisible Resource and House Allocations","abstract":"Envy-Freeness is one of the most fundamental and important concepts in fair allocation. Some recent studies have focused on the concept of weighted envy-freeness. Under this concept, each agent is assigned a weight, and their valuations are divided by their weights when assessing fairness. This concept can promote more fairness in some scenarios. But on the other hand, experimental research has shown that this weighted envy-freeness significantly reduces the likelihood of fair allocations. When we must allocate the resources, we may propose fairness concepts with lower requirements that are potentially more feasible to implement. In this paper, we revisit weighted envy-freeness and propose a new concept called SumAvg-envy-freeness, which substantially increases the existence of fair allocations. This new concept can be seen as a complement of the normal weighted envy-fairness. Furthermore, we systematically study the computational complexity of finding fair allocations under the old and new weighted fairness concepts in two types of classic problems: Indivisible Resource Allocation and House Allocation. Our study provides a comprehensive characterization of various properties of weighted envy-freeness.","authors":["Yuxi Liu","Mingyu Xiao"],"url":"https://arxiv.org/abs/2505.05353"}
{"created":"2025-05-09","title":"Nearly Optimal Sample Complexity for Learning with Label Proportions","abstract":"We investigate Learning from Label Proportions (LLP), a partial information setting where examples in a training set are grouped into bags, and only aggregate label values in each bag are available. Despite the partial observability, the goal is still to achieve small regret at the level of individual examples. We give results on the sample complexity of LLP under square loss, showing that our sample complexity is essentially optimal. From an algorithmic viewpoint, we rely on carefully designed variants of Empirical Risk Minimization, and Stochastic Gradient Descent algorithms, combined with ad hoc variance reduction techniques. On one hand, our theoretical results improve in important ways on the existing literature on LLP, specifically in the way the sample complexity depends on the bag size. On the other hand, we validate our algorithmic solutions on several datasets, demonstrating improved empirical performance (better accuracy for less samples) against recent baselines.","authors":["Robert Busa-Fekete","Travis Dick","Claudio Gentile","Haim Kaplan","Tomer Koren","Uri Stemmer"],"url":"https://arxiv.org/abs/2505.05355"}
{"created":"2025-05-09","title":"Time of the Flight of the Gaussians: Optimizing Depth Indirectly in Dynamic Radiance Fields","abstract":"We present a method to reconstruct dynamic scenes from monocular continuous-wave time-of-flight (C-ToF) cameras using raw sensor samples that achieves similar or better accuracy than neural volumetric approaches and is 100x faster. Quickly achieving high-fidelity dynamic 3D reconstruction from a single viewpoint is a significant challenge in computer vision. In C-ToF radiance field reconstruction, the property of interest-depth-is not directly measured, causing an additional challenge. This problem has a large and underappreciated impact upon the optimization when using a fast primitive-based scene representation like 3D Gaussian splatting, which is commonly used with multi-view data to produce satisfactory results and is brittle in its optimization otherwise. We incorporate two heuristics into the optimization to improve the accuracy of scene geometry represented by Gaussians. Experimental results show that our approach produces accurate reconstructions under constrained C-ToF sensing conditions, including for fast motions like swinging baseball bats. https://visual.cs.brown.edu/gftorf","authors":["Runfeng Li","Mikhail Okunev","Zixuan Guo","Anh Ha Duong","Christian Richardt","Matthew O'Toole","James Tompkin"],"url":"https://arxiv.org/abs/2505.05356"}
{"created":"2025-05-09","title":"Empirical Analysis of Transaction Conflicts in Ethereum and Solana for Parallel Execution","abstract":"This paper presents a comprehensive analysis of historical data across two popular blockchain networks: Ethereum and Solana. Our study focuses on two key aspects: transaction conflicts and the maximum theoretical parallelism within historical blocks. We aim to quantify the degree of transaction parallelism and assess how effectively it can be exploited by systematically examining block-level characteristics, both within individual blocks and across different historical periods. In particular, this study is the first of its kind to leverage historical transactional workloads to evaluate transactional conflict patterns. By offering a structured approach to analyzing these conflicts, our research provides valuable insights and an empirical basis for developing more efficient parallel execution techniques in the Ethereum and Solana Virtual Machines. Our empirical analysis reveals that Ethereum blocks frequently achieve high independence$-$over 50\\% in more than 50\\% of blocks, while Solana blocks contain longer conflict chains, comprising $\\sim$59\\% of the block size compared to $\\sim$18\\% in Ethereum, reflecting fundamentally different parallel execution dynamics.","authors":["Parwat Singh Anjana","Srivatsan Ravi"],"url":"https://arxiv.org/abs/2505.05358"}
{"created":"2025-05-09","title":"DSDrive: Distilling Large Language Model for Lightweight End-to-End Autonomous Driving with Unified Reasoning and Planning","abstract":"We present DSDrive, a streamlined end-to-end paradigm tailored for integrating the reasoning and planning of autonomous vehicles into a unified framework. DSDrive leverages a compact LLM that employs a distillation method to preserve the enhanced reasoning capabilities of a larger-sized vision language model (VLM). To effectively align the reasoning and planning tasks, a waypoint-driven dual-head coordination module is further developed, which synchronizes dataset structures, optimization objectives, and the learning process. By integrating these tasks into a unified framework, DSDrive anchors on the planning results while incorporating detailed reasoning insights, thereby enhancing the interpretability and reliability of the end-to-end pipeline. DSDrive has been thoroughly tested in closed-loop simulations, where it performs on par with benchmark models and even outperforms in many key metrics, all while being more compact in size. Additionally, the computational efficiency of DSDrive (as reflected in its time and memory requirements during inference) has been significantly enhanced. Evidently thus, this work brings promising aspects and underscores the potential of lightweight systems in delivering interpretable and efficient solutions for AD.","authors":["Wenru Liu","Pei Liu","Jun Ma"],"url":"https://arxiv.org/abs/2505.05360"}
{"created":"2025-05-09","title":"Finite element approximation for quantitative photoacoustic tomography in a diffusive regime","abstract":"In this paper, we focus on the numerical analysis of quantitative photoacoustic tomography. Our goal is to reconstruct the optical coefficients, i.e., the diffusion and absorption coefficients, using multiple internal observational data. The foundation of our numerical algorithm lies in solving an inverse diffusivity problem and a direct problem associated with elliptic equations. The stability of the inverse problem depends critically on a non-zero condition in the internal observations, a condition that can be met using randomly chosen boundary excitation data. Utilizing these randomly generated boundary data, we implement an output least squares formulation combined with finite element discretization to solve the inverse problem. In this scenario, we provide a rigorous error estimate in $L^2(\\Omega)$ norm for the numerical reconstruction using a weighted energy estimate, inspired by the analysis of a newly proposed conditional stability result. The resulting error estimate serves as a valuable guide for selecting appropriate regularization parameters and discretization mesh sizes according to the noise levels present in the data. Several numerical experiments are presented to support our theoretical results and illustrate the effectiveness of our numerical scheme.","authors":["Giovanni S. Alberti","Siyu Cen","Zhi Zhou"],"url":"https://arxiv.org/abs/2505.05361"}
{"created":"2025-05-09","title":"Modelling and Verifying Neuronal Archetypes in Coq","abstract":"Formal verification has become increasingly important because of the kinds of guarantees that it can provide for software systems. Verification of models of biological and medical systems is a promising application of formal verification. Human neural networks have recently been emulated and studied as a biological system. In this paper, we provide a model of some crucial neuronal circuits, called \"archetypes\", in the Coq Proof Assistant and prove properties concerning their dynamic behavior. Understanding the behavior of these modules is crucial because they constitute the elementary building blocks of bigger neuronal circuits. We consider seven fundamental archetypes (simple series, series with multiple outputs, parallel composition, positive loop, negative loop, inhibition of a behavior, and contralateral inhibition), and prove an important representative property for six of them. In building up to our model of archetypes, we also provide a general model of \"neuronal circuits\", and prove a variety of general properties about neurons and circuits. In addition, we have defined our model with a longer term goal of modelling the composition of basic archetypes into larger networks, and structured our libraries with definitions and lemmas useful for proving the properties in this paper as well as those to be proved as future work.","authors":["Abdorrahim Bahrami","R\\'ebecca Zucchini","Elisabetta De Maria","Amy Felty"],"url":"https://arxiv.org/abs/2505.05362"}
{"created":"2025-05-09","title":"SDR-RDMA: Software-Defined Reliability Architecture for Planetary Scale RDMA Communication","abstract":"RDMA is vital for efficient distributed training across datacenters, but millisecond-scale latencies complicate the design of its reliability layer. We show that depending on long-haul link characteristics, such as drop rate, distance and bandwidth, the widely used Selective Repeat algorithm can be inefficient, warranting alternatives like Erasure Coding. To enable such alternatives on existing hardware, we propose SDR-RDMA, a software-defined reliability stack for RDMA. Its core is a lightweight SDR SDK that extends standard point-to-point RDMA semantics -- fundamental to AI networking stacks -- with a receive buffer bitmap. SDR bitmap enables partial message completion to let applications implement custom reliability schemes tailored to specific deployments, while preserving zero-copy RDMA benefits. By offloading the SDR backend to NVIDIA's Data Path Accelerator (DPA), we achieve line-rate performance, enabling efficient inter-datacenter communication and advancing reliability innovation for intra-datacenter training.","authors":["Mikhail Khalilov","Siyuan Shen","Marcin Chrapek","Tiancheng Chen","Kenji Nakano","Peter-Jan Gootzen","Salvatore Di Girolamo","Rami Nudelman","Gil Bloch","Sreevatsa Anantharamu","Mahmoud Elhaddad","Jithin Jose","Abdul Kabbani","Scott Moe","Konstantin Taranov","Zhuolong Yu","Jie Zhang","Nicola Mazzoletti","Torsten Hoefler"],"url":"https://arxiv.org/abs/2505.05366"}
{"created":"2025-05-09","title":"Joint Super-Resolution and Segmentation for 1-m Impervious Surface Area Mapping in China's Yangtze River Economic Belt","abstract":"We propose a novel joint framework by integrating super-resolution and segmentation, called JointSeg, which enables the generation of 1-meter ISA maps directly from freely available Sentinel-2 imagery. JointSeg was trained on multimodal cross-resolution inputs, offering a scalable and affordable alternative to traditional approaches. This synergistic design enables gradual resolution enhancement from 10m to 1m while preserving fine-grained spatial textures, and ensures high classification fidelity through effective cross-scale feature fusion. This method has been successfully applied to the Yangtze River Economic Belt (YREB), a region characterized by complex urban-rural patterns and diverse topography. As a result, a comprehensive ISA mapping product for 2021, referred to as ISA-1, was generated, covering an area of over 2.2 million square kilometers. Quantitative comparisons against the 10m ESA WorldCover and other benchmark products reveal that ISA-1 achieves an F1-score of 85.71%, outperforming bilinear-interpolation-based segmentation by 9.5%, and surpassing other ISA datasets by 21.43%-61.07%. In densely urbanized areas (e.g., Suzhou, Nanjing), ISA-1 reduces ISA overestimation through improved discrimination of green spaces and water bodies. Conversely, in mountainous regions (e.g., Ganzi, Zhaotong), it identifies significantly more ISA due to its enhanced ability to detect fragmented anthropogenic features such as rural roads and sparse settlements, demonstrating its robustness across diverse landscapes. Moreover, we present biennial ISA maps from 2017 to 2023, capturing spatiotemporal urbanization dynamics across representative cities. The results highlight distinct regional growth patterns: rapid expansion in upstream cities, moderate growth in midstream regions, and saturation in downstream metropolitan areas.","authors":["Jie Deng","Danfeng Hong","Chenyu Li","Naoto Yokoya"],"url":"https://arxiv.org/abs/2505.05367"}
{"created":"2025-05-09","title":"Walrus: An Efficient Decentralized Storage Network","abstract":"Decentralized storage systems face a fundamental trade-off between replication overhead, recovery efficiency, and security guarantees. Current approaches either rely on full replication, incurring substantial storage costs, or employ trivial erasure coding schemes that struggle with efficient recovery especially under high storage-node churn. We present Walrus, a novel decentralized blob storage system that addresses these limitations through multiple technical innovations. At the core of Walrus is RedStuff, a two-dimensional erasure coding protocol that achieves high security with only 4.5x replication factor, while enabling self-healing recovery that requires bandwidth proportional to only the lost data $(O(|blob|/n)$ versus $O(|blob|)$ in traditional systems). Crucially, RedStuff is the first protocol to support storage challenges in asynchronous networks, preventing adversaries from exploiting network delays to pass verification without actually storing data. Walrus also introduces a novel multi-stage epoch change protocol that efficiently handles storage node churn while maintaining uninterrupted availability during committee transitions. Our system incorporates authenticated data structures to defend against malicious clients and ensures data consistency throughout storage and retrieval processes. Experimental evaluation demonstrates that Walrus achieves practical performance at scale, making it suitable for a wide range of decentralized applications requiring high-integrity, available blob storage with reasonable overhead.","authors":["George Danezis","Giacomo Giuliari","Eleftherios Kokoris Kogias","Markus Legner","Jean-Pierre Smith","Alberto Sonnino","Karl W\\\"ust"],"url":"https://arxiv.org/abs/2505.05370"}
{"created":"2025-05-09","title":"Threshold Modulation for Online Test-Time Adaptation of Spiking Neural Networks","abstract":"Recently, spiking neural networks (SNNs), deployed on neuromorphic chips, provide highly efficient solutions on edge devices in different scenarios. However, their ability to adapt to distribution shifts after deployment has become a crucial challenge. Online test-time adaptation (OTTA) offers a promising solution by enabling models to dynamically adjust to new data distributions without requiring source data or labeled target samples. Nevertheless, existing OTTA methods are largely designed for traditional artificial neural networks and are not well-suited for SNNs. To address this gap, we propose a low-power, neuromorphic chip-friendly online test-time adaptation framework, aiming to enhance model generalization under distribution shifts. The proposed approach is called Threshold Modulation (TM), which dynamically adjusts the firing threshold through neuronal dynamics-inspired normalization, being more compatible with neuromorphic hardware. Experimental results on benchmark datasets demonstrate the effectiveness of this method in improving the robustness of SNNs against distribution shifts while maintaining low computational cost. The proposed method offers a practical solution for online test-time adaptation of SNNs, providing inspiration for the design of future neuromorphic chips. The demo code is available at github.com/NneurotransmitterR/TM-OTTA-SNN.","authors":["Kejie Zhao","Wenjia Hua","Aiersi Tuerhong","Luziwei Leng","Yuxin Ma","Qinghua Guo"],"url":"https://arxiv.org/abs/2505.05375"}
{"created":"2025-05-09","title":"GeomHair: Reconstruction of Hair Strands from Colorless 3D Scans","abstract":"We propose a novel method that reconstructs hair strands directly from colorless 3D scans by leveraging multi-modal hair orientation extraction. Hair strand reconstruction is a fundamental problem in computer vision and graphics that can be used for high-fidelity digital avatar synthesis, animation, and AR/VR applications. However, accurately recovering hair strands from raw scan data remains challenging due to human hair's complex and fine-grained structure. Existing methods typically rely on RGB captures, which can be sensitive to the environment and can be a challenging domain for extracting the orientation of guiding strands, especially in the case of challenging hairstyles. To reconstruct the hair purely from the observed geometry, our method finds sharp surface features directly on the scan and estimates strand orientation through a neural 2D line detector applied to the renderings of scan shading. Additionally, we incorporate a diffusion prior trained on a diverse set of synthetic hair scans, refined with an improved noise schedule, and adapted to the reconstructed contents via a scan-specific text prompt. We demonstrate that this combination of supervision signals enables accurate reconstruction of both simple and intricate hairstyles without relying on color information. To facilitate further research, we introduce Strands400, the largest publicly available dataset of hair strands with detailed surface geometry extracted from real-world data, which contains reconstructed hair strands from the scans of 400 subjects.","authors":["Rachmadio Noval Lazuardi","Artem Sevastopolsky","Egor Zakharov","Matthias Niessner","Vanessa Sklyarova"],"url":"https://arxiv.org/abs/2505.05376"}
{"created":"2025-05-09","title":"Denoising Diffusion Probabilistic Models for Coastal Inundation Forecasting","abstract":"Coastal flooding poses significant risks to communities, necessitating fast and accurate forecasting methods to mitigate potential damage. To approach this problem, we present DIFF-FLOOD, a probabilistic spatiotemporal forecasting method designed based on denoising diffusion models. DIFF-FLOOD predicts inundation level at a location by taking both spatial and temporal context into account. It utilizes inundation levels at neighboring locations and digital elevation data as spatial context. Inundation history from a context time window, together with additional co-variates are used as temporal context. Convolutional neural networks and cross-attention mechanism are then employed to capture the spatiotemporal dynamics in the data. We trained and tested DIFF-FLOOD on coastal inundation data from the Eastern Shore of Virginia, a region highly impacted by coastal flooding. Our results show that, DIFF-FLOOD outperforms existing forecasting methods in terms of prediction performance (6% to 64% improvement in terms of two performance metrics) and scalability.","authors":["Kazi Ashik Islam","Zakaria Mehrab","Mahantesh Halappanavar","Henning Mortveit","Sridhar Katragadda","Jon Derek Loftis","Madhav Marathe"],"url":"https://arxiv.org/abs/2505.05381"}
{"created":"2025-05-09","title":"EDmamba: A Simple yet Effective Event Denoising Method with State Space Model","abstract":"Event cameras excel in high-speed vision due to their high temporal resolution, high dynamic range, and low power consumption. However, as dynamic vision sensors, their output is inherently noisy, making efficient denoising essential to preserve their ultra-low latency and real-time processing capabilities. Existing event denoising methods struggle with a critical dilemma: computationally intensive approaches compromise the sensor's high-speed advantage, while lightweight methods often lack robustness across varying noise levels. To address this, we propose a novel event denoising framework based on State Space Models (SSMs). Our approach represents events as 4D event clouds and includes a Coarse Feature Extraction (CFE) module that extracts embedding features from both geometric and polarity-aware subspaces. The model is further composed of two essential components: A Spatial Mamba (S-SSM) that models local geometric structures and a Temporal Mamba (T-SSM) that captures global temporal dynamics, efficiently propagating spatiotemporal features across events. Experiments demonstrate that our method achieves state-of-the-art accuracy and efficiency, with 88.89K parameters, 0.0685s per 100K events inference time, and a 0.982 accuracy score, outperforming Transformer-based methods by 2.08% in denoising accuracy and 36X faster.","authors":["Ciyu Ruan","Zihang Gong","Ruishan Guo","Jingao Xu","Xinlei Chen"],"url":"https://arxiv.org/abs/2505.05391"}
{"created":"2025-05-09","title":"A Pain Assessment Framework based on multimodal data and Deep Machine Learning methods","abstract":"From the original abstract:","authors":["Stefanos Gkikas"],"url":"https://arxiv.org/abs/2505.05396"}
{"created":"2025-05-09","title":"PillarMamba: Learning Local-Global Context for Roadside Point Cloud via Hybrid State Space Model","abstract":"Serving the Intelligent Transport System (ITS) and Vehicle-to-Everything (V2X) tasks, roadside perception has received increasing attention in recent years, as it can extend the perception range of connected vehicles and improve traffic safety. However, roadside point cloud oriented 3D object detection has not been effectively explored. To some extent, the key to the performance of a point cloud detector lies in the receptive field of the network and the ability to effectively utilize the scene context. The recent emergence of Mamba, based on State Space Model (SSM), has shaken up the traditional convolution and transformers that have long been the foundational building blocks, due to its efficient global receptive field. In this work, we introduce Mamba to pillar-based roadside point cloud perception and propose a framework based on Cross-stage State-space Group (CSG), called PillarMamba. It enhances the expressiveness of the network and achieves efficient computation through cross-stage feature fusion. However, due to the limitations of scan directions, state space model faces local connection disrupted and historical relationship forgotten. To address this, we propose the Hybrid State-space Block (HSB) to obtain the local-global context of roadside point cloud. Specifically, it enhances neighborhood connections through local convolution and preserves historical memory through residual attention. The proposed method outperforms the state-of-the-art methods on the popular large scale roadside benchmark: DAIR-V2X-I. The code will be released soon.","authors":["Zhang Zhang","Chao Sun","Chao Yue","Da Wen","Tianze Wang","Jianghao Leng"],"url":"https://arxiv.org/abs/2505.05397"}
{"created":"2025-05-09","title":"CART-ELC: Oblique Decision Tree Induction via Exhaustive Search","abstract":"Oblique decision trees have attracted attention due to their potential for improved classification performance over traditional axis-aligned decision trees. However, methods that rely on exhaustive search to find oblique splits face computational challenges. As a result, they have not been widely explored. We introduce a novel algorithm, Classification and Regression Tree - Exhaustive Linear Combinations (CART-ELC), for inducing oblique decision trees that performs an exhaustive search on a restricted set of hyperplanes. We then investigate the algorithm's computational complexity and its predictive capabilities. Our results demonstrate that CART-ELC consistently achieves competitive performance on small datasets, often yielding statistically significant improvements in classification accuracy relative to existing decision tree induction algorithms, while frequently producing shallower, simpler, and thus more interpretable trees.","authors":["Andrew D. Laack"],"url":"https://arxiv.org/abs/2505.05402"}
{"created":"2025-05-09","title":"Frame In, Frame Out: Do LLMs Generate More Biased News Headlines than Humans?","abstract":"Framing in media critically shapes public perception by selectively emphasizing some details while downplaying others. With the rise of large language models in automated news and content creation, there is growing concern that these systems may introduce or even amplify framing biases compared to human authors. In this paper, we explore how framing manifests in both out-of-the-box and fine-tuned LLM-generated news content. Our analysis reveals that, particularly in politically and socially sensitive contexts, LLMs tend to exhibit more pronounced framing than their human counterparts. In addition, we observe significant variation in framing tendencies across different model architectures, with some models displaying notably higher biases. These findings point to the need for effective post-training mitigation strategies and tighter evaluation frameworks to ensure that automated news content upholds the standards of balanced reporting.","authors":["Valeria Pastorino","Nafise Sadat Moosavi"],"url":"https://arxiv.org/abs/2505.05406"}
{"created":"2025-05-09","title":"Neural network methods for power series problems of Perron-Frobenius operators","abstract":"Problems related to Perron-Frobenius operators (or transfer operators) have been extensively studied and applied across various fields. In this work, we propose neural network methods for approximating solutions to problems involving these operators. Specifically, we focus on computing the power series of non-expansive Perron-Frobenius operators under a given $L^p$-norm with a constant damping parameter in $(0,1)$. We use PINNs and RVPINNs to approximate solutions in their strong and variational forms, respectively. We provide a priori error estimates for quasi-minimizers of the associated loss functions. We present some numerical results for 1D and 2D examples to show the performance of our methods.","authors":["T. Udomworarat","I. Brevis","M. Richter","S. Rojas","K. G. van der Zee"],"url":"https://arxiv.org/abs/2505.05407"}
{"created":"2025-05-09","title":"Crosslingual Reasoning through Test-Time Scaling","abstract":"Reasoning capabilities of large language models are primarily studied for English, even when pretrained models are multilingual. In this work, we investigate to what extent English reasoning finetuning with long chain-of-thoughts (CoTs) can generalize across languages. First, we find that scaling up inference compute for English-centric reasoning language models (RLMs) improves multilingual mathematical reasoning across many languages including low-resource languages, to an extent where they outperform models twice their size. Second, we reveal that while English-centric RLM's CoTs are naturally predominantly English, they consistently follow a quote-and-think pattern to reason about quoted non-English inputs. Third, we discover an effective strategy to control the language of long CoT reasoning, and we observe that models reason better and more efficiently in high-resource languages. Finally, we observe poor out-of-domain reasoning generalization, in particular from STEM to cultural commonsense knowledge, even for English. Overall, we demonstrate the potentials, study the mechanisms and outline the limitations of crosslingual generalization of English reasoning test-time scaling. We conclude that practitioners should let English-centric RLMs reason in high-resource languages, while further work is needed to improve reasoning in low-resource languages and out-of-domain contexts.","authors":["Zheng-Xin Yong","M. Farid Adilazuarda","Jonibek Mansurov","Ruochen Zhang","Niklas Muennighoff","Carsten Eickhoff","Genta Indra Winata","Julia Kreutzer","Stephen H. Bach","Alham Fikri Aji"],"url":"https://arxiv.org/abs/2505.05408"}
{"created":"2025-05-09","title":"Hide & Seek: Transformer Symmetries Obscure Sharpness & Riemannian Geometry Finds It","abstract":"The concept of sharpness has been successfully applied to traditional architectures like MLPs and CNNs to predict their generalization. For transformers, however, recent work reported weak correlation between flatness and generalization. We argue that existing sharpness measures fail for transformers, because they have much richer symmetries in their attention mechanism that induce directions in parameter space along which the network or its loss remain identical. We posit that sharpness must account fully for these symmetries, and thus we redefine it on a quotient manifold that results from quotienting out the transformer symmetries, thereby removing their ambiguities. Leveraging tools from Riemannian geometry, we propose a fully general notion of sharpness, in terms of a geodesic ball on the symmetry-corrected quotient manifold. In practice, we need to resort to approximating the geodesics. Doing so up to first order yields existing adaptive sharpness measures, and we demonstrate that including higher-order terms is crucial to recover correlation with generalization. We present results on diagonal networks with synthetic data, and show that our geodesic sharpness reveals strong correlation for real-world transformers on both text and image classification tasks.","authors":["Marvin F. da Silva","Felix Dangel","Sageev Oore"],"url":"https://arxiv.org/abs/2505.05409"}
{"created":"2025-05-09","title":"Reasoning Models Don't Always Say What They Think","abstract":"Chain-of-thought (CoT) offers a potential boon for AI safety as it allows monitoring a model's CoT to try to understand its intentions and reasoning processes. However, the effectiveness of such monitoring hinges on CoTs faithfully representing models' actual reasoning processes. We evaluate CoT faithfulness of state-of-the-art reasoning models across 6 reasoning hints presented in the prompts and find: (1) for most settings and models tested, CoTs reveal their usage of hints in at least 1% of examples where they use the hint, but the reveal rate is often below 20%, (2) outcome-based reinforcement learning initially improves faithfulness but plateaus without saturating, and (3) when reinforcement learning increases how frequently hints are used (reward hacking), the propensity to verbalize them does not increase, even without training against a CoT monitor. These results suggest that CoT monitoring is a promising way of noticing undesired behaviors during training and evaluations, but that it is not sufficient to rule them out. They also suggest that in settings like ours where CoT reasoning is not necessary, test-time monitoring of CoTs is unlikely to reliably catch rare and catastrophic unexpected behaviors.","authors":["Yanda Chen","Joe Benton","Ansh Radhakrishnan","Jonathan Uesato","Carson Denison","John Schulman","Arushi Somani","Peter Hase","Misha Wagner","Fabien Roger","Vlad Mikulik","Samuel R. Bowman","Jan Leike","Jared Kaplan","Ethan Perez"],"url":"https://arxiv.org/abs/2505.05410"}
{"created":"2025-05-09","title":"DPQ-HD: Post-Training Compression for Ultra-Low Power Hyperdimensional Computing","abstract":"Hyperdimensional Computing (HDC) is emerging as a promising approach for edge AI, offering a balance between accuracy and efficiency. However, current HDC-based applications often rely on high-precision models and/or encoding matrices to achieve competitive performance, which imposes significant computational and memory demands, especially for ultra-low power devices. While recent efforts use techniques like precision reduction and pruning to increase the efficiency, most require retraining to maintain performance, making them expensive and impractical. To address this issue, we propose a novel Post Training Compression algorithm, Decomposition-Pruning-Quantization (DPQ-HD), which aims at compressing the end-to-end HDC system, achieving near floating point performance without the need of retraining. DPQ-HD reduces computational and memory overhead by uniquely combining the above three compression techniques and efficiently adapts to hardware constraints. Additionally, we introduce an energy-efficient inference approach that progressively evaluates similarity scores such as cosine similarity and performs early exit to reduce the computation, accelerating prediction inference while maintaining accuracy. We demonstrate that DPQ-HD achieves up to 20-100x reduction in memory for image and graph classification tasks with only a 1-2% drop in accuracy compared to uncompressed workloads. Lastly, we show that DPQ-HD outperforms the existing post-training compression methods and performs better or at par with retraining-based state-of-the-art techniques, requiring significantly less overall optimization time (up to 100x) and faster inference (up to 56x) on a microcontroller","authors":["Nilesh Prasad Pandey","Shriniwas Kulkarni","David Wang","Onat Gungor","Flavio Ponzina","Tajana Rosing"],"url":"https://arxiv.org/abs/2505.05413"}
{"created":"2025-05-09","title":"TokLIP: Marry Visual Tokens to CLIP for Multimodal Comprehension and Generation","abstract":"Pioneering token-based works such as Chameleon and Emu3 have established a foundation for multimodal unification but face challenges of high training computational overhead and limited comprehension performance due to a lack of high-level semantics. In this paper, we introduce TokLIP, a visual tokenizer that enhances comprehension by semanticizing vector-quantized (VQ) tokens and incorporating CLIP-level semantics while enabling end-to-end multimodal autoregressive training with standard VQ tokens. TokLIP integrates a low-level discrete VQ tokenizer with a ViT-based token encoder to capture high-level continuous semantics. Unlike previous approaches (e.g., VILA-U) that discretize high-level features, TokLIP disentangles training objectives for comprehension and generation, allowing the direct application of advanced VQ tokenizers without the need for tailored quantization operations. Our empirical results demonstrate that TokLIP achieves exceptional data efficiency, empowering visual tokens with high-level semantic understanding while enhancing low-level generative capacity, making it well-suited for autoregressive Transformers in both comprehension and generation tasks. The code and models are available at https://github.com/TencentARC/TokLIP.","authors":["Haokun Lin","Teng Wang","Yixiao Ge","Yuying Ge","Zhichao Lu","Ying Wei","Qingfu Zhang","Zhenan Sun","Ying Shan"],"url":"https://arxiv.org/abs/2505.05422"}
{"created":"2025-05-09","title":"TransProQA: an LLM-based literary Translation evaluation metric with Professional Question Answering","abstract":"The impact of Large Language Models (LLMs) has extended into literary domains. However, existing evaluation metrics prioritize mechanical accuracy over artistic expression and tend to overrate machine translation (MT) as being superior to experienced professional human translation. In the long run, this bias could result in a permanent decline in translation quality and cultural authenticity. In response to the urgent need for a specialized literary evaluation metric, we introduce TransProQA, a novel, reference-free, LLM-based question-answering (QA) framework designed specifically for literary translation evaluation. TransProQA uniquely integrates insights from professional literary translators and researchers, focusing on critical elements in literary quality assessment such as literary devices, cultural understanding, and authorial voice. Our extensive evaluation shows that while literary-finetuned XCOMET-XL yields marginal gains, TransProQA substantially outperforms current metrics, achieving up to 0.07 gain in correlation (ACC-EQ and Kendall's tau) and surpassing the best state-of-the-art (SOTA) metrics by over 15 points in adequacy assessments. Incorporating professional translator insights as weights further improves performance, highlighting the value of translator inputs. Notably, TransProQA approaches human-level evaluation performance comparable to trained linguistic annotators. It demonstrates broad applicability to open-source models such as LLaMA3.3-70b and Qwen2.5-32b, indicating its potential as an accessible and training-free literary evaluation metric and a valuable tool for evaluating texts that require local processing due to copyright or ethical considerations.","authors":["Ran Zhang","Wei Zhao","Lieve Macken","Steffen Eger"],"url":"https://arxiv.org/abs/2505.05423"}
{"created":"2025-05-09","title":"Sideways on the highways","abstract":"We present two generalised ants (LLRRRL and LLRLRLL) which admit both highway behaviours and other kinds of emergent behaviours from initially finite configurations. This limits the well known Highway conjecture on Langton's ant as it shows that a generalised version of this conjecture generically does not hold on generalised ants.","authors":["Victor Lutfalla"],"url":"https://arxiv.org/abs/2505.05426"}
{"created":"2025-05-09","title":"Ultra-FineWeb: Efficient Data Filtering and Verification for High-Quality LLM Training Data","abstract":"Data quality has become a key factor in enhancing model performance with the rapid development of large language models (LLMs). Model-driven data filtering has increasingly become a primary approach for acquiring high-quality data. However, it still faces two main challenges: (1) the lack of an efficient data verification strategy makes it difficult to provide timely feedback on data quality; and (2) the selection of seed data for training classifiers lacks clear criteria and relies heavily on human expertise, introducing a degree of subjectivity. To address the first challenge, we introduce an efficient verification strategy that enables rapid evaluation of the impact of data on LLM training with minimal computational cost. To tackle the second challenge, we build upon the assumption that high-quality seed data is beneficial for LLM training, and by integrating the proposed verification strategy, we optimize the selection of positive and negative samples and propose an efficient data filtering pipeline. This pipeline not only improves filtering efficiency, classifier quality, and robustness, but also significantly reduces experimental and inference costs. In addition, to efficiently filter high-quality data, we employ a lightweight classifier based on fastText, and successfully apply the filtering pipeline to two widely-used pre-training corpora, FineWeb and Chinese FineWeb datasets, resulting in the creation of the higher-quality Ultra-FineWeb dataset. Ultra-FineWeb contains approximately 1 trillion English tokens and 120 billion Chinese tokens. Empirical results demonstrate that the LLMs trained on Ultra-FineWeb exhibit significant performance improvements across multiple benchmark tasks, validating the effectiveness of our pipeline in enhancing both data quality and training efficiency.","authors":["Yudong Wang","Zixuan Fu","Jie Cai","Peijun Tang","Hongya Lyu","Yewei Fang","Zhi Zheng","Jie Zhou","Guoyang Zeng","Chaojun Xiao","Xu Han","Zhiyuan Liu"],"url":"https://arxiv.org/abs/2505.05427"}
{"created":"2025-05-09","title":"Empowering Scientific Workflows with Federated Agents","abstract":"Agentic systems, in which diverse agents cooperate to tackle challenging problems, are exploding in popularity in the AI community. However, the agentic frameworks used to build these systems have not previously enabled use with research cyberinfrastructure. Here we introduce Academy, a modular and extensible middleware designed to deploy autonomous agents across the federated research ecosystem, including HPC systems, experimental facilities, and data repositories. To meet the demands of scientific computing, Academy supports asynchronous execution, heterogeneous resources, high-throughput data flows, and dynamic resource availability. It provides abstractions for expressing stateful agents, managing inter-agent coordination, and integrating computation with experimental control. We present microbenchmark results that demonstrate high performance and scalability in HPC environments. To demonstrate the breadth of applications that can be supported by agentic workflow designs, we also present case studies in materials discovery, decentralized learning, and information extraction in which agents are deployed across diverse HPC systems.","authors":["J. Gregory Pauloski","Yadu Babuji","Ryan Chard","Mansi Sakarvadia","Kyle Chard","Ian Foster"],"url":"https://arxiv.org/abs/2505.05428"}
{"created":"2025-05-09","title":"Artifact Sharing for Information Retrieval Research","abstract":"Sharing artifacts -- such as trained models, pre-built indexes, and the code to use them -- aids in reproducibility efforts by allowing researchers to validate intermediate steps and improves the sustainability of research by allowing multiple groups to build off one another's prior computational work. Although there are de facto consensuses on how to share research code (through a git repository linked to from publications) and trained models (via HuggingFace Hub), there is no consensus for other types of artifacts, such as built indexes. Given the practical utility of using shared indexes, researchers have resorted to self-hosting these resources or performing ad hoc file transfers upon request, ultimately limiting the artifacts' discoverability and reuse. This demonstration introduces a flexible and interoperable way to share artifacts for Information Retrieval research, improving both their accessibility and usability.","authors":["Sean MacAvaney"],"url":"https://arxiv.org/abs/2505.05434"}
{"created":"2025-05-09","title":"EcoAgent: An Efficient Edge-Cloud Collaborative Multi-Agent Framework for Mobile Automation","abstract":"Cloud-based mobile agents powered by (multimodal) large language models ((M)LLMs) offer strong reasoning abilities but suffer from high latency and cost. While fine-tuned (M)SLMs enable edge deployment, they often lose general capabilities and struggle with complex tasks. To address this, we propose EcoAgent, an Edge-Cloud cOllaborative multi-agent framework for mobile automation. EcoAgent features a closed-loop collaboration among a cloud-based Planning Agent and two edge-based agents: the Execution Agent for action execution and the Observation Agent for verifying outcomes. The Observation Agent uses a Pre-Understanding Module to compress screen images into concise text, reducing token usage. In case of failure, the Planning Agent retrieves screen history and replans via a Reflection Module. Experiments on AndroidWorld show that EcoAgent maintains high task success rates while significantly reducing MLLM token consumption, enabling efficient and practical mobile automation.","authors":["Biao Yi","Xavier Hu","Yurun Chen","Shengyu Zhang","Hongxia Yang","Fan Wu","Fei Wu"],"url":"https://arxiv.org/abs/2505.05440"}
{"created":"2025-05-09","title":"GesPrompt: Leveraging Co-Speech Gestures to Augment LLM-Based Interaction in Virtual Reality","abstract":"Large Language Model (LLM)-based copilots have shown great potential in Extended Reality (XR) applications. However, the user faces challenges when describing the 3D environments to the copilots due to the complexity of conveying spatial-temporal information through text or speech alone. To address this, we introduce GesPrompt, a multimodal XR interface that combines co-speech gestures with speech, allowing end-users to communicate more naturally and accurately with LLM-based copilots in XR environments. By incorporating gestures, GesPrompt extracts spatial-temporal reference from co-speech gestures, reducing the need for precise textual prompts and minimizing cognitive load for end-users. Our contributions include (1) a workflow to integrate gesture and speech input in the XR environment, (2) a prototype VR system that implements the workflow, and (3) a user study demonstrating its effectiveness in improving user communication in VR environments.","authors":["Xiyun Hu","Dizhi Ma","Fengming He","Zhengzhe Zhu","Shao-Kang Hsia","Chenfei Zhu","Ziyi Liu","Karthik Ramani"],"url":"https://arxiv.org/abs/2505.05441"}
{"created":"2025-05-09","title":"clem:todd: A Framework for the Systematic Benchmarking of LLM-Based Task-Oriented Dialogue System Realisations","abstract":"The emergence of instruction-tuned large language models (LLMs) has advanced the field of dialogue systems, enabling both realistic user simulations and robust multi-turn conversational agents. However, existing research often evaluates these components in isolation-either focusing on a single user simulator or a specific system design-limiting the generalisability of insights across architectures and configurations. In this work, we propose clem todd (chat-optimized LLMs for task-oriented dialogue systems development), a flexible framework for systematically evaluating dialogue systems under consistent conditions. clem todd enables detailed benchmarking across combinations of user simulators and dialogue systems, whether existing models from literature or newly developed ones. It supports plug-and-play integration and ensures uniform datasets, evaluation metrics, and computational constraints. We showcase clem todd's flexibility by re-evaluating existing task-oriented dialogue systems within this unified setup and integrating three newly proposed dialogue systems into the same evaluation pipeline. Our results provide actionable insights into how architecture, scale, and prompting strategies affect dialogue performance, offering practical guidance for building efficient and effective conversational AI systems.","authors":["Chalamalasetti Kranti","Sherzod Hakimov","David Schlangen"],"url":"https://arxiv.org/abs/2505.05445"}
{"created":"2025-05-09","title":"Adaptive Markup Language Generation for Contextually-Grounded Visual Document Understanding","abstract":"Visual Document Understanding has become essential with the increase of text-rich visual content. This field poses significant challenges due to the need for effective integration of visual perception and textual comprehension, particularly across diverse document types with complex layouts. Moreover, existing fine-tuning datasets for this domain often fall short in providing the detailed contextual information for robust understanding, leading to hallucinations and limited comprehension of spatial relationships among visual elements. To address these challenges, we propose an innovative pipeline that utilizes adaptive generation of markup languages, such as Markdown, JSON, HTML, and TiKZ, to build highly structured document representations and deliver contextually-grounded responses. We introduce two fine-grained structured datasets: DocMark-Pile, comprising approximately 3.8M pretraining data pairs for document parsing, and DocMark-Instruct, featuring 624k fine-tuning data annotations for grounded instruction following. Extensive experiments demonstrate that our proposed model significantly outperforms existing state-of-theart MLLMs across a range of visual document understanding benchmarks, facilitating advanced reasoning and comprehension capabilities in complex visual scenarios. Our code and models are released at https://github. com/Euphoria16/DocMark.","authors":["Han Xiao","Yina Xie","Guanxin Tan","Yinghao Chen","Rui Hu","Ke Wang","Aojun Zhou","Hao Li","Hao Shao","Xudong Lu","Peng Gao","Yafei Wen","Xiaoxin Chen","Shuai Ren","Hongsheng Li"],"url":"https://arxiv.org/abs/2505.05446"}
{"created":"2025-05-09","title":"RL-DAUNCE: Reinforcement Learning-Driven Data Assimilation with Uncertainty-Aware Constrained Ensembles","abstract":"Machine learning has become a powerful tool for enhancing data assimilation. While supervised learning remains the standard method, reinforcement learning (RL) offers unique advantages through its sequential decision-making framework, which naturally fits the iterative nature of data assimilation by dynamically balancing model forecasts with observations. We develop RL-DAUNCE, a new RL-based method that enhances data assimilation with physical constraints through three key aspects. First, RL-DAUNCE inherits the computational efficiency of machine learning while it uniquely structures its agents to mirror ensemble members in conventional data assimilation methods. Second, RL-DAUNCE emphasizes uncertainty quantification by advancing multiple ensemble members, moving beyond simple mean-state optimization. Third, RL-DAUNCE's ensemble-as-agents design facilitates the enforcement of physical constraints during the assimilation process, which is crucial to improving the state estimation and subsequent forecasting. A primal-dual optimization strategy is developed to enforce constraints, which dynamically penalizes the reward function to ensure constraint satisfaction throughout the learning process. Also, state variable bounds are respected by constraining the RL action space. Together, these features ensure physical consistency without sacrificing efficiency. RL-DAUNCE is applied to the Madden-Julian Oscillation, an intermittent atmospheric phenomenon characterized by strongly non-Gaussian features and multiple physical constraints. RL-DAUNCE outperforms the standard ensemble Kalman filter (EnKF), which fails catastrophically due to the violation of physical constraints. Notably, RL-DAUNCE matches the performance of constrained EnKF, particularly in recovering intermittent signals, capturing extreme events, and quantifying uncertainties, while requiring substantially less computational effort.","authors":["Pouria Behnoudfar","Nan Chen"],"url":"https://arxiv.org/abs/2505.05452"}
{"created":"2025-05-09","title":"Conversational Process Model Redesign","abstract":"With the recent success of large language models (LLMs), the idea of AI-augmented Business Process Management systems is becoming more feasible. One of their essential characteristics is the ability to be conversationally actionable, allowing humans to interact with the LLM effectively to perform crucial process life cycle tasks such as process model design and redesign. However, most current research focuses on single-prompt execution and evaluation of results, rather than on continuous interaction between the user and the LLM. In this work, we aim to explore the feasibility of using LLMs to empower domain experts in the creation and redesign of process models in an iterative and effective way. The proposed conversational process model redesign (CPD) approach receives as input a process model and a redesign request by the user in natural language. Instead of just letting the LLM make changes, the LLM is employed to (a) identify process change patterns from literature, (b) re-phrase the change request to be aligned with an expected wording for the identified pattern (i.e., the meaning), and then to (c) apply the meaning of the change to the process model. This multi-step approach allows for explainable and reproducible changes. In order to ensure the feasibility of the CPD approach, and to find out how well the patterns from literature can be handled by the LLM, we performed an extensive evaluation. The results show that some patterns are hard to understand by LLMs and by users. Within the scope of the study, we demonstrated that users need support to describe the changes clearly. Overall the evaluation shows that the LLMs can handle most changes well according to a set of completeness and correctness criteria.","authors":["Nataliia Klievtsova","Timotheus Kampik","Juergen Mangler","Stefanie Rinderle-Ma"],"url":"https://arxiv.org/abs/2505.05453"}
{"created":"2025-05-09","title":"SITE: towards Spatial Intelligence Thorough Evaluation","abstract":"Spatial intelligence (SI) represents a cognitive ability encompassing the visualization, manipulation, and reasoning about spatial relationships, underpinning disciplines from neuroscience to robotics. We introduce SITE, a benchmark dataset towards SI Thorough Evaluation in a standardized format of multi-choice visual question-answering, designed to assess large vision-language models' spatial intelligence across diverse visual modalities (single-image, multi-image, and video) and SI factors (figural to environmental scales, spatial visualization and orientation, intrinsic and extrinsic, static and dynamic). Our approach to curating the benchmark combines a bottom-up survey about 31 existing datasets and a top-down strategy drawing upon three classification systems in cognitive science, which prompt us to design two novel types of tasks about view-taking and dynamic scenes. Extensive experiments reveal that leading models fall behind human experts especially in spatial orientation, a fundamental SI factor. Moreover, we demonstrate a positive correlation between a model's spatial reasoning proficiency and its performance on an embodied AI task.","authors":["Wenqi Wang","Reuben Tan","Pengyue Zhu","Jianwei Yang","Zhengyuan Yang","Lijuan Wang","Andrey Kolobov","Jianfeng Gao","Boqing Gong"],"url":"https://arxiv.org/abs/2505.05456"}
{"created":"2025-05-09","title":"UKElectionNarratives: A Dataset of Misleading Narratives Surrounding Recent UK General Elections","abstract":"Misleading narratives play a crucial role in shaping public opinion during elections, as they can influence how voters perceive candidates and political parties. This entails the need to detect these narratives accurately. To address this, we introduce the first taxonomy of common misleading narratives that circulated during recent elections in Europe. Based on this taxonomy, we construct and analyse UKElectionNarratives: the first dataset of human-annotated misleading narratives which circulated during the UK General Elections in 2019 and 2024. We also benchmark Pre-trained and Large Language Models (focusing on GPT-4o), studying their effectiveness in detecting election-related misleading narratives. Finally, we discuss potential use cases and make recommendations for future research directions using the proposed codebook and dataset.","authors":["Fatima Haouari","Carolina Scarton","Nicol\\`o Faggiani","Nikolaos Nikolaidis","Bonka Kotseva","Ibrahim Abu Farha","Jens Linge","Kalina Bontcheva"],"url":"https://arxiv.org/abs/2505.05459"}
{"created":"2025-05-09","title":"Bring Reason to Vision: Understanding Perception and Reasoning through Model Merging","abstract":"Vision-Language Models (VLMs) combine visual perception with the general capabilities, such as reasoning, of Large Language Models (LLMs). However, the mechanisms by which these two abilities can be combined and contribute remain poorly understood. In this work, we explore to compose perception and reasoning through model merging that connects parameters of different models. Unlike previous works that often focus on merging models of the same kind, we propose merging models across modalities, enabling the incorporation of the reasoning capabilities of LLMs into VLMs. Through extensive experiments, we demonstrate that model merging offers a successful pathway to transfer reasoning abilities from LLMs to VLMs in a training-free manner. Moreover, we utilize the merged models to understand the internal mechanism of perception and reasoning and how merging affects it. We find that perception capabilities are predominantly encoded in the early layers of the model, whereas reasoning is largely facilitated by the middle-to-late layers. After merging, we observe that all layers begin to contribute to reasoning, whereas the distribution of perception abilities across layers remains largely unchanged. These observations shed light on the potential of model merging as a tool for multimodal integration and interpretation.","authors":["Shiqi Chen","Jinghan Zhang","Tongyao Zhu","Wei Liu","Siyang Gao","Miao Xiong","Manling Li","Junxian He"],"url":"https://arxiv.org/abs/2505.05464"}
{"created":"2025-05-09","title":"ComPO: Preference Alignment via Comparison Oracles","abstract":"Direct alignment methods are increasingly used for aligning large language models (LLMs) with human preferences. However, these methods suffer from the issues of verbosity and likelihood displacement, which can be driven by the noisy preference pairs that induce similar likelihood for preferred and dispreferred responses. The contributions of this paper are two-fold. First, we propose a new preference alignment method based on comparison oracles and provide the convergence guarantee for its basic scheme. Second, we improve our method using some heuristics and conduct the experiments to demonstrate the flexibility and compatibility of practical scheme in improving the performance of LLMs using noisy preference pairs. Evaluations are conducted across multiple base and instruction-tuned models (Mistral-7B, Llama-3-8B and Gemma-2-9B) with benchmarks (AlpacaEval 2, MT-Bench and Arena-Hard). Experimental results show the effectiveness of our method as an alternative to addressing the limitations of existing direct alignment methods. A highlight of our work is that we evidence the importance of designing specialized methods for preference pairs with distinct likelihood margin, which complements the recent findings in \\citet{Razin-2025-Unintentional}.","authors":["Peter Chen","Xi Chen","Wotao Yin","Tianyi Lin"],"url":"https://arxiv.org/abs/2505.05465"}
{"created":"2025-05-09","title":"StreamBridge: Turning Your Offline Video Large Language Model into a Proactive Streaming Assistant","abstract":"We present StreamBridge, a simple yet effective framework that seamlessly transforms offline Video-LLMs into streaming-capable models. It addresses two fundamental challenges in adapting existing models into online scenarios: (1) limited capability for multi-turn real-time understanding, and (2) lack of proactive response mechanisms. Specifically, StreamBridge incorporates (1) a memory buffer combined with a round-decayed compression strategy, supporting long-context multi-turn interactions, and (2) a decoupled, lightweight activation model that can be effortlessly integrated into existing Video-LLMs, enabling continuous proactive responses. To further support StreamBridge, we construct Stream-IT, a large-scale dataset tailored for streaming video understanding, featuring interleaved video-text sequences and diverse instruction formats. Extensive experiments show that StreamBridge significantly improves the streaming understanding capabilities of offline Video-LLMs across various tasks, outperforming even proprietary models such as GPT-4o and Gemini 1.5 Pro. Simultaneously, it achieves competitive or superior performance on standard video understanding benchmarks.","authors":["Haibo Wang","Bo Feng","Zhengfeng Lai","Mingze Xu","Shiyu Li","Weifeng Ge","Afshin Dehghan","Meng Cao","Ping Huang"],"url":"https://arxiv.org/abs/2505.05467"}
{"created":"2025-05-09","title":"Generating Physically Stable and Buildable LEGO Designs from Text","abstract":"We introduce LegoGPT, the first approach for generating physically stable LEGO brick models from text prompts. To achieve this, we construct a large-scale, physically stable dataset of LEGO designs, along with their associated captions, and train an autoregressive large language model to predict the next brick to add via next-token prediction. To improve the stability of the resulting designs, we employ an efficient validity check and physics-aware rollback during autoregressive inference, which prunes infeasible token predictions using physics laws and assembly constraints. Our experiments show that LegoGPT produces stable, diverse, and aesthetically pleasing LEGO designs that align closely with the input text prompts. We also develop a text-based LEGO texturing method to generate colored and textured designs. We show that our designs can be assembled manually by humans and automatically by robotic arms. We also release our new dataset, StableText2Lego, containing over 47,000 LEGO structures of over 28,000 unique 3D objects accompanied by detailed captions, along with our code and models at the project website: https://avalovelace1.github.io/LegoGPT/.","authors":["Ava Pun","Kangle Deng","Ruixuan Liu","Deva Ramanan","Changliu Liu","Jun-Yan Zhu"],"url":"https://arxiv.org/abs/2505.05469"}
{"created":"2025-05-09","title":"Flow-GRPO: Training Flow Matching Models via Online RL","abstract":"We propose Flow-GRPO, the first method integrating online reinforcement learning (RL) into flow matching models. Our approach uses two key strategies: (1) an ODE-to-SDE conversion that transforms a deterministic Ordinary Differential Equation (ODE) into an equivalent Stochastic Differential Equation (SDE) that matches the original model's marginal distribution at all timesteps, enabling statistical sampling for RL exploration; and (2) a Denoising Reduction strategy that reduces training denoising steps while retaining the original inference timestep number, significantly improving sampling efficiency without performance degradation. Empirically, Flow-GRPO is effective across multiple text-to-image tasks. For complex compositions, RL-tuned SD3.5 generates nearly perfect object counts, spatial relations, and fine-grained attributes, boosting GenEval accuracy from $63\\%$ to $95\\%$. In visual text rendering, its accuracy improves from $59\\%$ to $92\\%$, significantly enhancing text generation. Flow-GRPO also achieves substantial gains in human preference alignment. Notably, little to no reward hacking occurred, meaning rewards did not increase at the cost of image quality or diversity, and both remained stable in our experiments.","authors":["Jie Liu","Gongye Liu","Jiajun Liang","Yangguang Li","Jiaheng Liu","Xintao Wang","Pengfei Wan","Di Zhang","Wanli Ouyang"],"url":"https://arxiv.org/abs/2505.05470"}
{"created":"2025-05-09","title":"Facets of Disparate Impact: Evaluating Legally Consistent Bias in Machine Learning","abstract":"Leveraging current legal standards, we define bias through the lens of marginal benefits and objective testing with the novel metric \"Objective Fairness Index\". This index combines the contextual nuances of objective testing with metric stability, providing a legally consistent and reliable measure. Utilizing the Objective Fairness Index, we provide fresh insights into sensitive machine learning applications, such as COMPAS (recidivism prediction), highlighting the metric's practical and theoretical significance. The Objective Fairness Index allows one to differentiate between discriminatory tests and systemic disparities.","authors":["Jarren Briscoe","Assefaw Gebremedhin"],"url":"https://arxiv.org/abs/2505.05471"}
{"created":"2025-05-09","title":"Mogao: An Omni Foundation Model for Interleaved Multi-Modal Generation","abstract":"Recent progress in unified models for image understanding and generation has been impressive, yet most approaches remain limited to single-modal generation conditioned on multiple modalities. In this paper, we present Mogao, a unified framework that advances this paradigm by enabling interleaved multi-modal generation through a causal approach. Mogao integrates a set of key technical improvements in architecture design, including a deep-fusion design, dual vision encoders, interleaved rotary position embeddings, and multi-modal classifier-free guidance, which allow it to harness the strengths of both autoregressive models for text generation and diffusion models for high-quality image synthesis. These practical improvements also make Mogao particularly effective to process interleaved sequences of text and images arbitrarily. To further unlock the potential of unified models, we introduce an efficient training strategy on a large-scale, in-house dataset specifically curated for joint text and image generation. Extensive experiments show that Mogao not only achieves state-of-the-art performance in multi-modal understanding and text-to-image generation, but also excels in producing high-quality, coherent interleaved outputs. Its emergent capabilities in zero-shot image editing and compositional generation highlight Mogao as a practical omni-modal foundation model, paving the way for future development and scaling the unified multi-modal systems.","authors":["Chao Liao","Liyang Liu","Xun Wang","Zhengxiong Luo","Xinyu Zhang","Wenliang Zhao","Jie Wu","Liang Li","Zhi Tian","Weilin Huang"],"url":"https://arxiv.org/abs/2505.05472"}
{"created":"2025-05-09","title":"DiffusionSfM: Predicting Structure and Motion via Ray Origin and Endpoint Diffusion","abstract":"Current Structure-from-Motion (SfM) methods typically follow a two-stage pipeline, combining learned or geometric pairwise reasoning with a subsequent global optimization step. In contrast, we propose a data-driven multi-view reasoning approach that directly infers 3D scene geometry and camera poses from multi-view images. Our framework, DiffusionSfM, parameterizes scene geometry and cameras as pixel-wise ray origins and endpoints in a global frame and employs a transformer-based denoising diffusion model to predict them from multi-view inputs. To address practical challenges in training diffusion models with missing data and unbounded scene coordinates, we introduce specialized mechanisms that ensure robust learning. We empirically validate DiffusionSfM on both synthetic and real datasets, demonstrating that it outperforms classical and learning-based approaches while naturally modeling uncertainty.","authors":["Qitao Zhao","Amy Lin","Jeff Tan","Jason Y. Zhang","Deva Ramanan","Shubham Tulsiani"],"url":"https://arxiv.org/abs/2505.05473"}
{"created":"2025-05-09","title":"3D Scene Generation: A Survey","abstract":"3D scene generation seeks to synthesize spatially structured, semantically meaningful, and photorealistic environments for applications such as immersive media, robotics, autonomous driving, and embodied AI. Early methods based on procedural rules offered scalability but limited diversity. Recent advances in deep generative models (e.g., GANs, diffusion models) and 3D representations (e.g., NeRF, 3D Gaussians) have enabled the learning of real-world scene distributions, improving fidelity, diversity, and view consistency. Recent advances like diffusion models bridge 3D scene synthesis and photorealism by reframing generation as image or video synthesis problems. This survey provides a systematic overview of state-of-the-art approaches, organizing them into four paradigms: procedural generation, neural 3D-based generation, image-based generation, and video-based generation. We analyze their technical foundations, trade-offs, and representative results, and review commonly used datasets, evaluation protocols, and downstream applications. We conclude by discussing key challenges in generation capacity, 3D representation, data and annotations, and evaluation, and outline promising directions including higher fidelity, physics-aware and interactive generation, and unified perception-generation models. This review organizes recent advances in 3D scene generation and highlights promising directions at the intersection of generative AI, 3D vision, and embodied intelligence. To track ongoing developments, we maintain an up-to-date project page: https://github.com/hzxie/Awesome-3D-Scene-Generation.","authors":["Beichen Wen","Haozhe Xie","Zhaoxi Chen","Fangzhou Hong","Ziwei Liu"],"url":"https://arxiv.org/abs/2505.05474"}
{"created":"2025-05-09","title":"SVAD: From Single Image to 3D Avatar via Synthetic Data Generation with Video Diffusion and Data Augmentation","abstract":"Creating high-quality animatable 3D human avatars from a single image remains a significant challenge in computer vision due to the inherent difficulty of reconstructing complete 3D information from a single viewpoint. Current approaches face a clear limitation: 3D Gaussian Splatting (3DGS) methods produce high-quality results but require multiple views or video sequences, while video diffusion models can generate animations from single images but struggle with consistency and identity preservation. We present SVAD, a novel approach that addresses these limitations by leveraging complementary strengths of existing techniques. Our method generates synthetic training data through video diffusion, enhances it with identity preservation and image restoration modules, and utilizes this refined data to train 3DGS avatars. Comprehensive evaluations demonstrate that SVAD outperforms state-of-the-art (SOTA) single-image methods in maintaining identity consistency and fine details across novel poses and viewpoints, while enabling real-time rendering capabilities. Through our data augmentation pipeline, we overcome the dependency on dense monocular or multi-view training data typically required by traditional 3DGS approaches. Extensive quantitative, qualitative comparisons show our method achieves superior performance across multiple metrics against baseline models. By effectively combining the generative power of diffusion models with both the high-quality results and rendering efficiency of 3DGS, our work establishes a new approach for high-fidelity avatar generation from a single image input.","authors":["Yonwoo Choi"],"url":"https://arxiv.org/abs/2505.05475"}
{"created":"2025-05-09","title":"BitHEP -- The Limits of Low-Precision ML in HEP","abstract":"The increasing complexity of modern neural network architectures demands fast and memory-efficient implementations to mitigate computational bottlenecks. In this work, we evaluate the recently proposed BitNet architecture in HEP applications, assessing its performance in classification, regression, and generative modeling tasks. Specifically, we investigate its suitability for quark-gluon discrimination, SMEFT parameter estimation, and detector simulation, comparing its efficiency and accuracy to state-of-the-art methods. Our results show that while BitNet consistently performs competitively in classification tasks, its performance in regression and generation varies with the size and type of the network, highlighting key limitations and potential areas for improvement.","authors":["Claudius Krause","Daohan Wang","Ramon Winterhalder"],"url":"https://arxiv.org/abs/2504.03387"}
{"created":"2025-05-09","title":"Toward Holistic Evaluation of Recommender Systems Powered by Generative Models","abstract":"Recommender systems powered by generative models (Gen-RecSys) extend beyond classical item ranking by producing open-ended content, which simultaneously unlocks richer user experiences and introduces new risks. On one hand, these systems can enhance personalization and appeal through dynamic explanations and multi-turn dialogues. On the other hand, they might venture into unknown territory-hallucinating nonexistent items, amplifying bias, or leaking private information. Traditional accuracy metrics cannot fully capture these challenges, as they fail to measure factual correctness, content safety, or alignment with user intent.","authors":["Yashar Deldjoo","Nikhil Mehta","Maheswaran Sathiamoorthy","Shuai Zhang","Pablo Castells","Julian McAuley"],"url":"https://arxiv.org/abs/2504.06667"}
{"created":"2025-05-09","title":"From Dialect Gaps to Identity Maps: Tackling Variability in Speaker Verification","abstract":"The complexity and difficulties of Kurdish speaker detection among its several dialects are investigated in this work. Because of its great phonetic and lexical differences, Kurdish with several dialects including Kurmanji, Sorani, and Hawrami offers special challenges for speaker recognition systems. The main difficulties in building a strong speaker identification system capable of precisely identifying speakers across several dialects are investigated in this work. To raise the accuracy and dependability of these systems, it also suggests solutions like sophisticated machine learning approaches, data augmentation tactics, and the building of thorough dialect-specific corpus. The results show that customized strategies for every dialect together with cross-dialect training greatly enhance recognition performance.","authors":["Abdulhady Abas Abdullah","Soran Badawi","Dana A. Abdullah","Dana Rasul Hamad","Hanan Abdulrahman Taher","Sabat Salih Muhamad","Aram Mahmood Ahmed","Bryar A. Hassan","Sirwan Abdolwahed Aula","Tarik A. Rashid"],"url":"https://arxiv.org/abs/2505.04629"}
{"created":"2025-05-09","title":"Cryptogenic stroke and migraine: using probabilistic independence and machine learning to uncover latent sources of disease from the electronic health record","abstract":"Migraine is a common but complex neurological disorder that doubles the lifetime risk of cryptogenic stroke (CS). However, this relationship remains poorly characterized, and few clinical guidelines exist to reduce this associated risk. We therefore propose a data-driven approach to extract probabilistically-independent sources from electronic health record (EHR) data and create a 10-year risk-predictive model for CS in migraine patients. These sources represent external latent variables acting on the causal graph constructed from the EHR data and approximate root causes of CS in our population. A random forest model trained on patient expressions of these sources demonstrated good accuracy (ROC 0.771) and identified the top 10 most predictive sources of CS in migraine patients. These sources revealed that pharmacologic interventions were the most important factor in minimizing CS risk in our population and identified a factor related to allergic rhinitis as a potential causative source of CS in migraine patients.","authors":["Joshua W. Betts","John M. Still","Thomas A. Lasko"],"url":"https://arxiv.org/abs/2505.04631"}
{"created":"2025-05-09","title":"Quantum QSAR for drug discovery","abstract":"Quantitative Structure-Activity Relationship (QSAR) modeling is key in drug discovery, but classical methods face limitations when handling high-dimensional data and capturing complex molecular interactions. This research proposes enhancing QSAR techniques through Quantum Support Vector Machines (QSVMs), which leverage quantum computing principles to process information Hilbert spaces. By using quantum data encoding and quantum kernel functions, we aim to develop more accurate and efficient predictive models.","authors":["Alejandro Giraldo","Daniel Ruiz","Mariano Caruso","Guido Bellomo"],"url":"https://arxiv.org/abs/2505.04648"}
{"created":"2025-05-09","title":"Rethinking Boundary Detection in Deep Learning-Based Medical Image Segmentation","abstract":"Medical image segmentation is a pivotal task within the realms of medical image analysis and computer vision. While current methods have shown promise in accurately segmenting major regions of interest, the precise segmentation of boundary areas remains challenging. In this study, we propose a novel network architecture named CTO, which combines Convolutional Neural Networks (CNNs), Vision Transformer (ViT) models, and explicit edge detection operators to tackle this challenge. CTO surpasses existing methods in terms of segmentation accuracy and strikes a better balance between accuracy and efficiency, without the need for additional data inputs or label injections. Specifically, CTO adheres to the canonical encoder-decoder network paradigm, with a dual-stream encoder network comprising a mainstream CNN stream for capturing local features and an auxiliary StitchViT stream for integrating long-range dependencies. Furthermore, to enhance the model's ability to learn boundary areas, we introduce a boundary-guided decoder network that employs binary boundary masks generated by dedicated edge detection operators to provide explicit guidance during the decoding process. We validate the performance of CTO through extensive experiments conducted on seven challenging medical image segmentation datasets, namely ISIC 2016, PH2, ISIC 2018, CoNIC, LiTS17, and BTCV. Our experimental results unequivocally demonstrate that CTO achieves state-of-the-art accuracy on these datasets while maintaining competitive model complexity. The codes have been released at: https://github.com/xiaofang007/CTO.","authors":["Yi Lin","Dong Zhang","Xiao Fang","Yufan Chen","Kwang-Ting Cheng","Hao Chen"],"url":"https://arxiv.org/abs/2505.04652"}
{"created":"2025-05-09","title":"EvEnhancer: Empowering Effectiveness, Efficiency and Generalizability for Continuous Space-Time Video Super-Resolution with Events","abstract":"Continuous space-time video super-resolution (C-STVSR) endeavors to upscale videos simultaneously at arbitrary spatial and temporal scales, which has recently garnered increasing interest. However, prevailing methods struggle to yield satisfactory videos at out-of-distribution spatial and temporal scales. On the other hand, event streams characterized by high temporal resolution and high dynamic range, exhibit compelling promise in vision tasks. This paper presents EvEnhancer, an innovative approach that marries the unique advantages of event streams to elevate effectiveness, efficiency, and generalizability for C-STVSR. Our approach hinges on two pivotal components: 1) Event-adapted synthesis capitalizes on the spatiotemporal correlations between frames and events to discern and learn long-term motion trajectories, enabling the adaptive interpolation and fusion of informative spatiotemporal features; 2) Local implicit video transformer integrates local implicit video neural function with cross-scale spatiotemporal attention to learn continuous video representations utilized to generate plausible videos at arbitrary resolutions and frame rates. Experiments show that EvEnhancer achieves superiority on synthetic and real-world datasets and preferable generalizability on out-of-distribution scales against state-of-the-art methods. Code is available at https://github.com/W-Shuoyan/EvEnhancer.","authors":["Shuoyan Wei","Feng Li","Shengeng Tang","Yao Zhao","Huihui Bai"],"url":"https://arxiv.org/abs/2505.04657"}
{"created":"2025-05-09","title":"Advancing 3D Medical Image Segmentation: Unleashing the Potential of Planarian Neural Networks in Artificial Intelligence","abstract":"Our study presents PNN-UNet as a method for constructing deep neural networks that replicate the planarian neural network (PNN) structure in the context of 3D medical image data. Planarians typically have a cerebral structure comprising two neural cords, where the cerebrum acts as a coordinator, and the neural cords serve slightly different purposes within the organism's neurological system. Accordingly, PNN-UNet comprises a Deep-UNet and a Wide-UNet as the nerve cords, with a densely connected autoencoder performing the role of the brain. This distinct architecture offers advantages over both monolithic (UNet) and modular networks (Ensemble-UNet). Our outcomes on a 3D MRI hippocampus dataset, with and without data augmentation, demonstrate that PNN-UNet outperforms the baseline UNet and several other UNet variants in image segmentation.","authors":["Ziyuan Huang","Kevin Huggins","Srikar Bellur"],"url":"https://arxiv.org/abs/2505.04664"}
{"created":"2025-05-09","title":"Phase Retrieval via Gain-Based Photonic XY-Hamiltonian Optimization","abstract":"Phase-retrieval from coded diffraction patterns (CDP) is important to X-ray crystallography, diffraction tomography and astronomical imaging, yet remains a hard, non-convex inverse problem. We show that CDP recovery can be reformulated exactly as the minimisation of a continuous-variable XY Hamiltonian and solved by gain-based photonic networks. The coupled-mode equations we exploit are the natural mean-field dynamics of exciton-polariton condensate lattices, coupled-laser arrays and driven photon Bose-Einstein condensates, while other hardware such as the spatial photonic Ising machine can implement the same update rule through high-speed digital feedback, preserving full optical parallelism. Numerical experiments on images, two- and three-dimensional vortices and unstructured complex data demonstrate that the gain-based solver consistently outperforms the state-of-the-art Relaxed-Reflect-Reflect (RRR) algorithm in the medium-noise regime (signal-to-noise ratios 10--40 dB) and retains this advantage as problem size scales. Because the physical platform performs the continuous optimisation, our approach promises fast, energy-efficient phase retrieval on readily available photonic hardware. uch as two- and three-dimensional vortices, and unstructured random data. Moreover, the solver's accuracy remains high as problem sizes increase, underscoring its scalability.","authors":["Richard Zhipeng Wang","Guangyao Li","Silvia Gentilini","Marcello Calvanese Strinati","Claudio Conti","Natalia G. Berloff"],"url":"https://arxiv.org/abs/2505.04766"}
{"created":"2025-05-09","title":"Confabulation dynamics in a reservoir computer: Filling in the gaps with untrained attractors","abstract":"Artificial Intelligence has advanced significantly in recent years thanks to innovations in the design and training of artificial neural networks (ANNs). Despite these advancements, we still understand relatively little about how elementary forms of ANNs learn, fail to learn, and generate false information without the intent to deceive, a phenomenon known as `confabulation'. To provide some foundational insight, in this paper we analyse how confabulation occurs in reservoir computers (RCs): a dynamical system in the form of an ANN. RCs are particularly useful to study as they are known to confabulate in a well-defined way: when RCs are trained to reconstruct the dynamics of a given attractor, they sometimes construct an attractor that they were not trained to construct, a so-called `untrained attractor' (UA). This paper sheds light on the role played by UAs when reconstruction fails and their influence when modelling transitions between reconstructed attractors. Based on our results, we conclude that UAs are an intrinsic feature of learning systems whose state spaces are bounded, and that this means of confabulation may be present in systems beyond RCs.","authors":["Jack O'Hagan","Andrew Keane","Andrew Flynn"],"url":"https://arxiv.org/abs/2505.04792"}
{"created":"2025-05-09","title":"Convergent Complex Quasi-Newton Proximal Methods for Gradient-Driven Denoisers in Compressed Sensing MRI Reconstruction","abstract":"In compressed sensing (CS) MRI, model-based methods are pivotal to achieving accurate reconstruction. One of the main challenges in model-based methods is finding an effective prior to describe the statistical distribution of the target image. Plug-and-Play (PnP) and REgularization by Denoising (RED) are two general frameworks that use denoisers as the prior. While PnP/RED methods with convolutional neural networks (CNNs) based denoisers outperform classical hand-crafted priors in CS MRI, their convergence theory relies on assumptions that do not hold for practical CNNs. The recently developed gradient-driven denoisers offer a framework that bridges the gap between practical performance and theoretical guarantees. However, the numerical solvers for the associated minimization problem remain slow for CS MRI reconstruction. This paper proposes a complex quasi-Newton proximal method that achieves faster convergence than existing approaches. To address the complex domain in CS MRI, we propose a modified Hessian estimation method that guarantees Hermitian positive definiteness. Furthermore, we provide a rigorous convergence analysis of the proposed method for nonconvex settings. Numerical experiments on both Cartesian and non-Cartesian sampling trajectories demonstrate the effectiveness and efficiency of our approach.","authors":["Tao Hong","Zhaoyi Xu","Se Young Chun","Luis Hernandez-Garcia","Jeffrey A. Fessler"],"url":"https://arxiv.org/abs/2505.04820"}
{"created":"2025-05-09","title":"Integrated Image Reconstruction and Target Recognition based on Deep Learning Technique","abstract":"Computational microwave imaging (CMI) has gained attention as an alternative technique for conventional microwave imaging techniques, addressing their limitations such as hardware-intensive physical layer and slow data collection acquisition speed to name a few. Despite these advantages, CMI still encounters notable computational bottlenecks, especially during the image reconstruction stage. In this setting, both image recovery and object classification present significant processing demands. To address these challenges, our previous work introduced ClassiGAN, which is a generative deep learning model designed to simultaneously reconstruct images and classify targets using only back-scattered signals. In this study, we build upon that framework by incorporating attention gate modules into ClassiGAN. These modules are intended to refine feature extraction and improve the identification of relevant information. By dynamically focusing on important features and suppressing irrelevant ones, the attention mechanism enhances the overall model performance. The proposed architecture, named Att-ClassiGAN, significantly reduces the reconstruction time compared to traditional CMI approaches. Furthermore, it outperforms current advanced methods, delivering improved Normalized Mean Squared Error (NMSE), higher Structural Similarity Index (SSIM), and better classification outcomes for the reconstructed targets.","authors":["Cien Zhang","Jiaming Zhang","Jiajun He","Okan Yurduseven"],"url":"https://arxiv.org/abs/2505.04836"}
{"created":"2025-05-09","title":"Quantum-Inspired Optimization Process for Data Imputation","abstract":"Data imputation is a critical step in data pre-processing, particularly for datasets with missing or unreliable values. This study introduces a novel quantum-inspired imputation framework evaluated on the UCI Diabetes dataset, which contains biologically implausible missing values across several clinical features. The method integrates Principal Component Analysis (PCA) with quantum-assisted rotations, optimized through gradient-free classical optimizers -COBYLA, Simulated Annealing, and Differential Evolution to reconstruct missing values while preserving statistical fidelity. Reconstructed values are constrained within +/-2 standard deviations of original feature distributions, avoiding unrealistic clustering around central tendencies. This approach achieves a substantial and statistically significant improvement, including an average reduction of over 85% in Wasserstein distance and Kolmogorov-Smirnov test p-values between 0.18 and 0.22, compared to p-values > 0.99 in classical methods such as Mean, KNN, and MICE. The method also eliminates zero-value artifacts and enhances the realism and variability of imputed data. By combining quantum-inspired transformations with a scalable classical framework, this methodology provides a robust solution for imputation tasks in domains such as healthcare and AI pipelines, where data quality and integrity are crucial.","authors":["Nishikanta Mohanty","Bikash K. Behera","Badsah Mukherjee","Christopher Ferrie"],"url":"https://arxiv.org/abs/2505.04841"}
{"created":"2025-05-09","title":"Comparative Study of Generative Models for Early Detection of Failures in Medical Devices","abstract":"The medical device industry has significantly advanced by integrating sophisticated electronics like microchips and field-programmable gate arrays (FPGAs) to enhance the safety and usability of life-saving devices. These complex electro-mechanical systems, however, introduce challenging failure modes that are not easily detectable with conventional methods. Effective fault detection and mitigation become vital as reliance on such electronics grows. This paper explores three generative machine learning-based approaches for fault detection in medical devices, leveraging sensor data from surgical staplers,a class 2 medical device. Historically considered low-risk, these devices have recently been linked to an increasing number of injuries and fatalities. The study evaluates the performance and data requirements of these machine-learning approaches, highlighting their potential to enhance device safety.","authors":["Binesh Sadanandan","Bahareh Arghavani Nobar","Vahid Behzadan"],"url":"https://arxiv.org/abs/2505.04845"}
{"created":"2025-05-09","title":"GroverGPT-2: Simulating Grover's Algorithm via Chain-of-Thought Reasoning and Quantum-Native Tokenization","abstract":"Quantum computing offers theoretical advantages over classical computing for specific tasks, yet the boundary of practical quantum advantage remains an open question. To investigate this boundary, it is crucial to understand whether, and how, classical machines can learn and simulate quantum algorithms. Recent progress in large language models (LLMs) has demonstrated strong reasoning abilities, prompting exploration into their potential for this challenge. In this work, we introduce GroverGPT-2, an LLM-based method for simulating Grover's algorithm using Chain-of-Thought (CoT) reasoning and quantum-native tokenization. Building on its predecessor, GroverGPT-2 performs simulation directly from quantum circuit representations while producing logically structured and interpretable outputs. Our results show that GroverGPT-2 can learn and internalize quantum circuit logic through efficient processing of quantum-native tokens, providing direct evidence that classical models like LLMs can capture the structure of quantum algorithms. Furthermore, GroverGPT-2 outputs interleave circuit data with natural language, embedding explicit reasoning into the simulation. This dual capability positions GroverGPT-2 as a prototype for advancing machine understanding of quantum algorithms and modeling quantum circuit logic. We also identify an empirical scaling law for GroverGPT-2 with increasing qubit numbers, suggesting a path toward scalable classical simulation. These findings open new directions for exploring the limits of classical simulatability, enhancing quantum education and research, and laying groundwork for future foundation models in quantum computing.","authors":["Min Chen","Jinglei Cheng","Pingzhi Li","Haoran Wang","Tianlong Chen","Junyu Liu"],"url":"https://arxiv.org/abs/2505.04880"}
{"created":"2025-05-09","title":"Advanced 3D Imaging Approach to TSV/TGV Metrology and Inspection Using Only Optical Microscopy","abstract":"This paper introduces an innovative approach to silicon and glass via inspection, which combines hybrid field microscopy with photometric stereo. Conventional optical microscopy techniques are generally limited to superficial inspections and struggle to effectively visualize the internal structures of silicon and glass vias. By utilizing various lighting conditions for 3D reconstruction, the proposed method surpasses these limitations. By integrating photometric stereo to the traditional optical microscopy, the proposed method not only enhances the capability to detect micro-scale defects but also provides a detailed visualization of depth and edge abnormality, which are typically not visible with conventional optical microscopy inspection. The experimental results demonstrated that the proposed method effectively captures intricate surface details and internal structures. Quantitative comparisons between the reconstructed models and actual measurements present the capability of the proposed method to significantly improve silicon and glass via inspection process. As a result, the proposed method achieves enhanced cost-effectiveness while maintaining high accuracy and repeatability, suggesting substantial advancements in silicon and glass via inspection techniques","authors":["Gugeong Sung"],"url":"https://arxiv.org/abs/2505.04913"}
{"created":"2025-05-09","title":"Generalization Analysis for Contrastive Representation Learning under Non-IID Settings","abstract":"Contrastive Representation Learning (CRL) has achieved impressive success in various domains in recent years. Nevertheless, the theoretical understanding of the generalization behavior of CRL is limited. Moreover, to the best of our knowledge, the current literature only analyzes generalization bounds under the assumption that the data tuples used for contrastive learning are independently and identically distributed. However, in practice, we are often limited to a fixed pool of reusable labeled data points, making it inevitable to recycle data across tuples to create sufficiently large datasets. Therefore, the tuple-wise independence condition imposed by previous works is invalidated. In this paper, we provide a generalization analysis for the CRL framework under non-$i.i.d.$ settings that adheres to practice more realistically. Drawing inspiration from the literature on U-statistics, we derive generalization bounds which indicate the required number of samples in each class scales as the logarithm of the covering number of the class of learnable feature representations associated to each class. Next, we apply our main results to derive excess risk bounds for common function classes such as linear maps and neural networks.","authors":["Nong Minh Hieu","Antoine Ledent"],"url":"https://arxiv.org/abs/2505.04937"}
{"created":"2025-05-09","title":"Learning Linearized Models from Nonlinear Systems under Initialization Constraints with Finite Data","abstract":"The identification of a linear system model from data has wide applications in control theory. The existing work that provides finite sample guarantees for linear system identification typically uses data from a single long system trajectory under i.i.d. random inputs, and assumes that the underlying dynamics is truly linear. In contrast, we consider the problem of identifying a linearized model when the true underlying dynamics is nonlinear, given that there is a certain constraint on the region where one can initialize the experiments. We provide a multiple trajectories-based deterministic data acquisition algorithm followed by a regularized least squares algorithm, and provide a finite sample error bound on the learned linearized dynamics. Our error bound shows that one can consistently learn the linearized dynamics, and demonstrates a trade-off between the error due to nonlinearity and the error due to noise. We validate our results through numerical experiments, where we also show the potential insufficiency of linear system identification using a single trajectory with i.i.d. random inputs, when nonlinearity does exist.","authors":["Lei Xin","Baike She","Qi Dou","George Chiu","Shreyas Sundaram"],"url":"https://arxiv.org/abs/2505.04954"}
{"created":"2025-05-09","title":"MoRe-3DGSMR: Motion-resolved reconstruction framework for free-breathing pulmonary MRI based on 3D Gaussian representation","abstract":"This study presents an unsupervised, motion-resolved reconstruction framework for high-resolution, free-breathing pulmonary magnetic resonance imaging (MRI), utilizing a three-dimensional Gaussian representation (3DGS). The proposed method leverages 3DGS to address the challenges of motion-resolved 3D isotropic pulmonary MRI reconstruction by enabling data smoothing between voxels for continuous spatial representation. Pulmonary MRI data acquisition is performed using a golden-angle radial sampling trajectory, with respiratory motion signals extracted from the center of k-space in each radial spoke. Based on the estimated motion signal, the k-space data is sorted into multiple respiratory phases. A 3DGS framework is then applied to reconstruct a reference image volume from the first motion state. Subsequently, a patient-specific convolutional neural network is trained to estimate the deformation vector fields (DVFs), which are used to generate the remaining motion states through spatial transformation of the reference volume. The proposed reconstruction pipeline is evaluated on six datasets from six subjects and bench-marked against three state-of-the-art reconstruction methods. The experimental findings demonstrate that the proposed reconstruction framework effectively reconstructs high-resolution, motion-resolved pulmonary MR images. Compared with existing approaches, it achieves superior image quality, reflected by higher signal-to-noise ratio and contrast-to-noise ratio. The proposed unsupervised 3DGS-based reconstruction method enables accurate motion-resolved pulmonary MRI with isotropic spatial resolution. Its superior performance in image quality metrics over state-of-the-art methods highlights its potential as a robust solution for clinical pulmonary MR imaging.","authors":["Tengya Peng","Ruyi Zha","Qing Zou"],"url":"https://arxiv.org/abs/2505.04959"}
{"created":"2025-05-09","title":"Moments of Causal Effects","abstract":"The moments of random variables are fundamental statistical measures for characterizing the shape of a probability distribution, encompassing metrics such as mean, variance, skewness, and kurtosis. Additionally, the product moments, including covariance and correlation, reveal the relationships between multiple random variables. On the other hand, the primary focus of causal inference is the evaluation of causal effects, which are defined as the difference between two potential outcomes. While traditional causal effect assessment focuses on the average causal effect, this work provides definitions, identification theorems, and bounds for moments and product moments of causal effects to analyze their distribution and relationships. We conduct experiments to illustrate the estimation of the moments of causal effects from finite samples and demonstrate their practical application using a real-world medical dataset.","authors":["Yuta Kawakami","Jin Tian"],"url":"https://arxiv.org/abs/2505.04971"}
{"created":"2025-05-09","title":"Decomposition of Probabilities of Causation with Two Mediators","abstract":"Mediation analysis for probabilities of causation (PoC) provides a fundamental framework for evaluating the necessity and sufficiency of treatment in provoking an event through different causal pathways. One of the primary objectives of causal mediation analysis is to decompose the total effect into path-specific components. In this study, we investigate the path-specific probability of necessity and sufficiency (PNS) to decompose the total PNS into path-specific components along distinct causal pathways between treatment and outcome, incorporating two mediators. We define the path-specific PNS for decomposition and provide an identification theorem. Furthermore, we conduct numerical experiments to assess the properties of the proposed estimators from finite samples and demonstrate their practical application using a real-world educational dataset.","authors":["Yuta Kawakami","Jin Tian"],"url":"https://arxiv.org/abs/2505.04983"}
{"created":"2025-05-09","title":"Conformal Prediction with Cellwise Outliers: A Detect-then-Impute Approach","abstract":"Conformal prediction is a powerful tool for constructing prediction intervals for black-box models, providing a finite sample coverage guarantee for exchangeable data. However, this exchangeability is compromised when some entries of the test feature are contaminated, such as in the case of cellwise outliers. To address this issue, this paper introduces a novel framework called detect-then-impute conformal prediction. This framework first employs an outlier detection procedure on the test feature and then utilizes an imputation method to fill in those cells identified as outliers. To quantify the uncertainty in the processed test feature, we adaptively apply the detection and imputation procedures to the calibration set, thereby constructing exchangeable features for the conformal prediction interval of the test label. We develop two practical algorithms, PDI-CP and JDI-CP, and provide a distribution-free coverage analysis under some commonly used detection and imputation procedures. Notably, JDI-CP achieves a finite sample $1-2\\alpha$ coverage guarantee. Numerical experiments on both synthetic and real datasets demonstrate that our proposed algorithms exhibit robust coverage properties and comparable efficiency to the oracle baseline.","authors":["Qian Peng","Yajie Bao","Haojie Ren","Zhaojun Wang","Changliang Zou"],"url":"https://arxiv.org/abs/2505.04986"}
{"created":"2025-05-09","title":"Semi-Explicit Solution of Some Discrete-Time Mean-Field-Type Games with Higher-Order Costs","abstract":"Traditional solvable game theory and mean-field-type game theory (risk-aware games) predominantly focus on quadratic costs due to their analytical tractability. Nevertheless, they often fail to capture critical non-linearities inherent in real-world systems. In this work, we present a unified framework for solving discrete-time game problems with higher-order state and strategy costs involving power-law terms. We derive semi-explicit expressions for equilibrium strategies, cost-to-go functions, and recursive coefficient dynamics across deterministic, stochastic, and multi-agent system settings by convex-completion techniques. The contributions include variance-aware solutions under additive and multiplicative noise, extensions to mean-field-type-dependent dynamics, and conditions that ensure the positivity of recursive coefficients. Our results provide a foundational methodology for analyzing non linear multi-agent systems under higher-order penalization, bridging classical game theory and mean-field-type game theory with modern computational tools for engineering applications.","authors":["Julian Barreiro-Gomez","Tyrone E. Duncan","Bozenna Pasik-Duncan","Hamidou Tembine"],"url":"https://arxiv.org/abs/2505.04988"}
{"created":"2025-05-09","title":"Boosting Statistic Learning with Synthetic Data from Pretrained Large Models","abstract":"The rapid advancement of generative models, such as Stable Diffusion, raises a key question: how can synthetic data from these models enhance predictive modeling? While they can generate vast amounts of datasets, only a subset meaningfully improves performance. We propose a novel end-to-end framework that generates and systematically filters synthetic data through domain-specific statistical methods, selectively integrating high-quality samples for effective augmentation. Our experiments demonstrate consistent improvements in predictive performance across various settings, highlighting the potential of our framework while underscoring the inherent limitations of generative models for data augmentation. Despite the ability to produce large volumes of synthetic data, the proportion that effectively improves model performance is limited.","authors":["Jialong Jiang","Wenkang Hu","Jian Huang","Yuling Jiao","Xu Liu"],"url":"https://arxiv.org/abs/2505.04992"}
{"created":"2025-05-09","title":"ADNP-15: An Open-Source Histopathological Dataset for Neuritic Plaque Segmentation in Human Brain Whole Slide Images with Frequency Domain Image Enhancement for Stain Normalization","abstract":"Alzheimer's Disease (AD) is a neurodegenerative disorder characterized by amyloid-beta plaques and tau neurofibrillary tangles, which serve as key histopathological features. The identification and segmentation of these lesions are crucial for understanding AD progression but remain challenging due to the lack of large-scale annotated datasets and the impact of staining variations on automated image analysis. Deep learning has emerged as a powerful tool for pathology image segmentation; however, model performance is significantly influenced by variations in staining characteristics, necessitating effective stain normalization and enhancement techniques. In this study, we address these challenges by introducing an open-source dataset (ADNP-15) of neuritic plaques (i.e., amyloid deposits combined with a crown of dystrophic tau-positive neurites) in human brain whole slide images. We establish a comprehensive benchmark by evaluating five widely adopted deep learning models across four stain normalization techniques, providing deeper insights into their influence on neuritic plaque segmentation. Additionally, we propose a novel image enhancement method that improves segmentation accuracy, particularly in complex tissue structures, by enhancing structural details and mitigating staining inconsistencies. Our experimental results demonstrate that this enhancement strategy significantly boosts model generalization and segmentation accuracy. All datasets and code are open-source, ensuring transparency and reproducibility while enabling further advancements in the field.","authors":["Chenxi Zhao","Jianqiang Li","Qing Zhao","Jing Bai","Susana Boluda","Benoit Delatour","Lev Stimmer","Daniel Racoceanu","Gabriel Jimenez","Guanghui Fu"],"url":"https://arxiv.org/abs/2505.05041"}
{"created":"2025-05-09","title":"Statistical CSI Acquisition for Multi-frequency Massive MIMO Systems","abstract":"Multi-frequency massive multi-input multi-output (MIMO) communication is a promising strategy for both 5G and future 6G systems, ensuring reliable transmission while enhancing frequency resource utilization. Statistical channel state information (CSI) has been widely adopted in multi-frequency massive MIMO transmissions to reduce overhead and improve transmission performance. In this paper, we propose efficient and accurate methods for obtaining statistical CSI in multi-frequency massive MIMO systems. First, we introduce a multi-frequency massive MIMO channel model and analyze the mapping relationship between two types of statistical CSI, namely the angular power spectrum (APS) and the spatial covariance matrix, along with their correlation across different frequency bands. Next, we propose an autoregressive (AR) method to predict the spatial covariance matrix of any frequency band based on that of another frequency band. Furthermore, we emphasize that channels across different frequency bands share similar APS characteristics. Leveraging the maximum entropy (ME) criterion, we develop a low-complexity algorithm for high-resolution APS estimation. Simulation results validate the effectiveness of the AR-based covariance prediction method and demonstrate the high-resolution estimation capability of the ME-based approach. Furthermore, we demonstrate the effectiveness of multi-frequency cooperative transmission by applying the proposed methods to obtain statistical CSI from low-frequency bands and utilizing it for high-frequency channel transmission. This approach significantly enhances high-frequency transmission performance while effectively reducing system overhead.","authors":["Jinke Tang","Li You","Xinrui Gong","Chenjie Xie","Xiqi Gao","Xiang-Gen Xia","Xueyuan Shi"],"url":"https://arxiv.org/abs/2505.05045"}
{"created":"2025-05-09","title":"Direct Image Classification from Fourier Ptychographic Microscopy Measurements without Reconstruction","abstract":"The computational imaging technique of Fourier Ptychographic Microscopy (FPM) enables high-resolution imaging with a wide field of view and can serve as an extremely valuable tool, e.g. in the classification of cells in medical applications. However, reconstructing a high-resolution image from tens or even hundreds of measurements is computationally expensive, particularly for a wide field of view. Therefore, in this paper, we investigate the idea of classifying the image content in the FPM measurements directly without performing a reconstruction step first. We show that Convolutional Neural Networks (CNN) can extract meaningful information from measurement sequences, significantly outperforming the classification on a single band-limited image (up to 12 %) while being significantly more efficient than a reconstruction of a high-resolution image. Furthermore, we demonstrate that a learned multiplexing of several raw measurements allows maintaining the classification accuracy while reducing the amount of data (and consequently also the acquisition time) significantly.","authors":["Navya Sonal Agarwal","Jan Philipp Schneider","Kanchana Vaishnavi Gandikota","Syed Muhammad Kazim","John Meshreki","Ivo Ihrke","Michael Moeller"],"url":"https://arxiv.org/abs/2505.05054"}
{"created":"2025-05-09","title":"RepSNet: A Nucleus Instance Segmentation model based on Boundary Regression and Structural Re-parameterization","abstract":"Pathological diagnosis is the gold standard for tumor diagnosis, and nucleus instance segmentation is a key step in digital pathology analysis and pathological diagnosis. However, the computational efficiency of the model and the treatment of overlapping targets are the major challenges in the studies of this problem. To this end, a neural network model RepSNet was designed based on a nucleus boundary regression and a structural re-parameterization scheme for segmenting and classifying the nuclei in H\\&amp;E-stained histopathological images. First, RepSNet estimates the boundary position information (BPI) of the parent nucleus for each pixel. The BPI estimation incorporates the local information of the pixel and the contextual information of the parent nucleus. Then, the nucleus boundary is estimated by aggregating the BPIs from a series of pixels using a proposed boundary voting mechanism (BVM), and the instance segmentation results are computed from the estimated nucleus boundary using a connected component analysis procedure. The BVM intrinsically achieves a kind of synergistic belief enhancement among the BPIs from various pixels. Therefore, different from the methods available in literature that obtain nucleus boundaries based on a direct pixel recognition scheme, RepSNet computes its boundary decisions based on some guidances from macroscopic information using an integration mechanism. In addition, RepSNet employs a re-parametrizable encoder-decoder structure. This model can not only aggregate features from some receptive fields with various scales which helps segmentation accuracy improvement, but also reduce the parameter amount and computational burdens in the model inference phase through the structural re-parameterization technique. Extensive experiments demonstrated the superiorities of RepSNet compared to several typical benchmark models.","authors":["Shengchun Xiong","Xiangru Li","Yunpeng Zhong","Wanfen Peng"],"url":"https://arxiv.org/abs/2505.05073"}
{"created":"2025-05-09","title":"Learning dynamically inspired invariant subspaces for Koopman and transfer operator approximation","abstract":"Transfer and Koopman operator methods offer a framework for representing complex, nonlinear dynamical systems via linear transformations, enabling for a deeper understanding of the underlying dynamics. The spectrum of these operators provide important insights into system predictability and emergent behaviour, although efficiently estimating them from data can be challenging. We tackle this issue through the lens of general operator and representational learning, in which we approximate these linear operators using efficient finite-dimensional representations. Specifically, we machine-learn orthonormal, locally supported basis functions that are dynamically tailored to the system. This learned basis provides a particularly accurate approximation of the operator's action as well as a nearly invariant finite-dimensional subspace. We illustrate our approach with examples that showcase the retrieval of spectral properties from the estimated operator, and emphasise the dynamically adaptive quality of the machine-learned basis.","authors":["Gary Froyland","Kevin K\\\"uhl"],"url":"https://arxiv.org/abs/2505.05085"}
{"created":"2025-05-09","title":"MDAA-Diff: CT-Guided Multi-Dose Adaptive Attention Diffusion Model for PET Denoising","abstract":"Acquiring high-quality Positron Emission Tomography (PET) images requires administering high-dose radiotracers, which increases radiation exposure risks. Generating standard-dose PET (SPET) from low-dose PET (LPET) has become a potential solution. However, previous studies have primarily focused on single low-dose PET denoising, neglecting two critical factors: discrepancies in dose response caused by inter-patient variability, and complementary anatomical constraints derived from CT images. In this work, we propose a novel CT-Guided Multi-dose Adaptive Attention Denoising Diffusion Model (MDAA-Diff) for multi-dose PET denoising. Our approach integrates anatomical guidance and dose-level adaptation to achieve superior denoising performance under low-dose conditions. Specifically, this approach incorporates a CT-Guided High-frequency Wavelet Attention (HWA) module, which uses wavelet transforms to separate high-frequency anatomical boundary features from CT images. These extracted features are then incorporated into PET imaging through an adaptive weighted fusion mechanism to enhance edge details. Additionally, we propose the Dose-Adaptive Attention (DAA) module, a dose-conditioned enhancement mechanism that dynamically integrates dose levels into channel-spatial attention weight calculation. Extensive experiments on 18F-FDG and 68Ga-FAPI datasets demonstrate that MDAA-Diff outperforms state-of-the-art approaches in preserving diagnostic quality under reduced-dose conditions. Our code is publicly available.","authors":["Xiaolong Niu","Zanting Ye","Xu Han","Yanchao Huang","Hao Sun","Hubing Wu","Lijun Lu"],"url":"https://arxiv.org/abs/2505.05112"}
{"created":"2025-05-09","title":"Listen to Extract: Onset-Prompted Target Speaker Extraction","abstract":"We propose $\\textit{listen to extract}$ (LExt), a highly-effective while extremely-simple algorithm for monaural target speaker extraction (TSE). Given an enrollment utterance of a target speaker, LExt aims at extracting the target speaker from the speaker's mixed speech with other speakers. For each mixture, LExt concatenates an enrollment utterance of the target speaker to the mixture signal at the waveform level, and trains deep neural networks (DNN) to extract the target speech based on the concatenated mixture signal. The rationale is that, this way, an artificial speech onset is created for the target speaker and it could prompt the DNN (a) which speaker is the target to extract; and (b) spectral-temporal patterns of the target speaker that could help extraction. This simple approach produces strong TSE performance on multiple public TSE datasets including WSJ0-2mix, WHAM! and WHAMR!.","authors":["Pengjie Shen","Kangrui Chen","Shulin He","Pengru Chen","Shuqi Yuan","He Kong","Xueliang Zhang","Zhong-Qiu Wang"],"url":"https://arxiv.org/abs/2505.05114"}
{"created":"2025-05-09","title":"Error Analysis of Deep PDE Solvers for Option Pricing","abstract":"Option pricing often requires solving partial differential equations (PDEs). Although deep learning-based PDE solvers have recently emerged as quick solutions to this problem, their empirical and quantitative accuracy remain not well understood, hindering their real-world applicability. In this research, our aim is to offer actionable insights into the utility of deep PDE solvers for practical option pricing implementation. Through comparative experiments in both the Black--Scholes and the Heston model, we assess the empirical performance of two neural network algorithms to solve PDEs: the Deep Galerkin Method and the Time Deep Gradient Flow method (TDGF). We determine their empirical convergence rates and training time as functions of (i) the number of sampling stages, (ii) the number of samples, (iii) the number of layers, and (iv) the number of nodes per layer. For the TDGF, we also consider the order of the discretization scheme and the number of time steps.","authors":["Jasper Rou"],"url":"https://arxiv.org/abs/2505.05121"}
{"created":"2025-05-09","title":"Overcoming Dimensional Factorization Limits in Discrete Diffusion Models through Quantum Joint Distribution Learning","abstract":"This study explores quantum-enhanced discrete diffusion models to overcome classical limitations in learning high-dimensional distributions. We rigorously prove that classical discrete diffusion models, which calculate per-dimension transition probabilities to avoid exponential computational cost, exhibit worst-case linear scaling of Kullback-Leibler (KL) divergence with data dimension. To address this, we propose a Quantum Discrete Denoising Diffusion Probabilistic Model (QD3PM), which enables joint probability learning through diffusion and denoising in exponentially large Hilbert spaces. By deriving posterior states through quantum Bayes' theorem, similar to the crucial role of posterior probabilities in classical diffusion models, and by learning the joint probability, we establish a solid theoretical foundation for quantum-enhanced diffusion models. For denoising, we design a quantum circuit using temporal information for parameter sharing and learnable classical-data-controlled rotations for encoding. Exploiting joint distribution learning, our approach enables single-step sampling from pure noise, eliminating iterative requirements of existing models. Simulations demonstrate the proposed model's superior accuracy in modeling complex distributions compared to factorization methods. Hence, this paper establishes a new theoretical paradigm in generative models by leveraging the quantum advantage in joint distribution learning.","authors":["Chuangtao Chen","Qinglin Zhao","MengChu Zhou","Zhimin He","Haozhen Situ"],"url":"https://arxiv.org/abs/2505.05151"}
{"created":"2025-05-09","title":"Local linear Fr\\'echet curve regression in manifolds","abstract":"Global Fr\\'echet functional regression has been recently addressed from time correlated bivariate curve data evaluated in a manifold (see Torres et al. 2025). For this type of curve data sets, the present paper solves the problem of local linear approximation of the Fr\\'echet conditional mean in an extrinsic and intrinsic way. The extrinsic local linear Fr\\'echet functional regression predictor is obtained in the time varying tangent space by projection into an orthornormal basis of the ambient Hilbert space. The conditions assumed ensure the existence and uniqueness of this predictor, and its computation via exponential and logarithmic maps. A weighted Fr\\'echet mean approach is adopted in the computation of an intrinsic local linear Fr\\'echet functional regression predictor. The asymptotic optimality of this intrinsic local approximation is also proved. The performance of the empirical version of both, extrinsic and intrinsic functional predictors, and of a Nadaraya-Watson type Fr\\'echet curve predictor is illustrated in the simulation study undertaken. The finite-sample size properties are also tested in a real-data application via cross-validation. Specifically, functional prediction of the magnetic vector field from the time-varying geocentric latitude and longitude of the satellite NASA's MAGSAT spacecraft is addressed.","authors":["M. D. Ruiz-Medina","A. Torres--Signes"],"url":"https://arxiv.org/abs/2505.05168"}
{"created":"2025-05-09","title":"Smoothed analysis in compressed sensing","abstract":"Arbitrary matrices $M \\in \\mathbb{R}^{m \\times n}$, randomly perturbed in an additive manner using a random matrix $R \\in \\mathbb{R}^{m \\times n}$, are shown to asymptotically almost surely satisfy the so-called {\\sl robust null space property} whilst asymptotically meeting the optimal number of measurements required for {\\sl unique reconstruction} via $\\ell_1$-minimisation algorithms. A wide range of random perturbation matrices is considered; in that, $R$ is allowed to be sub-gaussian, sub-exponential, as well as extremely heavy-tailed, where only the first $\\log n$ moments of each entry of $R$ are bounded. A key tool driving our proofs is {\\sl Mendelson's small-ball method} ({\\em Learning without concentration}, J. ACM, Vol. $62$, $2015$).","authors":["Elad Aigner-Horev","Dan Hefetz","Michael Trushkin"],"url":"https://arxiv.org/abs/2505.05188"}
{"created":"2025-05-09","title":"A Fourier-based inference method for learning interaction kernels in particle systems","abstract":"We consider the problem of inferring the interaction kernel of stochastic interacting particle systems from observations of a single particle. We adopt a semi-parametric approach and represent the interaction kernel in terms of a generalized Fourier series. The basis functions in this expansion are tailored to the problem at hand and are chosen to be orthogonal polynomials with respect to the invariant measure of the mean-field dynamics. The generalized Fourier coefficients are obtained as the solution of an appropriate linear system whose coefficients depend on the moments of the invariant measure, and which are approximated from the particle trajectory that we observe. We quantify the approximation error in the Lebesgue space weighted by the invariant measure and study the asymptotic properties of the estimator in the joint limit as the observation interval and the number of particles tend to infinity, i.e. the joint large time-mean field limit. We also explore the regime where an increasing number of generalized Fourier coefficients is needed to represent the interaction kernel. Our theoretical results are supported by extensive numerical simulations.","authors":["Grigorios A. Pavliotis","Andrea Zanoni"],"url":"https://arxiv.org/abs/2505.05207"}
{"created":"2025-05-09","title":"Improved Brain Tumor Detection in MRI: Fuzzy Sigmoid Convolution in Deep Learning","abstract":"Early detection and accurate diagnosis are essential to improving patient outcomes. The use of convolutional neural networks (CNNs) for tumor detection has shown promise, but existing models often suffer from overparameterization, which limits their performance gains. In this study, fuzzy sigmoid convolution (FSC) is introduced along with two additional modules: top-of-the-funnel and middle-of-the-funnel. The proposed methodology significantly reduces the number of trainable parameters without compromising classification accuracy. A novel convolutional operator is central to this approach, effectively dilating the receptive field while preserving input data integrity. This enables efficient feature map reduction and enhances the model's tumor detection capability. In the FSC-based model, fuzzy sigmoid activation functions are incorporated within convolutional layers to improve feature extraction and classification. The inclusion of fuzzy logic into the architecture improves its adaptability and robustness. Extensive experiments on three benchmark datasets demonstrate the superior performance and efficiency of the proposed model. The FSC-based architecture achieved classification accuracies of 99.17%, 99.75%, and 99.89% on three different datasets. The model employs 100 times fewer parameters than large-scale transfer learning architectures, highlighting its computational efficiency and suitability for detecting brain tumors early. This research offers lightweight, high-performance deep-learning models for medical imaging applications.","authors":["Muhammad Irfan","Anum Nawaz","Riku Klen","Abdulhamit Subasi","Tomi Westerlund","Wei Chen"],"url":"https://arxiv.org/abs/2505.05208"}
{"created":"2025-05-09","title":"Normalize Everything: A Preconditioned Magnitude-Preserving Architecture for Diffusion-Based Speech Enhancement","abstract":"This paper presents a new framework for diffusion-based speech enhancement. Our method employs a Schroedinger bridge to transform the noisy speech distribution into the clean speech distribution. To stabilize and improve training, we employ time-dependent scalings of the inputs and outputs of the network, known as preconditioning. We consider two skip connection configurations, which either include or omit the current process state in the denoiser's output, enabling the network to predict either environmental noise or clean speech. Each approach leads to improved performance on different speech enhancement metrics. To maintain stable magnitude levels and balance during training, we use a magnitude-preserving network architecture that normalizes all activations and network weights to unit length. Additionally, we propose learning the contribution of the noisy input within each network block for effective input conditioning. After training, we apply a method to approximate different exponential moving average (EMA) profiles and investigate their effects on the speech enhancement performance. In contrast to image generation tasks, where longer EMA lengths often enhance mode coverage, we observe that shorter EMA lengths consistently lead to better performance on standard speech enhancement metrics. Code, audio examples, and checkpoints are available online.","authors":["Julius Richter","Danilo de Oliveira","Timo Gerkmann"],"url":"https://arxiv.org/abs/2505.05216"}
{"created":"2025-05-09","title":"White Light Specular Reflection Data Augmentation for Deep Learning Polyp Detection","abstract":"Colorectal cancer is one of the deadliest cancers today, but it can be prevented through early detection of malignant polyps in the colon, primarily via colonoscopies. While this method has saved many lives, human error remains a significant challenge, as missing a polyp could have fatal consequences for the patient. Deep learning (DL) polyp detectors offer a promising solution. However, existing DL polyp detectors often mistake white light reflections from the endoscope for polyps, which can lead to false positives.To address this challenge, in this paper, we propose a novel data augmentation approach that artificially adds more white light reflections to create harder training scenarios. Specifically, we first generate a bank of artificial lights using the training dataset. Then we find the regions of the training images that we should not add these artificial lights on. Finally, we propose a sliding window method to add the artificial light to the areas that fit of the training images, resulting in augmented images. By providing the model with more opportunities to make mistakes, we hypothesize that it will also have more chances to learn from those mistakes, ultimately improving its performance in polyp detection. Experimental results demonstrate the effectiveness of our new data augmentation method.","authors":["Jose Angel Nu\\~nez","Fabian Vazquez","Diego Adame","Xiaoyan Fu","Pengfei Gu","Bin Fu"],"url":"https://arxiv.org/abs/2505.05248"}
{"created":"2025-05-09","title":"Gap-preserving reductions and RE-completeness of independent set games","abstract":"In complexity theory, gap-preserving reductions play a crucial role in studying hardness of approximation and in analyzing the relative complexity of multiprover interactive proof systems. In the quantum setting, multiprover interactive proof systems with entangled provers correspond to gapped promise problems for nonlocal games, and the recent result MIP$^*$=RE (Ji et al., arXiv:2001.04383) shows that these are in general undecidable. However, the relative complexity of problems within MIP$^*$ is still not well-understood, as establishing gap-preserving reductions in the quantum setting presents new challenges. In this paper, we introduce a framework to study such reductions and use it to establish MIP$^*$-completeness of the gapped promise problem for the natural class of independent set games. In such a game, the goal is to determine whether a given graph contains an independent set of a specified size. We construct families of independent set games with constant question size for which the gapped promise problem is undecidable. In contrast, the same problem is decidable in polynomial time in the classical setting. To carry out our reduction, we establish a new stability theorem, which could be of independent interest, allowing us to perturb families of almost PVMs to genuine PVMs.","authors":["Laura Man\\v{c}inska","Pieter Spaas","Taro Spirig"],"url":"https://arxiv.org/abs/2505.05253"}
{"created":"2025-05-09","title":"ICNN-enhanced 2SP: Leveraging input convex neural networks for solving two-stage stochastic programming","abstract":"Two-stage stochastic programming (2SP) offers a basic framework for modelling decision-making under uncertainty, yet scalability remains a challenge due to the computational complexity of recourse function evaluation. Existing learning-based methods like Neural Two-Stage Stochastic Programming (Neur2SP) employ neural networks (NNs) as recourse function surrogates but rely on computationally intensive mixed-integer programming (MIP) formulations. We propose ICNN-enhanced 2SP, a method that leverages Input Convex Neural Networks (ICNNs) to exploit linear programming (LP) representability in convex 2SP problems. By architecturally enforcing convexity and enabling exact inference through LP, our approach eliminates the need for integer variables inherent to the conventional MIP-based formulation while retaining an exact embedding of the ICNN surrogate within the 2SP framework. This results in a more computationally efficient alternative that maintains solution quality. Comprehensive experiments reveal that ICNNs incur only marginally longer training times while achieving validation accuracy on par with their MIP-based counterparts. Across benchmark problems, ICNN-enhanced 2SP often exhibits considerably faster solution times than the MIP-based formulations while preserving solution quality, with these advantages becoming significantly more pronounced as problem scale increases. For the most challenging instances, the method achieves speedups of up to 100$\\times$ and solution quality superior to MIP-based formulations.","authors":["Yu Liu","Fabricio Oliveira"],"url":"https://arxiv.org/abs/2505.05261"}
{"created":"2025-05-09","title":"A Two-Sample Test of Text Generation Similarity","abstract":"The surge in digitized text data requires reliable inferential methods on observed textual patterns. This article proposes a novel two-sample text test for comparing similarity between two groups of documents. The hypothesis is whether the probabilistic mapping generating the textual data is identical across two groups of documents. The proposed test aims to assess text similarity by comparing the entropy of the documents. Entropy is estimated using neural network-based language models. The test statistic is derived from an estimation-and-inference framework, where the entropy is first approximated using an estimation set, followed by inference on the remaining data set. We showed theoretically that under mild conditions, the test statistic asymptotically follows a normal distribution. A multiple data-splitting strategy is proposed to enhance test power, which combines p-values into a unified decision. Various simulation studies and a real data example demonstrated that the proposed two-sample text test maintains the nominal Type one error rate while offering greater power compared to existing methods. The proposed method provides a novel solution to assert differences in document classes, particularly in fields where large-scale textual information is crucial.","authors":["Jingbin Xu","Chen Qian","Meimei Liu","Feng Guo"],"url":"https://arxiv.org/abs/2505.05269"}
{"created":"2025-05-09","title":"A Connection Between Learning to Reject and Bhattacharyya Divergences","abstract":"Learning to reject provide a learning paradigm which allows for our models to abstain from making predictions. One way to learn the rejector is to learn an ideal marginal distribution (w.r.t. the input domain) - which characterizes a hypothetical best marginal distribution - and compares it to the true marginal distribution via a density ratio. In this paper, we consider learning a joint ideal distribution over both inputs and labels; and develop a link between rejection and thresholding different statistical divergences. We further find that when one considers a variant of the log-loss, the rejector obtained by considering the joint ideal distribution corresponds to the thresholding of the skewed Bhattacharyya divergence between class-probabilities. This is in contrast to the marginal case - that is equivalent to a typical characterization of optimal rejection, Chow's Rule - which corresponds to a thresholding of the Kullback-Leibler divergence. In general, we find that rejecting via a Bhattacharyya divergence is less aggressive than Chow's Rule.","authors":["Alexander Soen"],"url":"https://arxiv.org/abs/2505.05273"}
{"created":"2025-05-09","title":"Benchmarking Ophthalmology Foundation Models for Clinically Significant Age Macular Degeneration Detection","abstract":"Self-supervised learning (SSL) has enabled Vision Transformers (ViTs) to learn robust representations from large-scale natural image datasets, enhancing their generalization across domains. In retinal imaging, foundation models pretrained on either natural or ophthalmic data have shown promise, but the benefits of in-domain pretraining remain uncertain. To investigate this, we benchmark six SSL-pretrained ViTs on seven digital fundus image (DFI) datasets totaling 70,000 expert-annotated images for the task of moderate-to-late age-related macular degeneration (AMD) identification. Our results show that iBOT pretrained on natural images achieves the highest out-of-distribution generalization, with AUROCs of 0.80-0.97, outperforming domain-specific models, which achieved AUROCs of 0.78-0.96 and a baseline ViT-L with no pretraining, which achieved AUROCs of 0.68-0.91. These findings highlight the value of foundation models in improving AMD identification and challenge the assumption that in-domain pretraining is necessary. Furthermore, we release BRAMD, an open-access dataset (n=587) of DFIs with AMD labels from Brazil.","authors":["Benjamin A. Cohen","Jonathan Fhima","Meishar Meisel","Baskin Meital","Luis Filipe Nakayama","Eran Berkowitz","Joachim A. Behar"],"url":"https://arxiv.org/abs/2505.05291"}
{"created":"2025-05-09","title":"Operator-Level Quantum Acceleration of Non-Logconcave Sampling","abstract":"Sampling from probability distributions of the form $\\sigma \\propto e^{-\\beta V}$, where $V$ is a continuous potential, is a fundamental task across physics, chemistry, biology, computer science, and statistics. However, when $V$ is non-convex, the resulting distribution becomes non-logconcave, and classical methods such as Langevin dynamics often exhibit poor performance. We introduce the first quantum algorithm that provably accelerates a broad class of continuous-time sampling dynamics. For Langevin dynamics, our method encodes the target Gibbs measure into the amplitudes of a quantum state, identified as the kernel of a block matrix derived from a factorization of the Witten Laplacian operator. This connection enables Gibbs sampling via singular value thresholding and yields the first provable quantum advantage with respect to the Poincar\\'e constant in the non-logconcave setting. Building on this framework, we further develop the first quantum algorithm that accelerates replica exchange Langevin diffusion, a widely used method for sampling from complex, rugged energy landscapes.","authors":["Jiaqi Leng","Zhiyan Ding","Zherui Chen","Lin Lin"],"url":"https://arxiv.org/abs/2505.05301"}
{"created":"2025-05-09","title":"Augmented Deep Contexts for Spatially Embedded Video Coding","abstract":"Most Neural Video Codecs (NVCs) only employ temporal references to generate temporal-only contexts and latent prior. These temporal-only NVCs fail to handle large motions or emerging objects due to limited contexts and misaligned latent prior. To relieve the limitations, we propose a Spatially Embedded Video Codec (SEVC), in which the low-resolution video is compressed for spatial references. Firstly, our SEVC leverages both spatial and temporal references to generate augmented motion vectors and hybrid spatial-temporal contexts. Secondly, to address the misalignment issue in latent prior and enrich the prior information, we introduce a spatial-guided latent prior augmented by multiple temporal latent representations. At last, we design a joint spatial-temporal optimization to learn quality-adaptive bit allocation for spatial references, further boosting rate-distortion performance. Experimental results show that our SEVC effectively alleviates the limitations in handling large motions or emerging objects, and also reduces 11.9% more bitrate than the previous state-of-the-art NVC while providing an additional low-resolution bitstream. Our code and model are available at https://github.com/EsakaK/SEVC.","authors":["Yifan Bian","Chuanbo Tang","Li Li","Dong Liu"],"url":"https://arxiv.org/abs/2505.05309"}
{"created":"2025-05-09","title":"Robust Online Learning with Private Information","abstract":"This paper investigates the robustness of online learning algorithms when learners possess private information. No-external-regret algorithms, prevalent in machine learning, are vulnerable to strategic manipulation, allowing an adaptive opponent to extract full surplus. Even standard no-weak-external-regret algorithms, designed for optimal learning in stationary environments, exhibit similar vulnerabilities. This raises a fundamental question: can a learner simultaneously prevent full surplus extraction by adaptive opponents while maintaining optimal performance in well-behaved environments? To address this, we model the problem as a two-player repeated game, where the learner with private information plays against the environment, facing ambiguity about the environment's types: stationary or adaptive. We introduce \\emph{partial safety} as a key design criterion for online learning algorithms to prevent full surplus extraction. We then propose the \\emph{Explore-Exploit-Punish} (\\textsf{EEP}) algorithm and prove that it satisfies partial safety while achieving optimal learning in stationary environments, and has a variant that delivers improved welfare performance. Our findings highlight the risks of applying standard online learning algorithms in strategic settings with adverse selection. We advocate for a shift toward online learning algorithms that explicitly incorporate safeguards against strategic manipulation while ensuring strong learning performance.","authors":["Kyohei Okumura"],"url":"https://arxiv.org/abs/2505.05341"}
{"created":"2025-05-09","title":"High-fidelity Grain Growth Modeling: Leveraging Deep Learning for Fast Computations","abstract":"Grain growth simulation is crucial for predicting metallic material microstructure evolution during annealing and resulting final mechanical properties, but traditional partial differential equation-based methods are computationally expensive, creating bottlenecks in materials design and manufacturing. In this work, we introduce a machine learning framework that combines a Convolutional Long Short-Term Memory networks with an Autoencoder to efficiently predict grain growth evolution. Our approach captures both spatial and temporal aspects of grain evolution while encoding high-dimensional grain structure data into a compact latent space for pattern learning, enhanced by a novel composite loss function combining Mean Squared Error, Structural Similarity Index Measurement, and Boundary Preservation to maintain structural integrity of grain boundary topology of the prediction. Results demonstrated that our machine learning approach accelerates grain growth prediction by up to \\SI{89}{\\times} faster, reducing computation time from \\SI{10}{\\minute} to approximately \\SI{10}{\\second} while maintaining high-fidelity predictions. The best model (S-30-30) achieving a structural similarity score of \\SI{86.71}{\\percent} and mean grain size error of just \\SI{0.07}{\\percent}. All models accurately captured grain boundary topology, morphology, and size distributions. This approach enables rapid microstructural prediction for applications where conventional simulations are prohibitively time-consuming, potentially accelerating innovation in materials science and manufacturing.","authors":["Pungponhavoan Tep","Marc Bernacki"],"url":"https://arxiv.org/abs/2505.05354"}
{"created":"2025-05-09","title":"From Sleep Staging to Spindle Detection: Evaluating End-to-End Automated Sleep Analysis","abstract":"Automation of sleep analysis, including both macrostructural (sleep stages) and microstructural (e.g., sleep spindles) elements, promises to enable large-scale sleep studies and to reduce variance due to inter-rater incongruencies. While individual steps, such as sleep staging and spindle detection, have been studied separately, the feasibility of automating multi-step sleep analysis remains unclear. Here, we evaluate whether a fully automated analysis using state-of-the-art machine learning models for sleep staging (RobustSleepNet) and subsequent spindle detection (SUMOv2) can replicate findings from an expert-based study of bipolar disorder. The automated analysis qualitatively reproduced key findings from the expert-based study, including significant differences in fast spindle densities between bipolar patients and healthy controls, accomplishing in minutes what previously took months to complete manually. While the results of the automated analysis differed quantitatively from the expert-based study, possibly due to biases between expert raters or between raters and the models, the models individually performed at or above inter-rater agreement for both sleep staging and spindle detection. Our results demonstrate that fully automated approaches have the potential to facilitate large-scale sleep research. We are providing public access to the tools used in our automated analysis by sharing our code and introducing SomnoBot, a privacy-preserving sleep analysis platform.","authors":["Niklas Grieger","Siamak Mehrkanoon","Philipp Ritter","Stephan Bialonski"],"url":"https://arxiv.org/abs/2505.05371"}
{"created":"2025-05-09","title":"OcularAge: A Comparative Study of Iris and Periocular Images for Pediatric Age Estimation","abstract":"Estimating a child's age from ocular biometric images is challenging due to subtle physiological changes and the limited availability of longitudinal datasets. Although most biometric age estimation studies have focused on facial features and adult subjects, pediatric-specific analysis, particularly of the iris and periocular regions, remains relatively unexplored. This study presents a comparative evaluation of iris and periocular images for estimating the ages of children aged between 4 and 16 years. We utilized a longitudinal dataset comprising more than 21,000 near-infrared (NIR) images, collected from 288 pediatric subjects over eight years using two different imaging sensors. A multi-task deep learning framework was employed to jointly perform age prediction and age-group classification, enabling a systematic exploration of how different convolutional neural network (CNN) architectures, particularly those adapted for non-square ocular inputs, capture the complex variability inherent in pediatric eye images. The results show that periocular models consistently outperform iris-based models, achieving a mean absolute error (MAE) of 1.33 years and an age-group classification accuracy of 83.82%. These results mark the first demonstration that reliable age estimation is feasible from children's ocular images, enabling privacy-preserving age checks in child-centric applications. This work establishes the first longitudinal benchmark for pediatric ocular age estimation, providing a foundation for designing robust, child-focused biometric systems. The developed models proved resilient across different imaging sensors, confirming their potential for real-world deployment. They also achieved inference speeds of less than 10 milliseconds per image on resource-constrained VR headsets, demonstrating their suitability for real-time applications.","authors":["Naveenkumar G Venkataswamy","Poorna Ravi","Stephanie Schuckers","Masudul H. Imtiaz"],"url":"https://arxiv.org/abs/2505.05374"}
{"created":"2025-05-09","title":"Representing spherical tensors with scalar-based machine-learning models","abstract":"Rotational symmetry plays a central role in physics, providing an elegant framework to describe how the properties of 3D objects -- from atoms to the macroscopic scale -- transform under the action of rigid rotations. Equivariant models of 3D point clouds are able to approximate structure-property relations in a way that is fully consistent with the structure of the rotation group, by combining intermediate representations that are themselves spherical tensors. The symmetry constraints however make this approach computationally demanding and cumbersome to implement, which motivates increasingly popular unconstrained architectures that learn approximate symmetries as part of the training process. In this work, we explore a third route to tackle this learning problem, where equivariant functions are expressed as the product of a scalar function of the point cloud coordinates and a small basis of tensors with the appropriate symmetry. We also propose approximations of the general expressions that, while lacking universal approximation properties, are fast, simple to implement, and accurate in practical settings.","authors":["Michelangelo Domina","Filippo Bigi","Paolo Pegolo","Michele Ceriotti"],"url":"https://arxiv.org/abs/2505.05404"}
{"created":"2025-05-09","title":"Robustly optimal dynamics for active matter reservoir computing","abstract":"We study the information processing abilities of active matter in the reservoir computing (RC) paradigm, using a model that is externally driven to infer the future state of a chaotic signal. The simulated system closely follows a previously reported model. We uncover an exceptional dynamical regime of agent dynamics that has been overlooked heretofore. It appears robustly optimal across varying physical parameters and inference tasks, thus providing valuable insights into computation and inference with physical systems more generally. The ability to form effective mechanisms for information processing are primarily determined by the system's own intrinsic relaxation abilities. These are identifiable when probing the system without a specific inference goal and manifest when testing minimalistic single-particle reservoirs. The regime that achieves optimal computation is situated just below the critical damping threshold, involving a microscopic dynamical relaxation with multiple stages. The optimal system is adaptable under chaotic external driving, due to a diversity in response mechanisms that emerge like rapid alternations between quasi-stationary and highly nonlinear dynamical states. Both coherent and incoherent dynamics contribute to their operation, partly at dissimilar scales of space and delay time. Correlations on agent dynamics can indicate the best-performing regimes and onsets of tight relationships between the responding system and the fluctuating driver. As this model of computation is interpretable in physical terms, it facilitates re-framing inquiries regarding learning and unconventional computing with a fresh rationale for many-body physics out of equilibrium.","authors":["Mario U. Gaimann","Miriam Klopotek"],"url":"https://arxiv.org/abs/2505.05420"}
{"created":"2025-05-09","title":"P vs. NP","abstract":"The method for analyzing algorithmic runtime complexity using decision trees is discussed using the sorting algorithm. This method is then extended to optimal algorithms which may find all cliques of size q in network N, or simply the first clique of size q in network N. Finally, the lower bound of such decision trees is demonstrated to not be in P.","authors":["Daniel Uribe"],"url":"https://arxiv.org/abs/1601.03619"}
{"created":"2025-05-09","title":"PointBA: Towards Backdoor Attacks in 3D Point Cloud","abstract":"3D deep learning has been increasingly more popular for a variety of tasks including many safety-critical applications. However, recently several works raise the security issues of 3D deep models. Although most of them consider adversarial attacks, we identify that backdoor attack is indeed a more serious threat to 3D deep learning systems but remains unexplored. We present the backdoor attacks in 3D point cloud with a unified framework that exploits the unique properties of 3D data and networks. In particular, we design two attack approaches on point cloud: the poison-label backdoor attack (PointPBA) and the clean-label backdoor attack (PointCBA). The first one is straightforward and effective in practice, while the latter is more sophisticated assuming there are certain data inspections. The attack algorithms are mainly motivated and developed by 1) the recent discovery of 3D adversarial samples suggesting the vulnerability of deep models under spatial transformation; 2) the proposed feature disentanglement technique that manipulates the feature of the data through optimization methods and its potential to embed a new task. Extensive experiments show the efficacy of the PointPBA with over 95% success rate across various 3D datasets and models, and the more stealthy PointCBA with around 50% success rate. Our proposed backdoor attack in 3D point cloud is expected to perform as a baseline for improving the robustness of 3D deep models.","authors":["Xinke Li","Zhirui Chen","Yue Zhao","Zekun Tong","Yabang Zhao","Andrew Lim","Joey Tianyi Zhou"],"url":"https://arxiv.org/abs/2103.16074"}
{"created":"2025-05-09","title":"Spectral Convergence of Symmetrized Graph Laplacian on manifolds with boundary","abstract":"We study the spectral convergence of a symmetrized Graph Laplacian matrix induced by a Gaussian kernel evaluated on pairs of embedded data, sampled from a manifold with boundary, a sub-manifold of $\\mathbb{R}^m$. Specifically, we deduce the convergence rates for eigenpairs of the discrete Graph-Laplacian matrix to the eigensolutions of the Laplace-Beltrami operator that are well-defined on manifolds with boundary, including the homogeneous Neumann and Dirichlet boundary conditions. For the Dirichlet problem, we deduce the convergence of the \\emph{truncated Graph Laplacian}, which is recently numerically observed in applications, and provide a detailed numerical investigation on simple manifolds. Our method of proof relies on the min-max argument over a compact and symmetric integral operator, leveraging the RKHS theory for spectral convergence of integral operator and a recent pointwise asymptotic result of a Gaussian kernel integral operator on manifolds with boundary.","authors":["J. Wilson Peoples","John Harlim"],"url":"https://arxiv.org/abs/2110.06988"}
{"created":"2025-05-09","title":"Parallel Contests for Crowdsourcing Reviews: Existence and Quality of Equilibria","abstract":"Motivated by the intricacies of allocating treasury funds in blockchain settings, we study the problem of crowdsourcing reviews for many different proposals, in parallel. During the reviewing phase, every reviewer can select the proposals to write reviews for, as well as the quality of each review. The quality levels follow certain very coarse community guidelines and can have values such as 'excellent' or 'good'. Based on these scores and the distribution of reviews, every reviewer will receive some reward for their efforts. In this paper, we design a reward scheme and show that it always has pure Nash equilibria, for any set of proposals and reviewers. In addition, we show that these equilibria guarantee constant factor approximations for two natural metrics: the total quality of all reviews, as well as the fraction of proposals that received at least one review, compared to the optimal outcome.","authors":["Georgios Birmpas","Lyudmila Kovalchuk","Philip Lazos","Roman Oliynykov"],"url":"https://arxiv.org/abs/2202.04064"}
{"created":"2025-05-09","title":"Transformer-based assignment decision network for multiple object tracking","abstract":"Data association is a crucial component for any multiple object tracking (MOT) method that follows the tracking-by-detection paradigm. To generate complete trajectories such methods employ a data association process to establish assignments between detections and existing targets during each timestep. Recent data association approaches try to solve either a multi-dimensional linear assignment task or a network flow minimization problem or tackle it via multiple hypotheses tracking. However, during inference an optimization step that computes optimal assignments is required for every sequence frame inducing additional complexity to any given solution. To this end, in the context of this work we introduce Transformer-based Assignment Decision Network (TADN) that tackles data association without the need of any explicit optimization during inference. In particular, TADN can directly infer assignment pairs between detections and active targets in a single forward pass of the network. We have integrated TADN in a rather simple MOT framework, designed a novel training strategy for efficient end-to-end training and demonstrated the high potential of our approach for online visual tracking-by-detection MOT on several popular benchmarks, i.e. MOT17, MOT20 and UA-DETRAC. Our proposed approach demonstrates strong performance in most evaluation metrics despite its simple nature as a tracker lacking significant auxiliary components such as occlusion handling or re-identification. The implementation of our method is publicly available at https://github.com/psaltaath/tadn-mot.","authors":["Athena Psalta","Vasileios Tsironis","Konstantinos Karantzalos"],"url":"https://arxiv.org/abs/2208.03571"}
{"created":"2025-05-09","title":"Label-Efficient Deep Learning in Medical Image Analysis: Challenges and Future Directions","abstract":"Deep learning has significantly advanced medical imaging analysis (MIA), achieving state-of-the-art performance across diverse clinical tasks. However, its success largely depends on large-scale, high-quality labeled datasets, which are costly and time-consuming to obtain due to the need for expert annotation. To mitigate this limitation, label-efficient deep learning methods have emerged to improve model performance under limited supervision by leveraging labeled, unlabeled, and weakly labeled data. In this survey, we systematically review over 350 peer-reviewed studies and present a comprehensive taxonomy of label-efficient learning methods in MIA. These methods are categorized into four labeling paradigms: no label, insufficient label, inexact label, and label refinement. For each category, we analyze representative techniques across imaging modalities and clinical applications, highlighting shared methodological principles and task-specific adaptations. We also examine the growing role of health foundation models (HFMs) in enabling label-efficient learning through large-scale pre-training and transfer learning, enhancing the use of limited annotations in downstream tasks. Finally, we identify current challenges and future directions to facilitate the translation of label-efficient learning from research promise to everyday clinical care.","authors":["Cheng Jin","Zhengrui Guo","Yi Lin","Luyang Luo","Hao Chen"],"url":"https://arxiv.org/abs/2303.12484"}
{"created":"2025-05-09","title":"Metamathematics of Algorithmic Composition","abstract":"This essay recounts my personal journey towards a deeper understanding of the mathematical foundations of algorithmic music composition. I do not spend much time on specific mathematical algorithms used by composers; rather, I focus on general issues such as fundamental limits and possibilities, by analogy with metalogic, metamathematics, and computability theory. I discuss implications from these foundations for the future of algorithmic composition.","authors":["Michael Gogins"],"url":"https://arxiv.org/abs/2305.15601"}
{"created":"2025-05-09","title":"A Fast Algorithm for Computing Prefix Probabilities","abstract":"Multiple algorithms are known for efficiently calculating the prefix probability of a string under a probabilistic context-free grammar (PCFG). Good algorithms for the problem have a runtime cubic in the length of the input string. However, some proposed algorithms are suboptimal with respect to the size of the grammar. This paper proposes a novel speed-up of Jelinek and Lafferty's (1991) algorithm, whose original runtime is $O(n^3 |N|^3 + |N|^4)$, where $n$ is the input length and $|N|$ is the number of non-terminals in the grammar. In contrast, our speed-up runs in $O(n^2 |N|^3+n^3|N|^2)$.","authors":["Franz Nowak","Ryan Cotterell"],"url":"https://arxiv.org/abs/2306.02303"}
{"created":"2025-05-09","title":"Position: AI Evaluation Should Learn from How We Test Humans","abstract":"As AI systems continue to evolve, their rigorous evaluation becomes crucial for their development and deployment. Researchers have constructed various large-scale benchmarks to determine their capabilities, typically against a gold-standard test set and report metrics averaged across all items. However, this static evaluation paradigm increasingly shows its limitations, including high evaluation costs, data contamination, and the impact of low-quality or erroneous items on evaluation reliability and efficiency. In this Position, drawing from human psychometrics, we discuss a paradigm shift from static evaluation methods to adaptive testing. This involves estimating the characteristics or value of each test item in the benchmark, and tailoring each model's evaluation instead of relying on a fixed test set. This paradigm provides robust ability estimation, uncovering the latent traits underlying a model's observed scores. This position paper analyze the current possibilities, prospects, and reasons for adopting psychometrics in AI evaluation. We argue that psychometrics, a theory originating in the 20th century for human assessment, could be a powerful solution to the challenges in today's AI evaluations.","authors":["Yan Zhuang","Qi Liu","Zachary A. Pardos","Patrick C. Kyllonen","Jiyun Zu","Zhenya Huang","Shijin Wang","Enhong Chen"],"url":"https://arxiv.org/abs/2306.10512"}
{"created":"2025-05-09","title":"Combating Confirmation Bias: A Unified Pseudo-Labeling Framework for Entity Alignment","abstract":"Entity alignment (EA) aims at identifying equivalent entity pairs across different knowledge graphs (KGs) that refer to the same real-world identity. To circumvent the shortage of seed alignments provided for training, recent EA models utilize pseudo-labeling strategies to iteratively add unaligned entity pairs predicted with high confidence to the seed alignments for model training. However, the adverse impact of confirmation bias during pseudo-labeling has been largely overlooked, thus hindering entity alignment performance. To systematically combat confirmation bias for pseudo-labeling-based entity alignment, we propose a Unified Pseudo-Labeling framework for Entity Alignment (UPL-EA) that explicitly eliminates pseudo-labeling errors to boost the accuracy of entity alignment. UPL-EA consists of two complementary components: (1) Optimal Transport (OT)-based pseudo-labeling uses discrete OT modeling as an effective means to determine entity correspondences and reduce erroneous matches across two KGs. An effective criterion is derived to infer pseudo-labeled alignments that satisfy one-to-one correspondences; (2) Parallel pseudo-label ensembling refines pseudo-labeled alignments by combining predictions over multiple models independently trained in parallel. The ensembled pseudo-labeled alignments are thereafter used to augment seed alignments to reinforce subsequent model training for alignment inference. The effectiveness of UPL-EA in eliminating pseudo-labeling errors is both theoretically supported and experimentally validated. Our extensive results and in-depth analyses demonstrate the superiority of UPL-EA over 15 competitive baselines and its utility as a general pseudo-labeling framework for entity alignment.","authors":["Qijie Ding","Jie Yin","Daokun Zhang","Junbin Gao"],"url":"https://arxiv.org/abs/2307.02075"}
{"created":"2025-05-09","title":"Semi-supervised Underwater Image Enhancement Using A Physics-Aware Triple-Stream Network","abstract":"Underwater images normally suffer from degradation due to the transmission medium of water bodies. Both traditional prior-based approaches and deep learning-based methods have been used to address this problem. However, the inflexible assumption of the former often impairs their effectiveness in handling diverse underwater scenes, while the generalization of the latter to unseen images is usually weakened by insufficient data. In this study, we leverage both the physics-based Image Formation Model (IFM) and deep learning techniques for Underwater Image Enhancement (UIE). To this end, we propose a novel Physics-Aware Triple-Stream Underwater Image Enhancement Network, i.e., PATS-UIENet, which comprises a Direct Signal Transmission Estimation Steam (D-Stream), a Backscatter Signal Transmission Estimation Steam (B-Stream) and an Ambient Light Estimation Stream (A-Stream). This network fulfills the UIE task by explicitly estimating the degradation parameters of a revised IFM. We also adopt an IFM-inspired semi-supervised learning framework, which exploits both the labeled and unlabeled images, to address the issue of insufficient data. To our knowledge, such a physics-aware deep network and the IFM-inspired semi-supervised learning framework have not been used for the UIE task before. Our method performs better than, or at least comparably to, sixteen baselines across six testing sets in the degradation estimation and UIE tasks. These promising results should be due to the fact that the proposed method can not only model the degradation but also learn the characteristics of diverse underwater scenes.","authors":["Shixuan Xu","Hao Qi","Xinghui Dong"],"url":"https://arxiv.org/abs/2307.11470"}
{"created":"2025-05-09","title":"Compressed Private Aggregation for Scalable and Robust Federated Learning over Massive Networks","abstract":"Federated learning (FL) is an emerging paradigm that allows a central server to train machine learning models using remote users' data. Despite its growing popularity, FL faces challenges in preserving the privacy of local datasets, its sensitivity to poisoning attacks by malicious users, and its communication overhead. The latter is additionally considerably dominant in large-scale networks. These limitations are often individually mitigated by local differential privacy (LDP) mechanisms, robust aggregation, compression, and user selection techniques, which typically come at the cost of accuracy. In this work, we present compressed private aggregation (CPA), that allows massive deployments to simultaneously communicate at extremely low bit rates while achieving privacy, anonymity, and resilience to malicious users. CPA randomizes a codebook for compressing the data into a few bits using nested lattice quantizers, while ensuring anonymity and robustness, with a subsequent perturbation to hold LDP. The proposed CPA is proven to result in FL convergence in the same asymptotic rate as FL without privacy, compression, and robustness considerations, while satisfying both anonymity and LDP requirements. These analytical properties are empirically confirmed in a numerical study, where we demonstrate the performance gains of CPA compared with separate mechanisms for compression and privacy for training different image classification models, as well as its robustness in mitigating the harmful effects of malicious users.","authors":["Natalie Lang","Nir Shlezinger","Rafael G. L. D'Oliveira","Salim El Rouayheb"],"url":"https://arxiv.org/abs/2308.00540"}
{"created":"2025-05-09","title":"On Incremental Stability of Interconnected Switched Systems","abstract":"In this paper, the incremental stability of interconnected switched nonlinear systems is discussed. The nature of switching considered is state-dependent. The incremental stability of the switched interconnected system is a stronger property compared to the conventional notion of stability. Even if individual systems in the interconnected setting are stable, guaranteeing stability for the overall system is challenging. However, one of the important features of incremental stability is that the notion is preserved over interconnection. Here, leveraging the contraction-theoretic tools, we derive a set of sufficient conditions for the overall interconnection consisting of bimodal switched systems. To showcase the wider usability of our proposed results, we have also included the effect of external input, which leads to the study of incremental input-to-state stability ($\\delta$-ISS). For the case of feedback interconnection, the small gain characterisation is presented for the overall system's $\\delta$-ISS. Further, for a special case of feedback, i.e., cascade interconnection, the results are derived. The derived conditions are based on the matrix measure, making it computationally tractable and general. To make the results more general, a generalised interconnection of bimodal switched systems is studied and corresponding sufficient condition for $\\delta$-ISS are presented. Two numerical examples are demonstrated and supported with simulation results to verify the theoretical claims.","authors":["Bhabani Shankar Dey","Indra Narayan Kar","Pushpak Jagtap"],"url":"https://arxiv.org/abs/2308.12746"}
{"created":"2025-05-09","title":"On the Role of Search Budgets in Model-Based Software Refactoring Optimization","abstract":"Software model optimization is a process that automatically generates design alternatives aimed at improving quantifiable non-functional properties of software systems, such as performance and reliability. Multi-objective evolutionary algorithms effectively help designers identify trade-offs among the desired non-functional properties. To reduce the use of computational resources, this work examines the impact of implementing a search budget to limit the search for design alternatives. In particular, we analyze how time budgets affect the quality of Pareto fronts by utilizing quality indicators and exploring the structural features of the generated design alternatives. This study identifies distinct behavioral differences among evolutionary algorithms when a search budget is implemented. It further reveals that design alternatives generated under a budget are structurally different from those produced without one. Additionally, we offer recommendations for designers on selecting algorithms in relation to time constraints, thereby facilitating the effective application of automated refactoring to improve non-functional properties.","authors":["J. Andres Diaz-Pace","Daniele Di Pompeo","Michele Tucci"],"url":"https://arxiv.org/abs/2308.15179"}
{"created":"2025-05-09","title":"Connecting NTK and NNGP: A Unified Theoretical Framework for Wide Neural Network Learning Dynamics","abstract":"Artificial neural networks have revolutionized machine learning in recent years, but a complete theoretical framework for their learning process is still lacking. Substantial advances were achieved for wide networks, within two disparate theoretical frameworks: the Neural Tangent Kernel (NTK), which assumes linearized gradient descent dynamics, and the Bayesian Neural Network Gaussian Process (NNGP). We unify these two theories using gradient descent learning with an additional noise in an ensemble of wide deep networks. We construct an analytical theory for the network input-output function and introduce a new time-dependent Neural Dynamical Kernel (NDK) from which both NTK and NNGP kernels are derived. We identify two learning phases: a gradient-driven learning phase, dominated by loss minimization, in which the time scale is governed by the initialization variance. It is followed by a slow diffusive learning stage, where the parameters sample the solution space, with a time constant decided by the noise and the Bayesian prior variance. The two variance parameters strongly affect the performance in the two regimes, especially in sigmoidal neurons. In contrast to the exponential convergence of the mean predictor in the initial phase, the convergence to the equilibrium is more complex and may behave nonmonotonically. By characterizing the diffusive phase, our work sheds light on representational drift in the brain, explaining how neural activity changes continuously without degrading performance, either by ongoing gradient signals that synchronize the drifts of different synapses or by architectural biases that generate task-relevant information that is robust against the drift process. This work closes the gap between the NTK and NNGP theories, providing a comprehensive framework for the learning process of deep wide neural networks and for analyzing dynamics in biological circuits.","authors":["Yehonatan Avidan","Qianyi Li","Haim Sompolinsky"],"url":"https://arxiv.org/abs/2309.04522"}
{"created":"2025-05-09","title":"USTEP: Spatio-Temporal Predictive Learning under A Unified View","abstract":"Spatio-temporal predictive learning plays a crucial role in self-supervised learning, with wide-ranging applications across a diverse range of fields. Previous approaches for temporal modeling fall into two categories: recurrent-based and recurrent-free methods. The former, while meticulously processing frames one by one, neglect short-term spatio-temporal information redundancies, leading to inefficiencies. The latter naively stack frames sequentially, overlooking the inherent temporal dependencies. In this paper, we re-examine the two dominant temporal modeling approaches within the realm of spatio-temporal predictive learning, offering a unified perspective. Building upon this analysis, we introduce USTEP (Unified Spatio-TEmporal Predictive learning), an innovative framework that reconciles the recurrent-based and recurrent-free methods by integrating both micro-temporal and macro-temporal scales. Extensive experiments on a wide range of spatio-temporal predictive learning demonstrate that USTEP achieves significant improvements over existing temporal modeling approaches, thereby establishing it as a robust solution for a wide range of spatio-temporal applications.","authors":["Cheng Tan","Jue Wang","Zhangyang Gao","Siyuan Li","Stan Z. Li"],"url":"https://arxiv.org/abs/2310.05829"}
{"created":"2025-05-09","title":"Two Views Are Better than One: Monocular 3D Pose Estimation with Multiview Consistency","abstract":"Deducing a 3D human pose from a single 2D image is inherently challenging because multiple 3D poses can correspond to the same 2D representation. 3D data can resolve this pose ambiguity, but it is expensive to record and requires an intricate setup that is often restricted to controlled lab environments. We propose a method that improves the performance of deep learning-based monocular 3D human pose estimation models by using multiview data only during training, but not during inference. We introduce a novel loss function, consistency loss, which operates on two synchronized views. This approach is simpler than previous models that require 3D ground truth or intrinsic and extrinsic camera parameters. Our consistency loss penalizes differences in two pose sequences after rigid alignment. We also demonstrate that our consistency loss substantially improves performance for fine-tuning without requiring 3D data. Furthermore, we show that using our consistency loss can yield state-of-the-art performance when training models from scratch in a semi-supervised manner. Our findings provide a simple way to capture new data, e.g in a new domain. This data can be added using off-the-shelf cameras with no calibration requirements. We make all our code and data publicly available.","authors":["Christian Keilstrup Ingwersen","Rasmus Tirsgaard","Rasmus Nylander","Janus N{\\o}rtoft Jensen","Anders Bjorholm Dahl","Morten Rieger Hannemose"],"url":"https://arxiv.org/abs/2311.12421"}
{"created":"2025-05-09","title":"The Inadequacy of Similarity-based Privacy Metrics: Privacy Attacks against \"Truly Anonymous\" Synthetic Datasets","abstract":"Generative models producing synthetic data are meant to provide a privacy-friendly approach to releasing data. However, their privacy guarantees are only considered robust when models satisfy Differential Privacy (DP). Alas, this is not a ubiquitous standard, as many leading companies (and, in fact, research papers) use ad-hoc privacy metrics based on testing the statistical similarity between synthetic and real data.","authors":["Georgi Ganev","Emiliano De Cristofaro"],"url":"https://arxiv.org/abs/2312.05114"}
{"created":"2025-05-09","title":"Fast Whole-Body Strain Regulation in Continuum Robots","abstract":"We propose reaching steps towards the real-time strain control of multiphysics, multiscale continuum soft robots. To study this problem fundamentally, we ground ourselves in a model-based control setting enabled by mathematically precise dynamics of a soft robot prototype. Poised to integrate, rather than reject, inherent mechanical nonlinearities for embodied compliance, we first separate the original robot dynamics into separate subdynamics -- aided by a perturbing time-scale separation parameter. Second, we prescribe a set of stabilizing nonlinear backstepping controllers for regulating the resulting subsystems' strain dynamics. Third, we study the interconnected singularly perturbed system by analyzing and establishing its stability. Fourth, our theories are backed up by fast numerical results on a single arm of the Octopus robot arm. We demonstrate strain regulation to equilibrium, in a significantly reduced time, of the whole-body reduced-order dynamics of an infinite degrees-of-freedom soft robot. This paper communicates our thinking within the backdrop of embodied intelligence: it informs our conceptualization, formulation, computational setup, and yields improved control performance for infinite degrees-of-freedom soft robots.","authors":["Lekan Molu"],"url":"https://arxiv.org/abs/2312.06039"}
{"created":"2025-05-09","title":"Unravelling Expressive Delegations: Complexity and Normative Analysis","abstract":"We consider binary group decision-making under a rich model of liquid democracy recently proposed by Colley, Grandi, and Novaro (2022): agents submit ranked delegation options, where each option may be a function of multiple agents' votes; e.g., \"I vote yes if a majority of my friends vote yes.\" Such ballots are unravelled into a profile of direct votes by selecting one entry from each ballot so as not to introduce cyclic dependencies. We study delegation via monotonic Boolean functions, and two unravelling procedures: MinSum, which minimises the sum of the ranks of the chosen entries, and its egalitarian counterpart, MinMax. We provide complete computational dichotomies: MinSum is hard to compute (and approximate) as soon as any non-trivial functions are permitted, and polynomial otherwise; for MinMax the easiness results extend to arbitrary-arity logical ORs and ANDs taken in isolation, but not beyond. For the classic model of delegating to individual agents, we give asymptotically near-tight algorithms for carrying out the two procedures and efficient algorithms for finding optimal unravellings with the highest vote count for a given alternative. These algorithms inspire novel tie-breaking rules for the setup of voting to change a status quo. We then introduce a new axiom, which can be viewed as a variant of the participation axiom, and use algorithmic techniques developed earlier in the paper to show that it is satisfied by MinSum and a lexicographic refinement of MinMax (but not MinMax itself).","authors":["Giannis Tyrovolas","Andrei Constantinescu","Edith Elkind"],"url":"https://arxiv.org/abs/2312.11932"}
{"created":"2025-05-09","title":"Learning Stable Koopman Embeddings for Identification and Control","abstract":"This paper introduces new model parameterizations for learning discrete-time dynamical systems from data via the Koopman operator and studies their properties. Whereas most existing works on Koopman learning do not take into account the stability or stabilizability of the model -- two fundamental pieces of prior knowledge about a given system to be identified -- in this paper, we propose new classes of Koopman models that have built-in guarantees of these properties. These guarantees are achieved through a novel {\\em direct parameterization approach} that leads to {\\em unconstrained} optimization problems over their parameter sets. {These results rely on the invertibility of the vector fields for autonomous systems and the generalized feedback linearizability (under smooth feedback), respectively.} To explore the representational flexibility of these model sets, we establish the theoretical connections between the stability of discrete-time Koopman embedding and contraction-based forms of nonlinear stability and stabilizability. The proposed approach is illustrated in applications to stable nonlinear system identification and imitation learning via stabilizable models. Simulation results empirically show that the proposed learning approaches outperform prior methods lacking stability guarantees.","authors":["Fletcher Fan","Bowen Yi","David Rye","Guodong Shi","Ian R. Manchester"],"url":"https://arxiv.org/abs/2401.08153"}
{"created":"2025-05-09","title":"When the Universe is Too Big: Bounding Consideration Probabilities for Plackett-Luce Rankings","abstract":"The widely used Plackett-Luce ranking model assumes that individuals rank items by making repeated choices from a universe of items. But in many cases the universe is too big for people to plausibly consider all options. In the choice literature, this issue has been addressed by supposing that individuals first sample a small consideration set and then choose among the considered items. However, inferring unobserved consideration sets (or item consideration probabilities) in this \"consider then choose\" setting poses significant challenges, because even simple models of consideration with strong independence assumptions are not identifiable, even if item utilities are known. We apply the consider-then-choose framework to top-$k$ rankings, where we assume rankings are constructed according to a Plackett-Luce model after sampling a consideration set. While item consideration probabilities remain non-identified in this setting, we prove that we can infer bounds on the relative values of consideration probabilities. Additionally, given a condition on the expected consideration set size and known item utilities, we derive absolute upper and lower bounds on item consideration probabilities. We also provide algorithms to tighten those bounds on consideration probabilities by propagating inferred constraints. Thus, we show that we can learn useful information about consideration probabilities despite not being able to identify them precisely. We demonstrate our methods on a ranking dataset from a psychology experiment with two different ranking tasks (one with fixed consideration sets and one with unknown consideration sets). This combination of data allows us to estimate utilities and then learn about unknown consideration probabilities using our bounds.","authors":["Ben Aoki-Sherwood","Catherine Bregou","David Liben-Nowell","Kiran Tomlinson","Thomas Zeng"],"url":"https://arxiv.org/abs/2401.11016"}
{"created":"2025-05-09","title":"Faster Fr\\'echet Distance Approximation through Truncated Smoothing","abstract":"The Fr\\'echet distance is a commonly used distance measure for curves. Computing the Fr\\'echet distance between two polygonal curves of $n$ vertices takes roughly quadratic time, and conditional lower bounds suggest that approximating to within a factor $3$ cannot be done in strongly-subquadratic time, even in one dimension. Currently, the best approximation algorithms present trade-offs between approximation quality and running time. At SoCG 2021, Colombe and Fox presented an $O((n^3 / \\alpha^2) \\log n)$-time $\\alpha$-approximate algorithm for curves in arbitrary dimensions, for any $\\alpha \\in [\\sqrt{n}, n]$. In this work, we give an $\\alpha$-approximate algorithm with a significantly faster running time of $O((n^2 / \\alpha) \\log n)$, for any $\\alpha \\in [1, n]$. In particular, we give the first strongly-subquadratic $n^\\varepsilon$-approximation algorithm, for any constant $\\varepsilon \\in (0, 1/2]$. For curves in one dimension we further improve the running time to $O((n^2 / \\alpha^3) \\log^2 n)$, for $\\alpha \\in [1, n^{1/3}]$. Both of our algorithms rely on a linear-time simplification procedure that in one dimension reduces the complexity of the reachable free space to $O(n^2 / \\alpha)$ without making sacrifices in the asymptotic approximation factor.","authors":["Thijs van der Horst","Marc van Kreveld","Tim Ophelders","Bettina Speckmann"],"url":"https://arxiv.org/abs/2401.14815"}
{"created":"2025-05-09","title":"Exploring Learning Complexity for Efficient Downstream Dataset Pruning","abstract":"The ever-increasing fine-tuning cost of large-scale pre-trained models gives rise to the importance of dataset pruning, which aims to reduce dataset size while maintaining task performance. However, existing dataset pruning methods require training on the entire dataset, which is impractical for large-scale pre-trained models. In this paper, we propose a straightforward, novel, and training-free hardness score named Distorting-based Learning Complexity (DLC), to identify informative images and instructions from the downstream dataset efficiently. Our method is motivated by the observation that easy samples learned faster can also be learned with fewer parameters. Specifically, we define the Learning Complexity to quantify sample hardness and utilize a lightweight weights masking process for fast estimation, instead of the costly SGD optimization. Based on DLC, we further design a flexible under-sampling with randomness (dubbed FlexRand), replacing the top-K strategy, to alleviate the severe subset distribution shift. Extensive experiments with downstream image and instructions dataset pruning benchmarks demonstrate the effectiveness and efficiency of the proposed approach. In the images pruning benchmark, DLC significantly reduces the pruning time by 35x while establishing state-of-the-art performance with FlexRand.","authors":["Wenyu Jiang","Zhenlong Liu","Zejian Xie","Songxin Zhang","Bingyi Jing","Hongxin Wei"],"url":"https://arxiv.org/abs/2402.05356"}
{"created":"2025-05-09","title":"Online Matching on $3$-Uniform Hypergraphs","abstract":"The online matching problem was introduced by Karp, Vazirani and Vazirani (STOC 1990) on bipartite graphs with vertex arrivals. It is well-known that the optimal competitive ratio is $1-1/e$ for both integral and fractional versions of the problem. Since then, there has been considerable effort to find optimal competitive ratios for other related settings. In this work, we go beyond the graph case and study the online matching problem on $k$-uniform hypergraphs. For $k=3$, we provide an optimal primal-dual fractional algorithm, which achieves a competitive ratio of $(e-1)/(e+1)\\approx 0.4621$. As our main technical contribution, we present a carefully constructed adversarial instance, which shows that this ratio is in fact optimal. It combines ideas from known hard instances for bipartite graphs under the edge-arrival and vertex-arrival models. For $k\\geq 3$, we give a simple integral algorithm which performs better than greedy when the online nodes have bounded degree. As a corollary, it achieves the optimal competitive ratio of 1/2 on 3-uniform hypergraphs when every online node has degree at most 2. This is because the special case where every online node has degree 1 is equivalent to the edge-arrival model on graphs, for which an upper bound of 1/2 is known.","authors":["Sander Borst","Danish Kashaev","Zhuan Khye Koh"],"url":"https://arxiv.org/abs/2402.13227"}
{"created":"2025-05-09","title":"DyCE: Dynamically Configurable Exiting for Deep Learning Compression and Real-time Scaling","abstract":"Conventional deep learning (DL) model compression and scaling methods focus on altering the model's components, impacting the results across all samples uniformly. However, since samples vary in difficulty, a dynamic model that adapts computation based on sample complexity offers a novel perspective for compression and scaling. Despite this potential, existing dynamic models are typically monolithic and model-specific, limiting their generalizability as broad compression and scaling methods. Additionally, most deployed DL systems are fixed, unable to adjust their scale once deployed and, therefore, cannot adapt to the varying real-time demands. This paper introduces DyCE, a dynamically configurable system that can adjust the performance-complexity trade-off of a DL model at runtime without requiring re-initialization or redeployment on inference hardware. DyCE achieves this by adding small exit networks to intermediate layers of the original model, allowing computation to terminate early if acceptable results are obtained. DyCE also decouples the design of an efficient dynamic model, facilitating easy adaptation to new base models and potential general use in compression and scaling. We also propose methods for generating optimized configurations and determining the types and positions of exit networks to achieve desired performance and complexity trade-offs. By enabling simple configuration switching, DyCE provides fine-grained performance tuning in real-time. We demonstrate the effectiveness of DyCE through image classification tasks using deep convolutional neural networks (CNNs). DyCE significantly reduces computational complexity by 23.5% for ResNet152 and 25.9% for ConvNextv2-tiny on ImageNet, with accuracy reductions of less than 0.5%.","authors":["Qingyuan Wang","Barry Cardiff","Antoine Frapp\\'e","Benoit Larras","Deepu John"],"url":"https://arxiv.org/abs/2403.01695"}
{"created":"2025-05-09","title":"Factorizations and fast diagonalization for the heat equation","abstract":"This work investigates diagonalization-based methods for efficiently solving linear evolution problems, with a particular focus on the heat equation. The plain diagonalization of the differential operator, though effective for elliptic problems where fast diagonalization can be used, exhibits instability when applied to the heat equation. To address this difficulty, we examine three alternative approaches, based on LU factorization, a suitable arrowhead factorization, and a low-rank modification. These methods introduce more robust factorizations of the time derivative, ensuring both computational efficiency and stability.","authors":["Andrea Bressan","Alen Kushova","Gabriele Loli","Monica Montardini","Giancarlo Sangalli","Mattia Tani"],"url":"https://arxiv.org/abs/2403.07875"}
{"created":"2025-05-09","title":"FieldNet: Efficient Real-Time Shadow Removal for Enhanced Vision in Field Robotics","abstract":"Shadows significantly hinder computer vision tasks in outdoor environments, particularly in field robotics, where varying lighting conditions complicate object detection and localisation. We present FieldNet, a novel deep learning framework for real-time shadow removal, optimised for resource-constrained hardware. FieldNet introduces a probabilistic enhancement module and a novel loss function to address challenges of inconsistent shadow boundary supervision and artefact generation, achieving enhanced accuracy and simplicity without requiring shadow masks during inference. Trained on a dataset of 10,000 natural images augmented with synthetic shadows, FieldNet outperforms state-of-the-art methods on benchmark datasets (ISTD, ISTD+, SRD), with up to $9$x speed improvements (66 FPS on Nvidia 2080Ti) and superior shadow removal quality (PSNR: 38.67, SSIM: 0.991). Real-world case studies in precision agriculture robotics demonstrate the practical impact of FieldNet in enhancing weed detection accuracy. These advancements establish FieldNet as a robust, efficient solution for real-time vision tasks in field robotics and beyond.","authors":["Alzayat Saleh","Alex Olsen","Jake Wood","Bronson Philippa","Mostafa Rahimi Azghadi"],"url":"https://arxiv.org/abs/2403.08142"}
{"created":"2025-05-09","title":"Public Perceptions of Fairness Metrics Across Borders","abstract":"Which fairness metrics are appropriately applicable in your contexts? There may be instances of discordance regarding the perception of fairness, even when the outcomes comply with established fairness metrics. Several questionnaire-based surveys have been conducted to evaluate fairness metrics with human perceptions of fairness. However, these surveys were limited in scope, including only a few hundred participants within a single country. In this study, we conduct an international survey to evaluate public perceptions of various fairness metrics in decision-making scenarios. We collected responses from 1,000 participants in each of China, France, Japan, and the United States, amassing a total of 4,000 participants, to analyze the preferences of fairness metrics. Our survey consists of three distinct scenarios paired with four fairness metrics. This investigation explores the relationship between personal attributes and the choice of fairness metrics, uncovering a significant influence of national context on these preferences.","authors":["Yuya Sasaki","Sohei Tokuno","Haruka Maeda","Kazuki Nakajima","Osamu Sakura","George Fletcher","Mykola Pechenizkiy","Panagiotis Karras","Irina Shklovski"],"url":"https://arxiv.org/abs/2403.16101"}
{"created":"2025-05-09","title":"Analyzing Consumer IoT Traffic from Security and Privacy Perspectives: a Comprehensive Survey","abstract":"The Consumer Internet of Things (CIoT), a notable segment within the IoT domain, involves the integration of IoT technology into consumer electronics and devices, such as smart homes and smart wearables. Compared to traditional IoT fields, CIoT differs notably in target users, product types, and design approaches. While offering convenience to users, it also raises new security and privacy concerns. Network traffic analysis, a widely used technique in the security community, has been extensively applied to investigate these concerns about CIoT. Compared to traditional network traffic analysis in fields like mobile apps and websites, CIoT introduces unique characteristics that pose new challenges and research opportunities. Researchers have made significant contributions in this area. To aid researchers in understanding the application of traffic analysis tools for assessing CIoT security and privacy risks, this survey reviews 310 publications on traffic analysis within the CIoT security and privacy domain from January 2018 to June 2024, focusing on three research questions. Our work: 1) outlines the CIoT traffic analysis process and highlights its differences from general network traffic analysis. 2) summarizes and classifies existing research into four categories according to its application objectives: device fingerprinting, user activity inference, malicious traffic detection, and measurement. 3) explores emerging challenges and potential future research directions based on each step of the CIoT traffic analysis process. This will provide new insights to the community and guide the industry towards safer product designs.","authors":["Yan Jia","Yuxin Song","Zihou Liu","Qingyin Tan","Yang Song","Yu Zhang","Zheli Liu"],"url":"https://arxiv.org/abs/2403.16149"}
{"created":"2025-05-09","title":"Symbolic and User-friendly Geometric Algebra Routines (SUGAR) for Computations in Matlab","abstract":"Geometric algebra (GA) is a mathematical tool for geometric computing, providing a framework that allows a unified and compact approach to geometric relations which in other mathematical systems are typically described using different more complicated elements. This fact has led to an increasing adoption of GA in applied mathematics and engineering problems. However, the scarcity of symbolic implementations of GA and its inherent complexity, requiring a specific mathematical background, make it challenging and less intuitive for engineers to work with. This prevents wider adoption among more applied professionals. To address this challenge, this paper introduces SUGAR (Symbolic and User-friendly Geometric Algebra Routines), an open-source toolbox designed for Matlab and licensed under the MIT License. SUGAR facilitates the translation of GA concepts into Matlab and provides a collection of user-friendly functions tailored for GA computations, including support for symbolic operations. It supports both numeric and symbolic computations in high-dimensional GAs. Specifically tailored for applied mathematics and engineering applications, SUGAR has been meticulously engineered to represent geometric elements and transformations within two and three-dimensional projective and conformal geometric algebras, aligning with established computational methodologies in the literature. Furthermore, SUGAR efficiently handles functions of multivectors, such as exponential, logarithmic, sinusoidal, and cosine functions, enhancing its applicability across various engineering domains, including robotics, control systems, and power electronics. Finally, this work includes four distinct validation examples, demonstrating SUGAR's capabilities across the above-mentioned fields and its practical utility in addressing real-world applied mathematics and engineering problems.","authors":["Manel Velasco","Isiah Zaplana","Arnau D\\'oria-Cerezo","Pau Mart\\'i"],"url":"https://arxiv.org/abs/2403.16634"}
{"created":"2025-05-09","title":"Comparing Hyper-optimized Machine Learning Models for Predicting Efficiency Degradation in Organic Solar Cells","abstract":"This work presents a set of optimal machine learning (ML) models to represent the temporal degradation suffered by the power conversion efficiency (PCE) of polymeric organic solar cells (OSCs) with a multilayer structure ITO/PEDOT:PSS/P3HT:PCBM/Al. To that aim, we generated a database with 996 entries, which includes up to 7 variables regarding both the manufacturing process and environmental conditions for more than 180 days. Then, we relied on a software framework that brings together a conglomeration of automated ML protocols that execute sequentially against our database by simply command-line interface. This easily permits hyper-optimizing and randomizing seeds of the ML models through exhaustive benchmarking so that optimal models are obtained. The accuracy achieved reaches values of the coefficient determination (R2) widely exceeding 0.90, whereas the root mean squared error (RMSE), sum of squared error (SSE), and mean absolute error (MAE)>1% of the target value, the PCE. Additionally, we contribute with validated models able to screen the behavior of OSCs never seen in the database. In that case, R2~0.96-0.97 and RMSE~1%, thus confirming the reliability of the proposal to predict. For comparative purposes, classical Bayesian regression fitting based on non-linear mean squares (LMS) are also presented, which only perform sufficiently for univariate cases of single OSCs. Hence they fail to outperform the breadth of the capabilities shown by the ML models. Finally, thanks to the standardized results offered by the ML framework, we study the dependencies between the variables of the dataset and their implications for the optimal performance and stability of the OSCs. Reproducibility is ensured by a standardized report altogether with the dataset, which are publicly available at Github.","authors":["David Valiente","Fernando Rodr\\'iguez-Mas","Juan V. Alegre-Requena","David Dalmau","Mar\\'ia Flores","Juan C. Ferrer"],"url":"https://arxiv.org/abs/2404.00173"}
{"created":"2025-05-09","title":"Information-Theoretic Generalization Bounds for Deep Neural Networks","abstract":"Deep neural networks (DNNs) exhibit an exceptional capacity for generalization in practical applications. This work aims to capture the effect and benefits of depth for supervised learning via information-theoretic generalization bounds. We first derive two hierarchical bounds on the generalization error in terms of the Kullback-Leibler (KL) divergence or the 1-Wasserstein distance between the train and test distributions of the network internal representations. The KL divergence bound shrinks as the layer index increases, while the Wasserstein bound implies the existence of a layer that serves as a generalization funnel, which attains a minimal 1-Wasserstein distance. Analytic expressions for both bounds are derived under the setting of binary Gaussian classification with linear DNNs. To quantify the contraction of the relevant information measures when moving deeper into the network, we analyze the strong data processing inequality (SDPI) coefficient between consecutive layers of three regularized DNN models: $\\mathsf{Dropout}$, $\\mathsf{DropConnect}$, and Gaussian noise injection. This enables refining our generalization bounds to capture the contraction as a function of the network architecture parameters. Specializing our results to DNNs with a finite parameter space and the Gibbs algorithm reveals that deeper yet narrower network architectures generalize better in those examples, although how broadly this statement applies remains a question.","authors":["Haiyun He","Ziv Goldfeld"],"url":"https://arxiv.org/abs/2404.03176"}
{"created":"2025-05-09","title":"Formulating the Restoration of Distribution Networks as a Multiple Traveling Salesman Problem","abstract":"Severe weather events can cause extensive damage to electrical distribution networks, requiring a multi-day restoration effort. Optimizing the dispatch of repair crews minimizes the severe socio-economic consequences of such events. Considering both repair times and travel times, we use graphical manipulations to transform this multiple crew scheduling problem into a type of traveling salesman problem(TSP). Specifically, we demonstrate that the restoration problem bears major resemblance to an instance of a cost constrained reward maximizing mTSP (multiple TSP) on node and edge weighted (doubly weighted) graphs (a variant we dub the CCRM-mTSP-DW), where the objective is to maximize the aggregate reward earned during the upcoming restoration window, provided no crew violates its time budget and electrical continuity constraints are met. Despite the rich history of research on the TSP and its variants, this CCRM-mTSP-DW variant has not been studied before, although its closest cousin happens to be the \"Selective TSP\" (S-TSP). This reinterpretation of the restoration problem not only opens up the possibility of drawing on existing solution methods developed for the TSP and its variants, it also adds a new chapter in the annals of research on \"TSP-like'' problems. In this paper, we propose a \"TSP-like'' mixed integer linear programming (MILP) model for solving the restoration problem and validate it on the IEEE PES 123-node test feeder network.","authors":["Ran Wei","Arindam K. Das","Payman Arabshahi","Daniel S. Kirschen"],"url":"https://arxiv.org/abs/2404.03197"}
{"created":"2025-05-09","title":"TCAN: Text-oriented Cross Attention Network for Multimodal Sentiment Analysis","abstract":"Multimodal Sentiment Analysis (MSA) endeavors to understand human sentiment by leveraging language, visual, and acoustic modalities. Despite the remarkable performance exhibited by previous MSA approaches, the presence of inherent multimodal heterogeneities poses a challenge, with the contribution of different modalities varying considerably. Past research predominantly focused on improving representation learning techniques and feature fusion strategies. However, many of these efforts overlooked the variation in semantic richness among different modalities, treating each modality uniformly. This approach may lead to underestimating the significance of strong modalities while overemphasizing the importance of weak ones. Motivated by these insights, we introduce a Text-oriented Cross-Attention Network (TCAN), emphasizing the predominant role of the text modality in MSA. Specifically, for each multimodal sample, by taking unaligned sequences of the three modalities as inputs, we initially allocate the extracted unimodal features into a visual-text and an acoustic-text pair. Subsequently, we implement self-attention on the text modality and apply text-queried cross-attention to the visual and acoustic modalities. To mitigate the influence of noise signals and redundant features, we incorporate a gated control mechanism into the framework. Additionally, we introduce unimodal joint learning to gain a deeper understanding of homogeneous emotional tendencies across diverse modalities through backpropagation. Experimental results demonstrate that TCAN consistently outperforms state-of-the-art MSA methods on two datasets (CMU-MOSI and CMU-MOSEI).","authors":["Weize Quan","Yunfei Feng","Ming Zhou","Yunzhen Zhao","Tong Wang","Dong-Ming Yan"],"url":"https://arxiv.org/abs/2404.04545"}
{"created":"2025-05-09","title":"The Church Synthesis Problem over Continuous Time","abstract":"The Church Problem asks for the construction of a procedure which, given a logical specification A(I,O) between input omega-strings I and output omega-strings O, determines whether there exists an operator F that implements the specification in the sense that A(I, F(I)) holds for all inputs I. Buchi and Landweber provided a procedure to solve the Church problem for MSO specifications and operators computable by finite-state automata. We investigate a generalization of the Church synthesis problem to the continuous time domain of the non-negative reals.","authors":["Alexander Rabinovich","Daniel Fattal"],"url":"https://arxiv.org/abs/2404.04782"}
{"created":"2025-05-09","title":"Robust Coordination under Misaligned Communication via Power Regularization","abstract":"Effective communication in Multi-Agent Reinforcement Learning (MARL) can significantly enhance coordination and collaborative performance in complex and partially observable environments. However, reliance on communication can also introduce vulnerabilities when agents are misaligned, potentially leading to adversarial interactions that exploit implicit assumptions of cooperative intent. Prior work has addressed adversarial behavior through power regularization through controlling the influence one agent exerts over another, but has largely overlooked the role of communication in these dynamics. This paper introduces Communicative Power Regularization (CPR), extending power regularization specifically to communication channels. By explicitly quantifying and constraining agents' communicative influence during training, CPR actively mitigates vulnerabilities arising from misaligned or adversarial communications. Evaluations across benchmark environments Red-Door-Blue-Door, Predator-Prey, and Grid Coverage demonstrate that our approach significantly enhances robustness to adversarial communication while preserving cooperative performance, offering a practical framework for secure and resilient cooperative MARL systems.","authors":["Nancirose Piazza","Amirhossein Karimia","Behnia Soleymanib","Vahid Behzadan","Stefan Sarkadi"],"url":"https://arxiv.org/abs/2404.06387"}
{"created":"2025-05-09","title":"Blockchain in a box: A portable blockchain network implementation on Raspberry Pi's","abstract":"In this paper we describe a prototype of a blockchain-in-a-box system which allows users to easily bootstrap the whole Ethereum Proof-of-Work (PoW) network running on multiple Raspberry Pi nodes - an inexpensive modular computers. Users are able to orchestrate the whole blockchain network using a single web based interface, for example they are able to set the topology of the peer-to-peer (P2P) connections and control the initialization parameters. Each Raspberry Pi has a screen attached which visualizes current state of local blockchain, allowing users to easily visualize the consensus of the network in real time. We show how this platform can be used to perform experiments on consensus quality while using different P2P topologies. Similar experiments can be used for demonstration purposes in a workshop or other educational settings.","authors":["Matija Pi\\v{s}korec","Anton Ivashkevich","Said Haji Abukar","Lundrim Azemi","Md Rezuanul Haque","Mostafa Chegenizadeh","Claudio J. Tessone"],"url":"https://arxiv.org/abs/2404.14282"}
{"created":"2025-05-09","title":"RoBERTa-Augmented Synthesis for Detecting Malicious API Requests","abstract":"Web applications and APIs face constant threats from malicious actors seeking to exploit vulnerabilities for illicit gains. To defend against these threats, it is essential to have anomaly detection systems that can identify a variety of malicious behaviors. However, a significant challenge in this area is the limited availability of training data. Existing datasets often do not provide sufficient coverage of the diverse API structures, parameter formats, and usage patterns encountered in real-world scenarios. As a result, models trained on these datasets often struggle to generalize and may fail to detect less common or emerging attack vectors. To enhance detection accuracy and robustness, it is crucial to access larger and more representative datasets that capture the true variability of API traffic. To address this, we introduce a GAN-inspired learning framework that extends limited API traffic datasets through targeted, domain-aware synthesis. Drawing on techniques from Natural Language Processing (NLP), our approach leverages Transformer-based architectures, particularly RoBERTa, to enhance the contextual representation of API requests and generate realistic synthetic samples aligned with security-specific semantics. We evaluate our framework on two benchmark datasets, CSIC 2010 and ATRDF 2023, and compare it with a previous data augmentation technique to assess the importance of domain-specific synthesis. In addition, we apply our augmented data to various anomaly detection models to evaluate its impact on classification performance. Our method achieves up to a 4.94% increase in F1 score on CSIC 2010 and up to 21.10% on ATRDF 2023. The source codes of this work are available at https://github.com/ArielCyber/GAN-API.","authors":["Udi Aharon","Revital Marbel","Ran Dubin","Amit Dvir","Chen Hajaj"],"url":"https://arxiv.org/abs/2405.11258"}
{"created":"2025-05-09","title":"DEGAP: Dual Event-Guided Adaptive Prefixes for Templated-Based Event Argument Extraction with Slot Querying","abstract":"Recent advancements in event argument extraction (EAE) involve incorporating useful auxiliary information into models during training and inference, such as retrieved instances and event templates. These methods face two challenges: (1) the retrieval results may be irrelevant and (2) templates are developed independently for each event without considering their possible relationship. In this work, we propose DEGAP to address these challenges through a simple yet effective components: dual prefixes, i.e. learnable prompt vectors, where the instance-oriented prefix and template-oriented prefix are trained to learn information from different event instances and templates. Additionally, we propose an event-guided adaptive gating mechanism, which can adaptively leverage possible connections between different events and thus capture relevant information from the prefix. Finally, these event-guided prefixes provide relevant information as cues to EAE model without retrieval. Extensive experiments demonstrate that our method achieves new state-of-the-art performance on four datasets (ACE05, RAMS, WIKIEVENTS, and MLEE). Further analysis shows the impact of different components.","authors":["Guanghui Wang","Dexi Liu","Jian-Yun Nie","Qizhi Wan","Rong Hu","Xiping Liu","Wanlong Liu","Jiaming Liu"],"url":"https://arxiv.org/abs/2405.13325"}
{"created":"2025-05-09","title":"Quantifying Multipolar Polarization","abstract":"Studying and understanding social networks is crucial for accurately defining ideological polarization, since they enable precise modeling of social structures. One of the limitations of many methods for quantifying polarization on networks is the assumption of a two-dimensional opinion space. This prevents accurate study of multipolar systems like multi-party political systems, where modeling more than two opinion poles is beneficial. Here, I experimentally compare methods for quantifying multipolar polarization on a network and find that the average pairwise distance extension of generalized Euclidean distance conforms to several desired properties, showing its advantages over other methods. This allows the study of multipolar polarized systems based on an empirically and intuitively good metric.","authors":["Christian Weidemann"],"url":"https://arxiv.org/abs/2405.16352"}
{"created":"2025-05-09","title":"A Probabilistic Approach to Learning the Degree of Equivariance in Steerable CNNs","abstract":"Steerable convolutional neural networks (SCNNs) enhance task performance by modelling geometric symmetries through equivariance constraints on weights. Yet, unknown or varying symmetries can lead to overconstrained weights and decreased performance. To address this, this paper introduces a probabilistic method to learn the degree of equivariance in SCNNs. We parameterise the degree of equivariance as a likelihood distribution over the transformation group using Fourier coefficients, offering the option to model layer-wise and shared equivariance. These likelihood distributions are regularised to ensure an interpretable degree of equivariance across the network. Advantages include the applicability to many types of equivariant networks through the flexible framework of SCNNs and the ability to learn equivariance with respect to any subgroup of any compact group without requiring additional layers. Our experiments reveal competitive performance on datasets with mixed symmetries, with learnt likelihood distributions that are representative of the underlying degree of equivariance.","authors":["Lars Veefkind","Gabriele Cesa"],"url":"https://arxiv.org/abs/2406.03946"}
{"created":"2025-05-09","title":"Generalizable Human Gaussians from Single-View Image","abstract":"In this work, we tackle the task of learning 3D human Gaussians from a single image, focusing on recovering detailed appearance and geometry including unobserved regions. We introduce a single-view generalizable Human Gaussian Model (HGM), which employs a novel generate-then-refine pipeline with the guidance from human body prior and diffusion prior. Our approach uses a ControlNet to refine rendered back-view images from coarse predicted human Gaussians, then uses the refined image along with the input image to reconstruct refined human Gaussians. To mitigate the potential generation of unrealistic human poses and shapes, we incorporate human priors from the SMPL-X model as a dual branch, propagating image features from the SMPL-X volume to the image Gaussians using sparse convolution and attention mechanisms. Given that the initial SMPL-X estimation might be inaccurate, we gradually refine it with our HGM model. We validate our approach on several publicly available datasets. Our method surpasses previous methods in both novel view synthesis and surface reconstruction. Our approach also exhibits strong generalization for cross-dataset evaluation and in-the-wild images.","authors":["Jinnan Chen","Chen Li","Jianfeng Zhang","Lingting Zhu","Buzhen Huang","Hanlin Chen","Gim Hee Lee"],"url":"https://arxiv.org/abs/2406.06050"}
{"created":"2025-05-09","title":"HORAE: A Domain-Agnostic Language for Automated Service Regulation","abstract":"Artificial intelligence is rapidly encroaching on the field of service regulation. However, existing AI-based regulation techniques are often tailored to specific application domains and thus are difficult to generalize in an automated manner. This paper presents Horae, a unified specification language for modeling (multimodal) regulation rules across a diverse set of domains. We showcase how Horae facilitates an intelligent service regulation pipeline by further exploiting a fine-tuned large language model named RuleGPT that automates the Horae modeling process, thereby yielding an end-to-end framework for fully automated intelligent service regulation. The feasibility and effectiveness of our framework are demonstrated over a benchmark of various real-world regulation domains. In particular, we show that our open-sourced, fine-tuned RuleGPT with 7B parameters suffices to outperform GPT-3.5 and perform on par with GPT-4o.","authors":["Yutao Sun","Mingshuai Chen","Tiancheng Zhao","Kangjia Zhao","He Li","Jintao Chen","Zhongyi Wang","Liqiang Lu","Xinkui Zhao","Shuiguang Deng","Jianwei Yin"],"url":"https://arxiv.org/abs/2406.06600"}
{"created":"2025-05-09","title":"Enhancing Differential Testing With LLMs For Testing Deep Learning Libraries","abstract":"Differential testing offers a promising strategy to alleviate the test oracle problem by comparing the test results between alternative implementations. However, existing differential testing techniques for deep learning (DL) libraries are limited by the key challenges of finding alternative implementations (called counterparts) for a given API and subsequently generating diverse test inputs. To address the two challenges, this paper introduces DLLens, an LLM-enhanced differential testing technique for DL libraries. To address the first challenge, DLLens incorporates an LLM-based counterpart synthesis workflow, with the insight that the counterpart of a given DL library API's computation could be successfully synthesized through certain composition and adaptation of the APIs from another DL library. To address the second challenge, DLLens incorporates a static analysis technique that extracts the path constraints from the implementations of a given API and its counterpart to guide diverse test input generation. The extraction is facilitated by LLM's knowledge of the concerned DL library and its upstream libraries.","authors":["Meiziniu Li","Dongze Li","Jianmeng Liu","Jialun Cao","Yongqiang Tian","Shing-Chi Cheung"],"url":"https://arxiv.org/abs/2406.07944"}
{"created":"2025-05-09","title":"Noise-Aware Differentially Private Regression via Meta-Learning","abstract":"Many high-stakes applications require machine learning models that protect user privacy and provide well-calibrated, accurate predictions. While Differential Privacy (DP) is the gold standard for protecting user privacy, standard DP mechanisms typically significantly impair performance. One approach to mitigating this issue is pre-training models on simulated data before DP learning on the private data. In this work we go a step further, using simulated data to train a meta-learning model that combines the Convolutional Conditional Neural Process (ConvCNP) with an improved functional DP mechanism of Hall et al. [2013] yielding the DPConvCNP. DPConvCNP learns from simulated data how to map private data to a DP predictive model in one forward pass, and then provides accurate, well-calibrated predictions. We compare DPConvCNP with a DP Gaussian Process (GP) baseline with carefully tuned hyperparameters. The DPConvCNP outperforms the GP baseline, especially on non-Gaussian data, yet is much faster at test time and requires less tuning.","authors":["Ossi R\\\"ais\\\"a","Stratis Markou","Matthew Ashman","Wessel P. Bruinsma","Marlon Tobaben","Antti Honkela","Richard E. Turner"],"url":"https://arxiv.org/abs/2406.08569"}
{"created":"2025-05-09","title":"Retraining with Predicted Hard Labels Provably Increases Model Accuracy","abstract":"The performance of a model trained with noisy labels is often improved by simply \\textit{retraining} the model with its \\textit{own predicted hard labels} (i.e., 1/0 labels). Yet, a detailed theoretical characterization of this phenomenon is lacking. In this paper, we theoretically analyze retraining in a linearly separable binary classification setting with randomly corrupted labels given to us and prove that retraining can improve the population accuracy obtained by initially training with the given (noisy) labels. To the best of our knowledge, this is the first such theoretical result. Retraining finds application in improving training with local label differential privacy (DP) which involves training with noisy labels. We empirically show that retraining selectively on the samples for which the predicted label matches the given label significantly improves label DP training at no extra privacy cost; we call this consensus-based retraining. As an example, when training ResNet-18 on CIFAR-100 with $\\epsilon=3$ label DP, we obtain more than 6% improvement in accuracy with consensus-based retraining.","authors":["Rudrajit Das","Inderjit S. Dhillon","Alessandro Epasto","Adel Javanmard","Jieming Mao","Vahab Mirrokni","Sujay Sanghavi","Peilin Zhong"],"url":"https://arxiv.org/abs/2406.11206"}
{"created":"2025-05-09","title":"CacheSquash: Making caches speculation-aware","abstract":"Speculation is key to achieving high CPU performance, yet it enables risks like Spectre attacks which remain a significant challenge to mitigate without incurring substantial performance overheads. These attacks typically unfold in three stages: access, transmit, and receive. Typically, they exploit a cache timing side channel during the transmit and receive phases: speculatively accessing sensitive data (access), altering cache state (transmit), and then utilizing a cache timing attack (e.g., Flush+Reload) to extract the secret (receive). Our key observation is that Spectre attacks only require the transmit instruction to execute and dispatch a request to the cache hierarchy. It need not complete before a misprediction is detected (and mis-speculated instructions squashed) because responses from memory that arrive at the cache after squashing still alter cache state. We propose a novel mitigation, CacheSquash, that cancels mis-speculated memory accesses. Immediately upon squashing, a cancellation is sent to the cache hierarchy, propagating downstream and preventing any changes to caches that have not yet received a response. This minimizes cache state changes, thereby reducing the likelihood of Spectre attacks succeeding. We implement CacheSquash on gem5 and show that it thwarts practical Spectre attacks, with near-zero performance overheads.","authors":["Hossam ElAtali","N. Asokan"],"url":"https://arxiv.org/abs/2406.12110"}
{"created":"2025-05-09","title":"Recite, Reconstruct, Recollect: Memorization in LMs as a Multifaceted Phenomenon","abstract":"Memorization in language models is typically treated as a homogenous phenomenon, neglecting the specifics of the memorized data. We instead model memorization as the effect of a set of complex factors that describe each sample and relate it to the model and corpus. To build intuition around these factors, we break memorization down into a taxonomy: recitation of highly duplicated sequences, reconstruction of inherently predictable sequences, and recollection of sequences that are neither. We demonstrate the usefulness of our taxonomy by using it to construct a predictive model for memorization. By analyzing dependencies and inspecting the weights of the predictive model, we find that different factors influence the likelihood of memorization differently depending on the taxonomic category.","authors":["USVSN Sai Prashanth","Alvin Deng","Kyle O'Brien","Jyothir S V","Mohammad Aflah Khan","Jaydeep Borkar","Christopher A. Choquette-Choo","Jacob Ray Fuehne","Stella Biderman","Tracy Ke","Katherine Lee","Naomi Saphra"],"url":"https://arxiv.org/abs/2406.17746"}
{"created":"2025-05-09","title":"Scaling Synthetic Data Creation with 1,000,000,000 Personas","abstract":"We propose a novel persona-driven data synthesis methodology that leverages various perspectives within a large language model (LLM) to create diverse synthetic data. To fully exploit this methodology at scale, we introduce Persona Hub -- a collection of 1 billion diverse personas automatically curated from web data. These 1 billion personas (~13% of the world's total population), acting as distributed carriers of world knowledge, can tap into almost every perspective encapsulated within the LLM, thereby facilitating the creation of diverse synthetic data at scale for various scenarios. By showcasing Persona Hub's use cases in synthesizing high-quality mathematical and logical reasoning problems, instructions (i.e., user prompts), knowledge-rich texts, game NPCs and tools (functions) at scale, we demonstrate persona-driven data synthesis is versatile, scalable, flexible, and easy to use, potentially driving a paradigm shift in synthetic data creation and applications in practice, which may have a profound impact on LLM research and development.","authors":["Tao Ge","Xin Chan","Xiaoyang Wang","Dian Yu","Haitao Mi","Dong Yu"],"url":"https://arxiv.org/abs/2406.20094"}
{"created":"2025-05-09","title":"Simplification of Robotic System Model Analysis by Petri Net Meta-Model Property Transfer","abstract":"This paper presents a simplification of robotic system model analysis due to the transfer of Robotic System Hierarchical Petri Net (RSHPN) meta-model properties onto the model of a designed system. Key contributions include: 1) analysis of RSHPN meta-model properties; 2) decomposition of RSHPN analysis into analysis of individual Petri nets, thus the reduction of state space explosion; and 3) transfer of RSHPN meta-model properties onto the produced models, hence elimination of the need for full re-analysis of the RSHPN model when creating new robotic systems. Only task-dependent parts of the model need to be analysed. This approach streamlines the analysis thus reducing the design time. Moreover, it produces a specification which is a solid foundation for the implementation of the system. The obtained results highlight the potential of Petri nets as a valuable formal framework for analysing robotic system properties.","authors":["Maksym Figat","Cezary Zieli\\'nski"],"url":"https://arxiv.org/abs/2407.06454"}
{"created":"2025-05-09","title":"Not Another Imputation Method: A Transformer-based Model for Missing Values in Tabular Datasets","abstract":"Handling missing values in tabular datasets presents a significant challenge in training and testing artificial intelligence models, an issue usually addressed using imputation techniques. Here we introduce \"Not Another Imputation Method\" (NAIM), a novel transformer-based model specifically designed to address this issue without the need for traditional imputation techniques. NAIM's ability to avoid the necessity of imputing missing values and to effectively learn from available data relies on two main techniques: the use of feature-specific embeddings to encode both categorical and numerical features also handling missing inputs; the modification of the masked self-attention mechanism to completely mask out the contributions of missing data. Additionally, a novel regularization technique is introduced to enhance the model's generalization capability from incomplete data. We extensively evaluated NAIM on 5 publicly available tabular datasets, demonstrating its superior performance over 6 state-of-the-art machine learning models and 5 deep learning models, each paired with 3 different imputation techniques when necessary. The results highlight the efficacy of NAIM in improving predictive performance and resilience in the presence of missing data. To facilitate further research and practical application in handling missing data without traditional imputation methods, we made the code for NAIM available at https://github.com/cosbidev/NAIM.","authors":["Camillo Maria Caruso","Paolo Soda","Valerio Guarrasi"],"url":"https://arxiv.org/abs/2407.11540"}
{"created":"2025-05-09","title":"Towards Certified Unlearning for Deep Neural Networks","abstract":"In the field of machine unlearning, certified unlearning has been extensively studied in convex machine learning models due to its high efficiency and strong theoretical guarantees. However, its application to deep neural networks (DNNs), known for their highly nonconvex nature, still poses challenges. To bridge the gap between certified unlearning and DNNs, we propose several simple techniques to extend certified unlearning methods to nonconvex objectives. To reduce the time complexity, we develop an efficient computation method by inverse Hessian approximation without compromising certification guarantees. In addition, we extend our discussion of certification to nonconvergence training and sequential unlearning, considering that real-world users can send unlearning requests at different time points. Extensive experiments on three real-world datasets demonstrate the efficacy of our method and the advantages of certified unlearning in DNNs.","authors":["Binchi Zhang","Yushun Dong","Tianhao Wang","Jundong Li"],"url":"https://arxiv.org/abs/2408.00920"}
{"created":"2025-05-09","title":"Smaller but Better: Self-Paced Knowledge Distillation for Lightweight yet Effective LCMs","abstract":"Large code models (LCMs) have remarkably advanced the field of code generation. Despite their impressive capabilities, they still face practical deployment issues, such as high inference costs, limited accessibility of proprietary LCMs, and adaptability issues of ultra-large LCMs. These issues highlight the critical need for more accessible, lightweight yet effective LCMs. Knowledge distillation (KD) offers a promising solution, which transfers the programming capabilities of larger, advanced LCMs to smaller, less powerful LCMs. In this paper, we propose a novel Self-Paced knOwledge DistillAtion framework, named SODA, aiming at developing lightweight yet effective student LCMs. SODA consists of three stages in one cycle: (1) Correct-and-Fault Knowledge Delivery stage aims at improving the student models capability to recognize errors while ensuring its basic programming skill during the knowledge transferring, which involves correctness-aware supervised learning and fault-aware contrastive learning methods. (2) Multi-View Feedback stage aims at measuring the quality of results generated by the student model from two views, including model-based and static tool-based measurement, for identifying the difficult questions. (3) Feedback-based Knowledge Update stage aims at updating the student model adaptively by generating new questions at different difficulty levels, in which the difficulty levels are categorized based on the feedback in the second stage. Experimental results show that SODA improves the student model by 65.96% in terms of average Pass@1, outperforming the best baseline by 29.85%. Based on the SODA framework, we develop SodaCoder, a series of lightweight yet effective LCMs, which outperform 15 LCMs with less than or equal to 16B parameters. Notably, SodaCoder-DS-6.7B, built on DeepseekCoder-6.7B, even surpasses the prominent ChatGPT on average Pass@1.","authors":["Yujia Chen","Yang Ye","Zhongqi Li","Yuchi Ma","Cuiyun Gao"],"url":"https://arxiv.org/abs/2408.03680"}
{"created":"2025-05-09","title":"Boosting Adverse Weather Crowd Counting via Multi-queue Contrastive Learning","abstract":"Currently, most crowd counting methods have outstanding performance under normal weather conditions. However, our experimental validation reveals two key obstacles limiting the accuracy improvement of crowd counting models: 1) the domain gap between the adverse weather and the normal weather images; 2) the weather class imbalance in the training set. To address the problems, we propose a two-stage crowd counting method named Multi-queue Contrastive Learning (MQCL). Specifically, in the first stage, our target is to equip the backbone network with weather-awareness capabilities. In this process, a contrastive learning method named multi-queue MoCo designed by us is employed to enable representation learning under weather class imbalance. After the first stage is completed, the backbone model is \"mature\" enough to extract weather-related representations. On this basis, we proceed to the second stage, in which we propose to refine the representations under the guidance of contrastive learning, enabling the conversion of the weather-aware representations to the normal weather domain. Through such representation and conversion, the model achieves robust counting performance under both normal and adverse weather conditions. Extensive experimental results show that, compared to the baseline, MQCL reduces the counting error under adverse weather conditions by 22%, while introducing only about 13% increase in computational burden, which achieves state-of-the-art performance.","authors":["Tianhang Pan","Xiuyi Jia"],"url":"https://arxiv.org/abs/2408.05956"}
{"created":"2025-05-09","title":"Contextual Bandits for Unbounded Context Distributions","abstract":"Nonparametric contextual bandit is an important model of sequential decision making problems. Under $\\alpha$-Tsybakov margin condition, existing research has established a regret bound of $\\tilde{O}\\left(T^{1-\\frac{\\alpha+1}{d+2}}\\right)$ for bounded supports. However, the optimal regret with unbounded contexts has not been analyzed. The challenge of solving contextual bandit problems with unbounded support is to achieve both exploration-exploitation tradeoff and bias-variance tradeoff simultaneously. In this paper, we solve the nonparametric contextual bandit problem with unbounded contexts. We propose two nearest neighbor methods combined with UCB exploration. The first method uses a fixed $k$. Our analysis shows that this method achieves minimax optimal regret under a weak margin condition and relatively light-tailed context distributions. The second method uses adaptive $k$. By a proper data-driven selection of $k$, this method achieves an expected regret of $\\tilde{O}\\left(T^{1-\\frac{(\\alpha+1)\\beta}{\\alpha+(d+2)\\beta}}+T^{1-\\beta}\\right)$, in which $\\beta$ is a parameter describing the tail strength. This bound matches the minimax lower bound up to logarithm factors, indicating that the second method is approximately optimal.","authors":["Puning Zhao","Rongfei Fan","Shaowei Wang","Li Shen","Qixin Zhang","Zong Ke","Tianhang Zheng"],"url":"https://arxiv.org/abs/2408.09655"}
{"created":"2025-05-09","title":"Deep learning-based ecological analysis of camera trap images is impacted by training data quality and quantity","abstract":"Large image collections generated from camera traps offer valuable insights into species richness, occupancy, and activity patterns, significantly aiding biodiversity monitoring. However, the manual processing of these datasets is time-consuming, hindering analytical processes. To address this, deep neural networks have been adopted to automate image labelling, but the impact of classification error on ecological metrics remains unclear. Here, we analyse data from camera trap collections in an African savannah (82,300 images, 47 species) and an Asian sub-tropical dry forest (40,308 images, 29 species) to compare ecological metrics derived from expert-generated species identifications with those generated by deep learning classification models. We specifically assess the impact of deep learning model architecture, the proportion of label noise in the training data, and the size of the training dataset on three ecological metrics: species richness, occupancy, and activity patterns. Overall, ecological metrics derived from deep neural networks closely match those calculated from expert labels and remain robust to manipulations in the training pipeline. We found that the choice of deep learning model architecture does not impact ecological metrics, and ecological metrics related to the overall community (species richness, community occupancy) were resilient to up to 10% noise in the training dataset and a 50% reduction in the training dataset size. However, we caution that less common species are disproportionately affected by a reduction in deep neural network accuracy, and this has consequences for species-specific metrics (occupancy, diel activity patterns). To ensure the reliability of their findings, practitioners should prioritize creating large, clean training sets with balanced representation across species over exploring numerous deep learning model architectures.","authors":["Peggy A. Bevan","Omiros Pantazis","Holly Pringle","Guilherme Braga Ferreira","Daniel J. Ingram","Emily Madsen","Liam Thomas","Dol Raj Thanet","Thakur Silwal","Santosh Rayamajhi","Gabriel Brostow","Oisin Mac Aodha","Kate E. Jones"],"url":"https://arxiv.org/abs/2408.14348"}
{"created":"2025-05-09","title":"Perceive-IR: Learning to Perceive Degradation Better for All-in-One Image Restoration","abstract":"Existing All-in-One image restoration methods often fail to perceive degradation types and severity levels simultaneously, overlooking the importance of fine-grained quality perception. Moreover, these methods often utilize highly customized backbones, which hinder their adaptability and integration into more advanced restoration networks. To address these limitations, we propose Perceive-IR, a novel backbone-agnostic All-in-One image restoration framework designed for fine-grained quality control across various degradation types and severity levels. Its modular structure allows core components to function independently of specific backbones, enabling seamless integration into advanced restoration models without significant modifications. Specifically, Perceive-IR operates in two key stages: 1) multi-level quality-driven prompt learning stage, where a fine-grained quality perceiver is meticulously trained to discern three tier quality levels by optimizing the alignment between prompts and images within the CLIP perception space. This stage ensures a nuanced understanding of image quality, laying the groundwork for subsequent restoration; 2) restoration stage, where the quality perceiver is seamlessly integrated with a difficulty-adaptive perceptual loss, forming a quality-aware learning strategy. This strategy not only dynamically differentiates sample learning difficulty but also achieves fine-grained quality control by driving the restored image toward the ground truth while pulling it away from both low- and medium-quality samples.","authors":["Xu Zhang","Jiaqi Ma","Guoli Wang","Qian Zhang","Huan Zhang","Lefei Zhang"],"url":"https://arxiv.org/abs/2408.15994"}
{"created":"2025-05-09","title":"XG-NID: Dual-Modality Network Intrusion Detection using a Heterogeneous Graph Neural Network and Large Language Model","abstract":"In the rapidly evolving field of cybersecurity, the integration of flow-level and packet-level information for real-time intrusion detection remains a largely untapped area of research. This paper introduces \"XG-NID,\" a novel framework that, to the best of our knowledge, is the first to fuse flow-level and packet-level data within a heterogeneous graph structure, offering a comprehensive analysis of network traffic. Leveraging a heterogeneous graph neural network (GNN) with graph-level classification, XG-NID uniquely enables real-time inference while effectively capturing the intricate relationships between flow and packet payload data. Unlike traditional GNN-based methodologies that predominantly analyze historical data, XG-NID is designed to accommodate the heterogeneous nature of network traffic, providing a robust and real-time defense mechanism. Our framework extends beyond mere classification; it integrates Large Language Models (LLMs) to generate detailed, human-readable explanations and suggest potential remedial actions, ensuring that the insights produced are both actionable and comprehensible. Additionally, we introduce a new set of flow features based on temporal information, further enhancing the contextual and explainable inferences provided by our model. To facilitate practical application and accessibility, we developed \"GNN4ID,\" an open-source tool that enables the extraction and transformation of raw network traffic into the proposed heterogeneous graph structure, seamlessly integrating flow and packet-level data. Our comprehensive quantitative comparative analysis demonstrates that XG-NID achieves an F1 score of 97\\% in multi-class classification, outperforming existing baseline and state-of-the-art methods. This sets a new standard in Network Intrusion Detection Systems by combining innovative data fusion with enhanced interpretability and real-time capabilities.","authors":["Yasir Ali Farrukh","Syed Wali","Irfan Khan","Nathaniel D. Bastian"],"url":"https://arxiv.org/abs/2408.16021"}
{"created":"2025-05-09","title":"Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene Understanding","abstract":"Complex 3D scene understanding has gained increasing attention, with scene encoding strategies playing a crucial role in this success. However, the optimal scene encoding strategies for various scenarios remain unclear, particularly compared to their image-based counterparts. To address this issue, we present a comprehensive study that probes various visual encoding models for 3D scene understanding, identifying the strengths and limitations of each model across different scenarios. Our evaluation spans seven vision foundation encoders, including image-based, video-based, and 3D foundation models. We evaluate these models in four tasks: Vision-Language Scene Reasoning, Visual Grounding, Segmentation, and Registration, each focusing on different aspects of scene understanding. Our evaluations yield key findings: DINOv2 demonstrates superior performance, video models excel in object-level tasks, diffusion models benefit geometric tasks, and language-pretrained models show unexpected limitations in language-related tasks. These insights challenge some conventional understandings, provide novel perspectives on leveraging visual foundation models, and highlight the need for more flexible encoder selection in future vision-language and scene-understanding tasks. Code: https://github.com/YunzeMan/Lexicon3D","authors":["Yunze Man","Shuhong Zheng","Zhipeng Bao","Martial Hebert","Liang-Yan Gui","Yu-Xiong Wang"],"url":"https://arxiv.org/abs/2409.03757"}
{"created":"2025-05-09","title":"Locality-aware Cross-modal Correspondence Learning for Dense Audio-Visual Events Localization","abstract":"Dense-localization Audio-Visual Events (DAVE) aims to identify time boundaries and corresponding categories for events that are both audible and visible in a long video, where events may co-occur and exhibit varying durations. However, complex audio-visual scenes often involve asynchronization between modalities, making accurate localization challenging. Existing DAVE solutions extract audio and visual features through unimodal encoders, and fuse them via dense cross-modal interaction. However, independent unimodal encoding struggles to emphasize shared semantics between modalities without cross-modal guidance, while dense cross-modal attention may over-attend to semantically unrelated audio-visual features. To address these problems, we present LoCo, a Locality-aware cross-modal Correspondence learning framework for DAVE. LoCo leverages the local temporal continuity of audio-visual events as important guidance to filter irrelevant cross-modal signals and enhance cross-modal alignment throughout both unimodal and cross-modal encoding stages. i) Specifically, LoCo applies Local Correspondence Feature (LCF) Modulation to enforce unimodal encoders to focus on modality-shared semantics by modulating agreement between audio and visual features based on local cross-modal coherence. ii) To better aggregate cross-modal relevant features, we further customize Local Adaptive Cross-modal (LAC) Interaction, which dynamically adjusts attention regions in a data-driven manner. This adaptive mechanism focuses attention on local event boundaries and accommodates varying event durations. By incorporating LCF and LAC, LoCo provides solid performance gains and outperforms existing DAVE methods.","authors":["Ling Xing","Hongyu Qu","Rui Yan","Xiangbo Shu","Jinhui Tang"],"url":"https://arxiv.org/abs/2409.07967"}
{"created":"2025-05-09","title":"Extending the Benefits of Parallel Elasticity across Multiple Actuation Tasks: A Geometric and Optimization-Based Approach","abstract":"A spring in parallel with an effort source (e.g., electric motor or human muscle) can reduce its energy consumption and effort (i.e., torque or force) depending on the spring stiffness, spring preload, and actuation task. However, selecting the spring stiffness and preload that guarantees effort or energy reduction for an arbitrary set of tasks is a design challenge. This work formulates a convex optimization problem to guarantee that a parallel spring reduces the root-mean-square source effort or energy consumption for multiple tasks. Specifically, we guarantee the benefits across multiple tasks by enforcing a set of convex quadratic constraints in our optimization variables, the parallel spring stiffness and preload. These quadratic constraints are equivalent to ellipses in the stiffness and preload plane; any combination of stiffness and preload inside the ellipse represents a parallel spring that minimizes effort source or energy consumption with respect to an actuator without a spring. This geometric interpretation intuitively guides the stiffness and preload selection process. We analytically and experimentally prove the convex quadratic function of the spring stiffness and preload. As applications, we analyze the stiffness and preload selection of a parallel spring for a knee exoskeleton using human muscle as the effort source and a prosthetic ankle powered by electric motors. The source code associated with our framework is available as supplemental open-source software.","authors":["Kang Yang","Myia Dickens","James Schmiedeler","Edgar Bol\\'ivar-Nieto"],"url":"https://arxiv.org/abs/2409.08889"}
{"created":"2025-05-09","title":"HESSO: Towards Automatic Efficient and User Friendly Any Neural Network Training and Pruning","abstract":"Structured pruning is one of the most popular approaches to effectively compress the heavy deep neural networks (DNNs) into compact sub-networks while retaining performance. The existing methods suffer from multi-stage procedures along with significant engineering efforts and human expertise. The Only-Train-Once (OTO) series has been recently proposed to resolve the many pain points by streamlining the workflow by automatically conducting (i) search space generation, (ii) structured sparse optimization, and (iii) sub-network construction. However, the built-in sparse optimizers in the OTO series, i.e., the Half-Space Projected Gradient (HSPG) family, have limitations that require hyper-parameter tuning and the implicit controls of the sparsity exploration, consequently requires intervening by human expertise. To address such limitations, we propose a Hybrid Efficient Structured Sparse Optimizer (HESSO). HESSO could automatically and efficiently train a DNN to produce a high-performing subnetwork. Meanwhile, it is almost tuning-free and enjoys user-friendly integration for generic training applications. To address another common issue of irreversible performance collapse observed in pruning DNNs, we further propose a Corrective Redundant Identification Cycle (CRIC) for reliably identifying indispensable structures. We numerically demonstrate the efficacy of HESSO and its enhanced version HESSO-CRIC on a variety of applications ranging from computer vision to natural language processing, including large language model. The numerical results showcase that HESSO can achieve competitive even superior performance to varying state-of-the-arts and support most DNN architectures. Meanwhile, CRIC can effectively prevent the irreversible performance collapse and further enhance the performance of HESSO on certain applications.","authors":["Tianyi Chen","Xiaoyi Qu","David Aponte","Colby Banbury","Jongwoo Ko","Tianyu Ding","Yong Ma","Vladimir Lyapunov","Ilya Zharkov","Luming Liang"],"url":"https://arxiv.org/abs/2409.09085"}
{"created":"2025-05-09","title":"On Synthetic Texture Datasets: Challenges, Creation, and Curation","abstract":"The influence of textures on machine learning models has been an ongoing investigation, specifically in texture bias/learning, interpretability, and robustness. However, due to the lack of large and diverse texture data available, the findings in these works have been limited, as more comprehensive evaluations have not been feasible. Image generative models are able to provide data creation at scale, but utilizing these models for texture synthesis has been unexplored and poses additional challenges both in creating accurate texture images and validating those images. In this work, we introduce an extensible methodology and corresponding new dataset for generating high-quality, diverse texture images capable of supporting a broad set of texture-based tasks. Our pipeline consists of: (1) developing prompts from a range of descriptors to serve as input to text-to-image models, (2) adopting and adapting Stable Diffusion pipelines to generate and filter the corresponding images, and (3) further filtering down to the highest quality images. Through this, we create the Prompted Textures Dataset (PTD), a dataset of 362,880 texture images that span 56 textures. During the process of generating images, we find that NSFW safety filters in image generation pipelines are highly sensitive to texture (and flag up to 60\\% of our texture images), uncovering a potential bias in these models and presenting unique challenges when working with texture data. Through both standard metrics and a human evaluation, we find that our dataset is high quality and diverse. Our dataset is available for download at https://zenodo.org/records/15359142.","authors":["Blaine Hoak","Patrick McDaniel"],"url":"https://arxiv.org/abs/2409.10297"}
{"created":"2025-05-09","title":"Exploring the Trade-Offs: Quantization Methods, Task Difficulty, and Model Size in Large Language Models From Edge to Giant","abstract":"Quantization has gained attention as a promising solution for the cost-effective deployment of large and small language models. However, most prior work has been limited to perplexity or basic knowledge tasks and lacks a comprehensive evaluation of recent models like Llama-3.3. In this paper, we conduct a comprehensive evaluation of instruction-tuned models spanning 1B to 405B parameters, applying four quantization methods across 13 datasets. Our findings reveal that (1) quantized models generally surpass smaller FP16 baselines, yet they often struggle with instruction-following and hallucination detection; (2) FP8 consistently emerges as the most robust option across tasks, and AWQ tends to outperform GPTQ in weight-only quantization; (3) smaller models can suffer severe accuracy drops at 4-bit quantization, while 70B-scale models maintain stable performance; (4) notably, \\textit{hard} tasks do not always experience the largest accuracy losses, indicating that quantization magnifies a model's inherent weaknesses rather than simply correlating with task difficulty; and (5) an LLM-based judge (MT-Bench) highlights significant performance declines in coding and STEM tasks, though reasoning may sometimes improve.","authors":["Jemin Lee","Sihyeong Park","Jinse Kwon","Jihun Oh","Yongin Kwon"],"url":"https://arxiv.org/abs/2409.11055"}
{"created":"2025-05-09","title":"Protecting Privacy in Software Logs: What Should Be Anonymized?","abstract":"Software logs, generated during the runtime of software systems, are essential for various development and analysis activities, such as anomaly detection and failure diagnosis. However, the presence of sensitive information in these logs poses significant privacy concerns, particularly regarding Personally Identifiable Information (PII) and quasi-identifiers that could lead to re-identification risks. While general data privacy has been extensively studied, the specific domain of privacy in software logs remains underexplored, with inconsistent definitions of sensitivity and a lack of standardized guidelines for anonymization. To mitigate this gap, this study offers a comprehensive analysis of privacy in software logs from multiple perspectives. We start by performing an analysis of 25 publicly available log datasets to identify potentially sensitive attributes. Based on the result of this step, we focus on three perspectives: privacy regulations, research literature, and industry practices. We first analyze key data privacy regulations, such as the General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA), to understand the legal requirements concerning sensitive information in logs. Second, we conduct a systematic literature review to identify common privacy attributes and practices in log anonymization, revealing gaps in existing approaches. Finally, we survey 45 industry professionals to capture practical insights on log anonymization practices. Our findings shed light on various perspectives of log privacy and reveal industry challenges, such as technical and efficiency issues while highlighting the need for standardized guidelines. By combining insights from regulatory, academic, and industry perspectives, our study aims to provide a clearer framework for identifying and protecting sensitive information in software logs.","authors":["Roozbeh Aghili","Heng Li","Foutse Khomh"],"url":"https://arxiv.org/abs/2409.11313"}
{"created":"2025-05-09","title":"Automated detection of underdiagnosed medical conditions via opportunistic imaging","abstract":"Abdominal computed tomography (CT) scans are frequently performed in clinical settings. Opportunistic CT involves repurposing routine CT images to extract diagnostic information and is an emerging tool for detecting underdiagnosed conditions such as sarcopenia, hepatic steatosis, and ascites. This study utilizes deep learning methods to promote accurate diagnosis and clinical documentation. We analyze 2,674 inpatient CT scans to identify discrepancies between imaging phenotypes (characteristics derived from opportunistic CT scans) and their corresponding documentation in radiology reports and ICD coding. Through our analysis, we find that only 0.5%, 3.2%, and 30.7% of scans diagnosed with sarcopenia, hepatic steatosis, and ascites (respectively) through either opportunistic imaging or radiology reports were ICD-coded. Our findings demonstrate opportunistic CT's potential to enhance diagnostic precision and accuracy of risk adjustment models, offering advancements in precision medicine.","authors":["Asad Aali","Andrew Johnston","Louis Blankemeier","Dave Van Veen","Laura T Derry","David Svec","Jason Hom","Robert D. Boutin","Akshay S. Chaudhari"],"url":"https://arxiv.org/abs/2409.11686"}
{"created":"2025-05-09","title":"To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning","abstract":"Chain-of-thought (CoT) via prompting is the de facto method for eliciting reasoning capabilities from large language models (LLMs). But for what kinds of tasks is this extra ``thinking'' really helpful? To analyze this, we conducted a quantitative meta-analysis covering over 100 papers using CoT and ran our own evaluations of 20 datasets across 14 models. Our results show that CoT gives strong performance benefits primarily on tasks involving math or logic, with much smaller gains on other types of tasks. On MMLU, directly generating the answer without CoT leads to almost identical accuracy as CoT unless the question or model's response contains an equals sign, indicating symbolic operations and reasoning. Following this finding, we analyze the behavior of CoT on these problems by separating planning and execution and comparing against tool-augmented LLMs. Much of CoT's gain comes from improving symbolic execution, but it underperforms relative to using a symbolic solver. Our results indicate that CoT can be applied selectively, maintaining performance while saving inference costs. Furthermore, they suggest a need to move beyond prompt-based CoT to new paradigms that better leverage intermediate computation across the whole range of LLM applications.","authors":["Zayne Sprague","Fangcong Yin","Juan Diego Rodriguez","Dongwei Jiang","Manya Wadhwa","Prasann Singhal","Xinyu Zhao","Xi Ye","Kyle Mahowald","Greg Durrett"],"url":"https://arxiv.org/abs/2409.12183"}
{"created":"2025-05-09","title":"Learning to Compare Hardware Designs for High-Level Synthesis","abstract":"High-level synthesis (HLS) is an automated design process that transforms high-level code into hardware designs, enabling the rapid development of hardware accelerators. HLS relies on pragmas, which are directives inserted into the source code to guide the synthesis process, and pragmas have various settings and values that significantly impact the resulting hardware design. State-of-the-art ML-based HLS methods, such as HARP, first train a deep learning model, typically based on graph neural networks (GNNs) applied to graph-based representations of the source code and pragmas. They then perform design space exploration (DSE) to explore the pragma design space, rank candidate designs using the model, and return the top designs. However, traditional DSE methods face challenges due to the highly nonlinear relationship between pragma settings and performance metrics, along with complex interactions between pragmas that affect performance in non-obvious ways.","authors":["Yunsheng Bai","Atefeh Sohrabizadeh","Zijian Ding","Rongjian Liang","Weikai Li","Ding Wang","Haoxing Ren","Yizhou Sun","Jason Cong"],"url":"https://arxiv.org/abs/2409.13138"}
{"created":"2025-05-09","title":"DiSPo: Diffusion-SSM based Policy Learning for Coarse-to-Fine Action Discretization","abstract":"We aim to solve the problem of generating coarse-to-fine skills learning from demonstrations (LfD). To scale precision, traditional LfD approaches often rely on extensive fine-grained demonstrations with external interpolations or dynamics models with limited generalization capabilities. For memory-efficient learning and convenient granularity change, we propose a novel diffusion-SSM based policy (DiSPo) that learns from diverse coarse skills and produces varying control scales of actions by leveraging a state-space model, Mamba. Our evaluations show the adoption of Mamba and the proposed step-scaling method enable DiSPo to outperform in three coarse-to-fine benchmark tests with maximum 81% higher success rate than baselines. In addition, DiSPo improves inference efficiency by generating coarse motions in less critical regions. We finally demonstrate the scalability of actions with simulation and real-world manipulation tasks.","authors":["Nayoung Oh","Jaehyeong Jang","Moonkyeong Jung","Daehyung Park"],"url":"https://arxiv.org/abs/2409.14719"}
{"created":"2025-05-09","title":"Diffusion Models for Intelligent Transportation Systems: A Survey","abstract":"Intelligent Transportation Systems (ITS) are vital in modern traffic management and optimization, significantly enhancing traffic efficiency and safety. Recently, diffusion models have emerged as transformative tools for addressing complex challenges within ITS. In this paper, we present a comprehensive survey of diffusion models for ITS, covering both theoretical and practical aspects. First, we introduce the theoretical foundations of diffusion models and their key variants, including conditional diffusion models and latent diffusion models, highlighting their suitability for modeling complex, multi-modal traffic data and enabling controllable generation. Second, we outline the primary challenges in ITS and the corresponding advantages of diffusion models, providing readers with a deeper understanding of the intersection between ITS and diffusion models. Third, we offer a multi-perspective investigation of current applications of diffusion models in ITS domains, including autonomous driving, traffic simulation, trajectory prediction, and traffic safety. Finally, we discuss state-of-the-art diffusion model techniques and highlight key ITS research directions that warrant further investigation. Through this structured overview, we aim to provide researchers with a comprehensive understanding of diffusion models for ITS, thereby advancing their future applications in the transportation domain.","authors":["Mingxing Peng","Kehua Chen","Xusen Guo","Qiming Zhang","Hui Zhong","Meixin Zhu","Hai Yang"],"url":"https://arxiv.org/abs/2409.15816"}
{"created":"2025-05-09","title":"CloudTrack: Scalable UAV Tracking with Cloud Semantics","abstract":"Nowadays, unmanned aerial vehicles (UAVs) are commonly used in search and rescue scenarios to gather information in the search area. The automatic identification of the person searched for in aerial footage could increase the autonomy of such systems, reduce the search time, and thus increase the missed person's chances of survival. In this paper, we present a novel approach to perform semantically conditioned open vocabulary object tracking that is specifically designed to cope with the limitations of UAV hardware. Our approach has several advantages. It can run with verbal descriptions of the missing person, e.g., the color of the shirt, it does not require dedicated training to execute the mission and can efficiently track a potentially moving person. Our experimental results demonstrate the versatility and efficacy of our approach.","authors":["Yannik Blei","Michael Krawez","Nisarga Nilavadi","Tanja Katharina Kaiser","Wolfram Burgard"],"url":"https://arxiv.org/abs/2409.16111"}
{"created":"2025-05-09","title":"Large-scale, Longitudinal, Hybrid Participatory Design Program to Create Navigation Technology for the Blind","abstract":"Empowering people who are blind or visually impaired (BVI) to enhance their orientation and mobility skills is critical to equalizing their access to social and economic opportunities. To manage this crucial challenge, we employed a novel design process based on a large-scale, longitudinal, community-based structure. Across three annual programs we engaged with the BVI community in online and in-person modes. In total, our team included 67 total BVI participatory design participants online, 11 BVI co-designers in-person, and 4 BVI program coordinators. Through this design process we built a mobile application that enables users to generate, share, and navigate maps of indoor and outdoor environments without the need to instrument each environment with beacons or fiducial markers. We evaluated this app at a healthcare facility, and participants in the evaluation rated the app highly with respect to its design, features, and potential for positive impact on quality of life.","authors":["Daeun Joyce Chung","Muya Guoji","Nina Mindel","Alexis Malkin","Fernando Albertorio","Shane Lowe","Chris McNally","Casandra Xavier","Paul Ruvolo"],"url":"https://arxiv.org/abs/2410.00192"}
{"created":"2025-05-09","title":"Characterizing and Efficiently Accelerating Multimodal Generation Model Inference","abstract":"Generative artificial intelligence (AI) technology is revolutionizing the computing industry. Not only its applications have broadened to various sectors but also poses new system design and optimization opportunities. The technology is capable of understanding and responding in multiple modalities. However, the advanced capability currently comes with significant system resource demands. To sustainably scale generative AI capabilities to billions of users in the world, inference must be fast and efficient. This paper pinpoints key system design and optimization opportunities by characterizing a family of emerging multi-modal generation models on real systems. Auto-regressive token generation is a critical latency performance bottleneck, typically dominated by GPU idle time. In addition to memory-intensive attention across the generative AI models, linear operations constitute significant inference latency due to the feed forward networks in Transformer-based models. We demonstrate that state-of-the-art optimization levers, spanning from applications to system software and hardware, set a 3.88x better baseline.","authors":["Yejin Lee","Anna Sun","Basil Hosmer","Bilge Acun","Can Balioglu","Changhan Wang","Charles David Hernandez","Christian Puhrsch","Daniel Haziza","Driss Guessous","Francisco Massa","Jacob Kahn","Jeffrey Wan","Jeremy Reizenstein","Jiaqi Zhai","Joe Isaacson","Joel Schlosser","Juan Pino","Kaushik Ram Sadagopan","Leonid Shamis","Linjian Ma","Min-Jae Hwang","Mingda Chen","Mostafa Elhoushi","Pedro Rodriguez","Ram Pasunuru","Scott Yih","Sravya Popuri","Xing Liu","Carole-Jean Wu"],"url":"https://arxiv.org/abs/2410.00215"}
{"created":"2025-05-09","title":"Learning stochastic dynamics from snapshots through regularized unbalanced optimal transport","abstract":"Reconstructing dynamics using samples from sparsely time-resolved snapshots is an important problem in both natural sciences and machine learning. Here, we introduce a new deep learning approach for solving regularized unbalanced optimal transport (RUOT) and inferring continuous unbalanced stochastic dynamics from observed snapshots. Based on the RUOT form, our method models these dynamics without requiring prior knowledge of growth and death processes or additional information, allowing them to be learned directly from data. Theoretically, we explore the connections between the RUOT and Schr\\\"odinger bridge problem and discuss the key challenges and potential solutions. The effectiveness of our method is demonstrated with a synthetic gene regulatory network, high-dimensional Gaussian Mixture Model, and single-cell RNA-seq data from blood development. Compared with other methods, our approach accurately identifies growth and transition patterns, eliminates false transitions, and constructs the Waddington developmental landscape. Our code is available at: https://github.com/zhenyiizhang/DeepRUOT.","authors":["Zhenyi Zhang","Tiejun Li","Peijie Zhou"],"url":"https://arxiv.org/abs/2410.00844"}
{"created":"2025-05-09","title":"C-MORL: Multi-Objective Reinforcement Learning through Efficient Discovery of Pareto Front","abstract":"Multi-objective reinforcement learning (MORL) excels at handling rapidly changing preferences in tasks that involve multiple criteria, even for unseen preferences. However, previous dominating MORL methods typically generate a fixed policy set or preference-conditioned policy through multiple training iterations exclusively for sampled preference vectors, and cannot ensure the efficient discovery of the Pareto front. Furthermore, integrating preferences into the input of policy or value functions presents scalability challenges, in particular as the dimension of the state and preference space grow, which can complicate the learning process and hinder the algorithm's performance on more complex tasks. To address these issues, we propose a two-stage Pareto front discovery algorithm called Constrained MORL (C-MORL), which serves as a seamless bridge between constrained policy optimization and MORL. Concretely, a set of policies is trained in parallel in the initialization stage, with each optimized towards its individual preference over the multiple objectives. Then, to fill the remaining vacancies in the Pareto front, the constrained optimization steps are employed to maximize one objective while constraining the other objectives to exceed a predefined threshold. Empirically, compared to recent advancements in MORL methods, our algorithm achieves more consistent and superior performances in terms of hypervolume, expected utility, and sparsity on both discrete and continuous control tasks, especially with numerous objectives (up to nine objectives in our experiments).","authors":["Ruohong Liu","Yuxin Pan","Linjie Xu","Lei Song","Jiang Bian","Pengcheng You","Yize Chen"],"url":"https://arxiv.org/abs/2410.02236"}
{"created":"2025-05-09","title":"Look Twice Before You Answer: Memory-Space Visual Retracing for Hallucination Mitigation in Multimodal Large Language Models","abstract":"Despite their impressive capabilities, multimodal large language models (MLLMs) are prone to hallucinations, i.e., the generated content that is nonsensical or unfaithful to input sources. Unlike in LLMs, hallucinations in MLLMs often stem from the sensitivity of text decoder to visual tokens, leading to a phenomenon akin to \"amnesia\" about visual information. To address this issue, we propose MemVR, a novel decoding paradigm inspired by common cognition: when the memory of an image seen the moment before is forgotten, people will look at it again for factual answers. Following this principle, we treat visual tokens as supplementary evidence, re-injecting them into the MLLM through Feed Forward Network (FFN) as \"key-value memory\" at the middle trigger layer. This \"look-twice\" mechanism occurs when the model exhibits high uncertainty during inference, effectively enhancing factual alignment. Comprehensive experimental evaluations demonstrate that MemVR significantly mitigates hallucination across various MLLMs and excels in general benchmarks without incurring additional time overhead. The implementation is available from https://github.com/1zhou-Wang/MemVR","authors":["Xin Zou","Yizhou Wang","Yibo Yan","Yuanhuiyi Lyu","Kening Zheng","Sirui Huang","Junkai Chen","Peijie Jiang","Jia Liu","Chang Tang","Xuming Hu"],"url":"https://arxiv.org/abs/2410.03577"}
{"created":"2025-05-09","title":"MonST3R: A Simple Approach for Estimating Geometry in the Presence of Motion","abstract":"Estimating geometry from dynamic scenes, where objects move and deform over time, remains a core challenge in computer vision. Current approaches often rely on multi-stage pipelines or global optimizations that decompose the problem into subtasks, like depth and flow, leading to complex systems prone to errors. In this paper, we present Motion DUSt3R (MonST3R), a novel geometry-first approach that directly estimates per-timestep geometry from dynamic scenes. Our key insight is that by simply estimating a pointmap for each timestep, we can effectively adapt DUST3R's representation, previously only used for static scenes, to dynamic scenes. However, this approach presents a significant challenge: the scarcity of suitable training data, namely dynamic, posed videos with depth labels. Despite this, we show that by posing the problem as a fine-tuning task, identifying several suitable datasets, and strategically training the model on this limited data, we can surprisingly enable the model to handle dynamics, even without an explicit motion representation. Based on this, we introduce new optimizations for several downstream video-specific tasks and demonstrate strong performance on video depth and camera pose estimation, outperforming prior work in terms of robustness and efficiency. Moreover, MonST3R shows promising results for primarily feed-forward 4D reconstruction.","authors":["Junyi Zhang","Charles Herrmann","Junhwa Hur","Varun Jampani","Trevor Darrell","Forrester Cole","Deqing Sun","Ming-Hsuan Yang"],"url":"https://arxiv.org/abs/2410.03825"}
{"created":"2025-05-09","title":"Self-Correction is More than Refinement: A Learning Framework for Visual and Language Reasoning Tasks","abstract":"While Vision-Language Models (VLMs) have shown remarkable abilities in visual and language reasoning tasks, they invariably generate flawed responses. Self-correction that instructs models to refine their outputs presents a promising solution to this issue. Previous studies have mainly concentrated on Large Language Models (LLMs), while the self-correction abilities of VLMs, particularly concerning both visual and linguistic information, remain largely unexamined. This study investigates the self-correction capabilities of VLMs during both inference and fine-tuning stages. We introduce a Self-Correction Learning (SCL) approach that enables VLMs to learn from their self-generated self-correction data through Direct Preference Optimization (DPO) without relying on external feedback, facilitating self-improvement. Specifically, we collect preferred and disfavored samples based on the correctness of initial and refined responses, which are obtained by two-turn self-correction with VLMs during the inference stage. Experimental results demonstrate that although VLMs struggle to self-correct effectively during iterative inference without additional fine-tuning and external feedback, they can enhance their performance and avoid previous mistakes through preference fine-tuning when their self-generated self-correction data are categorized into preferred and disfavored samples. This study emphasizes that self-correction is not merely a refinement process; rather, it should enhance the reasoning abilities of models through additional training, enabling them to generate high-quality responses directly without further refinement.","authors":["Jiayi He","Hehai Lin","Qingyun Wang","Yi Fung","Heng Ji"],"url":"https://arxiv.org/abs/2410.04055"}
{"created":"2025-05-09","title":"From Perception to Decision: Assessing the Role of Chart Types Affordances in High-Level Decision Tasks","abstract":"Visualization design influences how people perceive data patterns, yet most research focuses on low-level analytic tasks, such as finding correlations. The extent to which these perceptual affordances translate to high-level decision-making in the real world remains underexplored. Through a case study of academic mentorship selection using bar charts and pie charts, we investigated whether chart types differentially influence how students evaluate faculty research profiles. Our crowdsourced experiment revealed only minimal differences in decision outcomes between chart types, suggesting that perceptual affordances established in controlled analytical tasks may not directly translate to high-level decision scenarios. These findings emphasize the importance of evaluating visualizations within real-world contexts and highlight the need to distinguish between perceptual and decision affordances when developing visualization guidelines.","authors":["Yixuan Li","Emery D. Berger","Minsuk Kahng","Cindy Xiong Bearfield"],"url":"https://arxiv.org/abs/2410.04686"}
{"created":"2025-05-09","title":"Let's Ask GNN: Empowering Large Language Model for Graph In-Context Learning","abstract":"Textual Attributed Graphs (TAGs) are crucial for modeling complex real-world systems, yet leveraging large language models (LLMs) for TAGs presents unique challenges due to the gap between sequential text processing and graph-structured data. We introduce AskGNN, a novel approach that bridges this gap by leveraging In-Context Learning (ICL) to integrate graph data and task-specific information into LLMs. AskGNN employs a Graph Neural Network (GNN)-powered structure-enhanced retriever to select labeled nodes across graphs, incorporating complex graph structures and their supervision signals. Our learning-to-retrieve algorithm optimizes the retriever to select example nodes that maximize LLM performance on graph. Experiments across three tasks and seven LLMs demonstrate AskGNN's superior effectiveness in graph task performance, opening new avenues for applying LLMs to graph-structured data without extensive fine-tuning.","authors":["Zhengyu Hu","Yichuan Li","Zhengyu Chen","Jingang Wang","Han Liu","Kyumin Lee","Kaize Ding"],"url":"https://arxiv.org/abs/2410.07074"}
{"created":"2025-05-09","title":"SceneCraft: Layout-Guided 3D Scene Generation","abstract":"The creation of complex 3D scenes tailored to user specifications has been a tedious and challenging task with traditional 3D modeling tools. Although some pioneering methods have achieved automatic text-to-3D generation, they are generally limited to small-scale scenes with restricted control over the shape and texture. We introduce SceneCraft, a novel method for generating detailed indoor scenes that adhere to textual descriptions and spatial layout preferences provided by users. Central to our method is a rendering-based technique, which converts 3D semantic layouts into multi-view 2D proxy maps. Furthermore, we design a semantic and depth conditioned diffusion model to generate multi-view images, which are used to learn a neural radiance field (NeRF) as the final scene representation. Without the constraints of panorama image generation, we surpass previous methods in supporting complicated indoor space generation beyond a single room, even as complicated as a whole multi-bedroom apartment with irregular shapes and layouts. Through experimental analysis, we demonstrate that our method significantly outperforms existing approaches in complex indoor scene generation with diverse textures, consistent geometry, and realistic visual quality. Code and more results are available at: https://orangesodahub.github.io/SceneCraft","authors":["Xiuyu Yang","Yunze Man","Jun-Kun Chen","Yu-Xiong Wang"],"url":"https://arxiv.org/abs/2410.09049"}
{"created":"2025-05-09","title":"SAPIENT: Mastering Multi-turn Conversational Recommendation with Strategic Planning and Monte Carlo Tree Search","abstract":"Conversational Recommender Systems (CRS) proactively engage users in interactive dialogues to elicit user preferences and provide personalized recommendations. Existing methods train Reinforcement Learning (RL)-based agent with greedy action selection or sampling strategy, and may suffer from suboptimal conversational planning. To address this, we present a novel Monte Carlo Tree Search (MCTS)-based CRS framework SAPIENT. SAPIENT consists of a conversational agent (S-agent) and a conversational planner (S-planner). S-planner builds a conversational search tree with MCTS based on the initial actions proposed by S-agent to find conversation plans. The best conversation plans from S-planner are used to guide the training of S-agent, creating a self-training loop where S-agent can iteratively improve its capability for conversational planning. Furthermore, we propose an efficient variant SAPIENT for trade-off between training efficiency and performance. Extensive experiments on four benchmark datasets validate the effectiveness of our approach, showing that SAPIENT outperforms the state-of-the-art baselines. Our code and data are accessible through https://github.com/ninglab/SAPIENT.","authors":["Hanwen Du","Bo Peng","Xia Ning"],"url":"https://arxiv.org/abs/2410.09580"}
{"created":"2025-05-09","title":"Regularized Robustly Reliable Learners and Instance Targeted Attacks","abstract":"Instance-targeted data poisoning attacks, where an adversary corrupts a training set to induce errors on specific test points, have raised significant concerns. Balcan et al (2022) proposed an approach to addressing this challenge by defining a notion of robustly-reliable learners that provide per-instance guarantees of correctness under well-defined assumptions, even in the presence of data poisoning attacks. They then give a generic optimal (but computationally inefficient) robustly reliable learner as well as a computationally efficient algorithm for the case of linear separators over log-concave distributions.","authors":["Avrim Blum","Donya Saless"],"url":"https://arxiv.org/abs/2410.10572"}
{"created":"2025-05-09","title":"CATCH: Channel-Aware multivariate Time Series Anomaly Detection via Frequency Patching","abstract":"Anomaly detection in multivariate time series is challenging as heterogeneous subsequence anomalies may occur. Reconstruction-based methods, which focus on learning normal patterns in the frequency domain to detect diverse abnormal subsequences, achieve promising results, while still falling short on capturing fine-grained frequency characteristics and channel correlations. To contend with the limitations, we introduce CATCH, a framework based on frequency patching. We propose to patchify the frequency domain into frequency bands, which enhances its ability to capture fine-grained frequency characteristics. To perceive appropriate channel correlations, we propose a Channel Fusion Module (CFM), which features a patch-wise mask generator and a masked-attention mechanism. Driven by a bi-level multi-objective optimization algorithm, the CFM is encouraged to iteratively discover appropriate patch-wise channel correlations, and to cluster relevant channels while isolating adverse effects from irrelevant channels. Extensive experiments on 10 real-world datasets and 12 synthetic datasets demonstrate that CATCH achieves state-of-the-art performance. We make our code and datasets available at https://github.com/decisionintelligence/CATCH.","authors":["Xingjian Wu","Xiangfei Qiu","Zhengyu Li","Yihang Wang","Jilin Hu","Chenjuan Guo","Hui Xiong","Bin Yang"],"url":"https://arxiv.org/abs/2410.12261"}
{"created":"2025-05-09","title":"WorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines","abstract":"Vision Language Models (VLMs) often struggle with culture-specific knowledge, particularly in languages other than English and in underrepresented cultural contexts. To evaluate their understanding of such knowledge, we introduce WorldCuisines, a massive-scale benchmark for multilingual and multicultural, visually grounded language understanding. This benchmark includes a visual question answering (VQA) dataset with text-image pairs across 30 languages and dialects, spanning 9 language families and featuring over 1 million data points, making it the largest multicultural VQA benchmark to date. It includes tasks for identifying dish names and their origins. We provide evaluation datasets in two sizes (12k and 60k instances) alongside a training dataset (1 million instances). Our findings show that while VLMs perform better with correct location context, they struggle with adversarial contexts and predicting specific regional cuisines and languages. To support future research, we release a knowledge base with annotated food entries and images along with the VQA data.","authors":["Genta Indra Winata","Frederikus Hudi","Patrick Amadeus Irawan","David Anugraha","Rifki Afina Putri","Yutong Wang","Adam Nohejl","Ubaidillah Ariq Prathama","Nedjma Ousidhoum","Afifa Amriani","Anar Rzayev","Anirban Das","Ashmari Pramodya","Aulia Adila","Bryan Wilie","Candy Olivia Mawalim","Ching Lam Cheng","Daud Abolade","Emmanuele Chersoni","Enrico Santus","Fariz Ikhwantri","Garry Kuwanto","Hanyang Zhao","Haryo Akbarianto Wibowo","Holy Lovenia","Jan Christian Blaise Cruz","Jan Wira Gotama Putra","Junho Myung","Lucky Susanto","Maria Angelica Riera Machin","Marina Zhukova","Michael Anugraha","Muhammad Farid Adilazuarda","Natasha Santosa","Peerat Limkonchotiwat","Raj Dabre","Rio Alexander Audino","Samuel Cahyawijaya","Shi-Xiong Zhang","Stephanie Yulia Salim","Yi Zhou","Yinxuan Gui","David Ifeoluwa Adelani","En-Shiun Annie Lee","Shogo Okada","Ayu Purwarianti","Alham Fikri Aji","Taro Watanabe","Derry Tanti Wijaya","Alice Oh","Chong-Wah Ngo"],"url":"https://arxiv.org/abs/2410.12705"}
{"created":"2025-05-09","title":"Electrocardiogram-Language Model for Few-Shot Question Answering with Meta Learning","abstract":"Electrocardiogram (ECG) interpretation requires specialized expertise, often involving synthesizing insights from ECG signals with complex clinical queries posed in natural language. The scarcity of labeled ECG data coupled with the diverse nature of clinical inquiries presents a significant challenge for developing robust and adaptable ECG diagnostic systems. This work introduces a novel multimodal meta-learning method for few-shot ECG question answering, addressing the challenge of limited labeled data while leveraging the rich knowledge encoded within large language models (LLMs). Our LLM-agnostic approach integrates a pre-trained ECG encoder with a frozen LLM (e.g., LLaMA and Gemma) via a trainable fusion module, enabling the language model to reason about ECG data and generate clinically meaningful answers. Extensive experiments demonstrate superior generalization to unseen diagnostic tasks compared to supervised baselines, achieving notable performance even with limited ECG leads. For instance, in a 5-way 5-shot setting, our method using LLaMA-3.1-8B achieves an accuracy of 84.6%, 77.3%, and 69.6% on single verify, choose and query question types, respectively. These results highlight the potential of our method to enhance clinical ECG interpretation by combining signal processing with the nuanced language understanding capabilities of LLMs, particularly in data-constrained scenarios.","authors":["Jialu Tang","Tong Xia","Yuan Lu","Cecilia Mascolo","Aaqib Saeed"],"url":"https://arxiv.org/abs/2410.14464"}
{"created":"2025-05-09","title":"Jailbreaking and Mitigation of Vulnerabilities in Large Language Models","abstract":"Large Language Models (LLMs) have transformed artificial intelligence by advancing natural language understanding and generation, enabling applications across fields beyond healthcare, software engineering, and conversational systems. Despite these advancements in the past few years, LLMs have shown considerable vulnerabilities, particularly to prompt injection and jailbreaking attacks. This review analyzes the state of research on these vulnerabilities and presents available defense strategies. We roughly categorize attack approaches into prompt-based, model-based, multimodal, and multilingual, covering techniques such as adversarial prompting, backdoor injections, and cross-modality exploits. We also review various defense mechanisms, including prompt filtering, transformation, alignment techniques, multi-agent defenses, and self-regulation, evaluating their strengths and shortcomings. We also discuss key metrics and benchmarks used to assess LLM safety and robustness, noting challenges like the quantification of attack success in interactive contexts and biases in existing datasets. Identifying current research gaps, we suggest future directions for resilient alignment strategies, advanced defenses against evolving attacks, automation of jailbreak detection, and consideration of ethical and societal impacts. This review emphasizes the need for continued research and cooperation within the AI community to enhance LLM security and ensure their safe deployment.","authors":["Benji Peng","Keyu Chen","Qian Niu","Ziqian Bi","Ming Liu","Pohsun Feng","Tianyang Wang","Lawrence K. Q. Yan","Yizhu Wen","Yichao Zhang","Caitlyn Heqi Yin"],"url":"https://arxiv.org/abs/2410.15236"}
{"created":"2025-05-09","title":"E2E-AFG: An End-to-End Model with Adaptive Filtering for Retrieval-Augmented Generation","abstract":"Retrieval-augmented generation methods often neglect the quality of content retrieved from external knowledge bases, resulting in irrelevant information or potential misinformation that negatively affects the generation results of large language models. In this paper, we propose an end-to-end model with adaptive filtering for retrieval-augmented generation (E2E-AFG), which integrates answer existence judgment and text generation into a single end-to-end framework. This enables the model to focus more effectively on relevant content while reducing the influence of irrelevant information and generating accurate answers. We evaluate E2E-AFG on six representative knowledge-intensive language datasets, and the results show that it consistently outperforms baseline models across all tasks, demonstrating the effectiveness and robustness of the proposed approach.","authors":["Yun Jiang","Zilong Xie","Wei Zhang","Yun Fang","Shuai Pan"],"url":"https://arxiv.org/abs/2411.00437"}
{"created":"2025-05-09","title":"Learning from Convolution-based Unlearnable Datasets","abstract":"The construction of large datasets for deep learning has raised concerns regarding unauthorized use of online data, leading to increased interest in protecting data from third-parties who want to use it for training. The Convolution-based Unlearnable DAtaset (CUDA) method aims to make data unlearnable by applying class-wise blurs to every image in the dataset so that neural networks learn relations between blur kernels and labels, as opposed to informative features for classifying clean data. In this work, we evaluate whether CUDA data remains unlearnable after image sharpening and frequency filtering, finding that this combination of simple transforms improves the utility of CUDA data for training. In particular, we observe a substantial increase in test accuracy over adversarial training for models trained with CUDA unlearnable data from CIFAR-10, CIFAR-100, and ImageNet-100. In training models to high accuracy using unlearnable data, we underscore the need for ongoing refinement in data poisoning techniques to ensure data privacy. Our method opens new avenues for enhancing the robustness of unlearnable datasets by highlighting that simple methods such as sharpening and frequency filtering are capable of breaking convolution-based unlearnable datasets.","authors":["Dohyun Kim","Pedro Sandoval-Segura"],"url":"https://arxiv.org/abs/2411.01742"}
{"created":"2025-05-09","title":"Imagining and building wise machines: The centrality of AI metacognition","abstract":"Although AI has become increasingly smart, its wisdom has not kept pace. In this article, we examine what is known about human wisdom and sketch a vision of its AI counterpart. We analyze human wisdom as a set of strategies for solving intractable problems-those outside the scope of analytic techniques-including both object-level strategies like heuristics [for managing problems] and metacognitive strategies like intellectual humility, perspective-taking, or context-adaptability [for managing object-level strategies]. We argue that AI systems particularly struggle with metacognition; improved metacognition would lead to AI more robust to novel environments, explainable to users, cooperative with others, and safer in risking fewer misaligned goals with human users. We discuss how wise AI might be benchmarked, trained, and implemented.","authors":["Samuel G. B. Johnson","Amir-Hossein Karimi","Yoshua Bengio","Nick Chater","Tobias Gerstenberg","Kate Larson","Sydney Levine","Melanie Mitchell","Iyad Rahwan","Bernhard Sch\\\"olkopf","Igor Grossmann"],"url":"https://arxiv.org/abs/2411.02478"}
{"created":"2025-05-09","title":"Mixture-of-Transformers: A Sparse and Scalable Architecture for Multi-Modal Foundation Models","abstract":"The development of large language models (LLMs) has expanded to multi-modal systems capable of processing text, images, and speech within a unified framework. Training these models demands significantly larger datasets and computational resources compared to text-only LLMs. To address the scaling challenges, we introduce Mixture-of-Transformers (MoT), a sparse multi-modal transformer architecture that significantly reduces pretraining computational costs. MoT decouples non-embedding parameters of the model by modality -- including feed-forward networks, attention matrices, and layer normalization -- enabling modality-specific processing with global self-attention over the full input sequence. We evaluate MoT across multiple settings and model scales. In the Chameleon 7B setting (autoregressive text-and-image generation), MoT matches the dense baseline's performance using only 55.8\\% of the FLOPs. When extended to include speech, MoT reaches speech performance comparable to the dense baseline with only 37.2\\% of the FLOPs. In the Transfusion setting, where text and image are trained with different objectives, a 7B MoT model matches the image modality performance of the dense baseline with one third of the FLOPs, and a 760M MoT model outperforms a 1.4B dense baseline across key image generation metrics. System profiling further highlights MoT's practical benefits, achieving dense baseline image quality in 47.2\\% of the wall-clock time and text quality in 75.6\\% of the wall-clock time (measured on AWS p4de.24xlarge instances with NVIDIA A100 GPUs).","authors":["Weixin Liang","Lili Yu","Liang Luo","Srinivasan Iyer","Ning Dong","Chunting Zhou","Gargi Ghosh","Mike Lewis","Wen-tau Yih","Luke Zettlemoyer","Xi Victoria Lin"],"url":"https://arxiv.org/abs/2411.04996"}
{"created":"2025-05-09","title":"LLM-Assisted Relevance Assessments: When Should We Ask LLMs for Help?","abstract":"Test collections are information retrieval tools that allow researchers to quickly and easily evaluate ranking algorithms. While test collections have become an integral part of IR research, the process of data creation involves significant effort in manual annotations, which often makes it very expensive and time-consuming. Thus, test collections could become too small when the budget is limited, which may lead to unstable evaluations. As a cheaper alternative, recent studies have proposed the use of large language models (LLMs) to completely replace human assessors. However, while LLMs seem to somewhat correlate with human judgments, their predictions are not perfect and often show bias. Thus a complete replacement with LLMs is argued to be too risky and not fully reliable. Thus, in this paper, we propose LLM-Assisted Relevance Assessments (LARA), an effective method to balance manual annotations with LLM annotations, which helps to build a rich and reliable test collection even under a low budget. We use the LLM's predicted relevance probabilities to select the most profitable documents to manually annotate under a budget constraint. With theoretical reasoning, LARA effectively guides the human annotation process by actively learning to calibrate the LLM's predicted relevance probabilities. Then, using the calibration model learned from the limited manual annotations, LARA debiases the LLM predictions to annotate the remaining non-assessed data. Empirical evaluations on TREC-7 Ad Hoc, TREC-8 Ad Hoc, TREC Robust 2004, and TREC-COVID datasets show that LARA outperforms alternative solutions under almost any budget constraint.","authors":["Rikiya Takehi","Ellen M. Voorhees","Tetsuya Sakai","Ian Soboroff"],"url":"https://arxiv.org/abs/2411.06877"}
{"created":"2025-05-09","title":"Rate of convergence for numerical $\\alpha$-dissipative solutions of the Hunter-Saxton equation","abstract":"We prove that $\\alpha$-dissipative solutions to the Cauchy problem of the Hunter-Saxton equation, where $\\alpha \\in W^{1, \\infty}(\\mathbb{R}, [0, 1))$, can be computed numerically with order $\\mathcal{O}(\\Delta x^{{1}/{8}}+\\Delta x^{{\\beta}/{4}})$ in $L^{\\infty}(\\mathbb{R})$, provided there exist constants $C > 0$ and $\\beta \\in (0, 1]$ such that the initial spatial derivative $\\bar{u}_{x}$ satisfies $\\|\\bar{u}_x(\\cdot + h) - \\bar{u}_x(\\cdot)\\|_2 \\leq Ch^{\\beta}$ for all $h \\in (0, 2]$. The derived convergence rate is exemplified by a number of numerical experiments.","authors":["Thomas Christiansen","Katrin Grunert"],"url":"https://arxiv.org/abs/2411.07712"}
{"created":"2025-05-09","title":"Zero-shot Object-Centric Instruction Following: Integrating Foundation Models with Traditional Navigation","abstract":"Large scale scenes such as multifloor homes can be robustly and efficiently mapped with a 3D graph of landmarks estimated jointly with robot poses in a factor graph, a technique commonly used in commercial robots such as drones and robot vacuums. In this work, we propose Language-Inferred Factor Graph for Instruction Following (LIFGIF), a zero-shot method to ground natural language instructions in such a map. LIFGIF also includes a policy for following natural language navigation instructions in a novel environment while the map is constructed, enabling robust navigation performance in the physical world. To evaluate LIFGIF, we present a new dataset, Object-Centric VLN (OC-VLN), in order to evaluate grounding of object-centric natural language navigation instructions. We compare to two state-of-the-art zero-shot baselines from related tasks, Object Goal Navigation and Vision Language Navigation, to demonstrate that LIFGIF outperforms them across all our evaluation metrics on OCVLN. Finally, we successfully demonstrate the effectiveness of LIFGIF for performing zero-shot object-centric instruction following in the real world on a Boston Dynamics Spot robot.","authors":["Sonia Raychaudhuri","Duy Ta","Katrina Ashton","Angel X. Chang","Jiuguang Wang","Bernadette Bucher"],"url":"https://arxiv.org/abs/2411.07848"}
{"created":"2025-05-09","title":"Anonymous Self-Stabilising Localisation via Spatial Population Protocols","abstract":"In the distributed localization problem (DLP), $n$ anonymous robots (agents) $a_0, a_1, ..., a_{n-1}$ begin at arbitrary positions $p_0, ..., p_{n-1}$ in $S$, where $S$ is an Euclidean space. The primary goal in DLP is for agents to reach a consensus on a unified coordinate system that accurately reflects the relative positions of all points, $p_0, ..., p_{n-1}$. Extensive research on DLP has primarily focused on the feasibility and complexity of achieving consensus when agents have limited access to inter-agent distances, often due to missing or imprecise data. In this paper, however, we examine a minimalist, computationally efficient model of distributed computing in which agents have access to all pairwise distances, if needed. Specifically, we introduce a novel variant of population protocols, referred to as the spatial population protocols model. In this variant each agent can memorise one or a fixed number of coordinates, and when agents $a_i$ and $a_j$ interact, they can not only exchange their current knowledge but also either determine the distance $d(i,j)$ between them in $S$ (distance query model) or obtain the vector $v(i,j)$ spanning points $p_i$ and $p_j$ (vector query model). We propose several localisation protocols, including: (1) Two leader-based protocols with distance queries, stabilizing silently in $o(n)$ time using an efficient multi-contact epidemic, a generalization of the one-way epidemic in population protocols; (2) A distance-based protocol self-stabilizing silently in $O(n(\\log n/n)^{1/(k+1)}\\log n)$ time in $k$-dimensions, leveraging a leader election mechanism; (3) An optimally fast protocol with vector queries, self-stabilizing silently in $O(\\log n)$ time.","authors":["Leszek G\\k{a}sieniec","{\\L}ukasz Kuszner","Ehsan Latif","Ramviyas Parasuraman","Paul Spirakis","Grzegorz Stachowiak"],"url":"https://arxiv.org/abs/2411.08434"}
{"created":"2025-05-09","title":"LUDO: Low-Latency Understanding of Deformable Objects using Point Cloud Occupancy Functions","abstract":"Accurately determining the shape of objects and the location of their internal structures within deformable objects is crucial for medical tasks that require precise targeting, such as robotic biopsies. We introduce LUDO, a method for accurate low-latency understanding of deformable objects. LUDO reconstructs objects in their deformed state, including their internal structures, from a single-view point cloud observation in under 30 ms using occupancy networks. LUDO provides uncertainty estimates for its predictions. Additionally, it provides explainability by highlighting key features in its input observations. Both uncertainty and explainability are important for safety-critical applications such as surgical interventions. We demonstrate LUDO's abilities for autonomous targeting of internal regions of interest (ROIs) in deformable objects. We evaluate LUDO in real-world robotic experiments, achieving a success rate of 98.9% for puncturing various ROIs inside deformable objects. LUDO demonstrates the potential to interact with deformable objects without the need for deformable registration methods.","authors":["Pit Henrich","Franziska Mathis-Ullrich","Paul Maria Scheikl"],"url":"https://arxiv.org/abs/2411.08777"}
{"created":"2025-05-09","title":"Quantifying Risk Propensities of Large Language Models: Ethical Focus and Bias Detection through Role-Play","abstract":"As Large Language Models (LLMs) become more prevalent, concerns about their safety, ethics, and potential biases have risen. Systematically evaluating LLMs' risk decision-making tendencies and attitudes, particularly in the ethical domain, has become crucial. This study innovatively applies the Domain-Specific Risk-Taking (DOSPERT) scale from cognitive science to LLMs and proposes a novel Ethical Decision-Making Risk Attitude Scale (EDRAS) to assess LLMs' ethical risk attitudes in depth. We further propose a novel approach integrating risk scales and role-playing to quantitatively evaluate systematic biases in LLMs. Through systematic evaluation and analysis of multiple mainstream LLMs, we assessed the \"risk personalities\" of LLMs across multiple domains, with a particular focus on the ethical domain, and revealed and quantified LLMs' systematic biases towards different groups. This research helps understand LLMs' risk decision-making and ensure their safe and reliable application. Our approach provides a tool for identifying and mitigating biases, contributing to fairer and more trustworthy AI systems. The code and data are available.","authors":["Yifan Zeng","Liang Kairong","Fangzhou Dong","Peijia Zheng"],"url":"https://arxiv.org/abs/2411.08884"}
{"created":"2025-05-09","title":"On-device Anomaly Detection in Conveyor Belt Operations","abstract":"Conveyor belts are crucial in mining operations by enabling the continuous and efficient movement of bulk materials over long distances, which directly impacts productivity. While detecting anomalies in specific conveyor belt components has been widely studied, identifying the root causes of these failures, such as changing production conditions and operator errors, remains critical. Continuous monitoring of mining conveyor belt work cycles is still at an early stage and requires robust solutions. Recently, an anomaly detection method for duty cycle operations of a mining conveyor belt has been proposed. Based on its limited performance and unevaluated long-term proper operation, this study proposes two novel methods for classifying normal and abnormal duty cycles. The proposed approaches are pattern recognition systems that make use of threshold-based duty-cycle detection mechanisms, manually extracted features, pattern-matching, and supervised tiny machine learning models. The explored low-computational models include decision tree, random forest, extra trees, extreme gradient boosting, Gaussian naive Bayes, and multi-layer perceptron. A comprehensive evaluation of the former and proposed approaches is carried out on two datasets. Both proposed methods outperform the former method, with the best-performing approach being dataset-dependent. The heuristic rule-based approach achieves the highest performance in the same dataset used for algorithm training, with 97.3% for normal cycles and 80.2% for abnormal cycles. The ML-based approach performs better on a dataset including the effects of machine aging, scoring 91.3% for normal cycles and 67.9% for abnormal cycles. Implemented on two low-power microcontrollers, the methods demonstrate efficient, real-time operation with energy consumption of 13.3 and 20.6 ${\\mu}$J during inference. These results offer valuable insights for detecting ...","authors":["Luciano S. Martinez-Rau","Yuxuan Zhang","Bengt Oelmann","Sebastian Bader"],"url":"https://arxiv.org/abs/2411.10729"}
{"created":"2025-05-09","title":"PhysFlow: Unleashing the Potential of Multi-modal Foundation Models and Video Diffusion for 4D Dynamic Physical Scene Simulation","abstract":"Realistic simulation of dynamic scenes requires accurately capturing diverse material properties and modeling complex object interactions grounded in physical principles. However, existing methods are constrained to basic material types with limited predictable parameters, making them insufficient to represent the complexity of real-world materials. We introduce PhysFlow, a novel approach that leverages multi-modal foundation models and video diffusion to achieve enhanced 4D dynamic scene simulation. Our method utilizes multi-modal models to identify material types and initialize material parameters through image queries, while simultaneously inferring 3D Gaussian splats for detailed scene representation. We further refine these material parameters using video diffusion with a differentiable Material Point Method (MPM) and optical flow guidance rather than render loss or Score Distillation Sampling (SDS) loss. This integrated framework enables accurate prediction and realistic simulation of dynamic interactions in real-world scenarios, advancing both accuracy and flexibility in physics-based simulations.","authors":["Zhuoman Liu","Weicai Ye","Yan Luximon","Pengfei Wan","Di Zhang"],"url":"https://arxiv.org/abs/2411.14423"}
{"created":"2025-05-09","title":"E-Trojans: Ransomware, Tracking, DoS, and Data Leaks on Battery-powered Embedded Systems","abstract":"Battery-powered embedded systems (BESs) have become ubiquitous. Their internals include a battery management system (BMS), a radio interface, and a motor controller. Despite their associated risk, there is little research on BES internal attack surfaces. To fill this gap, we present the first security and privacy assessment of e-scooters internals. We cover Xiaomi M365 (2016) and ES3 (2023) e-scooters and their interactions with Mi Home (their companion app).","authors":["Marco Casagrande","Riccardo Cestaro","Eleonora Losiouk","Mauro Conti","Daniele Antonioli"],"url":"https://arxiv.org/abs/2411.17184"}
{"created":"2025-05-09","title":"Neural Operators for Predictor Feedback Control of Nonlinear Delay Systems","abstract":"Predictor feedback designs are critical for delay-compensating controllers in nonlinear systems. However, these designs are limited in practical applications as predictors cannot be directly implemented, but require numerical approximation schemes, which become computationally prohibitive when system dynamics are expensive to compute. To address this challenge, we recast the predictor design as an operator learning problem, and learn the predictor mapping via a neural operator. We prove the existence of an arbitrarily accurate neural operator approximation of the predictor operator. Under the approximated predictor, we achieve semiglobal practical stability of the closed-loop nonlinear delay system. The estimate is semiglobal in a unique sense - one can enlarge the set of initial states as desired, though this increases the difficulty of training a neural operator, which appears practically in the stability estimate. Furthermore, our analysis holds for any black-box predictor satisfying the universal approximation error bound. We demonstrate the approach by controlling a 5-link robotic manipulator with different neural operator models, achieving significant speedups compared to classic predictor feedback schemes while maintaining closed-loop stability.","authors":["Luke Bhan","Peijia Qin","Miroslav Krstic","Yuanyuan Shi"],"url":"https://arxiv.org/abs/2411.18964"}
{"created":"2025-05-09","title":"Fixed-Relative-Switched Threshold Strategies for Consensus Tracking Control of Nonlinear Multiagent Systems","abstract":"This paper investigates event-triggered consensus tracking in nonlinear semi-strict-feedback multi-agent systems involving one leader and multiple followers. We first employ radial basis function neural networks and backstepping techniques to approximate the unknown nonlinear dynamics, facilitating the design of dual observers to measure the unknown states and disturbances. Then three adaptive event-triggered control schemes are proposed: fixed-threshold, relative-threshold, and switched-threshold configurations, each featuring specialized controller architectures and triggering mechanisms. Through Lyapunov stability analysis, we establish that the follower agents can asymptotically track the reference trajectory of the leader, meanwhile all error signals remain uniform bounded. Our proposed control strategies effectively prevent Zeno behaviors through stringent exclusion criteria. Finally, an illustrative example is presented, demonstrating the competitive performance of our control framework in achieving consensus tracking and optimizing triggering efficiency.","authors":["Ziming Wang","Yun Gao","Apostolos I. Rikos","Ning Pang","Yiding Ji"],"url":"https://arxiv.org/abs/2411.19571"}
{"created":"2025-05-09","title":"Explicit error bounds of the SE and DE formulas for integrals with logarithmic and algebraic singularity","abstract":"The single exponential (SE) and double exponential (DE) formulas are widely recognized as efficient quadrature formulas for evaluating integrals with endpoint singularity. For integrals exhibiting algebraic singularity, explicit error bounds in a computable form have been provided, enabling computations with guaranteed accuracy. Such explicit error bounds have also been provided for integrals exhibiting logarithmic singularity. However, these error bounds have two points to be discussed. The first point is on overestimation of divergence speed of logarithmic singularity. The second point is on the case where there exist both logarithmic and algebraic singularity. To address these issues, this study provides new error bounds for integrals with logarithmic and algebraic singularity. Although existing and new error bounds described above pertain to integrals over the finite interval, the SE and DE formulas are also applicable to integrals over the semi-infinite interval. On the basis of the new results, this study provides new error bounds for integrals over the semi-infinite interval with logarithmic and algebraic singularity at the origin.","authors":["Tomoaki Okayama","Kosei Arakawa","Ryo Kamigaki","Eita Yabumoto"],"url":"https://arxiv.org/abs/2411.19755"}
{"created":"2025-05-09","title":"Lazy Eye Inspection: Capturing the State of Happy Eyeballs Implementations","abstract":"Happy Eyeballs (HE) started out by describing a mechanism that prefers IPv6 connections while ensuring a fast fallback to IPv4 when IPv6 fails. The IETF is currently working on the third version of HE. While the standards include recommendations for HE parameters choices, it is up to the client and OS to implement HE. In this paper we investigate the state of HE in various clients, particularly web browsers and recursive resolvers. We introduce a framework to analyze and measure client's HE implementations and parameter choices. According to our evaluation, only Safari supports all HE features. Safari is also the only client implementation in our study that uses a dynamic IPv4 connection attempt delay, a resolution delay, and interlaces addresses. We further show that problems with the DNS A record lookup can even delay and interrupt the network connectivity despite a fully functional IPv6 setup with Chrome and Firefox. We publish our testbed measurement framework and a web-based tool to test HE properties on arbitrary browsers.","authors":["Patrick Sattler","Matthias Kirstein","Lars W\\\"ustrich","Johannes Zirngibl","Georg Carle"],"url":"https://arxiv.org/abs/2412.00263"}
{"created":"2025-05-09","title":"A Unified Data Representation Learning for Non-parametric Two-sample Testing","abstract":"Learning effective data representations has been crucial in non-parametric two-sample testing. Common approaches will first split data into training and test sets and then learn data representations purely on the training set. However, recent theoretical studies have shown that, as long as the sample indexes are not used during the learning process, the whole data can be used to learn data representations, meanwhile ensuring control of Type-I errors. The above fact motivates us to use the test set (but without sample indexes) to facilitate the data representation learning in the testing. To this end, we propose a representation-learning two-sample testing (RL-TST) framework. RL-TST first performs purely self-supervised representation learning on the entire dataset to capture inherent representations (IRs) that reflect the underlying data manifold. A discriminative model is then trained on these IRs to learn discriminative representations (DRs), enabling the framework to leverage both the rich structural information from IRs and the discriminative power of DRs. Extensive experiments demonstrate that RL-TST outperforms representative approaches by simultaneously using data manifold information in the test set and enhancing test power via finding the DRs with the training set.","authors":["Xunye Tian","Liuhua Peng","Zhijian Zhou","Mingming Gong","Arthur Gretton","Feng Liu"],"url":"https://arxiv.org/abs/2412.00613"}
{"created":"2025-05-09","title":"MambaNUT: Nighttime UAV Tracking via Mamba-based Adaptive Curriculum Learning","abstract":"Harnessing low-light enhancement and domain adaptation, nighttime UAV tracking has made substantial strides. However, over-reliance on image enhancement, limited high-quality nighttime data, and a lack of integration between daytime and nighttime trackers hinder the development of an end-to-end trainable framework. Additionally, current ViT-based trackers demand heavy computational resources due to their reliance on the self-attention mechanism. In this paper, we propose a novel pure Mamba-based tracking framework (MambaNUT) that employs a state space model with linear complexity as its backbone, incorporating a single-stream architecture that integrates feature learning and template-search coupling within Vision Mamba. We introduce an adaptive curriculum learning (ACL) approach that dynamically adjusts sampling strategies and loss weights, thereby improving the model's ability of generalization. Our ACL is composed of two levels of curriculum schedulers: (1) sampling scheduler that transforms the data distribution from imbalanced to balanced, as well as from easier (daytime) to harder (nighttime) samples; (2) loss scheduler that dynamically assigns weights based on the size of the training data and IoU of individual instances. Exhaustive experiments on multiple nighttime UAV tracking benchmarks demonstrate that the proposed MambaNUT achieves state-of-the-art performance while requiring lower computational costs. The code will be available at https://github.com/wuyou3474/MambaNUT.","authors":["You Wu","Xiangyang Yang","Xucheng Wang","Hengzhou Ye","Dan Zeng","Shuiwang Li"],"url":"https://arxiv.org/abs/2412.00626"}
{"created":"2025-05-09","title":"Expanding Event Modality Applications through a Robust CLIP-Based Encoder","abstract":"This paper introduces a powerful encoder that transfers CLIP`s capabilities to event-based data, enhancing its utility and expanding its applicability across diverse domains. While large-scale datasets have significantly advanced image-based models, the scarcity of comprehensive event datasets has limited performance potential in event modality. To address this challenge, we adapt CLIP`s architecture to align event embeddings with image embeddings, supporting zero-shot learning and preserving text alignment while mitigating catastrophic forgetting. Our encoder achieves strong performance in object recognition, with competitive results in zero-shot and few-shot learning tasks. Notably, it generalizes effectively to events extracted from video data without requiring additional training, highlighting its versatility. Additionally, we integrate this encoder within a cross-modality framework that facilitates interaction across five modalities-Image, Event, Text, Sound, and Depth-expanding the possibilities for cross-modal applications. Overall, this work underscores the transformative potential of a robust event encoder, broadening the scope and utility of event-based data across various fields.","authors":["Sungheon Jeong","Hanning Chen","Sanggeon Yun","Suhyeon Cho","Wenjun Huang","Xiangjian Liu","Mohsen Imani"],"url":"https://arxiv.org/abs/2412.03093"}
{"created":"2025-05-09","title":"3DSRBench: A Comprehensive 3D Spatial Reasoning Benchmark","abstract":"3D spatial reasoning is the ability to analyze and interpret the positions, orientations, and spatial relationships of objects within the 3D space. This allows models to develop a comprehensive understanding of the 3D scene, enabling their applicability to a broader range of areas, such as autonomous navigation, robotics, and AR/VR. While large multi-modal models (LMMs) have achieved remarkable progress in a wide range of image and video understanding tasks, their capabilities to perform 3D spatial reasoning on diverse natural images are less studied. In this work we present the first comprehensive 3D spatial reasoning benchmark, 3DSRBench, with 2,772 manually annotated visual question-answer pairs across 12 question types. We conduct robust and thorough evaluation of 3D spatial reasoning capabilities by balancing the data distribution and adopting a novel FlipEval strategy. To further study the robustness of 3D spatial reasoning w.r.t. camera 3D viewpoints, our 3DSRBench includes two subsets with 3D spatial reasoning questions on paired images with common and uncommon viewpoints. We benchmark a wide range of open-sourced and proprietary LMMs, uncovering their limitations in various aspects of 3D awareness, such as height, orientation, location, and multi-object reasoning, as well as their degraded performance on images with uncommon camera viewpoints. Our 3DSRBench provide valuable findings and insights about the future development of LMMs with strong 3D reasoning capabilities. Our project page and dataset is available https://3dsrbench.github.io.","authors":["Wufei Ma","Haoyu Chen","Guofeng Zhang","Yu-Cheng Chou","Celso M de Melo","Alan Yuille"],"url":"https://arxiv.org/abs/2412.07825"}
{"created":"2025-05-09","title":"ECSeptional DNS Data: Evaluating Nameserver ECS Deployments with Response-Aware Scanning","abstract":"DNS is one of the cornerstones of the Internet. Nowadays, a substantial fraction of DNS queries are handled by public resolvers (e.g., Google Public DNS and Cisco's OpenDNS) rather than ISP nameservers. This behavior makes it difficult for authoritative nameservers to provide answers based on the requesting resolver. The impact is especially important for entities that make client origin inferences to perform DNS-based load balancing (e.g., CDNS). The EDNS0 Client Subnet (ECS) option adds the client's IP prefix to DNS queries, which allows authoritative nameservers to provide prefix-based responses. In this study, we introduce a new method for conducting ECS scans, which provides insights into ECS behavior and significantly reduces the required number of queries by up to 97% compared to state-of-the-art techniques. Our approach is also the first to facilitate ECS scans for IPv6. We conduct a comprehensive evaluation of the ECS landscape, examining the usage and implementation of ECS across various services. Overall, 53% of all nameservers support prefix-based responses. Furthermore, we find that Google nameservers do not comply with the Google Public DNS guidelines. Lastly, we plan to make our tool, and data publicly available to foster further research in the area.","authors":["Patrick Sattler","Johannes Zirngibl","Fahad Hilal","Oliver Gasser","Kevin Vermeulen","Georg Carle","Mattijs Jonker"],"url":"https://arxiv.org/abs/2412.08478"}
{"created":"2025-05-09","title":"Vision Transformers for Efficient Indoor Pathloss Radio Map Prediction","abstract":"Indoor pathloss prediction is a fundamental task in wireless network planning, yet it remains challenging due to environmental complexity and data scarcity. In this work, we propose a deep learning-based approach utilizing a vision transformer (ViT) architecture with DINO-v2 pretrained weights to model indoor radio propagation. Our method processes a floor map with additional features of the walls to generate indoor pathloss maps. We systematically evaluate the effects of architectural choices, data augmentation strategies, and feature engineering techniques. Our findings indicate that extensive augmentation significantly improves generalization, while feature engineering is crucial in low-data regimes. Through comprehensive experiments, we demonstrate the robustness of our model across different generalization scenarios.","authors":["Rafayel Mkrtchyan","Edvard Ghukasyan","Khoren Petrosyan","Hrant Khachatrian","Theofanis P. Raptis"],"url":"https://arxiv.org/abs/2412.09507"}
{"created":"2025-05-09","title":"Contiguous Boundary Guarding","abstract":"We study the problem of guarding the boundary of a simple polygon with a minimum number of guards such that each guard covers a contiguous portion of the boundary. First, we present a simple greedy algorithm for this problem that returns a guard set of size at most OPT + 1, where OPT is the number of guards in an optimal solution. Then, we present a polynomial-time exact algorithm. While the algorithm is not complicated, its correctness proof is rather involved. This result is interesting in the sense that guarding problems are typically NP-hard and, in particular, it is NP-hard to minimize the number of guards to see the boundary of a simple polygon, without the contiguous boundary guarding constraint.","authors":["Ahmad Biniaz","Anil Maheshwari","Joseph S. B. Mitchell","Saeed Odak","Valentin Polishchuk","Thomas Shermer"],"url":"https://arxiv.org/abs/2412.15053"}
{"created":"2025-05-09","title":"Graph Attention is Not Always Beneficial: A Theoretical Analysis of Graph Attention Mechanisms via Contextual Stochastic Block Models","abstract":"Despite the growing popularity of graph attention mechanisms, their theoretical understanding remains limited. This paper aims to explore the conditions under which these mechanisms are effective in node classification tasks through the lens of Contextual Stochastic Block Models (CSBMs). Our theoretical analysis reveals that incorporating graph attention mechanisms is \\emph{not universally beneficial}. Specifically, by appropriately defining \\emph{structure noise} and \\emph{feature noise} in graphs, we show that graph attention mechanisms can enhance classification performance when structure noise exceeds feature noise. Conversely, when feature noise predominates, simpler graph convolution operations are more effective. Furthermore, we examine the over-smoothing phenomenon and show that, in the high signal-to-noise ratio (SNR) regime, graph convolutional networks suffer from over-smoothing, whereas graph attention mechanisms can effectively resolve this issue. Building on these insights, we propose a novel multi-layer Graph Attention Network (GAT) architecture that significantly outperforms single-layer GATs in achieving \\emph{perfect node classification} in CSBMs, relaxing the SNR requirement from $ \\omega(\\sqrt{\\log n}) $ to $ \\omega(\\sqrt{\\log n} / \\sqrt[3]{n}) $. To our knowledge, this is the first study to delineate the conditions for perfect node classification using multi-layer GATs. Our theoretical contributions are corroborated by extensive experiments on both synthetic and real-world datasets, highlighting the practical implications of our findings.","authors":["Zhongtian Ma","Qiaosheng Zhang","Bocheng Zhou","Yexin Zhang","Shuyue Hu","Zhen Wang"],"url":"https://arxiv.org/abs/2412.15496"}
{"created":"2025-05-09","title":"Interact with me: Joint Egocentric Forecasting of Intent to Interact, Attitude and Social Actions","abstract":"For efficient human-agent interaction, an agent should proactively recognize their target user and prepare for upcoming interactions. We formulate this challenging problem as the novel task of jointly forecasting a person's intent to interact with the agent, their attitude towards the agent and the action they will perform, from the agent's (egocentric) perspective. So we propose \\emph{SocialEgoNet} - a graph-based spatiotemporal framework that exploits task dependencies through a hierarchical multitask learning approach. SocialEgoNet uses whole-body skeletons (keypoints from face, hands and body) extracted from only 1 second of video input for high inference speed. For evaluation, we augment an existing egocentric human-agent interaction dataset with new class labels and bounding box annotations. Extensive experiments on this augmented dataset, named JPL-Social, demonstrate \\emph{real-time} inference and superior performance (average accuracy across all tasks: 83.15\\%) of our model outperforming several competitive baselines. The additional annotations and code will be available upon acceptance.","authors":["Tongfei Bian","Yiming Ma","Mathieu Chollet","Victor Sanchez","Tanaya Guha"],"url":"https://arxiv.org/abs/2412.16698"}
{"created":"2025-05-09","title":"Balanced 3DGS: Gaussian-wise Parallelism Rendering with Fine-Grained Tiling","abstract":"3D Gaussian Splatting (3DGS) is increasingly attracting attention in both academia and industry owing to its superior visual quality and rendering speed. However, training a 3DGS model remains a time-intensive task, especially in load imbalance scenarios where workload diversity among pixels and Gaussian spheres causes poor renderCUDA kernel performance. We introduce Balanced 3DGS, a Gaussian-wise parallelism rendering with fine-grained tiling approach in 3DGS training process, perfectly solving load-imbalance issues. First, we innovatively introduce the inter-block dynamic workload distribution technique to map workloads to Streaming Multiprocessor(SM) resources within a single GPU dynamically, which constitutes the foundation of load balancing. Second, we are the first to propose the Gaussian-wise parallel rendering technique to significantly reduce workload divergence inside a warp, which serves as a critical component in addressing load imbalance. Based on the above two methods, we further creatively put forward the fine-grained combined load balancing technique to uniformly distribute workload across all SMs, which boosts the forward renderCUDA kernel performance by up to 7.52x. Besides, we present a self-adaptive render kernel selection strategy during the 3DGS training process based on different load-balance situations, which effectively improves training efficiency.","authors":["Hao Gui","Lin Hu","Rui Chen","Mingxiao Huang","Yuxin Yin","Jin Yang","Yong Wu","Chen Liu","Zhongxu Sun","Xueyang Zhang","Kun Zhan"],"url":"https://arxiv.org/abs/2412.17378"}
{"created":"2025-05-09","title":"Adaptive Rate Control for Deep Video Compression with Rate-Distortion Prediction","abstract":"Deep video compression has made significant progress in recent years, achieving rate-distortion performance that surpasses that of traditional video compression methods. However, rate control schemes tailored for deep video compression have not been well studied. In this paper, we propose a neural network-based $\\lambda$-domain rate control scheme for deep video compression, which determines the coding parameter $\\lambda$ for each to-be-coded frame based on the rate-distortion-$\\lambda$ (R-D-$\\lambda$) relationships directly learned from uncompressed frames, achieving high rate control accuracy efficiently without the need for pre-encoding. Moreover, this content-aware scheme is able to mitigate inter-frame quality fluctuations and adapt to abrupt changes in video content. Specifically, we introduce two neural network-based predictors to estimate the relationship between bitrate and $\\lambda$, as well as the relationship between distortion and $\\lambda$ for each frame. Then we determine the coding parameter $\\lambda$ for each frame to achieve the target bitrate. Experimental results demonstrate that our approach achieves high rate control accuracy at the mini-GOP level with low time overhead and mitigates inter-frame quality fluctuations across video content of varying resolutions.","authors":["Bowen Gu","Hao Chen","Ming Lu","Jie Yao","Zhan Ma"],"url":"https://arxiv.org/abs/2412.18834"}
{"created":"2025-05-09","title":"LUSIFER: Language Universal Space Integration for Enhanced Multilingual Embeddings with Large Language Models","abstract":"Recent advancements in large language models (LLMs) based embedding models have established new state-of-the-art benchmarks for text embedding tasks, particularly in dense vector-based retrieval. However, these models predominantly focus on English, leaving multilingual embedding capabilities largely unexplored. To address this limitation, we present LUSIFER, a novel zero-shot approach that adapts LLM-based embedding models for multilingual tasks without requiring multilingual supervision. LUSIFER's architecture combines a multilingual encoder, serving as a language-universal learner, with an LLM-based embedding model optimized for embedding-specific tasks. These components are seamlessly integrated through a minimal set of trainable parameters that act as a connector, effectively transferring the multilingual encoder's language understanding capabilities to the specialized embedding model. Additionally, to comprehensively evaluate multilingual embedding performance, we introduce a new benchmark encompassing 5 primary embedding tasks, 123 diverse datasets, and coverage across 14 languages. Extensive experimental results demonstrate that LUSIFER significantly enhances the multilingual performance across various embedding tasks, particularly for medium and low-resource languages, without requiring explicit multilingual training data.","authors":["Hieu Man","Nghia Trung Ngo","Viet Dac Lai","Ryan A. Rossi","Franck Dernoncourt","Thien Huu Nguyen"],"url":"https://arxiv.org/abs/2501.00874"}
{"created":"2025-05-09","title":"ValuesRAG: Enhancing Cultural Alignment Through Retrieval-Augmented Contextual Learning","abstract":"Ensuring cultural values alignment in Large Language Models (LLMs) remains a critical challenge, as these models often embed Western-centric biases from their training data, leading to misrepresentations and fairness concerns in cross-cultural applications. Existing approaches such as role assignment and few-shot learning struggle to address these limitations effectively due to their reliance on pre-trained knowledge, limited scalability, and inability to capture nuanced cultural values. To address these issues, we propose ValuesRAG, a novel and effective framework that applies Retrieval-Augmented Generation (RAG) with In-Context Learning (ICL) to integrate cultural and demographic knowledge dynamically during text generation. Leveraging the World Values Survey (WVS) dataset, ValuesRAG first generates summaries of values for each individual. We subsequently curate several representative regional datasets to serve as test datasets and retrieve relevant summaries of values based on demographic features, followed by a reranking step to select the top-k relevant summaries. We evaluate ValuesRAG using 6 diverse regional datasets and show that it consistently outperforms baselines: including zero-shot, role-assignment, few-shot, and hybrid methods, both in main experiments and ablation settings. Notably, ValuesRAG achieves the best overall performance over prior methods, demonstrating its effectiveness in fostering culturally aligned and inclusive AI systems. Our findings underscore the potential of dynamic retrieval-based methods to bridge the gap between global LLM capabilities and localized cultural values.","authors":["Wonduk Seo","Zonghao Yuan","Yi Bu"],"url":"https://arxiv.org/abs/2501.01031"}
{"created":"2025-05-09","title":"Quaternionic Reweighted Amplitude Flow for Phase Retrieval in Image Reconstruction","abstract":"Quaternionic signal processing provides powerful tools for efficiently managing color signals by preserving the intrinsic correlations among signal dimensions through quaternion algebra. In this paper, we address the quaternionic phase retrieval problem by systematically developing novel algorithms based on an amplitude-based model. Specifically, we propose the Quaternionic Reweighted Amplitude Flow (QRAF) algorithm, which is further enhanced by three of its variants: incremental, accelerated, and adapted QRAF algorithms. In addition, we introduce the Quaternionic Perturbed Amplitude Flow (QPAF) algorithm, which has linear convergence. Extensive numerical experiments on both synthetic data and real images, demonstrate that our proposed methods significantly improve recovery performance and computational efficiency compared to state-of-the-art approaches.","authors":["Ren Hu","Pan Lian"],"url":"https://arxiv.org/abs/2501.02180"}
{"created":"2025-05-09","title":"The Geodesic Fr\\'echet Distance Between Two Curves Bounding a Simple Polygon","abstract":"The Fr\\'echet distance is a popular similarity measure that is well-understood for polygonal curves in $\\mathbb{R}^d$: near-quadratic time algorithms exist, and conditional lower bounds suggest that these results cannot be improved significantly, even in one dimension and when approximating with a factor less than three. We consider the special case where the curves bound a simple polygon and distances are measured via geodesics inside this simple polygon. Here the conditional lower bounds do not apply; Efrat $et$ $al.$ (2002) were able to give a near-linear time $2$-approximation algorithm.","authors":["Thijs van der Horst","Marc van Kreveld","Tim Ophelders","Bettina Speckmann"],"url":"https://arxiv.org/abs/2501.03834"}
{"created":"2025-05-09","title":"A Direct-adjoint Approach for Material Point Model Calibration with Application to Plasticity","abstract":"This paper proposes a new approach for the calibration of material parameters in local elastoplastic constitutive models. The calibration is posed as a constrained optimization problem, where the constitutive model evolution equations for a single material point serve as constraints. The objective function quantifies the mismatch between the stress predicted by the model and corresponding experimental measurements. To improve calibration efficiency, a novel direct-adjoint approach is presented to compute the Hessian of the objective function, which enables the use of second-order optimization algorithms. Automatic differentiation is used for gradient and Hessian computations. Two numerical examples are employed to validate the Hessian matrices and to demonstrate that the Newton-Raphson algorithm consistently outperforms gradient-based algorithms such as L-BFGS-B.","authors":["Ryan Yan","D. Thomas Seidl","Reese E. Jones","Panayiotis Papadopoulos"],"url":"https://arxiv.org/abs/2501.04584"}
{"created":"2025-05-09","title":"FrontierNet: Learning Visual Cues to Explore","abstract":"Exploration of unknown environments is crucial for autonomous robots; it allows them to actively reason and decide on what new data to acquire for different tasks, such as mapping, object discovery, and environmental assessment. Existing solutions, such as frontier-based exploration approaches, rely heavily on 3D map operations, which are limited by map quality and, more critically, often overlook valuable context from visual cues. This work aims at leveraging 2D visual cues for efficient autonomous exploration, addressing the limitations of extracting goal poses from a 3D map. We propose a visual-only frontier-based exploration system, with FrontierNet as its core component. FrontierNet is a learning-based model that (i) proposes frontiers, and (ii) predicts their information gain, from posed RGB images enhanced by monocular depth priors. Our approach provides an alternative to existing 3D-dependent goal-extraction approaches, achieving a 15\\% improvement in early-stage exploration efficiency, as validated through extensive simulations and real-world experiments. The project is available at https://github.com/cvg/FrontierNet.","authors":["Boyang Sun","Hanzhi Chen","Stefan Leutenegger","Cesar Cadena","Marc Pollefeys","Hermann Blum"],"url":"https://arxiv.org/abs/2501.04597"}
{"created":"2025-05-09","title":"Algorithms of very high space-time orders of accuracy for hyperbolic equations in the semidiscrete WENO-DeC framework","abstract":"In this work, we provide a deep investigation of a family of arbitrary high order numerical methods for hyperbolic partial differential equations (PDEs), with particular emphasis on very high order versions, i.e., with order higher than 5. More in detail, within the context of a generic Finite Volume (FV) semidiscretization, we consider Weighted Essentially Non--Oscillatory (WENO) spatial reconstruction and Deferred Correction (DeC) time discretization. The goal of this paper is twofold. On the one hand, we want to demonstrate the possibility of utilizing very high order schemes in concrete situations and highlight the related advantages. On the other one, we want to debunk the myth according to which, in the context of numerical resolution of hyperbolic PDEs with very high order spatial discretizations, the adoption of lower order time discretizations, e.g., strong stability preserving (SSP) or linearly strong stability preserving ($\\ell SSP$) Runge--Kutta (RK) schemes, does not affect the overall accuracy of the resulting approach and consequently its computational efficiency. Numerical results are reported for the linear advection equation (LAE) and for the Euler equations of fluid dynamics, showing the advantages and the critical aspects of the adoption of very high order numerical methods. Overall, the results indicate the potential for their use in real--life applications, offering advantages in terms of efficiency, such as requiring shorter computational times to achieve a prescribed error, even in problems involving discontinuities. Furthermore, the results confirm order degradation and efficiency loss when coupling very high order space discretizations with lower order SSPRK time discretizations.","authors":["Lorenzo Micalizzi","Eleuterio F. Toro"],"url":"https://arxiv.org/abs/2501.12994"}
{"created":"2025-05-09","title":"Guaranteed Recovery of Unambiguous Clusters","abstract":"Clustering is often a challenging problem because of the inherent ambiguity in what the \"correct\" clustering should be. Even when the number of clusters $K$ is known, this ambiguity often still exists, particularly when there is variation in density among different clusters, and clusters have multiple relatively separated regions of high density. In this paper we propose an information-theoretic characterization of when a $K$-clustering is ambiguous, and design an algorithm that recovers the clustering whenever it is unambiguous. This characterization formalizes the situation when two high density regions within a cluster are separable enough that they look more like two distinct clusters than two truly distinct clusters in the $K$-clustering. The algorithm first identifies $K$ partial clusters (or \"seeds\") using a density-based approach, and then adds unclustered points to the initial $K$ partial clusters in a greedy manner to form a complete clustering. We implement and test a version of the algorithm that is modified to effectively handle overlapping clusters, and observe that it requires little parameter selection and displays improved performance on many datasets compared to widely used algorithms for non-convex cluster recovery.","authors":["Kayvon Mazooji","Ilan Shomorony"],"url":"https://arxiv.org/abs/2501.13093"}
{"created":"2025-05-09","title":"Communicating Activations Between Language Model Agents","abstract":"Communication between multiple language model (LM) agents has been shown to scale up the reasoning ability of LMs. While natural language has been the dominant medium for inter-LM communication, it is not obvious this should be the standard: not only does natural language communication incur high inference costs that scale quickly with the number of both agents and messages, but also the decoding process abstracts away too much rich information that could be otherwise accessed from the internal activations. In this work, we propose a simple technique whereby LMs communicate via activations; concretely, we pause an LM $\\textit{B}$'s computation at an intermediate layer, combine its current activation with another LM $\\textit{A}$'s intermediate activation via some function $\\textit{f}$, then pass $\\textit{f}$'s output into the next layer of $\\textit{B}$ and continue the forward pass till decoding is complete. This approach scales up LMs on new tasks with zero additional parameters and data, and saves a substantial amount of compute over natural language communication. We test our method with various functional forms $\\textit{f}$ on two experimental setups--multi-player coordination games and reasoning benchmarks--and find that it achieves up to $27.0\\%$ improvement over natural language communication across datasets with $<$$1/4$ the compute, illustrating the superiority and robustness of activations as an alternative \"language\" for communication between LMs.","authors":["Vignav Ramesh","Kenneth Li"],"url":"https://arxiv.org/abs/2501.14082"}
{"created":"2025-05-09","title":"Applications of Artificial Intelligence for Cross-language Intelligibility Assessment of Dysarthric Speech","abstract":"Purpose: Speech intelligibility is a critical outcome in the assessment and management of dysarthria, yet most research and clinical practices have focused on English, limiting their applicability across languages. This commentary introduces a conceptual framework--and a demonstration of how it can be implemented--leveraging artificial intelligence (AI) to advance cross-language intelligibility assessment of dysarthric speech. Method: We propose a two-tiered conceptual framework consisting of a universal speech model that encodes dysarthric speech into acoustic-phonetic representations, followed by a language-specific intelligibility assessment model that interprets these representations within the phonological or prosodic structures of the target language. We further identify barriers to cross-language intelligibility assessment of dysarthric speech, including data scarcity, annotation complexity, and limited linguistic insights into dysarthric speech, and outline potential AI-driven solutions to overcome these challenges. Conclusion: Advancing cross-language intelligibility assessment of dysarthric speech necessitates models that are both efficient and scalable, yet constrained by linguistic rules to ensure accurate and language-sensitive assessment. Recent advances in AI provide the foundational tools to support this integration, shaping future directions toward generalizable and linguistically informed assessment frameworks.","authors":["Eunjung Yeo","Julie Liss","Visar Berisha","David Mortensen"],"url":"https://arxiv.org/abs/2501.15858"}
{"created":"2025-05-09","title":"The Right to AI","abstract":"This paper proposes a Right to AI, which asserts that individuals and communities should meaningfully participate in the development and governance of the AI systems that shape their lives. Motivated by the increasing deployment of AI in critical domains and inspired by Henri Lefebvre's concept of the Right to the City, we reconceptualize AI as a societal infrastructure, rather than merely a product of expert design. In this paper, we critically evaluate how generative agents, large-scale data extraction, and diverse cultural values bring new complexities to AI oversight. The paper proposes that grassroots participatory methodologies can mitigate biased outcomes and enhance social responsiveness. It asserts that data is socially produced and should be managed and owned collectively. Drawing on Sherry Arnstein's Ladder of Citizen Participation and analyzing nine case studies, the paper develops a four-tier model for the Right to AI that situates the current paradigm and envisions an aspirational future. It proposes recommendations for inclusive data ownership, transparent design processes, and stakeholder-driven oversight. We also discuss market-led and state-centric alternatives and argue that participatory approaches offer a better balance between technical efficiency and democratic legitimacy.","authors":["Rashid Mushkani","Hugo Berard","Allison Cohen","Shin Koeski"],"url":"https://arxiv.org/abs/2501.17899"}
{"created":"2025-05-09","title":"Towards the Worst-case Robustness of Large Language Models","abstract":"Recent studies have revealed the vulnerability of large language models to adversarial attacks, where adversaries craft specific input sequences to induce harmful, violent, private, or incorrect outputs. In this work, we study their worst-case robustness, i.e., whether an adversarial example exists that leads to such undesirable outputs. We upper bound the worst-case robustness using stronger white-box attacks, indicating that most current deterministic defenses achieve nearly 0\\% worst-case robustness. We propose a general tight lower bound for randomized smoothing using fractional knapsack solvers or 0-1 knapsack solvers, and using them to bound the worst-case robustness of all stochastic defenses. Based on these solvers, we provide theoretical lower bounds for several previous empirical defenses. For example, we certify the robustness of a specific case, smoothing using a uniform kernel, against \\textit{any possible attack} with an average $\\ell_0$ perturbation of 2.02 or an average suffix length of 6.41.","authors":["Huanran Chen","Yinpeng Dong","Zeming Wei","Hang Su","Jun Zhu"],"url":"https://arxiv.org/abs/2501.19040"}
{"created":"2025-05-09","title":"Genetic AI: Evolutionary Games for ab initio dynamic Multi-Objective Optimization","abstract":"We introduce Genetic AI, a novel method for multi-objective optimization without external parameters or predefined weights. The method can be applied to all problems that can be formulated in matrix form and allows for a data-less training of AI models. Without employing predefined rules or training data, Genetic AI first converts the input data into genes and organisms. In a simulation from first principles, these genes and organisms compete for fitness, where their behavior is governed by universal evolutionary strategies. We present four evolutionary strategies: Dominant, Altruistic, Balanced and Selfish and show how a linear combination can be employed in a fully self-consistent evolutionary game. Investigating fitness and evolutionary stable equilibriums, Genetic AI helps solving optimization problems with a set of predefined, discrete solutions that change dynamically. We show the universality of the approach on two decision problems.","authors":["Philipp Wissgott"],"url":"https://arxiv.org/abs/2501.19113"}
{"created":"2025-05-09","title":"Toward Task Generalization via Memory Augmentation in Meta-Reinforcement Learning","abstract":"Agents trained via reinforcement learning (RL) often struggle to perform well on tasks that differ from those encountered during training. This limitation presents a challenge to the broader deployment of RL in diverse and dynamic task settings. In this work, we introduce memory augmentation, a memory-based RL approach to improve task generalization. Our approach leverages task-structured augmentations to simulate plausible out-of-distribution scenarios and incorporates memory mechanisms to enable context-aware policy adaptation. Trained on a predefined set of tasks, our policy demonstrates the ability to generalize to unseen tasks through memory augmentation without requiring additional interactions with the environment. Through extensive simulation experiments and real-world hardware evaluations on legged locomotion tasks, we demonstrate that our approach achieves zero-shot generalization to unseen tasks while maintaining robust in-distribution performance and high sample efficiency.","authors":["Kaixi Bao","Chenhao Li","Yarden As","Andreas Krause","Marco Hutter"],"url":"https://arxiv.org/abs/2502.01521"}
{"created":"2025-05-09","title":"Texture Image Synthesis Using Spatial GAN Based on Vision Transformers","abstract":"Texture synthesis is a fundamental task in computer vision, whose goal is to generate visually realistic and structurally coherent textures for a wide range of applications, from graphics to scientific simulations. While traditional methods like tiling and patch-based techniques often struggle with complex textures, recent advancements in deep learning have transformed this field. In this paper, we propose ViT-SGAN, a new hybrid model that fuses Vision Transformers (ViTs) with a Spatial Generative Adversarial Network (SGAN) to address the limitations of previous methods. By incorporating specialized texture descriptors such as mean-variance (mu, sigma) and textons into the self-attention mechanism of ViTs, our model achieves superior texture synthesis. This approach enhances the model's capacity to capture complex spatial dependencies, leading to improved texture quality that is superior to state-of-the-art models, especially for regular and irregular textures. Comparison experiments with metrics such as FID, IS, SSIM, and LPIPS demonstrate the substantial improvement of ViT-SGAN, which underlines its efficiency in generating diverse realistic textures.","authors":["Elahe Salari","Zohreh Azimifar"],"url":"https://arxiv.org/abs/2502.01842"}
{"created":"2025-05-09","title":"Generating Symbolic World Models via Test-time Scaling of Large Language Models","abstract":"Solving complex planning problems requires Large Language Models (LLMs) to explicitly model the state transition to avoid rule violations, comply with constraints, and ensure optimality-a task hindered by the inherent ambiguity of natural language. To overcome such ambiguity, Planning Domain Definition Language (PDDL) is leveraged as a planning abstraction that enables precise and formal state descriptions. With PDDL, we can generate a symbolic world model where classic searching algorithms, such as A*, can be seamlessly applied to find optimal plans. However, directly generating PDDL domains with current LLMs remains an open challenge due to the lack of PDDL training data. To address this challenge, we propose to scale up the test-time computation of LLMs to enhance their PDDL reasoning capabilities, thereby enabling the generation of high-quality PDDL domains. Specifically, we introduce a simple yet effective algorithm, which first employs a Best-of-N sampling approach to improve the quality of the initial solution and then refines the solution in a fine-grained manner with verbalized machine learning. Our method outperforms o1-mini by a considerable margin in the generation of PDDL domains, achieving over 50\\% success rate on two tasks (i.e., generating PDDL domains from natural language description or PDDL problems). This is done without requiring additional training. By taking advantage of PDDL as state abstraction, our method is able to outperform current state-of-the-art methods on almost all competition-level planning tasks.","authors":["Zhouliang Yu","Yuhuan Yuan","Tim Z. Xiao","Fuxiang Frank Xia","Jie Fu","Ge Zhang","Ge Lin","Weiyang Liu"],"url":"https://arxiv.org/abs/2502.04728"}
{"created":"2025-05-09","title":"Recursive Inference Scaling: A Winning Path to Scalable Inference in Language and Multimodal Systems","abstract":"Inspired by recent findings on the fractal geometry of language, we introduce Recursive INference Scaling (RINS) as a complementary, plug-in recipe for scaling inference time in language and multimodal systems. RINS is a particular form of recursive depth that significantly outperforms +55 other variants, including the recent \"repeat-all-over\" (RAO) strategy in Mobile LLM (Liu et al., 2024) and latent recurrent thinking (Geiping et al., 2025). Unlike prior works, we carry out our comparisons on a compute-matched regime, and demonstrate that for a fixed model size and training compute budget, RINS substantially improves language modeling performance. It also generalizes beyond pure language tasks, delivering gains in multimodal systems, including a +2% improvement in 0-shot ImageNet accuracy for SigLIP-B/16. Additionally, by deriving data scaling laws, we show that RINS improves both the asymptotic performance limits and the scaling exponents. More importantly, with light-weight (linear) adapters (comprising <1% of model parameters) and stochastic dropout, RINS offers a no-regret strategy, meaning that RINS-enabled pretraining improves performance in language modeling even when recursive depth is not applied at inference time. This corresponds to improving performance on a training compute-, parameter-, and inference-matched regime, suggesting its potential as a viable component of LLM pretraining!","authors":["Ibrahim Alabdulmohsin","Xiaohua Zhai"],"url":"https://arxiv.org/abs/2502.07503"}
{"created":"2025-05-09","title":"Deployment-friendly Lane-changing Intention Prediction Powered by Brain-inspired Spiking Neural Networks","abstract":"Accurate and real-time prediction of surrounding vehicles' lane-changing intentions is a critical challenge in deploying safe and efficient autonomous driving systems in open-world scenarios. Existing high-performing methods remain hard to deploy due to their high computational cost, long training times, and excessive memory requirements. Here, we propose an efficient lane-changing intention prediction approach based on brain-inspired Spiking Neural Networks (SNN). By leveraging the event-driven nature of SNN, the proposed approach enables us to encode the vehicle's states in a more efficient manner. Comparison experiments conducted on HighD and NGSIM datasets demonstrate that our method significantly improves training efficiency and reduces deployment costs while maintaining comparable prediction accuracy. Particularly, compared to the baseline, our approach reduces training time by 75% and memory usage by 99.9%. These results validate the efficiency and reliability of our method in lane-changing predictions, highlighting its potential for safe and efficient autonomous driving systems while offering significant advantages in deployment, including reduced training time, lower memory usage, and faster inference.","authors":["Shuqi Shen","Junjie Yang","Hui Zhong","Hongliang Lu","Xinhu Zheng","Hai Yang"],"url":"https://arxiv.org/abs/2502.08659"}
{"created":"2025-05-09","title":"DejAIvu: Identifying and Explaining AI Art on the Web in Real-Time with Saliency Maps","abstract":"The recent surge in advanced generative models, such as diffusion models and generative adversarial networks (GANs), has led to an alarming rise in AI-generated images across various domains on the web. While such technologies offer benefits such as democratizing artistic creation, they also pose challenges in misinformation, digital forgery, and authenticity verification. Additionally, the uncredited use of AI-generated images in media and marketing has sparked significant backlash from online communities. In response to this, we introduce DejAIvu, a Chrome Web extension that combines real-time AI-generated image detection with saliency-based explainability while users browse the web. Using an ONNX-optimized deep learning model, DejAIvu automatically analyzes images on websites such as Google Images, identifies AI-generated content using model inference, and overlays a saliency heatmap to highlight AI-related artifacts. Our approach integrates efficient in-browser inference, gradient-based saliency analysis, and a seamless user experience, ensuring that AI detection is both transparent and interpretable. We also evaluate DejAIvu across multiple pretrained architectures and benchmark datasets, demonstrating high accuracy and low latency, making it a practical and deployable tool for enhancing AI image accountability. The code for this system can be found at https://github.com/Noodulz/dejAIvu.","authors":["Jocelyn Dzuong"],"url":"https://arxiv.org/abs/2502.08821"}
{"created":"2025-05-09","title":"A Machine Learning Approach to Sensor Substitution from Tactile Sensing to Visual Perception for Non-Prehensile Manipulation","abstract":"Mobile manipulators are increasingly deployed in complex environments, requiring diverse sensors to perceive and interact with their surroundings. However, equipping every robot with every possible sensor is often impractical due to cost and physical constraints. A critical challenge arises when robots with differing sensor capabilities need to collaborate or perform similar tasks. For example, consider a scenario where a mobile manipulator equipped with high-resolution tactile skin is skilled at non-prehensile manipulation tasks like pushing. If this robot needs to be replaced or augmented by a robot lacking such tactile sensing, the learned manipulation policies become inapplicable. This paper addresses the problem of sensor substitution in non-prehensile manipulation. We propose a novel machine learning-based framework that enables a robot with a limited sensor set (e.g., LiDAR or RGB-D) to effectively perform tasks previously reliant on a richer sensor suite (e.g., tactile skin). Our approach learns a mapping between the available sensor data and the information provided by the substituted sensor, effectively synthesizing the missing sensory input. Specifically, we demonstrate the efficacy of our framework by training a model to substitute tactile skin data for the task of non-prehensile pushing using a mobile manipulator. We show that a manipulator equipped only with LiDAR or RGB-D can, after training, achieve comparable and sometimes even better pushing performance to a mobile base utilizing direct tactile feedback.","authors":["Idil Ozdamar (Human-Robot Interfaces and Interaction","Istituto Italiano di Tecnologia","Genoa","Italy","Dept. of Informatics","Bioengineering","Robotics","and System Engineering","University of Genoa","Genoa","Italy)","Doganay Sirintuna (Human-Robot Interfaces and Interaction","Istituto Italiano di Tecnologia","Genoa","Italy","Dept. of Informatics","Bioengineering","Robotics","and System Engineering","University of Genoa","Genoa","Italy)","Arash Ajoudani (Human-Robot Interfaces and Interaction","Istituto Italiano di Tecnologia","Genoa","Italy)"],"url":"https://arxiv.org/abs/2502.09180"}
{"created":"2025-05-09","title":"Global-Local Interface with Selective Direct and Singularity-Avoiding Motion Mapping for Intuitive Teleoperation","abstract":"This paper presents the Global-Local Teleoperation Interface, a hierarchical framework that enhances human-robot interaction by decoupling large-scale manipulator positioning from fine end-effector manipulation. The global component enables efficient workspace traversal, while the local component facilitates precise and dexterous control. To address slave-side kinematic singularities-especially during fine manipulation, we propose a singularity-avoiding motion mapping strategy that enhances both stability and intuitiveness. We further introduce the concept of an operational Jacobian to characterize the smoothness of joint motion under local control. The G-L interface is implemented in two variants: Direct Mapping and Singularity-Avoiding Mapping, and is validated through hardware experiments involving precision tasks and complex motion. Results show substantial improvements in task success rate, efficiency, and user experience over conventional global or local-only systems.","authors":["Jianshu Zhou","Boyuan Liang","Junda Huang","Ian Zhang","Zhengyang Liu","Pieter Abbeel","Masayoshi Tomizuka"],"url":"https://arxiv.org/abs/2502.09960"}
{"created":"2025-05-09","title":"Safety Evaluation of DeepSeek Models in Chinese Contexts","abstract":"Recently, the DeepSeek series of models, leveraging their exceptional reasoning capabilities and open-source strategy, is reshaping the global AI landscape. Despite these advantages, they exhibit significant safety deficiencies. Research conducted by Robust Intelligence, a subsidiary of Cisco, in collaboration with the University of Pennsylvania, revealed that DeepSeek-R1 has a 100\\% attack success rate when processing harmful prompts. Additionally, multiple safety companies and research institutions have confirmed critical safety vulnerabilities in this model. As models demonstrating robust performance in Chinese and English, DeepSeek models require equally crucial safety assessments in both language contexts. However, current research has predominantly focused on safety evaluations in English environments, leaving a gap in comprehensive assessments of their safety performance in Chinese contexts. In response to this gap, this study introduces CHiSafetyBench, a Chinese-specific safety evaluation benchmark. This benchmark systematically evaluates the safety of DeepSeek-R1 and DeepSeek-V3 in Chinese contexts, revealing their performance across safety categories. The experimental results quantify the deficiencies of these two models in Chinese contexts, providing key insights for subsequent improvements. It should be noted that, despite our efforts to establish a comprehensive, objective, and authoritative evaluation benchmark, the selection of test samples, characteristics of data distribution, and the setting of evaluation criteria may inevitably introduce certain biases into the evaluation results. We will continuously optimize the evaluation benchmark and periodically update this report to provide more comprehensive and accurate assessment outcomes. Please refer to the latest version of the paper for the most recent evaluation results and conclusions.","authors":["Wenjing Zhang","Xuejiao Lei","Zhaoxiang Liu","Ning Wang","Zhenhong Long","Peijun Yang","Jiaojiao Zhao","Minjie Hua","Chaoyang Ma","Kai Wang","Shiguo Lian"],"url":"https://arxiv.org/abs/2502.11137"}
{"created":"2025-05-09","title":"SATA: Safe and Adaptive Torque-Based Locomotion Policies Inspired by Animal Learning","abstract":"Despite recent advances in learning-based controllers for legged robots, deployments in human-centric environments remain limited by safety concerns. Most of these approaches use position-based control, where policies output target joint angles that must be processed by a low-level controller (e.g., PD or impedance controllers) to compute joint torques. Although impressive results have been achieved in controlled real-world scenarios, these methods often struggle with compliance and adaptability when encountering environments or disturbances unseen during training, potentially resulting in extreme or unsafe behaviors. Inspired by how animals achieve smooth and adaptive movements by controlling muscle extension and contraction, torque-based policies offer a promising alternative by enabling precise and direct control of the actuators in torque space. In principle, this approach facilitates more effective interactions with the environment, resulting in safer and more adaptable behaviors. However, challenges such as a highly nonlinear state space and inefficient exploration during training have hindered their broader adoption. To address these limitations, we propose SATA, a bio-inspired framework that mimics key biomechanical principles and adaptive learning mechanisms observed in animal locomotion. Our approach effectively addresses the inherent challenges of learning torque-based policies by significantly improving early-stage exploration, leading to high-performance final policies. Remarkably, our method achieves zero-shot sim-to-real transfer. Our experimental results indicate that SATA demonstrates remarkable compliance and safety, even in challenging environments such as soft/slippery terrain or narrow passages, and under significant external disturbances, highlighting its potential for practical deployments in human-centric and safety-critical scenarios.","authors":["Peizhuo Li","Hongyi Li","Ge Sun","Jin Cheng","Xinrong Yang","Guillaume Bellegarda","Milad Shafiee","Yuhong Cao","Auke Ijspeert","Guillaume Sartoretti"],"url":"https://arxiv.org/abs/2502.12674"}
{"created":"2025-05-09","title":"Correcting Noisy Multilabel Predictions: Modeling Label Noise through Latent Space Shifts","abstract":"Noise in data appears to be inevitable in most real-world machine learning applications and would cause severe overfitting problems. Not only can data features contain noise, but labels are also prone to be noisy due to human input. In this paper, rather than noisy label learning in multiclass classifications, we instead focus on the less explored area of noisy label learning for multilabel classifications. Specifically, we investigate the post-correction of predictions generated from classifiers learned with noisy labels. The reasons are two-fold. Firstly, this approach can directly work with the trained models to save computational resources. Secondly, it could be applied on top of other noisy label correction techniques to achieve further improvements. To handle this problem, we appeal to deep generative approaches that are possible for uncertainty estimation. Our model posits that label noise arises from a stochastic shift in the latent variable, providing a more robust and beneficial means for noisy learning. We develop both unsupervised and semi-supervised learning methods for our model. The extensive empirical study presents solid evidence to that our approach is able to consistently improve the independent models and performs better than a number of existing methods across various noisy label settings. Moreover, a comprehensive empirical analysis of the proposed method is carried out to validate its robustness, including sensitivity analysis and an ablation study, among other elements.","authors":["Weipeng Huang","Qin Li","Yang Xiao","Cheng Qiao","Tie Cai","Junwei Liang","Neil J. Hurley","Guangyuan Piao"],"url":"https://arxiv.org/abs/2502.14281"}
{"created":"2025-05-09","title":"Drift: Decoding-time Personalized Alignments with Implicit User Preferences","abstract":"Personalized alignments for individual users have been a long-standing goal in large language models (LLMs). We introduce Drift, a novel framework that personalizes LLMs at decoding time with implicit user preferences. Traditional Reinforcement Learning from Human Feedback (RLHF) requires thousands of annotated examples and expensive gradient updates. In contrast, Drift personalizes LLMs in a training-free manner, using only a few dozen examples to steer a frozen model through efficient preference modeling. Our approach models user preferences as a composition of predefined, interpretable attributes and aligns them at decoding time to enable personalized generation. Experiments on both a synthetic persona dataset (Perspective) and a real human-annotated dataset (PRISM) demonstrate that Drift significantly outperforms RLHF baselines while using only 50-100 examples. Our results and analysis show that Drift is both computationally efficient and interpretable.","authors":["Minbeom Kim","Kang-il Lee","Seongho Joo","Hwaran Lee","Thibaut Thonet","Kyomin Jung"],"url":"https://arxiv.org/abs/2502.14289"}
{"created":"2025-05-09","title":"On Space-Filling Input Design for Nonlinear Dynamic Model Learning: A Gaussian Process Approach","abstract":"While optimal input design for linear systems has been well-established, no systematic approach exists for nonlinear systems where robustness to extrapolation/interpolation errors is prioritized over minimizing estimated parameter variance. To address this issue, we develop a novel space-filling input design strategy for nonlinear system identification that ensures data coverage of a given region of interest. By placing a Gaussian Process (GP) prior on the joint input-state space, the proposed strategy leverages the GP posterior variance to construct a cost function that promotes space-filling input design. Consequently, this enables maximization of the coverage in the region of interest, thereby facilitating the generation of informative datasets. Furthermore, we theoretically prove that minimization of the cost function implies the space-filling property of the obtained data. Effectiveness of the proposed strategy is demonstrated on both an academic and a mass-spring-damper example, highlighting its potential practical impact on efficient exploration of the dynamics of nonlinear systems.","authors":["Yuhan Liu","M\\'at\\'e Kiss","Roland T\\'oth","Maarten Schoukens"],"url":"https://arxiv.org/abs/2502.17042"}
{"created":"2025-05-09","title":"Faster, Cheaper, Better: Multi-Objective Hyperparameter Optimization for LLM and RAG Systems","abstract":"While Retrieval Augmented Generation (RAG) has emerged as a popular technique for improving Large Language Model (LLM) systems, it introduces a large number of choices, parameters and hyperparameters that must be made or tuned. This includes the LLM, embedding, and ranker models themselves, as well as hyperparameters governing individual RAG components. Yet, collectively optimizing the entire configuration in a RAG or LLM system remains under-explored - especially in multi-objective settings - due to intractably large solution spaces, noisy objective evaluations, and the high cost of evaluations. In this work, we introduce the first approach for multi-objective parameter optimization of cost, latency, safety and alignment over entire LLM and RAG systems. We find that Bayesian optimization methods significantly outperform baseline approaches, obtaining a superior Pareto front on two new RAG benchmark tasks. We conclude our work with important considerations for practitioners who are designing multi-objective RAG systems, highlighting nuances such as how optimal configurations may not generalize across tasks and objectives.","authors":["Matthew Barker","Andrew Bell","Evan Thomas","James Carr","Thomas Andrews","Umang Bhatt"],"url":"https://arxiv.org/abs/2502.18635"}
{"created":"2025-05-09","title":"Re-evaluating Open-ended Evaluation of Large Language Models","abstract":"Evaluation has traditionally focused on ranking candidates for a specific skill. Modern generalist models, such as Large Language Models (LLMs), decidedly outpace this paradigm. Open-ended evaluation systems, where candidate models are compared on user-submitted prompts, have emerged as a popular solution. Despite their many advantages, we show that the current Elo-based rating systems can be susceptible to and even reinforce biases in data, intentional or accidental, due to their sensitivity to redundancies. To address this issue, we propose evaluation as a 3-player game, and introduce novel game-theoretic solution concepts to ensure robustness to redundancy. We show that our method leads to intuitive ratings and provide insights into the competitive landscape of LLM development.","authors":["Siqi Liu","Ian Gemp","Luke Marris","Georgios Piliouras","Nicolas Heess","Marc Lanctot"],"url":"https://arxiv.org/abs/2502.20170"}
{"created":"2025-05-09","title":"Uncertainty Comes for Free: Human-in-the-Loop Policies with Diffusion Models","abstract":"Human-in-the-loop (HitL) robot deployment has gained significant attention in both academia and industry as a semi-autonomous paradigm that enables human operators to intervene and adjust robot behaviors at deployment time, improving success rates. However, continuous human monitoring and intervention can be highly labor-intensive and impractical when deploying a large number of robots. To address this limitation, we propose a method that allows diffusion policies to actively seek human assistance only when necessary, reducing reliance on constant human oversight. To achieve this, we leverage the generative process of diffusion policies to compute an uncertainty-based metric based on which the autonomous agent can decide to request operator assistance at deployment time, without requiring any operator interaction during training. Additionally, we show that the same method can be used for efficient data collection for fine-tuning diffusion policies in order to improve their autonomous performance. Experimental results from simulated and real-world environments demonstrate that our approach enhances policy performance during deployment for a variety of scenarios.","authors":["Zhanpeng He","Yifeng Cao","Matei Ciocarlie"],"url":"https://arxiv.org/abs/2503.01876"}
{"created":"2025-05-09","title":"LIVS: A Pluralistic Alignment Dataset for Inclusive Public Spaces","abstract":"We introduce the Local Intersectional Visual Spaces (LIVS) dataset, a benchmark for multi-criteria alignment, developed through a two-year participatory process with 30 community organizations to support the pluralistic alignment of text-to-image (T2I) models in inclusive urban planning. The dataset encodes 37,710 pairwise comparisons across 13,462 images, structured along six criteria - Accessibility, Safety, Comfort, Invitingness, Inclusivity, and Diversity - derived from 634 community-defined concepts. Using Direct Preference Optimization (DPO), we fine-tune Stable Diffusion XL to reflect multi-criteria spatial preferences and evaluate the LIVS dataset and the fine-tuned model through four case studies: (1) DPO increases alignment with annotated preferences, particularly when annotation volume is high; (2) preference patterns vary across participant identities, underscoring the need for intersectional data; (3) human-authored prompts generate more distinctive visual outputs than LLM-generated ones, influencing annotation decisiveness; and (4) intersectional groups assign systematically different ratings across criteria, revealing the limitations of single-objective alignment. While DPO improves alignment under specific conditions, the prevalence of neutral ratings indicates that community values are heterogeneous and often ambiguous. LIVS provides a benchmark for developing T2I models that incorporate local, stakeholder-driven preferences, offering a foundation for context-aware alignment in spatial design.","authors":["Rashid Mushkani","Shravan Nayak","Hugo Berard","Allison Cohen","Shin Koseki","Hadrien Bertrand"],"url":"https://arxiv.org/abs/2503.01894"}
{"created":"2025-05-09","title":"LREA: Low-Rank Efficient Attention on Modeling Long-Term User Behaviors for CTR Prediction","abstract":"With the rapid growth of user historical behavior data, user interest modeling has become a prominent aspect in Click-Through Rate (CTR) prediction, focusing on learning user intent representations. However, this complexity poses computational challenges, requiring a balance between model performance and acceptable response times for online services. Traditional methods often utilize filtering techniques. These techniques can lead to the loss of significant information by prioritizing top K items based on item attributes or employing low-precision attention mechanisms. In this study, we introduce LREA, a novel attention mechanism that overcomes the limitations of existing approaches while ensuring computational efficiency. LREA leverages low-rank matrix decomposition to optimize runtime performance and incorporates a specially designed loss function to maintain attention capabilities while preserving information integrity. During the inference phase, matrix absorption and pre-storage strategies are employed to effectively meet runtime constraints. The results of extensive offline and online experiments demonstrate that our method outperforms state-of-the-art approaches.","authors":["Xin Song","Xiaochen Li","Jinxin Hu","Hong Wen","Zulong Chen","Yu Zhang","Xiaoyi Zeng","Jing Zhang"],"url":"https://arxiv.org/abs/2503.02542"}
{"created":"2025-05-09","title":"Don't Shake the Wheel: Momentum-Aware Planning in End-to-End Autonomous Driving","abstract":"End-to-end autonomous driving frameworks enable seamless integration of perception and planning but often rely on one-shot trajectory prediction, which may lead to unstable control and vulnerability to occlusions in single-frame perception. To address this, we propose the Momentum-Aware Driving (MomAD) framework, which introduces trajectory momentum and perception momentum to stabilize and refine trajectory predictions. MomAD comprises two core components: (1) Topological Trajectory Matching (TTM) employs Hausdorff Distance to select the optimal planning query that aligns with prior paths to ensure coherence;(2) Momentum Planning Interactor (MPI) cross-attends the selected planning query with historical queries to expand static and dynamic perception files. This enriched query, in turn, helps regenerate long-horizon trajectory and reduce collision risks. To mitigate noise arising from dynamic environments and detection errors, we introduce robust instance denoising during training, enabling the planning model to focus on critical signals and improve its robustness. We also propose a novel Trajectory Prediction Consistency (TPC) metric to quantitatively assess planning stability. Experiments on the nuScenes dataset demonstrate that MomAD achieves superior long-term consistency (>=3s) compared to SOTA methods. Moreover, evaluations on the curated Turning-nuScenes shows that MomAD reduces the collision rate by 26% and improves TPC by 0.97m (33.45%) over a 6s prediction horizon, while closedloop on Bench2Drive demonstrates an up to 16.3% improvement in success rate.","authors":["Ziying Song","Caiyan Jia","Lin Liu","Hongyu Pan","Yongchang Zhang","Junming Wang","Xingyu Zhang","Shaoqing Xu","Lei Yang","Yadan Luo"],"url":"https://arxiv.org/abs/2503.03125"}
{"created":"2025-05-09","title":"Rethinking Video Super-Resolution: Towards Diffusion-Based Methods without Motion Alignment","abstract":"In this work, we rethink the approach to video super-resolution by introducing a method based on the Diffusion Posterior Sampling framework, combined with an unconditional video diffusion transformer operating in latent space. The video generation model, a diffusion transformer, functions as a space-time model. We argue that a powerful model, which learns the physics of the real world, can easily handle various kinds of motion patterns as prior knowledge, thus eliminating the need for explicit estimation of optical flows or motion parameters for pixel alignment. Furthermore, a single instance of the proposed video diffusion transformer model can adapt to different sampling conditions without re-training. Empirical results on synthetic and real-world datasets illustrate the feasibility of diffusion-based, alignment-free video super-resolution.","authors":["Zhihao Zhan","Wang Pang","Xiang Zhu","Yechao Bai"],"url":"https://arxiv.org/abs/2503.03355"}
{"created":"2025-05-09","title":"Prismatic-Bending Transformable (PBT) Joint for a Modular, Foldable Manipulator with Enhanced Reachability and Dexterity","abstract":"Robotic manipulators, traditionally designed with classical joint-link articulated structures, excel in industrial applications but face challenges in human-centered and general-purpose tasks requiring greater dexterity and adaptability. To address these challenges, we propose the Prismatic-Bending Transformable (PBT) Joint, a novel, scissors-inspired mechanism with directional maintenance capability that provides bending, rotation, and elongation/contraction within a single module. This design enables transformable kinematic chains that are modular, reconfigurable, and scalable for diverse tasks. We detail the mechanical design, optimization, kinematic and dynamic modeling, and experimental validation of the PBT joint, demonstrating its integration into foldable, modular robotic manipulators. The PBT joint functions as a single stock keeping unit (SKU), enabling manipulators to be constructed entirely from standardized PBT joints. It also serves as a modular extension for existing systems, such as wrist modules, streamlining design, deployment, transportation, and maintenance. Three joint sizes have been developed and tested, showcasing enhanced dexterity, reachability, and adaptability, particularly in confined and cluttered spaces. This work presents a promising approach to robotic manipulator development, providing a compact and versatile solution for operation in dynamic and constrained environments.","authors":["Jianshu Zhou","Junda Huang","Boyuan Liang","Xiang Zhang","Xin Ma","Masayoshi Tomizuka"],"url":"https://arxiv.org/abs/2503.05057"}
{"created":"2025-05-09","title":"Semantic Shift Estimation via Dual-Projection and Classifier Reconstruction for Exemplar-Free Class-Incremental Learning","abstract":"Exemplar-Free Class-Incremental Learning (EFCIL) aims to sequentially learn from distinct categories without retaining exemplars but easily suffers from catastrophic forgetting of learned knowledge. While existing EFCIL methods leverage knowledge distillation to alleviate forgetting, they still face two critical challenges: semantic shift and decision bias. Specifically, the embeddings of old tasks shift in the embedding space after learning new tasks, and the classifier becomes biased towards new tasks due to training solely with new data, thereby hindering the balance between old and new knowledge. To address these issues, we propose the Dual-Projection Shift Estimation and Classifier Reconstruction (DPCR) approach for EFCIL. DPCR effectively estimates semantic shift through a dual-projection, which combines a learnable transformation with a row-space projection to capture both task-wise and category-wise shifts. Furthermore, to mitigate decision bias, DPCR employs ridge regression to reformulate classifier training as a reconstruction process. This reconstruction exploits previous information encoded in covariance and prototype of each class after calibration with estimated shift, thereby reducing decision bias. Extensive experiments demonstrate that, across various datasets, DPCR effectively balances old and new tasks, outperforming state-of-the-art EFCIL methods.","authors":["Run He","Di Fang","Yicheng Xu","Yawen Cui","Ming Li","Cen Chen","Ziqian Zeng","Huiping Zhuang"],"url":"https://arxiv.org/abs/2503.05423"}
{"created":"2025-05-09","title":"Correctness Coverage Evaluation for Medical Multiple-Choice Question Answering Based on the Enhanced Conformal Prediction Framework","abstract":"Large language models (LLMs) are increasingly adopted in medical question-answering (QA) scenarios. However, LLMs can generate hallucinations and nonfactual information, undermining their trustworthiness in high-stakes medical tasks. Conformal Prediction (CP) provides a statistically rigorous framework for marginal (average) coverage guarantees but has limited exploration in medical QA. This paper proposes an enhanced CP framework for medical multiple-choice question-answering (MCQA) tasks. By associating the non-conformance score with the frequency score of correct options and leveraging self-consistency, the framework addresses internal model opacity and incorporates a risk control strategy with a monotonic loss function. Evaluated on MedMCQA, MedQA, and MMLU datasets using four off-the-shelf LLMs, the proposed method meets specified error rate guarantees while reducing average prediction set size with increased risk level, offering a promising uncertainty evaluation metric for LLMs.","authors":["Yusong Ke","Hongru Lin","Yuting Ruan","Junya Tang","Li Li"],"url":"https://arxiv.org/abs/2503.05505"}
{"created":"2025-05-09","title":"A Quantitative Evaluation of the Expressivity of BMI, Pose and Gender in Body Embeddings for Recognition and Identification","abstract":"Person Re-identification (ReID) systems that match individuals across images or video frames are essential in many real-world applications. However, existing methods are often influenced by attributes such as gender, pose, and body mass index (BMI), which vary in unconstrained settings and raise concerns related to fairness and generalization. To address this, we extend the notion of expressivity, defined as the mutual information between learned features and specific attributes, using a secondary neural network to quantify how strongly attributes are encoded. Applying this framework to three ReID models, we find that BMI consistently shows the highest expressivity in the final layers, indicating its dominant role in recognition. In the last attention layer, attributes are ranked as BMI > Pitch > Gender > Yaw, revealing their relative influences in representation learning. Expressivity values also evolve across layers and training epochs, reflecting a dynamic encoding of attributes. These findings demonstrate the central role of body attributes in ReID and establish a principled approach for uncovering attribute driven correlations.","authors":["Basudha Pal","Siyuan Huang","Rama Chellappa"],"url":"https://arxiv.org/abs/2503.06451"}
{"created":"2025-05-09","title":"Large Language Models for Outpatient Referral: Problem Definition, Benchmarking and Challenges","abstract":"Large language models (LLMs) are increasingly applied to outpatient referral tasks across healthcare systems. However, there is a lack of standardized evaluation criteria to assess their effectiveness, particularly in dynamic, interactive scenarios. In this study, we systematically examine the capabilities and limitations of LLMs in managing tasks within Intelligent Outpatient Referral (IOR) systems and propose a comprehensive evaluation framework specifically designed for such systems. This framework comprises two core tasks: static evaluation, which focuses on evaluating the ability of predefined outpatient referrals, and dynamic evaluation, which evaluates capabilities of refining outpatient referral recommendations through iterative dialogues. Our findings suggest that LLMs offer limited advantages over BERT-like models, but show promise in asking effective questions during interactive dialogues.","authors":["Xiaoxiao Liu","Qingying Xiao","Junying Chen","Xiangyi Feng","Xiangbo Wu","Bairui Zhang","Xiang Wan","Jian Chang","Guangjun Yu","Yan Hu","Benyou Wang"],"url":"https://arxiv.org/abs/2503.08292"}
{"created":"2025-05-09","title":"New construction of Locally Perfect Nonlinear Functions with Application to Sequences Sets with Low Ambiguity Zone","abstract":"Low Ambiguity Zone (LAZ) sequences play a pivotal role in modern integrated sensing and communication (ISAC) systems. Recently, Wang et al.\\cite{WangZhou2025} proposed a definition of locally perfect nonlinear functions (LPNFs) and constructed three classes of both periodic and aperiodic LAZ sequence sets with flexible parameters by applying such functions and interleaving method. Some of these LAZ sequence sets are asymptotically optimal with respect to the Ye-Zhou-Liu-Fan-Lei-Tang bounds under certain conditions. In this paper, we proceed with the constructions of the three new classes of LPNFs with new parameters. By using these LPNFs, we also present a series of LAZ sequence sets with more flexible parameters, addressing the limitations of existing parameter choices. Furthermore, our results show that one of these classes is asymptotically optimal in both the periodic and aperiodic cases, respectively.","authors":["Zhiye Yang","Zheng Wang","Huaning Liu","Zhengchun Zhou","Keqin Feng"],"url":"https://arxiv.org/abs/2503.09172"}
{"created":"2025-05-09","title":"How Do Multimodal Large Language Models Handle Complex Multimodal Reasoning? Placing Them in An Extensible Escape Game","abstract":"The rapid advancing of Multimodal Large Language Models (MLLMs) has spurred interest in complex multimodal reasoning tasks in the real-world and virtual environment, which require coordinating multiple abilities, including visual perception, visual reasoning, spatial awareness, and target deduction. However, existing evaluations primarily assess the final task completion, often degrading assessments to isolated abilities such as visual grounding and visual question answering. Less attention is given to comprehensively and quantitatively analyzing reasoning process in multimodal environments, which is crucial for understanding model behaviors and underlying reasoning mechanisms beyond merely task success. To address this, we introduce MM-Escape, an extensible benchmark for investigating multimodal reasoning, inspired by real-world escape games. MM-Escape emphasizes intermediate model behaviors alongside final task completion. To achieve this, we develop EscapeCraft, a customizable and open environment that enables models to engage in free-form exploration for assessing multimodal reasoning. Extensive experiments show that MLLMs, regardless of scale, can successfully complete the simplest room escape tasks, with some exhibiting human-like exploration strategies. Yet, performance dramatically drops as task difficulty increases. Moreover, we observe that performance bottlenecks vary across models, revealing distinct failure modes and limitations in their multimodal reasoning abilities, such as repetitive trajectories without adaptive exploration, getting stuck in corners due to poor visual spatial awareness, and ineffective use of acquired props, such as the key. We hope our work sheds light on new challenges in multimodal reasoning, and uncovers potential improvements in MLLMs capabilities.","authors":["Ziyue Wang","Yurui Dong","Fuwen Luo","Minyuan Ruan","Zhili Cheng","Chi Chen","Peng Li","Yang Liu"],"url":"https://arxiv.org/abs/2503.10042"}
{"created":"2025-05-09","title":"MaskAttn-UNet: A Mask Attention-Driven Framework for Universal Low-Resolution Image Segmentation","abstract":"Low-resolution image segmentation is crucial in real-world applications such as robotics, augmented reality, and large-scale scene understanding, where high-resolution data is often unavailable due to computational constraints. To address this challenge, we propose MaskAttn-UNet, a novel segmentation framework that enhances the traditional U-Net architecture via a mask attention mechanism. Our model selectively emphasizes important regions while suppressing irrelevant backgrounds, thereby improving segmentation accuracy in cluttered and complex scenes. Unlike conventional U-Net variants, MaskAttn-UNet effectively balances local feature extraction with broader contextual awareness, making it particularly well-suited for low-resolution inputs. We evaluate our approach on three benchmark datasets with input images rescaled to 128x128 and demonstrate competitive performance across semantic, instance, and panoptic segmentation tasks. Our results show that MaskAttn-UNet achieves accuracy comparable to state-of-the-art methods at significantly lower computational cost than transformer-based models, making it an efficient and scalable solution for low-resolution segmentation in resource-constrained scenarios.","authors":["Anzhe Cheng","Chenzhong Yin","Yu Chang","Heng Ping","Shixuan Li","Shahin Nazarian","Paul Bogdan"],"url":"https://arxiv.org/abs/2503.10686"}
{"created":"2025-05-09","title":"Negotiative Alignment: Embracing Disagreement to Achieve Fairer Outcomes -- Insights from Urban Studies","abstract":"Cities are not monolithic; they are arenas of negotiation among groups that hold varying needs, values, and experiences. Conventional methods of urban assessment -- from standardized surveys to AI-driven evaluations -- frequently rely on a single consensus metric (e.g., an average measure of inclusivity or safety). Although such aggregations simplify design decisions, they risk obscuring the distinct perspectives of marginalized populations. In this paper, we present findings from a community-centered study in Montreal involving 35 residents with diverse demographic and social identities, particularly wheelchair users, seniors, and LGBTQIA2+ individuals. Using rating and ranking tasks on 20 urban sites, we observe that disagreements are systematic rather than random, reflecting structural inequalities, differing cultural values, and personal experiences of safety and accessibility.","authors":["Rashid Mushkani","Hugo Berard","Shin Koseki"],"url":"https://arxiv.org/abs/2503.12613"}
{"created":"2025-05-09","title":"Atyaephyra at SemEval-2025 Task 4: Low-Rank Negative Preference Optimization","abstract":"We present a submission to the SemEval 2025 shared task on unlearning sensitive content from LLMs. Our approach employs negative preference optimization using low-rank adaptation. We show that we can utilize this combination to efficiently compute additional regularization terms, which help with unlearning stabilization. The results of our approach significantly exceed the shared task baselines.","authors":["Jan Bronec (Charles University","Faculty of Mathematics and Physics","Institute of Formal and Applied Linguistics)","Jind\\v{r}ich Helcl (Charles University","Faculty of Mathematics and Physics","Institute of Formal and Applied Linguistics)"],"url":"https://arxiv.org/abs/2503.13690"}
{"created":"2025-05-09","title":"Effective Dimension Aware Fractional-Order Stochastic Gradient Descent for Convex Optimization Problems","abstract":"Fractional-order stochastic gradient descent (FOSGD) leverages fractional exponents to capture long-memory effects in optimization. However, its utility is often limited by the difficulty of tuning and stabilizing these exponents. We propose 2SED Fractional-Order Stochastic Gradient Descent (2SEDFOSGD), which integrates the Two-Scale Effective Dimension (2SED) algorithm with FOSGD to adapt the fractional exponent in a data-driven manner. By tracking model sensitivity and effective dimensionality, 2SEDFOSGD dynamically modulates the exponent to mitigate oscillations and hasten convergence. Theoretically, this approach preserves the advantages of fractional memory without the sluggish or unstable behavior observed in na\\\"ive fractional SGD. Empirical evaluations in Gaussian and $\\alpha$-stable noise scenarios using an autoregressive (AR) model\\textcolor{red}{, as well as on the MNIST and CIFAR-100 datasets for image classification,} highlight faster convergence and more robust parameter estimates compared to baseline methods, underscoring the potential of dimension-aware fractional techniques for advanced modeling and estimation tasks.","authors":["Mohammad Partohaghighi","Roummel Marcia","YangQuan Chen"],"url":"https://arxiv.org/abs/2503.13764"}
{"created":"2025-05-09","title":"Benchmarking Open-Source Large Language Models on Healthcare Text Classification Tasks","abstract":"The application of large language models (LLMs) to healthcare information extraction has emerged as a promising approach. This study evaluates the classification performance of five open-source LLMs: GEMMA-3-27B-IT, LLAMA3-70B, LLAMA4-109B, DEEPSEEK-R1-DISTILL-LLAMA-70B, and DEEPSEEK-V3-0324-UD-Q2_K_XL, across six healthcare-related classification tasks involving both social media data (breast cancer, changes in medication regimen, adverse pregnancy outcomes, potential COVID-19 cases) and clinical data (stigma labeling, medication change discussion). We report precision, recall, and F1 scores with 95% confidence intervals for all model-task combinations. Our findings reveal significant performance variability between LLMs, with DeepSeekV3 emerging as the strongest overall performer, achieving the highest F1 scores in four tasks. Notably, models generally performed better on social media tasks compared to clinical data tasks, suggesting potential domain-specific challenges. GEMMA-3-27B-IT demonstrated exceptionally high recall despite its smaller parameter count, while LLAMA4-109B showed surprisingly underwhelming performance compared to its predecessor LLAMA3-70B, indicating that larger parameter counts do not guarantee improved classification results. We observed distinct precision-recall trade-offs across models, with some favoring sensitivity over specificity and vice versa. These findings highlight the importance of task-specific model selection for healthcare applications, considering the particular data domain and precision-recall requirements rather than model size alone. As healthcare increasingly integrates AI-driven text classification tools, this comprehensive benchmarking provides valuable guidance for model selection and implementation while underscoring the need for continued evaluation and domain adaptation of LLMs in healthcare contexts.","authors":["Yuting Guo","Abeed Sarker"],"url":"https://arxiv.org/abs/2503.15169"}
{"created":"2025-05-09","title":"Advances in Protein Representation Learning: Methods, Applications, and Future Directions","abstract":"Proteins are complex biomolecules that play a central role in various biological processes, making them critical targets for breakthroughs in molecular biology, medical research, and drug discovery. Deciphering their intricate, hierarchical structures, and diverse functions is essential for advancing our understanding of life at the molecular level. Protein Representation Learning (PRL) has emerged as a transformative approach, enabling the extraction of meaningful computational representations from protein data to address these challenges. In this paper, we provide a comprehensive review of PRL research, categorizing methodologies into five key areas: feature-based, sequence-based, structure-based, multimodal, and complex-based approaches. To support researchers in this rapidly evolving field, we introduce widely used databases for protein sequences, structures, and functions, which serve as essential resources for model development and evaluation. We also explore the diverse applications of these approaches in multiple domains, demonstrating their broad impact. Finally, we discuss pressing technical challenges and outline future directions to advance PRL, offering insights to inspire continued innovation in this foundational field.","authors":["Viet Thanh Duy Nguyen","Truong-Son Hy"],"url":"https://arxiv.org/abs/2503.16659"}
{"created":"2025-05-09","title":"A Tutorial on Six-Dimensional Movable Antenna for 6G Networks: Synergizing Positionable and Rotatable Antennas","abstract":"Six-dimensional movable antenna (6DMA) is a new","authors":["Xiaodan Shao","Weidong Mei","Changsheng You","Qingqing Wu","Beixiong Zheng","Cheng-Xiang Wang","Junling Li","Rui Zhang","Robert Schober","Lipeng Zhu","Weihua Zhuang","Xuemin Shen"],"url":"https://arxiv.org/abs/2503.18240"}
{"created":"2025-05-09","title":"Probabilistic Uncertain Reward Model","abstract":"Reinforcement Learning from Human Feedback (RLHF) has emerged as a critical technique for training large language models. However, reward hacking-a phenomenon where models exploit flaws in the reward model-remains a significant barrier to achieving robust and scalable intelligence through long-term training. Existing studies have proposed the uncertain reward models to address reward hacking, however, they often lack systematic or theoretical foundations, failing to model the uncertainty intrinsically emerging from preference data, and thus cannot sufficiently mitigate reward hacking to sustain prolonged RLHF training and exploration. In this paper, we propose a Probabilistic Uncertain Reward Model (PURM), a natural generalization of the classical Bradley-Terry reward model, that can directly learn the reward distribution emerged from the preference data. We theoretically derived PURM's loss function and the uncertainty of the reward distribution. To mitigate reward hacking with PURM, we further introduce an uncertainty-aware penalty into Proximal Policy Optimization (PPO), which leverages the learned uncertainty to dynamically balance reward optimization and exploration. Experimental results demonstrate that PURM significantly delays the onset of reward hacking while improving final performance compared with existing methods. We also find that PURM genuinely produce sound reward and uncertainty estimations. The data and code of this paper can be found at https://anonymous.4open.science/r/Probabilistic-Uncertain-Reward-Model/","authors":["Wangtao Sun","Xiang Cheng","Xing Yu","Haotian Xu","Zhao Yang","Shizhu He","Jun Zhao","Kang Liu"],"url":"https://arxiv.org/abs/2503.22480"}
{"created":"2025-05-09","title":"CodeIF-Bench: Evaluating Instruction-Following Capabilities of Large Language Models in Interactive Code Generation","abstract":"Large Language Models (LLMs) have demonstrated exceptional performance in code generation tasks and have become indispensable programming assistants for developers. However, existing code generation benchmarks primarily assess the functional correctness of code generated by LLMs in single-turn interactions, offering limited insight into their capabilities to generate code that strictly follows users' instructions, especially in multi-turn interaction scenarios. In this paper, we introduce CodeIF-Bench, a benchmark for evaluating LLMs' instruction-following capabilities in interactive code generation. Specifically, CodeIF-Bench incorporates nine types of verifiable instructions aligned with the real-world software development requirements, which can be independently and objectively validated through specified test cases, facilitating the evaluation of instruction-following capability in multi-turn interactions. We evaluate nine prominent LLMs using CodeIF-Bench, and the experimental results reveal a significant disparity between their basic programming capability and instruction-following capability, particularly as task complexity, context length, and the number of dialogue rounds increase.","authors":["Peiding Wang","Li Zhang","Fang Liu","Lin Shi","Minxiao Li","Bo Shen","An Fu"],"url":"https://arxiv.org/abs/2503.22688"}
{"created":"2025-05-09","title":"Do We Truly Need So Many Samples? Multi-LLM Repeated Sampling Efficiently Scales Test-Time Compute","abstract":"This paper presents a simple, effective, and cost-efficient strategy to improve LLM performance by scaling test-time compute. Our strategy builds upon the repeated-sampling-then-voting framework, with a novel twist: incorporating multiple models, even weaker ones, to leverage their complementary strengths that potentially arise from diverse training data and paradigms. By using consistency as a signal, our strategy dynamically switches between models. Theoretical analysis highlights the efficiency and performance advantages of our strategy. Extensive experiments on six datasets demonstrate that our strategy not only outperforms self-consistency and state-of-the-art multi-agent debate approaches, but also significantly reduces inference costs. Additionally, ModelSwitch requires only a few comparable LLMs to achieve optimal performance and can be extended with verification methods, demonstrating the potential of leveraging multiple LLMs in the generation-verification paradigm.","authors":["Jianhao Chen","Zishuo Xun","Bocheng Zhou","Han Qi","Hangfan Zhang","Qiaosheng Zhang","Yang Chen","Wei Hu","Yuzhong Qu","Wanli Ouyang","Shuyue Hu"],"url":"https://arxiv.org/abs/2504.00762"}
{"created":"2025-05-09","title":"Facilitating Instructors-LLM Collaboration for Problem Design in Introductory Programming Classrooms","abstract":"Advancements in Large Language Models (LLMs), such as ChatGPT, offer significant opportunities to enhance instructional support in introductory programming courses. While extensive research has explored the effectiveness of LLMs in supporting student learning, limited studies have examined how these models can assist instructors in designing instructional activities. This work investigates how instructors' expertise in effective activity design can be integrated with LLMs' ability to generate novel and targeted programming problems, facilitating more effective activity creation for programming classrooms. To achieve this, we employ a participatory design approach to develop an instructor-authoring tool that incorporates LLM support, fostering collaboration between instructors and AI in generating programming exercises. This tool also allows instructors to specify common student mistakes and misconceptions, which informs the adaptive feedback generation process. We conduct case studies with three instructors, analyzing how they use our system to design programming problems for their introductory courses. Through these case studies, we assess instructors' perceptions of the usefulness and limitations of LLMs in authoring problem statements for instructional purposes. Additionally, we compare the efficiency, quality, effectiveness, and coverage of designed activities when instructors create problems with and without structured LLM prompting guidelines. Our findings provide insights into the potential of LLMs in enhancing instructor workflows and improving programming education and provide guidelines for designing effective AI-assisted problem-authoring interfaces.","authors":["Muntasir Hoq","Jessica Vandenberg","Shuyin Jiao","Seung Lee","Bradford Mott","Narges Norouzi","James Lester","Bita Akram"],"url":"https://arxiv.org/abs/2504.01259"}
{"created":"2025-05-09","title":"TiC-LM: A Web-Scale Benchmark for Time-Continual LLM Pretraining","abstract":"Large Language Models (LLMs) trained on historical web data inevitably become outdated. We investigate evaluation strategies and update methods for LLMs as new data becomes available. We introduce a web-scale dataset for time-continual pretraining of LLMs derived from 114 dumps of Common Crawl (CC) - orders of magnitude larger than previous continual language modeling benchmarks. We also design time-stratified evaluations across both general CC data and specific domains (Wikipedia, StackExchange, and code documentation) to assess how well various continual learning methods adapt to new data while retaining past knowledge. Our findings demonstrate that, on general CC data, autoregressive meta-schedules combined with a fixed-ratio replay of older data can achieve comparable held-out loss to re-training from scratch, while requiring significantly less computation (2.6x). However, the optimal balance between incorporating new data and replaying old data differs as replay is crucial to avoid forgetting on generic web data but less so on specific domains.","authors":["Jeffrey Li","Mohammadreza Armandpour","Iman Mirzadeh","Sachin Mehta","Vaishaal Shankar","Raviteja Vemulapalli","Samy Bengio","Oncel Tuzel","Mehrdad Farajtabar","Hadi Pouransari","Fartash Faghri"],"url":"https://arxiv.org/abs/2504.02107"}
{"created":"2025-05-09","title":"Shallow AutoEncoding Recommender with Cold Start Handling via Side Features","abstract":"User and item cold starts present significant challenges in industrial applications of recommendation systems. Supplementing user-item interaction data with metadata is a common solution-but often at the cost of introducing additional biases. In this work, we introduce an augmented EASE model, i.e. FEASE, that seamlessly integrates both user and item side information to address these cold start issues. Our straightforward, autoencoder-based method produces a closed-form solution that leverages rich content signals for cold items while refining user representations in data-sparse environments. Importantly, our method strikes a balance by effectively recommending cold start items and handling cold start users without incurring extra bias, and it maintains strong performance in warm settings. Experimental results demonstrate improved recommendation accuracy and robustness compared to previous collaborative filtering approaches. Moreover, our model serves as a strong baseline for future comparative studies.","authors":["Edward DongBo Cui","Lu Zhang","William Ping-hsun Lee"],"url":"https://arxiv.org/abs/2504.02288"}
{"created":"2025-05-09","title":"PPFPL: Cross-silo Privacy-preserving Federated Prototype Learning Against Data Poisoning Attacks on Non-IID Data","abstract":"Privacy-Preserving Federated Learning (PPFL) allows multiple clients to collaboratively train a deep learning model by submitting hidden model updates. Nonetheless, PPFL is vulnerable to data poisoning attacks due to the distributed training nature of clients. Existing solutions have struggled to improve the performance of cross-silo PPFL in poisoned Non-IID data. To address the issues, this paper proposes a privacy-preserving federated prototype learning framework, named PPFPL, which enhances the cross-silo FL performance in poisoned Non-IID data while effectively resisting data poisoning attacks. Specifically, we adopt prototypes as client-submitted model updates to eliminate the impact of tampered data distribution on federated learning. Moreover, we utilize two servers to achieve Byzantine-robust aggregation by secure aggregation protocol, which greatly reduces the impact of malicious clients. Theoretical analyses confirm the convergence of PPFPL, and experimental results on publicly available datasets show that PPFPL is effective for resisting data poisoning attacks with Non-IID conditions.","authors":["Hongliang Zhang","Jiguo Yu","Fenghua Xu","Chunqiang Hu","Yongzhao Zhang","Xiaofen Wang","Zhongyuan Yu","Xiaosong Zhang"],"url":"https://arxiv.org/abs/2504.03173"}
{"created":"2025-05-09","title":"An Efficient GPU-based Implementation for Noise Robust Sound Source Localization","abstract":"Robot audition, encompassing Sound Source Localization (SSL), Sound Source Separation (SSS), and Automatic Speech Recognition (ASR), enables robots and smart devices to acquire auditory capabilities similar to human hearing. Despite their wide applicability, processing multi-channel audio signals from microphone arrays in SSL involves computationally intensive matrix operations, which can hinder efficient deployment on Central Processing Units (CPUs), particularly in embedded systems with limited CPU resources. This paper introduces a GPU-based implementation of SSL for robot audition, utilizing the Generalized Singular Value Decomposition-based Multiple Signal Classification (GSVD-MUSIC), a noise-robust algorithm, within the HARK platform, an open-source software suite. For a 60-channel microphone array, the proposed implementation achieves significant performance improvements. On the Jetson AGX Orin, an embedded device powered by an NVIDIA GPU and ARM Cortex-A78AE v8.2 64-bit CPUs, we observe speedups of 5648.7x for GSVD calculations and 10.7x for the SSL module, while speedups of 4245.1x for GSVD calculation and 17.3x for the entire SSL module on a server configured with an NVIDIA A100 GPU and AMD EPYC 7352 CPUs, making real-time processing feasible for large-scale microphone arrays and providing ample capacity for real-time processing of potential subsequent machine learning or deep learning tasks.","authors":["Zirui Lin","Masayuki Takigahira","Naoya Terakado","Haris Gulzar","Monikka Roslianna Busto","Takeharu Eda","Katsutoshi Itoyama","Kazuhiro Nakadai","Hideharu Amano"],"url":"https://arxiv.org/abs/2504.03373"}
{"created":"2025-05-09","title":"Perils of Label Indeterminacy: A Case Study on Prediction of Neurological Recovery After Cardiac Arrest","abstract":"The design of AI systems to assist human decision-making typically requires the availability of labels to train and evaluate supervised models. Frequently, however, these labels are unknown, and different ways of estimating them involve unverifiable assumptions or arbitrary choices. In this work, we introduce the concept of label indeterminacy and derive important implications in high-stakes AI-assisted decision-making. We present an empirical study in a healthcare context, focusing specifically on predicting the recovery of comatose patients after resuscitation from cardiac arrest. Our study shows that label indeterminacy can result in models that perform similarly when evaluated on patients with known labels, but vary drastically in their predictions for patients where labels are unknown. After demonstrating crucial ethical implications of label indeterminacy in this high-stakes context, we discuss takeaways for evaluation, reporting, and design.","authors":["Jakob Schoeffer","Maria De-Arteaga","Jonathan Elmer"],"url":"https://arxiv.org/abs/2504.04243"}
{"created":"2025-05-09","title":"FindAnything: Open-Vocabulary and Object-Centric Mapping for Robot Exploration in Any Environment","abstract":"Geometrically accurate and semantically expressive map representations have proven invaluable to facilitate robust and safe mobile robot navigation and task planning. Nevertheless, real-time, open-vocabulary semantic understanding of large-scale unknown environments is still an open problem. In this paper we present FindAnything, an open-world mapping and exploration framework that incorporates vision-language information into dense volumetric submaps. Thanks to the use of vision-language features, FindAnything bridges the gap between pure geometric and open-vocabulary semantic information for a higher level of understanding while allowing to explore any environment without the help of any external source of ground-truth pose information. We represent the environment as a series of volumetric occupancy submaps, resulting in a robust and accurate map representation that deforms upon pose updates when the underlying SLAM system corrects its drift, allowing for a locally consistent representation between submaps. Pixel-wise vision-language features are aggregated from efficient SAM (eSAM)-generated segments, which are in turn integrated into object-centric volumetric submaps, providing a mapping from open-vocabulary queries to 3D geometry that is scalable also in terms of memory usage. The open-vocabulary map representation of FindAnything achieves state-of-the-art semantic accuracy in closed-set evaluations on the Replica dataset. This level of scene understanding allows a robot to explore environments based on objects or areas of interest selected via natural language queries. Our system is the first of its kind to be deployed on resource-constrained devices, such as MAVs, leveraging vision-language information for real-world robotic tasks.","authors":["Sebasti\\'an Barbas Laina","Simon Boche","Sotiris Papatheodorou","Simon Schaefer","Jaehyung Jung","Stefan Leutenegger"],"url":"https://arxiv.org/abs/2504.08603"}
{"created":"2025-05-09","title":"VL-Rethinker: Incentivizing Self-Reflection of Vision-Language Models with Reinforcement Learning","abstract":"Recently, slow-thinking systems like GPT-o1 and DeepSeek-R1 have demonstrated great potential in solving challenging problems through explicit reflection. They significantly outperform the best fast-thinking models, such as GPT-4o, on various math and science benchmarks. However, their multimodal reasoning capabilities remain on par with fast-thinking models. For instance, GPT-o1's performance on benchmarks like MathVista, MathVerse, and MathVision is similar to fast-thinking models. In this paper, we aim to enhance the slow-thinking capabilities of vision-language models using reinforcement learning (without relying on distillation) to advance the state of the art. First, we adapt the GRPO algorithm with a novel technique called Selective Sample Replay (SSR) to address the vanishing advantages problem. While this approach yields strong performance, the resulting RL-trained models exhibit limited self-reflection or self-verification. To further encourage slow-thinking, we introduce Forced Rethinking, which appends a rethinking trigger token to the end of rollouts in RL training, explicitly enforcing a self-reflection reasoning step. By combining these two techniques, our model, VL-Rethinker, advances state-of-the-art scores on MathVista, MathVerse to achieve 80.4%, 63.5% respectively. VL-Rethinker also achieves open-source SoTA on multi-disciplinary benchmarks such as MathVision, MMMU-Pro, EMMA, and MEGA-Bench, narrowing the gap with OpenAI-o1. Our empirical results show the effectiveness of our approaches.","authors":["Haozhe Wang","Chao Qu","Zuming Huang","Wei Chu","Fangzhen Lin","Wenhu Chen"],"url":"https://arxiv.org/abs/2504.08837"}
{"created":"2025-05-09","title":"RouterKT: Mixture-of-Experts for Knowledge Tracing","abstract":"Knowledge Tracing (KT) is a fundamental task in Intelligent Tutoring Systems (ITS), which aims to model the dynamic knowledge states of students based on their interaction histories. However, existing KT models often rely on a global forgetting decay mechanism for capturing learning patterns, assuming that students' performance is predominantly influenced by their most recent interactions. Such approaches fail to account for the diverse and complex learning patterns arising from individual differences and varying learning stages. To address this limitation, we propose RouterKT, a novel Mixture-of-Experts (MoE) architecture designed to capture heterogeneous learning patterns by enabling experts to specialize in different patterns without any handcrafted learning pattern bias such as forgetting decay. Specifically, RouterKT introduces a \\textbf{person-wise routing mechanism} to effectively model individual-specific learning behaviors and employs \\textbf{multi-heads as experts} to enhance the modeling of complex and diverse patterns. Comprehensive experiments on ten benchmark datasets demonstrate that RouterKT exhibits significant flexibility and improves the performance of various KT backbone models, with a maximum average AUC improvement of 3.29\\% across different backbones and datasets, outperforming other state-of-the-art models. Moreover, RouterKT demonstrates consistently superior inference efficiency compared to existing approaches based on handcrafted learning pattern bias, highlighting its usability for real-world educational applications. The source code is available at https://github.com/ringotc/RouterKT.git.","authors":["Han Liao","Shuaishuai Zu"],"url":"https://arxiv.org/abs/2504.08989"}
{"created":"2025-05-09","title":"Type-Constrained Code Generation with Language Models","abstract":"Large language models (LLMs) have achieved notable success in code generation. However, they still frequently produce uncompilable output because their next-token inference procedure does not model formal aspects of code. Although constrained decoding is a promising approach to alleviate this issue, it has only been applied to handle either domain-specific languages or syntactic features of general-purpose programming languages. However, LLMs frequently generate code with typing errors, which are beyond the domain of syntax and generally hard to adequately constrain. To address this challenge, we introduce a type-constrained decoding approach that leverages type systems to guide code generation. For this purpose, we develop novel prefix automata and a search over inhabitable types, forming a sound approach to enforce well-typedness on LLM-generated code. We formalize our approach on a foundational simply-typed language and extend it to TypeScript to demonstrate practicality. Our evaluation on the HumanEval and MBPP datasets shows that our approach reduces compilation errors by more than half and significantly increases functional correctness in code synthesis, translation, and repair tasks across LLMs of various sizes and model families, including state-of-the-art open-weight models with more than 30B parameters. The results demonstrate the generality and effectiveness of our approach in constraining LLM code generation with formal rules of type systems.","authors":["Niels M\\\"undler","Jingxuan He","Hao Wang","Koushik Sen","Dawn Song","Martin Vechev"],"url":"https://arxiv.org/abs/2504.09246"}
{"created":"2025-05-09","title":"A highly maneuverable flying squirrel drone with agility-improving foldable wings","abstract":"Drones, like most airborne aerial vehicles, face inherent disadvantages in achieving agile flight due to their limited thrust capabilities. These physical constraints cannot be fully addressed through advancements in control algorithms alone. Drawing inspiration from the winged flying squirrel, this paper proposes a highly maneuverable drone equipped with agility-enhancing foldable wings. By leveraging collaborative control between the conventional propeller system and the foldable wings-coordinated through the Thrust-Wing Coordination Control (TWCC) framework-the controllable acceleration set is expanded, enabling the generation of abrupt vertical forces that are unachievable with traditional wingless drones. The complex aerodynamics of the foldable wings are modeled using a physics-assisted recurrent neural network (paRNN), which calibrates the angle of attack (AOA) to align with the real aerodynamic behavior of the wings. The additional air resistance generated by appropriately deploying these wings significantly improves the tracking performance of the proposed \"flying squirrel\" drone. The model is trained on real flight data and incorporates flat-plate aerodynamic principles. Experimental results demonstrate that the proposed flying squirrel drone achieves a 13.1% improvement in tracking performance, as measured by root mean square error (RMSE), compared to a conventional wingless drone. A demonstration video is available on YouTube: https://youtu.be/O8nrip18azY.","authors":["Dohyeon Lee","Jun-Gill Kang","Soohee Han"],"url":"https://arxiv.org/abs/2504.09609"}
{"created":"2025-05-09","title":"ReadMe.LLM: A Framework to Help LLMs Understand Your Library","abstract":"Large Language Models (LLMs) often struggle with code generation tasks involving niche software libraries. Existing code generation techniques with only human-oriented documentation can fail -- even when the LLM has access to web search and the library is documented online. To address this challenge, we propose ReadMe$.$LLM, LLM-oriented documentation for software libraries. By attaching the contents of ReadMe$.$LLM to a query, performance consistently improves to near-perfect accuracy, with one case study demonstrating up to 100% success across all tested models. We propose a software development lifecycle where LLM-specific documentation is maintained alongside traditional software updates. In this study, we present two practical applications of the ReadMe$.$LLM idea with diverse software libraries, highlighting that our proposed approach could generalize across programming domains.","authors":["Sandya Wijaya","Jacob Bolano","Alejandro Gomez Soteres","Shriyanshu Kode","Yue Huang","Anant Sahai"],"url":"https://arxiv.org/abs/2504.09798"}
{"created":"2025-05-09","title":"GeoUni: A Unified Model for Generating Geometry Diagrams, Problems and Problem Solutions","abstract":"We propose GeoUni, the first unified geometry expert model capable of generating problem solutions and diagrams within a single framework in a way that enables the creation of unique and individualized geometry problems. Traditionally, solving geometry problems and generating diagrams have been treated as separate tasks in machine learning, with no models successfully integrating both to support problem creation. However, we believe that mastery in geometry requires frictionless integration of all of these skills, from solving problems to visualizing geometric relationships, and finally, crafting tailored problems. Our extensive experiments demonstrate that GeoUni, with only 1.5B parameters, achieves performance comparable to larger models such as DeepSeek-R1 with 671B parameters in geometric reasoning tasks. GeoUni also excels in generating precise geometric diagrams, surpassing both text-to-image models and unified models, including the GPT-4o image generation. Most importantly, GeoUni is the only model capable of successfully generating textual problems with matching diagrams based on specific knowledge points, thus offering a wider range of capabilities that extend beyond current models.","authors":["Jo-Ku Cheng","Zeren Zhang","Ran Chen","Jingyang Deng","Ziran Qin","Jinwen Ma"],"url":"https://arxiv.org/abs/2504.10146"}
{"created":"2025-05-09","title":"Search is All You Need for Few-shot Anomaly Detection","abstract":"Few-shot anomaly detection (FSAD) has emerged as a crucial yet challenging task in industrial inspection, where normal distribution modeling must be accomplished with only a few normal images. While existing approaches typically employ multi-modal foundation models combining language and vision modalities for prompt-guided anomaly detection, these methods often demand sophisticated prompt engineering and extensive manual tuning. In this paper, we demonstrate that a straightforward nearest-neighbor search framework can surpass state-of-the-art performance in both single-class and multi-class FSAD scenarios. Our proposed method, VisionAD, consists of four simple yet essential components: (1) scalable vision foundation models that extract universal and discriminative features; (2) dual augmentation strategies - support augmentation to enhance feature matching adaptability and query augmentation to address the oversights of single-view prediction; (3) multi-layer feature integration that captures both low-frequency global context and high-frequency local details with minimal computational overhead; and (4) a class-aware visual memory bank enabling efficient one-for-all multi-class detection. Extensive evaluations across MVTec-AD, VisA, and Real-IAD benchmarks demonstrate VisionAD's exceptional performance. Using only 1 normal images as support, our method achieves remarkable image-level AUROC scores of 97.4%, 94.8%, and 70.8% respectively, outperforming current state-of-the-art approaches by significant margins (+1.6%, +3.2%, and +1.4%). The training-free nature and superior few-shot capabilities of VisionAD make it particularly appealing for real-world applications where samples are scarce or expensive to obtain. Code is available at https://github.com/Qiqigeww/VisionAD.","authors":["Qishan Wang","Jia Guo","Shuyong Gao","Haofen Wang","Li Xiong","Junjie Hu","Hanqi Guo","Wenqiang Zhang"],"url":"https://arxiv.org/abs/2504.11895"}
{"created":"2025-05-09","title":"Stochastic Quadrature Rules for Solving PDEs using Neural Networks","abstract":"We examine the challenges associated with numerical integration when applying Neural Networks to solve Partial Differential Equations (PDEs). We specifically investigate the Deep Ritz Method (DRM), chosen for its practical applicability and known sensitivity to integration inaccuracies. Our research demonstrates that both standard deterministic integration techniques and biased stochastic quadrature methods can lead to incorrect solutions. In contrast, employing high-order, unbiased stochastic quadrature rules defined on integration meshes in low dimensions is shown to significantly enhance convergence rates at a comparable computational expense with respect to low-order methods like Monte Carlo. Additionally, we introduce novel stochastic quadrature approaches designed for triangular and tetrahedral mesh elements, offering increased adaptability for handling complex geometric domains. We highlight that the variance inherent in the stochastic gradient acts as a bottleneck for convergence. Furthermore, we observe that for gradient-based optimisation, the crucial factor is the accurate integration of the gradient, rather than just minimizing the quadrature error of the loss function itself.","authors":["Jamie M. Taylor","David Pardo"],"url":"https://arxiv.org/abs/2504.11976"}
{"created":"2025-05-09","title":"Building Trustworthy Multimodal AI: A Review of Fairness, Transparency, and Ethics in Vision-Language Tasks","abstract":"Objective: This review explores the trustworthiness of multimodal artificial intelligence (AI) systems, specifically focusing on vision-language tasks. It addresses critical challenges related to fairness, transparency, and ethical implications in these systems, providing a comparative analysis of key tasks such as Visual Question Answering (VQA), image captioning, and visual dialogue. Background: Multimodal models, particularly vision-language models, enhance artificial intelligence (AI) capabilities by integrating visual and textual data, mimicking human learning processes. Despite significant advancements, the trustworthiness of these models remains a crucial concern, particularly as AI systems increasingly confront issues regarding fairness, transparency, and ethics. Methods: This review examines research conducted from 2017 to 2024 focusing on forenamed core vision-language tasks. It employs a comparative approach to analyze these tasks through the lens of trustworthiness, underlining fairness, explainability, and ethics. This study synthesizes findings from recent literature to identify trends, challenges, and state-of-the-art solutions. Results: Several key findings were highlighted. Transparency: Explainability of vision language tasks is important for user trust. Techniques, such as attention maps and gradient-based methods, have successfully addressed this issue. Fairness: Bias mitigation in VQA and visual dialogue systems is essential for ensuring unbiased outcomes across diverse demographic groups. Ethical Implications: Addressing biases in multilingual models and ensuring ethical data handling is critical for the responsible deployment of vision-language systems. Conclusion: This study underscores the importance of integrating fairness, transparency, and ethical considerations in developing vision-language models within a unified framework.","authors":["Mohammad Saleh","Azadeh Tabatabaei"],"url":"https://arxiv.org/abs/2504.13199"}
{"created":"2025-05-09","title":"Inverse Inference on Cooperative Control of Networked Dynamical Systems","abstract":"Recent years have witnessed the rapid advancement of understanding the control mechanism of networked dynamical systems (NDSs), which are governed by components such as nodal dynamics and topology. This paper reveals that the critical components in continuous-time state feedback cooperative control of NDSs can be inferred merely from discrete observations. In particular, we advocate a bi-level inference framework to estimate the global closed-loop system and extract the components, respectively. The novelty lies in bridging the gap from discrete observations to the continuous-time model and effectively decoupling the concerned components. Specifically, in the first level, we design a causality-based estimator for the discrete-time closed-loop system matrix, which can achieve asymptotically unbiased performance when the NDS is stable. In the second level, we introduce a matrix logarithm based method to recover the continuous-time counterpart matrix, providing new sampling period guarantees and establishing the recovery error bound. By utilizing graph properties of the NDS, we develop least square based procedures to decouple the concerned components with up to a scalar ambiguity. Furthermore, we employ inverse optimal control techniques to reconstruct the objective function driving the control process, deriving necessary conditions for the solutions. Numerical simulations demonstrate the effectiveness of the proposed method.","authors":["Yushan Li","Jianping He","Dimos V. Dimarogonas"],"url":"https://arxiv.org/abs/2504.13701"}
{"created":"2025-05-09","title":"LLM-Driven Usefulness Judgment for Web Search Evaluation","abstract":"Evaluation is fundamental in optimizing search experiences and supporting diverse user intents in Information Retrieval (IR). Traditional search evaluation methods primarily rely on relevance labels, which assess how well retrieved documents match a user's query. However, relevance alone fails to capture a search system's effectiveness in helping users achieve their search goals, making usefulness a critical evaluation criterion. In this paper, we explore an alternative approach: LLM-generated usefulness labels, which incorporate both implicit and explicit user behavior signals to evaluate document usefulness. We propose Task-aware Rubric-based Usefulness Evaluation (TRUE), a rubric-driven evaluation method that employs iterative sampling and reasoning to model complex search behavior patterns. Our findings show that (i) LLMs can generate moderate usefulness labels by leveraging comprehensive search session history incorporating personalization and contextual understanding, and (ii) fine-tuned LLMs improve usefulness judgments when provided with structured search session contexts. Additionally, we examine whether LLMs can distinguish between relevance and usefulness, particularly in cases where this divergence impacts search success. We also conduct an ablation study to identify key metrics for accurate usefulness label generation, optimizing for token efficiency and cost-effectiveness in real-world applications. This study advances LLM-based usefulness evaluation by refining key user metrics, exploring LLM-generated label reliability, and ensuring feasibility for large-scale search systems.","authors":["Mouly Dewan","Jiqun Liu","Aditya Gautam","Chirag Shah"],"url":"https://arxiv.org/abs/2504.14401"}
{"created":"2025-05-09","title":"Algebraic Barriers to Halving Algorithmic Information Quantities in Correlated Strings","abstract":"We study the possibility of scaling down algorithmic information quantities in tuples of correlated strings. In particular, we address a question raised by Alexander Shen: whether, for any triple of strings \\((a, b, c)\\), there exists a string \\(z\\) such that each of the values of conditional Kolmogorov complexity \\(C(a|z), C(b|z), C(c|z)\\) is approximately half of the corresponding unconditional Kolmogorov complexity. We provide a negative answer to this question by constructing a triple \\((a, b, c)\\) for which no such string \\(z\\) exists. Our construction is based on combinatorial properties of incidences in finite projective planes and relies on recent bounds on point-line incidences over prime fields. As an application, we show that this impossibility implies lower bounds on the communication complexity of secret key agreement protocols in certain settings. These results reveal algebraic obstructions to efficient information exchange and highlight a separation in the information-theoretic behavior of projective planes over fields with and without proper subfields.","authors":["Andrei Romashchenko"],"url":"https://arxiv.org/abs/2504.14408"}
{"created":"2025-05-09","title":"Advancing Embodied Agent Security: From Safety Benchmarks to Input Moderation","abstract":"Embodied agents exhibit immense potential across a multitude of domains, making the assurance of their behavioral safety a fundamental prerequisite for their widespread deployment. However, existing research predominantly concentrates on the security of general large language models, lacking specialized methodologies for establishing safety benchmarks and input moderation tailored to embodied agents. To bridge this gap, this paper introduces a novel input moderation framework, meticulously designed to safeguard embodied agents. This framework encompasses the entire pipeline, including taxonomy definition, dataset curation, moderator architecture, model training, and rigorous evaluation. Notably, we introduce EAsafetyBench, a meticulously crafted safety benchmark engineered to facilitate both the training and stringent assessment of moderators specifically designed for embodied agents. Furthermore, we propose Pinpoint, an innovative prompt-decoupled input moderation scheme that harnesses a masked attention mechanism to effectively isolate and mitigate the influence of functional prompts on moderation tasks. Extensive experiments conducted on diverse benchmark datasets and models validate the feasibility and efficacy of the proposed approach. The results demonstrate that our methodologies achieve an impressive average detection accuracy of 94.58%, surpassing the performance of existing state-of-the-art techniques, alongside an exceptional moderation processing time of merely 0.002 seconds per instance.","authors":["Ning Wang","Zihan Yan","Weiyang Li","Chuan Ma","He Chen","Tao Xiang"],"url":"https://arxiv.org/abs/2504.15699"}
{"created":"2025-05-09","title":"Federated EndoViT: Pretraining Vision Transformers via Federated Learning on Endoscopic Image Collections","abstract":"Purpose: In this study, we investigate the training of foundation models using federated learning to address data-sharing limitations and enable collaborative model training without data transfer for minimally invasive surgery. Methods: Inspired by the EndoViT study, we adapt the Masked Autoencoder for federated learning, enhancing it with adaptive Sharpness-Aware Minimization (FedSAM) and Stochastic Weight Averaging (SWA). Our model is pretrained on the Endo700k dataset collection and later fine-tuned and evaluated for tasks such as Semantic Segmentation, Action Triplet Recognition, and Surgical Phase Recognition. Results: Our findings demonstrate that integrating adaptive FedSAM into the federated MAE approach improves pretraining, leading to a reduction in reconstruction loss per patch. The application of FL-EndoViT in surgical downstream tasks results in performance comparable to CEN-EndoViT. Furthermore, FL-EndoViT exhibits advantages over CEN-EndoViT in surgical scene segmentation when data is limited and in action triplet recognition when large datasets are used. Conclusion: These findings highlight the potential of federated learning for privacy-preserving training of surgical foundation models, offering a robust and generalizable solution for surgical data science. Effective collaboration requires adapting federated learning methods, such as the integration of FedSAM, which can accommodate the inherent data heterogeneity across institutions. In future, exploring FL in video-based models may enhance these capabilities by incorporating spatiotemporal dynamics crucial for real-world surgical environments.","authors":["Max Kirchner","Alexander C. Jenke","Sebastian Bodenstedt","Fiona R. Kolbinger","Oliver L. Saldanha","Jakob N. Kather","Martin Wagner","Stefanie Speidel"],"url":"https://arxiv.org/abs/2504.16612"}
{"created":"2025-05-09","title":"Unified Attacks to Large Language Model Watermarks: Spoofing and Scrubbing in Unauthorized Knowledge Distillation","abstract":"Watermarking has emerged as a critical technique for combating misinformation and protecting intellectual property in large language models (LLMs). A recent discovery, termed watermark radioactivity, reveals that watermarks embedded in teacher models can be inherited by student models through knowledge distillation. On the positive side, this inheritance allows for the detection of unauthorized knowledge distillation by identifying watermark traces in student models. However, the robustness of watermarks against scrubbing attacks and their unforgeability in the face of spoofing attacks under unauthorized knowledge distillation remain largely unexplored. Existing watermark attack methods either assume access to model internals or fail to simultaneously support both scrubbing and spoofing attacks. In this work, we propose Contrastive Decoding-Guided Knowledge Distillation (CDG-KD), a unified framework that enables bidirectional attacks under unauthorized knowledge distillation. Our approach employs contrastive decoding to extract corrupted or amplified watermark texts via comparing outputs from the student model and weakly watermarked references, followed by bidirectional distillation to train new student models capable of watermark removal and watermark forgery, respectively. Extensive experiments show that CDG-KD effectively performs attacks while preserving the general performance of the distilled model. Our findings underscore critical need for developing watermarking schemes that are robust and unforgeable.","authors":["Xin Yi","Shunfan Zheng","Linlin Wang","Xiaoling Wang","Liang He"],"url":"https://arxiv.org/abs/2504.17480"}
{"created":"2025-05-09","title":"On Multivariate Financial Time Series Classification","abstract":"This article investigates the use of Machine Learning and Deep Learning models in multivariate time series analysis within financial markets. It compares small and big data approaches, focusing on their distinct challenges and the benefits of scaling. Traditional methods such as SVMs are contrasted with modern architectures like ConvTimeNet. The results show the importance of using and understanding Big Data in depth in the analysis and prediction of financial time series.","authors":["Gr\\'egory Bournassenko"],"url":"https://arxiv.org/abs/2504.17664"}
{"created":"2025-05-09","title":"The Marco Polo Problem: A Combinatorial Approach to Geometric Localization","abstract":"We introduce and study the Marco Polo problem, which is a combinatorial approach to geometric localization. In this problem, we are told there are one or more points of interest (POIs) within distance $n$ of the origin that we wish to localize. Given a mobile search point, $\\Delta$, that is initially at the origin, a localization algorithm is a strategy to move $\\Delta$ to be within a distance of $1$ of a POI. In the combinatorial localization problem we study, the only tool we can use is reminiscent of the children's game, \"Marco Polo,\" in that $\\Delta$ can issue a probe signal out a specified distance, $d$, and the search algorithm learns whether or not there is a POI within distance $d$ of $\\Delta$. For example, we could imagine that POIs are one or more hikers lost in a forest and we need to design a search-and-rescue (SAR) strategy to find them using radio signal probes to a response device that hikers carry. Unlike other known localization algorithms, probe responses do not inform our search algorithm of the direction or distance to a POI. The optimization problem is to minimize the number of probes and/or POI responses, as well as possibly minimizing the distance traveled by $\\Delta$. We describe a number of efficient combinatorial Marco Polo localization strategies and we analyze each one in terms of the size, $n$, of the search domain. Moreover, we derive strong bounds for the constant factors for the search costs for our algorithms, which in some cases involve computer-assisted proofs. We also show how to extend these strategies to find all POIs using a simple, memoryless search algorithm, traveling a distance that is $\\mathcal{O}(\\log{k})$-competitive with the optimal traveling salesperson (TSP) tour for $k$ POIs.","authors":["Ofek Gila (University of California","Irvine)","Michael T. Goodrich (University of California","Irvine)","Zahra Hadizadeh (University of Rochester)","Daniel S. Hirschberg (University of California","Irvine)","Shayan Taherijam (University of California","Irvine)"],"url":"https://arxiv.org/abs/2504.17955"}
{"created":"2025-05-09","title":"MultiMind: Enhancing Werewolf Agents with Multimodal Reasoning and Theory of Mind","abstract":"Large Language Model (LLM) agents have demonstrated impressive capabilities in social deduction games (SDGs) like Werewolf, where strategic reasoning and social deception are essential. However, current approaches remain limited to textual information, ignoring crucial multimodal cues such as facial expressions and tone of voice that humans naturally use to communicate. Moreover, existing SDG agents primarily focus on inferring other players' identities without modeling how others perceive themselves or fellow players. To address these limitations, we use One Night Ultimate Werewolf (ONUW) as a testbed and present MultiMind, the first framework integrating multimodal information into SDG agents. MultiMind processes facial expressions and vocal tones alongside verbal content, while employing a Theory of Mind (ToM) model to represent each player's suspicion levels toward others. By combining this ToM model with Monte Carlo Tree Search (MCTS), our agent identifies communication strategies that minimize suspicion directed at itself. Through comprehensive evaluation in both agent-versus-agent simulations and studies with human players, we demonstrate MultiMind's superior performance in gameplay. Our work presents a significant advancement toward LLM agents capable of human-like social reasoning across multimodal domains.","authors":["Zheng Zhang","Nuoqian Xiao","Qi Chai","Deheng Ye","Hao Wang"],"url":"https://arxiv.org/abs/2504.18039"}
{"created":"2025-05-09","title":"Optimal tables for asymmetric numeral systems","abstract":"We present several algorithms to generate tables for asymmetric numeral systems and prove that they are optimal in terms of discrepancy. In turn, this gives rise to the strongest proven bound on entropy loss. We further give improved theoretical bounds for the entropy loss in tabled asymmetric numeral systems and a brief empirical evaluation of the stream variant.","authors":["Raphael S. Steiner","Mirko De Vita","Endri Bezati"],"url":"https://arxiv.org/abs/2504.18541"}
{"created":"2025-05-09","title":"An End-to-End Framework for Optimizing Foot Trajectory and Force in Dry Adhesion Legged Wall-Climbing Robots","abstract":"Foot trajectory planning for dry adhesion legged climbing robots presents challenges, as the phases of foot detachment, swing, and adhesion significantly influence the adhesion and detachment forces essential for stable climbing. To tackle this, an end-to-end foot trajectory and force optimization framework (FTFOF) is proposed, which optimizes foot adhesion and detachment forces through trajectory adjustments. This framework accepts general foot trajectory constraints and user-defined parameters as input, ultimately producing an optimal single foot trajectory. It integrates three-segment $C^2$ continuous Bezier curves, tailored to various foot structures, enabling the generation of effective climbing trajectories. A dilate-based GRU predictive model establishes the relationship between foot trajectories and the corresponding foot forces. Multi-objective optimization algorithms, combined with a redundancy hierarchical strategy, identify the most suitable foot trajectory for specific tasks, thereby ensuring optimal performance across detachment force, adhesion force and vibration amplitude. Experimental validation on the quadruped climbing robot MST-M3F showed that, compared to commonly used trajectories in existing legged climbing robots, the proposed framework achieved reductions in maximum detachment force by 28 \\%, vibration amplitude by 82 \\%, which ensures the stable climbing of dry adhesion legged climbing robots.","authors":["Jichun Xiao","Jiawei Nie","Lina Hao","Zhi Li"],"url":"https://arxiv.org/abs/2504.19448"}
{"created":"2025-05-09","title":"Accurate and Diverse LLM Mathematical Reasoning via Automated PRM-Guided GFlowNets","abstract":"Achieving both accuracy and diverse reasoning remains challenging for Large Language Models (LLMs) in complex domains like mathematics. A key bottleneck is evaluating intermediate reasoning steps to guide generation without costly human annotations. To address this, we first introduce a novel Process Reward Model (PRM) trained automatically using Monte Carlo Tree Search coupled with a similarity-based data augmentation technique, effectively capturing step-level reasoning quality. Leveraging this PRM, we then adapt Generative Flow Networks (GFlowNets) to operate at the reasoning step level. Unlike traditional reinforcement learning focused on maximizing a single reward, GFlowNets naturally sample diverse, high-quality solutions proportional to their rewards, as measured by our PRM. Empirical evaluation shows strong improvements in both accuracy and solution diversity on challenging mathematical benchmarks (e.g., +2.59% absolute accuracy on MATH Level 5 for Llama3.2-3B), with effective generalization to unseen datasets (+9.4% absolute on SAT MATH). Our work demonstrates the potential of PRM-guided, step-level GFlowNets for developing more robust and versatile mathematical reasoning in LLMs.","authors":["Adam Younsi","Abdalgader Abubaker","Mohamed El Amine Seddik","Hakim Hacid","Salem Lahlou"],"url":"https://arxiv.org/abs/2504.19981"}
{"created":"2025-05-09","title":"Approximate Lifted Model Construction","abstract":"Probabilistic relational models such as parametric factor graphs enable efficient (lifted) inference by exploiting the indistinguishability of objects. In lifted inference, a representative of indistinguishable objects is used for computations. To obtain a relational (i.e., lifted) representation, the Advanced Colour Passing (ACP) algorithm is the state of the art. The ACP algorithm, however, requires underlying distributions, encoded as potential-based factorisations, to exactly match to identify and exploit indistinguishabilities. Hence, ACP is unsuitable for practical applications where potentials learned from data inevitably deviate even if associated objects are indistinguishable. To mitigate this problem, we introduce the $\\varepsilon$-Advanced Colour Passing ($\\varepsilon$-ACP) algorithm, which allows for a deviation of potentials depending on a hyperparameter $\\varepsilon$. $\\varepsilon$-ACP efficiently uncovers and exploits indistinguishabilities that are not exact. We prove that the approximation error induced by $\\varepsilon$-ACP is strictly bounded and our experiments show that the approximation error is close to zero in practice.","authors":["Malte Luttermann","Jan Speller","Marcel Gehrke","Tanya Braun","Ralf M\\\"oller","Mattis Hartwig"],"url":"https://arxiv.org/abs/2504.20784"}
{"created":"2025-05-09","title":"Theoretical Foundations for Semantic Cognition in Artificial Intelligence","abstract":"This monograph presents a modular cognitive architecture for artificial intelligence grounded in the formal modeling of belief as structured semantic state. Belief states are defined as dynamic ensembles of linguistic expressions embedded within a navigable manifold, where operators enable assimilation, abstraction, nullification, memory, and introspection. Drawing from philosophy, cognitive science, and neuroscience, we develop a layered framework that enables self-regulating epistemic agents capable of reflective, goal-directed thought. At the core of this framework is the epistemic vacuum: a class of semantically inert cognitive states that serves as the conceptual origin of belief space. From this foundation, the Null Tower arises as a generative structure recursively built through internal representational capacities. The theoretical constructs are designed to be implementable in both symbolic and neural systems, including large language models, hybrid agents, and adaptive memory architectures. This work offers a foundational substrate for constructing agents that reason, remember, and regulate their beliefs in structured, interpretable ways.","authors":["Sebastian Dumbrava"],"url":"https://arxiv.org/abs/2504.21218"}
{"created":"2025-05-09","title":"Nexus-Gen: A Unified Model for Image Understanding, Generation, and Editing","abstract":"Unified multimodal large language models (MLLMs) aim to integrate multimodal understanding and generation abilities through a single framework. Despite their versatility, existing open-source unified models exhibit performance gaps against domain-specific architectures. To bridge this gap, we present Nexus-Gen, a unified model that synergizes the language reasoning capabilities of LLMs with the image synthesis power of diffusion models. To align the embedding space of the LLM and diffusion model, we conduct a dual-phase alignment training process. (1) The autoregressive LLM learns to predict image embeddings conditioned on multimodal inputs, while (2) the vision decoder is trained to reconstruct high-fidelity images from these embeddings. During training the LLM, we identified a critical discrepancy between the autoregressive paradigm's training and inference phases, where error accumulation in continuous embedding space severely degrades generation quality. To avoid this issue, we introduce a prefilled autoregression strategy that prefills input sequence with position-embedded special tokens instead of continuous embeddings. Through dual-phase training, Nexus-Gen has developed the integrated capability to comprehensively address the image understanding, generation and editing tasks. All models, datasets, and codes are published at https://github.com/modelscope/Nexus-Gen.git to facilitate further advancements across the field.","authors":["Hong Zhang","Zhongjie Duan","Xingjun Wang","Yuze Zhao","Weiyi Lu","Zhipeng Di","Yixuan Xu","Yingda Chen","Yu Zhang"],"url":"https://arxiv.org/abs/2504.21356"}
{"created":"2025-05-09","title":"SeriesBench: A Benchmark for Narrative-Driven Drama Series Understanding","abstract":"With the rapid development of Multi-modal Large Language Models (MLLMs), an increasing number of benchmarks have been established to evaluate the video understanding capabilities of these models. However, these benchmarks focus on standalone videos and mainly assess \"visual elements\" like human actions and object states. In reality, contemporary videos often encompass complex and continuous narratives, typically presented as a series. To address this challenge, we propose SeriesBench, a benchmark consisting of 105 carefully curated narrative-driven series, covering 28 specialized tasks that require deep narrative understanding. Specifically, we first select a diverse set of drama series spanning various genres. Then, we introduce a novel long-span narrative annotation method, combined with a full-information transformation approach to convert manual annotations into diverse task formats. To further enhance model capacity for detailed analysis of plot structures and character relationships within series, we propose a novel narrative reasoning framework, PC-DCoT. Extensive results on SeriesBench indicate that existing MLLMs still face significant challenges in understanding narrative-driven series, while PC-DCoT enables these MLLMs to achieve performance improvements. Overall, our SeriesBench and PC-DCoT highlight the critical necessity of advancing model capabilities to understand narrative-driven series, guiding the future development of MLLMs. SeriesBench is publicly available at https://github.com/zackhxn/SeriesBench-CVPR2025.","authors":["Chenkai Zhang","Yiming Lei","Zeming Liu","Haitao Leng","Shaoguo Liu","Tingting Gao","Qingjie Liu","Yunhong Wang"],"url":"https://arxiv.org/abs/2504.21435"}
{"created":"2025-05-09","title":"Identifying Critical Dependencies in Large-Scale Continuous Software Engineering","abstract":"Continuous Software Engineering (CSE) is widely adopted in the industry, integrating practices such as Continuous Integration and Continuous Deployment (CI/CD). Beyond technical aspects, CSE also encompasses business activities like continuous planning, budgeting, and operational processes. Coordinating these activities in large-scale product development involves multiple stakeholders, increasing complexity. This study aims to address this complexity by identifying and analyzing critical dependencies in large-scale CSE. Based on 17 semi-structured interviews conducted at two Nordic fintech companies, our preliminary findings indicate that dependencies between software teams and support functions, as well as between software teams and external entities, are the primary sources of delays and bottlenecks. As a next step, we plan to further refine our understanding of critical dependencies in large-scale CSE and explore coordination mechanisms that can better support software development teams in managing these challenges.","authors":["Anastasiia Tkalich","Eriks Klotins","Nils Brede Moe"],"url":"https://arxiv.org/abs/2504.21437"}
{"created":"2025-05-09","title":"DGSolver: Diffusion Generalist Solver with Universal Posterior Sampling for Image Restoration","abstract":"Diffusion models have achieved remarkable progress in universal image restoration. While existing methods speed up inference by reducing sampling steps, substantial step intervals often introduce cumulative errors. Moreover, they struggle to balance the commonality of degradation representations and restoration quality. To address these challenges, we introduce \\textbf{DGSolver}, a diffusion generalist solver with universal posterior sampling. We first derive the exact ordinary differential equations for generalist diffusion models and tailor high-order solvers with a queue-based accelerated sampling strategy to improve both accuracy and efficiency. We then integrate universal posterior sampling to better approximate manifold-constrained gradients, yielding a more accurate noise estimation and correcting errors in inverse inference. Extensive experiments show that DGSolver outperforms state-of-the-art methods in restoration accuracy, stability, and scalability, both qualitatively and quantitatively. Code and models will be available at https://github.com/MiliLab/DGSolver.","authors":["Hebaixu Wang","Jing Zhang","Haonan Guo","Di Wang","Jiayi Ma","Bo Du"],"url":"https://arxiv.org/abs/2504.21487"}
{"created":"2025-05-09","title":"Sibuya probability distributions and numerical evaluation of fractional-order operators","abstract":"In this work we explore the Sibuya discrete probability distribution, which serves as the basis and the main instrument for numerical simulations of Grunwald--Letnikov fractional derivatives by the Monte Carlo method. We provide three methods for simulating the Sibuya distribution. We also introduce the Sibuya-like sieved probability distributions, and apply them to numerical fractional-order differentiation. Additionally, we use the Monte Carlo method for evaluating fractional-order integrals, and suggest the notion of the continuous Sibuya probability distribution. The developed methods and tools are illustrated by examples of computation. We provide the MATLAB toolboxes for simulation of the Sibuya probability distribution, and for the numerical examples.","authors":["Nikolai Leonenko","Igor Podlubny"],"url":"https://arxiv.org/abs/2504.21523"}
{"created":"2025-05-09","title":"REHEARSE-3D: A Multi-modal Emulated Rain Dataset for 3D Point Cloud De-raining","abstract":"Sensor degradation poses a significant challenge in autonomous driving. During heavy rainfall, the interference from raindrops can adversely affect the quality of LiDAR point clouds, resulting in, for instance, inaccurate point measurements. This, in turn, can potentially lead to safety concerns if autonomous driving systems are not weather-aware, i.e., if they are unable to discern such changes. In this study, we release a new, large-scale, multi-modal emulated rain dataset, REHEARSE-3D, to promote research advancements in 3D point cloud de-raining. Distinct from the most relevant competitors, our dataset is unique in several respects. First, it is the largest point-wise annotated dataset, and second, it is the only one with high-resolution LiDAR data (LiDAR-256) enriched with 4D Radar point clouds logged in both daytime and nighttime conditions in a controlled weather environment. Furthermore, REHEARSE-3D involves rain-characteristic information, which is of significant value not only for sensor noise modeling but also for analyzing the impact of weather at a point level. Leveraging REHEARSE-3D, we benchmark raindrop detection and removal in fused LiDAR and 4D Radar point clouds. Our comprehensive study further evaluates the performance of various statistical and deep-learning models. Upon publication, the dataset and benchmark models will be made publicly available at: https://sporsho.github.io/REHEARSE3D.","authors":["Abu Mohammed Raisuddin","Jesper Holmblad","Hamed Haghighi","Yuri Poledna","Maikol Funk Drechsler","Valentina Donzella","Eren Erdal Aksoy"],"url":"https://arxiv.org/abs/2504.21699"}
{"created":"2025-05-09","title":"Data Therapist: Eliciting Domain Knowledge from Subject Matter Experts Using Large Language Models","abstract":"Effective data visualization requires not only technical proficiency but also a deep understanding of the domain-specific context in which data exists. This context often includes tacit knowledge about data provenance, quality, and intended use, which is rarely explicit in the dataset itself. We present the Data Therapist, a web-based tool that helps domain experts externalize this implicit knowledge through a mixed-initiative process combining iterative Q&amp;A with interactive annotation. Powered by a large language model, the system analyzes user-supplied datasets, prompts users with targeted questions, and allows annotation at varying levels of granularity. The resulting structured knowledge base can inform both human and automated visualization design. We evaluated the tool in a qualitative study involving expert pairs from Molecular Biology, Accounting, Political Science, and Usable Security. The study revealed recurring patterns in how experts reason about their data and highlights areas where AI support can improve visualization design.","authors":["Sungbok Shin","Hyeon Jeon","Sanghyun Hong","Niklas Elmqvist"],"url":"https://arxiv.org/abs/2505.00455"}
{"created":"2025-05-09","title":"Large Language Models Understanding: an Inherent Ambiguity Barrier","abstract":"A lively ongoing debate is taking place, since the extraordinary emergence of Large Language Models (LLMs) with regards to their capability to understand the world and capture the meaning of the dialogues in which they are involved. Arguments and counter-arguments have been proposed based upon thought experiments, anecdotal conversations between LLMs and humans, statistical linguistic analysis, philosophical considerations, and more. In this brief paper we present a counter-argument based upon a thought experiment and semi-formal considerations leading to an inherent ambiguity barrier which prevents LLMs from having any understanding of what their amazingly fluent dialogues mean.","authors":["Daniel N. Nissani (Nissensohn)"],"url":"https://arxiv.org/abs/2505.00654"}
{"created":"2025-05-09","title":"A Survey on Inference Engines for Large Language Models: Perspectives on Optimization and Efficiency","abstract":"Large language models (LLMs) are widely applied in chatbots, code generators, and search engines. Workloads such as chain-of-thought, complex reasoning, and agent services significantly increase the inference cost by invoking the model repeatedly. Optimization methods such as parallelism, compression, and caching have been adopted to reduce costs, but the diverse service requirements make it hard to select the right method. Recently, specialized LLM inference engines have emerged as a key component for integrating the optimization methods into service-oriented infrastructures. However, a systematic study on inference engines is still lacking. This paper provides a comprehensive evaluation of 25 open-source and commercial inference engines. We examine each inference engine in terms of ease-of-use, ease-of-deployment, general-purpose support, scalability, and suitability for throughput- and latency-aware computation. Furthermore, we explore the design goals of each inference engine by investigating the optimization techniques it supports. In addition, we assess the ecosystem maturity of open source inference engines and handle the performance and cost policy of commercial solutions. We outline future research directions that include support for complex LLM-based services, support of various hardware, and enhanced security, offering practical guidance to researchers and developers in selecting and designing optimized LLM inference engines. We also provide a public repository to continually track developments in this fast-evolving field: https://github.com/sihyeong/Awesome-LLM-Inference-Engine","authors":["Sihyeong Park","Sungryeol Jeon","Chaelyn Lee","Seokhun Jeon","Byung-Soo Kim","Jemin Lee"],"url":"https://arxiv.org/abs/2505.01658"}
{"created":"2025-05-09","title":"Humans can learn to detect AI-generated texts, or at least learn when they can't","abstract":"This study investigates whether individuals can learn to accurately discriminate between human-written and AI-produced texts when provided with immediate feedback, and if they can use this feedback to recalibrate their self-perceived competence. We also explore the specific criteria individuals rely upon when making these decisions, focusing on textual style and perceived readability.","authors":["Ji\\v{r}\\'i Mili\\v{c}ka","Anna Marklov\\'a","Ond\\v{r}ej Drobil","Eva Posp\\'i\\v{s}ilov\\'a"],"url":"https://arxiv.org/abs/2505.01877"}
{"created":"2025-05-09","title":"A Unified Perspective on Orthogonalization and Diagonalization","abstract":"This paper makes a formal connection between two families of widely used matrix factorization algorithms in numerical linear algebra. One family consists of the Jacobi eigenvalue algorithm and its variants for computing the Hermitian eigendecomposition and singular value decomposition. The other consists of Gaussian elimination and the Gram-Schmidt procedure with various pivoting rules for computing the Cholesky decomposition and QR decomposition respectively.","authors":["Isabel Detherage","Rikhav Shah"],"url":"https://arxiv.org/abs/2505.02023"}
{"created":"2025-05-09","title":"Transforming faces into video stories -- VideoFace2.0","abstract":"Face detection and face recognition have been in the focus of vision community since the very beginnings. Inspired by the success of the original Videoface digitizer, a pioneering device that allowed users to capture video signals from any source, we have designed an advanced video analytics tool to efficiently create structured video stories, i.e. identity-based information catalogs. VideoFace2.0 is the name of the developed system for spatial and temporal localization of each unique face in the input video, i.e. face re-identification (ReID), which also allows their cataloging, characterization and creation of structured video outputs for later downstream tasks. Developed near real-time solution is primarily designed to be utilized in application scenarios involving TV production, media analysis, and as an efficient tool for creating large video datasets necessary for training machine learning (ML) models in challenging vision tasks such as lip reading and multimodal speech recognition. Conducted experiments confirm applicability of the proposed face ReID algorithm that is combining the concepts of face detection, face recognition and passive tracking-by-detection in order to achieve robust and efficient face ReID. The system is envisioned as a compact and modular extensions of the existing video production equipment. Presented results are based on test implementation that achieves between 18-25 fps on consumer type notebook. Ablation experiments also confirmed that the proposed algorithm brings relative gain in the reduction of number of false identities in the range of 73%-93%. We hope that the presented work and shared code implementation will stimulate further interest in development of similar, application specific video analysis tools, and lower the entry barrier for production of high-quality multi-modal datasets in the future.","authors":["Branko Brklja\\v{c}","Vladimir Kalu\\v{s}ev","Branislav Popovi\\'c","Milan Se\\v{c}ujski"],"url":"https://arxiv.org/abs/2505.02060"}
{"created":"2025-05-09","title":"Performance Characterization of Containers in Edge Computing","abstract":"Edge computing addresses critical limitations of cloud computing such as high latency and network congestion by decentralizing processing from cloud to the edge. However, the need for software replication across heterogeneous edge devices introduces dependency and portability challenges, driving the adoption of containerization technologies like Docker. While containers offer lightweight isolation and deployment advantages, they introduce new bottlenecks in edge environments, including cold-start delays, memory constraints, network throughput variability, and inefficient IO handling when interfacing with embedded peripherals. This paper presents an empirical evaluation of Docker containers on resource-constrained edge devices, using Raspberry Pi as a representative platform. We benchmark performance across diverse workloads, including microbenchmarks (CPU, memory, network profiling) and macrobenchmarks (AI inference, sensor IO operations), to quantify the overheads of containerization in real-world edge scenarios. Our testbed comprises physical Raspberry Pi nodes integrated with environmental sensors and camera modules, enabling measurements of latency, memory faults, IO throughput, and cold start delays under varying loads. Key findings reveal trade-offs between container isolation and edge-specific resource limitations, with performance degradation observed in IO heavy and latency sensitive tasks. We identify configuration optimizations to mitigate these issues, providing actionable insights for deploying containers in edge environments while meeting real time and reliability requirements. This work advances the understanding of containerized edge computing by systematically evaluating its feasibility and pitfalls on low-power embedded systems.","authors":["Ragini Gupta","Klara Nahrstedt"],"url":"https://arxiv.org/abs/2505.02082"}
{"created":"2025-05-09","title":"Optimizing LLMs for Resource-Constrained Environments: A Survey of Model Compression Techniques","abstract":"Large Language Models (LLMs) have revolutionized many areas of artificial intelligence (AI), but their substantial resource requirements limit their deployment on mobile and edge devices. This survey paper provides a comprehensive overview of techniques for compressing LLMs to enable efficient inference in resource-constrained environments. We examine three primary approaches: Knowledge Distillation, Model Quantization, and Model Pruning. For each technique, we discuss the underlying principles, present different variants, and provide examples of successful applications. We also briefly discuss complementary techniques such as mixture-of-experts and early-exit strategies. Finally, we highlight promising future directions, aiming to provide a valuable resource for both researchers and practitioners seeking to optimize LLMs for edge deployment.","authors":["Sanjay Surendranath Girija","Shashank Kapoor","Lakshit Arora","Dipen Pradhan","Aman Raj","Ankit Shetgaonkar"],"url":"https://arxiv.org/abs/2505.02309"}
{"created":"2025-05-09","title":"Uncertainty-Weighted Image-Event Multimodal Fusion for Video Anomaly Detection","abstract":"Most existing video anomaly detectors rely solely on RGB frames, which lack the temporal resolution needed to capture abrupt or transient motion cues, key indicators of anomalous events. To address this limitation, we propose Image-Event Fusion for Video Anomaly Detection (IEF-VAD), a framework that synthesizes event representations directly from RGB videos and fuses them with image features through a principled, uncertainty-aware process. The system (i) models heavy-tailed sensor noise with a Student`s-t likelihood, deriving value-level inverse-variance weights via a Laplace approximation; (ii) applies Kalman-style frame-wise updates to balance modalities over time; and (iii) iteratively refines the fused latent state to erase residual cross-modal noise. Without any dedicated event sensor or frame-level labels, IEF-VAD sets a new state of the art across multiple real-world anomaly detection benchmarks. These findings highlight the utility of synthetic event representations in emphasizing motion cues that are often underrepresented in RGB frames, enabling accurate and robust video understanding across diverse applications without requiring dedicated event sensors. Code and models are available at https://github.com/EavnJeong/IEF-VAD.","authors":["Sungheon Jeong","Jihong Park","Mohsen Imani"],"url":"https://arxiv.org/abs/2505.02393"}
{"created":"2025-05-09","title":"T2S: High-resolution Time Series Generation with Text-to-Series Diffusion Models","abstract":"Text-to-Time Series generation holds significant potential to address challenges such as data sparsity, imbalance, and limited availability of multimodal time series datasets across domains. While diffusion models have achieved remarkable success in Text-to-X (e.g., vision and audio data) generation, their use in time series generation remains in its nascent stages. Existing approaches face two critical limitations: (1) the lack of systematic exploration of general-proposed time series captions, which are often domain-specific and struggle with generalization; and (2) the inability to generate time series of arbitrary lengths, limiting their applicability to real-world scenarios. In this work, we first categorize time series captions into three levels: point-level, fragment-level, and instance-level. Additionally, we introduce a new fragment-level dataset containing over 600,000 high-resolution time series-text pairs. Second, we propose Text-to-Series (T2S), a diffusion-based framework that bridges the gap between natural language and time series in a domain-agnostic manner. T2S employs a length-adaptive variational autoencoder to encode time series of varying lengths into consistent latent embeddings. On top of that, T2S effectively aligns textual representations with latent embeddings by utilizing Flow Matching and employing Diffusion Transformer as the denoiser. We train T2S in an interleaved paradigm across multiple lengths, allowing it to generate sequences of any desired length. Extensive evaluations demonstrate that T2S achieves state-of-the-art performance across 13 datasets spanning 12 domains.","authors":["Yunfeng Ge","Jiawei Li","Yiji Zhao","Haomin Wen","Zhao Li","Meikang Qiu","Hongyan Li","Ming Jin","Shirui Pan"],"url":"https://arxiv.org/abs/2505.02417"}
{"created":"2025-05-09","title":"Agentic Neurodivergence as a Contingent Solution to the AI Alignment Problem","abstract":"The AI alignment problem, which focusses on ensuring that artificial intelligence (AI), including AGI and ASI, systems act according to human values, presents profound challenges. With the progression from narrow AI to Artificial General Intelligence (AGI) and Superintelligence, fears about control and existential risk have escalated. Here, we investigate whether embracing inevitable AI misalignment can be a contingent strategy to foster a dynamic ecosystem of competing agents as a viable path to steer them in more human-aligned trends and mitigate risks. We explore how misalignment may serve and should be promoted as a counterbalancing mechanism to team up with whichever agents are most aligned to human interests, ensuring that no single system dominates destructively. The main premise of our contribution is that misalignment is inevitable because full AI-human alignment is a mathematical impossibility from Turing-complete systems, which we also offer as a proof in this contribution, a feature then inherited to AGI and ASI systems. We introduce and test change-of-opinion attacks based on this kind of perturbation and intervention analysis to study how agents may neutralise friendly or unfriendly AIs through cooperation and competition. We show that open models are more diverse and that most likely guardrails implemented in proprietary models are successful at steering and controlling to some extent the agents' range of opinion and sentiment change with possible positive and negative consequences in what we believe are signs of a neuro-symbolic approach even if shallow.","authors":["Alberto Hern\\'andez-Espinosa","Felipe S. Abrah\\~ao","Olaf Witkowski","Hector Zenil"],"url":"https://arxiv.org/abs/2505.02581"}
{"created":"2025-05-09","title":"A Survey of Slow Thinking-based Reasoning LLMs using Reinforced Learning and Inference-time Scaling Law","abstract":"This survey explores recent advancements in reasoning large language models (LLMs) designed to mimic \"slow thinking\" - a reasoning process inspired by human cognition, as described in Kahneman's Thinking, Fast and Slow. These models, like OpenAI's o1, focus on scaling computational resources dynamically during complex tasks, such as math reasoning, visual reasoning, medical diagnosis, and multi-agent debates. We present the development of reasoning LLMs and list their key technologies. By synthesizing over 100 studies, it charts a path toward LLMs that combine human-like deep thinking with scalable efficiency for reasoning. The review breaks down methods into three categories: (1) test-time scaling dynamically adjusts computation based on task complexity via search and sampling, dynamic verification; (2) reinforced learning refines decision-making through iterative improvement leveraging policy networks, reward models, and self-evolution strategies; and (3) slow-thinking frameworks (e.g., long CoT, hierarchical processes) that structure problem-solving with manageable steps. The survey highlights the challenges and further directions of this domain. Understanding and advancing the reasoning abilities of LLMs is crucial for unlocking their full potential in real-world applications, from scientific discovery to decision support systems.","authors":["Qianjun Pan","Wenkai Ji","Yuyang Ding","Junsong Li","Shilian Chen","Junyi Wang","Jie Zhou","Qin Chen","Min Zhang","Yulan Wu","Liang He"],"url":"https://arxiv.org/abs/2505.02665"}
{"created":"2025-05-09","title":"Physics-Learning AI Datamodel (PLAID) datasets: a collection of physics simulations for machine learning","abstract":"Machine learning-based surrogate models have emerged as a powerful tool to accelerate simulation-driven scientific workflows. However, their widespread adoption is hindered by the lack of large-scale, diverse, and standardized datasets tailored to physics-based simulations. While existing initiatives provide valuable contributions, many are limited in scope-focusing on specific physics domains, relying on fragmented tooling, or adhering to overly simplistic datamodels that restrict generalization. To address these limitations, we introduce PLAID (Physics-Learning AI Datamodel), a flexible and extensible framework for representing and sharing datasets of physics simulations. PLAID defines a unified standard for describing simulation data and is accompanied by a library for creating, reading, and manipulating complex datasets across a wide range of physical use cases (gitlab.com/drti/plaid). We release six carefully crafted datasets under the PLAID standard, covering structural mechanics and computational fluid dynamics, and provide baseline benchmarks using representative learning methods. Benchmarking tools are made available on Hugging Face, enabling direct participation by the community and contribution to ongoing evaluation efforts (huggingface.co/PLAIDcompetitions).","authors":["Fabien Casenave","Xavier Roynard","Brian Staber","William Piat","Michele Alessandro Bucci","Nissrine Akkari","Abbas Kabalan","Xuan Minh Vuong Nguyen","Luca Saverio","Rapha\\\"el Carpintero Perez","Anthony Kalaydjian","Samy Fouch\\'e","Thierry Gonon","Ghassan Najjar","Emmanuel Menier","Matthieu Nastorg","Giovanni Catalani","Christian Rey"],"url":"https://arxiv.org/abs/2505.02974"}
{"created":"2025-05-09","title":"RADLADS: Rapid Attention Distillation to Linear Attention Decoders at Scale","abstract":"We present Rapid Attention Distillation to Linear Attention Decoders at Scale (RADLADS), a protocol for rapidly converting softmax attention transformers into linear attention decoder models, along with two new RWKV-variant architectures, and models converted from popular Qwen2.5 open source models in 7B, 32B, and 72B sizes. Our conversion process requires only 350-700M tokens, less than 0.005% of the token count used to train the original teacher models. Converting to our 72B linear attention model costs less than \\$2,000 USD at today's prices, yet quality at inference remains close to the original transformer. These models achieve state-of-the-art downstream performance across a set of standard benchmarks for linear attention models of their size. We release all our models on HuggingFace under the Apache 2.0 license, with the exception of our 72B models which are also governed by the Qwen License Agreement.","authors":["Daniel Goldstein","Eric Alcaide","Janna Lu","Eugene Cheah"],"url":"https://arxiv.org/abs/2505.03005"}
{"created":"2025-05-09","title":"Motion-compensated cardiac MRI using low-rank diffeomorphic flow (DMoCo)","abstract":"We introduce an unsupervised motion-compensated image reconstruction algorithm for free-breathing and ungated 3D cardiac magnetic resonance imaging (MRI). We express the image volume corresponding to each specific motion phase as the deformation of a single static image template. The main contribution of the work is the low-rank model for the compact joint representation of the family of diffeomorphisms, parameterized by the motion phases. The diffeomorphism at a specific motion phase is obtained by integrating a parametric velocity field along a path connecting the reference template phase to the motion phase. The velocity field at different phases is represented using a low-rank model. The static template and the low-rank motion model parameters are learned directly from the k-space data in an unsupervised fashion. The more constrained motion model is observed to offer improved recovery compared to current motion-resolved and motion-compensated algorithms for free-breathing 3D cine MRI.","authors":["Joseph Kettelkamp","Ludovica Romanin","Sarv Priya","Mathews Jacob"],"url":"https://arxiv.org/abs/2505.03149"}
{"created":"2025-05-09","title":"Uncovering the Limitations of Model Inversion Evaluation -- Benchmarks and Connection to Type-I Adversarial Attacks","abstract":"Model Inversion (MI) attacks aim to reconstruct information of private training data by exploiting access to machine learning models. The most common evaluation framework for MI attacks/defenses relies on an evaluation model that has been utilized to assess progress across almost all MI attacks and defenses proposed in recent years. In this paper, for the first time, we present an in-depth study of MI evaluation. Firstly, we construct the first comprehensive human-annotated dataset of MI attack samples, based on 28 setups of different MI attacks, defenses, private and public datasets. Secondly, using our dataset, we examine the accuracy of the MI evaluation framework and reveal that it suffers from a significant number of false positives. These findings raise questions about the previously reported success rates of SOTA MI attacks. Thirdly, we analyze the causes of these false positives, design controlled experiments, and discover the surprising effect of Type I adversarial features on MI evaluation, as well as adversarial transferability, highlighting a relationship between two previously distinct research areas. Our findings suggest that the performance of SOTA MI attacks has been overestimated, with the actual privacy leakage being significantly less than previously reported. In conclusion, we highlight critical limitations in the widely used MI evaluation framework and present our methods to mitigate false positive rates. We remark that prior research has shown that Type I adversarial attacks are very challenging, with no existing solution. Therefore, we urge to consider human evaluation as a primary MI evaluation framework rather than merely a supplement as in previous MI research. We also encourage further work on developing more robust and reliable automatic evaluation frameworks.","authors":["Sy-Tuyen Ho","Koh Jun Hao","Ngoc-Bao Nguyen","Alexander Binder","Ngai-Man Cheung"],"url":"https://arxiv.org/abs/2505.03519"}
{"created":"2025-05-09","title":"Neural Integral Operators for Inverse problems in Spectroscopy","abstract":"Deep learning has shown high performance on spectroscopic inverse problems when sufficient data is available. However, it is often the case that data in spectroscopy is scarce, and this usually causes severe overfitting problems with deep learning methods. Traditional machine learning methods are viable when datasets are smaller, but the accuracy and applicability of these methods is generally more limited. We introduce a deep learning method for classification of molecular spectra based on learning integral operators via integral equations of the first kind, which results in an algorithm that is less affected by overfitting issues on small datasets, compared to other deep learning models. The problem formulation of the deep learning approach is based on inverse problems, which have traditionally found important applications in spectroscopy. We perform experiments on real world data to showcase our algorithm. It is seen that the model outperforms traditional machine learning approaches such as decision tree and support vector machine, and for small datasets it outperforms other deep learning models. Therefore, our methodology leverages the power of deep learning, still maintaining the performance when the available data is very limited, which is one of the main issues that deep learning faces in spectroscopy, where datasets are often times of small size.","authors":["Emanuele Zappala","Alice Giola","Andreas Kramer","Enrico Greco"],"url":"https://arxiv.org/abs/2505.03677"}
{"created":"2025-05-09","title":"Demonstrating ViSafe: Vision-enabled Safety for High-speed Detect and Avoid","abstract":"Assured safe-separation is essential for achieving seamless high-density operation of airborne vehicles in a shared airspace. To equip resource-constrained aerial systems with this safety-critical capability, we present ViSafe, a high-speed vision-only airborne collision avoidance system. ViSafe offers a full-stack solution to the Detect and Avoid (DAA) problem by tightly integrating a learning-based edge-AI framework with a custom multi-camera hardware prototype designed under SWaP-C constraints. By leveraging perceptual input-focused control barrier functions (CBF) to design, encode, and enforce safety thresholds, ViSafe can provide provably safe runtime guarantees for self-separation in high-speed aerial operations. We evaluate ViSafe's performance through an extensive test campaign involving both simulated digital twins and real-world flight scenarios. By independently varying agent types, closure rates, interaction geometries, and environmental conditions (e.g., weather and lighting), we demonstrate that ViSafe consistently ensures self-separation across diverse scenarios. In first-of-its-kind real-world high-speed collision avoidance tests with closure rates reaching 144 km/h, ViSafe sets a new benchmark for vision-only autonomous collision avoidance, establishing a new standard for safety in high-speed aerial navigation.","authors":["Parv Kapoor","Ian Higgins","Nikhil Keetha","Jay Patrikar","Brady Moon","Zelin Ye","Yao He","Ivan Cisneros","Yaoyu Hu","Changliu Liu","Eunsuk Kang","Sebastian Scherer"],"url":"https://arxiv.org/abs/2505.03694"}
{"created":"2025-05-09","title":"MAISY: Motion-Aware Image SYnthesis for Medical Image Motion Correction","abstract":"Patient motion during medical image acquisition causes blurring, ghosting, and distorts organs, which makes image interpretation challenging. Current state-of-the-art algorithms using Generative Adversarial Network (GAN)-based methods with their ability to learn the mappings between corrupted images and their ground truth via Structural Similarity Index Measure (SSIM) loss effectively generate motion-free images. However, we identified the following limitations: (i) they mainly focus on global structural characteristics and therefore overlook localized features that often carry critical pathological information, and (ii) the SSIM loss function struggles to handle images with varying pixel intensities, luminance factors, and variance. In this study, we propose Motion-Aware Image SYnthesis (MAISY) which initially characterize motion and then uses it for correction by: (a) leveraging the foundation model Segment Anything Model (SAM), to dynamically learn spatial patterns along anatomical boundaries where motion artifacts are most pronounced and, (b) introducing the Variance-Selective SSIM (VS-SSIM) loss which adaptively emphasizes spatial regions with high pixel variance to preserve essential anatomical details during artifact correction. Experiments on chest and head CT datasets demonstrate that our model outperformed the state-of-the-art counterparts, with Peak Signal-to-Noise Ratio (PSNR) increasing by 40%, SSIM by 10%, and Dice by 16%.","authors":["Andrew Zhang","Hao Wang","Shuchang Ye","Michael Fulham","Jinman Kim"],"url":"https://arxiv.org/abs/2505.04105"}
{"created":"2025-05-09","title":"An automated end-to-end deep learning-based framework for lung cancer diagnosis by detecting and classifying the lung nodules","abstract":"Lung cancer is a leading cause of cancer-related deaths worldwide, and early detection is crucial for improving patient outcomes. Nevertheless, early diagnosis of cancer is a major challenge, particularly in low-resource settings where access to medical resources and trained radiologists is limited. The objective of this study is to propose an automated end-to-end deep learning-based framework for the early detection and classification of lung nodules, specifically for low-resource settings. The proposed framework consists of three stages: lung segmentation using a modified 3D U-Net named 3D Res-U-Net, nodule detection using YOLO-v5, and classification with a Vision Transformer-based architecture. We evaluated the proposed framework on a publicly available dataset, LUNA16. The proposed framework's performance was measured using the respective domain's evaluation matrices. The proposed framework achieved a 98.82% lung segmentation dice score while detecting the lung nodule with 0.76 mAP@50 from the segmented lung, at a low false-positive rate. The performance of both networks of the proposed framework was compared with other studies and found to outperform them regarding segmentation and detection accuracy. Additionally, our proposed Vision transformer network obtained an accuracy of 93.57%, which is 1.21% higher than the state-of-the-art networks. Our proposed end-to-end deep learning-based framework can effectively segment lungs, and detect and classify lung nodules, specifically in low-resource settings with limited access to radiologists. The proposed framework outperforms existing studies regarding all the respective evaluation metrics. The proposed framework can potentially improve the accuracy and efficiency of lung cancer screening in low-resource settings, ultimately leading to better patient outcomes.","authors":["Samiul Based Shuvo","Tasnia Binte Mamun"],"url":"https://arxiv.org/abs/2305.00046"}
{"created":"2025-05-09","title":"Multi-objective optimisation via the R2 utilities","abstract":"The goal of multi-objective optimisation is to identify a collection of points which describe the best possible trade-offs between the multiple objectives. In order to solve this vector-valued optimisation problem, practitioners often appeal to the use of scalarisation functions in order to transform the multi-objective problem into a collection of single-objective problems. This set of scalarised problems can then be solved using traditional single-objective optimisation techniques. In this work, we formalise this convention into a general mathematical framework. We show how this strategy effectively recasts the original multi-objective optimisation problem into a single-objective optimisation problem defined over sets. An appropriate class of objective functions for this new problem are the R2 utilities, which are utility functions that are defined as a weighted integral over the scalarised optimisation problems. As part of our work, we show that these utilities are monotone and submodular set functions which can be optimised effectively using greedy optimisation algorithms. We then analyse the performance of these greedy algorithms both theoretically and empirically. Our analysis largely focusses on Bayesian optimisation, which is a popular probabilistic framework for black-box optimisation.","authors":["Ben Tu","Nikolas Kantas","Robert M. Lee","Behrang Shafei"],"url":"https://arxiv.org/abs/2305.11774"}
{"created":"2025-05-09","title":"Free Discontinuity Regression: With an Application to the Economic Effects of Internet Shutdowns","abstract":"Sharp, multidimensional changepoints-abrupt shifts in a regression surface whose locations and magnitudes are unknown-arise in settings as varied as gene-expression profiling, financial covariance breaks, climate-regime detection, and urban socioeconomic mapping. Despite their prevalence, there are no current approaches that jointly estimate the location and size of the discontinuity set in a one-shot approach with statistical guarantees. We therefore introduce Free Discontinuity Regression (FDR), a fully nonparametric estimator that simultaneously (i) smooths a regression surface, (ii) segments it into contiguous regions, and (iii) provably recovers the precise locations and sizes of its jumps. By extending a convex relaxation of the Mumford-Shah functional to random spatial sampling and correlated noise, FDR overcomes the fixed-grid and i.i.d. noise assumptions of classical image-segmentation approaches, thus enabling its application to real-world data of any dimension. This yields the first identification and uniform consistency results for multivariate jump surfaces: under mild SBV regularity, the estimated function, its discontinuity set, and all jump sizes converge to their true population counterparts. Hyperparameters are selected automatically from the data using Stein's Unbiased Risk Estimate, and large-scale simulations up to three dimensions validate the theoretical results and demonstrate good finite-sample performance. Applying FDR to an internet shutdown in India reveals a 25-35% reduction in economic activity around the estimated shutdown boundaries-much larger than previous estimates. By unifying smoothing, segmentation, and effect-size recovery in a general statistical setting, FDR turns free-discontinuity ideas into a practical tool with formal guarantees for modern multivariate data.","authors":["Florian Gunsilius","David Van Dijcke"],"url":"https://arxiv.org/abs/2309.14630"}
{"created":"2025-05-09","title":"Exact nonlinear state estimation","abstract":"The majority of data assimilation (DA) methods in the geosciences are based on Gaussian assumptions. While these assumptions facilitate efficient algorithms, they cause analysis biases and subsequent forecast degradations. Non-parametric, particle-based DA algorithms have superior accuracy, but their application to high-dimensional models still poses operational challenges. Drawing inspiration from recent advances in the field of generative artificial intelligence (AI), this article introduces a new nonlinear estimation theory which attempts to bridge the existing gap in DA methodology. Specifically, a Conjugate Transform Filter (CTF) is derived and shown to generalize the celebrated Kalman filter to arbitrarily non-Gaussian distributions. The new filter has several desirable properties, such as its ability to preserve statistical relationships in the prior state and convergence to highly accurate observations. An ensemble approximation of the new theory (ECTF) is also presented and validated using idealized statistical experiments that feature bounded quantities with non-Gaussian distributions, a prevalent challenge in Earth system models. Results from these experiments indicate that the greatest benefits from ECTF occur when observation errors are small relative to the forecast uncertainty and when state variables exhibit strong nonlinear dependencies. Ultimately, the new filtering theory offers exciting avenues for improving conventional DA algorithms through their principled integration with AI techniques.","authors":["Hristo G. Chipilski"],"url":"https://arxiv.org/abs/2310.10976"}
{"created":"2025-05-09","title":"Data-Driven Merton's Strategies via Policy Randomization","abstract":"We study Merton's expected utility maximization problem in an incomplete market, characterized by a factor process in addition to the stock price process, where all the model primitives are unknown. The agent under consideration is a price taker who has access only to the stock and factor value processes and the instantaneous volatility. We propose an auxiliary problem in which the agent can invoke policy randomization according to a specific class of Gaussian distributions, and prove that the mean of its optimal Gaussian policy solves the original Merton problem. With randomized policies, we are in the realm of continuous-time reinforcement learning (RL) recently developed in Wang et al. (2020) and Jia and Zhou (2022a, 2022b, 2023), enabling us to solve the auxiliary problem in a data-driven way without having to estimate the model primitives. Specifically, we establish a policy improvement theorem based on which we design both online and offline actor-critic RL algorithms for learning Merton's strategies. A key insight from this study is that RL in general and policy randomization in particular are useful beyond the purpose for exploration -- they can be employed as a technical tool to solve a problem that cannot be otherwise solved by mere deterministic policies. At last, we carry out both simulation and empirical studies in a stochastic volatility environment to demonstrate the decisive outperformance of the devised RL algorithms in comparison to the conventional model-based, plug-in method.","authors":["Min Dai","Yuchao Dong","Yanwei Jia","Xun Yu Zhou"],"url":"https://arxiv.org/abs/2312.11797"}
{"created":"2025-05-09","title":"GeoFlood (v1.0.0): Computational model for overland flooding","abstract":"This paper presents GeoFlood, a new open-source software package for solving the shallow-water equations (SWE) on a quadtree hierarchy of mapped, logically Cartesian grids managed by the parallel, adaptive library ForestClaw (Calhoun and Burstedde, 2017). The GeoFlood model is validated using standard benchmark tests from Neelz and Pender (2013) as well as the historical Malpasset dam failure. The benchmark test results are compared against those obtained from GeoClaw (Clawpack Development Team, 2020) and the software package HEC-RAS (Hydraulic Engineering Center River Analysis System, Army Corps of Engineers) (Brunner, 2018). The Malpasset outburst flood results are compared with those presented in George (2011) (obtained from the GeoClaw software), model results from Hervouet and Petitjean (1999), and empirical data. The comparisons validate GeoFlood's capabilities for idealized benchmarks compared to other commonly used models as well as its ability to efficiently simulate highly dynamic floods in complex terrain, consistent with historical field data. Because it is massively parallel and scalable, GeoFlood may be a valuable tool for efficiently computing large-scale flooding problems at very high resolutions.","authors":["Brian Kyanjo","Donna Calhoun","David L. George"],"url":"https://arxiv.org/abs/2403.15435"}
{"created":"2025-05-09","title":"WaveSleepNet: An Interpretable Network for Expert-like Sleep Staging","abstract":"Although deep learning algorithms have proven their efficiency in automatic sleep staging, the widespread skepticism about their \"black-box\" nature has limited its clinical acceptance. In this study, we propose WaveSleepNet, an interpretable neural network for sleep staging that reasons in a similar way to sleep experts. In this network, we utilize the latent space representations generated during training to identify characteristic wave prototypes corresponding to different sleep stages. The feature representation of an input signal is segmented into patches within the latent space, each of which is compared against the learned wave prototypes. The proximity between these patches and the wave prototypes is quantified through scores, indicating the prototypes' presence and relative proportion within the signal. The scores are served as the decision-making criteria for final sleep staging. During training, an ensemble of loss functions is employed for the prototypes' diversity and robustness. Furthermore, the learned wave prototypes are visualized by analysing occlusion sensitivity. The efficacy of WaveSleepNet is validated across three public datasets, achieving sleep staging performance that are on par with the state-of-the-art models when several WaveSleepNets are combine into a larger network. A detailed case study examined the decision-making process of the WaveSleepNet which aligns closely with American Academy of Sleep Medicine (AASM) manual guidelines. Another case study systematically explained the misidentified reason behind each sleep stage. WaveSleepNet's transparent process provides specialists with direct access to the physiological significance of its criteria, allowing for future adaptation or enrichment by sleep experts.","authors":["Yan Pei","Wei Luo"],"url":"https://arxiv.org/abs/2404.15342"}
{"created":"2025-05-09","title":"Barren Plateaus in Variational Quantum Computing","abstract":"Variational quantum computing offers a flexible computational paradigm with applications in diverse areas. However, a key obstacle to realizing their potential is the Barren Plateau (BP) phenomenon. When a model exhibits a BP, its parameter optimization landscape becomes exponentially flat and featureless as the problem size increases. Importantly, all the moving pieces of an algorithm -- choices of ansatz, initial state, observable, loss function and hardware noise -- can lead to BPs when ill-suited. Due to the significant impact of BPs on trainability, researchers have dedicated considerable effort to develop theoretical and heuristic methods to understand and mitigate their effects. As a result, the study of BPs has become a thriving area of research, influencing and cross-fertilizing other fields such as quantum optimal control, tensor networks, and learning theory. This article provides a comprehensive review of the current understanding of the BP phenomenon.","authors":["Martin Larocca","Supanut Thanasilp","Samson Wang","Kunal Sharma","Jacob Biamonte","Patrick J. Coles","Lukasz Cincio","Jarrod R. McClean","Zo\\\"e Holmes","M. Cerezo"],"url":"https://arxiv.org/abs/2405.00781"}
{"created":"2025-05-09","title":"Scientific Hypothesis Generation by a Large Language Model: Laboratory Validation in Breast Cancer Treatment","abstract":"Large language models LLMs have transformed AI and achieved breakthrough performance on a wide range of tasks In science the most interesting application of LLMs is for hypothesis formation A feature of LLMs which results from their probabilistic structure is that the output text is not necessarily a valid inference from the training text These are termed hallucinations and are harmful in many applications In science some hallucinations may be useful novel hypotheses whose validity may be tested by laboratory experiments Here we experimentally test the application of LLMs as a source of scientific hypotheses using the domain of breast cancer treatment We applied the LLM GPT4 to hypothesize novel synergistic pairs of FDA-approved noncancer drugs that target the MCF7 breast cancer cell line relative to the nontumorigenic breast cell line MCF10A In the first round of laboratory experiments GPT4 succeeded in discovering three drug combinations out of twelve tested with synergy scores above the positive controls GPT4 then generated new combinations based on its initial results this generated three more combinations with positive synergy scores out of four tested We conclude that LLMs are a valuable source of scientific hypotheses.","authors":["Abbi Abdel-Rehim","Hector Zenil","Oghenejokpeme Orhobor","Marie Fisher","Ross J. Collins","Elizabeth Bourne","Gareth W. Fearnley","Emma Tate","Holly X. Smith","Larisa N. Soldatova","Ross D. King"],"url":"https://arxiv.org/abs/2405.12258"}
{"created":"2025-05-09","title":"Rejection via Learning Density Ratios","abstract":"Classification with rejection emerges as a learning paradigm which allows models to abstain from making predictions. The predominant approach is to alter the supervised learning pipeline by augmenting typical loss functions, letting model rejection incur a lower loss than an incorrect prediction. Instead, we propose a different distributional perspective, where we seek to find an idealized data distribution which maximizes a pretrained model's performance. This can be formalized via the optimization of a loss's risk with a $\\varphi$-divergence regularization term. Through this idealized distribution, a rejection decision can be made by utilizing the density ratio between this distribution and the data distribution. We focus on the setting where our $\\varphi$-divergences are specified by the family of $\\alpha$-divergence. Our framework is tested empirically over clean and noisy datasets.","authors":["Alexander Soen","Hisham Husain","Philip Schulz","Vu Nguyen"],"url":"https://arxiv.org/abs/2405.18686"}
{"created":"2025-05-09","title":"Evaluating Deep Learning Models for Breast Cancer Classification: A Comparative Study","abstract":"This study evaluates the effectiveness of deep learning models in classifying histopathological images for early and accurate detection of breast cancer. Eight advanced models, including ResNet-50, DenseNet-121, ResNeXt-50, Vision Transformer (ViT), GoogLeNet (Inception v3), EfficientNet, MobileNet, and SqueezeNet, were compared using a dataset of 277,524 image patches. The Vision Transformer (ViT) model, with its attention-based mechanisms, achieved the highest validation accuracy of 94%, outperforming conventional CNNs. The study demonstrates the potential of advanced machine learning methods to enhance precision and efficiency in breast cancer diagnosis in clinical settings.","authors":["Sania Eskandari","Ali Eslamian","Nusrat Munia","Amjad Alqarni","Qiang Cheng"],"url":"https://arxiv.org/abs/2408.16859"}
{"created":"2025-05-09","title":"A nonlinear elasticity model in computer vision","abstract":"The purpose of this paper is to analyze a nonlinear elasticity model introduced by the authors for comparing two images, regarded as bounded open subsets of $\\R^n$ together with associated vector-valued intensity maps. Optimal transformations between the images are sought as minimisers of an integral functional among orientation-preserving homeomorphisms. The existence of minimisers is proved under natural coercivity and polyconvexity conditions, assuming only that the intensity functions are bounded measurable. Variants of the existence theorem are also proved, first under the constraint that finite sets of landmark points in the two images are mapped one to the other, and second when one image is to be compared to an unknown part of another.","authors":["John M. Ball","Christopher L. Horner"],"url":"https://arxiv.org/abs/2408.17237"}
{"created":"2025-05-09","title":"A Practical Theory of Generalization in Selectivity Learning","abstract":"Query-driven machine learning models have emerged as a promising estimation technique for query selectivities. Yet, surprisingly little is known about the efficacy of these techniques from a theoretical perspective, as there exist substantial gaps between practical solutions and state-of-the-art (SOTA) theory based on the Probably Approximately Correct (PAC) learning framework. In this paper, we aim to bridge the gaps between theory and practice. First, we demonstrate that selectivity predictors induced by signed measures are learnable, which relaxes the reliance on probability measures in SOTA theory. More importantly, beyond the PAC learning framework (which only allows us to characterize how the model behaves when both training and test workloads are drawn from the same distribution), we establish, under mild assumptions, that selectivity predictors from this class exhibit favorable out-of-distribution (OOD) generalization error bounds.","authors":["Peizhi Wu","Haoshu Xu","Ryan Marcus","Zachary G. Ives"],"url":"https://arxiv.org/abs/2409.07014"}
{"created":"2025-05-09","title":"$k$-local Graphs","abstract":"In 2017 Day et al. introduced the notion of locality as a structural complexity-measure for patterns in the field of pattern matching established by Angluin in 1980. In 2019 Casel et al. showed that determining the locality of an arbitrary pattern is NP-complete. Inspired by hierarchical clustering, we extend the notion to coloured graphs, i.e., given a coloured graph determine an enumeration of the colours such that colouring the graph stepwise according to the enumeration leads to as few clusters as possible. Next to first theoretical results on graph classes, we propose a priority search algorithm to compute the $k$-locality of a graph. The algorithm is optimal in the number of marking prefix expansions, and is faster by orders of magnitude than an exhaustive search. Finally, we perform a case study on a DBLP subgraph to demonstrate the potential of $k$-locality for knowledge discovery.","authors":["Christian Beth","Pamela Fleischmann","Annika Huch","Daniyal Kazempour","Peer Kr\\\"oger","Andrea Kulow","Matthias Renz"],"url":"https://arxiv.org/abs/2410.00601"}
{"created":"2025-05-09","title":"Large Scale MRI Collection and Segmentation of Cirrhotic Liver","abstract":"Liver cirrhosis represents the end stage of chronic liver disease, characterized by extensive fibrosis and nodular regeneration that significantly increases mortality risk. While magnetic resonance imaging (MRI) offers a non-invasive assessment, accurately segmenting cirrhotic livers presents substantial challenges due to morphological alterations and heterogeneous signal characteristics. Deep learning approaches show promise for automating these tasks, but progress has been limited by the absence of large-scale, annotated datasets. Here, we present CirrMRI600+, the first comprehensive dataset comprising 628 high-resolution abdominal MRI scans (310 T1-weighted and 318 T2-weighted sequences, totaling nearly 40,000 annotated slices) with expert-validated segmentation labels for cirrhotic livers. The dataset includes demographic information, clinical parameters, and histopathological validation where available. Additionally, we provide benchmark results from 11 state-of-the-art deep learning experiments to establish performance standards. CirrMRI600+ enables the development and validation of advanced computational methods for cirrhotic liver analysis, potentially accelerating progress toward automated Cirrhosis visual staging and personalized treatment planning.","authors":["Debesh Jha","Onkar Kishor Susladkar","Vandan Gorade","Elif Keles","Matthew Antalek","Deniz Seyithanoglu","Timurhan Cebeci","Halil Ertugrul Aktas","Gulbiz Dagoglu Kartal","Sabahattin Kaymakoglu","Sukru Mehmet Erturk","Yuri Velichko","Daniela Ladner","Amir A. Borhani","Alpay Medetalibeyoglu","Gorkem Durak","Ulas Bagci"],"url":"https://arxiv.org/abs/2410.16296"}
{"created":"2025-05-09","title":"Efficient Estimation of Relaxed Model Parameters for Robust UAV Trajectory Optimization","abstract":"Online trajectory optimization and optimal control methods are crucial for enabling sustainable unmanned aerial vehicle (UAV) services, such as agriculture, environmental monitoring, and transportation, where available actuation and energy are limited. However, optimal controllers are highly sensitive to model mismatch, which can occur due to loaded equipment, packages to be delivered, or pre-existing variability in fundamental structural and thrust-related parameters. To circumvent this problem, optimal controllers can be paired with parameter estimators to improve their trajectory planning performance and perform adaptive control. However, UAV platforms are limited in terms of onboard processing power, oftentimes making nonlinear parameter estimation too computationally expensive to consider. To address these issues, we propose a relaxed, affine-in-parameters multirotor model along with an efficient optimal parameter estimator. We convexify the nominal Moving Horizon Parameter Estimation (MHPE) problem into a linear-quadratic form (LQ-MHPE) via an affine-in-parameter relaxation on the nonlinear dynamics, resulting in fast quadratic programs (QPs) that facilitate adaptive Model Predictve Control (MPC) in real time. We compare this approach to the equivalent nonlinear estimator in Monte Carlo simulations, demonstrating a decrease in average solve time and trajectory optimality cost by 98.2% and 23.9-56.2%, respectively.","authors":["Derek Fan","David A. Copp"],"url":"https://arxiv.org/abs/2411.10941"}
{"created":"2025-05-09","title":"Pairwise Markov Chains for Volatility Forecasting","abstract":"The Pairwise Markov Chain (PMC) is a probabilistic graphical model extending the well-known Hidden Markov Model. This model, although highly effective for many tasks, has been scarcely utilized for continuous value prediction. This is mainly due to the issue of modeling observations inherent in generative probabilistic models. In this paper, we introduce a new algorithm for prediction with the PMC. On the one hand, this algorithm allows circumventing the feature problem, thus fully exploiting the capabilities of the PMC. On the other hand, it enables the PMC to extend any predictive model by introducing hidden states, updated at each time step, and allowing the introduction of non-stationarity for any model. We apply the PMC with its new algorithm for volatility forecasting, which we compare to the highly popular GARCH(1,1) and feedforward neural models across numerous pairs. This is particularly relevant given the regime changes that we can observe in volatility. For each scenario, our algorithm enhances the performance of the extended model, demonstrating the value of our approach.","authors":["Elie Azeraf"],"url":"https://arxiv.org/abs/2411.11838"}
{"created":"2025-05-09","title":"Active learning of neural population dynamics using two-photon holographic optogenetics","abstract":"Recent advances in techniques for monitoring and perturbing neural populations have greatly enhanced our ability to study circuits in the brain. In particular, two-photon holographic optogenetics now enables precise photostimulation of experimenter-specified groups of individual neurons, while simultaneous two-photon calcium imaging enables the measurement of ongoing and induced activity across the neural population. Despite the enormous space of potential photostimulation patterns and the time-consuming nature of photostimulation experiments, very little algorithmic work has been done to determine the most effective photostimulation patterns for identifying the neural population dynamics. Here, we develop methods to efficiently select which neurons to stimulate such that the resulting neural responses will best inform a dynamical model of the neural population activity. Using neural population responses to photostimulation in mouse motor cortex, we demonstrate the efficacy of a low-rank linear dynamical systems model, and develop an active learning procedure which takes advantage of low-rank structure to determine informative photostimulation patterns. We demonstrate our approach on both real and synthetic data, obtaining in some cases as much as a two-fold reduction in the amount of data required to reach a given predictive power. Our active stimulation design method is based on a novel active learning procedure for low-rank regression, which may be of independent interest.","authors":["Andrew Wagenmaker","Lu Mi","Marton Rozsa","Matthew S. Bull","Karel Svoboda","Kayvon Daie","Matthew D. Golub","Kevin Jamieson"],"url":"https://arxiv.org/abs/2412.02529"}
{"created":"2025-05-09","title":"AirMorph: Topology-Preserving Deep Learning for Pulmonary Airway Analysis","abstract":"Accurate anatomical labeling and analysis of the pulmonary structure and its surrounding anatomy from thoracic CT is getting increasingly important for understanding the etilogy of abnormalities or supporting targetted therapy and early interventions. Whilst lung and airway cell atlases have been attempted, there is a lack of fine-grained morphological atlases that are clinically deployable. In this work, we introduce AirMorph, a robust, end-to-end deep learning pipeline enabling fully automatic and comprehensive airway anatomical labeling at lobar, segmental, and subsegmental resolutions that can be used to create digital atlases of the lung. Evaluated across large-scale multi-center datasets comprising diverse pulmonary conditions, the AirMorph consistently outperformed existing segmentation and labeling methods in terms of accuracy, topological consistency, and completeness. To simplify clinical interpretation, we further introduce a compact anatomical signature quantifying critical morphological airway features, including stenosis, ectasia, tortuosity, divergence, length, and complexity. When applied to various pulmonary diseases such as pulmonary fibrosis, emphysema, atelectasis, consolidation, and reticular opacities, it demonstrates strong discriminative power, revealing disease-specific morphological patterns with high interpretability and explainability. Additionally, AirMorph supports efficient automated branching pattern analysis, potentially enhancing bronchoscopic navigation planning and procedural safety, offering a valuable clinical tool for improved diagnosis, targeted treatment, and personalized patient care.","authors":["Minghui Zhang","Chenyu Li","Fangfang Xie","Yaoyu Liu","Hanxiao Zhang","Junyang Wu","Chunxi Zhang","Jie Yang","Jiayuan Sun","Guang-Zhong Yang","Yun Gu"],"url":"https://arxiv.org/abs/2412.11039"}
{"created":"2025-05-09","title":"Provable DI-QRNG protocols based on self-testing methodologies in preparation and measure scenario","abstract":"We present two Device Independent Quantum Random Number Generator (DI-QRNG) protocols using two self-testing methodologies in Preparation \\& Measure (P\\&amp;M) scenario. These two methodologies are the variants of two well-known non-local games, namely, CHSH and pseudo-telepathy games, in P\\&amp;M framework. We exploit them as distinguishers in black-box settings to differentiate the classical and the quantum paradigms and hence to certify the Device Independence. The first self-test was proposed by Tavakoli et al. (Phys. Rev. A, 2018). We show that this is actually a P\\&amp;M variant of the CHSH game. Then based on this self-test, we design our first DI-QRNG protocol. We also propose a new self-testing methodology, which is the first of its kind that is reducible from pseudo-telepathy game in P\\&amp;M framework. Based on this new self-test, we design our second DI-QRNG protocol.","authors":["Asmita Samanta","Arpita Maitra","Goutam Paul"],"url":"https://arxiv.org/abs/2501.00916"}
{"created":"2025-05-09","title":"Dual Conic Proxy for Semidefinite Relaxation of AC Optimal Power Flow","abstract":"The nonlinear, non-convex AC Optimal Power Flow (AC-OPF) problem is fundamental for power systems operations. The intrinsic complexity of AC-OPF has fueled a growing interest in the development of optimization proxies for the problem, i.e., machine learning models that predict high-quality, close-to-optimal solutions. More recently, dual conic proxy architectures have been proposed, which combine machine learning and convex relaxations of AC-OPF, to provide valid certificates of optimality using learning-based methods. Building on this methodology, this paper proposes, for the first time, a dual conic proxy architecture for the semidefinite (SDP) relaxation of AC-OPF problems. Although the SDP relaxation is stronger than the second-order cone relaxation considered in previous work, its practical use has been hindered by its computational cost. The proposed method combines a neural network with a differentiable dual completion strategy that leverages the structure of the dual SDP problem. This approach guarantees dual feasibility, and therefore valid dual bounds, while providing orders of magnitude of speedups compared to interior-point algorithms. The paper also leverages self-supervised learning, which alleviates the need for time-consuming data generation and allows to train the proposed models efficiently. Numerical experiments are presented on several power grid benchmarks with up to 500 buses. The results demonstrate that the proposed SDP-based proxies can outperform weaker conic relaxations, while providing several orders of magnitude speedups compared to a state-of-the-art interior-point SDP solver.","authors":["Guancheng Qiu","Mathieu Tanneau","Pascal Van Hentenryck"],"url":"https://arxiv.org/abs/2502.06978"}
{"created":"2025-05-09","title":"TLOB: A Novel Transformer Model with Dual Attention for Price Trend Prediction with Limit Order Book Data","abstract":"Price Trend Prediction (PTP) based on Limit Order Book (LOB) data is a fundamental challenge in financial markets. Despite advances in deep learning, existing models fail to generalize across different market conditions and assets. Surprisingly, by adapting a simple MLP-based architecture to LOB, we show that we surpass SoTA performance; thus, challenging the necessity of complex architectures. Unlike past work that shows robustness issues, we propose TLOB, a transformer-based model that uses a dual attention mechanism to capture spatial and temporal dependencies in LOB data. This allows it to adaptively focus on the market microstructure, making it particularly effective for longer-horizon predictions and volatile market conditions. We also introduce a new labeling method that improves on previous ones, removing the horizon bias. We evaluate TLOB's effectiveness across four horizons, using the established FI-2010 benchmark, a NASDAQ and a Bitcoin dataset. TLOB outperforms SoTA methods in every dataset and horizon. Additionally, we empirically show how stock price predictability has declined over time, -6.68 in F1-score, highlighting the growing market efficiency. Predictability must be considered in relation to transaction costs, so we experimented with defining trends using an average spread, reflecting the primary transaction cost. The resulting performance deterioration underscores the complexity of translating trend classification into profitable trading strategies. We argue that our work provides new insights into the evolving landscape of stock price trend prediction and sets a strong foundation for future advancements in financial AI. We release the code at https://github.com/LeonardoBerti00/TLOB.","authors":["Leonardo Berti","Gjergji Kasneci"],"url":"https://arxiv.org/abs/2502.15757"}
{"created":"2025-05-09","title":"FLARE: A Framework for Stellar Flare Forecasting using Stellar Physical Properties and Historical Records","abstract":"Stellar flare events are critical observational samples for astronomical research; however, recorded flare events remain limited. Stellar flare forecasting can provide additional flare event samples to support research efforts. Despite this potential, no specialized models for stellar flare forecasting have been proposed to date. In this paper, we present extensive experimental evidence demonstrating that both stellar physical properties and historical flare records are valuable inputs for flare forecasting tasks. We then introduce FLARE (Forecasting Light-curve-based Astronomical Records via features Ensemble), the first-of-its-kind large model specifically designed for stellar flare forecasting. FLARE integrates stellar physical properties and historical flare records through a novel Soft Prompt Module and Residual Record Fusion Module. Our experiments on the publicly available Kepler light curve dataset demonstrate that FLARE achieves superior performance compared to other methods across all evaluation metrics. Finally, we validate the forecast capability of our model through a comprehensive case study.","authors":["Bingke Zhu","Xiaoxiao Wang","Minghui Jia","Yihan Tao","Xiao Kong","Ali Luo","Yingying Chen","Ming Tang","Jinqiao Wang"],"url":"https://arxiv.org/abs/2502.18218"}
{"created":"2025-05-09","title":"Large AI Model for Delay-Doppler Domain Channel Prediction in 6G OTFS-Based Vehicular Networks","abstract":"Channel prediction is crucial for high-mobility vehicular networks, as it enables the anticipation of future channel conditions and the proactive adjustment of communication strategies. However, achieving accurate vehicular channel prediction is challenging due to significant Doppler effects and rapid channel variations resulting from high-speed vehicle movement and complex propagation environments. In this paper, we propose a novel delay-Doppler (DD) domain channel prediction framework tailored for high-mobility vehicular networks. By transforming the channel representation into the DD domain, we obtain an intuitive, sparse, and stable depiction that closely aligns with the underlying physical propagation processes, effectively reducing the complex vehicular channel to a set of time-series parameters with enhanced predictability. Furthermore, we leverage the large artificial intelligence (AI) model to predict these DD-domain time-series parameters, capitalizing on their advanced ability to model temporal correlations. The zero-shot capability of the pre-trained large AI model facilitates accurate channel predictions without requiring task-specific training, while subsequent fine-tuning on specific vehicular channel data further improves prediction accuracy. Extensive simulation results demonstrate the effectiveness of our DD-domain channel prediction framework and the superior accuracy of the large AI model in predicting time-series channel parameters, thereby highlighting the potential of our approach for robust vehicular communication systems.","authors":["Jianzhe Xue","Dongcheng Yuan","Zhanxi Ma","Tiankai Jiang","Yu Sun","Haibo Zhou","Xuemin Shen"],"url":"https://arxiv.org/abs/2503.01116"}
{"created":"2025-05-09","title":"Exhaustive Search for Quantum Circuit Optimization using ZX Calculus","abstract":"Quantum computers allow a near-exponential speed-up for specific applications when compared to classical computers. Despite recent advances in the hardware of quantum computers, their practical usage is still severely limited due to a restricted number of available physical qubits and quantum gates, short coherence time, and high error rates. This paper lays the foundation towards a metric independent approach to quantum circuit optimization based on exhaustive search algorithms. This work uses depth-first search and iterative deepening depth-first search. We rely on ZX calculus to represent and optimize quantum circuits through the minimization of a given metric (e.g. the T-gate and edge count). ZX calculus formally guarantees that the semantics of the original circuit is preserved. As ZX calculus is a non-terminating rewriting system, we utilise a novel set of pruning rules to ensure termination while still obtaining high-quality solutions. We provide the first formalization of quantum circuit optimization using ZX calculus and exhaustive search. We extensively benchmark our approach on 100 standard quantum circuits. Finally, our implementation is integrated in the well-known libraries PyZX and Qiskit as a compiler pass to ensure applicability of our results.","authors":["Tobias Fischbach","Pierre Talbot","Pascal Bouvry"],"url":"https://arxiv.org/abs/2503.10983"}
{"created":"2025-05-09","title":"Integrating AI for Human-Centric Breast Cancer Diagnostics: A Multi-Scale and Multi-View Swin Transformer Framework","abstract":"Despite advancements in Computer-Aided Diagnosis (CAD) systems, breast cancer remains one of the leading causes of cancer-related deaths among women worldwide. Recent breakthroughs in Artificial Intelligence (AI) have shown significant promise in development of advanced Deep Learning (DL) architectures for breast cancer diagnosis through mammography. In this context, the paper focuses on the integration of AI within a Human-Centric workflow to enhance breast cancer diagnostics. Key challenges are, however, largely overlooked such as reliance on detailed tumor annotations and susceptibility to missing views, particularly during test time. To address these issues, we propose a hybrid, multi-scale and multi-view Swin Transformer-based framework (MSMV-Swin) that enhances diagnostic robustness and accuracy. The proposed MSMV-Swin framework is designed to work as a decision-support tool, helping radiologists analyze multi-view mammograms more effectively. More specifically, the MSMV-Swin framework leverages the Segment Anything Model (SAM) to isolate the breast lobe, reducing background noise and enabling comprehensive feature extraction. The multi-scale nature of the proposed MSMV-Swin framework accounts for tumor-specific regions as well as the spatial characteristics of tissues surrounding the tumor, capturing both localized and contextual information. The integration of contextual and localized data ensures that MSMV-Swin's outputs align with the way radiologists interpret mammograms, fostering better human-AI interaction and trust. A hybrid fusion structure is then designed to ensure robustness against missing views, a common occurrence in clinical practice when only a single mammogram view is available.","authors":["Farnoush Bayatmakou","Reza Taleei","Milad Amir Toutounchian","Arash Mohammadi"],"url":"https://arxiv.org/abs/2503.13309"}
{"created":"2025-05-09","title":"Proximal Gradient Dynamics and Feedback Control for Equality-Constrained Composite Optimization","abstract":"This paper studies equality-constrained composite minimization problems. This class of problems, capturing regularization terms and convex inequality constraints, naturally arises in a wide range of engineering and machine learning applications. To tackle these minimization problems, we introduce the \\emph{proportional--integral proximal gradient dynamics} (PI--PGD): a closed-loop system where the Lagrange multipliers are control inputs and states are the problem decision variables. First, we establish the equivalence between the minima of the optimization problem and the equilibria of the PI--PGD. Then {for the case of affine constraints}, {by} leveraging tools from contraction theory we give a comprehensive convergence analysis for the dynamics, showing linear--exponential convergence towards the equilibrium. That is, the distance between each solution and the equilibrium is upper bounded by a function that first decreases linearly and then exponentially. Our findings are illustrated numerically on a set of representative examples, which include an application to entropy-regularized optimal transport.","authors":["Veronica Centorrino","Francesca Rossi","Francesco Bullo","Giovanni Russo"],"url":"https://arxiv.org/abs/2503.15093"}
{"created":"2025-05-09","title":"NaFM: Pre-training a Foundation Model for Small-Molecule Natural Products","abstract":"Natural products, as metabolites from microorganisms, animals, or plants, exhibit diverse biological activities, making them crucial for drug discovery. Nowadays, existing deep learning methods for natural products research primarily rely on supervised learning approaches designed for specific downstream tasks. However, such one-model-for-a-task paradigm often lacks generalizability and leaves significant room for performance improvement. Additionally, existing molecular characterization methods are not well-suited for the unique tasks associated with natural products. To address these limitations, we have pre-trained a foundation model for natural products based on their unique properties. Our approach employs a novel pretraining strategy that is especially tailored to natural products. By incorporating contrastive learning and masked graph learning objectives, we emphasize evolutional information from molecular scaffolds while capturing side-chain information. Our framework achieves state-of-the-art (SOTA) results in various downstream tasks related to natural product mining and drug discovery. We first compare taxonomy classification with synthesized molecule-focused baselines to demonstrate that current models are inadequate for understanding natural synthesis. Furthermore, by diving into a fine-grained analysis at both the gene and microbial levels, NaFM demonstrates the ability to capture evolutionary information. Eventually, our method is experimented with virtual screening, illustrating informative natural product representations that can lead to more effective identification of potential drug candidates.","authors":["Yuheng Ding","Yusong Wang","Bo Qiang","Jie Yu","Qi Li","Yiran Zhou","Zhenmin Liu"],"url":"https://arxiv.org/abs/2503.17656"}
{"created":"2025-05-09","title":"Novel Deep Neural OFDM Receiver Architectures for LLR Estimation","abstract":"Neural receivers have recently become a popular topic, where the received signals can be directly decoded by data driven mechanisms such as machine learning and deep learning. In this paper, we propose two novel neural network based orthogonal frequency division multiplexing (OFDM) receivers performing channel estimation and equalization tasks and directly predicting log likelihood ratios (LLRs) from the received in phase and quadrature phase (IQ) signals. The first network, the Dual Attention Transformer (DAT), employs a state of the art (SOTA) transformer architecture with an attention mechanism. The second network, the Residual Dual Non Local Attention Network (RDNLA), utilizes a parallel residual architecture with a non local attention block. The bit error rate (BER) and block error rate (BLER) performance of various SOTA neural receiver architectures is compared with our proposed methods across different signal to noise ratio (SNR) levels. The simulation results show that DAT and RDNLA outperform both traditional communication systems and existing neural receiver models.","authors":["Erhan Karakoca","H\\\"useyin \\c{C}evik","\\.Ibrahim H\\\"okelek","Ali G\\\"or\\c{c}in"],"url":"https://arxiv.org/abs/2503.20500"}
{"created":"2025-05-09","title":"Adaptive Attention-Based Model for 5G Radio-based Outdoor Localization","abstract":"Radio-based localization in dynamic environments, such as urban and vehicular settings, requires systems that efficiently adapt to varying signal conditions and environmental changes. Factors like multipath interference and obstructions introduce different levels of complexity that affect the accuracy of the localization. Although generalized models offer broad applicability, they often struggle to capture the nuances of specific environments, leading to suboptimal performance in real-world deployments. In contrast, specialized models can be tailored to particular conditions, enabling more precise localization by effectively handling domain-specific variations, which also results in reduced execution time and smaller model size. However, deploying multiple specialized models requires an efficient mechanism to select the most appropriate one for a given scenario. In this work, we develop an adaptive localization framework that combines shallow attention-based models with a router/switching mechanism based on a single-layer perceptron. This enables seamless transitions between specialized localization models optimized for different conditions, balancing accuracy and computational complexity. We design three low-complex models tailored for distinct scenarios, and a router that dynamically selects the most suitable model based on real-time input characteristics. The proposed framework is validated using real-world vehicle localization data collected from a massive MIMO base station and compared to more general models.","authors":["Ilayda Yaman","Guoda Tian","Dino Pjanic","Fredrik Tufvesson","Ove Edfors","Zhengya Zhang","Liang Liu"],"url":"https://arxiv.org/abs/2503.23810"}
{"created":"2025-05-09","title":"Hofmann-Streicher lifting of fibred categories","abstract":"In 1997, Hofmann and Streicher introduced an explicit construction to lift a Grothendieck universe $\\mathcal{U}$ from $\\mathbf{Set}$ into the category of $\\mathbf{Set}$-valued presheaves on a $\\mathcal{U}$-small category $B$. More recently, Awodey presented an elegant functorial analysis of this construction in terms of the categorical nerve, the right adjoint to the functor that takes a presheaf to its category of elements; in particular, the categorical nerve's functorial action on the universal $\\mathcal{U}$-small discrete fibration gives the generic family of $\\mathcal{U}$'s Hofmann-Streicher lifting. Inspired by Awodey's analysis, we define a relative version of Hofmann-Streicher lifting in terms of the right pseudo-adjoint to the 2-functor $\\mathbf{Fib}_{A}\\to\\mathbf{Fib}_{B}$ given by postcomposition with a fibration $p\\colon A\\to B$.","authors":["Andrew Slattery","Jonathan Sterling"],"url":"https://arxiv.org/abs/2504.09520"}
{"created":"2025-05-09","title":"A Quantum of Learning: Using Quaternion Algebra to Model Learning on Quantum Devices","abstract":"This article considers the problem of designing adaption and optimisation techniques for training quantum learning machines. To this end, the division algebra of quaternions is used to derive an effective model for representing computation and measurement operations on qubits. In turn, the derived model, serves as the foundation for formulating an adaptive learning problem on principal quantum learning units, thereby establishing quantum information processing units akin to that of neurons in classical approaches. Then, leveraging the modern HR-calculus, a comprehensive training framework for learning on quantum machines is developed. The quaternion-valued model accommodates mathematical tractability and establishment of performance criteria, such as convergence conditions.","authors":["Sayed Pouria Talebi","Clive Cheong Took","Danilo P. Mandic"],"url":"https://arxiv.org/abs/2504.13232"}
{"created":"2025-05-09","title":"PINN-MEP: Continuous Neural Representations for Minimum-Energy Path Discovery in Molecular Systems","abstract":"Characterizing conformational transitions in physical systems remains a fundamental challenge in the computational sciences. Traditional sampling methods like molecular dynamics (MD) or MCMC often struggle with the high-dimensional nature of molecular systems and the high energy barriers of transitions between stable states. While these transitions are rare events in simulation timescales, they often represent the most biologically significant processes - for example, the conformational change of an ion channel protein from its closed to open state, which controls cellular ion flow and is crucial for neural signaling. Such transitions in real systems may take milliseconds to seconds but could require months or years of continuous simulation to observe even once. We present a method that reformulates transition path generation as a continuous optimization problem solved through physics-informed neural networks (PINNs) inspired by string methods for minimum-energy path (MEP) generation. By representing transition paths as implicit neural functions and leveraging automatic differentiation with differentiable molecular dynamics force fields, our method enables the efficient discovery of physically realistic transition pathways without requiring expensive path sampling. We demonstrate our method's effectiveness on two proteins, including an explicitly hydrated bovine pancreatic trypsin inhibitor (BPTI) system with over 8,300 atoms.","authors":["Magnus Petersen","Roberto Covino"],"url":"https://arxiv.org/abs/2504.16381"}
{"created":"2025-05-09","title":"Modular Debiasing: A Robust Method for Quantum Randomness Extraction","abstract":"We propose a novel modular debiasing technique applicable to any discrete random source, addressing the fundamental challenge of reliably extracting high-quality randomness from inherently imperfect physical processes. The method involves summing the outcomes of multiple independent trials from a biased source and reducing the sum modulo the number of possible outcomes, $m$. We provide a rigorous theoretical framework, utilizing probability generating functions and roots of unity, demonstrating that this simple operation guarantees the exponential convergence of the output distribution to the ideal uniform distribution over $\\{0, 1, \\dots, m-1\\}$. A key theoretical result is the method's remarkable robustness: convergence is proven for any initial bias (provided all outcomes have non-zero probability) and, crucially, is maintained even under non-stationary conditions or time-dependent noise, which are common in physical systems. Analytical bounds quantify this exponential rate of convergence, and are empirically validated by numerical simulations. This technique's simplicity, strong theoretical guarantees, robustness, and data efficiency make it particularly well-suited for practical implementation in quantum settings, such as spatial photon-detection-based Quantum Random Number Generators (QRNGs), offering an efficient method for extracting high-quality randomness resilient to experimental imperfections. This work contributes a valuable tool to the field of Quantum Information Science.","authors":["Eduardo Gueron"],"url":"https://arxiv.org/abs/2504.18585"}
{"created":"2025-05-09","title":"Invariant Bridges Between Four Successive Points: A New Tool for Data Coding","abstract":"We introduce a simple yet powerful invariant relation connecting four successive terms of a class of exponentially decaying alternating functions. Specifically, for the sequence defined by f(n) = ((1/2)^n + (-1)^n) / n, we prove that the combination [(n-2)f(n-2) + (n-3)f(n-3)] / [n f(n) + (n-1)f(n-1)] is universally equal to 4 for all integers n >= 4. This invariant bridge across four points opens new possibilities for predictive coding, data compression, and error detection. We demonstrate how the relation can be used to reconstruct missing data, verify data integrity, and reduce redundancy in data streams with minimal computational overhead. The simplicity and universality of this invariant make it a promising tool for a wide range of applications in information theory and coding systems.","authors":["Stanislav Semenov"],"url":"https://arxiv.org/abs/2504.21473"}
{"created":"2025-05-09","title":"Leveraging Depth Maps and Attention Mechanisms for Enhanced Image Inpainting","abstract":"Existing deep learning-based image inpainting methods typically rely on convolutional networks with RGB images to reconstruct images. However, relying exclusively on RGB images may neglect important depth information, which plays a critical role in understanding the spatial and structural context of a scene. Just as human vision leverages stereo cues to perceive depth, incorporating depth maps into the inpainting process can enhance the model's ability to reconstruct images with greater accuracy and contextual awareness. In this paper, we propose a novel approach that incorporates both RGB and depth images for enhanced image inpainting. Our models employ a dual encoder architecture, where one encoder processes the RGB image and the other handles the depth image. The encoded features from both encoders are then fused in the decoder using an attention mechanism, effectively integrating the RGB and depth representations. We use two different masking strategies, line and square, to test the robustness of the model under different types of occlusions. To further analyze the effectiveness of our approach, we use Gradient-weighted Class Activation Mapping (Grad-CAM) visualizations to examine the regions of interest the model focuses on during inpainting. We show that incorporating depth information alongside the RGB image significantly improves the reconstruction quality. Through both qualitative and quantitative comparisons, we demonstrate that the depth-integrated model outperforms the baseline, with attention mechanisms further enhancing inpainting performance, as evidenced by multiple evaluation metrics and visualization.","authors":["Jin Hyun Park","Harine Choi","Praewa Pitiphat"],"url":"https://arxiv.org/abs/2505.00735"}
