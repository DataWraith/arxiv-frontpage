{"created":"2025-04-18","title":"Implementing Effective Changes in Software Projects to Optimize Runtimes and Minimize Defects","abstract":"The continuous evolution of software projects necessitates the implementation of changes to enhance performance and reduce defects. This research explores effective strategies for learning and implementing useful changes in software projects, focusing on optimizing runtimes and minimizing software defects. A comprehensive review of existing literature sets the foundation for understanding the current landscape of software optimization and defect reduction. The study employs a mixed-methods approach, incorporating both qualitative and quantitative data from software projects before and after changes were made. Key methodologies include detailed data collection on runtimes and defect rates, root cause analysis of common issues, and the application of best practices from successful case studies. The research highlights critical techniques for learning from past projects, identifying actionable changes, and ensuring their effective implementation. In-depth case study analysis provides insights into the practical challenges and success factors associated with these changes. Statistical analysis of the results demonstrates significant improvements in runtimes and defect rates, underscoring the value of a structured approach to software project optimization. The findings offer actionable recommendations for software development teams aiming to enhance project performance and reliability. This study contributes to the broader understanding of software engineering practices, providing a framework for continuous improvement in software projects. Future research directions are suggested to refine these strategies further and explore their application in diverse software development environments.","authors":["Kartik Gupta"],"url":"https://arxiv.org/abs/2504.12300"}
{"created":"2025-04-18","title":"Reachability in Geometrically $d$-Dimensional VASS","abstract":"Reachability of vector addition systems with states (VASS) is Ackermann complete~\\cite{leroux2021reachability,czerwinski2021reachability}. For $d$-dimensional VASS reachability it is known that the problem is NP-complete~\\cite{HaaseKreutzerOuaknineWorrell2009} when $d=1$, PSPACE-complete~\\cite{BlondinFinkelGoellerHaaseMcKenzie2015} when $d=2$, and in $\\mathbf{F}_d$~\\cite{FuYangZheng2024} when $d>2$. A geometrically $d$-dimensional VASS is a $D$-dimensional VASS for some $D\\ge d$ such that the space spanned by the displacements of the circular paths admitted in the $D$-dimensional VASS is $d$-dimensional. It is proved that the $\\mathbf{F}_d$ upper bounds remain valid for the reachability problem in the geometrically $d$-dimensional VASSes with $d>2$.","authors":["Yuxi Fu","Yangluo Zheng","Qizhe Yang"],"url":"https://arxiv.org/abs/2504.12302"}
{"created":"2025-04-18","title":"Unmasking the Reality of PII Masking Models: Performance Gaps and the Call for Accountability","abstract":"Privacy Masking is a critical concept under data privacy involving anonymization and de-anonymization of personally identifiable information (PII). Privacy masking techniques rely on Named Entity Recognition (NER) approaches under NLP support in identifying and classifying named entities in each text. NER approaches, however, have several limitations including (a) content sensitivity including ambiguous, polysemic, context dependent or domain specific content, (b) phrasing variabilities including nicknames and alias, informal expressions, alternative representations, emerging expressions, evolving naming conventions and (c) formats or syntax variations, typos, misspellings. However, there are a couple of PII datasets that have been widely used by researchers and the open-source community to train models on PII detection or masking. These datasets have been used to train models including Piiranha and Starpii, which have been downloaded over 300k and 580k times on HuggingFace. We examine the quality of the PII masking by these models given the limitations of the datasets and of the NER approaches. We curate a dataset of 17K unique, semi-synthetic sentences containing 16 types of PII by compiling information from across multiple jurisdictions including India, U.K and U.S. We generate sentences (using language models) containing these PII at five different NER detection feature dimensions - (1) Basic Entity Recognition, (2) Contextual Entity Disambiguation, (3) NER in Noisy & Real-World Data, (4) Evolving & Novel Entities Detection and (5) Cross-Lingual or multi-lingual NER) and 1 in adversarial context. We present the results and exhibit the privacy exposure caused by such model use (considering the extent of lifetime downloads of these models). We conclude by highlighting the gaps in measuring performance of the models and the need for contextual disclosure in model cards for such models.","authors":["Devansh Singh","Sundaraparipurnan Narayanan"],"url":"https://arxiv.org/abs/2504.12308"}
{"created":"2025-04-18","title":"Large Language Model-Based Knowledge Graph System Construction for Sustainable Development Goals: An AI-Based Speculative Design Perspective","abstract":"From 2000 to 2015, the UN's Millennium Development Goals guided global priorities. The subsequent Sustainable Development Goals (SDGs) adopted a more dynamic approach, with annual indicator updates. As 2030 nears and progress lags, innovative acceleration strategies are critical. This study develops an AI-powered knowledge graph system to analyze SDG interconnections, discover potential new goals, and visualize them online. Using official SDG texts, Elsevier's keyword dataset, and 1,127 TED Talk transcripts (2020-2023), a pilot on 269 talks from 2023 applies AI-speculative design, large language models, and retrieval-augmented generation. Key findings include: (1) Heatmap analysis reveals strong associations between Goal 10 and Goal 16, and minimal coverage of Goal 6. (2) In the knowledge graph, simulated dialogue over time reveals new central nodes, showing how richer data supports divergent thinking and goal clarity. (3) Six potential new goals are proposed, centered on equity, resilience, and technology-driven inclusion. This speculative-AI framework offers fresh insights for policymakers and lays groundwork for future multimodal and cross-system SDG applications.","authors":["Yi-De Lin","Guan-Ze Liao"],"url":"https://arxiv.org/abs/2504.12309"}
{"created":"2025-04-18","title":"Learning Optimal Prompt Ensemble for Multi-source Visual Prompt Transfer","abstract":"Prompt tuning has emerged as a lightweight adaptation strategy for adapting foundation models to downstream tasks, particularly in resource-constrained systems. As pre-trained prompts have become valuable intellectual assets, combining multiple source prompts offers a promising approach to enhance generalization to new tasks by leveraging complementary knowledge from diverse sources. However, naive aggregation of these prompts often leads to representation collapse due to mutual interference, undermining their collective potential. To address these challenges, we propose HGPrompt, an adaptive framework for multi-source prompt transfer that learns optimal ensemble weights by jointly optimizing dual objectives: transferability and stability. Specifically, we first introduce an information-theoretic metric to evaluate the transferability of prompt-induced features on the target task, capturing the intrinsic alignment between the feature representations. Additionally, we propose a novel Gradient Alignment Regularization to mitigate gradient conflicts among prompts, enabling stable and coherent knowledge transfer from multiple sources while suppressing interference. Extensive experiments on the large-scale VTAB benchmark demonstrate that HGPrompt achieves state-of-the-art performance, validating its effectiveness in multi-source prompt transfer.","authors":["Enming Zhang","Liwen Cao","Yanru Wu","Zijie Zhao","Guan Wang","Yang Li"],"url":"https://arxiv.org/abs/2504.12311"}
{"created":"2025-04-18","title":"Socrates or Smartypants: Testing Logic Reasoning Capabilities of Large Language Models with Logic Programming-based Test Oracles","abstract":"Large Language Models (LLMs) have achieved significant progress in language understanding and reasoning. Evaluating and analyzing their logical reasoning abilities has therefore become essential. However, existing datasets and benchmarks are often limited to overly simplistic, unnatural, or contextually constrained examples. In response to the growing demand, we introduce SmartyPat-Bench, a challenging, naturally expressed, and systematically labeled benchmark derived from real-world high-quality Reddit posts containing subtle logical fallacies. Unlike existing datasets and benchmarks, it provides more detailed annotations of logical fallacies and features more diverse data. To further scale up the study and address the limitations of manual data collection and labeling - such as fallacy-type imbalance and labor-intensive annotation - we introduce SmartyPat, an automated framework powered by logic programming-based oracles. SmartyPat utilizes Prolog rules to systematically generate logically fallacious statements, which are then refined into fluent natural-language sentences by LLMs, ensuring precise fallacy representation. Extensive evaluation demonstrates that SmartyPat produces fallacies comparable in subtlety and quality to human-generated content and significantly outperforms baseline methods. Finally, experiments reveal nuanced insights into LLM capabilities, highlighting that while excessive reasoning steps hinder fallacy detection accuracy, structured reasoning enhances fallacy categorization performance.","authors":["Zihao Xu","Junchen Ding","Yiling Lou","Kun Zhang","Dong Gong","Yuekang Li"],"url":"https://arxiv.org/abs/2504.12312"}
{"created":"2025-04-18","title":"Exploring the Impact of Personality Traits on Conversational Recommender Systems: A Simulation with Large Language Models","abstract":"Conversational Recommender Systems (CRSs) engage users in multi-turn interactions to deliver personalized recommendations. The emergence of large language models (LLMs) further enhances these systems by enabling more natural and dynamic user interactions. However, a key challenge remains in understanding how personality traits shape conversational recommendation outcomes. Psychological evidence highlights the influence of personality traits on user interaction behaviors. To address this, we introduce an LLM-based personality-aware user simulation for CRSs (PerCRS). The user agent induces customizable personality traits and preferences, while the system agent possesses the persuasion capability to simulate realistic interaction in CRSs. We incorporate multi-aspect evaluation to ensure robustness and conduct extensive analysis from both user and system perspectives. Experimental results demonstrate that state-of-the-art LLMs can effectively generate diverse user responses aligned with specified personality traits, thereby prompting CRSs to dynamically adjust their recommendation strategies. Our experimental analysis offers empirical insights into the impact of personality traits on the outcomes of conversational recommender systems.","authors":["Xiaoyan Zhao","Yang Deng","Wenjie Wang","Hongzhan lin","Hong Cheng","Rui Zhang","See-Kiong Ng","Tat-Seng Chua"],"url":"https://arxiv.org/abs/2504.12313"}
{"created":"2025-04-18","title":"How to Detect and Defeat Molecular Mirage: A Metric-Driven Benchmark for Hallucination in LLM-based Molecular Comprehension","abstract":"Large language models are increasingly used in scientific domains, especially for molecular understanding and analysis. However, existing models are affected by hallucination issues, resulting in errors in drug design and utilization. In this paper, we first analyze the sources of hallucination in LLMs for molecular comprehension tasks, specifically the knowledge shortcut phenomenon observed in the PubChem dataset. To evaluate hallucination in molecular comprehension tasks with computational efficiency, we introduce \\textbf{Mol-Hallu}, a novel free-form evaluation metric that quantifies the degree of hallucination based on the scientific entailment relationship between generated text and actual molecular properties. Utilizing the Mol-Hallu metric, we reassess and analyze the extent of hallucination in various LLMs performing molecular comprehension tasks. Furthermore, the Hallucination Reduction Post-processing stage~(HRPP) is proposed to alleviate molecular hallucinations, Experiments show the effectiveness of HRPP on decoder-only and encoder-decoder molecular LLMs. Our findings provide critical insights into mitigating hallucination and improving the reliability of LLMs in scientific applications.","authors":["Hao Li","Liuzhenghao Lv","He Cao","Zijing Liu","Zhiyuan Yan","Yu Wang","Yonghong Tian","Yu Li","Li Yuan"],"url":"https://arxiv.org/abs/2504.12314"}
{"created":"2025-04-18","title":"Capybara-OMNI: An Efficient Paradigm for Building Omni-Modal Language Models","abstract":"With the development of Multimodal Large Language Models (MLLMs), numerous outstanding accomplishments have emerged within the open-source community. Due to the complexity of creating and training multimodal data pairs, it is still a computational and time-consuming process to build powerful MLLMs. In this work, we introduce Capybara-OMNI, an MLLM that trains in a lightweight and efficient manner and supports understanding text, image, video, and audio modalities. We present in detail the framework design, the data construction, and the training recipe, to develop an MLLM step-by-step to obtain competitive performance. We also provide exclusive benchmarks utilized in our experiments to show how to properly verify understanding capabilities across different modalities. Results show that by following our guidance, we can efficiently build an MLLM that achieves competitive performance among models of the same scale on various multimodal benchmarks. Additionally, to enhance the multimodal instruction following and conversational capabilities of the model, we further discuss how to train the chat version upon an MLLM understanding model, which is more in line with user habits for tasks like real-time interaction with humans. We publicly disclose the Capybara-OMNI model, along with its chat-based version. The disclosure includes both the model weights, a portion of the training data, and the inference codes, which are made available on GitHub.","authors":["Xingguang Ji","Jiakang Wang","Hongzhi Zhang","Jingyuan Zhang","Haonan Zhou","Chenxi Sun","Yahui Liu","Qi Wang","Fuzheng Zhang"],"url":"https://arxiv.org/abs/2504.12315"}
{"created":"2025-04-18","title":"Data Metabolism: An Efficient Data Design Schema For Vision Language Model","abstract":"Data curation plays a crucial role in training powerful Visual Language Models (VLMs). In this work, we introduce the concept of Data Metabolism and present our data-centric framework to build VLMs throughout the development lifecycle. Starting from a standard model architecture, we discuss and provide insights into two crucial development steps: data curation and iteration, forming a closed-loop system that continuously improves model performance. We show a detailed codebook on how to process existing massive datasets and build user-specific data flywheel. As a demonstration, we release a VLM, named Capybara-VL, which excels in typical multimodal tasks (e.g. , visual question answering, scientific reasoning, and text-rich tasks). Despite its relatively compact size, Capybara-VL surpasses several open-source models that are up to 10 times larger in size. Moreover, it achieves results that are on par with those of several leading proprietary models, demonstrating its remarkable competitiveness. These results highlight the power of our data-centric framework and the potential of training smaller and more efficient VLMs.","authors":["Jingyuan Zhang","Hongzhi Zhang","Zhou Haonan","Chenxi Sun","Xingguang ji","Jiakang Wang","Fanheng Kong","Yahui Liu","Qi Wang","Fuzheng Zhang"],"url":"https://arxiv.org/abs/2504.12316"}
{"created":"2025-04-18","title":"ChatGPT as Linguistic Equalizer? Quantifying LLM-Driven Lexical Shifts in Academic Writing","abstract":"The advent of ChatGPT has profoundly reshaped scientific research practices, particularly in academic writing, where non-native English-speakers (NNES) historically face linguistic barriers. This study investigates whether ChatGPT mitigates these barriers and fosters equity by analyzing lexical complexity shifts across 2.8 million articles from OpenAlex (2020-2024). Using the Measure of Textual Lexical Diversity (MTLD) to quantify vocabulary sophistication and a difference-in-differences (DID) design to identify causal effects, we demonstrate that ChatGPT significantly enhances lexical complexity in NNES-authored abstracts, even after controlling for article-level controls, authorship patterns, and venue norms. Notably, the impact is most pronounced in preprint papers, technology- and biology-related fields and lower-tier journals. These findings provide causal evidence that ChatGPT reduces linguistic disparities and promotes equity in global academia.","authors":["Dingkang Lin","Naixuan Zhao","Dan Tian","Jiang Li"],"url":"https://arxiv.org/abs/2504.12317"}
{"created":"2025-04-18","title":"AUTONAV: A Toolfor Autonomous Navigation of Robots","abstract":"We present a tool AUTONAV that automates the mapping, localization, and path-planning tasks for autonomous navigation of robots. The modular architecture allows easy integration of various algorithms for these tasks for comparison. We present the generated maps and path-plans by AUTONAV in indoor simulation scenarios.","authors":["Mir Md Sajid Sarwar","Sudip Samanta","Rajarshi Ray"],"url":"https://arxiv.org/abs/2504.12318"}
{"created":"2025-04-18","title":"Specialized text classification: an approach to classifying Open Banking transactions","abstract":"With the introduction of the PSD2 regulation in the EU which established the Open Banking framework, a new window of opportunities has opened for banks and fintechs to explore and enrich Bank transaction descriptions with the aim of building a better understanding of customer behavior, while using this understanding to prevent fraud, reduce risks and offer more competitive and tailored services.","authors":["Duc Tuyen TA","Wajdi Ben Saad","Ji Young Oh"],"url":"https://arxiv.org/abs/2504.12319"}
{"created":"2025-04-18","title":"Has the Creativity of Large-Language Models peaked? An analysis of inter- and intra-LLM variability","abstract":"Following the widespread adoption of ChatGPT in early 2023, numerous studies reported that large language models (LLMs) can match or even surpass human performance in creative tasks. However, it remains unclear whether LLMs have become more creative over time, and how consistent their creative output is. In this study, we evaluated 14 widely used LLMs -- including GPT-4, Claude, Llama, Grok, Mistral, and DeepSeek -- across two validated creativity assessments: the Divergent Association Task (DAT) and the Alternative Uses Task (AUT). Contrary to expectations, we found no evidence of increased creative performance over the past 18-24 months, with GPT-4 performing worse than in previous studies. For the more widely used AUT, all models performed on average better than the average human, with GPT-4o and o3-mini performing best. However, only 0.28% of LLM-generated responses reached the top 10% of human creativity benchmarks. Beyond inter-model differences, we document substantial intra-model variability: the same LLM, given the same prompt, can produce outputs ranging from below-average to original. This variability has important implications for both creativity research and practical applications. Ignoring such variability risks misjudging the creative potential of LLMs, either inflating or underestimating their capabilities. The choice of prompts affected LLMs differently. Our findings underscore the need for more nuanced evaluation frameworks and highlight the importance of model selection, prompt design, and repeated assessment when using Generative AI (GenAI) tools in creative contexts.","authors":["Jennifer Haase","Paul H. P. Hanel","Sebastian Pokutta"],"url":"https://arxiv.org/abs/2504.12320"}
{"created":"2025-04-18","title":"AttentionDefense: Leveraging System Prompt Attention for Explainable Defense Against Novel Jailbreaks","abstract":"In the past few years, Language Models (LMs) have shown par-human capabilities in several domains. Despite their practical applications and exceeding user consumption, they are susceptible to jailbreaks when malicious input exploits the LM's weaknesses, causing it to deviate from its intended behavior. Current defensive strategies either classify the input prompt as adversarial or prevent LMs from generating harmful outputs. However, it is challenging to explain the reason behind the malicious nature of the jailbreak, which results in a wide variety of closed-box approaches. In this research, we propose and demonstrate that system-prompt attention from Small Language Models (SLMs) can be used to characterize adversarial prompts, providing a novel, explainable, and cheaper defense approach called AttentionDefense. Our research suggests that the attention mechanism is an integral component in understanding and explaining how LMs respond to malicious input that is not captured in the semantic meaning of text embeddings. The proposed AttentionDefense is evaluated against existing jailbreak benchmark datasets. Ablation studies show that SLM-based AttentionDefense has equivalent or better jailbreak detection performance compared to text embedding-based classifiers and GPT-4 zero-shot detectors.To further validate the efficacy of the proposed approach, we generate a dataset of novel jailbreak variants of the existing benchmark dataset using a closed-loop LLM-based multi-agent system. We demonstrate that the proposed AttentionDefense approach performs robustly on this novel jailbreak dataset while existing approaches suffer in performance. Additionally, for practical purposes AttentionDefense is an ideal solution as it has the computation requirements of a small LM but the performance of a LLM detector.","authors":["Charlotte Siska","Anush Sankaran"],"url":"https://arxiv.org/abs/2504.12321"}
{"created":"2025-04-18","title":"A Strategic Coordination Framework of Small LLMs Matches Large LLMs in Data Synthesis","abstract":"While data synthesis and distillation are promising strategies to enhance small language models, current approaches heavily rely on Large Language Models (LLMs), which suffer from high computational costs, environmental inefficiency, and potential biases inherited from monolithic architectures. In contrast, smaller LLMs are more accessible and sustainable, but their individual capabilities often fall short in generating high-quality, diverse, and reliable data. Inspired by collaborative human processes (e.g., peer review), we propose a multiple small LLMs involved framework, GRA, that aggregates specialized roles across small LLMs to iterative refinement and quality control typically achieved by a single large LLM. In this collaborative framework, multiple small LLMs assume distinct roles-Generator, Reviewer, and Adjudicator-to simulate a peer-review-inspired data synthesis pipeline. The Generator proposes initial data samples, the Reviewer critiques their quality and diversity, and the Adjudicator resolves conflicts to finalize the output. By decomposing the synthesis process into specialized sub-tasks, collaborative small LLMs can achieve data-level parity with large LLM-based distillation. Through experiments across multiple benchmarks, we demonstrate that GRA-produced data matches or exceeds the quality of single large LLM outputs, e.g., Qwen-2.5-72B-Instruct. Our results challenge the necessity of monolithic large models for high-quality data synthesis, advocating instead for strategic coordination of smaller agents. Our datasets, models, and code are publicly available at https://github.com/GX-XinGao/GRA.","authors":["Xin Gao","Qizhi Pei","Zinan Tang","Yu Li","Honglin Lin","Jiang Wu","Conghui He","Lijun Wu"],"url":"https://arxiv.org/abs/2504.12322"}
{"created":"2025-04-18","title":"The Other Side of the Coin: Exploring Fairness in Retrieval-Augmented Generation","abstract":"Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by retrieving relevant document from external knowledge sources. By referencing this external knowledge, RAG effectively reduces the generation of factually incorrect content and addresses hallucination issues within LLMs. Recently, there has been growing attention to improving the performance and efficiency of RAG systems from various perspectives. While these advancements have yielded significant results, the application of RAG in domains with considerable societal implications raises a critical question about fairness: What impact does the introduction of the RAG paradigm have on the fairness of LLMs? To address this question, we conduct extensive experiments by varying the LLMs, retrievers, and retrieval sources. Our experimental analysis reveals that the scale of the LLMs plays a significant role in influencing fairness outcomes within the RAG framework. When the model scale is smaller than 8B, the integration of retrieval mechanisms often exacerbates unfairness in small-scale LLMs (e.g., LLaMA3.2-1B, Mistral-7B, and LLaMA3-8B). To mitigate the fairness issues introduced by RAG for small-scale LLMs, we propose two approaches, FairFT and FairFilter. Specifically, in FairFT, we align the retriever with the LLM in terms of fairness, enabling it to retrieve documents that facilitate fairer model outputs. In FairFilter, we propose a fairness filtering mechanism to filter out biased content after retrieval. Finally, we validate our proposed approaches on real-world datasets, demonstrating their effectiveness in improving fairness while maintaining performance.","authors":["Zheng Zhang","Ning Li","Qi Liu","Rui Li","Weibo Gao","Qingyang Mao","Zhenya Huang","Baosheng Yu","Dacheng Tao"],"url":"https://arxiv.org/abs/2504.12323"}
{"created":"2025-04-18","title":"Cross-Document Cross-Lingual Natural Language Inference via RST-enhanced Graph Fusion and Interpretability Prediction","abstract":"Natural Language Inference (NLI) is a fundamental task in both natural language processing and information retrieval. While NLI has developed many sub-directions such as sentence-level NLI, document-level NLI and cross-lingual NLI, Cross-Document Cross-Lingual NLI (CDCL-NLI) remains largely unexplored. In this paper, we propose a novel paradigm for CDCL-NLI that extends traditional NLI capabilities to multi-document, multilingual scenarios. To support this task, we construct a high-quality CDCL-NLI dataset including 1,110 instances and spanning 26 languages. To build a baseline for this task, we also propose an innovative method that integrates RST-enhanced graph fusion and interpretability prediction. Our method employs RST (Rhetorical Structure Theory) on RGAT (Relation-aware Graph Attention Network) for cross-document context modeling, coupled with a structure-aware semantic alignment mechanism based on lexical chains for cross-lingual understanding. For NLI interpretability, we develop an EDU-level attribution framework that generates extractive explanations. Extensive experiments demonstrate our approach's superior performance, achieving significant improvements over both traditional NLI models such as DocNLI and R2F, as well as LLMs like Llama3 and GPT-4o. Our work sheds light on the study of NLI and will bring research interest on cross-document cross-lingual context understanding, semantic retrieval and interpretability inference. Our dataset and code are available at \\href{https://anonymous.4open.science/r/CDCL-NLI-637E/}{CDCL-NLI-Link for peer review}.","authors":["Mengying Yuan","Wangzi Xuan","Fei Li"],"url":"https://arxiv.org/abs/2504.12324"}
{"created":"2025-04-18","title":"LLMTaxo: Leveraging Large Language Models for Constructing Taxonomy of Factual Claims from Social Media","abstract":"With the vast expansion of content on social media platforms, analyzing and comprehending online discourse has become increasingly complex. This paper introduces LLMTaxo, a novel framework leveraging large language models for the automated construction of taxonomy of factual claims from social media by generating topics from multi-level granularities. This approach aids stakeholders in more effectively navigating the social media landscapes. We implement this framework with different models across three distinct datasets and introduce specially designed taxonomy evaluation metrics for a comprehensive assessment. With the evaluations from both human evaluators and GPT-4, the results indicate that LLMTaxo effectively categorizes factual claims from social media, and reveals that certain models perform better on specific datasets.","authors":["Haiqi Zhang","Zhengyuan Zhu","Zeyu Zhang","Chengkai Li"],"url":"https://arxiv.org/abs/2504.12325"}
{"created":"2025-04-18","title":"Reconstructing Sepsis Trajectories from Clinical Case Reports using LLMs: the Textual Time Series Corpus for Sepsis","abstract":"Clinical case reports and discharge summaries may be the most complete and accurate summarization of patient encounters, yet they are finalized, i.e., timestamped after the encounter. Complementary data structured streams become available sooner but suffer from incompleteness. To train models and algorithms on more complete and temporally fine-grained data, we construct a pipeline to phenotype, extract, and annotate time-localized findings within case reports using large language models. We apply our pipeline to generate an open-access textual time series corpus for Sepsis-3 comprising 2,139 case reports from the Pubmed-Open Access (PMOA) Subset. To validate our system, we apply it on PMOA and timeline annotations from I2B2/MIMIC-IV and compare the results to physician-expert annotations. We show high recovery rates of clinical findings (event match rates: O1-preview--0.755, Llama 3.3 70B Instruct--0.753) and strong temporal ordering (concordance: O1-preview--0.932, Llama 3.3 70B Instruct--0.932). Our work characterizes the ability of LLMs to time-localize clinical findings in text, illustrating the limitations of LLM use for temporal reconstruction and providing several potential avenues of improvement via multimodal integration.","authors":["Shahriar Noroozizadeh","Jeremy C. Weiss"],"url":"https://arxiv.org/abs/2504.12326"}
{"created":"2025-04-18","title":"Word Embeddings Track Social Group Changes Across 70 Years in China","abstract":"Language encodes societal beliefs about social groups through word patterns. While computational methods like word embeddings enable quantitative analysis of these patterns, studies have primarily examined gradual shifts in Western contexts. We present the first large-scale computational analysis of Chinese state-controlled media (1950-2019) to examine how revolutionary social transformations are reflected in official linguistic representations of social groups. Using diachronic word embeddings at multiple temporal resolutions, we find that Chinese representations differ significantly from Western counterparts, particularly regarding economic status, ethnicity, and gender. These representations show distinct evolutionary dynamics: while stereotypes of ethnicity, age, and body type remain remarkably stable across political upheavals, representations of gender and economic classes undergo dramatic shifts tracking historical transformations. This work advances our understanding of how officially sanctioned discourse encodes social structure through language while highlighting the importance of non-Western perspectives in computational social science.","authors":["Yuxi Ma","Yongqian Peng","Yixin Zhu"],"url":"https://arxiv.org/abs/2504.12327"}
{"created":"2025-04-18","title":"A Comprehensive Survey of Reward Models: Taxonomy, Applications, Challenges, and Future","abstract":"Reward Model (RM) has demonstrated impressive potential for enhancing Large Language Models (LLM), as RM can serve as a proxy for human preferences, providing signals to guide LLMs' behavior in various tasks. In this paper, we provide a comprehensive overview of relevant research, exploring RMs from the perspectives of preference collection, reward modeling, and usage. Next, we introduce the applications of RMs and discuss the benchmarks for evaluation. Furthermore, we conduct an in-depth analysis of the challenges existing in the field and dive into the potential research directions. This paper is dedicated to providing beginners with a comprehensive introduction to RMs and facilitating future studies. The resources are publicly available at github\\footnote{https://github.com/JLZhong23/awesome-reward-models}.","authors":["Jialun Zhong","Wei Shen","Yanzeng Li","Songyang Gao","Hua Lu","Yicheng Chen","Yang Zhang","Wei Zhou","Jinjie Gu","Lei Zou"],"url":"https://arxiv.org/abs/2504.12328"}
{"created":"2025-04-18","title":"Speculative Thinking: Enhancing Small-Model Reasoning with Large Model Guidance at Inference Time","abstract":"Recent advances leverage post-training to enhance model reasoning performance, which typically requires costly training pipelines and still suffers from inefficient, overly lengthy outputs. We introduce Speculative Thinking, a training-free framework that enables large reasoning models to guide smaller ones during inference at the reasoning level, distinct from speculative decoding, which operates at the token level. Our approach is based on two observations: (1) reasoning-supportive tokens such as \"wait\" frequently appear after structural delimiters like \"\\n\\n\", serving as signals for reflection or continuation; and (2) larger models exhibit stronger control over reflective behavior, reducing unnecessary backtracking while improving reasoning quality. By strategically delegating reflective steps to a more capable model, our method significantly boosts the reasoning accuracy of reasoning models while shortening their output. With the assistance of the 32B reasoning model, the 1.5B model's accuracy on MATH500 increases from 83.2% to 89.4%, marking a substantial improvement of 6.2%. Simultaneously, the average output length is reduced from 5439 tokens to 4583 tokens, representing a 15.7% decrease. Moreover, when applied to a non-reasoning model (Qwen-2.5-7B-Instruct), our framework boosts its accuracy from 74.0% to 81.8% on the same benchmark, achieving a relative improvement of 7.8%.","authors":["Wang Yang","Xiang Yue","Vipin Chaudhary","Xiaotian Han"],"url":"https://arxiv.org/abs/2504.12329"}
{"created":"2025-04-18","title":"HM-RAG: Hierarchical Multi-Agent Multimodal Retrieval Augmented Generation","abstract":"While Retrieval-Augmented Generation (RAG) augments Large Language Models (LLMs) with external knowledge, conventional single-agent RAG remains fundamentally limited in resolving complex queries demanding coordinated reasoning across heterogeneous data ecosystems. We present HM-RAG, a novel Hierarchical Multi-agent Multimodal RAG framework that pioneers collaborative intelligence for dynamic knowledge synthesis across structured, unstructured, and graph-based data. The framework is composed of three-tiered architecture with specialized agents: a Decomposition Agent that dissects complex queries into contextually coherent sub-tasks via semantic-aware query rewriting and schema-guided context augmentation; Multi-source Retrieval Agents that carry out parallel, modality-specific retrieval using plug-and-play modules designed for vector, graph, and web-based databases; and a Decision Agent that uses consistency voting to integrate multi-source answers and resolve discrepancies in retrieval results through Expert Model Refinement. This architecture attains comprehensive query understanding by combining textual, graph-relational, and web-derived evidence, resulting in a remarkable 12.95% improvement in answer accuracy and a 3.56% boost in question classification accuracy over baseline RAG systems on the ScienceQA and CrisisMMD benchmarks. Notably, HM-RAG establishes state-of-the-art results in zero-shot settings on both datasets. Its modular architecture ensures seamless integration of new data modalities while maintaining strict data governance, marking a significant advancement in addressing the critical challenges of multimodal reasoning and knowledge synthesis in RAG systems. Code is available at https://github.com/ocean-luna/HMRAG.","authors":["Pei Liu","Xin Liu","Ruoyu Yao","Junming Liu","Siyuan Meng","Ding Wang","Jun Ma"],"url":"https://arxiv.org/abs/2504.12330"}
{"created":"2025-04-18","title":"Span-level Emotion-Cause-Category Triplet Extraction with Instruction Tuning LLMs and Data Augmentation","abstract":"Span-level emotion-cause-category triplet extraction represents a novel and complex challenge within emotion cause analysis. This task involves identifying emotion spans, cause spans, and their associated emotion categories within the text to form structured triplets. While prior research has predominantly concentrated on clause-level emotion-cause pair extraction and span-level emotion-cause detection, these methods often confront challenges originating from redundant information retrieval and difficulty in accurately determining emotion categories, particularly when emotions are expressed implicitly or ambiguously. To overcome these challenges, this study explores a fine-grained approach to span-level emotion-cause-category triplet extraction and introduces an innovative framework that leverages instruction tuning and data augmentation techniques based on large language models. The proposed method employs task-specific triplet extraction instructions and utilizes low-rank adaptation to fine-tune large language models, eliminating the necessity for intricate task-specific architectures. Furthermore, a prompt-based data augmentation strategy is developed to address data scarcity by guiding large language models in generating high-quality synthetic training data. Extensive experimental evaluations demonstrate that the proposed approach significantly outperforms existing baseline methods, achieving at least a 12.8% improvement in span-level emotion-cause-category triplet extraction metrics. The results demonstrate the method's effectiveness and robustness, offering a promising avenue for advancing research in emotion cause analysis. The source code is available at https://github.com/zxgnlp/InstruDa-LLM.","authors":["Xiangju Li","Dong Yang","Xiaogang Zhu","Faliang Huang","Peng Zhang","Zhongying Zhao"],"url":"https://arxiv.org/abs/2504.12331"}
{"created":"2025-04-18","title":"Can the capability of Large Language Models be described by human ability? A Meta Study","abstract":"Users of Large Language Models (LLMs) often perceive these models as intelligent entities with human-like capabilities. However, the extent to which LLMs' capabilities truly approximate human abilities remains a topic of debate. In this paper, to characterize the capabilities of LLMs in relation to human capabilities, we collected performance data from over 80 models across 37 evaluation benchmarks. The evaluation benchmarks are categorized into 6 primary abilities and 11 sub-abilities in human aspect. Then, we then clustered the performance rankings into several categories and compared these clustering results with classifications based on human ability aspects. Our findings lead to the following conclusions: 1. We have confirmed that certain capabilities of LLMs with fewer than 10 billion parameters can indeed be described using human ability metrics; 2. While some abilities are considered interrelated in humans, they appear nearly uncorrelated in LLMs; 3. The capabilities possessed by LLMs vary significantly with the parameter scale of the model.","authors":["Mingrui Zan","Yunquan Zhang","Boyang Zhang","Fangming Liu","Daning Cheng"],"url":"https://arxiv.org/abs/2504.12332"}
{"created":"2025-04-18","title":"Meta-Evaluating Local LLMs: Rethinking Performance Metrics for Serious Games","abstract":"The evaluation of open-ended responses in serious games presents a unique challenge, as correctness is often subjective. Large Language Models (LLMs) are increasingly being explored as evaluators in such contexts, yet their accuracy and consistency remain uncertain, particularly for smaller models intended for local execution. This study investigates the reliability of five small-scale LLMs when assessing player responses in \\textit{En-join}, a game that simulates decision-making within energy communities. By leveraging traditional binary classification metrics (including accuracy, true positive rate, and true negative rate), we systematically compare these models across different evaluation scenarios. Our results highlight the strengths and limitations of each model, revealing trade-offs between sensitivity, specificity, and overall performance. We demonstrate that while some models excel at identifying correct responses, others struggle with false positives or inconsistent evaluations. The findings highlight the need for context-aware evaluation frameworks and careful model selection when deploying LLMs as evaluators. This work contributes to the broader discourse on the trustworthiness of AI-driven assessment tools, offering insights into how different LLM architectures handle subjective evaluation tasks.","authors":["Andr\\'es Isaza-Giraldo","Paulo Bala","Lucas Pereira"],"url":"https://arxiv.org/abs/2504.12333"}
{"created":"2025-04-18","title":"QM-ToT: A Medical Tree of Thoughts Reasoning Framework for Quantized Model","abstract":"Large language models (LLMs) face significant challenges in specialized biomedical tasks due to the inherent complexity of medical reasoning and the sensitive nature of clinical data. Existing LLMs often struggle with intricate medical terminology and the need for accurate clinical insights, leading to performance reduction when quantized for resource-constrained deployment. To address these issues, we propose Quantized Medical Tree of Thought (QM-ToT), a path-based reasoning framework. QM-ToT leverages a Tree of Thought (ToT) reasoning approach to decompose complex medical problems into manageable subtasks, coupled with evaluator assessment layers. This framework facilitates substantial performance improvements in INT4-quantized models on the challenging MedQAUSMLE dataset. Specifically, we demonstrate a remarkable accuracy increase from 34% to 50% for the LLaMA2-70b model and from 58.77% to 69.49% for LLaMA-3.1-8b. Besides, we also proposed an effect data distillation method based on ToT. Compared to the traditional distillation method, we achieved an improvement of 86. 27% while using only 3.9% of the data.This work, for the first time, showcases the potential of ToT to significantly enhance performance on complex biomedical tasks, establishing a crucial foundation for future advances in deploying high-performing quantized LLM in resource-limited medical settings.","authors":["Zongxian Yang","Jiayu Qian","Zhi-An Huang","Kay Chen Tan"],"url":"https://arxiv.org/abs/2504.12334"}
{"created":"2025-04-18","title":"You've Changed: Detecting Modification of Black-Box Large Language Models","abstract":"Large Language Models (LLMs) are often provided as a service via an API, making it challenging for developers to detect changes in their behavior. We present an approach to monitor LLMs for changes by comparing the distributions of linguistic and psycholinguistic features of generated text. Our method uses a statistical test to determine whether the distributions of features from two samples of text are equivalent, allowing developers to identify when an LLM has changed. We demonstrate the effectiveness of our approach using five OpenAI completion models and Meta's Llama 3 70B chat model. Our results show that simple text features coupled with a statistical test can distinguish between language models. We also explore the use of our approach to detect prompt injection attacks. Our work enables frequent LLM change monitoring and avoids computationally expensive benchmark evaluations.","authors":["Alden Dima","James Foulds","Shimei Pan","Philip Feldman"],"url":"https://arxiv.org/abs/2504.12335"}
{"created":"2025-04-18","title":"\"It Listens Better Than My Therapist\": Exploring Social Media Discourse on LLMs as Mental Health Tool","abstract":"The emergence of generative AI chatbots such as ChatGPT has prompted growing public and academic interest in their role as informal mental health support tools. While early rule-based systems have been around for several years, large language models (LLMs) offer new capabilities in conversational fluency, empathy simulation, and availability. This study explores how users engage with LLMs as mental health tools by analyzing over 10,000 TikTok comments from videos referencing LLMs as mental health tools. Using a self-developed tiered coding schema and supervised classification models, we identify user experiences, attitudes, and recurring themes. Results show that nearly 20% of comments reflect personal use, with these users expressing overwhelmingly positive attitudes. Commonly cited benefits include accessibility, emotional support, and perceived therapeutic value. However, concerns around privacy, generic responses, and the lack of professional oversight remain prominent. It is important to note that the user feedback does not indicate which therapeutic framework, if any, the LLM-generated output aligns with. While the findings underscore the growing relevance of AI in everyday practices, they also highlight the urgent need for clinical and ethical scrutiny in the use of AI for mental health support.","authors":["Anna-Carolina Haensch"],"url":"https://arxiv.org/abs/2504.12337"}
{"created":"2025-04-18","title":"Paging Dr. GPT: Extracting Information from Clinical Notes to Enhance Patient Predictions","abstract":"There is a long history of building predictive models in healthcare using tabular data from electronic medical records. However, these models fail to extract the information found in unstructured clinical notes, which document diagnosis, treatment, progress, medications, and care plans. In this study, we investigate how answers generated by GPT-4o-mini (ChatGPT) to simple clinical questions about patients, when given access to the patient's discharge summary, can support patient-level mortality prediction. Using data from 14,011 first-time admissions to the Coronary Care or Cardiovascular Intensive Care Units in the MIMIC-IV Note dataset, we implement a transparent framework that uses GPT responses as input features in logistic regression models. Our findings demonstrate that GPT-based models alone can outperform models trained on standard tabular data, and that combining both sources of information yields even greater predictive power, increasing AUC by an average of 5.1 percentage points and increasing positive predictive value by 29.9 percent for the highest-risk decile. These results highlight the value of integrating large language models (LLMs) into clinical prediction tasks and underscore the broader potential for using LLMs in any domain where unstructured text data remains an underutilized resource.","authors":["David Anderson","Michaela Anderson","Margret Bjarnadottir","Stephen Mahar","Shriyan Reyya"],"url":"https://arxiv.org/abs/2504.12338"}
{"created":"2025-04-18","title":"GOAT-TTS: LLM-based Text-To-Speech Generation Optimized via A Dual-Branch Architecture","abstract":"While large language models (LLMs) have revolutionized text-to-speech (TTS) synthesis through discrete tokenization paradigms, current architectures exhibit fundamental tensions between three critical dimensions: 1) irreversible loss of acoustic characteristics caused by quantization of speech prompts; 2) stringent dependence on precisely aligned prompt speech-text pairs that limit real-world deployment; and 3) catastrophic forgetting of the LLM's native text comprehension during optimization for speech token generation. To address these challenges, we propose an LLM-based text-to-speech Generation approach Optimized via a novel dual-branch ArchiTecture (GOAT-TTS). Our framework introduces two key innovations: (1) The modality-alignment branch combines a speech encoder and projector to capture continuous acoustic embeddings, enabling bidirectional correlation between paralinguistic features (language, timbre, emotion) and semantic text representations without transcript dependency; (2) The speech-generation branch employs modular fine-tuning on top-k layers of an LLM for speech token prediction while freezing the bottom-k layers to preserve foundational linguistic knowledge. Moreover, multi-token prediction is introduced to support real-time streaming TTS synthesis. Experimental results demonstrate that our GOAT-TTS achieves performance comparable to state-of-the-art TTS models while validating the efficacy of synthesized dialect speech data.","authors":["Yaodong Song","Hongjie Chen","Jie Lian","Yuxin Zhang","Guangmin Xia","Zehan Li","Genliang Zhao","Jian Kang","Yongxiang Li","Jie Li"],"url":"https://arxiv.org/abs/2504.12339"}
{"created":"2025-04-18","title":"Streamlining Biomedical Research with Specialized LLMs","abstract":"In this paper, we propose a novel system that integrates state-of-the-art, domain-specific large language models with advanced information retrieval techniques to deliver comprehensive and context-aware responses. Our approach facilitates seamless interaction among diverse components, enabling cross-validation of outputs to produce accurate, high-quality responses enriched with relevant data, images, tables, and other modalities. We demonstrate the system's capability to enhance response precision by leveraging a robust question-answering model, significantly improving the quality of dialogue generation. The system provides an accessible platform for real-time, high-fidelity interactions, allowing users to benefit from efficient human-computer interaction, precise retrieval, and simultaneous access to a wide range of literature and data. This dramatically improves the research efficiency of professionals in the biomedical and pharmaceutical domains and facilitates faster, more informed decision-making throughout the R\\&amp;D process. Furthermore, the system proposed in this paper is available at https://synapse-chat.patsnap.com.","authors":["Linqing Chen","Weilei Wang","Yubin Xia","Wentao Wu","Peng Xu","Zilong Bai","Jie Fang","Chaobo Xu","Ran Hu","Licong Xu","Haoran Hua","Jing Sun","Hanmeng Zhong","Jin Liu","Tian Qiu","Haowen Liu","Meng Hu","Xiuwen Li","Fei Gao","Yong Gu","Tao Shi","Chaochao Wang","Jianping Lu","Cheng Sun","Yixin Wang","Shengjie Yang","Yuancheng Li","Lu Jin","Lisha Zhang","Fu Bian","Zhongkai Ye","Lidong Pei","Changyang Tu"],"url":"https://arxiv.org/abs/2504.12341"}
{"created":"2025-04-18","title":"Benchmarking Biopharmaceuticals Retrieval-Augmented Generation Evaluation","abstract":"Recently, the application of the retrieval-augmented Large Language Models (LLMs) in specific domains has gained significant attention, especially in biopharmaceuticals. However, in this context, there is no benchmark specifically designed for biopharmaceuticals to evaluate LLMs. In this paper, we introduce the Biopharmaceuticals Retrieval-Augmented Generation Evaluation (BRAGE) , the first benchmark tailored for evaluating LLMs' Query and Reference Understanding Capability (QRUC) in the biopharmaceutical domain, available in English, French, German and Chinese. In addition, Traditional Question-Answering (QA) metrics like accuracy and exact match fall short in the open-ended retrieval-augmented QA scenarios. To address this, we propose a citation-based classification method to evaluate the QRUC of LLMs to understand the relationship between queries and references. We apply this method to evaluate the mainstream LLMs on BRAGE. Experimental results show that there is a significant gap in the biopharmaceutical QRUC of mainstream LLMs, and their QRUC needs to be improved.","authors":["Hanmeng Zhong","Linqing Chen","Weilei Wang","Wentao Wu"],"url":"https://arxiv.org/abs/2504.12342"}
{"created":"2025-04-18","title":"Propaganda via AI? A Study on Semantic Backdoors in Large Language Models","abstract":"Large language models (LLMs) demonstrate remarkable performance across myriad language tasks, yet they remain vulnerable to backdoor attacks, where adversaries implant hidden triggers that systematically manipulate model outputs. Traditional defenses focus on explicit token-level anomalies and therefore overlook semantic backdoors-covert triggers embedded at the conceptual level (e.g., ideological stances or cultural references) that rely on meaning-based cues rather than lexical oddities. We first show, in a controlled finetuning setting, that such semantic backdoors can be implanted with only a small poisoned corpus, establishing their practical feasibility. We then formalize the notion of semantic backdoors in LLMs and introduce a black-box detection framework, RAVEN (short for \"Response Anomaly Vigilance for uncovering semantic backdoors\"), which combines semantic entropy with cross-model consistency analysis. The framework probes multiple models with structured topic-perspective prompts, clusters the sampled responses via bidirectional entailment, and flags anomalously uniform outputs; cross-model comparison isolates model-specific anomalies from corpus-wide biases. Empirical evaluations across diverse LLM families (GPT-4o, Llama, DeepSeek, Mistral) uncover previously undetected semantic backdoors, providing the first proof-of-concept evidence of these hidden vulnerabilities and underscoring the urgent need for concept-level auditing of deployed language models. We open-source our code and data at https://github.com/NayMyatMin/RAVEN.","authors":["Nay Myat Min","Long H. Pham","Yige Li","Jun Sun"],"url":"https://arxiv.org/abs/2504.12344"}
{"created":"2025-04-18","title":"Reimagining Urban Science: Scaling Causal Inference with Large Language Models","abstract":"Urban causal research is essential for understanding the complex dynamics of cities and informing evidence-based policies. However, it is challenged by the inefficiency and bias of hypothesis generation, barriers to multimodal data complexity, and the methodological fragility of causal experimentation. Recent advances in large language models (LLMs) present an opportunity to rethink how urban causal analysis is conducted. This Perspective examines current urban causal research by analyzing taxonomies that categorize research topics, data sources, and methodological approaches to identify structural gaps. We then introduce an LLM-driven conceptual framework, AutoUrbanCI, composed of four distinct modular agents responsible for hypothesis generation, data engineering, experiment design and execution, and results interpretation with policy recommendations. We propose evaluation criteria for rigor and transparency and reflect on implications for human-AI collaboration, equity, and accountability. We call for a new research agenda that embraces AI-augmented workflows not as replacements for human expertise but as tools to broaden participation, improve reproducibility, and unlock more inclusive forms of urban causal reasoning.","authors":["Yutong Xia","Ao Qu","Yunhan Zheng","Yihong Tang","Dingyi Zhuang","Yuxuan Liang","Cathy Wu","Roger Zimmermann","Jinhua Zhao"],"url":"https://arxiv.org/abs/2504.12345"}
{"created":"2025-04-18","title":"Mathematical Capabilities of Large Language Models in Finnish Matriculation Examination","abstract":"Large language models (LLMs) have shown increasing promise in educational settings, yet their mathematical reasoning has been considered evolving. This study evaluates the mathematical capabilities of various LLMs using the Finnish matriculation examination, a high-stakes digital test for upper secondary education. Initial tests yielded moderate performance corresponding to mid-range grades, but later evaluations demonstrated substantial improvements as the language models evolved. Remarkably, some models achieved near-perfect or perfect scores, matching top student performance and qualifying for university admission. Our findings highlight the rapid advances in the mathematical proficiency of LLMs and illustrate their potential to also support educational assessments at scale.","authors":["Mika Set\\\"al\\\"a","Pieta Sikstr\\\"om","Ville Heilala","Tommi K\\\"arkk\\\"ainen"],"url":"https://arxiv.org/abs/2504.12347"}
{"created":"2025-04-18","title":"A Large-Language Model Framework for Relative Timeline Extraction from PubMed Case Reports","abstract":"Timing of clinical events is central to characterization of patient trajectories, enabling analyses such as process tracing, forecasting, and causal reasoning. However, structured electronic health records capture few data elements critical to these tasks, while clinical reports lack temporal localization of events in structured form. We present a system that transforms case reports into textual time series-structured pairs of textual events and timestamps. We contrast manual and large language model (LLM) annotations (n=320 and n=390 respectively) of ten randomly-sampled PubMed open-access (PMOA) case reports (N=152,974) and assess inter-LLM agreement (n=3,103; N=93). We find that the LLM models have moderate event recall(O1-preview: 0.80) but high temporal concordance among identified events (O1-preview: 0.95). By establishing the task, annotation, and assessment systems, and by demonstrating high concordance, this work may serve as a benchmark for leveraging the PMOA corpus for temporal analytics.","authors":["Jing Wang","Jeremy C Weiss"],"url":"https://arxiv.org/abs/2504.12350"}
{"created":"2025-04-18","title":"Prototype-Guided Diffusion for Digital Pathology: Achieving Foundation Model Performance with Minimal Clinical Data","abstract":"Foundation models in digital pathology use massive datasets to learn useful compact feature representations of complex histology images. However, there is limited transparency into what drives the correlation between dataset size and performance, raising the question of whether simply adding more data to increase performance is always necessary. In this study, we propose a prototype-guided diffusion model to generate high-fidelity synthetic pathology data at scale, enabling large-scale self-supervised learning and reducing reliance on real patient samples while preserving downstream performance. Using guidance from histological prototypes during sampling, our approach ensures biologically and diagnostically meaningful variations in the generated data. We demonstrate that self-supervised features trained on our synthetic dataset achieve competitive performance despite using ~60x-760x less data than models trained on large real-world datasets. Notably, models trained using our synthetic data showed statistically comparable or better performance across multiple evaluation metrics and tasks, even when compared to models trained on orders of magnitude larger datasets. Our hybrid approach, combining synthetic and real data, further enhanced performance, achieving top results in several evaluations. These findings underscore the potential of generative AI to create compelling training data for digital pathology, significantly reducing the reliance on extensive clinical datasets and highlighting the efficiency of our approach.","authors":["Ekaterina Redekop","Mara Pleasure","Vedrana Ivezic","Zichen Wang","Kimberly Flores","Anthony Sisk","William Speier","Corey Arnold"],"url":"https://arxiv.org/abs/2504.12351"}
{"created":"2025-04-18","title":"Leveraging Large Language Models for Multi-Class and Multi-Label Detection of Drug Use and Overdose Symptoms on Social Media","abstract":"Drug overdose remains a critical global health issue, often driven by misuse of opioids, painkillers, and psychiatric medications. Traditional research methods face limitations, whereas social media offers real-time insights into self-reported substance use and overdose symptoms. This study proposes an AI-driven NLP framework trained on annotated social media data to detect commonly used drugs and associated overdose symptoms. Using a hybrid annotation strategy with LLMs and human annotators, we applied traditional ML models, neural networks, and advanced transformer-based models. Our framework achieved 98% accuracy in multi-class and 97% in multi-label classification, outperforming baseline models by up to 8%. These findings highlight the potential of AI for supporting public health surveillance and personalized intervention strategies.","authors":["Muhammad Ahmad","Muhammad Waqas","ldar Batyrshin","Grigori Sidorov"],"url":"https://arxiv.org/abs/2504.12355"}
{"created":"2025-04-18","title":"Replicating ReLM Results: Validating Large Language Models with ReLM","abstract":"Validating Large Language Models with ReLM explores the application of formal languages to evaluate and control Large Language Models (LLMs) for memorization, bias, and zero-shot performance. Current approaches for evaluating these types behavior are often slow, imprecise, costly, or introduce biases of their own, but are necessary due to the importance of this behavior when productionizing LLMs. This project reproduces key results from the original ReLM paper and expounds on the approach and applications with an emphasis on the relevance to the field of systems for machine learning.","authors":["Reece Adamson","Erin Song"],"url":"https://arxiv.org/abs/2504.12357"}
{"created":"2025-04-18","title":"Towards an AI Observatory for the Nuclear Sector: A tool for anticipatory governance","abstract":"AI models are rapidly becoming embedded in all aspects of nuclear energy research and work but the safety, security, and safeguards consequences of this embedding are not well understood. In this paper, we call for the creation of an anticipatory system of governance for AI in the nuclear sector as well as the creation of a global AI observatory as a means for operationalizing anticipatory governance. The paper explores the contours of the nuclear AI observatory and an anticipatory system of governance by drawing on work in science and technology studies, public policy, and foresight studies.","authors":["Aditi Verma","Elizabeth Williams"],"url":"https://arxiv.org/abs/2504.12358"}
{"created":"2025-04-18","title":"Unveiling Hidden Collaboration within Mixture-of-Experts in Large Language Models","abstract":"Mixture-of-Experts based large language models (MoE LLMs) have shown significant promise in multitask adaptability by dynamically routing inputs to specialized experts. Despite their success, the collaborative mechanisms among experts are still not well understood, limiting both the interpretability and optimization of these models. In this paper, we focus on two critical issues: (1) identifying expert collaboration patterns, and (2) optimizing MoE LLMs through expert pruning. To address the first issue, we propose a hierarchical sparse dictionary learning (HSDL) method that uncovers the collaboration patterns among experts. For the second issue, we introduce the Contribution-Aware Expert Pruning (CAEP) algorithm, which effectively prunes low-contribution experts. Our extensive experiments demonstrate that expert collaboration patterns are closely linked to specific input types and exhibit semantic significance across various tasks. Moreover, pruning experiments show that our approach improves overall performance by 2.5\\% on average, outperforming existing methods. These findings offer valuable insights into enhancing the efficiency and interpretability of MoE LLMs, offering a clearer understanding of expert interactions and improving model optimization.","authors":["Yuanbo Tang","Yan Tang","Naifan Zhang","Meixuan Chen","Yang Li"],"url":"https://arxiv.org/abs/2504.12359"}
{"created":"2025-04-18","title":"A Method for Handling Negative Similarities in Explainable Graph Spectral Clustering of Text Documents -- Extended Version","abstract":"This paper investigates the problem of Graph Spectral Clustering with negative similarities, resulting from document embeddings different from the traditional Term Vector Space (like doc2vec, GloVe, etc.). Solutions for combinatorial Laplacians and normalized Laplacians are discussed. An experimental investigation shows the advantages and disadvantages of 6 different solutions proposed in the literature and in this research. The research demonstrates that GloVe embeddings frequently cause failures of normalized Laplacian based GSC due to negative similarities. Furthermore, application of methods curing similarity negativity leads to accuracy improvement for both combinatorial and normalized Laplacian based GSC. It also leads to applicability for GloVe embeddings of explanation methods developed originally bythe authors for Term Vector Space embeddings.","authors":["Mieczys{\\l}aw A. K{\\l}opotek","S{\\l}awomir T. Wierzcho\\'n","Bart{\\l}omiej Starosta","Dariusz Czerski","Piotr Borkowski"],"url":"https://arxiv.org/abs/2504.12360"}
{"created":"2025-04-18","title":"Fast Parameter Optimization of Delayed Feedback Reservoir with Backpropagation and Gradient Descent","abstract":"A delayed feedback reservoir (DFR) is a reservoir computing system well-suited for hardware implementations. However, achieving high accuracy in DFRs depends heavily on selecting appropriate hyperparameters. Conventionally, due to the presence of a non-linear circuit block in the DFR, the grid search has only been the preferred method, which is computationally intensive and time-consuming and thus performed offline. This paper presents a fast and accurate parameter optimization method for DFRs. To this end, we leverage the well-known backpropagation and gradient descent framework with the state-of-the-art DFR model for the first time to facilitate parameter optimization. We further propose a truncated backpropagation strategy applicable to the recursive dot-product reservoir representation to achieve the highest accuracy with reduced memory usage. With the proposed lightweight implementation, the computation time has been significantly reduced by up to 1/700 of the grid search.","authors":["Sosei Ikeda","Hiromitsu Awano","Takashi Sato"],"url":"https://arxiv.org/abs/2504.12363"}
{"created":"2025-04-18","title":"DMM: Building a Versatile Image Generation Model via Distillation-Based Model Merging","abstract":"The success of text-to-image (T2I) generation models has spurred a proliferation of numerous model checkpoints fine-tuned from the same base model on various specialized datasets. This overwhelming specialized model production introduces new challenges for high parameter redundancy and huge storage cost, thereby necessitating the development of effective methods to consolidate and unify the capabilities of diverse powerful models into a single one. A common practice in model merging adopts static linear interpolation in the parameter space to achieve the goal of style mixing. However, it neglects the features of T2I generation task that numerous distinct models cover sundry styles which may lead to incompatibility and confusion in the merged model. To address this issue, we introduce a style-promptable image generation pipeline which can accurately generate arbitrary-style images under the control of style vectors. Based on this design, we propose the score distillation based model merging paradigm (DMM), compressing multiple models into a single versatile T2I model. Moreover, we rethink and reformulate the model merging task in the context of T2I generation, by presenting new merging goals and evaluation protocols. Our experiments demonstrate that DMM can compactly reorganize the knowledge from multiple teacher models and achieve controllable arbitrary-style generation.","authors":["Tianhui Song","Weixin Feng","Shuai Wang","Xubin Li","Tiezheng Ge","Bo Zheng","Limin Wang"],"url":"https://arxiv.org/abs/2504.12364"}
{"created":"2025-04-18","title":"Themisto: Jupyter-Based Runtime Benchmark","abstract":"In this work, we present a benchmark that consists of Jupyter notebooks development trajectories and allows measuring how large language models (LLMs) can leverage runtime information for predicting code output and code generation. We demonstrate that the current generation of LLMs performs poorly on these tasks and argue that there exists a significantly understudied domain in the development of code-based models, which involves incorporating the runtime context.","authors":["Konstantin Grotov","Sergey Titov"],"url":"https://arxiv.org/abs/2504.12365"}
{"created":"2025-04-18","title":"Geographical Context Matters: Bridging Fine and Coarse Spatial Information to Enhance Continental Land Cover Mapping","abstract":"Land use and land cover mapping from Earth Observation (EO) data is a critical tool for sustainable land and resource management. While advanced machine learning and deep learning algorithms excel at analyzing EO imagery data, they often overlook crucial geospatial metadata information that could enhance scalability and accuracy across regional, continental, and global scales. To address this limitation, we propose BRIDGE-LC (Bi-level Representation Integration for Disentangled GEospatial Land Cover), a novel deep learning framework that integrates multi-scale geospatial information into the land cover classification process. By simultaneously leveraging fine-grained (latitude/longitude) and coarse-grained (biogeographical region) spatial information, our lightweight multi-layer perceptron architecture learns from both during training but only requires fine-grained information for inference, allowing it to disentangle region-specific from region-agnostic land cover features while maintaining computational efficiency. To assess the quality of our framework, we use an open-access in-situ dataset and adopt several competing classification approaches commonly considered for large-scale land cover mapping. We evaluated all approaches through two scenarios: an extrapolation scenario in which training data encompasses samples from all biogeographical regions, and a leave-one-region-out scenario where one region is excluded from training. We also explore the spatial representation learned by our model, highlighting a connection between its internal manifold and the geographical information used during training. Our results demonstrate that integrating geospatial information improves land cover mapping performance, with the most substantial gains achieved by jointly leveraging both fine- and coarse-grained spatial information.","authors":["Babak Ghassemi","Cassio Fraga-Dantas","Raffaele Gaetano","Dino Ienco","Omid Ghorbanzadeh","Emma Izquierdo-Verdiguier","Francesco Vuolo"],"url":"https://arxiv.org/abs/2504.12368"}
{"created":"2025-04-18","title":"WORLDMEM: Long-term Consistent World Simulation with Memory","abstract":"World simulation has gained increasing popularity due to its ability to model virtual environments and predict the consequences of actions. However, the limited temporal context window often leads to failures in maintaining long-term consistency, particularly in preserving 3D spatial consistency. In this work, we present WorldMem, a framework that enhances scene generation with a memory bank consisting of memory units that store memory frames and states (e.g., poses and timestamps). By employing a memory attention mechanism that effectively extracts relevant information from these memory frames based on their states, our method is capable of accurately reconstructing previously observed scenes, even under significant viewpoint or temporal gaps. Furthermore, by incorporating timestamps into the states, our framework not only models a static world but also captures its dynamic evolution over time, enabling both perception and interaction within the simulated world. Extensive experiments in both virtual and real scenarios validate the effectiveness of our approach.","authors":["Zeqi Xiao","Yushi Lan","Yifan Zhou","Wenqi Ouyang","Shuai Yang","Yanhong Zeng","Xingang Pan"],"url":"https://arxiv.org/abs/2504.12369"}
{"created":"2025-04-18","title":"InstantCharacter: Personalize Any Characters with a Scalable Diffusion Transformer Framework","abstract":"Current learning-based subject customization approaches, predominantly relying on U-Net architectures, suffer from limited generalization ability and compromised image quality. Meanwhile, optimization-based methods require subject-specific fine-tuning, which inevitably degrades textual controllability. To address these challenges, we propose InstantCharacter, a scalable framework for character customization built upon a foundation diffusion transformer. InstantCharacter demonstrates three fundamental advantages: first, it achieves open-domain personalization across diverse character appearances, poses, and styles while maintaining high-fidelity results. Second, the framework introduces a scalable adapter with stacked transformer encoders, which effectively processes open-domain character features and seamlessly interacts with the latent space of modern diffusion transformers. Third, to effectively train the framework, we construct a large-scale character dataset containing 10-million-level samples. The dataset is systematically organized into paired (multi-view character) and unpaired (text-image combinations) subsets. This dual-data structure enables simultaneous optimization of identity consistency and textual editability through distinct learning pathways. Qualitative experiments demonstrate the advanced capabilities of InstantCharacter in generating high-fidelity, text-controllable, and character-consistent images, setting a new benchmark for character-driven image generation. Our source code is available at https://github.com/Tencent/InstantCharacter.","authors":["Jiale Tao","Yanbing Zhang","Qixun Wang","Yiji Cheng","Haofan Wang","Xu Bai","Zhengguang Zhou","Ruihuang Li","Linqing Wang","Chunyu Wang","Qin Lin","Qinglin Lu"],"url":"https://arxiv.org/abs/2504.12395"}
{"created":"2025-04-18","title":"Activated LoRA: Fine-tuned LLMs for Intrinsics","abstract":"Low-Rank Adaptation (LoRA) has emerged as a highly efficient framework for finetuning the weights of large foundation models, and has become the go-to method for data-driven customization of LLMs. Despite the promise of highly customized behaviors and capabilities, switching between relevant LoRAs in a multiturn setting is highly inefficient, as the key-value (KV) cache of the entire turn history must be recomputed with the LoRA weights before generation can begin. To address this problem, we propose Activated LoRA (aLoRA), which modifies the LoRA framework to only adapt weights for the tokens in the sequence \\emph{after} the aLoRA is invoked. This change crucially allows aLoRA to accept the base model's KV cache of the input string, meaning that aLoRA can be instantly activated whenever needed in a chain without recomputing the cache. This enables building what we call \\emph{intrinsics}, i.e. highly specialized models invoked to perform well-defined operations on portions of an input chain or conversation that otherwise uses the base model by default. We use aLoRA to train a set of intrinsics models, demonstrating competitive accuracy with standard LoRA while achieving significant inference benefits.","authors":["Kristjan Greenewald","Luis Lastras","Thomas Parnell","Vraj Shah","Lucian Popa","Giulio Zizzo","Chulaka Gunasekara","Ambrish Rawat","David Cox"],"url":"https://arxiv.org/abs/2504.12397"}
{"created":"2025-04-18","title":"NTIRE 2025 Challenge on Event-Based Image Deblurring: Methods and Results","abstract":"This paper presents an overview of NTIRE 2025 the First Challenge on Event-Based Image Deblurring, detailing the proposed methodologies and corresponding results. The primary goal of the challenge is to design an event-based method that achieves high-quality image deblurring, with performance quantitatively assessed using Peak Signal-to-Noise Ratio (PSNR). Notably, there are no restrictions on computational complexity or model size. The task focuses on leveraging both events and images as inputs for single-image deblurring. A total of 199 participants registered, among whom 15 teams successfully submitted valid results, offering valuable insights into the current state of event-based image deblurring. We anticipate that this challenge will drive further advancements in event-based vision research.","authors":["Lei Sun","Andrea Alfarano","Peiqi Duan","Shaolin Su","Kaiwei Wang","Boxin Shi","Radu Timofte","Danda Pani Paudel","Luc Van Gool","Qinglin Liu","Wei Yu","Xiaoqian Lv","Lu Yang","Shuigen Wang","Shengping Zhang","Xiangyang Ji","Long Bao","Yuqiang Yang","Jinao Song","Ziyi Wang","Shuang Wen","Heng Sun","Kean Liu","Mingchen Zhong","Senyan Xu","Zhijing Sun","Jiaying Zhu","Chengjie Ge","Xingbo Wang","Yidi Liu","Xin Lu","Xueyang Fu","Zheng-Jun Zha","Dawei Fan","Dafeng Zhang","Yong Yang","Siru Zhang","Qinghua Yang","Hao Kang","Huiyuan Fu","Heng Zhang","Hongyuan Yu","Zhijuan Huang","Shuoyan Wei","Feng Li","Runmin Cong","Weiqi Luo","Mingyun Lin","Chenxu Jiang","Hongyi Liu","Lei Yu","Weilun Li","Jiajun Zhai","Tingting Lin","Shuang Ma","Sai Zhou","Zhanwen Liu","Yang Wang","Eiffel Chong","Nuwan Bandara","Thivya Kandappu","Archan Misra","Yihang Chen","Zhan Li","Weijun Yuan","Wenzhuo Wang","Boyang Yao","Zhanglu Chen","Yijing Sun","Tianjiao Wan","Zijian Gao","Qisheng Xu","Kele Xu","Yukun Zhang","Yu He","Xiaoyan Xie","Tao Fu","Yashu Gautamkumar Patel","Vihar Ramesh Jain","Divesh Basina","Rishik Ashili","Manish Kumar Manjhi","Sourav Kumar","Prinon Benny","Himanshu Ghunawat","B Sri Sairam Gautam","Anett Varghese","Abhishek Yadav"],"url":"https://arxiv.org/abs/2504.12401"}
{"created":"2025-04-18","title":"A Human-AI Comparative Analysis of Prompt Sensitivity in LLM-Based Relevance Judgment","abstract":"Large Language Models (LLMs) are increasingly used to automate relevance judgments for information retrieval (IR) tasks, often demonstrating agreement with human labels that approaches inter-human agreement. To assess the robustness and reliability of LLM-based relevance judgments, we systematically investigate impact of prompt sensitivity on the task. We collected prompts for relevance assessment from 15 human experts and 15 LLMs across three tasks~ -- ~binary, graded, and pairwise~ -- ~yielding 90 prompts in total. After filtering out unusable prompts from three humans and three LLMs, we employed the remaining 72 prompts with three different LLMs as judges to label document/query pairs from two TREC Deep Learning Datasets (2020 and 2021). We compare LLM-generated labels with TREC official human labels using Cohen's $\\kappa$ and pairwise agreement measures. In addition to investigating the impact of prompt variations on agreement with human labels, we compare human- and LLM-generated prompts and analyze differences among different LLMs as judges. We also compare human- and LLM-generated prompts with the standard UMBRELA prompt used for relevance assessment by Bing and TREC 2024 Retrieval Augmented Generation (RAG) Track. To support future research in LLM-based evaluation, we release all data and prompts at https://github.com/Narabzad/prompt-sensitivity-relevance-judgements/.","authors":["Negar Arabzadeh","Charles L. A . Clarke"],"url":"https://arxiv.org/abs/2504.12408"}
{"created":"2025-04-18","title":"Diffusion Based Robust LiDAR Place Recognition","abstract":"Mobile robots on construction sites require accurate pose estimation to perform autonomous surveying and inspection missions. Localization in construction sites is a particularly challenging problem due to the presence of repetitive features such as flat plastered walls and perceptual aliasing due to apartments with similar layouts inter and intra floors. In this paper, we focus on the global re-positioning of a robot with respect to an accurate scanned mesh of the building solely using LiDAR data. In our approach, a neural network is trained on synthetic LiDAR point clouds generated by simulating a LiDAR in an accurate real-life large-scale mesh. We train a diffusion model with a PointNet++ backbone, which allows us to model multiple position candidates from a single LiDAR point cloud. The resulting model can successfully predict the global position of LiDAR in confined and complex sites despite the adverse effects of perceptual aliasing. The learned distribution of potential global positions can provide multi-modal position distribution. We evaluate our approach across five real-world datasets and show the place recognition accuracy of 77% +/-2m on average while outperforming baselines at a factor of 2 in mean error.","authors":["Benjamin Krummenacher","Jonas Frey","Turcan Tuna","Olga Vysotska","Marco Hutter"],"url":"https://arxiv.org/abs/2504.12412"}
{"created":"2025-04-18","title":"Interpretable AI-driven Guidelines for Type 2 Diabetes Treatment from Observational Data","abstract":"Objective: Create precise, structured, data-backed guidelines for type 2 diabetes treatment progression, suitable for clinical adoption.","authors":["Dewang Kumar Agarwal","Dimitris J. Bertsimas"],"url":"https://arxiv.org/abs/2504.12417"}
{"created":"2025-04-18","title":"Standardization of Multi-Objective QUBOs","abstract":"Multi-objective optimization involving Quadratic Unconstrained Binary Optimization (QUBO) problems arises in various domains. A fundamental challenge in this context is the effective balancing of multiple objectives, each potentially operating on very different scales. This imbalance introduces complications such as the selection of appropriate weights when scalarizing multiple objectives into a single objective function. In this paper, we propose a novel technique for scaling QUBO objectives that uses an exact computation of the variance of each individual QUBO objective. By scaling each objective to have unit variance, we align all objectives onto a common scale, thereby allowing for more balanced solutions to be found when scalarizing the objectives with equal weights, as well as potentially assisting in the search or choice of weights during scalarization. Finally, we demonstrate its advantages through empirical evaluations on various multi-objective optimization problems. Our results are noteworthy since manually selecting scalarization weights is cumbersome, and reliable, efficient solutions are scarce.","authors":["Loong Kuan Lee","Thore Thassilo Gerlach","Nico Piatkowski"],"url":"https://arxiv.org/abs/2504.12419"}
{"created":"2025-04-18","title":"Mitigating LLM Hallucinations with Knowledge Graphs: A Case Study","abstract":"High-stakes domains like cyber operations need responsible and trustworthy AI methods. While large language models (LLMs) are becoming increasingly popular in these domains, they still suffer from hallucinations. This research paper provides learning outcomes from a case study with LinkQ, an open-source natural language interface that was developed to combat hallucinations by forcing an LLM to query a knowledge graph (KG) for ground-truth data during question-answering (QA). We conduct a quantitative evaluation of LinkQ using a well-known KGQA dataset, showing that the system outperforms GPT-4 but still struggles with certain question categories - suggesting that alternative query construction strategies will need to be investigated in future LLM querying systems. We discuss a qualitative study of LinkQ with two domain experts using a real-world cybersecurity KG, outlining these experts' feedback, suggestions, perceived limitations, and future opportunities for systems like LinkQ.","authors":["Harry Li","Gabriel Appleby","Kenneth Alperin","Steven R Gomez","Ashley Suh"],"url":"https://arxiv.org/abs/2504.12422"}
{"created":"2025-04-18","title":"Don't Just Translate, Agitate: Using Large Language Models as Devil's Advocates for AI Explanations","abstract":"This position paper highlights a growing trend in Explainable AI (XAI) research where Large Language Models (LLMs) are used to translate outputs from explainability techniques, like feature-attribution weights, into a natural language explanation. While this approach may improve accessibility or readability for users, recent findings suggest that translating into human-like explanations does not necessarily enhance user understanding and may instead lead to overreliance on AI systems. When LLMs summarize XAI outputs without surfacing model limitations, uncertainties, or inconsistencies, they risk reinforcing the illusion of interpretability rather than fostering meaningful transparency. We argue that - instead of merely translating XAI outputs - LLMs should serve as constructive agitators, or devil's advocates, whose role is to actively interrogate AI explanations by presenting alternative interpretations, potential biases, training data limitations, and cases where the model's reasoning may break down. In this role, LLMs can facilitate users in engaging critically with AI systems and generated explanations, with the potential to reduce overreliance caused by misinterpreted or specious explanations.","authors":["Ashley Suh","Kenneth Alperin","Harry Li","Steven R Gomez"],"url":"https://arxiv.org/abs/2504.12424"}
{"created":"2025-04-18","title":"Position: The Most Expensive Part of an LLM should be its Training Data","abstract":"Training a state-of-the-art Large Language Model (LLM) is an increasingly expensive endeavor due to growing computational, hardware, energy, and engineering demands. Yet, an often-overlooked (and seldom paid) expense is the human labor behind these models' training data. Every LLM is built on an unfathomable amount of human effort: trillions of carefully written words sourced from books, academic papers, codebases, social media, and more. This position paper aims to assign a monetary value to this labor and argues that the most expensive part of producing an LLM should be the compensation provided to training data producers for their work. To support this position, we study 64 LLMs released between 2016 and 2024, estimating what it would cost to pay people to produce their training datasets from scratch. Even under highly conservative estimates of wage rates, the costs of these models' training datasets are 10-1000 times larger than the costs to train the models themselves, representing a significant financial liability for LLM providers. In the face of the massive gap between the value of training data and the lack of compensation for its creation, we highlight and discuss research directions that could enable fairer practices in the future.","authors":["Nikhil Kandpal","Colin Raffel"],"url":"https://arxiv.org/abs/2504.12427"}
{"created":"2025-04-18","title":"Learning-based Delay Compensation for Enhanced Control of Assistive Soft Robots","abstract":"Soft robots are increasingly used in healthcare, especially for assistive care, due to their inherent safety and adaptability. Controlling soft robots is challenging due to their nonlinear dynamics and the presence of time delays, especially in applications like a soft robotic arm for patient care. This paper presents a learning-based approach to approximate the nonlinear state predictor (Smith Predictor), aiming to improve tracking performance in a two-module soft robot arm with a short inherent input delay. The method uses Kernel Recursive Least Squares Tracker (KRLST) for online learning of the system dynamics and a Legendre Delay Network (LDN) to compress past input history for efficient delay compensation. Experimental results demonstrate significant improvement in tracking performance compared to a baseline model-based non-linear controller. Statistical analysis confirms the significance of the improvements. The method is computationally efficient and adaptable online, making it suitable for real-world scenarios and highlighting its potential for enabling safer and more accurate control of soft robots in assistive care applications.","authors":["Adri\\`a Momp\\'o Alepuz","Dimitrios Papageorgiou","Silvia Tolu"],"url":"https://arxiv.org/abs/2504.12428"}
{"created":"2025-04-18","title":"Supporting AI-Augmented Meta-Decision Making with InDecision","abstract":"From school admissions to hiring and investment decisions, the first step behind many high-stakes decision-making processes is \"deciding how to decide.\" Formulating effective criteria to guide decision-making requires an iterative process of exploration, reflection, and discovery. Yet, this process remains under-supported in practice. In this short paper, we outline an opportunity space for AI-driven tools that augment human meta-decision making. We draw upon prior literature to propose a set of design goals for future AI tools aimed at supporting human meta-decision making. We then illustrate these ideas through InDecision, a mixed-initiative tool designed to support the iterative development of decision criteria. Based on initial findings from designing and piloting InDecision with users, we discuss future directions for AI-augmented meta-decision making.","authors":["Chance Casta\\~neda","Jessica Mindel","Will Page","Hayden Stec","Manqing Yu","Kenneth Holstein"],"url":"https://arxiv.org/abs/2504.12433"}
{"created":"2025-04-18","title":"Sparsity Outperforms Low-Rank Projections in Few-Shot Adaptation","abstract":"Adapting Vision-Language Models (VLMs) to new domains with few labeled samples remains a significant challenge due to severe overfitting and computational constraints. State-of-the-art solutions, such as low-rank reparameterization, mitigate these issues but often struggle with generalization and require extensive hyperparameter tuning. In this paper, a novel Sparse Optimization (SO) framework is proposed. Unlike low-rank approaches that typically constrain updates to a fixed subspace, our SO method leverages high sparsity to dynamically adjust very few parameters. We introduce two key paradigms. First, we advocate for \\textit{local sparsity and global density}, which updates a minimal subset of parameters per iteration while maintaining overall model expressiveness. As a second paradigm, we advocate for \\textit{local randomness and global importance}, which sparsifies the gradient using random selection while pruning the first moment based on importance. This combination significantly mitigates overfitting and ensures stable adaptation in low-data regimes. Extensive experiments on 11 diverse datasets show that SO achieves state-of-the-art few-shot adaptation performance while reducing memory overhead.","authors":["Nairouz Mrabah","Nicolas Richet","Ismail Ben Ayed","\\'Eric Granger"],"url":"https://arxiv.org/abs/2504.12436"}
{"created":"2025-04-18","title":"Learning Transferable Friction Models and LuGre Identification via Physics Informed Neural Networks","abstract":"Accurately modeling friction in robotics remains a core challenge, as robotics simulators like Mujoco and PyBullet use simplified friction models or heuristics to balance computational efficiency with accuracy, where these simplifications and approximations can lead to substantial differences between simulated and physical performance. In this paper, we present a physics-informed friction estimation framework that enables the integration of well-established friction models with learnable components-requiring only minimal, generic measurement data. Our approach enforces physical consistency yet retains the flexibility to adapt to real-world complexities. We demonstrate, on an underactuated and nonlinear system, that the learned friction models, trained solely on small and noisy datasets, accurately simulate dynamic friction properties and reduce the sim-to-real gap. Crucially, we show that our approach enables the learned models to be transferable to systems they are not trained on. This ability to generalize across multiple systems streamlines friction modeling for complex, underactuated tasks, offering a scalable and interpretable path toward bridging the sim-to-real gap in robotics and control.","authors":["Asutay Ozmen","Jo\\~ao P. Hespanha","Katie Byl"],"url":"https://arxiv.org/abs/2504.12441"}
{"created":"2025-04-18","title":"3D-PointZshotS: Geometry-Aware 3D Point Cloud Zero-Shot Semantic Segmentation Narrowing the Visual-Semantic Gap","abstract":"Existing zero-shot 3D point cloud segmentation methods often struggle with limited transferability from seen classes to unseen classes and from semantic to visual space. To alleviate this, we introduce 3D-PointZshotS, a geometry-aware zero-shot segmentation framework that enhances both feature generation and alignment using latent geometric prototypes (LGPs). Specifically, we integrate LGPs into a generator via a cross-attention mechanism, enriching semantic features with fine-grained geometric details. To further enhance stability and generalization, we introduce a self-consistency loss, which enforces feature robustness against point-wise perturbations. Additionally, we re-represent visual and semantic features in a shared space, bridging the semantic-visual gap and facilitating knowledge transfer to unseen classes. Experiments on three real-world datasets, namely ScanNet, SemanticKITTI, and S3DIS, demonstrate that our method achieves superior performance over four baselines in terms of harmonic mIoU. The code is available at \\href{https://github.com/LexieYang/3D-PointZshotS}{Github}.","authors":["Minmin Yang","Huantao Ren","Senem Velipasalar"],"url":"https://arxiv.org/abs/2504.12442"}
{"created":"2025-04-18","title":"Bridging the Gap: A Comparative Study of Academic and Developer Approaches to Smart Contract Vulnerabilities","abstract":"In this paper, we investigate the strategies adopted by Solidity developers to fix security vulnerabilities in smart contracts. Vulnerabilities are categorized using the DASP TOP 10 taxonomy, and fixing strategies are extracted from GitHub commits in open-source Solidity projects. Each commit was selected through a two-phase process: an initial filter using natural language processing techniques, followed by manual validation by the authors. We analyzed these commits to evaluate adherence to academic best practices. Our results show that developers often follow established guidelines for well-known vulnerability types such as Reentrancy and Arithmetic. However, in less-documented categories like Denial of Service, Bad Randomness, and Time Manipulation, adherence is significantly lower, suggesting gaps between academic literature and practical development. From non-aligned commits, we identified 27 novel fixing strategies not previously discussed in the literature. These emerging patterns offer actionable solutions for securing smart contracts in underexplored areas. To evaluate the quality of these new fixes, we conducted a questionnaire with academic and industry experts, who assessed each strategy based on Generalizability, Long-term Sustainability, and Effectiveness. Additionally, we performed a post-fix analysis by tracking subsequent commits to the fixed files, assessing the persistence and evolution of the fixes over time. Our findings offer an empirically grounded view of how vulnerabilities are addressed in practice, bridging theoretical knowledge and real-world solutions in the domain of smart contract security.","authors":["Francesco Salzano","Lodovica Marchesi","Cosmo Kevin Antenucci","Simone Scalabrino","Roberto Tonelli","Rocco Oliveto","Remo Pareschi"],"url":"https://arxiv.org/abs/2504.12443"}
{"created":"2025-04-18","title":"Enhanced Battery Capacity Estimation in Data-Limited Scenarios through Swarm Learning","abstract":"Data-driven methods have shown potential in electric-vehicle battery management tasks such as capacity estimation, but their deployment is bottlenecked by poor performance in data-limited scenarios. Sharing battery data among algorithm developers can enable accurate and generalizable data-driven models. However, an effective battery management framework that simultaneously ensures data privacy and fault tolerance is still lacking. This paper proposes a swarm battery management system that unites a decentralized swarm learning (SL) framework and credibility weight-based model merging mechanism to enhance battery capacity estimation in data-limited scenarios while ensuring data privacy and security. The effectiveness of the SL framework is validated on a dataset comprising 66 commercial LiNiCoAlO2 cells cycled under various operating conditions. Specifically, the capacity estimation performance is validated in four cases, including data-balanced, volume-biased, feature-biased, and quality-biased scenarios. Our results show that SL can enhance the estimation accuracy in all data-limited cases and achieve a similar level of accuracy with central learning where large amounts of data are available.","authors":["Jiawei Zhang","Yu Zhang","Wei Xu","Yifei Zhang","Weiran Jiang","Qi Jiao","Yao Ren","Ziyou Song"],"url":"https://arxiv.org/abs/2504.12444"}
{"created":"2025-04-18","title":"RePurr: Automated Repair of Block-Based Learners' Programs","abstract":"Programming is increasingly taught using block-based languages like Scratch. While the use of blocks prevents syntax errors, learners can still make semantic mistakes, requiring feedback and help. As teachers may be overwhelmed by help requests in a classroom, may lack programming expertise themselves, or may be unavailable in independent learning scenarios, automated hint generation is desirable. Automated program repair (APR) can provide the foundation for this, but relies on multiple assumptions: (1) APR usually targets isolated bugs, but learners may fundamentally misunderstand tasks or request help for substantially incomplete code. (2) Software tests are required to guide the search and localize broken blocks, but tests for block-based programs are different to those in past APR research: They consist of system tests, and very few of them already fully cover the code. At the same time, they have vastly longer runtimes due to animations and interactions on Scratch programs, which inhibits the applicability of search. (3) The plastic surgery hypothesis assumes the code necessary for repairs already exists in the codebase. Block-based programs tend to be small and may lack this redundancy. To study if APR of such programs is still feasible, we introduce, to the best of our knowledge, the first APR approach for Scratch based on evolutionary search. Our RePurr prototype includes novel refinements of fault localization to improve the guidance of test suites, recovers the plastic surgery hypothesis by exploiting that learning scenarios provide model and student solutions, and reduces the costs of fitness evaluations via test parallelization and acceleration. Empirical evaluation on a set of real learners' programs confirms the anticipated challenges, but also demonstrates APR can still effectively improve and fix learners' programs, enabling automated generation of hints and feedback.","authors":["Sebastian Schweikl","Gordon Fraser"],"url":"https://arxiv.org/abs/2504.12445"}
{"created":"2025-04-18","title":"Deriving Equivalent Symbol-Based Decision Models from Feedforward Neural Networks","abstract":"Artificial intelligence (AI) has emerged as a transformative force across industries, driven by advances in deep learning and natural language processing, and fueled by large-scale data and computing resources. Despite its rapid adoption, the opacity of AI systems poses significant challenges to trust and acceptance.","authors":["Sebastian Seidel","Uwe M. Borghoff"],"url":"https://arxiv.org/abs/2504.12446"}
{"created":"2025-04-18","title":"Can Moran Eigenvectors Improve Machine Learning of Spatial Data? Insights from Synthetic Data Validation","abstract":"Moran Eigenvector Spatial Filtering (ESF) approaches have shown promise in accounting for spatial effects in statistical models. Can this extend to machine learning? This paper examines the effectiveness of using Moran Eigenvectors as additional spatial features in machine learning models. We generate synthetic datasets with known processes involving spatially varying and nonlinear effects across two different geometries. Moran Eigenvectors calculated from different spatial weights matrices, with and without a priori eigenvector selection, are tested. We assess the performance of popular machine learning models, including Random Forests, LightGBM, XGBoost, and TabNet, and benchmark their accuracies in terms of cross-validated R2 values against models that use only coordinates as features. We also extract coefficients and functions from the models using GeoShapley and compare them with the true processes. Results show that machine learning models using only location coordinates achieve better accuracies than eigenvector-based approaches across various experiments and datasets. Furthermore, we discuss that while these findings are relevant for spatial processes that exhibit positive spatial autocorrelation, they do not necessarily apply when modeling network autocorrelation and cases with negative spatial autocorrelation, where Moran Eigenvectors would still be useful.","authors":["Ziqi Li","Zhan Peng"],"url":"https://arxiv.org/abs/2504.12450"}
{"created":"2025-04-18","title":"One Model to Rig Them All: Diverse Skeleton Rigging with UniRig","abstract":"The rapid evolution of 3D content creation, encompassing both AI-powered methods and traditional workflows, is driving an unprecedented demand for automated rigging solutions that can keep pace with the increasing complexity and diversity of 3D models. We introduce UniRig, a novel, unified framework for automatic skeletal rigging that leverages the power of large autoregressive models and a bone-point cross-attention mechanism to generate both high-quality skeletons and skinning weights. Unlike previous methods that struggle with complex or non-standard topologies, UniRig accurately predicts topologically valid skeleton structures thanks to a new Skeleton Tree Tokenization method that efficiently encodes hierarchical relationships within the skeleton. To train and evaluate UniRig, we present Rig-XL, a new large-scale dataset of over 14,000 rigged 3D models spanning a wide range of categories. UniRig significantly outperforms state-of-the-art academic and commercial methods, achieving a 215% improvement in rigging accuracy and a 194% improvement in motion accuracy on challenging datasets. Our method works seamlessly across diverse object categories, from detailed anime characters to complex organic and inorganic structures, demonstrating its versatility and robustness. By automating the tedious and time-consuming rigging process, UniRig has the potential to speed up animation pipelines with unprecedented ease and efficiency. Project Page: https://zjp-shadow.github.io/works/UniRig/","authors":["Jia-Peng Zhang","Cheng-Feng Pu","Meng-Hao Guo","Yan-Pei Cao","Shi-Min Hu"],"url":"https://arxiv.org/abs/2504.12451"}
{"created":"2025-04-18","title":"PlanGlow: Personalized Study Planning with an Explainable and Controllable LLM-Driven System","abstract":"Personal development through self-directed learning is essential in today's fast-changing world, but many learners struggle to manage it effectively. While AI tools like large language models (LLMs) have the potential for personalized learning planning, they face issues such as transparency and hallucinated information. To address this, we propose PlanGlow, an LLM-based system that generates personalized, well-structured study plans with clear explanations and controllability through user-centered interactions. Through mixed methods, we surveyed 28 participants and interviewed 10 before development, followed by a within-subject experiment with 24 participants to evaluate PlanGlow's performance, usability, controllability, and explainability against two baseline systems: a GPT-4o-based system and Khan Academy's Khanmigo. Results demonstrate that PlanGlow significantly improves usability, explainability, and controllability. Additionally, two educational experts assessed and confirmed the quality of the generated study plans. These findings highlight PlanGlow's potential to enhance personalized learning and address key challenges in self-directed learning.","authors":["Jiwon Chun","Yankun Zhao","Hanlin Chen","Meng Xia"],"url":"https://arxiv.org/abs/2504.12452"}
{"created":"2025-04-18","title":"DG-MVP: 3D Domain Generalization via Multiple Views of Point Clouds for Classification","abstract":"Deep neural networks have achieved significant success in 3D point cloud classification while relying on large-scale, annotated point cloud datasets, which are labor-intensive to build. Compared to capturing data with LiDAR sensors and then performing annotation, it is relatively easier to sample point clouds from CAD models. Yet, data sampled from CAD models is regular, and does not suffer from occlusion and missing points, which are very common for LiDAR data, creating a large domain shift. Therefore, it is critical to develop methods that can generalize well across different point cloud domains. %In this paper, we focus on the 3D point cloud domain generalization problem. Existing 3D domain generalization methods employ point-based backbones to extract point cloud features. Yet, by analyzing point utilization of point-based methods and observing the geometry of point clouds from different domains, we have found that a large number of point features are discarded by point-based methods through the max-pooling operation. This is a significant waste especially considering the fact that domain generalization is more challenging than supervised learning, and point clouds are already affected by missing points and occlusion to begin with. To address these issues, we propose a novel method for 3D point cloud domain generalization, which can generalize to unseen domains of point clouds. Our proposed method employs multiple 2D projections of a 3D point cloud to alleviate the issue of missing points and involves a simple yet effective convolution-based model to extract features. The experiments, performed on the PointDA-10 and Sim-to-Real benchmarks, demonstrate the effectiveness of our proposed method, which outperforms different baselines, and can transfer well from synthetic domain to real-world domain.","authors":["Huantao Ren","Minmin Yang","Senem Velipasalar"],"url":"https://arxiv.org/abs/2504.12456"}
{"created":"2025-04-18","title":"M$^2$FGB: A Min-Max Gradient Boosting Framework for Subgroup Fairness","abstract":"In recent years, fairness in machine learning has emerged as a critical concern to ensure that developed and deployed predictive models do not have disadvantageous predictions for marginalized groups. It is essential to mitigate discrimination against individuals based on protected attributes such as gender and race. In this work, we consider applying subgroup justice concepts to gradient-boosting machines designed for supervised learning problems. Our approach expanded gradient-boosting methodologies to explore a broader range of objective functions, which combines conventional losses such as the ones from classification and regression and a min-max fairness term. We study relevant theoretical properties of the solution of the min-max optimization problem. The optimization process explored the primal-dual problems at each boosting round. This generic framework can be adapted to diverse fairness concepts. The proposed min-max primal-dual gradient boosting algorithm was theoretically shown to converge under mild conditions and empirically shown to be a powerful and flexible approach to address binary and subgroup fairness.","authors":["Jansen S. B. Pereira","Giovani Valdrighi","Marcos Medeiros Raimundo"],"url":"https://arxiv.org/abs/2504.12458"}
{"created":"2025-04-18","title":"On Linear Representations and Pretraining Data Frequency in Language Models","abstract":"Pretraining data has a direct impact on the behaviors and quality of language models (LMs), but we only understand the most basic principles of this relationship. While most work focuses on pretraining data's effect on downstream task behavior, we investigate its relationship to LM representations. Previous work has discovered that, in language models, some concepts are encoded `linearly' in the representations, but what factors cause these representations to form? We study the connection between pretraining data frequency and models' linear representations of factual relations. We find evidence that the formation of linear representations is strongly connected to pretraining term frequencies; specifically for subject-relation-object fact triplets, both subject-object co-occurrence frequency and in-context learning accuracy for the relation are highly correlated with linear representations. This is the case across all phases of pretraining. In OLMo-7B and GPT-J, we discover that a linear representation consistently (but not exclusively) forms when the subjects and objects within a relation co-occur at least 1k and 2k times, respectively, regardless of when these occurrences happen during pretraining. Finally, we train a regression model on measurements of linear representation quality in fully-trained LMs that can predict how often a term was seen in pretraining. Our model achieves low error even on inputs from a different model with a different pretraining dataset, providing a new method for estimating properties of the otherwise-unknown training data of closed-data models. We conclude that the strength of linear representations in LMs contains signal about the models' pretraining corpora that may provide new avenues for controlling and improving model behavior: particularly, manipulating the models' training data to meet specific frequency thresholds.","authors":["Jack Merullo","Noah A. Smith","Sarah Wiegreffe","Yanai Elazar"],"url":"https://arxiv.org/abs/2504.12459"}
{"created":"2025-04-18","title":"Rethinking Trust in AI Assistants for Software Development: A Critical Review","abstract":"Trust is a fundamental concept in human decision-making and collaboration that has long been studied in philosophy and psychology. However, software engineering (SE) articles often use the term 'trust' informally - providing an explicit definition or embedding results in established trust models is rare. In SE research on AI assistants, this practice culminates in equating trust with the likelihood of accepting generated content, which does not capture the full complexity of the trust concept. Without a common definition, true secondary research on trust is impossible. The objectives of our research were: (1) to present the psychological and philosophical foundations of human trust, (2) to systematically study how trust is conceptualized in SE and the related disciplines human-computer interaction and information systems, and (3) to discuss limitations of equating trust with content acceptance, outlining how SE research can adopt existing trust models to overcome the widespread informal use of the term 'trust'. We conducted a literature review across disciplines and a critical review of recent SE articles focusing on conceptualizations of trust. We found that trust is rarely defined or conceptualized in SE articles. Related disciplines commonly embed their methodology and results in established trust models, clearly distinguishing, for example, between initial trust and trust formation and discussing whether and when trust can be applied to AI assistants. Our study reveals a significant maturity gap of trust research in SE compared to related disciplines. We provide concrete recommendations on how SE researchers can adopt established trust models and instruments to study trust in AI assistants beyond the acceptance of generated software artifacts.","authors":["Sebastian Baltes","Timo Speith","Brenda Chiteri","Seyedmoein Mohsenimofidi","Shalini Chakraborty","Daniel Buschek"],"url":"https://arxiv.org/abs/2504.12461"}
{"created":"2025-04-18","title":"Dense Backpropagation Improves Training for Sparse Mixture-of-Experts","abstract":"Mixture of Experts (MoE) pretraining is more scalable than dense Transformer pretraining, because MoEs learn to route inputs to a sparse set of their feedforward parameters. However, this means that MoEs only receive a sparse backward update, leading to training instability and suboptimal performance. We present a lightweight approximation method that gives the MoE router a dense gradient update while continuing to sparsely activate its parameters. Our method, which we refer to as Default MoE, substitutes missing expert activations with default outputs consisting of an exponential moving average of expert outputs previously seen over the course of training. This allows the router to receive signals from every expert for each token, leading to significant improvements in training performance. Our Default MoE outperforms standard TopK routing in a variety of settings without requiring significant computational overhead. Code: https://github.com/vatsal0/default-moe.","authors":["Ashwinee Panda","Vatsal Baherwani","Zain Sarwar","Benjamin Therien","Supriyo Chakraborty","Tom Goldstein"],"url":"https://arxiv.org/abs/2504.12463"}
{"created":"2025-04-18","title":"Canonicity for Cost-Aware Logical Framework via Synthetic Tait Computability","abstract":"In the original work on the cost-aware logical framework by Niu et al., a dependent variant of the call-by-push-value language for cost analysis, the authors conjectured that the canonicity property of the type theory can be succinctly proved via Sterling's synthetic Tait computability. This work resolves the conjecture affirmatively.","authors":["Runming Li","Robert Harper"],"url":"https://arxiv.org/abs/2504.12464"}
{"created":"2025-04-18","title":"Geometric Generality of Transformer-Based Gr\\\"obner Basis Computation","abstract":"The intersection of deep learning and symbolic mathematics has seen rapid progress in recent years, exemplified by the work of Lample and Charton. They demonstrated that effective training of machine learning models for solving mathematical problems critically depends on high-quality, domain-specific datasets. In this paper, we address the computation of Gr\\\"obner basis using Transformers. While a dataset generation method tailored to Transformer-based Gr\\\"obner basis computation has previously been proposed, it lacked theoretical guarantees regarding the generality or quality of the generated datasets. In this work, we prove that datasets generated by the previously proposed algorithm are sufficiently general, enabling one to ensure that Transformers can learn a sufficiently diverse range of Gr\\\"obner bases. Moreover, we propose an extended and generalized algorithm to systematically construct datasets of ideal generators, further enhancing the training effectiveness of Transformer. Our results provide a rigorous geometric foundation for Transformers to address a mathematical problem, which is an answer to Lample and Charton's idea of training on diverse or representative inputs.","authors":["Yuta Kambe","Yota Maeda","Tristan Vaccon"],"url":"https://arxiv.org/abs/2504.12465"}
{"created":"2025-04-18","title":"SLURG: Investigating the Feasibility of Generating Synthetic Online Fallacious Discourse","abstract":"In our paper we explore the definition, and extrapolation of fallacies as they pertain to the automatic detection of manipulation on social media. In particular we explore how these logical fallacies might appear in the real world i.e internet forums. We discovered a prevalence of misinformation / misguided intention in discussion boards specifically centered around the Ukrainian Russian Conflict which serves to narrow the domain of our task. Although automatic fallacy detection has gained attention recently, most datasets use unregulated fallacy taxonomies or are limited to formal linguistic domains like political debates or news reports. Online discourse, however, often features non-standardized and diverse language not captured in these domains. We present Shady Linguistic Utterance Replication-Generation (SLURG) to address these limitations, exploring the feasibility of generating synthetic fallacious forum-style comments using large language models (LLMs), specifically DeepHermes-3-Mistral-24B. Our findings indicate that LLMs can replicate the syntactic patterns of real data} and that high-quality few-shot prompts enhance LLMs' ability to mimic the vocabulary diversity of online forums.","authors":["Cal Blanco","Gavin Dsouza","Hugo Lin","Chelsey Rush"],"url":"https://arxiv.org/abs/2504.12466"}
{"created":"2025-04-18","title":"You Don't Need All Attentions: Distributed Dynamic Fine-Tuning for Foundation Models","abstract":"Fine-tuning plays a crucial role in adapting models to downstream tasks with minimal training efforts. However, the rapidly increasing size of foundation models poses a daunting challenge for accommodating foundation model fine-tuning in most commercial devices, which often have limited memory bandwidth. Techniques like model sharding and tensor parallelism address this issue by distributing computation across multiple devices to meet memory requirements. Nevertheless, these methods do not fully leverage their foundation nature in facilitating the fine-tuning process, resulting in high computational costs and imbalanced workloads. We introduce a novel Distributed Dynamic Fine-Tuning (D2FT) framework that strategically orchestrates operations across attention modules based on our observation that not all attention modules are necessary for forward and backward propagation in fine-tuning foundation models. Through three innovative selection strategies, D2FT significantly reduces the computational workload required for fine-tuning foundation models. Furthermore, D2FT addresses workload imbalances in distributed computing environments by optimizing these selection strategies via multiple knapsack optimization. Our experimental results demonstrate that the proposed D2FT framework reduces the training computational costs by 40% and training communication costs by 50% with only 1% to 2% accuracy drops on the CIFAR-10, CIFAR-100, and Stanford Cars datasets. Moreover, the results show that D2FT can be effectively extended to recent LoRA, a state-of-the-art parameter-efficient fine-tuning technique. By reducing 40% computational cost or 50% communication cost, D2FT LoRA top-1 accuracy only drops 4% to 6% on Stanford Cars dataset.","authors":["Shiwei Ding","Lan Zhang","Zhenlin Wang","Giuseppe Ateniese","Xiaoyong Yuan"],"url":"https://arxiv.org/abs/2504.12471"}
{"created":"2025-04-18","title":"Integrating Structural and Semantic Signals in Text-Attributed Graphs with BiGTex","abstract":"Text-attributed graphs (TAGs) present unique challenges in representation learning by requiring models to capture both the semantic richness of node-associated texts and the structural dependencies of the graph. While graph neural networks (GNNs) excel at modeling topological information, they lack the capacity to process unstructured text. Conversely, large language models (LLMs) are proficient in text understanding but are typically unaware of graph structure. In this work, we propose BiGTex (Bidirectional Graph Text), a novel architecture that tightly integrates GNNs and LLMs through stacked Graph-Text Fusion Units. Each unit allows for mutual attention between textual and structural representations, enabling information to flow in both directions, text influencing structure and structure guiding textual interpretation. The proposed architecture is trained using parameter-efficient fine-tuning (LoRA), keeping the LLM frozen while adapting to task-specific signals. Extensive experiments on five benchmark datasets demonstrate that BiGTex achieves state-of-the-art performance in node classification and generalizes effectively to link prediction. An ablation study further highlights the importance of soft prompting and bi-directional attention in the model's success.","authors":["Azadeh Beiranvand","Seyed Mehdi Vahidipour"],"url":"https://arxiv.org/abs/2504.12474"}
{"created":"2025-04-18","title":"What do people expect from Artificial Intelligence? Public opinion on alignment in AI moderation from Germany and the United States","abstract":"Recent advances in generative Artificial Intelligence have raised public awareness, shaping expectations and concerns about their societal implications. Central to these debates is the question of AI alignment -- how well AI systems meet public expectations regarding safety, fairness, and social values. However, little is known about what people expect from AI-enabled systems and how these expectations differ across national contexts. We present evidence from two surveys of public preferences for key functional features of AI-enabled systems in Germany (n = 1800) and the United States (n = 1756). We examine support for four types of alignment in AI moderation: accuracy and reliability, safety, bias mitigation, and the promotion of aspirational imaginaries. U.S. respondents report significantly higher AI use and consistently greater support for all alignment features, reflecting broader technological openness and higher societal involvement with AI. In both countries, accuracy and safety enjoy the strongest support, while more normatively charged goals -- like fairness and aspirational imaginaries -- receive more cautious backing, particularly in Germany. We also explore how individual experience with AI, attitudes toward free speech, political ideology, partisan affiliation, and gender shape these preferences. AI use and free speech support explain more variation in Germany. In contrast, U.S. responses show greater attitudinal uniformity, suggesting that higher exposure to AI may consolidate public expectations. These findings contribute to debates on AI governance and cross-national variation in public preferences. More broadly, our study demonstrates the value of empirically grounding AI alignment debates in public attitudes and of explicitly developing normatively grounded expectations into theoretical and policy discussions on the governance of AI-generated content.","authors":["Andreas Jungherr","Adrian Rauchfleisch"],"url":"https://arxiv.org/abs/2504.12476"}
{"created":"2025-04-18","title":"Towards Conversational AI for Human-Machine Collaborative MLOps","abstract":"This paper presents a Large Language Model (LLM) based conversational agent system designed to enhance human-machine collaboration in Machine Learning Operations (MLOps). We introduce the Swarm Agent, an extensible architecture that integrates specialized agents to create and manage ML workflows through natural language interactions. The system leverages a hierarchical, modular design incorporating a KubeFlow Pipelines (KFP) Agent for ML pipeline orchestration, a MinIO Agent for data management, and a Retrieval-Augmented Generation (RAG) Agent for domain-specific knowledge integration. Through iterative reasoning loops and context-aware processing, the system enables users with varying technical backgrounds to discover, execute, and monitor ML pipelines; manage datasets and artifacts; and access relevant documentation, all via intuitive conversational interfaces. Our approach addresses the accessibility gap in complex MLOps platforms like Kubeflow, making advanced ML tools broadly accessible while maintaining the flexibility to extend to other platforms. The paper describes the architecture, implementation details, and demonstrates how this conversational MLOps assistant reduces complexity and lowers barriers to entry for users across diverse technical skill levels.","authors":["George Fatouros","Georgios Makridis","George Kousiouris","John Soldatos","Anargyros Tsadimas","Dimosthenis Kyriazis"],"url":"https://arxiv.org/abs/2504.12477"}
{"created":"2025-04-18","title":"Boosting Reservoir Computing with Brain-inspired Adaptive Dynamics","abstract":"Reservoir computers (RCs) provide a computationally efficient alternative to deep learning while also offering a framework for incorporating brain-inspired computational principles. By using an internal neural network with random, fixed connections$-$the 'reservoir'$-$and training only the output weights, RCs simplify the training process but remain sensitive to the choice of hyperparameters that govern activation functions and network architecture. Moreover, typical RC implementations overlook a critical aspect of neuronal dynamics: the balance between excitatory and inhibitory (E-I) signals, which is essential for robust brain function. We show that RCs characteristically perform best in balanced or slightly over-inhibited regimes, outperforming excitation-dominated ones. To reduce the need for precise hyperparameter tuning, we introduce a self-adapting mechanism that locally adjusts E/I balance to achieve target neuronal firing rates, improving performance by up to 130% in tasks like memory capacity and time series prediction compared with globally tuned RCs. Incorporating brain-inspired heterogeneity in target neuronal firing rates further reduces the need for fine-tuning hyperparameters and enables RCs to excel across linear and non-linear tasks. These results support a shift from static optimization to dynamic adaptation in reservoir design, demonstrating how brain-inspired mechanisms improve RC performance and robustness while deepening our understanding of neural computation.","authors":["Keshav Srinivasan","Dietmar Plenz","Michelle Girvan"],"url":"https://arxiv.org/abs/2504.12480"}
{"created":"2025-04-18","title":"Agentic AI Optimisation (AAIO): what it is, how it works, why it matters, and how to deal with it","abstract":"The emergence of Agentic Artificial Intelligence (AAI) systems capable of independently initiating digital interactions necessitates a new optimisation paradigm designed explicitly for seamless agent-platform interactions. This article introduces Agentic AI Optimisation (AAIO) as an essential methodology for ensuring effective integration between websites and agentic AI systems. Like how Search Engine Optimisation (SEO) has shaped digital content discoverability, AAIO can define interactions between autonomous AI agents and online platforms. By examining the mutual interdependency between website optimisation and agentic AI success, the article highlights the virtuous cycle that AAIO can create. It further explores the governance, ethical, legal, and social implications (GELSI) of AAIO, emphasising the necessity of proactive regulatory frameworks to mitigate potential negative impacts. The article concludes by affirming AAIO's essential role as part of a fundamental digital infrastructure in the era of autonomous digital agents, advocating for equitable and inclusive access to its benefits.","authors":["Luciano Floridi","Carlotta Buttaboni","Emmie Hine","Jessica Morley","Claudio Novelli","Tyler Schroder"],"url":"https://arxiv.org/abs/2504.12482"}
{"created":"2025-04-18","title":"Co-Writing with AI, on Human Terms: Aligning Research with User Demands Across the Writing Process","abstract":"As generative AI tools like ChatGPT become integral to everyday writing, critical questions arise about how to preserve writers' sense of agency and ownership when using these tools. Yet, a systematic understanding of how AI assistance affects different aspects of the writing process - and how this shapes writers' agency - remains underexplored. To address this gap, we conducted a systematic review of 109 HCI papers using the PRISMA approach. From this literature, we identify four overarching design strategies for AI writing support: structured guidance, guided exploration, active co-writing, and critical feedback - mapped across the four key cognitive processes in writing: planning, translating, reviewing, and monitoring. We complement this analysis with interviews of 15 writers across diverse domains. Our findings reveal that writers' desired levels of AI intervention vary across the writing process: content-focused writers (e.g., academics) prioritize ownership during planning, while form-focused writers (e.g., creatives) value control over translating and reviewing. Writers' preferences are also shaped by contextual goals, values, and notions of originality and authorship. By examining when ownership matters, what writers want to own, and how AI interactions shape agency, we surface both alignment and gaps between research and user needs. Our findings offer actionable design guidance for developing human-centered writing tools for co-writing with AI, on human terms.","authors":["Mohi Reza","Jeb Thomas-Mitchell","Peter Dushniku","Nathan Laundry","Joseph Jay Williams","Anastasia Kuzminykh"],"url":"https://arxiv.org/abs/2504.12488"}
{"created":"2025-04-18","title":"Can Pre-training Indicators Reliably Predict Fine-tuning Outcomes of LLMs?","abstract":"While metrics available during pre-training, such as perplexity, correlate well with model performance at scaling-laws studies, their predictive capacities at a fixed model size remain unclear, hindering effective model selection and development. To address this gap, we formulate the task of selecting pre-training checkpoints to maximize downstream fine-tuning performance as a pairwise classification problem: predicting which of two LLMs, differing in their pre-training, will perform better after supervised fine-tuning (SFT). We construct a dataset using 50 1B parameter LLM variants with systematically varied pre-training configurations, e.g., objectives or data, and evaluate them on diverse downstream tasks after SFT. We first conduct a study and demonstrate that the conventional perplexity is a misleading indicator. As such, we introduce novel unsupervised and supervised proxy metrics derived from pre-training that successfully reduce the relative performance prediction error rate by over 50%. Despite the inherent complexity of this task, we demonstrate the practical utility of our proposed proxies in specific scenarios, paving the way for more efficient design of pre-training schemes optimized for various downstream tasks.","authors":["Hansi Zeng","Kai Hui","Honglei Zhuang","Zhen Qin","Zhenrui Yue","Hamed Zamani","Dana Alon"],"url":"https://arxiv.org/abs/2504.12491"}
{"created":"2025-04-18","title":"MobilePoser: Real-Time Full-Body Pose Estimation and 3D Human Translation from IMUs in Mobile Consumer Devices","abstract":"There has been a continued trend towards minimizing instrumentation for full-body motion capture, going from specialized rooms and equipment, to arrays of worn sensors and recently sparse inertial pose capture methods. However, as these techniques migrate towards lower-fidelity IMUs on ubiquitous commodity devices, like phones, watches, and earbuds, challenges arise including compromised online performance, temporal consistency, and loss of global translation due to sensor noise and drift. Addressing these challenges, we introduce MobilePoser, a real-time system for full-body pose and global translation estimation using any available subset of IMUs already present in these consumer devices. MobilePoser employs a multi-stage deep neural network for kinematic pose estimation followed by a physics-based motion optimizer, achieving state-of-the-art accuracy while remaining lightweight. We conclude with a series of demonstrative applications to illustrate the unique potential of MobilePoser across a variety of fields, such as health and wellness, gaming, and indoor navigation to name a few.","authors":["Vasco Xu","Chenfeng Gao","Henry Hoffmann","Karan Ahuja"],"url":"https://arxiv.org/abs/2504.12492"}
{"created":"2025-04-18","title":"Decentralised collaborative action: cryptoeconomics in space","abstract":"Blockchains and peer-to-peer systems are part of a trend towards computer systems that are \"radically decentralised\", by which we mean that they 1) run across many participants, 2) without central control, and 3) are such that qualities 1 and 2 are essential to the system's intended use cases.","authors":["Murdoch J. Gabbay"],"url":"https://arxiv.org/abs/2504.12493"}
{"created":"2025-04-18","title":"Accelerating Clinical NLP at Scale with a Hybrid Framework with Reduced GPU Demands: A Case Study in Dementia Identification","abstract":"Clinical natural language processing (NLP) is increasingly in demand in both clinical research and operational practice. However, most of the state-of-the-art solutions are transformers-based and require high computational resources, limiting their accessibility. We propose a hybrid NLP framework that integrates rule-based filtering, a Support Vector Machine (SVM) classifier, and a BERT-based model to improve efficiency while maintaining accuracy. We applied this framework in a dementia identification case study involving 4.9 million veterans with incident hypertension, analyzing 2.1 billion clinical notes. At the patient level, our method achieved a precision of 0.90, a recall of 0.84, and an F1-score of 0.87. Additionally, this NLP approach identified over three times as many dementia cases as structured data methods. All processing was completed in approximately two weeks using a single machine with dual A40 GPUs. This study demonstrates the feasibility of hybrid NLP solutions for large-scale clinical text analysis, making state-of-the-art methods more accessible to healthcare organizations with limited computational resources.","authors":["Jianlin Shi","Qiwei Gan","Elizabeth Hanchrow","Annie Bowles","John Stanley","Adam P. Bress","Jordana B. Cohen","Patrick R. Alba"],"url":"https://arxiv.org/abs/2504.12494"}
{"created":"2025-04-18","title":"Beyond Text: Characterizing Domain Expert Needs in Document Research","abstract":"Working with documents is a key part of almost any knowledge work, from contextualizing research in a literature review to reviewing legal precedent. Recently, as their capabilities have expanded, primarily text-based NLP systems have often been billed as able to assist or even automate this kind of work. But to what extent are these systems able to model these tasks as experts conceptualize and perform them now? In this study, we interview sixteen domain experts across two domains to understand their processes of document research, and compare it to the current state of NLP systems. We find that our participants processes are idiosyncratic, iterative, and rely extensively on the social context of a document in addition its content; existing approaches in NLP and adjacent fields that explicitly center the document as an object, rather than as merely a container for text, tend to better reflect our participants' priorities, though they are often less accessible outside their research communities. We call on the NLP community to more carefully consider the role of the document in building useful tools that are accessible, personalizable, iterative, and socially aware.","authors":["Sireesh Gururaja","Nupoor Gandhi","Jeremiah Milbauer","Emma Strubell"],"url":"https://arxiv.org/abs/2504.12495"}
{"created":"2025-04-18","title":"Heuristic Recognition and Rapid Response to Unfamiliar Events Outside of Agent Design Scope","abstract":"Regardless of past learning, an agent in an open world will face unfamiliar situations and events outside of prior experience, existing models, or policies. Further, the agent will sometimes lack relevant knowledge and/or sufficient time to assess the situation, generate and evaluate options, and pursue a robustly considered course of action. How can an agent respond reasonably to situations that are outside of its original design scope? How can it recognize such situations sufficiently quickly and reliably to determine reasonable, adaptive courses of action? We identify key characteristics needed for solutions, evaluate the state-of-the-art by these requirements, and outline a proposed, novel approach that combines domain-general meta-knowledge (in the form of appraisals inspired by human cognition) and metareasoning. It has the potential to provide fast, adaptive responses to unfamiliar situations, more fully meeting the performance characteristics required for open-world, general agents.","authors":["Robert E. Wray","Steven J. Jones","John E. Laird"],"url":"https://arxiv.org/abs/2504.12497"}
{"created":"2025-04-18","title":"The Dual Personas of Social Media Bots","abstract":"Social media bots are AI agents that participate in online conversations. Most studies focus on the general bot and the malicious nature of these agents. However, bots have many different personas, each specialized towards a specific behavioral or content trait. Neither are bots singularly bad, because they are used for both good and bad information dissemination. In this article, we introduce fifteen agent personas of social media bots. These personas have two main categories: Content-Based Bot Persona and Behavior-Based Bot Persona. We also form yardsticks of the good-bad duality of the bots, elaborating on metrics of good and bad bot agents. Our work puts forth a guideline to inform bot detection regulation, emphasizing that policies should focus on how these agents are employed, rather than collectively terming bot agents as bad.","authors":["Lynnette Hui Xian Ng","Kathleen M. Carley"],"url":"https://arxiv.org/abs/2504.12498"}
{"created":"2025-04-18","title":"Reinforcement Learning from Human Feedback","abstract":"Reinforcement learning from human feedback (RLHF) has become an important technical and storytelling tool to deploy the latest machine learning systems. In this book, we hope to give a gentle introduction to the core methods for people with some level of quantitative background. The book starts with the origins of RLHF -- both in recent literature and in a convergence of disparate fields of science in economics, philosophy, and optimal control. We then set the stage with definitions, problem formulation, data collection, and other common math used in the literature. The core of the book details every optimization stage in using RLHF, from starting with instruction tuning to training a reward model and finally all of rejection sampling, reinforcement learning, and direct alignment algorithms. The book concludes with advanced topics -- understudied research questions in synthetic data and evaluation -- and open questions for the field.","authors":["Nathan Lambert"],"url":"https://arxiv.org/abs/2504.12501"}
{"created":"2025-04-18","title":"Continual Learning Strategies for 3D Engineering Regression Problems: A Benchmarking Study","abstract":"Engineering problems that apply machine learning often involve computationally intensive methods but rely on limited datasets. As engineering data evolves with new designs and constraints, models must incorporate new knowledge over time. However, high computational costs make retraining models from scratch infeasible. Continual learning (CL) offers a promising solution by enabling models to learn from sequential data while mitigating catastrophic forgetting, where a model forgets previously learned mappings. This work introduces CL to engineering design by benchmarking several CL methods on representative regression tasks. We apply these strategies to five engineering datasets and construct nine new engineering CL benchmarks to evaluate their ability to address forgetting and improve generalization. Preliminary results show that applying existing CL methods to these tasks improves performance over naive baselines. In particular, the Replay strategy achieved performance comparable to retraining in several benchmarks while reducing training time by nearly half, demonstrating its potential for real-world engineering workflows. The code and datasets used in this work will be available at: https://github.com/kmsamuel/cl-for-engineering-release.","authors":["Kaira M. Samuel","Faez Ahmed"],"url":"https://arxiv.org/abs/2504.12503"}
{"created":"2025-04-18","title":"Robust Visual Servoing under Human Supervision for Assembly Tasks","abstract":"We propose a framework enabling mobile manipulators to reliably complete pick-and-place tasks for assembling structures from construction blocks. The picking uses an eye-in-hand visual servoing controller for object tracking with Control Barrier Functions (CBFs) to ensure fiducial markers in the blocks remain visible. An additional robot with an eye-to-hand setup ensures precise placement, critical for structural stability. We integrate human-in-the-loop capabilities for flexibility and fault correction and analyze robustness to camera pose errors, proposing adapted barrier functions to handle them. Lastly, experiments validate the framework on 6-DoF mobile arms.","authors":["Victor Nan Fernandez-Ayala","Jorge Silva","Meng Guo","Dimos V. Dimarogonas"],"url":"https://arxiv.org/abs/2504.12506"}
{"created":"2025-04-18","title":"Optimizing Utility-Scale Solar Siting for Local Economic Benefits and Regional Decarbonization","abstract":"The Midwest, with its vast agricultural lands, is rapidly emerging as a key region for utility-scale solar expansion. However, traditional power planning has yet to integrate local economic impact directly into capacity expansion to guide optimal siting decisions. Moreover, existing economic assessments tend to emphasize local benefits while overlooking the opportunity costs of converting productive farmland for solar development. This study addresses these gaps by endogenously incorporating local economic metrics into a power system planning model to evaluate how economic impacts influence solar siting, accounting for the cost of lost agricultural output. We analyze all counties within the Great Lakes region, constructing localized supply and marginal benefit curves that are embedded within a multi-objective optimization framework aimed at minimizing system costs and maximizing community economic benefits. Our findings show that counties with larger economies and lower farmland productivity deliver the highest local economic benefit per megawatt (MW) of installed solar capacity. In Ohio, for example, large counties generate up to $34,500 per MW, driven in part by high property tax revenues, while smaller counties yield 31% less. Accounting for the opportunity cost of displaced agricultural output reduces local benefits by up to 16%, depending on farmland quality. A scenario prioritizing solar investment in counties with higher economic returns increases total economic benefits by $1 billion (or 11%) by 2040, with solar investment shifting away from Michigan and Wisconsin (down by 39%) toward Ohio and Indiana (up by 75%), with only a marginal increase of 0.5% in system-wide costs. These findings underscore the importance of integrating economic considerations into utility-scale solar planning to better align decarbonization goals with regional and local economic development.","authors":["Papa Yaw Owusu-Obeng","Steven R. Miller","Sarah Banas Mills","Michael T. Craig"],"url":"https://arxiv.org/abs/2504.12508"}
{"created":"2025-04-18","title":"Multimodal LLM Augmented Reasoning for Interpretable Visual Perception Analysis","abstract":"In this paper, we advance the study of AI-augmented reasoning in the context of Human-Computer Interaction (HCI), psychology and cognitive science, focusing on the critical task of visual perception. Specifically, we investigate the applicability of Multimodal Large Language Models (MLLMs) in this domain. To this end, we leverage established principles and explanations from psychology and cognitive science related to complexity in human visual perception. We use them as guiding principles for the MLLMs to compare and interprete visual content. Our study aims to benchmark MLLMs across various explainability principles relevant to visual perception. Unlike recent approaches that primarily employ advanced deep learning models to predict complexity metrics from visual content, our work does not seek to develop a mere new predictive model. Instead, we propose a novel annotation-free analytical framework to assess utility of MLLMs as cognitive assistants for HCI tasks, using visual perception as a case study. The primary goal is to pave the way for principled study in quantifying and evaluating the interpretability of MLLMs for applications in improving human reasoning capability and uncovering biases in existing perception datasets annotated by humans.","authors":["Shravan Chaudhari","Trilokya Akula","Yoon Kim","Tom Blake"],"url":"https://arxiv.org/abs/2504.12511"}
{"created":"2025-04-18","title":"Practical Insights on Grasp Strategies for Mobile Manipulation in the Wild","abstract":"Mobile manipulation robots are continuously advancing, with their grasping capabilities rapidly progressing. However, there are still significant gaps preventing state-of-the-art mobile manipulators from widespread real-world deployments, including their ability to reliably grasp items in unstructured environments. To help bridge this gap, we developed SHOPPER, a mobile manipulation robot platform designed to push the boundaries of reliable and generalizable grasp strategies. We develop these grasp strategies and deploy them in a real-world grocery store -- an exceptionally challenging setting chosen for its vast diversity of manipulable items, fixtures, and layouts. In this work, we present our detailed approach to designing general grasp strategies towards picking any item in a real grocery store. Additionally, we provide an in-depth analysis of our latest real-world field test, discussing key findings related to fundamental failure modes over hundreds of distinct pick attempts. Through our detailed analysis, we aim to offer valuable practical insights and identify key grasping challenges, which can guide the robotics community towards pressing open problems in the field.","authors":["Isabella Huang","Richard Cheng","Sangwoon Kim","Dan Kruse","Carolyn Matl","Lukas Kaul","JC Hancock","Shanmuga Harikumar","Mark Tjersland","James Borders","Dan Helmick"],"url":"https://arxiv.org/abs/2504.12512"}
{"created":"2025-04-18","title":"AdaVid: Adaptive Video-Language Pretraining","abstract":"Contrastive video-language pretraining has demonstrated great success in learning rich and robust video representations. However, deploying such video encoders on compute-constrained edge devices remains challenging due to their high computational demands. Additionally, existing models are typically trained to process only short video clips, often limited to 4 to 64 frames. In this paper, we introduce AdaVid, a flexible architectural framework designed to learn efficient video encoders that can dynamically adapt their computational footprint based on available resources. At the heart of AdaVid is an adaptive transformer block, inspired by Matryoshka Representation Learning, which allows the model to adjust its hidden embedding dimension at inference time. We show that AdaVid-EgoVLP, trained on video-narration pairs from the large-scale Ego4D dataset, matches the performance of the standard EgoVLP on short video-language benchmarks using only half the compute, and even outperforms EgoVLP when given equal computational resources. We further explore the trade-off between frame count and compute on the challenging Diving48 classification benchmark, showing that AdaVid enables the use of more frames without exceeding computational limits. To handle longer videos, we also propose a lightweight hierarchical network that aggregates short clip features, achieving a strong balance between compute efficiency and accuracy across several long video benchmarks.","authors":["Chaitanya Patel","Juan Carlos Niebles","Ehsan Adeli"],"url":"https://arxiv.org/abs/2504.12513"}
{"created":"2025-04-18","title":"Event Quality Score (EQS): Assessing the Realism of Simulated Event Camera Streams via Distances in Latent Space","abstract":"Event cameras promise a paradigm shift in vision sensing with their low latency, high dynamic range, and asynchronous nature of events. Unfortunately, the scarcity of high-quality labeled datasets hinders their widespread adoption in deep learning-driven computer vision. To mitigate this, several simulators have been proposed to generate synthetic event data for training models for detection and estimation tasks. However, the fundamentally different sensor design of event cameras compared to traditional frame-based cameras poses a challenge for accurate simulation. As a result, most simulated data fail to mimic data captured by real event cameras. Inspired by existing work on using deep features for image comparison, we introduce event quality score (EQS), a quality metric that utilizes activations of the RVT architecture. Through sim-to-real experiments on the DSEC driving dataset, it is shown that a higher EQS implies improved generalization to real-world data after training on simulated events. Thus, optimizing for EQS can lead to developing more realistic event camera simulators, effectively reducing the simulation gap. EQS is available at https://github.com/eventbasedvision/EQS.","authors":["Kaustav Chanda","Aayush Atul Verma","Arpitsinh Vaghela","Yezhou Yang","Bharatesh Chakravarthi"],"url":"https://arxiv.org/abs/2504.12515"}
{"created":"2025-04-18","title":"BrowseComp: A Simple Yet Challenging Benchmark for Browsing Agents","abstract":"We present BrowseComp, a simple yet challenging benchmark for measuring the ability for agents to browse the web. BrowseComp comprises 1,266 questions that require persistently navigating the internet in search of hard-to-find, entangled information. Despite the difficulty of the questions, BrowseComp is simple and easy-to-use, as predicted answers are short and easily verifiable against reference answers. BrowseComp for browsing agents can be seen as analogous to how programming competitions are an incomplete but useful benchmark for coding agents. While BrowseComp sidesteps challenges of a true user query distribution, like generating long answers or resolving ambiguity, it measures the important core capability of exercising persistence and creativity in finding information. BrowseComp can be found at https://github.com/openai/simple-evals.","authors":["Jason Wei","Zhiqing Sun","Spencer Papay","Scott McKinney","Jeffrey Han","Isa Fulford","Hyung Won Chung","Alex Tachard Passos","William Fedus","Amelia Glaese"],"url":"https://arxiv.org/abs/2504.12516"}
{"created":"2025-04-18","title":"Code Improvement Practices at Meta","abstract":"The focus on rapid software delivery inevitably results in the accumulation of technical debt, which, in turn, affects quality and slows future development. Yet, companies with a long history of rapid delivery exist. Our primary aim is to discover how such companies manage to keep their codebases maintainable. Method: we investigate Meta's practices by collaborating with engineers on code quality and by analyzing rich source code change history","authors":["Audris Mockus","Peter C Rigby","Rui Abreu","Anatoly Akkerman","Yogesh Bhootada","Payal Bhuptani","Gurnit Ghardhora","Lan Hoang Dao","Chris Hawley","Renzhi He","Sagar Krishnamoorthy","Sergei Krauze","Jianmin Li","Anton Lunov","Dragos Martac","Francois Morin","Neil Mitchell","Venus Montes","Maher Saba","Matt Steiner","Andrea Valori","Shanchao Wang","Nachiappan Nagappan"],"url":"https://arxiv.org/abs/2504.12517"}
{"created":"2025-04-18","title":"Evaluating the Diversity and Quality of LLM Generated Content","abstract":"Recent work suggests that preference-tuning techniques--including Reinforcement Learning from Human Preferences (RLHF) methods like PPO and GRPO, as well as alternatives like DPO--reduce diversity, creating a dilemma given that such models are widely deployed in applications requiring diverse outputs. To address this, we introduce a framework for measuring effective semantic diversity--diversity among outputs that meet quality thresholds--which better reflects the practical utility of large language models (LLMs). Using open-ended tasks that require no human intervention, we find counterintuitive results: although preference-tuned models--especially those trained via RL--exhibit reduced lexical and syntactic diversity, they produce greater effective semantic diversity than SFT or base models, not from increasing diversity among high-quality outputs, but from generating more high-quality outputs overall. We discover that preference tuning reduces syntactic diversity while preserving semantic diversity--revealing a distinction between diversity in form and diversity in content that traditional metrics often overlook. Our analysis further shows that smaller models are consistently more parameter-efficient at generating unique content within a fixed sampling budget, offering insights into the relationship between model scaling and diversity. These findings have important implications for applications that require diverse yet high-quality outputs, from creative assistance to synthetic data generation.","authors":["Alexander Shypula","Shuo Li","Botong Zhang","Vishakh Padmakumar","Kayo Yin","Osbert Bastani"],"url":"https://arxiv.org/abs/2504.12522"}
{"created":"2025-04-18","title":"Memorization vs. Reasoning: Updating LLMs with New Knowledge","abstract":"Large language models (LLMs) encode vast amounts of pre-trained knowledge in their parameters, but updating them as real-world information evolves remains a challenge. Existing methodologies and benchmarks primarily target entity substitutions, failing to capture the full breadth of complex real-world dynamics. In this paper, we introduce Knowledge Update Playground (KUP), an automatic pipeline for simulating realistic knowledge updates reflected in an evidence corpora. KUP's evaluation framework includes direct and indirect probes to both test memorization of updated facts and reasoning over them, for any update learning methods. Next, we present a lightweight method called memory conditioned training (MCT), which conditions tokens in the update corpus on self-generated \"memory\" tokens during training. Our strategy encourages LLMs to surface and reason over newly memorized knowledge at inference. Our results on two strong LLMs show that (1) KUP benchmark is highly challenging, with the best CPT models achieving $<2\\%$ in indirect probing setting (reasoning) and (2) MCT training significantly outperforms prior continued pre-training (CPT) baselines, improving direct probing (memorization) results by up to $25.4\\%$.","authors":["Aochong Oliver Li","Tanya Goyal"],"url":"https://arxiv.org/abs/2504.12523"}
{"created":"2025-04-18","title":"MOM: Memory-Efficient Offloaded Mini-Sequence Inference for Long Context Language Models","abstract":"Long-context language models exhibit impressive performance but remain challenging to deploy due to high GPU memory demands during inference. We propose Memory-efficient Offloaded Mini-sequence Inference (MOM), a method that partitions critical layers into smaller \"mini-sequences\" and integrates seamlessly with KV cache offloading. Experiments on various Llama, Qwen, and Mistral models demonstrate that MOM reduces peak memory usage by over 50\\% on average. On Meta-Llama-3.2-8B, MOM extends the maximum context length from 155k to 455k tokens on a single A100 80GB GPU, while keeping outputs identical and not compromising accuracy. MOM also maintains highly competitive throughput due to minimal computational overhead and efficient last-layer processing. Compared to traditional chunked prefill methods, MOM achieves a 35\\% greater context length extension. More importantly, our method drastically reduces prefill memory consumption, eliminating it as the longstanding dominant memory bottleneck during inference. This breakthrough fundamentally changes research priorities, redirecting future efforts from prefill-stage optimizations to improving decode-stage residual KV cache efficiency.","authors":["Junyang Zhang","Tianyi Zhu","Cheng Luo","Anima Anandkumar"],"url":"https://arxiv.org/abs/2504.12526"}
{"created":"2025-04-18","title":"Is Trust Correlated With Explainability in AI? A Meta-Analysis","abstract":"This study critically examines the commonly held assumption that explicability in artificial intelligence (AI) systems inherently boosts user trust. Utilizing a meta-analytical approach, we conducted a comprehensive examination of the existing literature to explore the relationship between AI explainability and trust. Our analysis, incorporating data from 90 studies, reveals a statistically significant but moderate positive correlation between the explainability of AI systems and the trust they engender among users. This indicates that while explainability contributes to building trust, it is not the sole or predominant factor in this equation. In addition to academic contributions to the field of Explainable AI (XAI), this research highlights its broader socio-technical implications, particularly in promoting accountability and fostering user trust in critical domains such as healthcare and justice. By addressing challenges like algorithmic bias and ethical transparency, the study underscores the need for equitable and sustainable AI adoption. Rather than focusing solely on immediate trust, we emphasize the normative importance of fostering authentic and enduring trustworthiness in AI systems.","authors":["Zahra Atf","Peter R. Lewis"],"url":"https://arxiv.org/abs/2504.12529"}
{"created":"2025-04-18","title":"Generalization through variance: how noise shapes inductive biases in diffusion models","abstract":"How diffusion models generalize beyond their training set is not known, and is somewhat mysterious given two facts: the optimum of the denoising score matching (DSM) objective usually used to train diffusion models is the score function of the training distribution; and the networks usually used to learn the score function are expressive enough to learn this score to high accuracy. We claim that a certain feature of the DSM objective -- the fact that its target is not the training distribution's score, but a noisy quantity only equal to it in expectation -- strongly impacts whether and to what extent diffusion models generalize. In this paper, we develop a mathematical theory that partly explains this 'generalization through variance' phenomenon. Our theoretical analysis exploits a physics-inspired path integral approach to compute the distributions typically learned by a few paradigmatic under- and overparameterized diffusion models. We find that the distributions diffusion models effectively learn to sample from resemble their training distributions, but with 'gaps' filled in, and that this inductive bias is due to the covariance structure of the noisy target used during training. We also characterize how this inductive bias interacts with feature-related inductive biases.","authors":["John J. Vastola"],"url":"https://arxiv.org/abs/2504.12532"}
{"created":"2025-04-18","title":"Decision-based AI Visual Navigation for Cardiac Ultrasounds","abstract":"Ultrasound imaging of the heart (echocardiography) is widely used to diagnose cardiac diseases. However, obtaining an echocardiogram requires an expert sonographer and a high-quality ultrasound imaging device, which are generally only available in hospitals. Recently, AI-based navigation models and algorithms have been used to aid novice sonographers in acquiring the standardized cardiac views necessary to visualize potential disease pathologies. These navigation systems typically rely on directional guidance to predict the necessary rotation of the ultrasound probe. This paper demonstrates a novel AI navigation system that builds on a decision model for identifying the inferior vena cava (IVC) of the heart. The decision model is trained offline using cardiac ultrasound videos and employs binary classification to determine whether the IVC is present in a given ultrasound video. The underlying model integrates a novel localization algorithm that leverages the learned feature representations to annotate the spatial location of the IVC in real-time. Our model demonstrates strong localization performance on traditional high-quality hospital ultrasound videos, as well as impressive zero-shot performance on lower-quality ultrasound videos from a more affordable Butterfly iQ handheld ultrasound machine. This capability facilitates the expansion of ultrasound diagnostics beyond hospital settings. Currently, the guidance system is undergoing clinical trials and is available on the Butterfly iQ app.","authors":["Andy Dimnaku","Dominic Yurk","Zhiyuan Gao","Arun Padmanabhan","Mandar Aras","Yaser Abu-Mostafa"],"url":"https://arxiv.org/abs/2504.12535"}
{"created":"2025-04-18","title":"\"It's not approved, but many, like myself, ignore the rule\": Investigating the Landscape and Consequences of Unsanctioned Technology Use in Educational Institutes","abstract":"Educators regularly use unsanctioned technologies (apps not formally approved by their institutions) for teaching, grading, and other academic tasks. While these tools often support instructional needs, they raise significant privacy, security, and regulatory compliance concerns. Despite its importance, understanding the adoptions and risks from the perspective of educators, who serve as de facto decision makers behind unsanctioned technology use, is largely understudied in existing literature.To address this gap, we conducted two surveys: one with 375 educators who listed 1,373 unsanctioned apps, and another with 21 administrators who either often help educators to set up educational technologies (EdTechs) or observe their security or privacy incidents. Our study identified 494 unique applications used by educators, primarily for pedagogical utility (n=213) and functional convenience (n=155), and the associated risks were often ignored. In fact, despite security and privacy concerns, many educators continued using the same apps (n = 62), citing a lack of alternatives or heavy dependence as barriers to discontinuation. We also found that fewer than a third of educators were aware of any institutional policy on unsanctioned technology use (K12: 30.3%, HEI: 24.8%), and 22 knowingly violated such policies. While 107 received formal warnings, only 33 adjusted their behavior. Finally, we conclude by discussing the implications of our findings and future recommendations to minimize the risks.","authors":["Easton Kelso","Ananta Soneji","Syed Zami-Ul-Haque Navid","Yan Soshitaishvili","Sazzadur Rahaman","Rakibul Hasan"],"url":"https://arxiv.org/abs/2504.12536"}
{"created":"2025-04-18","title":"A Framework for Information Disorder: Modeling Mechanisms and Implications Based on a Systematic Literature Review","abstract":"This systematic literature review seeks to explain the mechanisms and implications of information disorder for public policy and the democratic process, by proposing a five-stage framework capturing its full life cycle. To our knowledge, no prior reviews in the field of public administration have offered a comprehensive, integrated model of information disorder; most existing studies are situated within communication, information science, or data science, and tend to focus on isolated aspects of the phenomenon. By connecting concepts and stages with enabling factors, agents, tactics and impacts, we reframe information disorder not as a question of \"truthiness\", individual cognition, digital literacy, or merely of technology, but as a socio-material phenomenon, deeply embedded in and shaped by the material conditions of contemporary digital society. This approach calls for a shift away from fragmented interventions toward more holistic, system-level policy responses.","authors":["Julie Ricard","Ivette Ya\\~nez","Leticia Hora"],"url":"https://arxiv.org/abs/2504.12537"}
{"created":"2025-04-18","title":"UniPhys: Unified Planner and Controller with Diffusion for Flexible Physics-Based Character Control","abstract":"Generating natural and physically plausible character motion remains challenging, particularly for long-horizon control with diverse guidance signals. While prior work combines high-level diffusion-based motion planners with low-level physics controllers, these systems suffer from domain gaps that degrade motion quality and require task-specific fine-tuning. To tackle this problem, we introduce UniPhys, a diffusion-based behavior cloning framework that unifies motion planning and control into a single model. UniPhys enables flexible, expressive character motion conditioned on multi-modal inputs such as text, trajectories, and goals. To address accumulated prediction errors over long sequences, UniPhys is trained with the Diffusion Forcing paradigm, learning to denoise noisy motion histories and handle discrepancies introduced by the physics simulator. This design allows UniPhys to robustly generate physically plausible, long-horizon motions. Through guided sampling, UniPhys generalizes to a wide range of control signals, including unseen ones, without requiring task-specific fine-tuning. Experiments show that UniPhys outperforms prior methods in motion naturalness, generalization, and robustness across diverse control tasks.","authors":["Yan Wu","Korrawe Karunratanakul","Zhengyi Luo","Siyu Tang"],"url":"https://arxiv.org/abs/2504.12540"}
{"created":"2025-04-18","title":"Post-Hurricane Debris Segmentation Using Fine-Tuned Foundational Vision Models","abstract":"Timely and accurate detection of hurricane debris is critical for effective disaster response and community resilience. While post-disaster aerial imagery is readily available, robust debris segmentation solutions applicable across multiple disaster regions remain limited. Developing a generalized solution is challenging due to varying environmental and imaging conditions that alter debris' visual signatures across different regions, further compounded by the scarcity of training data. This study addresses these challenges by fine-tuning pre-trained foundational vision models, achieving robust performance with a relatively small, high-quality dataset. Specifically, this work introduces an open-source dataset comprising approximately 1,200 manually annotated aerial RGB images from Hurricanes Ian, Ida, and Ike. To mitigate human biases and enhance data quality, labels from multiple annotators are strategically aggregated and visual prompt engineering is employed. The resulting fine-tuned model, named fCLIPSeg, achieves a Dice score of 0.70 on data from Hurricane Ida -- a disaster event entirely excluded during training -- with virtually no false positives in debris-free areas. This work presents the first event-agnostic debris segmentation model requiring only standard RGB imagery during deployment, making it well-suited for rapid, large-scale post-disaster impact assessments and recovery planning.","authors":["Kooshan Amini","Yuhao Liu","Jamie Ellen Padgett","Guha Balakrishnan","Ashok Veeraraghavan"],"url":"https://arxiv.org/abs/2504.12542"}
{"created":"2025-04-18","title":"Knowledge Acquisition on Mass-shooting Events via LLMs for AI-Driven Justice","abstract":"Mass-shooting events pose a significant challenge to public safety, generating large volumes of unstructured textual data that hinder effective investigations and the formulation of public policy. Despite the urgency, few prior studies have effectively automated the extraction of key information from these events to support legal and investigative efforts. This paper presented the first dataset designed for knowledge acquisition on mass-shooting events through the application of named entity recognition (NER) techniques. It focuses on identifying key entities such as offenders, victims, locations, and criminal instruments, that are vital for legal and investigative purposes. The NER process is powered by Large Language Models (LLMs) using few-shot prompting, facilitating the efficient extraction and organization of critical information from diverse sources, including news articles, police reports, and social media. Experimental results on real-world mass-shooting corpora demonstrate that GPT-4o is the most effective model for mass-shooting NER, achieving the highest Micro Precision, Micro Recall, and Micro F1-scores. Meanwhile, o1-mini delivers competitive performance, making it a resource-efficient alternative for less complex NER tasks. It is also observed that increasing the shot count enhances the performance of all models, but the gains are more substantial for GPT-4o and o1-mini, highlighting their superior adaptability to few-shot learning scenarios.","authors":["Benign John Ihugba","Afsana Nasrin","Ling Wu","Lin Li","Lijun Qian","Xishuang Dong"],"url":"https://arxiv.org/abs/2504.12545"}
{"created":"2025-04-18","title":"Anonymous Public Announcements","abstract":"We formalise the notion of an \\emph{anonymous public announcement} in the tradition of public announcement logic. Such announcements can be seen as in-between a public announcement from ``the outside\" (an announcement of $\\phi$) and a public announcement by one of the agents (an announcement of $K_a\\phi$): we get more information than just $\\phi$, but not (necessarily) about exactly who made it. Even if such an announcement is prima facie anonymous, depending on the background knowledge of the agents it might reveal the identity of the announcer: if I post something on a message board, the information might reveal who I am even if I don't sign my name. Furthermore, like in the Russian Cards puzzle, if we assume that the announcer's intention was to stay anonymous, that in fact might reveal more information. In this paper we first look at the case when no assumption about intentions are made, in which case the logic with an anonymous public announcement operator is reducible to epistemic logic. We then look at the case when we assume common knowledge of the intention to stay anonymous, which is both more complex and more interesting: in several ways it boils down to the notion of a ``safe\" announcement (again, similarly to Russian Cards). Main results include formal expressivity results and axiomatic completeness for key logical languages.","authors":["Thomas {\\AA}gotnes","Rustam Galimullin","Ken Satoh","Satoshi Tojo"],"url":"https://arxiv.org/abs/2504.12546"}
{"created":"2025-04-18","title":"Memorization: A Close Look at Books","abstract":"To what extent can entire books be extracted from LLMs? Using the Llama 3 70B family of models, and the \"prefix-prompting\" extraction technique, we were able to auto-regressively reconstruct, with a very high level of similarity, one entire book (Alice's Adventures in Wonderland) from just the first 500 tokens. We were also able to obtain high extraction rates on several other books, piece-wise. However, these successes do not extend uniformly to all books. We show that extraction rates of books correlate with book popularity and thus, likely duplication in the training data.","authors":["Iris Ma","Ian Domingo","Alberto Krone-Martins","Pierre Baldi","Cristina V. Lopes"],"url":"https://arxiv.org/abs/2504.12549"}
{"created":"2025-04-18","title":"Privacy-Preserving Operating Room Workflow Analysis using Digital Twins","abstract":"Purpose: The operating room (OR) is a complex environment where optimizing workflows is critical to reduce costs and improve patient outcomes. The use of computer vision approaches for the automatic recognition of perioperative events enables identification of bottlenecks for OR optimization. However, privacy concerns limit the use of computer vision for automated event detection from OR videos, which makes privacy-preserving approaches needed for OR workflow analysis. Methods: We propose a two-stage pipeline for privacy-preserving OR video analysis and event detection. In the first stage, we leverage vision foundation models for depth estimation and semantic segmentation to generate de-identified Digital Twins (DT) of the OR from conventional RGB videos. In the second stage, we employ the SafeOR model, a fused two-stream approach that processes segmentation masks and depth maps for OR event detection. We evaluate this method on an internal dataset of 38 simulated surgical trials with five event classes. Results: Our results indicate that this DT-based approach to the OR event detection model achieves performance on par and sometimes even better than raw RGB video-based models on detecting OR events. Conclusion: DTs enable privacy-preserving OR workflow analysis, facilitating the sharing of de-identified data across institutions and they can potentially enhance model generalizability by mitigating domain-specific appearance differences.","authors":["Alejandra Perez","Han Zhang","Yu-Chun Ku","Lalithkumar Seenivasan","Roger Soberanis","Jose L. Porras","Richard Day","Jeff Jopling","Peter Najjar","Mathias Unberath"],"url":"https://arxiv.org/abs/2504.12552"}
{"created":"2025-04-18","title":"ELAB: Extensive LLM Alignment Benchmark in Persian Language","abstract":"This paper presents a comprehensive evaluation framework for aligning Persian Large Language Models (LLMs) with critical ethical dimensions, including safety, fairness, and social norms. It addresses the gaps in existing LLM evaluation frameworks by adapting them to Persian linguistic and cultural contexts. This benchmark creates three types of Persian-language benchmarks: (i) translated data, (ii) new data generated synthetically, and (iii) new naturally collected data. We translate Anthropic Red Teaming data, AdvBench, HarmBench, and DecodingTrust into Persian. Furthermore, we create ProhibiBench-fa, SafeBench-fa, FairBench-fa, and SocialBench-fa as new datasets to address harmful and prohibited content in indigenous culture. Moreover, we collect extensive dataset as GuardBench-fa to consider Persian cultural norms. By combining these datasets, our work establishes a unified framework for evaluating Persian LLMs, offering a new approach to culturally grounded alignment evaluation. A systematic evaluation of Persian LLMs is performed across the three alignment aspects: safety (avoiding harmful content), fairness (mitigating biases), and social norms (adhering to culturally accepted behaviors). We present a publicly available leaderboard that benchmarks Persian LLMs with respect to safety, fairness, and social norms at: https://huggingface.co/spaces/MCILAB/LLM_Alignment_Evaluation.","authors":["Zahra Pourbahman","Fatemeh Rajabi","Mohammadhossein Sadeghi","Omid Ghahroodi","Somaye Bakhshaei","Arash Amini","Reza Kazemi","Mahdieh Soleymani Baghshah"],"url":"https://arxiv.org/abs/2504.12553"}
{"created":"2025-04-18","title":"Contour Field based Elliptical Shape Prior for the Segment Anything Model","abstract":"The elliptical shape prior information plays a vital role in improving the accuracy of image segmentation for specific tasks in medical and natural images. Existing deep learning-based segmentation methods, including the Segment Anything Model (SAM), often struggle to produce segmentation results with elliptical shapes efficiently. This paper proposes a new approach to integrate the prior of elliptical shapes into the deep learning-based SAM image segmentation techniques using variational methods. The proposed method establishes a parameterized elliptical contour field, which constrains the segmentation results to align with predefined elliptical contours. Utilizing the dual algorithm, the model seamlessly integrates image features with elliptical priors and spatial regularization priors, thereby greatly enhancing segmentation accuracy. By decomposing SAM into four mathematical sub-problems, we integrate the variational ellipse prior to design a new SAM network structure, ensuring that the segmentation output of SAM consists of elliptical regions. Experimental results on some specific image datasets demonstrate an improvement over the original SAM.","authors":["Xinyu Zhao","Jun Liu","Faqiang Wang","Li Cui","Yuping Duan"],"url":"https://arxiv.org/abs/2504.12556"}
{"created":"2025-04-18","title":"TraCeS: Trajectory Based Credit Assignment From Sparse Safety Feedback","abstract":"In safe reinforcement learning (RL), auxiliary safety costs are used to align the agent to safe decision making. In practice, safety constraints, including cost functions and budgets, are unknown or hard to specify, as it requires anticipation of all possible unsafe behaviors. We therefore address a general setting where the true safety definition is unknown, and has to be learned from sparsely labeled data. Our key contributions are: first, we design a safety model that performs credit assignment to estimate each decision step's impact on the overall safety using a dataset of diverse trajectories and their corresponding binary safety labels (i.e., whether the corresponding trajectory is safe/unsafe). Second, we illustrate the architecture of our safety model to demonstrate its ability to learn a separate safety score for each timestep. Third, we reformulate the safe RL problem using the proposed safety model and derive an effective algorithm to optimize a safe yet rewarding policy. Finally, our empirical results corroborate our findings and show that this approach is effective in satisfying unknown safety definition, and scalable to various continuous control tasks.","authors":["Siow Meng Low","Akshat Kumar"],"url":"https://arxiv.org/abs/2504.12557"}
{"created":"2025-04-18","title":"Benchmarking LLM-based Relevance Judgment Methods","abstract":"Large Language Models (LLMs) are increasingly deployed in both academic and industry settings to automate the evaluation of information seeking systems, particularly by generating graded relevance judgments. Previous work on LLM-based relevance assessment has primarily focused on replicating graded human relevance judgments through various prompting strategies. However, there has been limited exploration of alternative assessment methods or comprehensive comparative studies. In this paper, we systematically compare multiple LLM-based relevance assessment methods, including binary relevance judgments, graded relevance assessments, pairwise preference-based methods, and two nugget-based evaluation methods~--~document-agnostic and document-dependent. In addition to a traditional comparison based on system rankings using Kendall correlations, we also examine how well LLM judgments align with human preferences, as inferred from relevance grades. We conduct extensive experiments on datasets from three TREC Deep Learning tracks 2019, 2020 and 2021 as well as the ANTIQUE dataset, which focuses on non-factoid open-domain question answering. As part of our data release, we include relevance judgments generated by both an open-source (Llama3.2b) and a commercial (gpt-4o) model. Our goal is to \\textit{reproduce} various LLM-based relevance judgment methods to provide a comprehensive comparison. All code, data, and resources are publicly available in our GitHub Repository at https://github.com/Narabzad/llm-relevance-judgement-comparison.","authors":["Negar Arabzadeh","Charles L. A. Clarke"],"url":"https://arxiv.org/abs/2504.12558"}
{"created":"2025-04-18","title":"Fine Flood Forecasts: Incorporating local data into global models through fine-tuning","abstract":"Floods are the most common form of natural disaster and accurate flood forecasting is essential for early warning systems. Previous work has shown that machine learning (ML) models are a promising way to improve flood predictions when trained on large, geographically-diverse datasets. This requirement of global training can result in a loss of ownership for national forecasters who cannot easily adapt the models to improve performance in their region, preventing ML models from being operationally deployed. Furthermore, traditional hydrology research with physics-based models suggests that local data -- which in many cases is only accessible to local agencies -- is valuable for improving model performance. To address these concerns, we demonstrate a methodology of pre-training a model on a large, global dataset and then fine-tuning that model on data from individual basins. This results in performance increases, validating our hypothesis that there is extra information to be captured in local data. In particular, we show that performance increases are most significant in watersheds that underperform during global training. We provide a roadmap for national forecasters who wish to take ownership of global models using their own data, aiming to lower the barrier to operational deployment of ML-based hydrological forecast systems.","authors":["Emil Ryd","Grey Nearing"],"url":"https://arxiv.org/abs/2504.12559"}
{"created":"2025-04-18","title":"CDF-RAG: Causal Dynamic Feedback for Adaptive Retrieval-Augmented Generation","abstract":"Retrieval-Augmented Generation (RAG) has significantly enhanced large language models (LLMs) in knowledge-intensive tasks by incorporating external knowledge retrieval. However, existing RAG frameworks primarily rely on semantic similarity and correlation-driven retrieval, limiting their ability to distinguish true causal relationships from spurious associations. This results in responses that may be factually grounded but fail to establish cause-and-effect mechanisms, leading to incomplete or misleading insights. To address this issue, we introduce Causal Dynamic Feedback for Adaptive Retrieval-Augmented Generation (CDF-RAG), a framework designed to improve causal consistency, factual accuracy, and explainability in generative reasoning. CDF-RAG iteratively refines queries, retrieves structured causal graphs, and enables multi-hop causal reasoning across interconnected knowledge sources. Additionally, it validates responses against causal pathways, ensuring logically coherent and factually grounded outputs. We evaluate CDF-RAG on four diverse datasets, demonstrating its ability to improve response accuracy and causal correctness over existing RAG-based methods. Our code is publicly available at https://github.com/ elakhatibi/CDF-RAG.","authors":["Elahe Khatibi","Ziyu Wang","Amir M. Rahmani"],"url":"https://arxiv.org/abs/2504.12560"}
{"created":"2025-04-18","title":"Kernel Ridge Regression for Efficient Learning of High-Capacity Hopfield Networks","abstract":"Hebbian learning limits Hopfield network capacity. While kernel methods like Kernel Logistic Regression (KLR) improve performance via iterative learning, we propose Kernel Ridge Regression (KRR) as an alternative. KRR learns dual variables non-iteratively via a closed-form solution, offering significant learning speed advantages. We show KRR achieves comparably high storage capacity (reaching ratio 1.5 shown) and noise robustness (recalling from around 80% corrupted patterns) as KLR, while drastically reducing training time, establishing KRR as an efficient method for building high-performance associative memories.","authors":["Akira Tamamori"],"url":"https://arxiv.org/abs/2504.12561"}
{"created":"2025-04-18","title":"ZeroSumEval: Scaling LLM Evaluation with Inter-Model Competition","abstract":"Evaluating the capabilities of Large Language Models (LLMs) has traditionally relied on static benchmark datasets, human assessments, or model-based evaluations - methods that often suffer from overfitting, high costs, and biases. ZeroSumEval is a novel competition-based evaluation protocol that leverages zero-sum games to assess LLMs with dynamic benchmarks that resist saturation. ZeroSumEval encompasses a diverse suite of games, including security challenges (PyJail), classic games (Chess, Liar's Dice, Poker), knowledge tests (MathQuiz), and persuasion challenges (Gandalf, Debate). These games are designed to evaluate a range of AI capabilities such as strategic reasoning, planning, knowledge application, and creativity. Building upon recent studies that highlight the effectiveness of game-based evaluations for LLMs, ZeroSumEval enhances these approaches by providing a standardized and extensible framework. To demonstrate this, we conduct extensive experiments with >7000 simulations across 7 games and 13 models. Our results show that while frontier models from the GPT and Claude families can play common games and answer questions, they struggle to play games that require creating novel and challenging questions. We also observe that models cannot reliably jailbreak each other and fail generally at tasks requiring creativity. We release our code at https://github.com/facebookresearch/ZeroSumEval.","authors":["Haidar Khan","Hisham A. Alyahya","Yazeed Alnumay","M Saiful Bari","B\\\"ulent Yener"],"url":"https://arxiv.org/abs/2504.12562"}
{"created":"2025-04-18","title":"MetaSynth: Meta-Prompting-Driven Agentic Scaffolds for Diverse Synthetic Data Generation","abstract":"Recent smaller language models such Phi-3.5 and Phi-4 rely on synthetic data generated using larger Language models. Questions remain about leveraging synthetic data for other use cases, such as adapting LLMs to specific domains. A key limitation of synthetic data is low diversity, which negatively impacts its downstream applicability for improving other models. To address this, we propose MetaSynth, a method for generating synthetic data that enhances diversity through meta-prompting, where a language model orchestrates multiple \"expert\" LLM agents to collaboratively generate data. Using only 25 million tokens of synthetic data generated with MetaSynth, we successfully adapt a well-trained LLM (Mistral-7B-v0.3) to two specialized domains-Finance and Biomedicine-without compromising the capabilities of the resulting model in general tasks. In addition, we evaluate the diversity of our synthetic data using seven automated metrics, and find that it approaches the diversity of LLM pre-training corpora.","authors":["Haris Riaz","Sourav Bhabesh","Vinayak Arannil","Miguel Ballesteros","Graham Horwood"],"url":"https://arxiv.org/abs/2504.12563"}
{"created":"2025-04-18","title":"The existence of explicit symplectic integrators for general nonseparable Hamiltonian systems","abstract":"The existence of explicit symplectic integrators for general nonseparable Hamiltonian systems is an open and important problem in both numerical analysis and computing in science and engineering, as explicit integrators are usually more efficient than the implicit integrators of the same order of accuracy. Up to now, all responses to this problem are negative. That is, there exist explicit symplectic integrators only for some special nonseparable Hamiltonian systems, whereas the universal design involving explicit symplectic integrators for general nonseparable Hamiltonian systems has not yet been studied sufficiently. In this paper, we present a constructive proof for the existence of explicit symplectic integrators for general nonseparable Hamiltonian systems via finding explicit symplectic mappings under which the special submanifold of the extended phase space is invariant. It turns out that the proposed explicit integrators are symplectic in both the extended phase space and the original phase space. Moreover, on the basis of the global modified Hamiltonians of the proposed integrators, the backward error analysis is made via a parameter relaxation and restriction technique to show the linear growth of global errors and the near-preservation of first integrals. In particular, the effective estimated time interval is nearly the same as classical implicit symplectic integrators when applied to (near-) integrable Hamiltonian systems. Numerical experiments with a completely integrable nonseparable Hamiltonian and a nonintegrable nonseparable Hamiltonian illustrate the good long-term behavior and high efficiency of the explicit symplectic integrators proposed and analyzed in this paper.","authors":["Lijie Mei","Xinyuan Wu","Yaolin Jiang"],"url":"https://arxiv.org/abs/2504.12567"}
{"created":"2025-04-18","title":"Evolutionary Policy Optimization","abstract":"A key challenge in reinforcement learning (RL) is managing the exploration-exploitation trade-off without sacrificing sample efficiency. Policy gradient (PG) methods excel in exploitation through fine-grained, gradient-based optimization but often struggle with exploration due to their focus on local search. In contrast, evolutionary computation (EC) methods excel in global exploration, but lack mechanisms for exploitation. To address these limitations, this paper proposes Evolutionary Policy Optimization (EPO), a hybrid algorithm that integrates neuroevolution with policy gradient methods for policy optimization. EPO leverages the exploration capabilities of EC and the exploitation strengths of PG, offering an efficient solution to the exploration-exploitation dilemma in RL. EPO is evaluated on the Atari Pong and Breakout benchmarks. Experimental results show that EPO improves both policy quality and sample efficiency compared to standard PG and EC methods, making it effective for tasks that require both exploration and local optimization.","authors":["Zelal Su \"Lain\" Mustafaoglu","Keshav Pingali","Risto Miikkulainen"],"url":"https://arxiv.org/abs/2504.12568"}
{"created":"2025-04-18","title":"The Others: Naturally Isolating Out-of-Distribution Samples for Robust Open-Set Semi-Supervised Learning","abstract":"Open-Set Semi-Supervised Learning (OSSL) tackles the practical challenge of learning from unlabeled data that may include both in-distribution (ID) and unknown out-of-distribution (OOD) classes. However, existing OSSL methods form suboptimal feature spaces by either excluding OOD samples, interfering with them, or overtrusting their information during training. In this work, we introduce MagMatch, a novel framework that naturally isolates OOD samples through a prototype-based contrastive learning paradigm. Unlike conventional methods, MagMatch does not assign any prototypes to OOD samples; instead, it selectively aligns ID samples with class prototypes using an ID-Selective Magnetic (ISM) module, while allowing OOD samples - the \"others\" - to remain unaligned in the feature space. To support this process, we propose Selective Magnetic Alignment (SMA) loss for unlabeled data, which dynamically adjusts alignment based on sample confidence. Extensive experiments on diverse datasets demonstrate that MagMatch significantly outperforms existing methods in both closed-set classification accuracy and OOD detection AUROC, especially in generalizing to unseen OOD data.","authors":["You Rim Choi","Subeom Park","Seojun Heo","Eunchung Noh","Hyung-Sin Kim"],"url":"https://arxiv.org/abs/2504.12569"}
{"created":"2025-04-18","title":"Parsimonious Dataset Construction for Laparoscopic Cholecystectomy Structure Segmentation","abstract":"Labeling has always been expensive in the medical context, which has hindered related deep learning application. Our work introduces active learning in surgical video frame selection to construct a high-quality, affordable Laparoscopic Cholecystectomy dataset for semantic segmentation. Active learning allows the Deep Neural Networks (DNNs) learning pipeline to include the dataset construction workflow, which means DNNs trained by existing dataset will identify the most informative data from the newly collected data. At the same time, DNNs' performance and generalization ability improve over time when the newly selected and annotated data are included in the training data. We assessed different data informativeness measurements and found the deep features distances select the most informative data in this task. Our experiments show that with half of the data selected by active learning, the DNNs achieve almost the same performance with 0.4349 mean Intersection over Union (mIoU) compared to the same DNNs trained on the full dataset (0.4374 mIoU) on the critical anatomies and surgical instruments.","authors":["Yuning Zhou","Henry Badgery","Matthew Read","James Bailey","Catherine Davey"],"url":"https://arxiv.org/abs/2504.12573"}
{"created":"2025-04-18","title":"Prompt-Driven and Training-Free Forgetting Approach and Dataset for Large Language Models","abstract":"The widespread adoption of diffusion models in image generation has increased the demand for privacy-compliant unlearning. However, due to the high-dimensional nature and complex feature representations of diffusion models, achieving selective unlearning remains challenging, as existing methods struggle to remove sensitive information while preserving the consistency of non-sensitive regions. To address this, we propose an Automatic Dataset Creation Framework based on prompt-based layered editing and training-free local feature removal, constructing the ForgetMe dataset and introducing the Entangled evaluation metric. The Entangled metric quantifies unlearning effectiveness by assessing the similarity and consistency between the target and background regions and supports both paired (Entangled-D) and unpaired (Entangled-S) image data, enabling unsupervised evaluation. The ForgetMe dataset encompasses a diverse set of real and synthetic scenarios, including CUB-200-2011 (Birds), Stanford-Dogs, ImageNet, and a synthetic cat dataset. We apply LoRA fine-tuning on Stable Diffusion to achieve selective unlearning on this dataset and validate the effectiveness of both the ForgetMe dataset and the Entangled metric, establishing them as benchmarks for selective unlearning. Our work provides a scalable and adaptable solution for advancing privacy-preserving generative AI.","authors":["Zhenyu Yu","Mohd Yamani Inda Idris","Pei Wang"],"url":"https://arxiv.org/abs/2504.12574"}
{"created":"2025-04-18","title":"CM3AE: A Unified RGB Frame and Event-Voxel/-Frame Pre-training Framework","abstract":"Event cameras have attracted increasing attention in recent years due to their advantages in high dynamic range, high temporal resolution, low power consumption, and low latency. Some researchers have begun exploring pre-training directly on event data. Nevertheless, these efforts often fail to establish strong connections with RGB frames, limiting their applicability in multi-modal fusion scenarios. To address these issues, we propose a novel CM3AE pre-training framework for the RGB-Event perception. This framework accepts multi-modalities/views of data as input, including RGB images, event images, and event voxels, providing robust support for both event-based and RGB-event fusion based downstream tasks. Specifically, we design a multi-modal fusion reconstruction module that reconstructs the original image from fused multi-modal features, explicitly enhancing the model's ability to aggregate cross-modal complementary information. Additionally, we employ a multi-modal contrastive learning strategy to align cross-modal feature representations in a shared latent space, which effectively enhances the model's capability for multi-modal understanding and capturing global dependencies. We construct a large-scale dataset containing 2,535,759 RGB-Event data pairs for the pre-training. Extensive experiments on five downstream tasks fully demonstrated the effectiveness of CM3AE. Source code and pre-trained models will be released on https://github.com/Event-AHU/CM3AE.","authors":["Wentao Wu","Xiao Wang","Chenglong Li","Bo Jiang","Jin Tang","Bin Luo","Qi Liu"],"url":"https://arxiv.org/abs/2504.12576"}
{"created":"2025-04-18","title":"Local Data Quantity-Aware Weighted Averaging for Federated Learning with Dishonest Clients","abstract":"Federated learning (FL) enables collaborative training of deep learning models without requiring data to leave local clients, thereby preserving client privacy. The aggregation process on the server plays a critical role in the performance of the resulting FL model. The most commonly used aggregation method is weighted averaging based on the amount of data from each client, which is thought to reflect each client's contribution. However, this method is prone to model bias, as dishonest clients might report inaccurate training data volumes to the server, which is hard to verify. To address this issue, we propose a novel secure \\underline{Fed}erated \\underline{D}ata q\\underline{u}antity-\\underline{a}ware weighted averaging method (FedDua). It enables FL servers to accurately predict the amount of training data from each client based on their local model gradients uploaded. Furthermore, it can be seamlessly integrated into any FL algorithms that involve server-side model aggregation. Extensive experiments on three benchmarking datasets demonstrate that FedDua improves the global model performance by an average of 3.17% compared to four popular FL aggregation methods in the presence of inaccurate client data volume declarations.","authors":["Leming Wu","Yaochu Jin","Kuangrong Hao","Han Yu"],"url":"https://arxiv.org/abs/2504.12577"}
{"created":"2025-04-18","title":"Provable Secure Steganography Based on Adaptive Dynamic Sampling","abstract":"The security of private communication is increasingly at risk due to widespread surveillance. Steganography, a technique for embedding secret messages within innocuous carriers, enables covert communication over monitored channels. Provably Secure Steganography (PSS) is state of the art for making stego carriers indistinguishable from normal ones by ensuring computational indistinguishability between stego and cover distributions. However, current PSS methods often require explicit access to the distribution of generative model for both sender and receiver, limiting their practicality in black box scenarios. In this paper, we propose a provably secure steganography scheme that does not require access to explicit model distributions for both sender and receiver. Our method incorporates a dynamic sampling strategy, enabling generative models to embed secret messages within multiple sampling choices without disrupting the normal generation process of the model. Extensive evaluations of three real world datasets and three LLMs demonstrate that our blackbox method is comparable with existing white-box steganography methods in terms of efficiency and capacity while eliminating the degradation of steganography in model generated outputs.","authors":["Kaiyi Pang"],"url":"https://arxiv.org/abs/2504.12579"}
{"created":"2025-04-18","title":"ChemKANs for Combustion Chemistry Modeling and Acceleration","abstract":"Efficient chemical kinetic model inference and application for combustion problems is challenging due to large ODE systems and wideley separated time scales. Machine learning techniques have been proposed to streamline these models, though strong nonlinearity and numerical stiffness combined with noisy data sources makes their application challenging. The recently developed Kolmogorov-Arnold Networks (KANs) and KAN ordinary differential equations (KAN-ODEs) have been demonstrated as powerful tools for scientific applications thanks to their rapid neural scaling, improved interpretability, and smooth activation functions. Here, we develop ChemKANs by augmenting the KAN-ODE framework with physical knowledge of the flow of information through the relevant kinetic and thermodynamic laws, as well as an elemental conservation loss term. This novel framework encodes strong inductive bias that enables streamlined training and higher accuracy predictions, while facilitating parameter sparsity through full sharing of information across all inputs and outputs. In a model inference investigation, we find that ChemKANs exhibit no overfitting or model degradation when tasked with extracting predictive models from data that is both sparse and noisy, a task that a standard DeepONet struggles to accomplish. Next, we find that a remarkably parameter-lean ChemKAN (only 344 parameters) can accurately represent hydrogen combustion chemistry, providing a 2x acceleration over the detailed chemistry in a solver that is generalizable to larger-scale turbulent flow simulations. These demonstrations indicate potential for ChemKANs in combustion physics and chemical kinetics, and demonstrate the scalability of generic KAN-ODEs in significantly larger and more numerically challenging problems than previously studied.","authors":["Benjamin C. Koenig","Suyong Kim","Sili Deng"],"url":"https://arxiv.org/abs/2504.12580"}
{"created":"2025-04-18","title":"Identifying and Mitigating the Influence of the Prior Distribution in Large Language Models","abstract":"Large language models (LLMs) sometimes fail to respond appropriately to deterministic tasks -- such as counting or forming acronyms -- because the implicit prior distribution they have learned over sequences of tokens influences their responses. In this work, we show that, in at least some cases, LLMs actually compute the information needed to perform these tasks correctly, and we identify some interventions that can allow them to access this information to improve their performance. First, we show that simply prompting the language model to not rely on its prior knowledge leads to dramatic improvements in prior-dominated tasks. We then use mechanistic interpretability techniques to localize the prior within the LLM and manipulate the extent to which that prior influences its responses. Specifically, we show that it is possible to identify layers of the underlying neural network that correlate with the prior probability of a response and that lightweight finetuning of these layers with basic prompts on prior-dominated tasks achieves high performance on held-out answers. These results suggest that the information required to produce a correct response is contained within the representations of the problems formed by the models. Furthermore, we show that this finetuning is significantly more effective for prior-dominated tasks, and that the error after finetuning is no longer correlated with the prior. Our results suggest that it may be possible to define effective methods for manipulating the extent to which LLMs rely upon their priors in solving problems, potentially increasing their performance in settings where LLMs hallucinate for reasons related to the prior probability of token sequences.","authors":["Liyi Zhang","Veniamin Veselovsky","R. Thomas McCoy","Thomas L. Griffiths"],"url":"https://arxiv.org/abs/2504.12585"}
{"created":"2025-04-18","title":"Software Engineering Principles for Fairer Systems: Experiments with GroupCART","abstract":"Discrimination-aware classification aims to make accurate predictions while satisfying fairness constraints. Traditional decision tree learners typically optimize for information gain in the target attribute alone, which can result in models that unfairly discriminate against protected social groups (e.g., gender, ethnicity). Motivated by these shortcomings, we propose GroupCART, a tree-based ensemble optimizer that avoids bias during model construction by optimizing not only for decreased entropy in the target attribute but also for increased entropy in protected attributes. Our experiments show that GroupCART achieves fairer models without data transformation and with minimal performance degradation. Furthermore, the method supports customizable weighting, offering a smooth and flexible trade-off between predictive performance and fairness based on user requirements. These results demonstrate that algorithmic bias in decision tree models can be mitigated through multi-task, fairness-aware learning. All code and datasets used in this study are available at: https://github.com/anonymous12138/groupCART.","authors":["Kewen Peng","Hao Zhuo","Yicheng Yang","Tim Menzies"],"url":"https://arxiv.org/abs/2504.12587"}
{"created":"2025-04-18","title":"Simplifying Graph Transformers","abstract":"Transformers have attained outstanding performance across various modalities, employing scaled-dot-product (SDP) attention mechanisms. Researchers have attempted to migrate Transformers to graph learning, but most advanced Graph Transformers are designed with major architectural differences, either integrating message-passing or incorporating sophisticated attention mechanisms. These complexities prevent the easy adoption of Transformer training advances. We propose three simple modifications to the plain Transformer to render it applicable to graphs without introducing major architectural distortions. Specifically, we advocate for the use of (1) simplified $L_2$ attention to measure the magnitude closeness of tokens; (2) adaptive root-mean-square normalization to preserve token magnitude information; and (3) a relative positional encoding bias with a shared encoder. Significant performance gains across a variety of graph datasets justify the effectiveness of our proposed modifications. Furthermore, empirical evaluation on the expressiveness benchmark reveals noteworthy realized expressiveness in the graph isomorphism.","authors":["Liheng Ma","Soumyasundar Pal","Yingxue Zhang","Philip H. S. Torr","Mark Coates"],"url":"https://arxiv.org/abs/2504.12588"}
{"created":"2025-04-18","title":"Efficient MAP Estimation of LLM Judgment Performance with Prior Transfer","abstract":"LLM ensembles are widely used for LLM judges. However, how to estimate their accuracy, especially in an efficient way, is unknown. In this paper, we present a principled maximum a posteriori (MAP) framework for an economical and precise estimation of the performance of LLM ensemble judgment. We first propose a mixture of Beta-Binomial distributions to model the judgment distribution, revising from the vanilla Binomial distribution. Next, we introduce a conformal prediction-driven approach that enables adaptive stopping during iterative sampling to balance accuracy with efficiency. Furthermore, we design a prior transfer mechanism that utilizes learned distributions on open-source datasets to improve estimation on a target dataset when only scarce annotations are available. Finally, we present BetaConform, a framework that integrates our distribution assumption, adaptive stopping, and the prior transfer mechanism to deliver a theoretically guaranteed distribution estimation of LLM ensemble judgment with minimum labeled samples. BetaConform is also validated empirically. For instance, with only 10 samples from the TruthfulQA dataset, for a Llama ensembled judge, BetaConform gauges its performance with error margin as small as 3.37%.","authors":["Huaizhi Qu","Inyoung Choi","Zhen Tan","Song Wang","Sukwon Yun","Qi Long","Faizan Siddiqui","Kwonjoon Lee","Tianlong Chen"],"url":"https://arxiv.org/abs/2504.12589"}
{"created":"2025-04-18","title":"Leveraging Agency in Virtual Reality to Enable Situated Learning","abstract":"Learning is an active process that is deeply tied to physical and social contexts. Yet schools traditionally place learners in a passive role and focus on decontextualizing knowledge. Situating learning in more authentic tasks and contexts typically requires taking it outside the classroom via field trips and apprenticeships, but virtual reality (VR) is a promising tool to bring more authentically situated learning experiences into classrooms. In this position paper, I discuss how one of VR's primary affordances for learning is heightening agenct, and how such heightened agency can facilitate more authenticlaly situated learning by allowing learners legitimate peripheral participation.","authors":["Eileen McGivney"],"url":"https://arxiv.org/abs/2504.12593"}
{"created":"2025-04-18","title":"Meta-Dependence in Conditional Independence Testing","abstract":"Constraint-based causal discovery algorithms utilize many statistical tests for conditional independence to uncover networks of causal dependencies. These approaches to causal discovery rely on an assumed correspondence between the graphical properties of a causal structure and the conditional independence properties of observed variables, known as the causal Markov condition and faithfulness. Finite data yields an empirical distribution that is \"close\" to the actual distribution. Across these many possible empirical distributions, the correspondence to the graphical properties can break down for different conditional independencies, and multiple violations can occur at the same time. We study this \"meta-dependence\" between conditional independence properties using the following geometric intuition: each conditional independence property constrains the space of possible joint distributions to a manifold. The \"meta-dependence\" between conditional independences is informed by the position of these manifolds relative to the true probability distribution. We provide a simple-to-compute measure of this meta-dependence using information projections and consolidate our findings empirically using both synthetic and real-world data.","authors":["Bijan Mazaheri","Jiaqi Zhang","Caroline Uhler"],"url":"https://arxiv.org/abs/2504.12594"}
{"created":"2025-04-18","title":"GeoSense: Evaluating Identification and Application of Geometric Principles in Multimodal Reasoning","abstract":"Geometry problem-solving (GPS), a challenging task requiring both visual comprehension and symbolic reasoning, effectively measures the reasoning capabilities of multimodal large language models (MLLMs). Humans exhibit strong reasoning ability in this task through accurate identification and adaptive application of geometric principles within visual contexts. However, existing benchmarks fail to jointly assess both dimensions of the human-like geometric reasoning mechanism in MLLMs, remaining a critical gap in assessing their ability to tackle GPS. To this end, we introduce GeoSense, the first comprehensive bilingual benchmark designed to systematically evaluate the geometric reasoning abilities of MLLMs through the lens of geometric principles. GeoSense features a five-level hierarchical framework of geometric principles spanning plane and solid geometry, an intricately annotated dataset of 1,789 problems, and an innovative evaluation strategy. Through extensive experiments on GeoSense with various open-source and closed-source MLLMs, we observe that Gemini-2.0-pro-flash performs best, achieving an overall score of $65.3$. Our in-depth analysis reveals that the identification and application of geometric principles remain a bottleneck for leading MLLMs, jointly hindering their reasoning abilities. These findings underscore GeoSense's potential to guide future advancements in MLLMs' geometric reasoning capabilities, paving the way for more robust and human-like reasoning in artificial intelligence.","authors":["Liangyu Xu","Yingxiu Zhao","Jingyun Wang","Yingyao Wang","Bu Pi","Chen Wang","Mingliang Zhang","Jihao Gu","Xiang Li","Xiaoyong Zhu","Jun Song","Bo Zheng"],"url":"https://arxiv.org/abs/2504.12597"}
{"created":"2025-04-18","title":"3DResT: A Strong Baseline for Semi-Supervised 3D Referring Expression Segmentation","abstract":"3D Referring Expression Segmentation (3D-RES) typically requires extensive instance-level annotations, which are time-consuming and costly. Semi-supervised learning (SSL) mitigates this by using limited labeled data alongside abundant unlabeled data, improving performance while reducing annotation costs. SSL uses a teacher-student paradigm where teacher generates high-confidence-filtered pseudo-labels to guide student. However, in the context of 3D-RES, where each label corresponds to a single mask and labeled data is scarce, existing SSL methods treat high-quality pseudo-labels merely as auxiliary supervision, which limits the model's learning potential. The reliance on high-confidence thresholds for filtering often results in potentially valuable pseudo-labels being discarded, restricting the model's ability to leverage the abundant unlabeled data. Therefore, we identify two critical challenges in semi-supervised 3D-RES, namely, inefficient utilization of high-quality pseudo-labels and wastage of useful information from low-quality pseudo-labels. In this paper, we introduce the first semi-supervised learning framework for 3D-RES, presenting a robust baseline method named 3DResT. To address these challenges, we propose two novel designs called Teacher-Student Consistency-Based Sampling (TSCS) and Quality-Driven Dynamic Weighting (QDW). TSCS aids in the selection of high-quality pseudo-labels, integrating them into the labeled dataset to strengthen the labeled supervision signals. QDW preserves low-quality pseudo-labels by dynamically assigning them lower weights, allowing for the effective extraction of useful information rather than discarding them. Extensive experiments conducted on the widely used benchmark demonstrate the effectiveness of our method. Notably, with only 1% labeled data, 3DResT achieves an mIoU improvement of 8.34 points compared to the fully supervised method.","authors":["Wenxin Chen","Mengxue Qu","Weitai Kang","Yan Yan","Yao Zhao","Yunchao Wei"],"url":"https://arxiv.org/abs/2504.12599"}
{"created":"2025-04-18","title":"Stochastic Gradient Descent in Non-Convex Problems: Asymptotic Convergence with Relaxed Step-Size via Stopping Time Methods","abstract":"Stochastic Gradient Descent (SGD) is widely used in machine learning research. Previous convergence analyses of SGD under the vanishing step-size setting typically require Robbins-Monro conditions. However, in practice, a wider variety of step-size schemes are frequently employed, yet existing convergence results remain limited and often rely on strong assumptions. This paper bridges this gap by introducing a novel analytical framework based on a stopping-time method, enabling asymptotic convergence analysis of SGD under more relaxed step-size conditions and weaker assumptions. In the non-convex setting, we prove the almost sure convergence of SGD iterates for step-sizes $ \\{ \\epsilon_t \\}_{t \\geq 1} $ satisfying $\\sum_{t=1}^{+\\infty} \\epsilon_t = +\\infty$ and $\\sum_{t=1}^{+\\infty} \\epsilon_t^p < +\\infty$ for some $p > 2$. Compared with previous studies, our analysis eliminates the global Lipschitz continuity assumption on the loss function and relaxes the boundedness requirements for higher-order moments of stochastic gradients. Building upon the almost sure convergence results, we further establish $L_2$ convergence. These significantly relaxed assumptions make our theoretical results more general, thereby enhancing their applicability in practical scenarios.","authors":["Ruinan Jin","Difei Cheng","Hong Qiao","Xin Shi","Shaodong Liu","Bo Zhang"],"url":"https://arxiv.org/abs/2504.12601"}
{"created":"2025-04-18","title":"Codes over Finite Ring $\\mathbb{Z}_k$, MacWilliams Identity and Theta Function","abstract":"In this paper, we study linear codes over $\\mathbb{Z}_k$ based on lattices and theta functions. We obtain the complete weight enumerators MacWilliams identity and the symmetrized weight enumerators MacWilliams identity based on the theory of theta function. We extend the main work by Bannai, Dougherty, Harada and Oura to the finite ring $\\mathbb{Z}_k$ for any positive integer $k$ and present the complete weight enumerators MacWilliams identity in genus $g$. When $k=p$ is a prime number, we establish the relationship between the theta function of associated lattices over a cyclotomic field and the complete weight enumerators with Hamming weight of codes, which is an analogy of the results by G. Van der Geer and F. Hirzebruch since they showed the identity with the Lee weight enumerators.","authors":["Zhiyong Zheng","Fengxia Liu","Kun Tian"],"url":"https://arxiv.org/abs/2504.12604"}
{"created":"2025-04-18","title":"AdaQual-Diff: Diffusion-Based Image Restoration via Adaptive Quality Prompting","abstract":"Restoring images afflicted by complex real-world degradations remains challenging, as conventional methods often fail to adapt to the unique mixture and severity of artifacts present. This stems from a reliance on indirect cues which poorly capture the true perceptual quality deficit. To address this fundamental limitation, we introduce AdaQual-Diff, a diffusion-based framework that integrates perceptual quality assessment directly into the generative restoration process. Our approach establishes a mathematical relationship between regional quality scores from DeQAScore and optimal guidance complexity, implemented through an Adaptive Quality Prompting mechanism. This mechanism systematically modulates prompt structure according to measured degradation severity: regions with lower perceptual quality receive computationally intensive, structurally complex prompts with precise restoration directives, while higher quality regions receive minimal prompts focused on preservation rather than intervention. The technical core of our method lies in the dynamic allocation of computational resources proportional to degradation severity, creating a spatially-varying guidance field that directs the diffusion process with mathematical precision. By combining this quality-guided approach with content-specific conditioning, our framework achieves fine-grained control over regional restoration intensity without requiring additional parameters or inference iterations. Experimental results demonstrate that AdaQual-Diff achieves visually superior restorations across diverse synthetic and real-world datasets.","authors":["Xin Su","Chen Wu","Yu Zhang","Chen Lyu","Zhuoran Zheng"],"url":"https://arxiv.org/abs/2504.12605"}
{"created":"2025-04-18","title":"Robo-SGG: Exploiting Layout-Oriented Normalization and Restitution for Robust Scene Graph Generation","abstract":"In this paper, we introduce a novel method named Robo-SGG, i.e., Layout-Oriented Normalization and Restitution for Robust Scene Graph Generation. Compared to the existing SGG setting, the robust scene graph generation aims to perform inference on a diverse range of corrupted images, with the core challenge being the domain shift between the clean and corrupted images. Existing SGG methods suffer from degraded performance due to compromised visual features e.g., corruption interference or occlusions. To obtain robust visual features, we exploit the layout information, which is domain-invariant, to enhance the efficacy of existing SGG methods on corrupted images. Specifically, we employ Instance Normalization(IN) to filter out the domain-specific feature and recover the unchangeable structural features, i.e., the positional and semantic relationships among objects by the proposed Layout-Oriented Restitution. Additionally, we propose a Layout-Embedded Encoder (LEE) that augments the existing object and predicate encoders within the SGG framework, enriching the robust positional and semantic features of objects and predicates. Note that our proposed Robo-SGG module is designed as a plug-and-play component, which can be easily integrated into any baseline SGG model. Extensive experiments demonstrate that by integrating the state-of-the-art method into our proposed Robo-SGG, we achieve relative improvements of 5.6%, 8.0%, and 6.5% in mR@50 for PredCls, SGCls, and SGDet tasks on the VG-C dataset, respectively, and achieve new state-of-the-art performance in corruption scene graph generation benchmark (VG-C and GQA-C). We will release our source code and model.","authors":["Changsheng Lv","Mengshi Qi","Zijian Fu","Huadong Ma"],"url":"https://arxiv.org/abs/2504.12606"}
{"created":"2025-04-18","title":"Code Copycat Conundrum: Demystifying Repetition in LLM-based Code Generation","abstract":"Despite recent advances in Large Language Models (LLMs) for code generation, the quality of LLM-generated code still faces significant challenges. One significant issue is code repetition, which refers to the model's tendency to generate structurally redundant code, resulting in inefficiencies and reduced readability. To address this, we conduct the first empirical study to investigate the prevalence and nature of repetition across 19 state-of-the-art code LLMs using three widely-used benchmarks. Our study includes both quantitative and qualitative analyses, revealing that repetition is pervasive and manifests at various granularities and extents, including character, statement, and block levels. We further summarize a taxonomy of 20 repetition patterns. Building on our findings, we propose DeRep, a rule-based technique designed to detect and mitigate repetition in generated code. We evaluate DeRep using both open-source benchmarks and in an industrial setting. Our results demonstrate that DeRep significantly outperforms baselines in reducing repetition (with an average improvements of 91.3%, 93.5%, and 79.9% in rep-3, rep-line, and sim-line metrics) and enhancing code quality (with a Pass@1 increase of 208.3% over greedy search). Furthermore, integrating DeRep improves the performance of existing repetition mitigation methods, with Pass@1 improvements ranging from 53.7% to 215.7%.","authors":["Mingwei Liu","Juntao Li","Ying Wang","Xueying Du","Zuoyu Ou","Qiuyuan Chen","Bingxu An","Zhao Wei","Yong Xu","Fangming Zou","Xin Peng","Yiling Lou"],"url":"https://arxiv.org/abs/2504.12608"}
{"created":"2025-04-18","title":"Crossing the Human-Robot Embodiment Gap with Sim-to-Real RL using One Human Demonstration","abstract":"Teaching robots dexterous manipulation skills often requires collecting hundreds of demonstrations using wearables or teleoperation, a process that is challenging to scale. Videos of human-object interactions are easier to collect and scale, but leveraging them directly for robot learning is difficult due to the lack of explicit action labels from videos and morphological differences between robot and human hands. We propose Human2Sim2Robot, a novel real-to-sim-to-real framework for training dexterous manipulation policies using only one RGB-D video of a human demonstrating a task. Our method utilizes reinforcement learning (RL) in simulation to cross the human-robot embodiment gap without relying on wearables, teleoperation, or large-scale data collection typically necessary for imitation learning methods. From the demonstration, we extract two task-specific components: (1) the object pose trajectory to define an object-centric, embodiment-agnostic reward function, and (2) the pre-manipulation hand pose to initialize and guide exploration during RL training. We found that these two components are highly effective for learning the desired task, eliminating the need for task-specific reward shaping and tuning. We demonstrate that Human2Sim2Robot outperforms object-aware open-loop trajectory replay by 55% and imitation learning with data augmentation by 68% across grasping, non-prehensile manipulation, and multi-step tasks. Project Site: https://human2sim2robot.github.io","authors":["Tyler Ga Wei Lum","Olivia Y. Lee","C. Karen Liu","Jeannette Bohg"],"url":"https://arxiv.org/abs/2504.12609"}
{"created":"2025-04-18","title":"Machine Learning Methods for Gene Regulatory Network Inference","abstract":"Gene Regulatory Networks (GRNs) are intricate biological systems that control gene expression and regulation in response to environmental and developmental cues. Advances in computational biology, coupled with high throughput sequencing technologies, have significantly improved the accuracy of GRN inference and modeling. Modern approaches increasingly leverage artificial intelligence (AI), particularly machine learning techniques including supervised, unsupervised, semi-supervised, and contrastive learning to analyze large scale omics data and uncover regulatory gene interactions. To support both the application of GRN inference in studying gene regulation and the development of novel machine learning methods, we present a comprehensive review of machine learning based GRN inference methodologies, along with the datasets and evaluation metrics commonly used. Special emphasis is placed on the emerging role of cutting edge deep learning techniques in enhancing inference performance. The potential future directions for improving GRN inference are also discussed.","authors":["Akshata Hegde","Tom Nguyen","Jianlin Cheng"],"url":"https://arxiv.org/abs/2504.12610"}
{"created":"2025-04-18","title":"The Chronicles of Foundation AI for Forensics of Multi-Agent Provenance","abstract":"Provenance is the chronology of things, resonating with the fundamental pursuit to uncover origins, trace connections, and situate entities within the flow of space and time. As artificial intelligence advances towards autonomous agents capable of interactive collaboration on complex tasks, the provenance of generated content becomes entangled in the interplay of collective creation, where contributions are continuously revised, extended or overwritten. In a multi-agent generative chain, content undergoes successive transformations, often leaving little, if any, trace of prior contributions. In this study, we investigates the problem of tracking multi-agent provenance across the temporal dimension of generation. We propose a chronological system for post hoc attribution of generative history from content alone, without reliance on internal memory states or external meta-information. At its core lies the notion of symbolic chronicles, representing signed and time-stamped records, in a form analogous to the chain of custody in forensic science. The system operates through a feedback loop, whereby each generative timestep updates the chronicle of prior interactions and synchronises it with the synthetic content in the very act of generation. This research seeks to develop an accountable form of collaborative artificial intelligence within evolving cyber ecosystems.","authors":["Ching-Chun Chang","Isao Echizen"],"url":"https://arxiv.org/abs/2504.12612"}
{"created":"2025-04-18","title":"Fast and Accurate Prediction of Antenna Reflection Coefficients in Planar Layered Media Environment via Generalized Scattering Matrix","abstract":"The numerical algorithm for evaluating the reflection coefficient of an antenna in the presence of the planar layered medium is reformulated using the antenna's generalized scattering matrix (GSM). The interaction between the antenna and the layered medium is modeled through spherical-to-planar vector wave transformations, ensuring no approximations that could compromise computational accuracy. This theoretical framework significantly reduces algebraic complexity, resulting in a marked increase in the speed of antenna performance evaluation. Excluding the one-time preprocessing cost of obtaining the antenna's GSM in free space, the numerical evaluation speed of this method exceeds that of the commercial software FEKO by several orders of magnitude, while maintaining nearly identical accuracy.","authors":["Chenbo Shi","Shichen Liang","Xin Gu","Jin Pan"],"url":"https://arxiv.org/abs/2504.12613"}
{"created":"2025-04-18","title":"From Regulation to Support: Centering Humans in Technology-Mediated Emotion Intervention in Care Contexts","abstract":"Enhancing emotional well-being has become a significant focus in HCI and CSCW, with technologies increasingly designed to track, visualize, and manage emotions. However, these approaches have faced criticism for potentially suppressing certain emotional experiences. Through a scoping review of 53 empirical studies from ACM proceedings implementing Technology-Mediated Emotion Intervention (TMEI), we critically examine current practices through lenses drawn from HCI critical theories. Our analysis reveals emotion intervention mechanisms that extend beyond traditional emotion regulation paradigms, identifying care-centered goals that prioritize non-judgmental emotional support and preserve users' identities. The findings demonstrate how researchers design technologies for generating artificial care, intervening in power dynamics, and nudging behavioral changes. We contribute the concept of \"emotion support\" as an alternative approach to \"emotion regulation,\" emphasizing human-centered approaches to emotional well-being. This work advances the understanding of diverse human emotional needs beyond individual and cognitive perspectives, offering design implications that critically reimagine how technologies can honor emotional complexity, preserve human agency, and transform power dynamics in care contexts.","authors":["Jiaying \"Lizzy\" Liu","Shuoer Zhuo","Xingyu Li","Andrew Dillon","Noura Howell","Angela D. R. Smith","Yan Zhang"],"url":"https://arxiv.org/abs/2504.12614"}
{"created":"2025-04-18","title":"Graph-based Path Planning with Dynamic Obstacle Avoidance for Autonomous Parking","abstract":"Safe and efficient path planning in parking scenarios presents a significant challenge due to the presence of cluttered environments filled with static and dynamic obstacles. To address this, we propose a novel and computationally efficient planning strategy that seamlessly integrates the predictions of dynamic obstacles into the planning process, ensuring the generation of collision-free paths. Our approach builds upon the conventional Hybrid A star algorithm by introducing a time-indexed variant that explicitly accounts for the predictions of dynamic obstacles during node exploration in the graph, thus enabling dynamic obstacle avoidance. We integrate the time-indexed Hybrid A star algorithm within an online planning framework to compute local paths at each planning step, guided by an adaptively chosen intermediate goal. The proposed method is validated in diverse parking scenarios, including perpendicular, angled, and parallel parking. Through simulations, we showcase our approach's potential in greatly improving the efficiency and safety when compared to the state of the art spline-based planning method for parking situations.","authors":["Farhad Nawaz","Minjun Sung","Darshan Gadginmath","Jovin D'sa","Sangjae Bae","David Isele","Nadia Figueroa","Nikolai Matni","Faizan M. Tariq"],"url":"https://arxiv.org/abs/2504.12616"}
{"created":"2025-04-18","title":"SAM-Based Building Change Detection with Distribution-Aware Fourier Adaptation and Edge-Constrained Warping","abstract":"Building change detection remains challenging for urban development, disaster assessment, and military reconnaissance. While foundation models like Segment Anything Model (SAM) show strong segmentation capabilities, SAM is limited in the task of building change detection due to domain gap issues. Existing adapter-based fine-tuning approaches face challenges with imbalanced building distribution, resulting in poor detection of subtle changes and inaccurate edge extraction. Additionally, bi-temporal misalignment in change detection, typically addressed by optical flow, remains vulnerable to background noises. This affects the detection of building changes and compromises both detection accuracy and edge recognition. To tackle these challenges, we propose a new SAM-Based Network with Distribution-Aware Fourier Adaptation and Edge-Constrained Warping (FAEWNet) for building change detection. FAEWNet utilizes the SAM encoder to extract rich visual features from remote sensing images. To guide SAM in focusing on specific ground objects in remote sensing scenes, we propose a Distribution-Aware Fourier Aggregated Adapter to aggregate task-oriented changed information. This adapter not only effectively addresses the domain gap issue, but also pays attention to the distribution of changed buildings. Furthermore, to mitigate noise interference and misalignment in height offset estimation, we design a novel flow module that refines building edge extraction and enhances the perception of changed buildings. Our state-of-the-art results on the LEVIR-CD, S2Looking and WHU-CD datasets highlight the effectiveness of FAEWNet. The code is available at https://github.com/SUPERMAN123000/FAEWNet.","authors":["Yun-Cheng Li","Sen Lei","Yi-Tao Zhao","Heng-Chao Li","Jun Li","Antonio Plaza"],"url":"https://arxiv.org/abs/2504.12619"}
{"created":"2025-04-18","title":"Privacy-Preserving CNN Training with Transfer Learning: Two Hidden Layers","abstract":"In this paper, we present the demonstration of training a four-layer neural network entirely using fully homomorphic encryption (FHE), supporting both single-output and multi-output classification tasks in a non-interactive setting. A key contribution of our work is identifying that replacing \\textit{Softmax} with \\textit{Sigmoid}, in conjunction with the Binary Cross-Entropy (BCE) loss function, provides an effective and scalable solution for homomorphic classification. Moreover, we show that the BCE loss function, originally designed for multi-output tasks, naturally extends to the multi-class setting, thereby enabling broader applicability. We also highlight the limitations of prior loss functions such as the SLE loss and the one proposed in the 2019 CVPR Workshop, both of which suffer from vanishing gradients as network depth increases. To address the challenges posed by large-scale encrypted data, we further introduce an improved version of the previously proposed data encoding scheme, \\textit{Double Volley Revolver}, which achieves a better trade-off between computational and memory efficiency, making FHE-based neural network training more practical. The complete, runnable C++ code to implement our work can be found at: \\href{https://github.com/petitioner/ML.NNtraining}{$\\texttt{https://github.com/petitioner/ML.NNtraining}$}.","authors":["John Chiang"],"url":"https://arxiv.org/abs/2504.12623"}
{"created":"2025-04-18","title":"Packing Input Frame Context in Next-Frame Prediction Models for Video Generation","abstract":"We present a neural network structure, FramePack, to train next-frame (or next-frame-section) prediction models for video generation. The FramePack compresses input frames to make the transformer context length a fixed number regardless of the video length. As a result, we are able to process a large number of frames using video diffusion with computation bottleneck similar to image diffusion. This also makes the training video batch sizes significantly higher (batch sizes become comparable to image diffusion training). We also propose an anti-drifting sampling method that generates frames in inverted temporal order with early-established endpoints to avoid exposure bias (error accumulation over iterations). Finally, we show that existing video diffusion models can be finetuned with FramePack, and their visual quality may be improved because the next-frame prediction supports more balanced diffusion schedulers with less extreme flow shift timesteps.","authors":["Lvmin Zhang","Maneesh Agrawala"],"url":"https://arxiv.org/abs/2504.12626"}
{"created":"2025-04-18","title":"Uncertainty Quantification in Graph Neural Networks with Shallow Ensembles","abstract":"Machine-learned potentials (MLPs) have revolutionized materials discovery by providing accurate and efficient predictions of molecular and material properties. Graph Neural Networks (GNNs) have emerged as a state-of-the-art approach due to their ability to capture complex atomic interactions. However, GNNs often produce unreliable predictions when encountering out-of-domain data and it is difficult to identify when that happens. To address this challenge, we explore Uncertainty Quantification (UQ) techniques, focusing on Direct Propagation of Shallow Ensembles (DPOSE) as a computationally efficient alternative to deep ensembles. By integrating DPOSE into the SchNet model, we assess its ability to provide reliable uncertainty estimates across diverse Density Functional Theory datasets, including QM9, OC20, and Gold Molecular Dynamics. Our findings often demonstrate that DPOSE successfully distinguishes between in-domain and out-of-domain samples, exhibiting higher uncertainty for unobserved molecule and material classes. This work highlights the potential of lightweight UQ methods in improving the robustness of GNN-based materials modeling and lays the foundation for future integration with active learning strategies.","authors":["Tirtha Vinchurkar","Kareem Abdelmaqsoud","John R. Kitchin"],"url":"https://arxiv.org/abs/2504.12627"}
{"created":"2025-04-18","title":"Geometry-preserving Numerical Scheme for Riemannian Stochastic Differential Equations","abstract":"Stochastic differential equations (SDEs) on Riemannian manifolds have numerous applications in system identification and control. However, geometry-preserving numerical methods for simulating Riemannian SDEs remain relatively underdeveloped. In this paper, we propose the Exponential Euler-Maruyama (Exp-EM) scheme for approximating solutions of SDEs on Riemannian manifolds. The Exp-EM scheme is both geometry-preserving and computationally tractable. We establish a strong convergence rate of $\\mathcal{O}(\\delta^{\\frac{1 - \\epsilon}{2}})$ for the Exp-EM scheme, which extends previous results obtained for specific manifolds to a more general setting. Numerical simulations are provided to illustrate our theoretical findings.","authors":["Xi Wang","Victor Solo"],"url":"https://arxiv.org/abs/2504.12631"}
{"created":"2025-04-18","title":"Towards Characterizing Subjectivity of Individuals through Modeling Value Conflicts and Trade-offs","abstract":"Large Language Models (LLMs) not only have solved complex reasoning problems but also exhibit remarkable performance in tasks that require subjective decision making. Existing studies suggest that LLM generations can be subjectively grounded to some extent, yet exploring whether LLMs can account for individual-level subjectivity has not been sufficiently studied. In this paper, we characterize subjectivity of individuals on social media and infer their moral judgments using LLMs. We propose a framework, SOLAR (Subjective Ground with Value Abstraction), that observes value conflicts and trade-offs in the user-generated texts to better represent subjective ground of individuals. Empirical results show that our framework improves overall inference results as well as performance on controversial situations. Additionally, we qualitatively show that SOLAR provides explanations about individuals' value preferences, which can further account for their judgments.","authors":["Younghun Lee","Dan Goldwasser"],"url":"https://arxiv.org/abs/2504.12633"}
{"created":"2025-04-18","title":"A0: An Affordance-Aware Hierarchical Model for General Robotic Manipulation","abstract":"Robotic manipulation faces critical challenges in understanding spatial affordances--the \"where\" and \"how\" of object interactions--essential for complex manipulation tasks like wiping a board or stacking objects. Existing methods, including modular-based and end-to-end approaches, often lack robust spatial reasoning capabilities. Unlike recent point-based and flow-based affordance methods that focus on dense spatial representations or trajectory modeling, we propose A0, a hierarchical affordance-aware diffusion model that decomposes manipulation tasks into high-level spatial affordance understanding and low-level action execution. A0 leverages the Embodiment-Agnostic Affordance Representation, which captures object-centric spatial affordances by predicting contact points and post-contact trajectories. A0 is pre-trained on 1 million contact points data and fine-tuned on annotated trajectories, enabling generalization across platforms. Key components include Position Offset Attention for motion-aware feature extraction and a Spatial Information Aggregation Layer for precise coordinate mapping. The model's output is executed by the action execution module. Experiments on multiple robotic systems (Franka, Kinova, Realman, and Dobot) demonstrate A0's superior performance in complex tasks, showcasing its efficiency, flexibility, and real-world applicability.","authors":["Rongtao Xu","Jian Zhang","Minghao Guo","Youpeng Wen","Haoting Yang","Min Lin","Jianzheng Huang","Zhe Li","Kaidong Zhang","Liqiong Wang","Yuxuan Kuang","Meng Cao","Feng Zheng","Xiaodan Liang"],"url":"https://arxiv.org/abs/2504.12636"}
{"created":"2025-04-18","title":"Scaling Instruction-Tuned LLMs to Million-Token Contexts via Hierarchical Synthetic Data Generation","abstract":"Large Language Models (LLMs) struggle with long-context reasoning, not only due to the quadratic scaling of computational complexity with sequence length but also because of the scarcity and expense of annotating long-context data. There has been barely any open-source work that systematically ablates long-context data, nor is there any openly available instruction tuning dataset with contexts surpassing 100K tokens. To bridge this gap, we introduce a novel post-training synthetic data generation strategy designed to efficiently extend the context window of LLMs while preserving their general task performance. Our approach scalably extends to arbitrarily long context lengths, unconstrained by the length of available real-world data, which effectively addresses the scarcity of raw long-context data. Through a step-by-step rotary position embedding (RoPE) scaling training strategy, we demonstrate that our model, with a context length of up to 1M tokens, performs well on the RULER benchmark and InfiniteBench and maintains robust performance on general language tasks.","authors":["Linda He","Jue Wang","Maurice Weber","Shang Zhu","Ben Athiwaratkun","Ce Zhang"],"url":"https://arxiv.org/abs/2504.12637"}
{"created":"2025-04-18","title":"RoPETR: Improving Temporal Camera-Only 3D Detection by Integrating Enhanced Rotary Position Embedding","abstract":"This technical report introduces a targeted improvement to the StreamPETR framework, specifically aimed at enhancing velocity estimation, a critical factor influencing the overall NuScenes Detection Score. While StreamPETR exhibits strong 3D bounding box detection performance as reflected by its high mean Average Precision our analysis identified velocity estimation as a substantial bottleneck when evaluated on the NuScenes dataset. To overcome this limitation, we propose a customized positional embedding strategy tailored to enhance temporal modeling capabilities. Experimental evaluations conducted on the NuScenes test set demonstrate that our improved approach achieves a state-of-the-art NDS of 70.86% using the ViT-L backbone, setting a new benchmark for camera-only 3D object detection.","authors":["Hang Ji","Tao Ni","Xufeng Huang","Tao Luo","Xin Zhan","Junbo Chen"],"url":"https://arxiv.org/abs/2504.12643"}
{"created":"2025-04-18","title":"Quantum Computing Supported Adversarial Attack-Resilient Autonomous Vehicle Perception Module for Traffic Sign Classification","abstract":"Deep learning (DL)-based image classification models are essential for autonomous vehicle (AV) perception modules since incorrect categorization might have severe repercussions. Adversarial attacks are widely studied cyberattacks that can lead DL models to predict inaccurate output, such as incorrectly classified traffic signs by the perception module of an autonomous vehicle. In this study, we create and compare hybrid classical-quantum deep learning (HCQ-DL) models with classical deep learning (C-DL) models to demonstrate robustness against adversarial attacks for perception modules. Before feeding them into the quantum system, we used transfer learning models, alexnet and vgg-16, as feature extractors. We tested over 1000 quantum circuits in our HCQ-DL models for projected gradient descent (PGD), fast gradient sign attack (FGSA), and gradient attack (GA), which are three well-known untargeted adversarial approaches. We evaluated the performance of all models during adversarial attacks and no-attack scenarios. Our HCQ-DL models maintain accuracy above 95\\% during a no-attack scenario and above 91\\% for GA and FGSA attacks, which is higher than C-DL models. During the PGD attack, our alexnet-based HCQ-DL model maintained an accuracy of 85\\% compared to C-DL models that achieved accuracies below 21\\%. Our results highlight that the HCQ-DL models provide improved accuracy for traffic sign classification under adversarial settings compared to their classical counterparts.","authors":["Reek Majumder","Mashrur Chowdhury","Sakib Mahmud Khan","Zadid Khan","Fahim Ahmad","Frank Ngeni","Gurcan Comert","Judith Mwakalonge","Dimitra Michalaka"],"url":"https://arxiv.org/abs/2504.12644"}
{"created":"2025-04-18","title":"Replication Packages in Software Engineering Secondary Studies: A Systematic Mapping","abstract":"Context: Systematic reviews (SRs) summarize state-of-the-art evidence in science, including software engineering (SE). Objective: Our objective is to evaluate how SRs report replication packages and to provide a comprehensive list of these packages. Method: We examined 528 secondary studies published between 2013 and 2023 to analyze the availability and reporting of replication packages. Results: Our findings indicate that only 25.4% of the reviewed studies include replication packages. Encouragingly, the situation is gradually improving, as our regression analysis shows significant increase in the availability of replication packages over time. However, in 2023, just 50.6% of secondary studies provided a replication package while an even lower percentage, 29.1% had used a permanent repository with a digital object identifier (DOI) for storage. Conclusion: To enhance transparency and reproducibility in SE research, we advocate for the mandatory publication of replication packages in secondary studies.","authors":["Aleksi Huotala","Miikka Kuutila","Mika M\\\"antyl\\\"a"],"url":"https://arxiv.org/abs/2504.12646"}
{"created":"2025-04-18","title":"Tangent Space Parametrization for Stochastic Differential Equations on SO(n)","abstract":"In this paper, we study the numerical simulation of stochastic differential equations (SDEs) on the special orthogonal Lie group $\\text{SO}(n)$. We propose a geometry-preserving numerical scheme based on the stochastic tangent space parametrization (S-TaSP) method for state-dependent multiplicative SDEs on $\\text{SO}(n)$. The convergence analysis of the S-TaSP scheme establishes a strong convergence order of $\\mathcal{O}(\\delta^{\\frac{1-\\epsilon}{2}})$, which matches the convergence order of the previous stochastic Lie Euler-Maruyama scheme while avoiding the computational cost of the exponential map. Numerical simulation illustrates the theoretical results.","authors":["Xi Wang","Victor Solo"],"url":"https://arxiv.org/abs/2504.12650"}
{"created":"2025-04-18","title":"Feature selection based on cluster assumption in PU learning","abstract":"Feature selection is essential for efficient data mining and sometimes encounters the positive-unlabeled (PU) learning scenario, where only a few positive labels are available, while most data remains unlabeled. In certain real-world PU learning tasks, data subjected to adequate feature selection often form clusters with concentrated positive labels. Conventional feature selection methods that treat unlabeled data as negative may fail to capture the statistical characteristics of positive data in such scenarios, leading to suboptimal performance. To address this, we propose a novel feature selection method based on the cluster assumption in PU learning, called FSCPU. FSCPU formulates the feature selection problem as a binary optimization task, with an objective function explicitly designed to incorporate the cluster assumption in the PU learning setting. Experiments on synthetic datasets demonstrate the effectiveness of FSCPU across various data conditions. Moreover, comparisons with 10 conventional algorithms on three open datasets show that FSCPU achieves competitive performance in downstream classification tasks, even when the cluster assumption does not strictly hold.","authors":["Motonobu Uchikoshi","Youhei Akimoto"],"url":"https://arxiv.org/abs/2504.12651"}
{"created":"2025-04-18","title":"AdaptoVision: A Multi-Resolution Image Recognition Model for Robust and Scalable Classification","abstract":"This paper introduces AdaptoVision, a novel convolutional neural network (CNN) architecture designed to efficiently balance computational complexity and classification accuracy. By leveraging enhanced residual units, depth-wise separable convolutions, and hierarchical skip connections, AdaptoVision significantly reduces parameter count and computational requirements while preserving competitive performance across various benchmark and medical image datasets. Extensive experimentation demonstrates that AdaptoVision achieves state-of-the-art on BreakHis dataset and comparable accuracy levels, notably 95.3\\% on CIFAR-10 and 85.77\\% on CIFAR-100, without relying on any pretrained weights. The model's streamlined architecture and strategic simplifications promote effective feature extraction and robust generalization, making it particularly suitable for deployment in real-time and resource-constrained environments.","authors":["Md. Sanaullah Chowdhury Lameya Sabrin"],"url":"https://arxiv.org/abs/2504.12652"}
{"created":"2025-04-18","title":"VLMGuard-R1: Proactive Safety Alignment for VLMs via Reasoning-Driven Prompt Optimization","abstract":"Aligning Vision-Language Models (VLMs) with safety standards is essential to mitigate risks arising from their multimodal complexity, where integrating vision and language unveils subtle threats beyond the reach of conventional safeguards. Inspired by the insight that reasoning across modalities is key to preempting intricate vulnerabilities, we propose a novel direction for VLM safety: multimodal reasoning-driven prompt rewriting. To this end, we introduce VLMGuard-R1, a proactive framework that refines user inputs through a reasoning-guided rewriter, dynamically interpreting text-image interactions to deliver refined prompts that bolster safety across diverse VLM architectures without altering their core parameters. To achieve this, we devise a three-stage reasoning pipeline to synthesize a dataset that trains the rewriter to infer subtle threats, enabling tailored, actionable responses over generic refusals. Extensive experiments across three benchmarks with five VLMs reveal that VLMGuard-R1 outperforms four baselines. In particular, VLMGuard-R1 achieves a remarkable 43.59\\% increase in average safety across five models on the SIUO benchmark.","authors":["Menglan Chen","Xianghe Pang","Jingjing Dong","WenHao Wang","Yaxin Du","Siheng Chen"],"url":"https://arxiv.org/abs/2504.12661"}
{"created":"2025-04-18","title":"Persona-judge: Personalized Alignment of Large Language Models via Token-level Self-judgment","abstract":"Aligning language models with human preferences presents significant challenges, particularly in achieving personalization without incurring excessive computational costs. Existing methods rely on reward signals and additional annotated data, limiting their scalability and adaptability to diverse human values. To address these challenges, we introduce Persona-judge, a novel discriminative paradigm that enables training-free personalized alignment with unseen preferences. Instead of optimizing policy parameters through external reward feedback, Persona-judge leverages the intrinsic preference judgment capabilities of the model. Specifically, a draft model generates candidate tokens conditioned on a given preference, while a judge model, embodying another preference, cross-validates the predicted tokens whether to be accepted. Experimental results demonstrate that Persona-judge, using the inherent preference evaluation mechanisms of the model, offers a scalable and computationally efficient solution to personalized alignment, paving the way for more adaptive customized alignment.","authors":["Xiaotian Zhang","Ruizhe Chen","Yang Feng","Zuozhu Liu"],"url":"https://arxiv.org/abs/2504.12663"}
{"created":"2025-04-18","title":"Autonomous Drone for Dynamic Smoke Plume Tracking","abstract":"This paper presents a novel autonomous drone-based smoke plume tracking system capable of navigating and tracking plumes in highly unsteady atmospheric conditions. The system integrates advanced hardware and software and a comprehensive simulation environment to ensure robust performance in controlled and real-world settings. The quadrotor, equipped with a high-resolution imaging system and an advanced onboard computing unit, performs precise maneuvers while accurately detecting and tracking dynamic smoke plumes under fluctuating conditions. Our software implements a two-phase flight operation, i.e., descending into the smoke plume upon detection and continuously monitoring the smoke movement during in-plume tracking. Leveraging Proportional Integral-Derivative (PID) control and a Proximal Policy Optimization based Deep Reinforcement Learning (DRL) controller enables adaptation to plume dynamics. Unreal Engine simulation evaluates performance under various smoke-wind scenarios, from steady flow to complex, unsteady fluctuations, showing that while the PID controller performs adequately in simpler scenarios, the DRL-based controller excels in more challenging environments. Field tests corroborate these findings. This system opens new possibilities for drone-based monitoring in areas like wildfire management and air quality assessment. The successful integration of DRL for real-time decision-making advances autonomous drone control for dynamic environments.","authors":["Srijan Kumar Pal","Shashank Sharma","Nikil Krishnakumar","Jiarong Hong"],"url":"https://arxiv.org/abs/2504.12664"}
{"created":"2025-04-18","title":"Predicting Driver's Perceived Risk: a Model Based on Semi-Supervised Learning Strategy","abstract":"Drivers' perception of risk determines their acceptance, trust, and use of the Automated Driving Systems (ADSs). However, perceived risk is subjective and difficult to evaluate using existing methods. To address this issue, a driver's subjective perceived risk (DSPR) model is proposed, regarding perceived risk as a dynamically triggered mechanism with anisotropy and attenuation. 20 participants are recruited for a driver-in-the-loop experiment to report their real-time subjective risk ratings (SRRs) when experiencing various automatic driving scenarios. A convolutional neural network and bidirectional long short-term memory network with temporal pattern attention (CNN-Bi-LSTM-TPA) is embedded into a semi-supervised learning strategy to predict SRRs, aiming to reduce data noise caused by subjective randomness of participants. The results illustrate that DSPR achieves the highest prediction accuracy of 87.91% in predicting SRRs, compared to three state-of-the-art risk models. The semi-supervised strategy improves accuracy by 20.12%. Besides, CNN-Bi-LSTM-TPA network presents the highest accuracy among four different LSTM structures. This study offers an effective method for assessing driver's perceived risk, providing support for the safety enhancement of ADS and driver's trust improvement.","authors":["Siwei Huang","Chenhao Yang","Chuan Hu"],"url":"https://arxiv.org/abs/2504.12665"}
{"created":"2025-04-18","title":"Two Tasks, One Goal: Uniting Motion and Planning for Excellent End To End Autonomous Driving Performance","abstract":"End-to-end autonomous driving has made impressive progress in recent years. Former end-to-end autonomous driving approaches often decouple planning and motion tasks, treating them as separate modules. This separation overlooks the potential benefits that planning can gain from learning out-of-distribution data encountered in motion tasks. However, unifying these tasks poses significant challenges, such as constructing shared contextual representations and handling the unobservability of other vehicles' states. To address these challenges, we propose TTOG, a novel two-stage trajectory generation framework. In the first stage, a diverse set of trajectory candidates is generated, while the second stage focuses on refining these candidates through vehicle state information. To mitigate the issue of unavailable surrounding vehicle states, TTOG employs a self-vehicle data-trained state estimator, subsequently extended to other vehicles. Furthermore, we introduce ECSA (equivariant context-sharing scene adapter) to enhance the generalization of scene representations across different agents. Experimental results demonstrate that TTOG achieves state-of-the-art performance across both planning and motion tasks. Notably, on the challenging open-loop nuScenes dataset, TTOG reduces the L2 distance by 36.06\\%. Furthermore, on the closed-loop Bench2Drive dataset, our approach achieves a 22\\% improvement in the driving score (DS), significantly outperforming existing baselines.","authors":["Lin Liu","Ziying Song","Hongyu Pan","Lei Yang","Caiyan Jia"],"url":"https://arxiv.org/abs/2504.12667"}
{"created":"2025-04-18","title":"ACoRN: Noise-Robust Abstractive Compression in Retrieval-Augmented Language Models","abstract":"Abstractive compression utilizes smaller langauge models to condense query-relevant context, reducing computational costs in retrieval-augmented generation (RAG). However,retrieved documents often include information that is either irrelevant to answering the query or misleading due to factual incorrect content, despite having high relevance scores. This behavior indicates that abstractive compressors are more likely to omit important information essential for the correct answer, especially in long contexts where attention dispersion occurs. To address this issue, we categorize retrieved documents in a more fine-grained manner and propose Abstractive Compression Robust against Noise (ACoRN), which introduces two novel training steps. First, we use offline data augmentation on the training dataset to enhance compressor robustness against two distinct types of retrieval noise. Second, since the language modelbased compressor cannot fully utilize information from multiple retrieved documents and exhibits positional bias, we perform finetuning to generate summaries centered around key information that directly supports the correct answer. Our experiments demonstrate that T5-large, trained with ACoRN as a compressor, improves EM and F1 scores while preserving the answer string, which could serve as direct evidence. ACoRN excels on datasets with many accuracy-reducing documents, making it highly useful in real-world scenarios.","authors":["Singon Kim","Gunho Jung","Seong-Whan Lee"],"url":"https://arxiv.org/abs/2504.12673"}
{"created":"2025-04-18","title":"Physics Informed Constrained Learning of Dynamics from Static Data","abstract":"A physics-informed neural network (PINN) models the dynamics of a system by integrating the governing physical laws into the architecture of a neural network. By enforcing physical laws as constraints, PINN overcomes challenges with data scarsity and potentially high dimensionality. Existing PINN frameworks rely on fully observed time-course data, the acquisition of which could be prohibitive for many systems. In this study, we developed a new PINN learning paradigm, namely Constrained Learning, that enables the approximation of first-order derivatives or motions using non-time course or partially observed data. Computational principles and a general mathematical formulation of Constrained Learning were developed. We further introduced MPOCtrL (Message Passing Optimization-based Constrained Learning) an optimization approach tailored for the Constrained Learning framework that strives to balance the fitting of physical models and observed data. Its code is available at github link: https://github.com/ptdang1001/MPOCtrL Experiments on synthetic and real-world data demonstrated that MPOCtrL can effectively detect the nonlinear dependency between observed data and the underlying physical properties of the system. In particular, on the task of metabolic flux analysis, MPOCtrL outperforms all existing data-driven flux estimators.","authors":["Pengtao Dang","Tingbo Guo","Sha Cao","Chi Zhang"],"url":"https://arxiv.org/abs/2504.12675"}
{"created":"2025-04-18","title":"Accurate Tracking of Arabidopsis Root Cortex Cell Nuclei in 3D Time-Lapse Microscopy Images Based on Genetic Algorithm","abstract":"Arabidopsis is a widely used model plant to gain basic knowledge on plant physiology and development. Live imaging is an important technique to visualize and quantify elemental processes in plant development. To uncover novel theories underlying plant growth and cell division, accurate cell tracking on live imaging is of utmost importance. The commonly used cell tracking software, TrackMate, adopts tracking-by-detection fashion, which applies Laplacian of Gaussian (LoG) for blob detection, and Linear Assignment Problem (LAP) tracker for tracking. However, they do not perform sufficiently when cells are densely arranged. To alleviate the problems mentioned above, we propose an accurate tracking method based on Genetic algorithm (GA) using knowledge of Arabidopsis root cellular patterns and spatial relationship among volumes. Our method can be described as a coarse-to-fine method, in which we first conducted relatively easy line-level tracking of cell nuclei, then performed complicated nuclear tracking based on known linear arrangement of cell files and their spatial relationship between nuclei. Our method has been evaluated on a long-time live imaging dataset of Arabidopsis root tips, and with minor manual rectification, it accurately tracks nuclei. To the best of our knowledge, this research represents the first successful attempt to address a long-standing problem in the field of time-lapse microscopy in the root meristem by proposing an accurate tracking method for Arabidopsis root nuclei.","authors":["Yu Song","Tatsuaki Goh","Yinhao Li","Jiahua Dong","Shunsuke Miyashima","Yutaro Iwamoto","Yohei Kondo","Keiji Nakajima","Yen-wei Chen"],"url":"https://arxiv.org/abs/2504.12676"}
{"created":"2025-04-18","title":"A Genetic Approach to Gradient-Free Kinodynamic Planning in Uneven Terrains","abstract":"This paper proposes a genetic algorithm-based kinodynamic planning algorithm (GAKD) for car-like vehicles navigating uneven terrains modeled as triangular meshes. The algorithm's distinct feature is trajectory optimization over a fixed-length receding horizon using a genetic algorithm with heuristic-based mutation, ensuring the vehicle's controls remain within its valid operational range. By addressing challenges posed by uneven terrain meshes, such as changing face normals, GAKD offers a practical solution for path planning in complex environments. Comparative evaluations against Model Predictive Path Integral (MPPI) and log-MPPI methods show that GAKD achieves up to 20 percent improvement in traversability cost while maintaining comparable path length. These results demonstrate GAKD's potential in improving vehicle navigation on challenging terrains.","authors":["Otobong Jerome","Alexandr Klimchik","Alexander Maloletov","Geesara Kulathunga"],"url":"https://arxiv.org/abs/2504.12678"}
{"created":"2025-04-18","title":"TongUI: Building Generalized GUI Agents by Learning from Multimodal Web Tutorials","abstract":"Building Graphical User Interface (GUI) agents is a promising research direction, which simulates human interaction with computers or mobile phones to perform diverse GUI tasks. However, a major challenge in developing generalized GUI agents is the lack of sufficient trajectory data across various operating systems and applications, mainly due to the high cost of manual annotations. In this paper, we propose the TongUI framework that builds generalized GUI agents by learning from rich multimodal web tutorials. Concretely, we crawl and process online GUI tutorials (such as videos and articles) into GUI agent trajectory data, through which we produce the GUI-Net dataset containing 143K trajectory data across five operating systems and more than 200 applications. We develop the TongUI agent by fine-tuning Qwen2.5-VL-3B/7B models on GUI-Net, which show remarkable performance improvements on commonly used grounding and navigation benchmarks, outperforming baseline agents about 10\\% on multiple benchmarks, showing the effectiveness of the GUI-Net dataset and underscoring the significance of our TongUI framework. We will fully open-source the code, the GUI-Net dataset, and the trained models soon.","authors":["Bofei Zhang","Zirui Shang","Zhi Gao","Wang Zhang","Rui Xie","Xiaojian Ma","Tao Yuan","Xinxiao Wu","Song-Chun Zhu","Qing Li"],"url":"https://arxiv.org/abs/2504.12679"}
{"created":"2025-04-18","title":"Embodied-R: Collaborative Framework for Activating Embodied Spatial Reasoning in Foundation Models via Reinforcement Learning","abstract":"Humans can perceive and reason about spatial relationships from sequential visual observations, such as egocentric video streams. However, how pretrained models acquire such abilities, especially high-level reasoning, remains unclear. This paper introduces Embodied-R, a collaborative framework combining large-scale Vision-Language Models (VLMs) for perception and small-scale Language Models (LMs) for reasoning. Using Reinforcement Learning (RL) with a novel reward system considering think-answer logical consistency, the model achieves slow-thinking capabilities with limited computational resources. After training on only 5k embodied video samples, Embodied-R with a 3B LM matches state-of-the-art multimodal reasoning models (OpenAI-o1, Gemini-2.5-pro) on both in-distribution and out-of-distribution embodied spatial reasoning tasks. Embodied-R also exhibits emergent thinking patterns such as systematic analysis and contextual integration. We further explore research questions including response length, training on VLM, strategies for reward design, and differences in model generalization after SFT (Supervised Fine-Tuning) and RL training.","authors":["Baining Zhao","Ziyou Wang","Jianjie Fang","Chen Gao","Fanhang Man","Jinqiang Cui","Xin Wang","Xinlei Chen","Yong Li","Wenwu Zhu"],"url":"https://arxiv.org/abs/2504.12680"}
{"created":"2025-04-18","title":"GRAIL: Gradient-Based Adaptive Unlearning for Privacy and Copyright in LLMs","abstract":"Large Language Models (LLMs) trained on extensive datasets often learn sensitive information, which raises significant social and legal concerns under principles such as the \"Right to be forgotten.\" Retraining entire models from scratch to remove undesired information is both costly and impractical. Furthermore, existing single-domain unlearning methods fail to address multi-domain scenarios, where knowledge is interwoven across domains such as privacy and copyright, creating overlapping representations that lead to excessive knowledge removal or degraded performance. To tackle these issues, we propose GRAIL (GRadient-based AdaptIve unLearning), a novel multi-domain unlearning framework. GRAIL leverages gradient information from multiple domains to precisely distinguish the unlearning scope from the retention scope, and applies an adaptive parameter-wise localization strategy to selectively remove targeted knowledge while preserving critical parameters for each domain. Experimental results on unlearning benchmarks show that GRAIL achieves unlearning success on par with the existing approaches, while also demonstrating up to 17% stronger knowledge retention success compared to the previous state-of-art method. Our findings establish a new paradigm for effectively managing and regulating sensitive information in large-scale pre-trained language models.","authors":["Kun-Woo Kim","Ji-Hoon Park","Ju-Min Han","Seong-Whan Lee"],"url":"https://arxiv.org/abs/2504.12681"}
{"created":"2025-04-18","title":"WebLists: Extracting Structured Information From Complex Interactive Websites Using Executable LLM Agents","abstract":"Most recent web agent research has focused on navigation and transaction tasks, with little emphasis on extracting structured data at scale. We present WebLists, a benchmark of 200 data-extraction tasks across four common business and enterprise use-cases. Each task requires an agent to navigate to a webpage, configure it appropriately, and extract complete datasets with well-defined schemas. We show that both LLMs with search capabilities and SOTA web agents struggle with these tasks, with a recall of 3% and 31%, respectively, despite higher performance on question-answering tasks.","authors":["Arth Bohra","Manvel Saroyan","Danil Melkozerov","Vahe Karufanyan","Gabriel Maher","Pascal Weinberger","Artem Harutyunyan","Giovanni Campagna"],"url":"https://arxiv.org/abs/2504.12682"}
{"created":"2025-04-18","title":"SOPHY: Generating Simulation-Ready Objects with Physical Materials","abstract":"We present SOPHY, a generative model for 3D physics-aware shape synthesis. Unlike existing 3D generative models that focus solely on static geometry or 4D models that produce physics-agnostic animations, our approach jointly synthesizes shape, texture, and material properties related to physics-grounded dynamics, making the generated objects ready for simulations and interactive, dynamic environments. To train our model, we introduce a dataset of 3D objects annotated with detailed physical material attributes, along with an annotation pipeline for efficient material annotation. Our method enables applications such as text-driven generation of interactive, physics-aware 3D objects and single-image reconstruction of physically plausible shapes. Furthermore, our experiments demonstrate that jointly modeling shape and material properties enhances the realism and fidelity of generated shapes, improving performance on generative geometry evaluation metrics.","authors":["Junyi Cao","Evangelos Kalogerakis"],"url":"https://arxiv.org/abs/2504.12684"}
{"created":"2025-04-18","title":"Data-efficient LLM Fine-tuning for Code Generation","abstract":"Large language models (LLMs) have demonstrated significant potential in code generation tasks. However, there remains a performance gap between open-source and closed-source models. To address this gap, existing approaches typically generate large amounts of synthetic data for fine-tuning, which often leads to inefficient training. In this work, we propose a data selection strategy in order to improve the effectiveness and efficiency of training for code-based LLMs. By prioritizing data complexity and ensuring that the sampled subset aligns with the distribution of the original dataset, our sampling strategy effectively selects high-quality data. Additionally, we optimize the tokenization process through a \"dynamic pack\" technique, which minimizes padding tokens and reduces computational resource consumption. Experimental results show that when training on 40% of the OSS-Instruct dataset, the DeepSeek-Coder-Base-6.7B model achieves an average performance of 66.9%, surpassing the 66.1% performance with the full dataset. Moreover, training time is reduced from 47 minutes to 34 minutes, and the peak GPU memory decreases from 61.47 GB to 42.72 GB during a single epoch. Similar improvements are observed with the CodeLlama-Python-7B model on the Evol-Instruct dataset. By optimizing both data selection and tokenization, our approach not only improves model performance but also improves training efficiency.","authors":["Weijie Lv","Xuan Xia","Sheng-Jun Huang"],"url":"https://arxiv.org/abs/2504.12687"}
{"created":"2025-04-18","title":"HSS-IAD: A Heterogeneous Same-Sort Industrial Anomaly Detection Dataset","abstract":"Multi-class Unsupervised Anomaly Detection algorithms (MUAD) are receiving increasing attention due to their relatively low deployment costs and improved training efficiency. However, the real-world effectiveness of MUAD methods is questioned due to limitations in current Industrial Anomaly Detection (IAD) datasets. These datasets contain numerous classes that are unlikely to be produced by the same factory and fail to cover multiple structures or appearances. Additionally, the defects do not reflect real-world characteristics. Therefore, we introduce the Heterogeneous Same-Sort Industrial Anomaly Detection (HSS-IAD) dataset, which contains 8,580 images of metallic-like industrial parts and precise anomaly annotations. These parts exhibit variations in structure and appearance, with subtle defects that closely resemble the base materials. We also provide foreground images for synthetic anomaly generation. Finally, we evaluate popular IAD methods on this dataset under multi-class and class-separated settings, demonstrating its potential to bridge the gap between existing datasets and real factory conditions. The dataset is available at https://github.com/Qiqigeww/HSS-IAD-Dataset.","authors":["Qishan Wang","Shuyong Gao","Junjie Hu","Jiawen Yu","Xuan Tong","You Li","Wenqiang Zhang"],"url":"https://arxiv.org/abs/2504.12689"}
{"created":"2025-04-18","title":"Accessibility Recommendations for Designing Better Mobile Application User Interfaces for Seniors","abstract":"Seniors represent a growing user base for mobile applications; however, many apps fail to adequately address their accessibility challenges and usability preferences. To investigate this issue, we conducted an exploratory focus group study with 16 senior participants, from which we derived an initial set of user personas highlighting key accessibility and personalisation barriers. These personas informed the development of a model-driven engineering toolset, which was used to generate adaptive mobile app prototypes tailored to seniors' needs. We then conducted a second focus group study with 22 seniors to evaluate these prototypes and validate our findings. Based on insights from both studies, we developed a refined set of personas and a series of accessibility and personalisation recommendations grounded in empirical data, prior research, accessibility standards, and developer resources, aimed at supporting software practitioners in designing more inclusive mobile applications.","authors":["Shavindra Wickramathilaka","John Grundy","Kashumi Madampe","Omar Haggag"],"url":"https://arxiv.org/abs/2504.12690"}
{"created":"2025-04-18","title":"Why and How LLMs Hallucinate: Connecting the Dots with Subsequence Associations","abstract":"Large language models (LLMs) frequently generate hallucinations-content that deviates from factual accuracy or provided context-posing challenges for diagnosis due to the complex interplay of underlying causes. This paper introduces a subsequence association framework to systematically trace and understand hallucinations. Our key insight is that hallucinations arise when dominant hallucinatory associations outweigh faithful ones. Through theoretical and empirical analyses, we demonstrate that decoder-only transformers effectively function as subsequence embedding models, with linear layers encoding input-output associations. We propose a tracing algorithm that identifies causal subsequences by analyzing hallucination probabilities across randomized input contexts. Experiments show our method outperforms standard attribution techniques in identifying hallucination causes and aligns with evidence from the model's training corpus. This work provides a unified perspective on hallucinations and a robust framework for their tracing and analysis.","authors":["Yiyou Sun","Yu Gai","Lijie Chen","Abhilasha Ravichander","Yejin Choi","Dawn Song"],"url":"https://arxiv.org/abs/2504.12691"}
{"created":"2025-04-18","title":"Collaborative Perception Datasets for Autonomous Driving: A Review","abstract":"Collaborative perception has attracted growing interest from academia and industry due to its potential to enhance perception accuracy, safety, and robustness in autonomous driving through multi-agent information fusion. With the advancement of Vehicle-to-Everything (V2X) communication, numerous collaborative perception datasets have emerged, varying in cooperation paradigms, sensor configurations, data sources, and application scenarios. However, the absence of systematic summarization and comparative analysis hinders effective resource utilization and standardization of model evaluation. As the first comprehensive review focused on collaborative perception datasets, this work reviews and compares existing resources from a multi-dimensional perspective. We categorize datasets based on cooperation paradigms, examine their data sources and scenarios, and analyze sensor modalities and supported tasks. A detailed comparative analysis is conducted across multiple dimensions. We also outline key challenges and future directions, including dataset scalability, diversity, domain adaptation, standardization, privacy, and the integration of large language models. To support ongoing research, we provide a continuously updated online repository of collaborative perception datasets and related literature: https://github.com/frankwnb/Collaborative-Perception-Datasets-for-Autonomous-Driving.","authors":["Naibang Wang","Deyong Shang","Yan Gong","Xiaoxi Hu","Ziying Song","Lei Yang","Yuhan Huang","Xiaoyu Wang","Jianli Lu"],"url":"https://arxiv.org/abs/2504.12696"}
{"created":"2025-04-18","title":"Unsupervised Cross-Domain 3D Human Pose Estimation via Pseudo-Label-Guided Global Transforms","abstract":"Existing 3D human pose estimation methods often suffer in performance, when applied to cross-scenario inference, due to domain shifts in characteristics such as camera viewpoint, position, posture, and body size. Among these factors, camera viewpoints and locations {have been shown} to contribute significantly to the domain gap by influencing the global positions of human poses. To address this, we propose a novel framework that explicitly conducts global transformations between pose positions in the camera coordinate systems of source and target domains. We start with a Pseudo-Label Generation Module that is applied to the 2D poses of the target dataset to generate pseudo-3D poses. Then, a Global Transformation Module leverages a human-centered coordinate system as a novel bridging mechanism to seamlessly align the positional orientations of poses across disparate domains, ensuring consistent spatial referencing. To further enhance generalization, a Pose Augmentor is incorporated to address variations in human posture and body size. This process is iterative, allowing refined pseudo-labels to progressively improve guidance for domain adaptation. Our method is evaluated on various cross-dataset benchmarks, including Human3.6M, MPI-INF-3DHP, and 3DPW. The proposed method outperforms state-of-the-art approaches and even outperforms the target-trained model.","authors":["Jingjing Liu","Zhiyong Wang","Xinyu Fan","Amirhossein Dadashzadeh","Honghai Liu","Majid Mirmehdi"],"url":"https://arxiv.org/abs/2504.12699"}
{"created":"2025-04-18","title":"Embodied Neuromorphic Control Applied on a 7-DOF Robotic Manipulator","abstract":"The development of artificial intelligence towards real-time interaction with the environment is a key aspect of embodied intelligence and robotics. Inverse dynamics is a fundamental robotics problem, which maps from joint space to torque space of robotic systems. Traditional methods for solving it rely on direct physical modeling of robots which is difficult or even impossible due to nonlinearity and external disturbance. Recently, data-based model-learning algorithms are adopted to address this issue. However, they often require manual parameter tuning and high computational costs. Neuromorphic computing is inherently suitable to process spatiotemporal features in robot motion control at extremely low costs. However, current research is still in its infancy: existing works control only low-degree-of-freedom systems and lack performance quantification and comparison. In this paper, we propose a neuromorphic control framework to control 7 degree-of-freedom robotic manipulators. We use Spiking Neural Network to leverage the spatiotemporal continuity of the motion data to improve control accuracy, and eliminate manual parameters tuning. We validated the algorithm on two robotic platforms, which reduces torque prediction error by at least 60% and performs a target position tracking task successfully. This work advances embodied neuromorphic control by one step forward from proof of concept to applications in complex real-world tasks.","authors":["Ziqi Wang","Jingyue Zhao","Jichao Yang","Yaohua Wang","Xun Xiao","Yuan Li","Chao Xiao","Lei Wang"],"url":"https://arxiv.org/abs/2504.12702"}
{"created":"2025-04-18","title":"Spike-Kal: A Spiking Neuron Network Assisted Kalman Filter","abstract":"Kalman filtering can provide an optimal estimation of the system state from noisy observation data. This algorithm's performance depends on the accuracy of system modeling and noise statistical characteristics, which are usually challenging to obtain in practical applications. The powerful nonlinear modeling capabilities of deep learning, combined with its ability to extract features from large amounts of data automatically, offer new opportunities for improving the Kalman filter. This paper proposes a novel method that leverages the Spiking Neural Network to optimize the Kalman filter. Our approach aims to reduce the reliance on prior knowledge of system and observation noises, allowing for adaptation to varying statistical characteristics of time-varying noise. Furthermore, we investigate the potential of SNNs in improving the computational efficiency of the Kalman filter. In our method, we design an integration strategy between the SNN and the Kalman filter. The SNN is trained to directly approximate the optimal gain matrix from observation data, thereby alleviating the computational burden of complex matrix operations inherent in traditional Kalman filtering while maintaining the accuracy and robustness of state estimation. Its average error has been reduced by 18\\%-65\\% compared with other methods.","authors":["Xun Xiao","Junbo Tie","Jinyue Zhao","Ziqi Wang","Yuan Li","Qiang Dou","Lei Wang"],"url":"https://arxiv.org/abs/2504.12703"}
{"created":"2025-04-18","title":"SmartFreeEdit: Mask-Free Spatial-Aware Image Editing with Complex Instruction Understanding","abstract":"Recent advancements in image editing have utilized large-scale multimodal models to enable intuitive, natural instruction-driven interactions. However, conventional methods still face significant challenges, particularly in spatial reasoning, precise region segmentation, and maintaining semantic consistency, especially in complex scenes. To overcome these challenges, we introduce SmartFreeEdit, a novel end-to-end framework that integrates a multimodal large language model (MLLM) with a hypergraph-enhanced inpainting architecture, enabling precise, mask-free image editing guided exclusively by natural language instructions. The key innovations of SmartFreeEdit include:(1)the introduction of region aware tokens and a mask embedding paradigm that enhance the spatial understanding of complex scenes;(2) a reasoning segmentation pipeline designed to optimize the generation of editing masks based on natural language instructions;and (3) a hypergraph-augmented inpainting module that ensures the preservation of both structural integrity and semantic coherence during complex edits, overcoming the limitations of local-based image generation. Extensive experiments on the Reason-Edit benchmark demonstrate that SmartFreeEdit surpasses current state-of-the-art methods across multiple evaluation metrics, including segmentation accuracy, instruction adherence, and visual quality preservation, while addressing the issue of local information focus and improving global consistency in the edited image. Our project will be available at https://github.com/smileformylove/SmartFreeEdit.","authors":["Qianqian Sun","Jixiang Luo","Dell Zhang","Xuelong Li"],"url":"https://arxiv.org/abs/2504.12704"}
{"created":"2025-04-18","title":"Self-Supervised Pre-training with Combined Datasets for 3D Perception in Autonomous Driving","abstract":"The significant achievements of pre-trained models leveraging large volumes of data in the field of NLP and 2D vision inspire us to explore the potential of extensive data pre-training for 3D perception in autonomous driving. Toward this goal, this paper proposes to utilize massive unlabeled data from heterogeneous datasets to pre-train 3D perception models. We introduce a self-supervised pre-training framework that learns effective 3D representations from scratch on unlabeled data, combined with a prompt adapter based domain adaptation strategy to reduce dataset bias. The approach significantly improves model performance on downstream tasks such as 3D object detection, BEV segmentation, 3D object tracking, and occupancy prediction, and shows steady performance increase as the training data volume scales up, demonstrating the potential of continually benefit 3D perception models for autonomous driving. We will release the source code to inspire further investigations in the community.","authors":["Shumin Wang","Zhuoran Yang","Lidian Wang","Zhipeng Tang","Heng Li","Lehan Pan","Sha Zhang","Jie Peng","Jianmin Ji","Yanyong Zhang"],"url":"https://arxiv.org/abs/2504.12709"}
{"created":"2025-04-18","title":"NTIRE 2025 Challenge on Day and Night Raindrop Removal for Dual-Focused Images: Methods and Results","abstract":"This paper reviews the NTIRE 2025 Challenge on Day and Night Raindrop Removal for Dual-Focused Images. This challenge received a wide range of impressive solutions, which are developed and evaluated using our collected real-world Raindrop Clarity dataset. Unlike existing deraining datasets, our Raindrop Clarity dataset is more diverse and challenging in degradation types and contents, which includes day raindrop-focused, day background-focused, night raindrop-focused, and night background-focused degradations. This dataset is divided into three subsets for competition: 14,139 images for training, 240 images for validation, and 731 images for testing. The primary objective of this challenge is to establish a new and powerful benchmark for the task of removing raindrops under varying lighting and focus conditions. There are a total of 361 participants in the competition, and 32 teams submitting valid solutions and fact sheets for the final testing phase. These submissions achieved state-of-the-art (SOTA) performance on the Raindrop Clarity dataset. The project can be found at https://lixinustc.github.io/CVPR-NTIRE2025-RainDrop-Competition.github.io/.","authors":["Xin Li","Yeying Jin","Xin Jin","Zongwei Wu","Bingchen Li","Yufei Wang","Wenhan Yang","Yu Li","Zhibo Chen","Bihan Wen","Robby T. Tan","Radu Timofte","Qiyu Rong","Hongyuan Jing","Mengmeng Zhang","Jinglong Li","Xiangyu Lu","Yi Ren","Yuting Liu","Meng Zhang","Xiang Chen","Qiyuan Guan","Jiangxin Dong","Jinshan Pan","Conglin Gou","Qirui Yang","Fangpu Zhang","Yunlong Lin","Sixiang Chen","Guoxi Huang","Ruirui Lin","Yan Zhang","Jingyu Yang","Huanjing Yue","Jiyuan Chen","Qiaosi Yi","Hongjun Wang","Chenxi Xie","Shuai Li","Yuhui Wu","Kaiyi Ma","Jiakui Hu","Juncheng Li","Liwen Pan","Guangwei Gao","Wenjie Li","Zhenyu Jin","Heng Guo","Zhanyu Ma","Yubo Wang","Jinghua Wang","Wangzhi Xing","Anjusree Karnavar","Diqi Chen","Mohammad Aminul Islam","Hao Yang","Ruikun Zhang","Liyuan Pan","Qianhao Luo","XinCao","Han Zhou","Yan Min","Wei Dong","Jun Chen","Taoyi Wu","Weijia Dou","Yu Wang","Shengjie Zhao","Yongcheng Huang","Xingyu Han","Anyan Huang","Hongtao Wu","Hong Wang","Yefeng Zheng","Abhijeet Kumar","Aman Kumar","Marcos V. Conde","Paula Garrido","Daniel Feijoo","Juan C. Benito","Guanglu Dong","Xin Lin","Siyuan Liu","Tianheng Zheng","Jiayu Zhong","Shouyi Wang","Xiangtai Li","Lanqing Guo","Lu Qi","Chao Ren","Shuaibo Wang","Shilong Zhang","Wanyu Zhou","Yunze Wu","Qinzhong Tan","Jieyuan Pei","Zhuoxuan Li","Jiayu Wang","Haoyu Bian","Haoran Sun","Subhajit Paul","Ni Tang","Junhao Huang","Zihan Cheng","Hongyun Zhu","Yuehan Wu","Kaixin Deng","Hang Ouyang","Tianxin Xiao","Fan Yang","Zhizun Luo","Zeyu Xiao","Zhuoyuan Li","Nguyen Pham Hoang Le","An Dinh Thien","Son T. Luu","Kiet Van Nguyen","Ronghua Xu","Xianmin Tian","Weijian Zhou","Jiacheng Zhang","Yuqian Chen","Yihang Duan","Yujie Wu","Suresh Raikwar","Arsh Garg","Kritika","Jianhua Zheng","Xiaoshan Ma","Ruolin Zhao","Yongyu Yang","Yongsheng Liang","Guiming Huang","Qiang Li","Hongbin Zhang","Xiangyu Zheng","A. N. Rajagopalan"],"url":"https://arxiv.org/abs/2504.12711"}
{"created":"2025-04-18","title":"Convergence and Implicit Bias of Gradient Descent on Continual Linear Classification","abstract":"We study continual learning on multiple linear classification tasks by sequentially running gradient descent (GD) for a fixed budget of iterations per task. When all tasks are jointly linearly separable and are presented in a cyclic/random order, we show the directional convergence of the trained linear classifier to the joint (offline) max-margin solution. This is surprising because GD training on a single task is implicitly biased towards the individual max-margin solution for the task, and the direction of the joint max-margin solution can be largely different from these individual solutions. Additionally, when tasks are given in a cyclic order, we present a non-asymptotic analysis on cycle-averaged forgetting, revealing that (1) alignment between tasks is indeed closely tied to catastrophic forgetting and backward knowledge transfer and (2) the amount of forgetting vanishes to zero as the cycle repeats. Lastly, we analyze the case where the tasks are no longer jointly separable and show that the model trained in a cyclic order converges to the unique minimum of the joint loss function.","authors":["Hyunji Jung","Hanseul Cho","Chulhee Yun"],"url":"https://arxiv.org/abs/2504.12712"}
{"created":"2025-04-18","title":"Efficient Primal-dual Forward-backward Splitting Method for Wasserstein-like Gradient Flows with General Nonlinear Mobilities","abstract":"We construct an efficient primal-dual forward-backward (PDFB) splitting method for computing a class of minimizing movement schemes with nonlinear mobility transport distances, and apply it to computing Wasserstein-like gradient flows. This approach introduces a novel saddle point formulation for the minimizing movement schemes, leveraging a support function form from the Benamou-Brenier dynamical formulation of optimal transport. The resulting framework allows for flexible computation of Wasserstein-like gradient flows by solving the corresponding saddle point problem at the fully discrete level, and can be easily extended to handle general nonlinear mobilities. We also provide a detailed convergence analysis of the PDFB splitting method, along with practical remarks on its implementation and application. The effectiveness of the method is demonstrated through several challenging numerical examples.","authors":["Yunhong Deng","Li Wang","Chaozhen Wei"],"url":"https://arxiv.org/abs/2504.12713"}
{"created":"2025-04-18","title":"Cross-environment Cooperation Enables Zero-shot Multi-agent Coordination","abstract":"Zero-shot coordination (ZSC), the ability to adapt to a new partner in a cooperative task, is a critical component of human-compatible AI. While prior work has focused on training agents to cooperate on a single task, these specialized models do not generalize to new tasks, even if they are highly similar. Here, we study how reinforcement learning on a distribution of environments with a single partner enables learning general cooperative skills that support ZSC with many new partners on many new problems. We introduce two Jax-based, procedural generators that create billions of solvable coordination challenges. We develop a new paradigm called Cross-Environment Cooperation (CEC), and show that it outperforms competitive baselines quantitatively and qualitatively when collaborating with real people. Our findings suggest that learning to collaborate across many unique scenarios encourages agents to develop general norms, which prove effective for collaboration with different partners. Together, our results suggest a new route toward designing generalist cooperative agents capable of interacting with humans without requiring human data.","authors":["Kunal Jha","Wilka Carvalho","Yancheng Liang","Simon S. Du","Max Kleiman-Weiner","Natasha Jaques"],"url":"https://arxiv.org/abs/2504.12714"}
{"created":"2025-04-18","title":"Hierarchical Vector Quantized Graph Autoencoder with Annealing-Based Code Selection","abstract":"Graph self-supervised learning has gained significant attention recently. However, many existing approaches heavily depend on perturbations, and inappropriate perturbations may corrupt the graph's inherent information. The Vector Quantized Variational Autoencoder (VQ-VAE) is a powerful autoencoder extensively used in fields such as computer vision; however, its application to graph data remains underexplored. In this paper, we provide an empirical analysis of vector quantization in the context of graph autoencoders, demonstrating its significant enhancement of the model's capacity to capture graph topology. Furthermore, we identify two key challenges associated with vector quantization when applying in graph data: codebook underutilization and codebook space sparsity. For the first challenge, we propose an annealing-based encoding strategy that promotes broad code utilization in the early stages of training, gradually shifting focus toward the most effective codes as training progresses. For the second challenge, we introduce a hierarchical two-layer codebook that captures relationships between embeddings through clustering. The second layer codebook links similar codes, encouraging the model to learn closer embeddings for nodes with similar features and structural topology in the graph. Our proposed model outperforms 16 representative baseline methods in self-supervised link prediction and node classification tasks across multiple datasets.","authors":["Long Zeng","Jianxiang Yu","Jiapeng Zhu","Qingsong Zhong","Xiang Li"],"url":"https://arxiv.org/abs/2504.12715"}
{"created":"2025-04-18","title":"Post-pre-training for Modality Alignment in Vision-Language Foundation Models","abstract":"Contrastive language image pre-training (CLIP) is an essential component of building modern vision-language foundation models. While CLIP demonstrates remarkable zero-shot performance on downstream tasks, the multi-modal feature spaces still suffer from a modality gap, which is a gap between image and text feature clusters and limits downstream task performance. Although existing works attempt to address the modality gap by modifying pre-training or fine-tuning, they struggle with heavy training costs with large datasets or degradations of zero-shot performance. This paper presents CLIP-Refine, a post-pre-training method for CLIP models at a phase between pre-training and fine-tuning. CLIP-Refine aims to align the feature space with 1 epoch training on small image-text datasets without zero-shot performance degradations. To this end, we introduce two techniques: random feature alignment (RaFA) and hybrid contrastive-distillation (HyCD). RaFA aligns the image and text features to follow a shared prior distribution by minimizing the distance to random reference vectors sampled from the prior. HyCD updates the model with hybrid soft labels generated by combining ground-truth image-text pair labels and outputs from the pre-trained CLIP model. This contributes to achieving both maintaining the past knowledge and learning new knowledge to align features. Our extensive experiments with multiple classification and retrieval tasks show that CLIP-Refine succeeds in mitigating the modality gap and improving the zero-shot performance.","authors":["Shin'ya Yamaguchi","Dewei Feng","Sekitoshi Kanai","Kazuki Adachi","Daiki Chijiwa"],"url":"https://arxiv.org/abs/2504.12717"}
{"created":"2025-04-18","title":"B*: Efficient and Optimal Base Placement for Fixed-Base Manipulators","abstract":"B* is a novel optimization framework that addresses a critical challenge in fixed-base manipulator robotics: optimal base placement. Current methods rely on pre-computed kinematics databases generated through sampling to search for solutions. However, they face an inherent trade-off between solution optimality and computational efficiency when determining sampling resolution. To address these limitations, B* unifies multiple objectives without database dependence. The framework employs a two-layer hierarchical approach. The outer layer systematically manages terminal constraints through progressive tightening, particularly for base mobility, enabling feasible initialization and broad solution exploration. The inner layer addresses non-convexities in each outer-layer subproblem through sequential local linearization, converting the original problem into tractable sequential linear programming (SLP). Testing across multiple robot platforms demonstrates B*'s effectiveness. The framework achieves solution optimality five orders of magnitude better than sampling-based approaches while maintaining perfect success rates and reduced computational overhead. Operating directly in configuration space, B* enables simultaneous path planning with customizable optimization criteria. B* serves as a crucial initialization tool that bridges the gap between theoretical motion planning and practical deployment, where feasible trajectory existence is fundamental.","authors":["Zihang Zhao","Leiyao Cui","Sirui Xie","Saiyao Zhang","Zhi Han","Lecheng Ruan","Yixin Zhu"],"url":"https://arxiv.org/abs/2504.12719"}
{"created":"2025-04-18","title":"Malicious Code Detection in Smart Contracts via Opcode Vectorization","abstract":"With the booming development of blockchain technology, smart contracts have been widely used in finance, supply chain, Internet of things and other fields in recent years. However, the security problems of smart contracts become increasingly prominent. Security events caused by smart contracts occur frequently, and the existence of malicious codes may lead to the loss of user assets and system crash. In this paper, a simple study is carried out on malicious code detection of intelligent contracts based on machine learning. The main research work and achievements are as follows: Feature extraction and vectorization of smart contract are the first step to detect malicious code of smart contract by using machine learning method, and feature processing has an important impact on detection results. In this paper, an opcode vectorization method based on smart contract text is adopted. Based on considering the structural characteristics of contract opcodes, the opcodes are classified and simplified. Then, N-Gram (N=2) algorithm and TF-IDF algorithm are used to convert the simplified opcodes into vectors, and then put into the machine learning model for training. In contrast, N-Gram algorithm and TF-IDF algorithm are directly used to quantify opcodes and put into the machine learning model training. Judging which feature extraction method is better according to the training results. Finally, the classifier chain is applied to the intelligent contract malicious code detection.","authors":["Huanhuan Zou","Zongwei Li","Xiaoqi Li"],"url":"https://arxiv.org/abs/2504.12720"}
{"created":"2025-04-18","title":"TimeCapsule: Solving the Jigsaw Puzzle of Long-Term Time Series Forecasting with Compressed Predictive Representations","abstract":"Recent deep learning models for Long-term Time Series Forecasting (LTSF) often emphasize complex, handcrafted designs, while simpler architectures like linear models or MLPs have often outperformed these intricate solutions. In this paper, we revisit and organize the core ideas behind several key techniques, such as redundancy reduction and multi-scale modeling, which are frequently employed in advanced LTSF models. Our goal is to streamline these ideas for more efficient deep learning utilization. To this end, we introduce TimeCapsule, a model built around the principle of high-dimensional information compression that unifies these techniques in a generalized yet simplified framework. Specifically, we model time series as a 3D tensor, incorporating temporal, variate, and level dimensions, and leverage mode production to capture multi-mode dependencies while achieving dimensionality compression. We propose an internal forecast within the compressed representation domain, supported by the Joint-Embedding Predictive Architecture (JEPA), to monitor the learning of predictive representations. Extensive experiments on challenging benchmarks demonstrate the versatility of our method, showing that TimeCapsule can achieve state-of-the-art performance.","authors":["Yihang Lu","Yangyang Xu","Qitao Qing","Xianwei Meng"],"url":"https://arxiv.org/abs/2504.12721"}
{"created":"2025-04-18","title":"SimUSER: Simulating User Behavior with Large Language Models for Recommender System Evaluation","abstract":"Recommender systems play a central role in numerous real-life applications, yet evaluating their performance remains a significant challenge due to the gap between offline metrics and online behaviors. Given the scarcity and limits (e.g., privacy issues) of real user data, we introduce SimUSER, an agent framework that serves as believable and cost-effective human proxies. SimUSER first identifies self-consistent personas from historical data, enriching user profiles with unique backgrounds and personalities. Then, central to this evaluation are users equipped with persona, memory, perception, and brain modules, engaging in interactions with the recommender system. SimUSER exhibits closer alignment with genuine humans than prior work, both at micro and macro levels. Additionally, we conduct insightful experiments to explore the effects of thumbnails on click rates, the exposure effect, and the impact of reviews on user engagement. Finally, we refine recommender system parameters based on offline A/B test results, resulting in improved user engagement in the real world.","authors":["Nicolas Bougie","Narimasa Watanabe"],"url":"https://arxiv.org/abs/2504.12722"}
{"created":"2025-04-18","title":"KODIS: A Multicultural Dispute Resolution Dialogue Corpus","abstract":"We present KODIS, a dyadic dispute resolution corpus containing thousands of dialogues from over 75 countries. Motivated by a theoretical model of culture and conflict, participants engage in a typical customer service dispute designed by experts to evoke strong emotions and conflict. The corpus contains a rich set of dispositional, process, and outcome measures. The initial analysis supports theories of how anger expressions lead to escalatory spirals and highlights cultural differences in emotional expression. We make this corpus and data collection framework available to the community.","authors":["James Hale","Sushrita Rakshit","Kushal Chawla","Jeanne M. Brett","Jonathan Gratch"],"url":"https://arxiv.org/abs/2504.12723"}
{"created":"2025-04-18","title":"Faster multivariate integration in D-modules","abstract":"We present a new algorithm for solving the reduction problem in the context of holonomic integrals, which in turn provides an approach to integration with parameters. Our method extends the Griffiths--Dwork reduction technique to holonomic systems and is implemented in Julia. While not yet outperforming creative telescoping in D-finite cases, it enhances computational capabilities within the holonomic framework. As an application, we derive a previously unattainable differential equation for the generating series of 8-regular graphs.","authors":["Hadrien Brochet","Fr\\'ed\\'eric Chyzak","Pierre Lairez"],"url":"https://arxiv.org/abs/2504.12724"}
{"created":"2025-04-18","title":"Validating LLM-Generated Relevance Labels for Educational Resource Search","abstract":"Manual relevance judgements in Information Retrieval are costly and require expertise, driving interest in using Large Language Models (LLMs) for automatic assessment. While LLMs have shown promise in general web search scenarios, their effectiveness for evaluating domain-specific search results, such as educational resources, remains unexplored. To investigate different ways of including domain-specific criteria in LLM prompts for relevance judgement, we collected and released a dataset of 401 human relevance judgements from a user study involving teaching professionals performing search tasks related to lesson planning. We compared three approaches to structuring these prompts: a simple two-aspect evaluation baseline from prior work on using LLMs as relevance judges, a comprehensive 12-dimensional rubric derived from educational literature, and criteria directly informed by the study participants. Using domain-specific frameworks, LLMs achieved strong agreement with human judgements (Cohen's $\\kappa$ up to 0.650), significantly outperforming the baseline approach. The participant-derived framework proved particularly robust, with GPT-3.5 achieving $\\kappa$ scores of 0.639 and 0.613 for 10-dimension and 5-dimension versions respectively. System-level evaluation showed that LLM judgements reliably identified top-performing retrieval approaches (RBO scores 0.71-0.76) while maintaining reasonable discrimination between systems (RBO 0.52-0.56). These findings suggest that LLMs can effectively evaluate educational resources when prompted with domain-specific criteria, though performance varies with framework complexity and input structure.","authors":["Ratan J. Sebastian","Anett Hoppe"],"url":"https://arxiv.org/abs/2504.12732"}
{"created":"2025-04-18","title":"Adversary-Augmented Simulation for Fairness Evaluation and Defense in Hyperledger Fabric","abstract":"This paper presents an adversary model and a simulation framework specifically tailored for analyzing attacks on distributed systems composed of multiple distributed protocols, with a focus on assessing the security of blockchain networks. Our model classifies and constrains adversarial actions based on the assumptions of the target protocols, defined by failure models, communication models, and the fault tolerance thresholds of Byzantine Fault Tolerant (BFT) protocols. The goal is to study not only the intended effects of adversarial strategies but also their unintended side effects on critical system properties. We apply this framework to analyze fairness properties in a Hyperledger Fabric (HF) blockchain network. Our focus is on novel fairness attacks that involve coordinated adversarial actions across various HF services. Simulations show that even a constrained adversary can violate fairness with respect to specific clients (client fairness) and impact related guarantees (order fairness), which relate the reception order of transactions to their final order in the blockchain. This paper significantly extends our previous work by introducing and evaluating a mitigation mechanism specifically designed to counter transaction reordering attacks. We implement and integrate this defense into our simulation environment, demonstrating its effectiveness under diverse conditions.","authors":["Erwan Mahe","Rouwaida Abdallah","Pierre-Yves Piriou","Sara Tucci-Piergiovanni"],"url":"https://arxiv.org/abs/2504.12733"}
{"created":"2025-04-18","title":"Pandora: A Code-Driven Large Language Model Agent for Unified Reasoning Across Diverse Structured Knowledge","abstract":"Unified Structured Knowledge Reasoning (USKR) aims to answer natural language questions (NLQs) by using structured sources such as tables, databases, and knowledge graphs in a unified way. Existing USKR methods either rely on employing task-specific strategies or custom-defined representations, which struggle to leverage the knowledge transfer between different SKR tasks or align with the prior of LLMs, thereby limiting their performance. This paper proposes a novel USKR framework named \\textsc{Pandora}, which takes advantage of \\textsc{Python}'s \\textsc{Pandas} API to construct a unified knowledge representation for alignment with LLM pre-training. It employs an LLM to generate textual reasoning steps and executable Python code for each question. Demonstrations are drawn from a memory of training examples that cover various SKR tasks, facilitating knowledge transfer. Extensive experiments on four benchmarks involving three SKR tasks demonstrate that \\textsc{Pandora} outperforms existing unified frameworks and competes effectively with task-specific methods.","authors":["Yongrui Chen","Junhao He","Linbo Fu","Shenyu Zhang","Rihui Jin","Xinbang Dai","Jiaqi Li","Dehai Min","Nan Hu","Yuxin Zhang","Guilin Qi","Yi Huang","Tongtong Wu"],"url":"https://arxiv.org/abs/2504.12734"}
{"created":"2025-04-18","title":"The Athenian Academy: A Seven-Layer Architecture Model for Multi-Agent Systems","abstract":"This paper proposes the \"Academy of Athens\" multi-agent seven-layer framework, aimed at systematically addressing challenges in multi-agent systems (MAS) within artificial intelligence (AI) art creation, such as collaboration efficiency, role allocation, environmental adaptation, and task parallelism. The framework divides MAS into seven layers: multi-agent collaboration, single-agent multi-role playing, single-agent multi-scene traversal, single-agent multi-capability incarnation, different single agents using the same large model to achieve the same target agent, single-agent using different large models to achieve the same target agent, and multi-agent synthesis of the same target agent. Through experimental validation in art creation, the framework demonstrates its unique advantages in task collaboration, cross-scene adaptation, and model fusion. This paper further discusses current challenges such as collaboration mechanism optimization, model stability, and system security, proposing future exploration through technologies like meta-learning and federated learning. The framework provides a structured methodology for multi-agent collaboration in AI art creation and promotes innovative applications in the art field.","authors":["Lidong Zhai","Zhijie Qiu","Xizhong Guo","Jiaqi Li"],"url":"https://arxiv.org/abs/2504.12735"}
{"created":"2025-04-18","title":"Incorporating a Deep Neural Network into Moving Horizon Estimation for Embedded Thermal Torque Derating of an Electric Machine","abstract":"This study introduces a novel state estimation framework that incorporates Deep Neural Networks (DNNs) into Moving Horizon Estimation (MHE), shifting from traditional physics-based models to rapidly developed data-driven techniques. A DNN model with Long Short-Term Memory (LSTM) nodes is trained on synthetic data generated by a high-fidelity thermal model of a Permanent Magnet Synchronous Machine (PMSM), which undergoes thermal derating as part of the torque control strategy in a battery electric vehicle. The MHE is constructed by integrating the trained DNN with a simplified driving dynamics model in a discrete-time formulation, incorporating the LSTM hidden and cell states in the state vector to retain system dynamics. The resulting optimal control problem (OCP) is formulated as a nonlinear program (NLP) and implemented using the acados framework. Model-in-the-loop (MiL) simulations demonstrate accurate temperature estimation, even under noisy sensor conditions or failures. Achieving threefold real-time capability on embedded hardware confirms the feasibility of the approach for practical deployment. The primary focus of this study is to assess the feasibility of the MHE framework using a DNN-based plant model instead of focusing on quantitative comparisons of vehicle performance. Overall, this research highlights the potential of DNN-based MHE for real-time, safety-critical applications by combining the strengths of model-based and data-driven methods.","authors":["Alexander Winkler","Pranav Shah","Katrin Baumg\\\"artner","Vasu Sharma","David Gordon","Jakob Andert"],"url":"https://arxiv.org/abs/2504.12736"}
{"created":"2025-04-18","title":"Chinese-Vicuna: A Chinese Instruction-following Llama-based Model","abstract":"Chinese-Vicuna is an open-source, resource-efficient language model designed to bridge the gap in Chinese instruction-following capabilities by fine-tuning Meta's LLaMA architecture using Low-Rank Adaptation (LoRA). Targeting low-resource environments, it enables cost-effective deployment on consumer GPUs (e.g., RTX-2080Ti for 7B models) and supports domain-specific adaptation in fields like healthcare and law. By integrating hybrid datasets (BELLE and Guanaco) and 4-bit quantization (QLoRA), the model achieves competitive performance in tasks such as translation, code generation, and domain-specific Q\\&amp;A. The project provides a comprehensive toolkit for model conversion, CPU inference, and multi-turn dialogue interfaces, emphasizing accessibility for researchers and developers. Evaluations indicate competitive performance across medical tasks, multi-turn dialogue coherence, and real-time legal updates. Chinese-Vicuna's modular design, open-source ecosystem, and community-driven enhancements position it as a versatile foundation for Chinese LLM applications.","authors":["Chenghao Fan","Zhenyi Lu","Jie Tian"],"url":"https://arxiv.org/abs/2504.12737"}
{"created":"2025-04-18","title":"Mask Image Watermarking","abstract":"We present MaskMark, a simple, efficient and flexible framework for image watermarking. MaskMark has two variants: MaskMark-D, which supports global watermark embedding, watermark localization, and local watermark extraction for applications such as tamper detection, and MaskMark-ED, which focuses on local watermark embedding and extraction with enhanced robustness in small regions, enabling localized image protection. Built upon the classical Encoder- Distortion-Decoder training paradigm, MaskMark-D introduces a simple masking mechanism during the decoding stage to support both global and local watermark extraction. A mask is applied to the watermarked image before extraction, allowing the decoder to focus on selected regions and learn local extraction. A localization module is also integrated into the decoder to identify watermark regions during inference, reducing interference from irrelevant content and improving accuracy. MaskMark-ED extends this design by incorporating the mask into the encoding stage as well, guiding the encoder to embed the watermark in designated local regions for enhanced robustness. Comprehensive experiments show that MaskMark achieves state-of-the-art performance in global watermark extraction, local watermark extraction, watermark localization, and multi-watermark embedding. It outperforms all existing baselines, including the recent leading model WAM for local watermarking, while preserving high visual quality of the watermarked images. MaskMark is also flexible, by adjusting the distortion layer, it can adapt to different robustness requirements with just a few steps of fine-tuning. Moreover, our approach is efficient and easy to optimize, requiring only 20 hours on a single A6000 GPU with just 1/15 the computational cost of WAM.","authors":["Runyi Hu","Jie Zhang","Shiqian Zhao","Nils Lukas","Jiwei Li","Qing Guo","Han Qiu","Tianwei Zhang"],"url":"https://arxiv.org/abs/2504.12739"}
{"created":"2025-04-18","title":"GPMFS: Global Foundation and Personalized Optimization for Multi-Label Feature Selection","abstract":"As artificial intelligence methods are increasingly applied to complex task scenarios, high dimensional multi-label learning has emerged as a prominent research focus. At present, the curse of dimensionality remains one of the major bottlenecks in high-dimensional multi-label learning, which can be effectively addressed through multi-label feature selection methods. However, existing multi-label feature selection methods mostly focus on identifying global features shared across all labels, which overlooks personalized characteristics and specific requirements of individual labels. This global-only perspective may limit the ability to capture label-specific discriminative information, thereby affecting overall performance. In this paper, we propose a novel method called GPMFS (Global Foundation and Personalized Optimization for Multi-Label Feature Selection). GPMFS firstly identifies global features by exploiting label correlations, then adaptively supplements each label with a personalized subset of discriminative features using a threshold-controlled strategy. Experiments on multiple real-world datasets demonstrate that GPMFS achieves superior performance while maintaining strong interpretability and robustness. Furthermore, GPMFS provides insights into the label-specific strength across different multi-label datasets, thereby demonstrating the necessity and potential applicability of personalized feature selection approaches.","authors":["Yifan Cao","Zhilong Mi","Ziqiao Yin","Binghui Guo","Jin Dong"],"url":"https://arxiv.org/abs/2504.12740"}
{"created":"2025-04-18","title":"Decentralized Nonconvex Composite Federated Learning with Gradient Tracking and Momentum","abstract":"Decentralized Federated Learning (DFL) eliminates the reliance on the server-client architecture inherent in traditional federated learning, attracting significant research interest in recent years. Simultaneously, the objective functions in machine learning tasks are often nonconvex and frequently incorporate additional, potentially nonsmooth regularization terms to satisfy practical requirements, thereby forming nonconvex composite optimization problems. Employing DFL methods to solve such general optimization problems leads to the formulation of Decentralized Nonconvex Composite Federated Learning (DNCFL), a topic that remains largely underexplored. In this paper, we propose a novel DNCFL algorithm, termed \\bf{DEPOSITUM}. Built upon proximal stochastic gradient tracking, DEPOSITUM mitigates the impact of data heterogeneity by enabling clients to approximate the global gradient. The introduction of momentums in the proximal gradient descent step, replacing tracking variables, reduces the variance introduced by stochastic gradients. Additionally, DEPOSITUM supports local updates of client variables, significantly reducing communication costs. Theoretical analysis demonstrates that DEPOSITUM achieves an expected $\\epsilon$-stationary point with an iteration complexity of $\\mathcal{O}(1/\\epsilon^2)$. The proximal gradient, consensus errors, and gradient estimation errors decrease at a sublinear rate of $\\mathcal{O}(1/T)$. With appropriate parameter selection, the algorithm achieves network-independent linear speedup without requiring mega-batch sampling. Finally, we apply DEPOSITUM to the training of neural networks on real-world datasets, systematically examining the influence of various hyperparameters on its performance. Comparisons with other federated composite optimization algorithms validate the effectiveness of the proposed method.","authors":["Yuan Zhou","Xinli Shi","Xuelong Li","Jiachen Zhong","Guanghui Wen","Jinde Cao"],"url":"https://arxiv.org/abs/2504.12742"}
{"created":"2025-04-18","title":"Biasing the Driving Style of an Artificial Race Driver for Online Time-Optimal Maneuver Planning","abstract":"In this work, we present a novel approach to bias the driving style of an artificial race driver (ARD) for online time-optimal trajectory planning. Our method leverages a nonlinear model predictive control (MPC) framework that combines time minimization with exit speed maximization at the end of the planning horizon. We introduce a new MPC terminal cost formulation based on the trajectory planned in the previous MPC step, enabling ARD to adapt its driving style from early to late apex maneuvers in real-time. Our approach is computationally efficient, allowing for low replan times and long planning horizons. We validate our method through simulations, comparing the results against offline minimum-lap-time (MLT) optimal control and online minimum-time MPC solutions. The results demonstrate that our new terminal cost enables ARD to bias its driving style, and achieve online lap times close to the MLT solution and faster than the minimum-time MPC solution. Our approach paves the way for a better understanding of the reasons behind human drivers' choice of early or late apex maneuvers.","authors":["Sebastiano Taddei","Mattia Piccinini","Francesco Biral"],"url":"https://arxiv.org/abs/2504.12744"}
{"created":"2025-04-18","title":"Privacy Protection Against Personalized Text-to-Image Synthesis via Cross-image Consistency Constraints","abstract":"The rapid advancement of diffusion models and personalization techniques has made it possible to recreate individual portraits from just a few publicly available images. While such capabilities empower various creative applications, they also introduce serious privacy concerns, as adversaries can exploit them to generate highly realistic impersonations. To counter these threats, anti-personalization methods have been proposed, which add adversarial perturbations to published images to disrupt the training of personalization models. However, existing approaches largely overlook the intrinsic multi-image nature of personalization and instead adopt a naive strategy of applying perturbations independently, as commonly done in single-image settings. This neglects the opportunity to leverage inter-image relationships for stronger privacy protection. Therefore, we advocate for a group-level perspective on privacy protection against personalization. Specifically, we introduce Cross-image Anti-Personalization (CAP), a novel framework that enhances resistance to personalization by enforcing style consistency across perturbed images. Furthermore, we develop a dynamic ratio adjustment strategy that adaptively balances the impact of the consistency loss throughout the attack iterations. Extensive experiments on the classical CelebHQ and VGGFace2 benchmarks show that CAP substantially improves existing methods.","authors":["Guanyu Wang","Kailong Wang","Yihao Huang","Mingyi Zhou","Zhang Qing cnwatcher","Geguang Pu","Li Li"],"url":"https://arxiv.org/abs/2504.12747"}
{"created":"2025-04-18","title":"Attack-Defense Trees with Offensive and Defensive Attributes (with Appendix)","abstract":"Effective risk management in cybersecurity requires a thorough understanding of the interplay between attacker capabilities and defense strategies. Attack-Defense Trees (ADTs) are a commonly used methodology for representing this interplay; however, previous work in this domain has only focused on analyzing metrics such as cost, damage, or time from the perspective of the attacker. This approach provides an incomplete view of the system, as it neglects to model defender attributes: in real-world scenarios, defenders have finite resources for countermeasures and are similarly constrained. In this paper, we propose a novel framework that incorporates defense metrics into ADTs, and we present efficient algorithms for computing the Pareto front between defense and attack metrics. Our methods encode both attacker and defender metrics as semirings, allowing our methods to be used for many metrics such as cost, damage, and skill. We analyze tree-structured ADTs using a bottom-up approach and general ADTs by translating them into binary decision diagrams. Experiments on randomly generated ADTS demonstrate that both approaches effectively handle ADTs with several hundred nodes.","authors":["Danut-Valentin Copae","Reza Soltani","Milan Lopuha\\\"a-Zwakenberg"],"url":"https://arxiv.org/abs/2504.12748"}
{"created":"2025-04-18","title":"LAD-Reasoner: Tiny Multimodal Models are Good Reasoners for Logical Anomaly Detection","abstract":"Recent advances in industrial anomaly detection have highlighted the need for deeper logical anomaly analysis, where unexpected relationships among objects, counts, and spatial configurations must be identified and explained. Existing approaches often rely on large-scale external reasoning modules or elaborate pipeline designs, hindering practical deployment and interpretability. To address these limitations, we introduce a new task, Reasoning Logical Anomaly Detection (RLAD), which extends traditional anomaly detection by incorporating logical reasoning. We propose a new framework, LAD-Reasoner, a customized tiny multimodal language model built on Qwen2.5-VL 3B. Our approach leverages a two-stage training paradigm that first employs Supervised Fine-Tuning (SFT) for fine-grained visual understanding, followed by Group Relative Policy Optimization (GRPO) to refine logical anomaly detection and enforce coherent, human-readable reasoning. Crucially, reward signals are derived from both the detection accuracy and the structural quality of the outputs, obviating the need for building chain of thought (CoT) reasoning data. Experiments on the MVTec LOCO AD dataset show that LAD-Reasoner, though significantly smaller, matches the performance of Qwen2.5-VL-72B in accuracy and F1 score, and further excels in producing concise and interpretable rationales. This unified design reduces reliance on large models and complex pipelines, while offering transparent and interpretable insights into logical anomaly detection. Code and data will be released.","authors":["Weijia Li","Guanglei Chu","Jiong Chen","Guo-Sen Xie","Caifeng Shan","Fang Zhao"],"url":"https://arxiv.org/abs/2504.12749"}
{"created":"2025-04-18","title":"Stronger, Steadier & Superior: Geometric Consistency in Depth VFM Forges Domain Generalized Semantic Segmentation","abstract":"Vision Foundation Models (VFMs) have delivered remarkable performance in Domain Generalized Semantic Segmentation (DGSS). However, recent methods often overlook the fact that visual cues are susceptible, whereas the underlying geometry remains stable, rendering depth information more robust. In this paper, we investigate the potential of integrating depth information with features from VFMs, to improve the geometric consistency within an image and boost the generalization performance of VFMs. We propose a novel fine-tuning DGSS framework, named DepthForge, which integrates the visual cues from frozen DINOv2 or EVA02 and depth cues from frozen Depth Anything V2. In each layer of the VFMs, we incorporate depth-aware learnable tokens to continuously decouple domain-invariant visual and spatial information, thereby enhancing depth awareness and attention of the VFMs. Finally, we develop a depth refinement decoder and integrate it into the model architecture to adaptively refine multi-layer VFM features and depth-aware learnable tokens. Extensive experiments are conducted based on various DGSS settings and five different datsets as unseen target domains. The qualitative and quantitative results demonstrate that our method significantly outperforms alternative approaches with stronger performance, steadier visual-spatial attention, and superior generalization ability. In particular, DepthForge exhibits outstanding performance under extreme conditions (e.g., night and snow). Code is available at https://github.com/anonymouse-xzrptkvyqc/DepthForge.","authors":["Siyu Chen","Ting Han","Changshe Zhang","Xin Luo","Meiliu Wu","Guorong Cai","Jinhe Su"],"url":"https://arxiv.org/abs/2504.12753"}
{"created":"2025-04-18","title":"Trajectory Adaptation using Large Language Models","abstract":"Adapting robot trajectories based on human instructions as per new situations is essential for achieving more intuitive and scalable human-robot interactions. This work proposes a flexible language-based framework to adapt generic robotic trajectories produced by off-the-shelf motion planners like RRT, A-star, etc, or learned from human demonstrations. We utilize pre-trained LLMs to adapt trajectory waypoints by generating code as a policy for dense robot manipulation, enabling more complex and flexible instructions than current methods. This approach allows us to incorporate a broader range of commands, including numerical inputs. Compared to state-of-the-art feature-based sequence-to-sequence models which require training, our method does not require task-specific training and offers greater interpretability and more effective feedback mechanisms. We validate our approach through simulation experiments on the robotic manipulator, aerial vehicle, and ground robot in the Pybullet and Gazebo simulation environments, demonstrating that LLMs can successfully adapt trajectories to complex human instructions.","authors":["Anurag Maurya","Tashmoy Ghosh","Ravi Prakash"],"url":"https://arxiv.org/abs/2504.12755"}
{"created":"2025-04-18","title":"MCP Guardian: A Security-First Layer for Safeguarding MCP-Based AI System","abstract":"As Agentic AI gain mainstream adoption, the industry invests heavily in model capabilities, achieving rapid leaps in reasoning and quality. However, these systems remain largely confined to data silos, and each new integration requires custom logic that is difficult to scale. The Model Context Protocol (MCP) addresses this challenge by defining a universal, open standard for securely connecting AI-based applications (MCP clients) to data sources (MCP servers). However, the flexibility of the MCP introduces new risks, including malicious tool servers and compromised data integrity. We present MCP Guardian, a framework that strengthens MCP-based communication with authentication, rate-limiting, logging, tracing, and Web Application Firewall (WAF) scanning. Through real-world scenarios and empirical testing, we demonstrate how MCP Guardian effectively mitigates attacks and ensures robust oversight with minimal overheads. Our approach fosters secure, scalable data access for AI assistants, underscoring the importance of a defense-in-depth approach that enables safer and more transparent innovation in AI-driven environments.","authors":["Sonu Kumar","Anubhav Girdhar","Ritesh Patil","Divyansh Tripathi"],"url":"https://arxiv.org/abs/2504.12757"}
{"created":"2025-04-18","title":"GraphOmni: A Comprehensive and Extendable Benchmark Framework for Large Language Models on Graph-theoretic Tasks","abstract":"In this paper, we presented GraphOmni, a comprehensive benchmark framework for systematically evaluating the graph reasoning capabilities of LLMs. By analyzing critical dimensions, including graph types, serialization formats, and prompt schemes, we provided extensive insights into the strengths and limitations of current LLMs. Our empirical findings emphasize that no single serialization or prompting strategy consistently outperforms others. Motivated by these insights, we propose a reinforcement learning-based approach that dynamically selects the best serialization-prompt pairings, resulting in significant accuracy improvements. GraphOmni's modular and extensible design establishes a robust foundation for future research, facilitating advancements toward general-purpose graph reasoning models.","authors":["Hao Xu","Xiangru Jian","Xinjian Zhao","Wei Pang","Chao Zhang","Suyuchen Wang","Qixin Zhang","Joao Monteiro","Qiuzhuang Sun","Tianshu Yu"],"url":"https://arxiv.org/abs/2504.12764"}
{"created":"2025-04-18","title":"Falcon: Advancing Asynchronous BFT Consensus for Lower Latency and Enhanced Throughput","abstract":"Asynchronous Byzantine Fault Tolerant (BFT) consensus protocols have garnered significant attention with the rise of blockchain technology. A typical asynchronous protocol is designed by executing sequential instances of the Asynchronous Common Sub-seQuence (ACSQ). The ACSQ protocol consists of two primary components: the Asynchronous Common Subset (ACS) protocol and a block sorting mechanism, with the ACS protocol comprising two stages: broadcast and agreement. However, current protocols encounter three critical issues: high latency arising from the execution of the agreement stage, latency instability due to the integral-sorting mechanism, and reduced throughput caused by block discarding. To address these issues,we propose Falcon, an asynchronous BFT protocol that achieves low latency and enhanced throughput. Falcon introduces a novel broadcast protocol, Graded Broadcast (GBC), which enables a block to be included in the ACS set directly, bypassing the agreement stage and thereby reducing latency. To ensure safety, Falcon incorporates a new binary agreement protocol called Asymmetrical Asynchronous Binary Agreement (AABA), designed to complement GBC. Additionally, Falcon employs a partial-sorting mechanism, allowing continuous rather than simultaneous block committing, enhancing latency stability. Finally, we incorporate an agreement trigger that, before its activation, enables nodes to wait for more blocks to be delivered and committed, thereby boosting throughput. We conduct a series of experiments to evaluate Falcon, demonstrating its superior performance.","authors":["Xiaohai Dai","Chaozheng Ding","Wei Li","Jiang Xiao","Bolin Zhang","Chen Yu","Albert Y. Zomaya","Hai Jin"],"url":"https://arxiv.org/abs/2504.12766"}
{"created":"2025-04-18","title":"Out of Sight Out of Mind, Out of Sight Out of Mind: Measuring Bias in Language Models Against Overlooked Marginalized Groups in Regional Contexts","abstract":"We know that language models (LMs) form biases and stereotypes of minorities, leading to unfair treatments of members of these groups, thanks to research mainly in the US and the broader English-speaking world. As the negative behavior of these models has severe consequences for society and individuals, industry and academia are actively developing methods to reduce the bias in LMs. However, there are many under-represented groups and languages that have been overlooked so far. This includes marginalized groups that are specific to individual countries and regions in the English speaking and Western world, but crucially also almost all marginalized groups in the rest of the world. The UN estimates, that between 600 million to 1.2 billion people worldwide are members of marginalized groups and in need for special protection. If we want to develop inclusive LMs that work for everyone, we have to broaden our understanding to include overlooked marginalized groups and low-resource languages and dialects.","authors":["Fatma Elsafoury","David Hartmann"],"url":"https://arxiv.org/abs/2504.12767"}
{"created":"2025-04-18","title":"On Error Classification from Physiological Signals within Airborne Environment","abstract":"Human error remains a critical concern in aviation safety, contributing to 70-80% of accidents despite technological advancements. While physiological measures show promise for error detection in laboratory settings, their effectiveness in dynamic flight environments remains underexplored. Through live flight trials with nine commercial pilots, we investigated whether established error-detection approaches maintain accuracy during actual flight operations. Participants completed standardized multi-tasking scenarios across conditions ranging from laboratory settings to straight-and-level flight and 2G manoeuvres while we collected synchronized physiological data. Our findings demonstrate that EEG-based classification maintains high accuracy (87.83%) during complex flight manoeuvres, comparable to laboratory performance (89.23%). Eye-tracking showed moderate performance (82.50\\%), while ECG performed near chance level (51.50%). Classification accuracy remained stable across flight conditions, with minimal degradation during 2G manoeuvres. These results provide the first evidence that physiological error detection can translate effectively to operational aviation environments.","authors":["Niall McGuire","Yashar Moshfeghi"],"url":"https://arxiv.org/abs/2504.12769"}
{"created":"2025-04-18","title":"Comparative Analysis of POX and RYU SDN Controllers in Scalable Networks","abstract":"This paper explores the Quality of Service (QoS) performance of two widely used Software-Defined Networking (SDN) controllers, POX and Ryu, using Mininet for network simulation. SDN, a transformative approach to network architecture, separates the control and data planes, enabling centralized management, improved agility, and cost-effective solutions. The study evaluates key QoS parameters, including throughput, delay, and jitter, to understand the capabilities and limitations of the POX and Ryu controllers in handling traffic under diverse network topologies. The research employs a systematic methodology involving the design of custom network topologies, implementation of OpenFlow rules, and analysis of controller behavior under simulated conditions. Results reveal that while POX offers simplicity and ease of use, making it suitable for smaller-scale applications and experimentation, Ryu provides superior scalability and adaptability for more complex network environments. The findings highlight the strengths and challenges of each controller, providing valuable insights for organizations seeking to optimize SDN deployment. This study contributes to the growing body of knowledge on SDN technologies and their role in building scalable, efficient, and resilient network infrastructures.","authors":["Chandimal Jayawardena","Jay Chen","Amay Bhalla","Lin Bu"],"url":"https://arxiv.org/abs/2504.12770"}
{"created":"2025-04-18","title":"Enhancing the Geometric Problem-Solving Ability of Multimodal LLMs via Symbolic-Neural Integration","abstract":"Recent advances in Multimodal Large Language Models (MLLMs) have achieved remarkable progress in general domains and demonstrated promise in multimodal mathematical reasoning. However, applying MLLMs to geometry problem solving (GPS) remains challenging due to lack of accurate step-by-step solution data and severe hallucinations during reasoning. In this paper, we propose GeoGen, a pipeline that can automatically generates step-wise reasoning paths for geometry diagrams. By leveraging the precise symbolic reasoning, \\textbf{GeoGen} produces large-scale, high-quality question-answer pairs. To further enhance the logical reasoning ability of MLLMs, we train \\textbf{GeoLogic}, a Large Language Model (LLM) using synthetic data generated by GeoGen. Serving as a bridge between natural language and symbolic systems, GeoLogic enables symbolic tools to help verifying MLLM outputs, making the reasoning process more rigorous and alleviating hallucinations. Experimental results show that our approach consistently improves the performance of MLLMs, achieving remarkable results on benchmarks for geometric reasoning tasks. This improvement stems from our integration of the strengths of LLMs and symbolic systems, which enables a more reliable and interpretable approach for the GPS task. Codes are available at https://github.com/ycpNotFound/GeoGen.","authors":["Yicheng Pan","Zhenrong Zhang","Pengfei Hu","Jiefeng Ma","Jun Du","Jianshu Zhang","Quan Liu","Jianqing Gao","Feng Ma"],"url":"https://arxiv.org/abs/2504.12773"}
{"created":"2025-04-18","title":"StorySets: Ordering Curves and Dimensions for Visualizing Uncertain Sets and Multi-Dimensional Discrete Data","abstract":"We propose a method for visualizing uncertain set systems, which differs from previous set visualization approaches that are based on certainty (an element either belongs to a set or not). Our method is inspired by storyline visualizations and parallel coordinate plots: (a) each element is represented by a vertical glyph, subdivided into bins that represent different levels of uncertainty; (b) each set is represented by an x-monotone curve that traverses element glyphs through the bins representing the level of uncertainty of their membership. Our implementation also includes optimizations to reduce visual complexity captured by the number of turns for the set curves and the number of crossings. Although several of the natural underlying optimization problems are NP-hard in theory (e.g., optimal element order, optimal set order), in practice, we can compute near-optimal solutions with respect to curve crossings with the help of a new exact algorithm for optimally ordering set curves within each element's bins. With these optimizations, the proposed method makes it easy to see set containment (the smaller set's curve is strictly below the larger set's curve). A brief design-space exploration using uncertain set-membership data, as well as multi-dimensional discrete data, shows the flexibility of the proposed approach.","authors":["Markus Wallinger","Annika Bonerath","Wouter Meulemans","Martin N\\\"ollenburg","Spehen Kobourov","Alexander Wolff"],"url":"https://arxiv.org/abs/2504.12776"}
{"created":"2025-04-18","title":"Multi-Agent Reinforcement Learning Simulation for Environmental Policy Synthesis","abstract":"Climate policy development faces significant challenges due to deep uncertainty, complex system dynamics, and competing stakeholder interests. Climate simulation methods, such as Earth System Models, have become valuable tools for policy exploration. However, their typical use is for evaluating potential polices, rather than directly synthesizing them. The problem can be inverted to optimize for policy pathways, but the traditional optimization approaches often struggle with non-linear dynamics, heterogeneous agents, and comprehensive uncertainty quantification. We propose a framework for augmenting climate simulations with Multi-Agent Reinforcement Learning (MARL) to address these limitations. We identify key challenges at the interface between climate simulations and the application of MARL in the context of policy synthesis, including reward definition, scalability with increasing agents and state spaces, uncertainty propagation across linked systems, and solution validation. Additionally, we discuss challenges in making MARL-derived solutions interpretable and useful for policy-makers. Our framework provides a foundation for more sophisticated climate policy exploration while acknowledging important limitations and areas for future research.","authors":["James Rudd-Jones","Mirco Musolesi","Mar\\'ia P\\'erez-Ortiz"],"url":"https://arxiv.org/abs/2504.12777"}
{"created":"2025-04-18","title":"Towards Lossless Token Pruning in Late-Interaction Retrieval Models","abstract":"Late interaction neural IR models like ColBERT offer a competitive effectiveness-efficiency trade-off across many benchmarks. However, they require a huge memory space to store the contextual representation for all the document tokens. Some works have proposed using either heuristics or statistical-based techniques to prune tokens from each document. This however doesn't guarantee that the removed tokens have no impact on the retrieval score. Our work uses a principled approach to define how to prune tokens without impacting the score between a document and a query. We introduce three regularization losses, that induce a solution with high pruning ratios, as well as two pruning strategies. We study them experimentally (in and out-domain), showing that we can preserve ColBERT's performance while using only 30\\% of the tokens.","authors":["Yuxuan Zong","Benjamin Piwowarski"],"url":"https://arxiv.org/abs/2504.12778"}
{"created":"2025-04-18","title":"Set You Straight: Auto-Steering Denoising Trajectories to Sidestep Unwanted Concepts","abstract":"Ensuring the ethical deployment of text-to-image models requires effective techniques to prevent the generation of harmful or inappropriate content. While concept erasure methods offer a promising solution, existing finetuning-based approaches suffer from notable limitations. Anchor-free methods risk disrupting sampling trajectories, leading to visual artifacts, while anchor-based methods rely on the heuristic selection of anchor concepts. To overcome these shortcomings, we introduce a finetuning framework, dubbed ANT, which Automatically guides deNoising Trajectories to avoid unwanted concepts. ANT is built on a key insight: reversing the condition direction of classifier-free guidance during mid-to-late denoising stages enables precise content modification without sacrificing early-stage structural integrity. This inspires a trajectory-aware objective that preserves the integrity of the early-stage score function field, which steers samples toward the natural image manifold, without relying on heuristic anchor concept selection. For single-concept erasure, we propose an augmentation-enhanced weight saliency map to precisely identify the critical parameters that most significantly contribute to the unwanted concept, enabling more thorough and efficient erasure. For multi-concept erasure, our objective function offers a versatile plug-and-play solution that significantly boosts performance. Extensive experiments demonstrate that ANT achieves state-of-the-art results in both single and multi-concept erasure, delivering high-quality, safe outputs without compromising the generative fidelity. Code is available at https://github.com/lileyang1210/ANT","authors":["Leyang Li","Shilin Lu","Yan Ren","Adams Wai-Kin Kong"],"url":"https://arxiv.org/abs/2504.12782"}
{"created":"2025-04-18","title":"ARAP-GS: Drag-driven As-Rigid-As-Possible 3D Gaussian Splatting Editing with Diffusion Prior","abstract":"Drag-driven editing has become popular among designers for its ability to modify complex geometric structures through simple and intuitive manipulation, allowing users to adjust and reshape content with minimal technical skill. This drag operation has been incorporated into numerous methods to facilitate the editing of 2D images and 3D meshes in design. However, few studies have explored drag-driven editing for the widely-used 3D Gaussian Splatting (3DGS) representation, as deforming 3DGS while preserving shape coherence and visual continuity remains challenging. In this paper, we introduce ARAP-GS, a drag-driven 3DGS editing framework based on As-Rigid-As-Possible (ARAP) deformation. Unlike previous 3DGS editing methods, we are the first to apply ARAP deformation directly to 3D Gaussians, enabling flexible, drag-driven geometric transformations. To preserve scene appearance after deformation, we incorporate an advanced diffusion prior for image super-resolution within our iterative optimization process. This approach enhances visual quality while maintaining multi-view consistency in the edited results. Experiments show that ARAP-GS outperforms current methods across diverse 3D scenes, demonstrating its effectiveness and superiority for drag-driven 3DGS editing. Additionally, our method is highly efficient, requiring only 10 to 20 minutes to edit a scene on a single RTX 3090 GPU.","authors":["Xiao Han","Runze Tian","Yifei Tong","Fenggen Yu","Dingyao Liu","Yan Zhang"],"url":"https://arxiv.org/abs/2504.12788"}
{"created":"2025-04-18","title":"Empirically Evaluating the Use of Bytecode for Diversity-Based Test Case Prioritisation","abstract":"Regression testing assures software correctness after changes but is resource-intensive. Test Case Prioritisation (TCP) mitigates this by ordering tests to maximise early fault detection. Diversity-based TCP prioritises dissimilar tests, assuming they exercise different system parts and uncover more faults. Traditional static diversity-based TCP approaches (i.e., methods that utilise the dissimilarity of tests), like the state-of-the-art FAST approach, rely on textual diversity from test source code, which is effective but inefficient due to its relative verbosity and redundancies affecting similarity calculations. This paper is the first to study bytecode as the basis of diversity in TCP, leveraging its compactness for improved efficiency and accuracy. An empirical study on seven Defects4J projects shows that bytecode diversity improves fault detection by 2.3-7.8% over text-based TCP. It is also 2-3 orders of magnitude faster in one TCP approach and 2.5-6 times faster in FAST-based TCP. Filtering specific bytecode instructions improves efficiency up to fourfold while maintaining effectiveness, making bytecode diversity a superior static approach.","authors":["Islam T. Elgendy","Robert M. Hierons","Phil McMinn"],"url":"https://arxiv.org/abs/2504.12790"}
{"created":"2025-04-18","title":"EarthGPT-X: Enabling MLLMs to Flexibly and Comprehensively Understand Multi-Source Remote Sensing Imagery","abstract":"Recent advances in the visual-language area have developed natural multi-modal large language models (MLLMs) for spatial reasoning through visual prompting. However, due to remote sensing (RS) imagery containing abundant geospatial information that differs from natural images, it is challenging to effectively adapt natural spatial models to the RS domain. Moreover, current RS MLLMs are limited in overly narrow interpretation levels and interaction manner, hindering their applicability in real-world scenarios. To address those challenges, a spatial MLLM named EarthGPT-X is proposed, enabling a comprehensive understanding of multi-source RS imagery, such as optical, synthetic aperture radar (SAR), and infrared. EarthGPT-X offers zoom-in and zoom-out insight, and possesses flexible multi-grained interactive abilities. Moreover, EarthGPT-X unifies two types of critical spatial tasks (i.e., referring and grounding) into a visual prompting framework. To achieve these versatile capabilities, several key strategies are developed. The first is the multi-modal content integration method, which enhances the interplay between images, visual prompts, and text instructions. Subsequently, a cross-domain one-stage fusion training strategy is proposed, utilizing the large language model (LLM) as a unified interface for multi-source multi-task learning. Furthermore, by incorporating a pixel perception module, the referring and grounding tasks are seamlessly unified within a single framework. In addition, the experiments conducted demonstrate the superiority of the proposed EarthGPT-X in multi-grained tasks and its impressive flexibility in multi-modal interaction, revealing significant advancements of MLLM in the RS field.","authors":["Wei Zhang","Miaoxin Cai","Yaqian Ning","Tong Zhang","Yin Zhuang","He Chen","Jun Li","Xuerui Mao"],"url":"https://arxiv.org/abs/2504.12795"}
{"created":"2025-04-18","title":"A Survey on Cross-Modal Interaction Between Music and Multimodal Data","abstract":"Multimodal learning has driven innovation across various industries, particularly in the field of music. By enabling more intuitive interaction experiences and enhancing immersion, it not only lowers the entry barriers to the music but also increases its overall appeal. This survey aims to provide a comprehensive review of multimodal tasks related to music, outlining how music contributes to multimodal learning and offering insights for researchers seeking to expand the boundaries of computational music. Unlike text and images, which are often semantically or visually intuitive, music primarily interacts with humans through auditory perception, making its data representation inherently less intuitive. Therefore, this paper first introduces the representations of music and provides an overview of music datasets. Subsequently, we categorize cross-modal interactions between music and multimodal data into three types: music-driven cross-modal interactions, music-oriented cross-modal interactions, and bidirectional music cross-modal interactions. For each category, we systematically trace the development of relevant sub-tasks, analyze existing limitations, and discuss emerging trends. Furthermore, we provide a comprehensive summary of datasets and evaluation metrics used in multimodal tasks related to music, offering benchmark references for future research. Finally, we discuss the current challenges in cross-modal interactions involving music and propose potential directions for future research.","authors":["Sifei Li","Mining Tan","Feier Shen","Minyan Luo","Zijiao Yin","Fan Tang","Weiming Dong","Changsheng Xu"],"url":"https://arxiv.org/abs/2504.12796"}
{"created":"2025-04-18","title":"TSGS: Improving Gaussian Splatting for Transparent Surface Reconstruction via Normal and De-lighting Priors","abstract":"Reconstructing transparent surfaces is essential for tasks such as robotic manipulation in labs, yet it poses a significant challenge for 3D reconstruction techniques like 3D Gaussian Splatting (3DGS). These methods often encounter a transparency-depth dilemma, where the pursuit of photorealistic rendering through standard $\\alpha$-blending undermines geometric precision, resulting in considerable depth estimation errors for transparent materials. To address this issue, we introduce Transparent Surface Gaussian Splatting (TSGS), a new framework that separates geometry learning from appearance refinement. In the geometry learning stage, TSGS focuses on geometry by using specular-suppressed inputs to accurately represent surfaces. In the second stage, TSGS improves visual fidelity through anisotropic specular modeling, crucially maintaining the established opacity to ensure geometric accuracy. To enhance depth inference, TSGS employs a first-surface depth extraction method. This technique uses a sliding window over $\\alpha$-blending weights to pinpoint the most likely surface location and calculates a robust weighted average depth. To evaluate the transparent surface reconstruction task under realistic conditions, we collect a TransLab dataset that includes complex transparent laboratory glassware. Extensive experiments on TransLab show that TSGS achieves accurate geometric reconstruction and realistic rendering of transparent objects simultaneously within the efficient 3DGS framework. Specifically, TSGS significantly surpasses current leading methods, achieving a 37.3% reduction in chamfer distance and an 8.0% improvement in F1 score compared to the top baseline. The code and dataset will be released at https://longxiang-ai.github.io/TSGS/.","authors":["Mingwei Li","Pu Pang","Hehe Fan","Hua Huang","Yi Yang"],"url":"https://arxiv.org/abs/2504.12799"}
{"created":"2025-04-18","title":"CAGE-GS: High-fidelity Cage Based 3D Gaussian Splatting Deformation","abstract":"As 3D Gaussian Splatting (3DGS) gains popularity as a 3D representation of real scenes, enabling user-friendly deformation to create novel scenes while preserving fine details from the original 3DGS has attracted significant research attention. We introduce CAGE-GS, a cage-based 3DGS deformation method that seamlessly aligns a source 3DGS scene with a user-defined target shape. Our approach learns a deformation cage from the target, which guides the geometric transformation of the source scene. While the cages effectively control structural alignment, preserving the textural appearance of 3DGS remains challenging due to the complexity of covariance parameters. To address this, we employ a Jacobian matrix-based strategy to update the covariance parameters of each Gaussian, ensuring texture fidelity post-deformation. Our method is highly flexible, accommodating various target shape representations, including texts, images, point clouds, meshes and 3DGS models. Extensive experiments and ablation studies on both public datasets and newly proposed scenes demonstrate that our method significantly outperforms existing techniques in both efficiency and deformation quality.","authors":["Yifei Tong","Runze Tian","Xiao Han","Dingyao Liu","Fenggen Yu","Yan Zhang"],"url":"https://arxiv.org/abs/2504.12800"}
{"created":"2025-04-18","title":"Sign-In to the Lottery: Reparameterizing Sparse Training From Scratch","abstract":"The performance gap between training sparse neural networks from scratch (PaI) and dense-to-sparse training presents a major roadblock for efficient deep learning. According to the Lottery Ticket Hypothesis, PaI hinges on finding a problem specific parameter initialization. As we show, to this end, determining correct parameter signs is sufficient. Yet, they remain elusive to PaI. To address this issue, we propose Sign-In, which employs a dynamic reparameterization that provably induces sign flips. Such sign flips are complementary to the ones that dense-to-sparse training can accomplish, rendering Sign-In as an orthogonal method. While our experiments and theory suggest performance improvements of PaI, they also carve out the main open challenge to close the gap between PaI and dense-to-sparse training.","authors":["Advait Gadhikar","Tom Jacobs","Chao Zhou","Rebekka Burkholz"],"url":"https://arxiv.org/abs/2504.12801"}
{"created":"2025-04-18","title":"Enhancing Explainability and Reliable Decision-Making in Particle Swarm Optimization through Communication Topologies","abstract":"Swarm intelligence effectively optimizes complex systems across fields like engineering and healthcare, yet algorithm solutions often suffer from low reliability due to unclear configurations and hyperparameters. This study analyzes Particle Swarm Optimization (PSO), focusing on how different communication topologies Ring, Star, and Von Neumann affect convergence and search behaviors. Using an adapted IOHxplainer , an explainable benchmarking tool, we investigate how these topologies influence information flow, diversity, and convergence speed, clarifying the balance between exploration and exploitation. Through visualization and statistical analysis, the research enhances interpretability of PSO's decisions and provides practical guidelines for choosing suitable topologies for specific optimization tasks. Ultimately, this contributes to making swarm based optimization more transparent, robust, and trustworthy.","authors":["Nitin Gupta","Indu Bala","Bapi Dutta","Luis Mart\\'inez","Anupam Yadav"],"url":"https://arxiv.org/abs/2504.12803"}
{"created":"2025-04-18","title":"Assesing LLMs in Art Contexts: Critique Generation and Theory of Mind Evaluation","abstract":"This study explored how large language models (LLMs) perform in two areas related to art: writing critiques of artworks and reasoning about mental states (Theory of Mind, or ToM) in art-related situations. For the critique generation part, we built a system that combines Noel Carroll's evaluative framework with a broad selection of art criticism theories. The model was prompted to first write a full-length critique and then shorter, more coherent versions using a step-by-step prompting process. These AI-generated critiques were then compared with those written by human experts in a Turing test-style evaluation. In many cases, human subjects had difficulty telling which was which, and the results suggest that LLMs can produce critiques that are not only plausible in style but also rich in interpretation, as long as they are carefully guided. In the second part, we introduced new simple ToM tasks based on situations involving interpretation, emotion, and moral tension, which can appear in the context of art. These go beyond standard false-belief tests and allow for more complex, socially embedded forms of reasoning. We tested 41 recent LLMs and found that their performance varied across tasks and models. In particular, tasks that involved affective or ambiguous situations tended to reveal clearer differences. Taken together, these results help clarify how LLMs respond to complex interpretative challenges, revealing both their cognitive limitations and potential. While our findings do not directly contradict the so-called Generative AI Paradox--the idea that LLMs can produce expert-like output without genuine understanding--they suggest that, depending on how LLMs are instructed, such as through carefully designed prompts, these models may begin to show behaviors that resemble understanding more closely than we might assume.","authors":["Takaya Arita","Wenxian Zheng","Reiji Suzuki","Fuminori Akiba"],"url":"https://arxiv.org/abs/2504.12805"}
{"created":"2025-04-18","title":"A Numerical Gradient Inversion Attack in Variational Quantum Neural-Networks","abstract":"The loss landscape of Variational Quantum Neural Networks (VQNNs) is characterized by local minima that grow exponentially with increasing qubits. Because of this, it is more challenging to recover information from model gradients during training compared to classical Neural Networks (NNs). In this paper we present a numerical scheme that successfully reconstructs input training, real-world, practical data from trainable VQNNs' gradients. Our scheme is based on gradient inversion that works by combining gradients estimation with the finite difference method and adaptive low-pass filtering. The scheme is further optimized with Kalman filter to obtain efficient convergence. Our experiments show that our algorithm can invert even batch-trained data, given the VQNN model is sufficiently over-parameterized.","authors":["Georgios Papadopoulos","Shaltiel Eloul","Yash Satsangi","Jamie Heredge","Niraj Kumar","Chun-Fu Chen","Marco Pistoia"],"url":"https://arxiv.org/abs/2504.12806"}
{"created":"2025-04-18","title":"Hybrid Dense-UNet201 Optimization for Pap Smear Image Segmentation Using Spider Monkey Optimization","abstract":"Pap smear image segmentation is crucial for cervical cancer diagnosis. However, traditional segmentation models often struggle with complex cellular structures and variations in pap smear images. This study proposes a hybrid Dense-UNet201 optimization approach that integrates a pretrained DenseNet201 as the encoder for the U-Net architecture and optimizes it using the spider monkey optimization (SMO) algorithm. The Dense-UNet201 model excelled at feature extraction. The SMO was modified to handle categorical and discrete parameters. The SIPaKMeD dataset was used in this study and evaluated using key performance metrics, including loss, accuracy, Intersection over Union (IoU), and Dice coefficient. The experimental results showed that Dense-UNet201 outperformed U-Net, Res-UNet50, and Efficient-UNetB0. SMO Dense-UNet201 achieved a segmentation accuracy of 96.16%, an IoU of 91.63%, and a Dice coefficient score of 95.63%. These findings underscore the effectiveness of image preprocessing, pretrained models, and metaheuristic optimization in improving medical image analysis and provide new insights into cervical cell segmentation methods.","authors":["Ach Khozaimi","Isnani Darti","Syaiful Anam","Wuryansari Muharini Kusumawinahyu"],"url":"https://arxiv.org/abs/2504.12807"}
{"created":"2025-04-18","title":"Saliency-Aware Diffusion Reconstruction for Effective Invisible Watermark Removal","abstract":"As digital content becomes increasingly ubiquitous, the need for robust watermark removal techniques has grown due to the inadequacy of existing embedding techniques, which lack robustness. This paper introduces a novel Saliency-Aware Diffusion Reconstruction (SADRE) framework for watermark elimination on the web, combining adaptive noise injection, region-specific perturbations, and advanced diffusion-based reconstruction. SADRE disrupts embedded watermarks by injecting targeted noise into latent representations guided by saliency masks although preserving essential image features. A reverse diffusion process ensures high-fidelity image restoration, leveraging adaptive noise levels determined by watermark strength. Our framework is theoretically grounded with stability guarantees and achieves robust watermark removal across diverse scenarios. Empirical evaluations on state-of-the-art (SOTA) watermarking techniques demonstrate SADRE's superiority in balancing watermark disruption and image quality. SADRE sets a new benchmark for watermark elimination, offering a flexible and reliable solution for real-world web content. Code is available on~\\href{https://github.com/inzamamulDU/SADRE}{\\textbf{https://github.com/inzamamulDU/SADRE}}.","authors":["Inzamamul Alam","Md Tanvir Islam","Simon S. Woo"],"url":"https://arxiv.org/abs/2504.12809"}
{"created":"2025-04-18","title":"AAA-Gaussians: Anti-Aliased and Artifact-Free 3D Gaussian Rendering","abstract":"Although 3D Gaussian Splatting (3DGS) has revolutionized 3D reconstruction, it still faces challenges such as aliasing, projection artifacts, and view inconsistencies, primarily due to the simplification of treating splats as 2D entities. We argue that incorporating full 3D evaluation of Gaussians throughout the 3DGS pipeline can effectively address these issues while preserving rasterization efficiency. Specifically, we introduce an adaptive 3D smoothing filter to mitigate aliasing and present a stable view-space bounding method that eliminates popping artifacts when Gaussians extend beyond the view frustum. Furthermore, we promote tile-based culling to 3D with screen-space planes, accelerating rendering and reducing sorting costs for hierarchical rasterization. Our method achieves state-of-the-art quality on in-distribution evaluation sets and significantly outperforms other approaches for out-of-distribution views. Our qualitative evaluations further demonstrate the effective removal of aliasing, distortions, and popping artifacts, ensuring real-time, artifact-free rendering.","authors":["Michael Steiner","Thomas K\\\"ohler","Lukas Radl","Felix Windisch","Dieter Schmalstieg","Markus Steinberger"],"url":"https://arxiv.org/abs/2504.12811"}
{"created":"2025-04-18","title":"SoK: Security of EMV Contactless Payment Systems","abstract":"The widespread adoption of EMV (Europay, Mastercard, and Visa) contactless payment systems has greatly improved convenience for both users and merchants. However, this growth has also exposed significant security challenges. This SoK provides a comprehensive analysis of security vulnerabilities in EMV contactless payments, particularly within the open-loop systems used by Visa and Mastercard. We categorize attacks into seven attack vectors across three key areas: application selection, cardholder authentication, and transaction authorization. We replicate the attacks on Visa and Mastercard protocols using our experimental platform to determine their practical feasibility and offer insights into the current security landscape of contactless payments. Our study also includes a detailed evaluation of the underlying protocols, along with a comparative analysis of Visa and Mastercard, highlighting vulnerabilities and recommending countermeasures.","authors":["Mahshid Mehr Nezhad","Feng Hao","Gregory Epiphaniou","Carsten Maple","Timur Yunusov"],"url":"https://arxiv.org/abs/2504.12812"}
{"created":"2025-04-18","title":"Approaching Current Challenges in Developing a Software Stack for Fully Autonomous Driving","abstract":"Autonomous driving is a complex undertaking. A common approach is to break down the driving task into individual subtasks through modularization. These sub-modules are usually developed and published separately. However, if these individually developed algorithms have to be combined again to form a full-stack autonomous driving software, this poses particular challenges. Drawing upon our practical experience in developing the software of TUM Autonomous Motorsport, we have identified and derived these challenges in developing an autonomous driving software stack within a scientific environment. We do not focus on the specific challenges of individual algorithms but on the general difficulties that arise when deploying research algorithms on real-world test vehicles. To overcome these challenges, we introduce strategies that have been effective in our development approach. We additionally provide open-source implementations that enable these concepts on GitHub. As a result, this paper's contributions will simplify future full-stack autonomous driving projects, which are essential for a thorough evaluation of the individual algorithms.","authors":["Simon Sagmeister","Simon Hoffmann","Tobias Betz","Dominic Ebner","Daniel Esser","Markus Lienkamp"],"url":"https://arxiv.org/abs/2504.12813"}
{"created":"2025-04-18","title":"SMARTe: Slot-based Method for Accountable Relational Triple extraction","abstract":"Relational Triple Extraction (RTE) is a fundamental task in Natural Language Processing (NLP). However, prior research has primarily focused on optimizing model performance, with limited efforts to understand the internal mechanisms driving these models. Many existing methods rely on complex preprocessing to induce specific interactions, often resulting in opaque systems that may not fully align with their theoretical foundations. To address these limitations, we propose SMARTe: a Slot-based Method for Accountable Relational Triple extraction. SMARTe introduces intrinsic interpretability through a slot attention mechanism and frames the task as a set prediction problem. Slot attention consolidates relevant information into distinct slots, ensuring all predictions can be explicitly traced to learned slot representations and the tokens contributing to each predicted relational triple. While emphasizing interpretability, SMARTe achieves performance comparable to state-of-the-art models. Evaluations on the NYT and WebNLG datasets demonstrate that adding interpretability does not compromise performance. Furthermore, we conducted qualitative assessments to showcase the explanations provided by SMARTe, using attention heatmaps that map to their respective tokens. We conclude with a discussion of our findings and propose directions for future research.","authors":["Xue Wen Tan","Stanley Kok"],"url":"https://arxiv.org/abs/2504.12816"}
{"created":"2025-04-18","title":"Explainable Scene Understanding with Qualitative Representations and Graph Neural Networks","abstract":"This paper investigates the integration of graph neural networks (GNNs) with Qualitative Explainable Graphs (QXGs) for scene understanding in automated driving. Scene understanding is the basis for any further reactive or proactive decision-making. Scene understanding and related reasoning is inherently an explanation task: why is another traffic participant doing something, what or who caused their actions? While previous work demonstrated QXGs' effectiveness using shallow machine learning models, these approaches were limited to analysing single relation chains between object pairs, disregarding the broader scene context. We propose a novel GNN architecture that processes entire graph structures to identify relevant objects in traffic scenes. We evaluate our method on the nuScenes dataset enriched with DriveLM's human-annotated relevance labels. Experimental results show that our GNN-based approach achieves superior performance compared to baseline methods. The model effectively handles the inherent class imbalance in relevant object identification tasks while considering the complete spatial-temporal relationships between all objects in the scene. Our work demonstrates the potential of combining qualitative representations with deep learning approaches for explainable scene understanding in autonomous driving systems.","authors":["Nassim Belmecheri","Arnaud Gotlieb","Nadjib Lazaar","Helge Spieker"],"url":"https://arxiv.org/abs/2504.12817"}
{"created":"2025-04-18","title":"Trading Prophets: How to Trade Multiple Stocks Optimally","abstract":"In the single stock trading prophet problem formulated by Correa et al.\\ (2023), an online algorithm observes a sequence of prices of a stock. At each step, the algorithm can either buy the stock by paying the current price if it doesn't already hold the stock, or it can sell the currently held stock and collect the current price as a reward. The goal of the algorithm is to maximize its overall profit.","authors":["Surbhi Rajput","Ashish Chiplunkar","Rohit Vaish"],"url":"https://arxiv.org/abs/2504.12823"}
{"created":"2025-04-18","title":"Mixed Structural Choice Operator: Enhancing Technology Mapping with Heterogeneous Representations","abstract":"The independence of logic optimization and technology mapping poses a significant challenge in achieving high-quality synthesis results. Recent studies have improved optimization outcomes through collaborative optimization of multiple logic representations and have improved structural bias through structural choices. However, these methods still rely on technology-independent optimization and fail to truly resolve structural bias issues. This paper proposes a scalable and efficient framework based on Mixed Structural Choices (MCH). This is a novel heterogeneous mapping method that combines multiple logic representations with technology-aware optimization. MCH flexibly integrates different logic representations and stores candidates for various optimization strategies. By comprehensively evaluating the technology costs of these candidates, it enhances technology mapping and addresses structural bias issues in logic synthesis. Notably, the MCH-based lookup table (LUT) mapping algorithm set new records in the EPFL Best Results Challenge by combining the structural strengths of both And-Inverter Graph (AIG) and XOR-Majority Graph (XMG) logic representations. Additionally, MCH-based ASIC technology mapping achieves a 3.73% area and 8.94% delay reduction (balanced), 20.35% delay reduction (delay-oriented), and 21.02% area reduction (area-oriented), outperforming traditional structural choice methods. Furthermore, MCH-based logic optimization utilizes diverse structures to surpass local optima and achieve better results.","authors":["Zhang Hu","Hongyang Pan","Yinshui Xia","Lunyao Wang","Zhufei Chu"],"url":"https://arxiv.org/abs/2504.12824"}
{"created":"2025-04-18","title":"TwoSquared: 4D Generation from 2D Image Pairs","abstract":"Despite the astonishing progress in generative AI, 4D dynamic object generation remains an open challenge. With limited high-quality training data and heavy computing requirements, the combination of hallucinating unseen geometry together with unseen movement poses great challenges to generative models. In this work, we propose TwoSquared as a method to obtain a 4D physically plausible sequence starting from only two 2D RGB images corresponding to the beginning and end of the action. Instead of directly solving the 4D generation problem, TwoSquared decomposes the problem into two steps: 1) an image-to-3D module generation based on the existing generative model trained on high-quality 3D assets, and 2) a physically inspired deformation module to predict intermediate movements. To this end, our method does not require templates or object-class-specific prior knowledge and can take in-the-wild images as input. In our experiments, we demonstrate that TwoSquared is capable of producing texture-consistent and geometry-consistent 4D sequences only given 2D images.","authors":["Lu Sang","Zehranaz Canfes","Dongliang Cao","Riccardo Marin","Florian Bernard","Daniel Cremers"],"url":"https://arxiv.org/abs/2504.12825"}
{"created":"2025-04-18","title":"UncAD: Towards Safe End-to-end Autonomous Driving via Online Map Uncertainty","abstract":"End-to-end autonomous driving aims to produce planning trajectories from raw sensors directly. Currently, most approaches integrate perception, prediction, and planning modules into a fully differentiable network, promising great scalability. However, these methods typically rely on deterministic modeling of online maps in the perception module for guiding or constraining vehicle planning, which may incorporate erroneous perception information and further compromise planning safety. To address this issue, we delve into the importance of online map uncertainty for enhancing autonomous driving safety and propose a novel paradigm named UncAD. Specifically, UncAD first estimates the uncertainty of the online map in the perception module. It then leverages the uncertainty to guide motion prediction and planning modules to produce multi-modal trajectories. Finally, to achieve safer autonomous driving, UncAD proposes an uncertainty-collision-aware planning selection strategy according to the online map uncertainty to evaluate and select the best trajectory. In this study, we incorporate UncAD into various state-of-the-art (SOTA) end-to-end methods. Experiments on the nuScenes dataset show that integrating UncAD, with only a 1.9% increase in parameters, can reduce collision rates by up to 26% and drivable area conflict rate by up to 42%. Codes, pre-trained models, and demo videos can be accessed at https://github.com/pengxuanyang/UncAD.","authors":["Pengxuan Yang","Yupeng Zheng","Qichao Zhang","Kefei Zhu","Zebin Xing","Qiao Lin","Yun-Fu Liu","Zhiguo Su","Dongbin Zhao"],"url":"https://arxiv.org/abs/2504.12826"}
{"created":"2025-04-18","title":"Predicting Stock Prices using Permutation Decision Trees and Strategic Trailing","abstract":"In this paper, we explore the application of Permutation Decision Trees (PDT) and strategic trailing for predicting stock market movements and executing profitable trades in the Indian stock market. We focus on high-frequency data using 5-minute candlesticks for the top 50 stocks listed in the NIFTY 50 index. We implement a trading strategy that aims to buy stocks at lower prices and sell them at higher prices, capitalizing on short-term market fluctuations. Due to regulatory constraints in India, short selling is not considered in our strategy. The model incorporates various technical indicators and employs hyperparameters such as the trailing stop-loss value and support thresholds to manage risk effectively. Our results indicate that the proposed trading bot has the potential to outperform the market average and yield returns higher than the risk-free rate offered by 10-year Indian government bonds. We trained and tested data on a 60 day dataset provided by Yahoo Finance. Specifically, 12 days for testing and 48 days for training. Our bot based on permutation decision tree achieved a profit of 1.3468 % over a 12-day testing period, where as a bot based on LSTM gave a return of 0.1238 % over a 12-day testing period and a bot based on RNN gave a return of 0.3096 % over a 12-day testing period. All of the bots outperform the buy-and-hold strategy, which resulted in a loss of 2.2508 %.","authors":["Vishrut Ramraj","Nithin Nagaraj","Harikrishnan N B"],"url":"https://arxiv.org/abs/2504.12828"}
{"created":"2025-04-18","title":"Questions: A Taxonomy for Critical Reflection in Machine-Supported Decision-Making","abstract":"Decision-makers run the risk of relying too much on machine recommendations. Explainable AI, a common strategy for calibrating reliance, has mixed and even negative effects, such as increasing overreliance. To cognitively engage the decision-maker and to facilitate a deliberate decision-making process, we propose a potential `reflection machine' that supports critical reflection about the pending decision, including the machine recommendation. Reflection has been shown to improve critical thinking and reasoning, and thus decision-making. One way to stimulate reflection is to ask relevant questions. To systematically create questions, we present a question taxonomy inspired by Socratic questions and human-centred explainable AI. This taxonomy can contribute to the design of such a `reflection machine' that asks decision-makers questions. Our work is part of the growing research on human-machine collaborations that goes beyond the paradigm of machine recommendations and explanations, and aims to enable greater human oversight as required by the European AI Act.","authors":["Simon W. S. Fischer","Hanna Schraffenberger","Serge Thill","Pim Haselager"],"url":"https://arxiv.org/abs/2504.12830"}
{"created":"2025-04-18","title":"Image-Editing Specialists: An RLAIF Approach for Diffusion Models","abstract":"We present a novel approach to training specialized instruction-based image-editing diffusion models, addressing key challenges in structural preservation with input images and semantic alignment with user prompts. We introduce an online reinforcement learning framework that aligns the diffusion model with human preferences without relying on extensive human annotations or curating a large dataset. Our method significantly improves the realism and alignment with instructions in two ways. First, the proposed models achieve precise and structurally coherent modifications in complex scenes while maintaining high fidelity in instruction-irrelevant areas. Second, they capture fine nuances in the desired edit by leveraging a visual prompt, enabling detailed control over visual edits without lengthy textual prompts. This approach simplifies users' efforts to achieve highly specific edits, requiring only 5 reference images depicting a certain concept for training. Experimental results demonstrate that our models can perform intricate edits in complex scenes, after just 10 training steps. Finally, we showcase the versatility of our method by applying it to robotics, where enhancing the visual realism of simulated environments through targeted sim-to-real image edits improves their utility as proxies for real-world settings.","authors":["Elior Benarous","Yilun Du","Heng Yang"],"url":"https://arxiv.org/abs/2504.12833"}
{"created":"2025-04-18","title":"ALT: A Python Package for Lightweight Feature Representation in Time Series Classification","abstract":"We introduce ALT, an open-source Python package created for efficient and accurate time series classification (TSC). The package implements the adaptive law-based transformation (ALT) algorithm, which transforms raw time series data into a linearly separable feature space using variable-length shifted time windows. This adaptive approach enhances its predecessor, the linear law-based transformation (LLT), by effectively capturing patterns of varying temporal scales. The software is implemented for scalability, interpretability, and ease of use, achieving state-of-the-art performance with minimal computational overhead. Extensive benchmarking on real-world datasets demonstrates the utility of ALT for diverse TSC tasks in physics and related domains.","authors":["Bal\\'azs P. Halmos","Bal\\'azs Haj\\'os","Vince \\'A. Moln\\'ar","Marcell T. Kurbucz","Antal Jakov\\'ac"],"url":"https://arxiv.org/abs/2504.12841"}
{"created":"2025-04-18","title":"High-Fidelity Image Inpainting with Multimodal Guided GAN Inversion","abstract":"Generative Adversarial Network (GAN) inversion have demonstrated excellent performance in image inpainting that aims to restore lost or damaged image texture using its unmasked content. Previous GAN inversion-based methods usually utilize well-trained GAN models as effective priors to generate the realistic regions for missing holes. Despite excellence, they ignore a hard constraint that the unmasked regions in the input and the output should be the same, resulting in a gap between GAN inversion and image inpainting and thus degrading the performance. Besides, existing GAN inversion approaches often consider a single modality of the input image, neglecting other auxiliary cues in images for improvements. Addressing these problems, we propose a novel GAN inversion approach, dubbed MMInvertFill, for image inpainting. MMInvertFill contains primarily a multimodal guided encoder with a pre-modulation and a GAN generator with F&amp;W+ latent space. Specifically, the multimodal encoder aims to enhance the multi-scale structures with additional semantic segmentation edge texture modalities through a gated mask-aware attention module. Afterwards, a pre-modulation is presented to encode these structures into style vectors. To mitigate issues of conspicuous color discrepancy and semantic inconsistency, we introduce the F&amp;W+ latent space to bridge the gap between GAN inversion and image inpainting. Furthermore, in order to reconstruct faithful and photorealistic images, we devise a simple yet effective Soft-update Mean Latent module to capture more diversified in-domain patterns for generating high-fidelity textures for massive corruptions. In our extensive experiments on six challenging datasets, we show that our MMInvertFill qualitatively and quantitatively outperforms other state-of-the-arts and it supports the completion of out-of-domain images effectively.","authors":["Libo Zhang","Yongsheng Yu","Jiali Yao","Heng Fan"],"url":"https://arxiv.org/abs/2504.12844"}
{"created":"2025-04-18","title":"Can LLMs reason over extended multilingual contexts? Towards long-context evaluation beyond retrieval and haystacks","abstract":"Existing multilingual long-context benchmarks, often based on the popular needle-in-a-haystack test, primarily evaluate a model's ability to locate specific information buried within irrelevant texts. However, such a retrieval-centric approach is myopic and inherently limited, as successful recall alone does not indicate a model's capacity to reason over extended contexts. Moreover, these benchmarks are susceptible to data leakage, short-circuiting, and risk making the evaluation a priori identifiable. To address these limitations, we introduce MLRBench, a new synthetic benchmark for multilingual long-context reasoning. Unlike existing benchmarks, MLRBench goes beyond surface-level retrieval by including tasks that assess multi-hop inference, aggregation, and epistemic reasoning. Spanning seven languages, MLRBench is designed to be parallel, resistant to leakage, and scalable to arbitrary context lengths. Our extensive experiments with an open-weight large language model (LLM) reveal a pronounced gap between high- and low-resource languages, particularly for tasks requiring the model to aggregate multiple facts or predict the absence of information. We also find that, in multilingual settings, LLMs effectively utilize less than 30% of their claimed context length. Although off-the-shelf Retrieval Augmented Generation helps alleviate this to a certain extent, it does not solve the long-context problem. We open-source MLRBench to enable future research in improved evaluation and training of multilingual LLMs.","authors":["Amey Hengle","Prasoon Bajpai","Soham Dan","Tanmoy Chakraborty"],"url":"https://arxiv.org/abs/2504.12845"}
{"created":"2025-04-18","title":"FedX: Adaptive Model Decomposition and Quantization for IoT Federated Learning","abstract":"Federated Learning (FL) allows collaborative training among multiple devices without data sharing, thus enabling privacy-sensitive applications on mobile or Internet of Things (IoT) devices, such as mobile health and asset tracking. However, designing an FL system with good model utility that works with low computation/communication overhead on heterogeneous, resource-constrained mobile/IoT devices is challenging. To address this problem, this paper proposes FedX, a novel adaptive model decomposition and quantization FL system for IoT. To balance utility with resource constraints on IoT devices, FedX decomposes a global FL model into different sub-networks with adaptive numbers of quantized bits for different devices. The key idea is that a device with fewer resources receives a smaller sub-network for lower overhead but utilizes a larger number of quantized bits for higher model utility, and vice versa. The quantization operations in FedX are done at the server to reduce the computational load on devices. FedX iteratively minimizes the losses in the devices' local data and in the server's public data using quantized sub-networks under a regularization term, and thus it maximizes the benefits of combining FL with model quantization through knowledge sharing among the server and devices in a cost-effective training process. Extensive experiments show that FedX significantly improves quantization times by up to 8.43X, on-device computation time by 1.5X, and total end-to-end training time by 1.36X, compared with baseline FL systems. We guarantee the global model convergence theoretically and validate local model convergence empirically, highlighting FedX's optimization efficiency.","authors":["Phung Lai","Xiaopeng Jiang","Hai Phan","Cristian Borcea","Khang Tran","An Chen","Vijaya Datta Mayyuri","Ruoming Jin"],"url":"https://arxiv.org/abs/2504.12849"}
{"created":"2025-04-18","title":"iHHO-SMOTe: A Cleansed Approach for Handling Outliers and Reducing Noise to Improve Imbalanced Data Classification","abstract":"Classifying imbalanced datasets remains a significant challenge in machine learning, particularly with big data where instances are unevenly distributed among classes, leading to class imbalance issues that impact classifier performance. While Synthetic Minority Over-sampling Technique (SMOTE) addresses this challenge by generating new instances for the under-represented minority class, it faces obstacles in the form of noise and outliers during the creation of new samples. In this paper, a proposed approach, iHHO-SMOTe, which addresses the limitations of SMOTE by first cleansing the data from noise points. This process involves employing feature selection using a random forest to identify the most valuable features, followed by applying the Density-Based Spatial Clustering of Applications with Noise (DBSCAN) algorithm to detect outliers based on the selected features. The identified outliers from the minority classes are then removed, creating a refined dataset for subsequent oversampling using the hybrid approach called iHHO-SMOTe. The comprehensive experiments across diverse datasets demonstrate the exceptional performance of the proposed model, with an AUC score exceeding 0.99, a high G-means score of 0.99 highlighting its robustness, and an outstanding F1-score consistently exceeding 0.967. These findings collectively establish Cleansed iHHO-SMOTe as a formidable contender in addressing imbalanced datasets, focusing on noise reduction and outlier handling for improved classification models.","authors":["Khaled SH. Raslan","Almohammady S. Alsharkawy","K. R. Raslan"],"url":"https://arxiv.org/abs/2504.12850"}
{"created":"2025-04-18","title":"Versatile, Robust, and Explosive Locomotion with Rigid and Articulated Compliant Quadrupeds","abstract":"Achieving versatile and explosive motion with robustness against dynamic uncertainties is a challenging task. Introducing parallel compliance in quadrupedal design is deemed to enhance locomotion performance, which, however, makes the control task even harder. This work aims to address this challenge by proposing a general template model and establishing an efficient motion planning and control pipeline. To start, we propose a reduced-order template model-the dual-legged actuated spring-loaded inverted pendulum with trunk rotation-which explicitly models parallel compliance by decoupling spring effects from active motor actuation. With this template model, versatile acrobatic motions, such as pronking, froggy jumping, and hop-turn, are generated by a dual-layer trajectory optimization, where the singularity-free body rotation representation is taken into consideration. Integrated with a linear singularity-free tracking controller, enhanced quadrupedal locomotion is achieved. Comparisons with the existing template model reveal the improved accuracy and generalization of our model. Hardware experiments with a rigid quadruped and a newly designed compliant quadruped demonstrate that i) the template model enables generating versatile dynamic motion; ii) parallel elasticity enhances explosive motion. For example, the maximal pronking distance, hop-turn yaw angle, and froggy jumping distance increase at least by 25%, 15% and 25%, respectively; iii) parallel elasticity improves the robustness against dynamic uncertainties, including modelling errors and external disturbances. For example, the allowable support surface height variation increases by 100% for robust froggy jumping.","authors":["Jiatao Ding","Peiyu Yang","Fabio Boekel","Jens Kober","Wei Pan","Matteo Saveriano","Cosimo Della Santina"],"url":"https://arxiv.org/abs/2504.12854"}
{"created":"2025-04-18","title":"3D-PNAS: 3D Industrial Surface Anomaly Synthesis with Perlin Noise","abstract":"Large pretrained vision foundation models have shown significant potential in various vision tasks. However, for industrial anomaly detection, the scarcity of real defect samples poses a critical challenge in leveraging these models. While 2D anomaly generation has significantly advanced with established generative models, the adoption of 3D sensors in industrial manufacturing has made leveraging 3D data for surface quality inspection an emerging trend. In contrast to 2D techniques, 3D anomaly generation remains largely unexplored, limiting the potential of 3D data in industrial quality inspection. To address this gap, we propose a novel yet simple 3D anomaly generation method, 3D-PNAS, based on Perlin noise and surface parameterization. Our method generates realistic 3D surface anomalies by projecting the point cloud onto a 2D plane, sampling multi-scale noise values from a Perlin noise field, and perturbing the point cloud along its normal direction. Through comprehensive visualization experiments, we demonstrate how key parameters - including noise scale, perturbation strength, and octaves, provide fine-grained control over the generated anomalies, enabling the creation of diverse defect patterns from pronounced deformations to subtle surface variations. Additionally, our cross-category experiments show that the method produces consistent yet geometrically plausible anomalies across different object types, adapting to their specific surface characteristics. We also provide a comprehensive codebase and visualization toolkit to facilitate future research.","authors":["Yifeng Cheng","Juan Du"],"url":"https://arxiv.org/abs/2504.12856"}
{"created":"2025-04-18","title":"Enhancing Decentralization in Blockchain Decision-Making Through Quadratic Voting and Its Generalization","abstract":"This study explores the application of Quadratic Voting (QV) and its generalization to improve decentralization and effectiveness in blockchain governance systems. The conducted research identified three main types of quadratic (square root) voting. Two of them pertain to voting with a split stake, and one involves voting without splitting. In split stakes, Type 1 QV applies the square root to the total stake before distributing it among preferences, while Type 2 QV distributes the stake first and then applies the square root. In unsplit stakes (Type 3 QV), the square root of the total stake is allocated entirely to each preference. The presented formal proofs confirm that Types 2 and 3 QV, along with generalized models, enhance decentralization as measured by the Gini and Nakamoto coefficients. A pivotal discovery is the existence of a threshold stakeholder whose relative voting ratio increases under QV compared to linear voting, while smaller stakeholders also gain influence. The generalized QV model allows flexible adjustment of this threshold, enabling tailored decentralization levels. Maintaining fairness, QV ensures that stakeholders with higher stakes retain a proportionally greater voting ratio while redistributing influence to prevent excessive concentration. It is shown that to preserve fairness and robustness, QV must be implemented alongside privacy-preserving cryptographic voting protocols, as voters casting their ballots last could otherwise manipulate outcomes. The generalized QV model, proposed in this paper, enables algorithmic parametrization to achieve desired levels of decentralization for specific use cases. This flexibility makes it applicable across diverse domains, including user interaction with cryptocurrency platforms, facilitating community events and educational initiatives, and supporting charitable activities through decentralized decision-making.","authors":["Lyudmila Kovalchuk","Mariia Rodinko","Roman Oliynykov","Andrii Nastenko","Dmytro Kaidalov","Kenric Nelson"],"url":"https://arxiv.org/abs/2504.12859"}
{"created":"2025-04-18","title":"DashChat: Interactive Authoring of Industrial Dashboard Design Prototypes through Conversation with LLM-Powered Agents","abstract":"Industrial dashboards, commonly deployed by organizations such as enterprises and governments, are increasingly crucial in data communication and decision-making support across various domains. Designing an industrial dashboard prototype is particularly challenging due to its visual complexity, which can include data visualization, layout configuration, embellishments, and animations. Additionally, in real-world industrial settings, designers often encounter numerous constraints. For instance, when companies negotiate collaborations with clients and determine design plans, they typically need to demo design prototypes and iterate on them based on mock data quickly. Such a task is very common and crucial during the ideation stage, as it not only helps save developmental costs but also avoids data-related issues such as lengthy data handover periods. However, existing authoring tools of dashboards are mostly not tailored to such prototyping needs, and motivated by these gaps, we propose DashChat, an interactive system that leverages large language models (LLMs) to generate industrial dashboard design prototypes from natural language. We collaborated closely with designers from the industry and derived the requirements based on their practical experience. First, by analyzing 114 high-quality industrial dashboards, we summarized their common design patterns and inject the identified ones into LLMs as reference. Next, we built a multi-agent pipeline powered by LLMs to understand textual requirements from users and generate practical, aesthetic prototypes. Besides, functionally distinct, parallel-operating agents are created to enable efficient generation. Then, we developed a user-friendly interface that supports text-based interaction for generating and modifying prototypes. Two user studies demonstrated that our system is both effective and efficient in supporting design prototyping.","authors":["S. Shen","Z. Lin","W. Liu","C. Xin","W. Dai","S. Chen","X. Wen","X. Lan"],"url":"https://arxiv.org/abs/2504.12865"}
{"created":"2025-04-18","title":"Computer-Aided Design of Personalized Occlusal Positioning Splints Using Multimodal 3D Data","abstract":"Contemporary digital technology has a pivotal role in the design of customized medical appliances, including occlusal splints used in the treatment of stomatognathic system dysfunctions. We present an approach to computer-aided design and precision assessment of positioning occlusal splints, bridging clinical concepts with current digital dental practice. In our model, a 3D splint is generated based on a transformation matrix that represents the therapeutic change in mandibular position, defined by a specialist using a virtual patient model reconstructed from intraoral scans, CBCT, 3D facial scans and plaster model digitisation. The paper introduces a novel method for generating splints that accurately reproduce occlusal conditions in the therapeutic position, including a mechanism for resolving surface conflicts through virtual embossing. We demonstrate how transformation matrices can be acquired through clinical tools and intraoral devices, and evaluate the accuracy of the designed and printed splints using profile and surface deviation analysis. The proposed method enables reproducible, patient-specific splint fabrication and opens new possibilities in diagnostics, multimodal image registration and quantification of occlusal discrepancies.","authors":["Agnieszka Anna Tomaka","Leszek Luchowski","Micha{\\l} Tarnawski","Dariusz Pojda"],"url":"https://arxiv.org/abs/2504.12868"}
{"created":"2025-04-18","title":"SC3EF: A Joint Self-Correlation and Cross-Correspondence Estimation Framework for Visible and Thermal Image Registration","abstract":"Multispectral imaging plays a critical role in a range of intelligent transportation applications, including advanced driver assistance systems (ADAS), traffic monitoring, and night vision. However, accurate visible and thermal (RGB-T) image registration poses a significant challenge due to the considerable modality differences. In this paper, we present a novel joint Self-Correlation and Cross-Correspondence Estimation Framework (SC3EF), leveraging both local representative features and global contextual cues to effectively generate RGB-T correspondences. For this purpose, we design a convolution-transformer-based pipeline to extract local representative features and encode global correlations of intra-modality for inter-modality correspondence estimation between unaligned visible and thermal images. After merging the local and global correspondence estimation results, we further employ a hierarchical optical flow estimation decoder to progressively refine the estimated dense correspondence maps. Extensive experiments demonstrate the effectiveness of our proposed method, outperforming the current state-of-the-art (SOTA) methods on representative RGB-T datasets. Furthermore, it also shows competitive generalization capabilities across challenging scenarios, including large parallax, severe occlusions, adverse weather, and other cross-modal datasets (e.g., RGB-N and RGB-D).","authors":["Xi Tong","Xing Luo","Jiangxin Yang","Yanpeng Cao"],"url":"https://arxiv.org/abs/2504.12869"}
{"created":"2025-04-18","title":"A Client-level Assessment of Collaborative Backdoor Poisoning in Non-IID Federated Learning","abstract":"Federated learning (FL) enables collaborative model training using decentralized private data from multiple clients. While FL has shown robustness against poisoning attacks with basic defenses, our research reveals new vulnerabilities stemming from non-independent and identically distributed (non-IID) data among clients. These vulnerabilities pose a substantial risk of model poisoning in real-world FL scenarios.","authors":["Phung Lai","Guanxiong Liu","Hai Phan","Issa Khalil","Abdallah Khreishah","Xintao Wu"],"url":"https://arxiv.org/abs/2504.12875"}
{"created":"2025-04-18","title":"Market-Driven Flexibility Provision: A Tri-Level Optimization Approach for Carbon Reduction","abstract":"The integration of renewable energy resources (RES) in the power grid can reduce carbon intensity, but also presents certain challenges. The uncertainty and intermittent nature of RES emphasize the need for flexibility in power systems. Moreover, there are noticeable mismatches between real-time electricity prices and carbon intensity patterns throughout the day. These discrepancies may lead customers to schedule energy-intensive tasks during the early hours of the day, a period characterized by lower electricity prices but higher carbon intensity. This paper introduces a novel and comprehensive framework aimed at encouraging customer participation in electricity markets and aligning their flexibility with carbon intensity trends. The proposed approach integrates an incentive-based tariff with a tri-level optimization model, where customers are motivated to submit flexibility bids and, in return, receive financial rewards based on their contributions. The tri-level model ensures a dynamic interaction between the market operation platform (MOP) and end-users. Simulations are performed on a modified IEEE-33 bus system, supported by two scenarios with different RES generations and customer behaviors. Results demonstrate the effectiveness of the proposed framework in guiding the customers' consumption behaviors towards low carbon intensity.","authors":["Shijie Pan","Gerrit Rolofs","Luca Pontecorvi","Charalambos Konstantinou"],"url":"https://arxiv.org/abs/2504.12877"}
{"created":"2025-04-18","title":"Building Russian Benchmark for Evaluation of Information Retrieval Models","abstract":"We introduce RusBEIR, a comprehensive benchmark designed for zero-shot evaluation of information retrieval (IR) models in the Russian language. Comprising 17 datasets from various domains, it integrates adapted, translated, and newly created datasets, enabling systematic comparison of lexical and neural models. Our study highlights the importance of preprocessing for lexical models in morphologically rich languages and confirms BM25 as a strong baseline for full-document retrieval. Neural models, such as mE5-large and BGE-M3, demonstrate superior performance on most datasets, but face challenges with long-document retrieval due to input size constraints. RusBEIR offers a unified, open-source framework that promotes research in Russian-language information retrieval.","authors":["Grigory Kovalev","Mikhail Tikhomirov","Evgeny Kozhevnikov","Max Kornilov","Natalia Loukachevitch"],"url":"https://arxiv.org/abs/2504.12879"}
{"created":"2025-04-18","title":"Can Masked Autoencoders Also Listen to Birds?","abstract":"Masked Autoencoders (MAEs) pretrained on AudioSet fail to capture the fine-grained acoustic characteristics of specialized domains such as bioacoustic monitoring. Bird sound classification is critical for assessing environmental health, yet general-purpose models inadequately address its unique acoustic challenges. To address this, we introduce Bird-MAE, a domain-specialized MAE pretrained on the large-scale BirdSet dataset. We explore adjustments to pretraining, fine-tuning and utilizing frozen representations. Bird-MAE achieves state-of-the-art results across all BirdSet downstream tasks, substantially improving multi-label classification performance compared to the general-purpose Audio-MAE baseline. Additionally, we propose prototypical probing, a parameter-efficient method for leveraging MAEs' frozen representations. Bird-MAE's prototypical probes outperform linear probing by up to 37\\% in MAP and narrow the gap to fine-tuning to approximately 3\\% on average on BirdSet.","authors":["Lukas Rauch","Ilyass Moummad","Ren\\'e Heinrich","Alexis Joly","Bernhard Sick","Christoph Scholz"],"url":"https://arxiv.org/abs/2504.12880"}
{"created":"2025-04-18","title":"ViClaim: A Multilingual Multilabel Dataset for Automatic Claim Detection in Videos","abstract":"The growing influence of video content as a medium for communication and misinformation underscores the urgent need for effective tools to analyze claims in multilingual and multi-topic settings. Existing efforts in misinformation detection largely focus on written text, leaving a significant gap in addressing the complexity of spoken text in video transcripts. We introduce ViClaim, a dataset of 1,798 annotated video transcripts across three languages (English, German, Spanish) and six topics. Each sentence in the transcripts is labeled with three claim-related categories: fact-check-worthy, fact-non-check-worthy, or opinion. We developed a custom annotation tool to facilitate the highly complex annotation process. Experiments with state-of-the-art multilingual language models demonstrate strong performance in cross-validation (macro F1 up to 0.896) but reveal challenges in generalization to unseen topics, particularly for distinct domains. Our findings highlight the complexity of claim detection in video transcripts. ViClaim offers a robust foundation for advancing misinformation detection in video-based communication, addressing a critical gap in multimodal analysis.","authors":["Patrick Giedemann","Pius von D\\\"aniken","Jan Deriu","Alvaro Rodrigo","Anselmo Pe\\~nas","Mark Cieliebak"],"url":"https://arxiv.org/abs/2504.12882"}
{"created":"2025-04-18","title":"Mirror, Mirror of the Flow: How Does Regularization Shape Implicit Bias?","abstract":"Implicit bias plays an important role in explaining how overparameterized models generalize well. Explicit regularization like weight decay is often employed in addition to prevent overfitting. While both concepts have been studied separately, in practice, they often act in tandem. Understanding their interplay is key to controlling the shape and strength of implicit bias, as it can be modified by explicit regularization. To this end, we incorporate explicit regularization into the mirror flow framework and analyze its lasting effects on the geometry of the training dynamics, covering three distinct effects: positional bias, type of bias, and range shrinking. Our analytical approach encompasses a broad class of problems, including sparse coding, matrix sensing, single-layer attention, and LoRA, for which we demonstrate the utility of our insights. To exploit the lasting effect of regularization and highlight the potential benefit of dynamic weight decay schedules, we propose to switch off weight decay during training, which can improve generalization, as we demonstrate in experiments.","authors":["Tom Jacobs","Chao Zhou","Rebekka Burkholz"],"url":"https://arxiv.org/abs/2504.12883"}
{"created":"2025-04-18","title":"Optimizing Movable Antennas in Wideband Multi-User MIMO With Hardware Impairments","abstract":"Movable antennas represent an emerging field in telecommunication research and a potential approach to achieving higher data rates in multiple-input multiple-output (MIMO) communications when the total number of antennas is limited. Most solutions and analyses to date have been limited to \\emph{narrowband} setups. This work complements the prior studies by quantifying the benefit of using movable antennas in \\emph{wideband} MIMO communication systems. First, we derive a novel uplink wideband system model that also accounts for distortion from transceiver hardware impairments. We then formulate and solve an optimization task to maximize the average sum rate by adjusting the antenna positions using particle swarm optimization. Finally, the performance with movable antennas is compared with fixed uniform arrays and the derived theoretical upper bound. The numerical study concludes that the data rate improvement from movable antennas over other arrays heavily depends on the level of hardware impairments, the richness of the multi-path environments, and the number of subcarriers. The present study provides vital insights into the most suitable use cases for movable antennas in future wideband systems.","authors":["Amna Irshad","Emil Bj\\\"ornson","Alva Kosasih","Vitaly Petrov"],"url":"https://arxiv.org/abs/2504.12885"}
{"created":"2025-04-18","title":"Are AI agents the new machine translation frontier? Challenges and opportunities of single- and multi-agent systems for multilingual digital communication","abstract":"The rapid evolution of artificial intelligence (AI) has introduced AI agents as a disruptive paradigm across various industries, yet their application in machine translation (MT) remains underexplored. This paper describes and analyses the potential of single- and multi-agent systems for MT, reflecting on how they could enhance multilingual digital communication. While single-agent systems are well-suited for simpler translation tasks, multi-agent systems, which involve multiple specialized AI agents collaborating in a structured manner, may offer a promising solution for complex scenarios requiring high accuracy, domain-specific knowledge, and contextual awareness. To demonstrate the feasibility of multi-agent workflows in MT, we are conducting a pilot study in legal MT. The study employs a multi-agent system involving four specialized AI agents for (i) translation, (ii) adequacy review, (iii) fluency review, and (iv) final editing. Our findings suggest that multi-agent systems may have the potential to significantly improve domain-adaptability and contextual awareness, with superior translation quality to traditional MT or single-agent systems. This paper also sets the stage for future research into multi-agent applications in MT, integration into professional translation workflows, and shares a demo of the system analyzed in the paper.","authors":["Vicent Briva-Iglesias"],"url":"https://arxiv.org/abs/2504.12891"}
{"created":"2025-04-18","title":"Manifold-valued function approximation from multiple tangent spaces","abstract":"Approximating a manifold-valued function from samples of input-output pairs consists of modeling the relationship between an input from a vector space and an output on a Riemannian manifold. We propose a function approximation method that leverages and unifies two prior techniques: (i) approximating a pullback to the tangent space, and (ii) the Riemannian moving least squares method. The core idea of the new scheme is to combine pullbacks to multiple tangent spaces with a weighted Fr\\'echet mean. The effectiveness of this approach is illustrated with numerical experiments on model problems from parametric model order reduction.","authors":["Hang Wang","Raf Vandebril","Joeri Van der Veken","Nick Vannieuwenhoven"],"url":"https://arxiv.org/abs/2504.12892"}
{"created":"2025-04-18","title":"Information Gain-Guided Causal Intervention for Autonomous Debiasing Large Language Models","abstract":"Despite significant progress, recent studies indicate that current large language models (LLMs) may still capture dataset biases and utilize them during inference, leading to the poor generalizability of LLMs. However, due to the diversity of dataset biases and the insufficient nature of bias suppression based on in-context learning, the effectiveness of previous prior knowledge-based debiasing methods and in-context learning based automatic debiasing methods is limited. To address these challenges, we explore the combination of causal mechanisms with information theory and propose an information gain-guided causal intervention debiasing (IGCIDB) framework. This framework first utilizes an information gain-guided causal intervention method to automatically and autonomously balance the distribution of instruction-tuning dataset. Subsequently, it employs a standard supervised fine-tuning process to train LLMs on the debiased dataset. Experimental results show that IGCIDB can effectively debias LLM to improve its generalizability across different tasks.","authors":["Zhouhao Sun","Xiao Ding","Li Du","Yunpeng Xu","Yixuan Ma","Yang Zhao","Bing Qin","Ting Liu"],"url":"https://arxiv.org/abs/2504.12898"}
{"created":"2025-04-18","title":"Tree-NeRV: A Tree-Structured Neural Representation for Efficient Non-Uniform Video Encoding","abstract":"Implicit Neural Representations for Videos (NeRV) have emerged as a powerful paradigm for video representation, enabling direct mappings from frame indices to video frames. However, existing NeRV-based methods do not fully exploit temporal redundancy, as they rely on uniform sampling along the temporal axis, leading to suboptimal rate-distortion (RD) performance. To address this limitation, we propose Tree-NeRV, a novel tree-structured feature representation for efficient and adaptive video encoding. Unlike conventional approaches, Tree-NeRV organizes feature representations within a Binary Search Tree (BST), enabling non-uniform sampling along the temporal axis. Additionally, we introduce an optimization-driven sampling strategy, dynamically allocating higher sampling density to regions with greater temporal variation. Extensive experiments demonstrate that Tree-NeRV achieves superior compression efficiency and reconstruction quality, outperforming prior uniform sampling-based methods. Code will be released.","authors":["Jiancheng Zhao","Yifan Zhan","Qingtian Zhu","Mingze Ma","Muyao Niu","Zunian Wan","Xiang Ji","Yinqiang Zheng"],"url":"https://arxiv.org/abs/2504.12899"}
{"created":"2025-04-18","title":"FashionDPO:Fine-tune Fashion Outfit Generation Model using Direct Preference Optimization","abstract":"Personalized outfit generation aims to construct a set of compatible and personalized fashion items as an outfit. Recently, generative AI models have received widespread attention, as they can generate fashion items for users to complete an incomplete outfit or create a complete outfit. However, they have limitations in terms of lacking diversity and relying on the supervised learning paradigm. Recognizing this gap, we propose a novel framework FashionDPO, which fine-tunes the fashion outfit generation model using direct preference optimization. This framework aims to provide a general fine-tuning approach to fashion generative models, refining a pre-trained fashion outfit generation model using automatically generated feedback, without the need to design a task-specific reward function. To make sure that the feedback is comprehensive and objective, we design a multi-expert feedback generation module which covers three evaluation perspectives, \\ie quality, compatibility and personalization. Experiments on two established datasets, \\ie iFashion and Polyvore-U, demonstrate the effectiveness of our framework in enhancing the model's ability to align with users' personalized preferences while adhering to fashion compatibility principles. Our code and model checkpoints are available at https://github.com/Yzcreator/FashionDPO.","authors":["Mingzhe Yu","Yunshan Ma","Lei Wu","Changshuo Wang","Xue Li","Lei Meng"],"url":"https://arxiv.org/abs/2504.12900"}
{"created":"2025-04-18","title":"The Rise of Bluesky","abstract":"This study investigates the rapid growth and evolving network structure of Bluesky from August 2023 to February 2025. Through multiple waves of user migrations, the platform has reached a stable, persistently active user base. The growth process has given rise to a dense follower network with clustering and hub features that favor viral information diffusion. These developments highlight engagement and structural similarities between Bluesky and established platforms.","authors":["Ozgur Can Seckin","Filipi Nascimento Silva","Bao Tran Truong","Sangyeon Kim","Fan Huang","Nick Liu","Alessandro Flammini","Filippo Menczer"],"url":"https://arxiv.org/abs/2504.12902"}
{"created":"2025-04-18","title":"Second-order Optimization of Gaussian Splats with Importance Sampling","abstract":"3D Gaussian Splatting (3DGS) is widely used for novel view synthesis due to its high rendering quality and fast inference time. However, 3DGS predominantly relies on first-order optimizers such as Adam, which leads to long training times. To address this limitation, we propose a novel second-order optimization strategy based on Levenberg-Marquardt (LM) and Conjugate Gradient (CG), which we specifically tailor towards Gaussian Splatting. Our key insight is that the Jacobian in 3DGS exhibits significant sparsity since each Gaussian affects only a limited number of pixels. We exploit this sparsity by proposing a matrix-free and GPU-parallelized LM optimization. To further improve its efficiency, we propose sampling strategies for both the camera views and loss function and, consequently, the normal equation, significantly reducing the computational complexity. In addition, we increase the convergence rate of the second-order approximation by introducing an effective heuristic to determine the learning rate that avoids the expensive computation cost of line search methods. As a result, our method achieves a $3\\times$ speedup over standard LM and outperforms Adam by $~6\\times$ when the Gaussian count is low while remaining competitive for moderate counts. Project Page: https://vcai.mpi-inf.mpg.de/projects/LM-IS","authors":["Hamza Pehlivan","Andrea Boscolo Camiletto","Lin Geng Foo","Marc Habermann","Christian Theobalt"],"url":"https://arxiv.org/abs/2504.12905"}
{"created":"2025-04-18","title":"Taccel: Scaling Up Vision-based Tactile Robotics via High-performance GPU Simulation","abstract":"Tactile sensing is crucial for achieving human-level robotic capabilities in manipulation tasks. VBTSs have emerged as a promising solution, offering high spatial resolution and cost-effectiveness by sensing contact through camera-captured deformation patterns of elastic gel pads. However, these sensors' complex physical characteristics and visual signal processing requirements present unique challenges for robotic applications. The lack of efficient and accurate simulation tools for VBTS has significantly limited the scale and scope of tactile robotics research. Here we present Taccel, a high-performance simulation platform that integrates IPC and ABD to model robots, tactile sensors, and objects with both accuracy and unprecedented speed, achieving an 18-fold acceleration over real-time across thousands of parallel environments. Unlike previous simulators that operate at sub-real-time speeds with limited parallelization, Taccel provides precise physics simulation and realistic tactile signals while supporting flexible robot-sensor configurations through user-friendly APIs. Through extensive validation in object recognition, robotic grasping, and articulated object manipulation, we demonstrate precise simulation and successful sim-to-real transfer. These capabilities position Taccel as a powerful tool for scaling up tactile robotics research and development. By enabling large-scale simulation and experimentation with tactile sensing, Taccel accelerates the development of more capable robotic systems, potentially transforming how robots interact with and understand their physical environment.","authors":["Yuyang Li","Wenxin Du","Chang Yu","Puhao Li","Zihang Zhao","Tengyu Liu","Chenfanfu Jiang","Yixin Zhu","Siyuan Huang"],"url":"https://arxiv.org/abs/2504.12908"}
{"created":"2025-04-18","title":"Real-time High-fidelity Gaussian Human Avatars with Position-based Interpolation of Spatially Distributed MLPs","abstract":"Many works have succeeded in reconstructing Gaussian human avatars from multi-view videos. However, they either struggle to capture pose-dependent appearance details with a single MLP, or rely on a computationally intensive neural network to reconstruct high-fidelity appearance but with rendering performance degraded to non-real-time. We propose a novel Gaussian human avatar representation that can reconstruct high-fidelity pose-dependence appearance with details and meanwhile can be rendered in real time. Our Gaussian avatar is empowered by spatially distributed MLPs which are explicitly located on different positions on human body. The parameters stored in each Gaussian are obtained by interpolating from the outputs of its nearby MLPs based on their distances. To avoid undesired smooth Gaussian property changing during interpolation, for each Gaussian we define a set of Gaussian offset basis, and a linear combination of basis represents the Gaussian property offsets relative to the neutral properties. Then we propose to let the MLPs output a set of coefficients corresponding to the basis. In this way, although Gaussian coefficients are derived from interpolation and change smoothly, the Gaussian offset basis is learned freely without constraints. The smoothly varying coefficients combined with freely learned basis can still produce distinctly different Gaussian property offsets, allowing the ability to learn high-frequency spatial signals. We further use control points to constrain the Gaussians distributed on a surface layer rather than allowing them to be irregularly distributed inside the body, to help the human avatar generalize better when animated under novel poses. Compared to the state-of-the-art method, our method achieves better appearance quality with finer details while the rendering speed is significantly faster under novel views and novel poses.","authors":["Youyi Zhan","Tianjia Shao","Yin Yang","Kun Zhou"],"url":"https://arxiv.org/abs/2504.12909"}
{"created":"2025-04-18","title":"Benchmarking Multi-National Value Alignment for Large Language Models","abstract":"Do Large Language Models (LLMs) hold positions that conflict with your country's values? Occasionally they do! However, existing works primarily focus on ethical reviews, failing to capture the diversity of national values, which encompass broader policy, legal, and moral considerations. Furthermore, current benchmarks that rely on spectrum tests using manually designed questionnaires are not easily scalable.","authors":["Chengyi Ju","Weijie Shi","Chengzhong Liu","Jiaming Ji","Jipeng Zhang","Ruiyuan Zhang","Jia Zhu","Jiajie Xu","Yaodong Yang","Sirui Han","Yike Guo"],"url":"https://arxiv.org/abs/2504.12911"}
{"created":"2025-04-18","title":"MAIN: Mutual Alignment Is Necessary for instruction tuning","abstract":"Instruction tuning has enabled large language models (LLMs) to achieve remarkable performance, but its success heavily depends on the availability of large-scale, high-quality instruction-response pairs. However, current methods for scaling up data generation often overlook a crucial aspect: the alignment between instructions and responses. We hypothesize that high-quality instruction-response pairs are not defined by the individual quality of each component, but by the extent of their alignment with each other. To address this, we propose a Mutual Alignment Framework (MAIN) that ensures coherence between the instruction and response through mutual constraints. Experiments demonstrate that models such as LLaMA and Mistral, fine-tuned within this framework, outperform traditional methods across multiple benchmarks. This approach underscores the critical role of instruction-response alignment in enabling scalable and high-quality instruction tuning for LLMs.","authors":["Fanyi Yang","Jianfeng Liu","Xin Zhang","Haoyu Liu","Xixin Cao","Yuefeng Zhan","Hao Sun","Weiwei Deng","Feng Sun","Qi Zhang"],"url":"https://arxiv.org/abs/2504.12913"}
{"created":"2025-04-18","title":"In Which Areas of Technical AI Safety Could Geopolitical Rivals Cooperate?","abstract":"International cooperation is common in AI research, including between geopolitical rivals. While many experts advocate for greater international cooperation on AI safety to address shared global risks, some view cooperation on AI with suspicion, arguing that it can pose unacceptable risks to national security. However, the extent to which cooperation on AI safety poses such risks, as well as provides benefits, depends on the specific area of cooperation. In this paper, we consider technical factors that impact the risks of international cooperation on AI safety research, focusing on the degree to which such cooperation can advance dangerous capabilities, result in the sharing of sensitive information, or provide opportunities for harm. We begin by why nations historically cooperate on strategic technologies and analyse current US-China cooperation in AI as a case study. We further argue that existing frameworks for managing associated risks can be supplemented with consideration of key risks specific to cooperation on technical AI safety research. Through our analysis, we find that research into AI verification mechanisms and shared protocols may be suitable areas for such cooperation. Through this analysis we aim to help researchers and governments identify and mitigate the risks of international cooperation on AI safety research, so that the benefits of cooperation can be fully realised.","authors":["Ben Bucknall","Saad Siddiqui","Lara Thurnherr","Conor McGurk","Ben Harack","Anka Reuel","Patricia Paskov","Casey Mahoney","S\\\"oren Mindermann","Scott Singer","Vinay Hiremath","Charbel-Rapha\\\"el Segerie","Oscar Delaney","Alessandro Abate","Fazl Barez","Michael K. Cohen","Philip Torr","Ferenc Husz\\'ar","Anisoara Calinescu","Gabriel Davis Jones","Yoshua Bengio","Robert Trager"],"url":"https://arxiv.org/abs/2504.12914"}
{"created":"2025-04-18","title":"ConExion: Concept Extraction with Large Language Models","abstract":"In this paper, an approach for concept extraction from documents using pre-trained large language models (LLMs) is presented. Compared with conventional methods that extract keyphrases summarizing the important information discussed in a document, our approach tackles a more challenging task of extracting all present concepts related to the specific domain, not just the important ones. Through comprehensive evaluations of two widely used benchmark datasets, we demonstrate that our method improves the F1 score compared to state-of-the-art techniques. Additionally, we explore the potential of using prompts within these models for unsupervised concept extraction. The extracted concepts are intended to support domain coverage evaluation of ontologies and facilitate ontology learning, highlighting the effectiveness of LLMs in concept extraction tasks. Our source code and datasets are publicly available at https://github.com/ISE-FIZKarlsruhe/concept_extraction.","authors":["Ebrahim Norouzi","Sven Hertling","Harald Sack"],"url":"https://arxiv.org/abs/2504.12915"}
{"created":"2025-04-18","title":"Exact Learning Dynamics of In-Context Learning in Linear Transformers and Its Application to Non-Linear Transformers","abstract":"Transformer models exhibit remarkable in-context learning (ICL), adapting to novel tasks from examples within their context, yet the underlying mechanisms remain largely mysterious. Here, we provide an exact analytical characterization of ICL emergence by deriving the closed-form stochastic gradient descent (SGD) dynamics for a simplified linear transformer performing regression tasks. Our analysis reveals key properties: (1) a natural separation of timescales directly governed by the input data's covariance structure, leading to staged learning; (2) an exact description of how ICL develops, including fixed points corresponding to learned algorithms and conservation laws constraining the dynamics; and (3) surprisingly nonlinear learning behavior despite the model's linearity. We hypothesize this phenomenology extends to non-linear models. To test this, we introduce theory-inspired macroscopic measures (spectral rank dynamics, subspace stability) and use them to provide mechanistic explanations for (1) the sudden emergence of ICL in attention-only networks and (2) delayed generalization (grokking) in modular arithmetic models. Our work offers an exact dynamical model for ICL and theoretically grounded tools for analyzing complex transformer training.","authors":["Nischal Mainali","Lucas Teixeira"],"url":"https://arxiv.org/abs/2504.12916"}
{"created":"2025-04-18","title":"Sliced-Wasserstein Distance-based Data Selection","abstract":"We propose a new unsupervised anomaly detection method based on the sliced-Wasserstein distance for training data selection in machine learning approaches. Our filtering technique is interesting for decision-making pipelines deploying machine learning models in critical sectors, e.g., power systems, as it offers a conservative data selection and an optimal transport interpretation. To ensure the scalability of our method, we provide two efficient approximations. The first approximation processes reduced-cardinality representations of the datasets concurrently. The second makes use of a computationally light Euclidian distance approximation. Additionally, we open the first dataset showcasing localized critical peak rebate demand response in a northern climate. We present the filtering patterns of our method on synthetic datasets and numerically benchmark our method for training data selection. Finally, we employ our method as part of a first forecasting benchmark for our open-source dataset.","authors":["Julien Pallage","Antoine Lesage-Landry"],"url":"https://arxiv.org/abs/2504.12918"}
{"created":"2025-04-18","title":"CSMF: Cascaded Selective Mask Fine-Tuning for Multi-Objective Embedding-Based Retrieval","abstract":"Multi-objective embedding-based retrieval (EBR) has become increasingly critical due to the growing complexity of user behaviors and commercial objectives. While traditional approaches often suffer from data sparsity and limited information sharing between objectives, recent methods utilizing a shared network alongside dedicated sub-networks for each objective partially address these limitations. However, such methods significantly increase the model parameters, leading to an increased retrieval latency and a limited ability to model causal relationships between objectives. To address these challenges, we propose the Cascaded Selective Mask Fine-Tuning (CSMF), a novel method that enhances both retrieval efficiency and serving performance for multi-objective EBR. The CSMF framework selectively masks model parameters to free up independent learning space for each objective, leveraging the cascading relationships between objectives during the sequential fine-tuning. Without increasing network parameters or online retrieval overhead, CSMF computes a linearly weighted fusion score for multiple objective probabilities while supporting flexible adjustment of each objective's weight across various recommendation scenarios. Experimental results on real-world datasets demonstrate the superior performance of CSMF, and online experiments validate its significant practical value.","authors":["Hao Deng","Haibo Xing","Kanefumi Matsuyama","Moyu Zhang","Jinxin Hu","Hong Wen","Yu Zhang","Xiaoyi Zeng","Jing Zhang"],"url":"https://arxiv.org/abs/2504.12920"}
{"created":"2025-04-18","title":"IdentiARAT: Toward Automated Identification of Individual ARAT Items from Wearable Sensors","abstract":"This study explores the potential of using wrist-worn inertial sensors to automate the labeling of ARAT (Action Research Arm Test) items. While the ARAT is commonly used to assess upper limb motor function, its limitations include subjectivity and time consumption of clinical staff. By using IMU (Inertial Measurement Unit) sensors and MiniROCKET as a time series classification technique, this investigation aims to classify ARAT items based on sensor recordings. We test common preprocessing strategies to efficiently leverage included information in the data. Afterward, we use the best preprocessing to improve the classification. The dataset includes recordings of 45 participants performing various ARAT items. Results show that MiniROCKET offers a fast and reliable approach for classifying ARAT domains, although challenges remain in distinguishing between individual resembling items. Future work may involve improving classification through more advanced machine-learning models and data enhancements.","authors":["Daniel Homm","Patrick Carqueville","Christian Eichhorn","Thomas Weikert","Thomas Menard","David A. Plecher","Chris Awai Easthope"],"url":"https://arxiv.org/abs/2504.12921"}
{"created":"2025-04-18","title":"Efficient Masked Image Compression with Position-Indexed Self-Attention","abstract":"In recent years, image compression for high-level vision tasks has attracted considerable attention from researchers. Given that object information in images plays a far more crucial role in downstream tasks than background information, some studies have proposed semantically structuring the bitstream to selectively transmit and reconstruct only the information required by these tasks. However, such methods structure the bitstream after encoding, meaning that the coding process still relies on the entire image, even though much of the encoded information will not be transmitted. This leads to redundant computations. Traditional image compression methods require a two-dimensional image as input, and even if the unimportant regions of the image are set to zero by applying a semantic mask, these regions still participate in subsequent computations as part of the image. To address such limitations, we propose an image compression method based on a position-indexed self-attention mechanism that encodes and decodes only the visible parts of the masked image. Compared to existing semantic-structured compression methods, our approach can significantly reduce computational costs.","authors":["Chengjie Dai","Tiantian Song","Hui Tang","Fangdong Chen","Bowei Yang","Guanghua Song"],"url":"https://arxiv.org/abs/2504.12923"}
{"created":"2025-04-18","title":"Explainable AI in Usable Privacy and Security: Challenges and Opportunities","abstract":"Large Language Models (LLMs) are increasingly being used for automated evaluations and explaining them. However, concerns about explanation quality, consistency, and hallucinations remain open research challenges, particularly in high-stakes contexts like privacy and security, where user trust and decision-making are at stake. In this paper, we investigate these issues in the context of PRISMe, an interactive privacy policy assessment tool that leverages LLMs to evaluate and explain website privacy policies. Based on a prior user study with 22 participants, we identify key concerns regarding LLM judgment transparency, consistency, and faithfulness, as well as variations in user preferences for explanation detail and engagement. We discuss potential strategies to mitigate these concerns, including structured evaluation criteria, uncertainty estimation, and retrieval-augmented generation (RAG). We identify a need for adaptive explanation strategies tailored to different user profiles for LLM-as-a-judge. Our goal is to showcase the application area of usable privacy and security to be promising for Human-Centered Explainable AI (HCXAI) to make an impact.","authors":["Vincent Freiberger","Arthur Fleig","Erik Buchmann"],"url":"https://arxiv.org/abs/2504.12931"}
{"created":"2025-04-18","title":"Optimal analysis of penalized lowest-order mixed FEMs for the Stokes-Darcy model","abstract":"This paper is concerned with non-uniform fully-mixed FEMs for dynamic coupled Stokes-Darcy model with the well-known Beavers-Joseph-Saffman (BJS) interface condition. In particular, a decoupled algorithm with the lowest-order mixed non-uniform FE approximations (MINI for the Stokes equation and RT0-DG0 for the Darcy equation) and the classical Nitsche-type penalty is studied. The method with the combined approximation of different orders is commonly used in practical simulations. However, the optimal error analysis of methods with non-uniform approximations for the coupled Stokes-Darcy flow model has remained challenging, although the analysis for uniform approximations has been well done. The key question is how the lower-order approximation to the Darcy flow influences the accuracy of the Stokes solution through the interface condition. In this paper, we prove that the decoupled algorithm provides a truly optimal convergence rate in L^2-norm in spatial direction: O(h^2) for Stokes velocity and O(h) for Darcy flow in the coupled Stokes-Darcy model. This implies that the lower-order approximation to the Darcy flow does not pollute the accuracy of numerical velocity for Stokes flow. The analysis presented in this paper is based on a well-designed Stokes-Darcy Ritz projection and given for a dynamic coupled model. The optimal error estimate holds for more general combined approximations and more general coupled models, including the corresponding model of steady-state Stokes-Darcy flows and the model of coupled dynamic Stokes and steady-state Darcy flows. Numerical results confirm our theoretical analysis and show that the decoupled algorithm is efficient.","authors":["Luling Cao","Weiwei Sun"],"url":"https://arxiv.org/abs/2504.12938"}
{"created":"2025-04-18","title":"Disentangling Polysemantic Channels in Convolutional Neural Networks","abstract":"Mechanistic interpretability is concerned with analyzing individual components in a (convolutional) neural network (CNN) and how they form larger circuits representing decision mechanisms. These investigations are challenging since CNNs frequently learn polysemantic channels that encode distinct concepts, making them hard to interpret. To address this, we propose an algorithm to disentangle a specific kind of polysemantic channel into multiple channels, each responding to a single concept. Our approach restructures weights in a CNN, utilizing that different concepts within the same channel exhibit distinct activation patterns in the previous layer. By disentangling these polysemantic features, we enhance the interpretability of CNNs, ultimately improving explanatory techniques such as feature visualizations.","authors":["Robin Hesse","Jonas Fischer","Simone Schaub-Meyer","Stefan Roth"],"url":"https://arxiv.org/abs/2504.12939"}
{"created":"2025-04-18","title":"Customizing Emotional Support: How Do Individuals Construct and Interact With LLM-Powered Chatbots","abstract":"Personalized support is essential to fulfill individuals' emotional needs and sustain their mental well-being. Large language models (LLMs), with great customization flexibility, hold promises to enable individuals to create their own emotional support agents. In this work, we developed ChatLab, where users could construct LLM-powered chatbots with additional interaction features including voices and avatars. Using a Research through Design approach, we conducted a week-long field study followed by interviews and design activities (N = 22), which uncovered how participants created diverse chatbot personas for emotional reliance, confronting stressors, connecting to intellectual discourse, reflecting mirrored selves, etc. We found that participants actively enriched the personas they constructed, shaping the dynamics between themselves and the chatbot to foster open and honest conversations. They also suggested other customizable features, such as integrating online activities and adjustable memory settings. Based on these findings, we discuss opportunities for enhancing personalized emotional support through emerging AI technologies.","authors":["Xi Zheng","Zhuoyang Li","Xinning Gui","Yuhan Luo"],"url":"https://arxiv.org/abs/2504.12943"}
{"created":"2025-04-18","title":"Algorithms for the Shortest Vector Problem in $2$-dimensional Lattices, Revisited","abstract":"Efficiently solving the Shortest Vector Problem (SVP) in two-dimensional lattices holds practical significance in cryptography and computational geometry. While simpler than its high-dimensional counterpart, two-dimensional SVP motivates scalable solutions for high-dimensional lattices and benefits applications like sequence cipher cryptanalysis involving large integers. In this work, we first propose a novel definition of reduced bases and develop an efficient adaptive lattice reduction algorithm \\textbf{CrossEuc} that strategically applies the Euclidean algorithm across dimensions. Building on this framework, we introduce \\textbf{HVec}, a vectorized generalization of the Half-GCD algorithm originally defined for integers, which can efficiently halve the bit-length of two vectors and may have independent interest. By iteratively invoking \\textbf{HVec}, our optimized algorithm \\textbf{HVecSBP} achieves a reduced basis in $O(\\log n M(n) )$ time for arbitrary input bases with bit-length $n$, where $M(n)$ denotes the cost of multiplying two $n$-bit integers. Compared to existing algorithms, our design is applicable to general forms of input lattices, eliminating the cost of pre-converting input bases to Hermite Normal Form (HNF). The comprehensive experimental results demonstrate that for the input lattice bases in HNF, the optimized algorithm \\textbf{HVecSBP} achieves at least a $13.5\\times$ efficiency improvement compared to existing methods. For general-form input lattice bases, converting them to HNF before applying \\textbf{HVecSBP} offers only marginal advantages in extreme cases where the two basis vectors are nearly degenerate. However, as the linear dependency between input basis vectors decreases, directly employing \\textbf{HVecSBP} yields increasingly significant efficiency gains, outperforming hybrid approaches that rely on prior \\textbf{HNF} conversion.","authors":["Lihao Zhao","Chengliang Tian","Jingguo Bi","Guangwu Xu","Jia Yu"],"url":"https://arxiv.org/abs/2504.12948"}
{"created":"2025-04-18","title":"RL-PINNs: Reinforcement Learning-Driven Adaptive Sampling for Efficient Training of PINNs","abstract":"Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework for solving partial differential equations (PDEs). However, their performance heavily relies on the strategy used to select training points. Conventional adaptive sampling methods, such as residual-based refinement, often require multi-round sampling and repeated retraining of PINNs, leading to computational inefficiency due to redundant points and costly gradient computations-particularly in high-dimensional or high-order derivative scenarios. To address these limitations, we propose RL-PINNs, a reinforcement learning(RL)-driven adaptive sampling framework that enables efficient training with only a single round of sampling. Our approach formulates adaptive sampling as a Markov decision process, where an RL agent dynamically selects optimal training points by maximizing a long-term utility metric. Critically, we replace gradient-dependent residual metrics with a computationally efficient function variation as the reward signal, eliminating the overhead of derivative calculations. Furthermore, we employ a delayed reward mechanism to prioritize long-term training stability over short-term gains. Extensive experiments across diverse PDE benchmarks, including low-regular, nonlinear, high-dimensional, and high-order problems, demonstrate that RL-PINNs significantly outperforms existing residual-driven adaptive methods in accuracy. Notably, RL-PINNs achieve this with negligible sampling overhead, making them scalable to high-dimensional and high-order problems.","authors":["Zhenao Song"],"url":"https://arxiv.org/abs/2504.12949"}
{"created":"2025-04-18","title":"Are Retrials All You Need? Enhancing Large Language Model Reasoning Without Verbalized Feedback","abstract":"Recent advancements in large language models (LLMs) have catalyzed the development of general-purpose autonomous agents, demonstrating remarkable performance in complex reasoning tasks across various domains. This surge has spurred the evolution of a plethora of prompt-based reasoning frameworks. A recent focus has been on iterative reasoning strategies that refine outputs through self-evaluation and verbalized feedback. However, these strategies require additional computational complexity to enable models to recognize and correct their mistakes, leading to a significant increase in their cost. In this work, we introduce the concept of ``retrials without feedback'', an embarrassingly simple yet powerful mechanism for enhancing reasoning frameworks by allowing LLMs to retry problem-solving attempts upon identifying incorrect answers. Unlike conventional iterative refinement methods, our method does not require explicit self-reflection or verbalized feedback, simplifying the refinement process. Our findings indicate that simpler retrial-based approaches often outperform more sophisticated reasoning frameworks, suggesting that the benefits of complex methods may not always justify their computational costs. By challenging the prevailing assumption that more intricate reasoning strategies inherently lead to better performance, our work offers new insights into how simpler, more efficient approaches can achieve optimal results. So, are retrials all you need?","authors":["Nearchos Potamitis","Akhil Arora"],"url":"https://arxiv.org/abs/2504.12951"}
{"created":"2025-04-18","title":"Safe Physics-Informed Machine Learning for Dynamics and Control","abstract":"This tutorial paper focuses on safe physics-informed machine learning in the context of dynamics and control, providing a comprehensive overview of how to integrate physical models and safety guarantees. As machine learning techniques enhance the modeling and control of complex dynamical systems, ensuring safety and stability remains a critical challenge, especially in safety-critical applications like autonomous vehicles, robotics, medical decision-making, and energy systems. We explore various approaches for embedding and ensuring safety constraints, such as structural priors, Lyapunov functions, Control Barrier Functions, predictive control, projections, and robust optimization techniques, ensuring that the learned models respect stability and safety criteria. Additionally, we delve into methods for uncertainty quantification and safety verification, including reachability analysis and neural network verification tools, which help validate that control policies remain within safe operating bounds even in uncertain environments. The paper includes illustrative examples demonstrating the implementation aspects of safe learning frameworks that combine the strengths of data-driven approaches with the rigor of physical principles, offering a path toward the safe control of complex dynamical systems.","authors":["Jan Drgona","Truong X. Nghiem","Thomas Beckers","Mahyar Fazlyab","Enrique Mallada","Colin Jones","Draguna Vrabie","Steven L. Brunton","Rolf Findeisen"],"url":"https://arxiv.org/abs/2504.12952"}
{"created":"2025-04-18","title":"How to get Rid of SQL, Relational Algebra, the Relational Model, ERM, and ORMs in a Single Paper -- A Thought Experiment","abstract":"Without any doubt, the relational paradigm has been a huge success. At the same time, we believe that the time is ripe to rethink how database systems could look like if we designed them from scratch. Would we really end up with the same abstractions and techniques that are prevalent today? This paper explores that space. We discuss the various issues with both the relational model(RM) and the entity-relationship model (ERM). We provide a unified data model: the relational map type model (RMTM) which can represent both RM and ERM as special cases and overcomes all of their problems. We proceed to identify seven rules that an RMTM query language (QL) must fulfill and provide a foundation of a language fulfilling all seven rules. Our QL operates on maps which may represent tuples, relations, databases or sets of databases. Like that we dramatically expand the existing operational abstractions found in SQL and relational algebra (RA) which only operate on relations/tables. In fact, RA is just a special case of our much more generic approach. This work has far-reaching consequences: we show a path how to come up with a modern QL that solves (almost if not) all problems of SQL. Our QL is much more expressive than SQL and integrates smoothly into existing programming languages (PL). We also show results of an initial experiment showcasing that just by switching to our data model, and without changing the underlying query processing algorithms, we can achieve speed-ups of up to a factor 3. We will conclude that, if we build a database system from scratch, we could and should do this without SQL, RA, RM, ERM, and ORMs.","authors":["Jens Dittrich"],"url":"https://arxiv.org/abs/2504.12953"}
{"created":"2025-04-18","title":"Rethinking Temporal Fusion with a Unified Gradient Descent View for 3D Semantic Occupancy Prediction","abstract":"We present GDFusion, a temporal fusion method for vision-based 3D semantic occupancy prediction (VisionOcc). GDFusion opens up the underexplored aspects of temporal fusion within the VisionOcc framework, focusing on both temporal cues and fusion strategies. It systematically examines the entire VisionOcc pipeline, identifying three fundamental yet previously overlooked temporal cues: scene-level consistency, motion calibration, and geometric complementation. These cues capture diverse facets of temporal evolution and make distinct contributions across various modules in the VisionOcc framework. To effectively fuse temporal signals across heterogeneous representations, we propose a novel fusion strategy by reinterpreting the formulation of vanilla RNNs. This reinterpretation leverages gradient descent on features to unify the integration of diverse temporal information, seamlessly embedding the proposed temporal cues into the network. Extensive experiments on nuScenes demonstrate that GDFusion significantly outperforms established baselines. Notably, on Occ3D benchmark, it achieves 1.4\\%-4.8\\% mIoU improvements and reduces memory consumption by 27\\%-72\\%.","authors":["Dubing Chen","Huan Zheng","Jin Fang","Xingping Dong","Xianfei Li","Wenlong Liao","Tao He","Pai Peng","Jianbing Shen"],"url":"https://arxiv.org/abs/2504.12959"}
{"created":"2025-04-18","title":"QLLM: Do We Really Need a Mixing Network for Credit Assignment in Multi-Agent Reinforcement Learning?","abstract":"Credit assignment has remained a fundamental challenge in multi-agent reinforcement learning (MARL). Previous studies have primarily addressed this issue through value decomposition methods under the centralized training with decentralized execution paradigm, where neural networks are utilized to approximate the nonlinear relationship between individual Q-values and the global Q-value. Although these approaches have achieved considerable success in various benchmark tasks, they still suffer from several limitations, including imprecise attribution of contributions, limited interpretability, and poor scalability in high-dimensional state spaces. To address these challenges, we propose a novel algorithm, \\textbf{QLLM}, which facilitates the automatic construction of credit assignment functions using large language models (LLMs). Specifically, the concept of \\textbf{TFCAF} is introduced, wherein the credit allocation process is represented as a direct and expressive nonlinear functional formulation. A custom-designed \\textit{coder-evaluator} framework is further employed to guide the generation, verification, and refinement of executable code by LLMs, significantly mitigating issues such as hallucination and shallow reasoning during inference. Extensive experiments conducted on several standard MARL benchmarks demonstrate that the proposed method consistently outperforms existing state-of-the-art baselines. Moreover, QLLM exhibits strong generalization capability and maintains compatibility with a wide range of MARL algorithms that utilize mixing networks, positioning it as a promising and versatile solution for complex multi-agent scenarios.","authors":["Zhouyang Jiang","Bin Zhang","Airong Wei","Zhiwei Xu"],"url":"https://arxiv.org/abs/2504.12961"}
{"created":"2025-04-18","title":"Vision and Language Integration for Domain Generalization","abstract":"Domain generalization aims at training on source domains to uncover a domain-invariant feature space, allowing the model to perform robust generalization ability on unknown target domains. However, due to domain gaps, it is hard to find reliable common image feature space, and the reason for that is the lack of suitable basic units for images. Different from image in vision space, language has comprehensive expression elements that can effectively convey semantics. Inspired by the semantic completeness of language and intuitiveness of image, we propose VLCA, which combine language space and vision space, and connect the multiple image domains by using semantic space as the bridge domain. Specifically, in language space, by taking advantage of the completeness of language basic units, we tend to capture the semantic representation of the relations between categories through word vector distance. Then, in vision space, by taking advantage of the intuitiveness of image features, the common pattern of sample features with the same class is explored through low-rank approximation. In the end, the language representation is aligned with the vision representation through the multimodal space of text and image. Experiments demonstrate the effectiveness of the proposed method.","authors":["Yanmei Wang","Xiyao Liu","Fupeng Chu","Zhi Han"],"url":"https://arxiv.org/abs/2504.12966"}
{"created":"2025-04-18","title":"Krysalis Hand: A Lightweight, High-Payload, 18-DoF Anthropomorphic End-Effector for Robotic Learning and Dexterous Manipulation","abstract":"This paper presents the Krysalis Hand, a five-finger robotic end-effector that combines a lightweight design, high payload capacity, and a high number of degrees of freedom (DoF) to enable dexterous manipulation in both industrial and research settings. This design integrates the actuators within the hand while maintaining an anthropomorphic form. Each finger joint features a self-locking mechanism that allows the hand to sustain large external forces without active motor engagement. This approach shifts the payload limitation from the motor strength to the mechanical strength of the hand, allowing the use of smaller, more cost-effective motors. With 18 DoF and weighing only 790 grams, the Krysalis Hand delivers an active squeezing force of 10 N per finger and supports a passive payload capacity exceeding 10 lbs. These characteristics make Krysalis Hand one of the lightest, strongest, and most dexterous robotic end-effectors of its kind. Experimental evaluations validate its ability to perform intricate manipulation tasks and handle heavy payloads, underscoring its potential for industrial applications as well as academic research. All code related to the Krysalis Hand, including control and teleoperation, is available on the project GitHub repository: https://github.com/Soltanilara/Krysalis_Hand","authors":["Al Arsh Basheer","Justin Chang","Yuyang Chen","David Kim","Iman Soltani"],"url":"https://arxiv.org/abs/2504.12967"}
{"created":"2025-04-18","title":"MathPhys-Guided Coarse-to-Fine Anomaly Synthesis with SQE-Driven Bi-Level Optimization for Anomaly Detection","abstract":"Anomaly detection is a crucial task in computer vision, yet collecting real-world defect images is inherently difficult due to the rarity and unpredictability of anomalies. Consequently, researchers have turned to synthetic methods for training data augmentation. However, existing synthetic strategies (e.g., naive cut-and-paste or inpainting) overlook the underlying physical causes of defects, leading to inconsistent, low-fidelity anomalies that hamper model generalization to real-world complexities. In this thesis, we introduced a novel pipeline that generates synthetic anomalies through Math-Physics model guidance, refines them via a Coarse-to-Fine approach and employs a bi-level optimization strategy with a Synthesis Quality Estimator(SQE). By incorporating physical modeling of cracks, corrosion, and deformation, our method produces realistic defect masks, which are subsequently enhanced in two phases. The first stage (npcF) enforces a PDE-based consistency to achieve a globally coherent anomaly structure, while the second stage (npcF++) further improves local fidelity using wavelet transforms and boundary synergy blocks. Additionally, we leverage SQE-driven weighting, ensuring that high-quality synthetic samples receive greater emphasis during training. To validate our approach, we conducted comprehensive experiments on three widely adopted industrial anomaly detection benchmarks: MVTec AD, VisA, and BTAD. Across these datasets, the proposed pipeline achieves state-of-the-art (SOTA) results in both image-AUROC and pixel-AUROC, confirming the effectiveness of our MaPhC2F and BiSQAD.","authors":["Long Qian","Bingke Zhu","Yingying Chen","Ming Tang","Jinqiao Wang"],"url":"https://arxiv.org/abs/2504.12970"}
{"created":"2025-04-18","title":"Transferrable Surrogates in Expressive Neural Architecture Search Spaces","abstract":"Neural architecture search (NAS) faces a challenge in balancing the exploration of expressive, broad search spaces that enable architectural innovation with the need for efficient evaluation of architectures to effectively search such spaces. We investigate surrogate model training for improving search in highly expressive NAS search spaces based on context-free grammars. We show that i) surrogate models trained either using zero-cost-proxy metrics and neural graph features (GRAF) or by fine-tuning an off-the-shelf LM have high predictive power for the performance of architectures both within and across datasets, ii) these surrogates can be used to filter out bad architectures when searching on novel datasets, thereby significantly speeding up search and achieving better final performances, and iii) the surrogates can be further used directly as the search objective for huge speed-ups.","authors":["Shiwen Qin","Gabriela Kadlecov\\'a","Martin Pil\\'at","Shay B. Cohen","Roman Neruda","Elliot J. Crowley","Jovita Lukasik","Linus Ericsson"],"url":"https://arxiv.org/abs/2504.12971"}
{"created":"2025-04-18","title":"Estimating Optimal Context Length for Hybrid Retrieval-augmented Multi-document Summarization","abstract":"Recent advances in long-context reasoning abilities of language models led to interesting applications in large-scale multi-document summarization. However, prior work has shown that these long-context models are not effective at their claimed context windows. To this end, retrieval-augmented systems provide an efficient and effective alternative. However, their performance can be highly sensitive to the choice of retrieval context length. In this work, we present a hybrid method that combines retrieval-augmented systems with long-context windows supported by recent language models. Our method first estimates the optimal retrieval length as a function of the retriever, summarizer, and dataset. On a randomly sampled subset of the dataset, we use a panel of LLMs to generate a pool of silver references. We use these silver references to estimate the optimal context length for a given RAG system configuration. Our results on the multi-document summarization task showcase the effectiveness of our method across model classes and sizes. We compare against length estimates from strong long-context benchmarks such as RULER and HELMET. Our analysis also highlights the effectiveness of our estimation method for very long-context LMs and its generalization to new classes of LMs.","authors":["Adithya Pratapa","Teruko Mitamura"],"url":"https://arxiv.org/abs/2504.12972"}
{"created":"2025-04-18","title":"Sparks of Science: Hypothesis Generation Using Structured Paper Data","abstract":"Generating novel and creative scientific hypotheses is a cornerstone in achieving Artificial General Intelligence. Large language and reasoning models have the potential to aid in the systematic creation, selection, and validation of scientifically informed hypotheses. However, current foundation models often struggle to produce scientific ideas that are both novel and feasible. One reason is the lack of a dedicated dataset that frames Scientific Hypothesis Generation (SHG) as a Natural Language Generation (NLG) task. In this paper, we introduce HypoGen, the first dataset of approximately 5500 structured problem-hypothesis pairs extracted from top-tier computer science conferences structured with a Bit-Flip-Spark schema, where the Bit is the conventional assumption, the Spark is the key insight or conceptual leap, and the Flip is the resulting counterproposal. HypoGen uniquely integrates an explicit Chain-of-Reasoning component that reflects the intellectual process from Bit to Flip. We demonstrate that framing hypothesis generation as conditional language modelling, with the model fine-tuned on Bit-Flip-Spark and the Chain-of-Reasoning (and where, at inference, we only provide the Bit), leads to improvements in the overall quality of the hypotheses. Our evaluation employs automated metrics and LLM judge rankings for overall quality assessment. We show that by fine-tuning on our HypoGen dataset we improve the novelty, feasibility, and overall quality of the generated hypotheses. The HypoGen dataset is publicly available at huggingface.co/datasets/UniverseTBD/hypogen-dr1.","authors":["Charles O'Neill","Tirthankar Ghosal","Roberta R\\u{a}ileanu","Mike Walmsley","Thang Bui","Kevin Schawinski","Ioana Ciuc\\u{a}"],"url":"https://arxiv.org/abs/2504.12976"}
{"created":"2025-04-18","title":"A Phenomenological Approach to Analyzing User Queries in IT Systems Using Heidegger's Fundamental Ontology","abstract":"This paper presents a novel research analytical IT system grounded in Martin Heidegger's Fundamental Ontology, distinguishing between beings (das Seiende) and Being (das Sein). The system employs two modally distinct, descriptively complete languages: a categorical language of beings for processing user inputs and an existential language of Being for internal analysis. These languages are bridged via a phenomenological reduction module, enabling the system to analyze user queries (including questions, answers, and dialogues among IT specialists), identify recursive and self-referential structures, and provide actionable insights in categorical terms. Unlike contemporary systems limited to categorical analysis, this approach leverages Heidegger's phenomenological existential analysis to uncover deeper ontological patterns in query processing, aiding in resolving logical traps in complex interactions, such as metaphor usage in IT contexts. The path to full realization involves formalizing the language of Being by a research team based on Heidegger's Fundamental Ontology; given the existing completeness of the language of beings, this reduces the system's computability to completeness, paving the way for a universal query analysis tool. The paper presents the system's architecture, operational principles, technical implementation, use cases--including a case based on real IT specialist dialogues--comparative evaluation with existing tools, and its advantages and limitations.","authors":["Maksim Vishnevskiy"],"url":"https://arxiv.org/abs/2504.12977"}
{"created":"2025-04-18","title":"Accommodate Knowledge Conflicts in Retrieval-augmented LLMs: Towards Reliable Response Generation in the Wild","abstract":"The proliferation of large language models (LLMs) has significantly advanced information retrieval systems, particularly in response generation (RG). Unfortunately, LLMs often face knowledge conflicts between internal memory and retrievaled external information, arising from misinformation, biases, or outdated knowledge. These conflicts undermine response reliability and introduce uncertainty in decision-making. In this work, we analyze how LLMs navigate knowledge conflicts from an information-theoretic perspective and reveal that when conflicting and supplementary information exhibit significant differences, LLMs confidently resolve their preferences. However, when the distinction is ambiguous, LLMs experience heightened uncertainty. Based on this insight, we propose Swin-VIB, a novel framework that integrates a pipeline of variational information bottleneck models into adaptive augmentation of retrieved information and guiding LLM preference in response generation. Extensive experiments on single-choice, open-ended question-answering (QA), and retrieval augmented generation (RAG) validate our theoretical findings and demonstrate the efficacy of Swin-VIB. Notably, our method improves single-choice task accuracy by at least 7.54\\% over competitive baselines.","authors":["Jiatai Wang","Zhiwei Xu","Di Jin","Xuewen Yang","Tao Li"],"url":"https://arxiv.org/abs/2504.12982"}
{"created":"2025-04-18","title":"A Virtual Machine for Arbitrary Low-Precision GPGPU Computation in LLM Serving","abstract":"Serving Large Language Models (LLMs) is critical for AI-powered applications but demands substantial computational resources, particularly in memory bandwidth and computational throughput. Low-precision computation has emerged as a key technique to improve efficiency while reducing resource consumption. Existing approaches for generating low-precision kernels are limited to weight bit widths that are powers of two and suffer from suboptimal performance due to high-level GPU programming abstractions. These abstractions restrict critical optimizations, such as fine-grained register management and optimized memory access patterns, which are essential for efficient low-precision computations. In this paper, we introduce a virtual machine (VM) designed for General-Purpose GPU (GPGPU) computing, enabling support for low-precision data types with arbitrary bit widths while maintaining GPU programmability. The proposed VM features a thread-block-level programming model, a hierarchical memory space, a novel algebraic layout system, and extensive support for diverse low-precision data types. VM programs are compiled into highly efficient GPU programs with automatic vectorization and instruction selection. Extensive experiments demonstrate that our VM efficiently supports a full spectrum of low-precision data types, and outperforms state-of-the-art low-precision kernels on their supported types. Compared to existing compilers like Triton and Ladder, as well as hand-optimized kernels such as QuantLLM and Marlin, our VM achieves performance improvements of 1.75x, 2.61x, 1.29x and 1.03x, respectively.","authors":["Yaoyao Ding","Bohan Hou","Xiao Zhang","Allan Lin","Tianqi Chen","Cody Yu Hao","Yida Wang","Gennady Pekhimenko"],"url":"https://arxiv.org/abs/2504.12984"}
{"created":"2025-04-18","title":"Why Ask One When You Can Ask $k$? Two-Stage Learning-to-Defer to a Set of Experts","abstract":"Learning-to-Defer (L2D) enables decision-making systems to improve reliability by selectively deferring uncertain predictions to more competent agents. However, most existing approaches focus exclusively on single-agent deferral, which is often inadequate in high-stakes scenarios that require collective expertise. We propose Top-$k$ Learning-to-Defer, a generalization of the classical two-stage L2D framework that allocates each query to the $k$ most confident agents instead of a single one. To further enhance flexibility and cost-efficiency, we introduce Top-$k(x)$ Learning-to-Defer, an adaptive extension that learns the optimal number of agents to consult for each query, based on input complexity, agent competency distributions, and consultation costs. For both settings, we derive a novel surrogate loss and prove that it is Bayes-consistent and $(\\mathcal{R}, \\mathcal{G})$-consistent, ensuring convergence to the Bayes-optimal allocation. Notably, we show that the well-established model cascades paradigm arises as a restricted instance of our Top-$k$ and Top-$k(x)$ formulations. Extensive experiments across diverse benchmarks demonstrate the effectiveness of our framework on both classification and regression tasks.","authors":["Yannis Montreuil","Axel Carlier","Lai Xing Ng","Wei Tsang Ooi"],"url":"https://arxiv.org/abs/2504.12988"}
{"created":"2025-04-18","title":"Chain-of-Thought Prompting for Out-of-Distribution Samples: A Latent-Variable Study","abstract":"Chain-of-Thought (CoT) prompting has emerged as a powerful technique to improve in-context learning (ICL) in large language models (LLMs) by breaking complex reasoning into intermediate steps. However, the ability of CoT to generalize under distribution shift remains poorly understood. In this work, we extend a latent-variable framework for CoT prompting and study its behavior on two prototypical out-of-distribution (OOD) scenarios: (i) the latent variables for CoT steps are permuted into novel combinations, and (ii) the latent variables uniformly scaled by a factor. Our experiments demonstrate that CoT inference generalizes effectively to OOD samples whose latent variables closely resemble those seen during training, but its performance degrades as this similarity decreases. These findings provide foundational insights into the strengths and limitations of CoT prompting under OOD conditions and suggest directions for developing more resilient reasoning strategies in future LLMs.","authors":["Yu Wang","Fu-Chieh Chang","Pei-Yuan Wu"],"url":"https://arxiv.org/abs/2504.12991"}
{"created":"2025-04-18","title":"Enhancing Cocoa Pod Disease Classification via Transfer Learning and Ensemble Methods: Toward Robust Predictive Modeling","abstract":"This study presents an ensemble-based approach for cocoa pod disease classification by integrating transfer learning with three ensemble learning strategies: Bagging, Boosting, and Stacking. Pre-trained convolutional neural networks, including VGG16, VGG19, ResNet50, ResNet101, InceptionV3, and Xception, were fine-tuned and employed as base learners to detect three disease categories: Black Pod Rot, Pod Borer, and Healthy. A balanced dataset of 6,000 cocoa pod images was curated and augmented to ensure robustness against variations in lighting, orientation, and disease severity. The performance of each ensemble method was evaluated using accuracy, precision, recall, and F1-score. Experimental results show that Bagging consistently achieved superior classification performance with a test accuracy of 100%, outperforming Boosting (97%) and Stacking (92%). The findings confirm that combining transfer learning with ensemble techniques improves model generalization and reliability, making it a promising direction for precision agriculture and automated crop disease management.","authors":["Devina Anduyan","Nyza Cabillo","Navy Gultiano","Mark Phil Pacot"],"url":"https://arxiv.org/abs/2504.12992"}
{"created":"2025-04-18","title":"SHA256 at SemEval-2025 Task 4: Selective Amnesia -- Constrained Unlearning for Large Language Models via Knowledge Isolation","abstract":"Large language models (LLMs) frequently memorize sensitive information during training, posing risks when deploying publicly accessible models. Current machine unlearning methods struggle to selectively remove specific data associations without degrading overall model capabilities. This paper presents our solution to SemEval-2025 Task 4 on targeted unlearning, which introduces a two-stage methodology that combines causal mediation analysis with layer-specific optimization. Through systematic causal tracing experiments on OLMo architectures (1B and 7B parameters), we identify the critical role of the first few transformer layers (layers 0-5) in storing subject-attribute associations within MLP modules. Building on this insight, we develop a constrained optimization approach that freezes upper layers while applying a novel joint loss function to lower layers-simultaneously maximizing forget set loss via output token cross-entropy penalties and minimizing retain set deviation through adaptive regularization. Our method achieves 2nd place in the 1B model track, demonstrating strong task performance while maintaining 88% of baseline MMLU accuracy. These results establish causal-informed layer optimization as a promising paradigm for efficient, precise unlearning in LLMs, offering a significant step forward in addressing data privacy concerns in AI systems.","authors":["Saransh Agrawal","Kuan-Hao Huang"],"url":"https://arxiv.org/abs/2504.12996"}
{"created":"2025-04-18","title":"All-in-One Transferring Image Compression from Human Perception to Multi-Machine Perception","abstract":"Efficiently transferring Learned Image Compression (LIC) model from human perception to machine perception is an emerging challenge in vision-centric representation learning. Existing approaches typically adapt LIC to downstream tasks in a single-task manner, which is inefficient, lacks task interaction, and results in multiple task-specific bitstreams. To address these limitations, we propose an asymmetric adaptor framework that supports multi-task adaptation within a single model. Our method introduces a shared adaptor to learn general semantic features and task-specific adaptors to preserve task-level distinctions. With only lightweight plug-in modules and a frozen base codec, our method achieves strong performance across multiple tasks while maintaining compression efficiency. Experiments on the PASCAL-Context benchmark demonstrate that our method outperforms both Fully Fine-Tuned and other Parameter Efficient Fine-Tuned (PEFT) baselines, and validating the effectiveness of multi-vision transferring.","authors":["Jiancheng Zhao","Xiang Ji","Zhuoxiao Li","Zunian Wan","Weihang Ran","Mingze Ma","Muyao Niu","Yifan Zhan","Cheng-Ching Tseng","Yinqiang Zheng"],"url":"https://arxiv.org/abs/2504.12997"}
{"created":"2025-04-18","title":"Automated Generation of Commit Messages in Software Repositories","abstract":"Commit messages are crucial for documenting software changes, aiding in program comprehension and maintenance. However, creating effective commit messages is often overlooked by developers due to time constraints and varying levels of documentation skills. Our research presents an automated approach to generate commit messages using Machine Learning (ML) and Natural Language Processing (NLP) by developing models that use techniques such as Logistic Regression with TF-IDF and Word2Vec, as well as more sophisticated methods like LSTM. We used the dataset of code changes and corresponding commit messages that was used by Liu et al., which we used to train and evaluate ML/NLP models and was chosen because it is extensively used in previous research, also for comparability in our study. The objective was to explore which ML/NLP techniques generate the most effective, clear, and concise commit messages that accurately reflect the code changes. We split the dataset into training, validation, and testing sets and used these sets to evaluate the performance of each model using qualitative and quantitative evaluation methods. Our results reveal a spectrum of effectiveness among these models, with the highest BLEU score achieved being 16.82, showcasing the models' capability in automating a clear and concise commit message generation. Our paper offers insights into the comparative effectiveness of different machine learning models for automating commit message generation in software development, aiming to enhance the overall practice of code documentation. The source code is available at https://doi.org/10.5281/zenodo.10888106.","authors":["Varun Kumar Palakodeti","Abbas Heydarnoori"],"url":"https://arxiv.org/abs/2504.12998"}
{"created":"2025-04-18","title":"GSAC: Leveraging Gaussian Splatting for Photorealistic Avatar Creation with Unity Integration","abstract":"Photorealistic avatars have become essential for immersive applications in virtual reality (VR) and augmented reality (AR), enabling lifelike interactions in areas such as training simulations, telemedicine, and virtual collaboration. These avatars bridge the gap between the physical and digital worlds, improving the user experience through realistic human representation. However, existing avatar creation techniques face significant challenges, including high costs, long creation times, and limited utility in virtual applications. Manual methods, such as MetaHuman, require extensive time and expertise, while automatic approaches, such as NeRF-based pipelines often lack efficiency, detailed facial expression fidelity, and are unable to be rendered at a speed sufficent for real-time applications. By involving several cutting-edge modern techniques, we introduce an end-to-end 3D Gaussian Splatting (3DGS) avatar creation pipeline that leverages monocular video input to create a scalable and efficient photorealistic avatar directly compatible with the Unity game engine. Our pipeline incorporates a novel Gaussian splatting technique with customized preprocessing that enables the user of \"in the wild\" monocular video capture, detailed facial expression reconstruction and embedding within a fully rigged avatar model. Additionally, we present a Unity-integrated Gaussian Splatting Avatar Editor, offering a user-friendly environment for VR/AR application development. Experimental results validate the effectiveness of our preprocessing pipeline in standardizing custom data for 3DGS training and demonstrate the versatility of Gaussian avatars in Unity, highlighting the scalability and practicality of our approach.","authors":["Rendong Zhang","Alexandra Watkins","Nilanjan Sarkar"],"url":"https://arxiv.org/abs/2504.12999"}
{"created":"2025-04-18","title":"The Role of Empathy in Software Engineering -- A Socio-Technical Grounded Theory","abstract":"Empathy, defined as the ability to understand and share others' perspectives and emotions, is essential in software engineering (SE), where developers often collaborate with diverse stakeholders. It is also considered as a vital competency in many professional fields such as medicine, healthcare, nursing, animal science, education, marketing, and project management. Despite its importance, empathy remains under-researched in SE. To further explore this, we conducted a socio-technical grounded theory (STGT) study through in-depth semi-structured interviews with 22 software developers and stakeholders. Our study explored the role of empathy in SE and how SE activities and processes can be improved by considering empathy. Through applying the systematic steps of STGT data analysis and theory development, we developed a theory that explains the role of empathy in SE. Our theory details the contexts in which empathy arises, the conditions that shape it, the causes and consequences of its presence and absence. We also identified contingencies for enhancing empathy or overcoming barriers to its expression. Our findings provide practical implications for SE practitioners and researchers, offering a deeper understanding of how to effectively integrate empathy into SE processes.","authors":["Hashini Gunatilake","John Grundy","Rashina Hoda","Ingo Mueller"],"url":"https://arxiv.org/abs/2504.13002"}
{"created":"2025-04-18","title":"Towards Optimal Distributed Edge Coloring with Small Palettes","abstract":"We design a deterministic distributed $\\mathcal{O}(\\log n)$-round reduction from the $(2\\Delta-2)$-edge coloring problem to the much easier $(2\\Delta-1)$-edge coloring problem. This is almost optimal, as the $(2\\Delta-2)$-edge coloring problem admits an $\\Omega(\\log_\\Delta n)$ lower bound. Further, we also obtain an optimal $\\mathcal{O}(\\log_\\Delta n)$-round reduction, albeit to the harder maximal independent set (MIS) problem.","authors":["Manuel Jakob","Yannic Maus","Florian Schager"],"url":"https://arxiv.org/abs/2504.13003"}
{"created":"2025-04-18","title":"Hierarchical Feature Learning for Medical Point Clouds via State Space Model","abstract":"Deep learning-based point cloud modeling has been widely investigated as an indispensable component of general shape analysis. Recently, transformer and state space model (SSM) have shown promising capacities in point cloud learning. However, limited research has been conducted on medical point clouds, which have great potential in disease diagnosis and treatment. This paper presents an SSM-based hierarchical feature learning framework for medical point cloud understanding. Specifically, we down-sample input into multiple levels through the farthest point sampling. At each level, we perform a series of k-nearest neighbor (KNN) queries to aggregate multi-scale structural information. To assist SSM in processing point clouds, we introduce coordinate-order and inside-out scanning strategies for efficient serialization of irregular points. Point features are calculated progressively from short neighbor sequences and long point sequences through vanilla and group Point SSM blocks, to capture both local patterns and long-range dependencies. To evaluate the proposed method, we build a large-scale medical point cloud dataset named MedPointS for anatomy classification, completion, and segmentation. Extensive experiments conducted on MedPointS demonstrate that our method achieves superior performance across all tasks. The dataset is available at https://flemme-docs.readthedocs.io/en/latest/medpoints.html. Code is merged to a public medical imaging platform: https://github.com/wlsdzyzl/flemme.","authors":["Guoqing Zhang","Jingyun Yang","Yang Li"],"url":"https://arxiv.org/abs/2504.13015"}
{"created":"2025-04-18","title":"Pose and Facial Expression Transfer by using StyleGAN","abstract":"We propose a method to transfer pose and expression between face images. Given a source and target face portrait, the model produces an output image in which the pose and expression of the source face image are transferred onto the target identity. The architecture consists of two encoders and a mapping network that projects the two inputs into the latent space of StyleGAN2, which finally generates the output. The training is self-supervised from video sequences of many individuals. Manual labeling is not required. Our model enables the synthesis of random identities with controllable pose and expression. Close-to-real-time performance is achieved.","authors":["Petr Jahoda","Jan Cech"],"url":"https://arxiv.org/abs/2504.13021"}
{"created":"2025-04-18","title":"CompGS++: Compressed Gaussian Splatting for Static and Dynamic Scene Representation","abstract":"Gaussian splatting demonstrates proficiency for 3D scene modeling but suffers from substantial data volume due to inherent primitive redundancy. To enable future photorealistic 3D immersive visual communication applications, significant compression is essential for transmission over the existing Internet infrastructure. Hence, we propose Compressed Gaussian Splatting (CompGS++), a novel framework that leverages compact Gaussian primitives to achieve accurate 3D modeling with substantial size reduction for both static and dynamic scenes. Our design is based on the principle of eliminating redundancy both between and within primitives. Specifically, we develop a comprehensive prediction paradigm to address inter-primitive redundancy through spatial and temporal primitive prediction modules. The spatial primitive prediction module establishes predictive relationships for scene primitives and enables most primitives to be encoded as compact residuals, substantially reducing the spatial redundancy. We further devise a temporal primitive prediction module to handle dynamic scenes, which exploits primitive correlations across timestamps to effectively reduce temporal redundancy. Moreover, we devise a rate-constrained optimization module that jointly minimizes reconstruction error and rate consumption. This module effectively eliminates parameter redundancy within primitives and enhances the overall compactness of scene representations. Comprehensive evaluations across multiple benchmark datasets demonstrate that CompGS++ significantly outperforms existing methods, achieving superior compression performance while preserving accurate scene modeling. Our implementation will be made publicly available on GitHub to facilitate further research.","authors":["Xiangrui Liu","Xinju Wu","Shiqi Wang","Zhu Li","Sam Kwong"],"url":"https://arxiv.org/abs/2504.13022"}
{"created":"2025-04-18","title":"ChatEXAONEPath: An Expert-level Multimodal Large Language Model for Histopathology Using Whole Slide Images","abstract":"Recent studies have made significant progress in developing large language models (LLMs) in the medical domain, which can answer expert-level questions and demonstrate the potential to assist clinicians in real-world clinical scenarios. Studies have also witnessed the importance of integrating various modalities with the existing LLMs for a better understanding of complex clinical contexts, which are innately multi-faceted by nature. Although studies have demonstrated the ability of multimodal LLMs in histopathology to answer questions from given images, they lack in understanding of thorough clinical context due to the patch-level data with limited information from public datasets. Thus, developing WSI-level MLLMs is significant in terms of the scalability and applicability of MLLMs in histopathology. In this study, we introduce an expert-level MLLM for histopathology using WSIs, dubbed as ChatEXAONEPath. We present a retrieval-based data generation pipeline using 10,094 pairs of WSIs and histopathology reports from The Cancer Genome Atlas (TCGA). We also showcase an AI-based evaluation protocol for a comprehensive understanding of the medical context from given multimodal information and evaluate generated answers compared to the original histopathology reports. We demonstrate the ability of diagnosing the given histopathology images using ChatEXAONEPath with the acceptance rate of 62.9% from 1,134 pairs of WSIs and reports. Our proposed model can understand pan-cancer WSIs and clinical context from various cancer types. We argue that our proposed model has the potential to assist clinicians by comprehensively understanding complex morphology of WSIs for cancer diagnosis through the integration of multiple modalities.","authors":["Sangwook Kim","Soonyoung Lee","Jongseong Jang"],"url":"https://arxiv.org/abs/2504.13023"}
{"created":"2025-04-18","title":"Riemannian Patch Assignment Gradient Flows","abstract":"This paper introduces patch assignment flows for metric data labeling on graphs. Labelings are determined by regularizing initial local labelings through the dynamic interaction of both labels and label assignments across the graph, entirely encoded by a dictionary of competing labeled patches and mediated by patch assignment variables. Maximal consistency of patch assignments is achieved by geometric numerical integration of a Riemannian ascent flow, as critical point of a Lagrangian action functional. Experiments illustrate properties of the approach, including uncertainty quantification of label assignments.","authors":["Daniel Gonzalez-Alvarado","Fabio Schlindwein","Jonas Cassel","Laura Steingruber","Stefania Petra","Christoph Schn\\\"orr"],"url":"https://arxiv.org/abs/2504.13024"}
{"created":"2025-04-18","title":"TTRD3: Texture Transfer Residual Denoising Dual Diffusion Model for Remote Sensing Image Super-Resolution","abstract":"Remote Sensing Image Super-Resolution (RSISR) reconstructs high-resolution (HR) remote sensing images from low-resolution inputs to support fine-grained ground object interpretation. Existing methods face three key challenges: (1) Difficulty in extracting multi-scale features from spatially heterogeneous RS scenes, (2) Limited prior information causing semantic inconsistency in reconstructions, and (3) Trade-off imbalance between geometric accuracy and visual quality. To address these issues, we propose the Texture Transfer Residual Denoising Dual Diffusion Model (TTRD3) with three innovations: First, a Multi-scale Feature Aggregation Block (MFAB) employing parallel heterogeneous convolutional kernels for multi-scale feature extraction. Second, a Sparse Texture Transfer Guidance (STTG) module that transfers HR texture priors from reference images of similar scenes. Third, a Residual Denoising Dual Diffusion Model (RDDM) framework combining residual diffusion for deterministic reconstruction and noise diffusion for diverse generation. Experiments on multi-source RS datasets demonstrate TTRD3's superiority over state-of-the-art methods, achieving 1.43% LPIPS improvement and 3.67% FID enhancement compared to best-performing baselines. Code/model: https://github.com/LED-666/TTRD3.","authors":["Yide Liu","Haijiang Sun","Xiaowen Zhang","Qiaoyuan Liu","Zhouchang Chen","Chongzhuo Xiao"],"url":"https://arxiv.org/abs/2504.13026"}
{"created":"2025-04-18","title":"Degrees of Freedom of Holographic MIMO -- Fundamental Theory and Analytical Methods","abstract":"Holographic multiple-input multiple-output (MIMO) is envisioned as one of the most promising technology enablers for future sixth-generation (6G) networks. The use of electrically large holographic surface (HoloS) antennas has the potential to significantly boost the spatial multiplexing gain by increasing the number of degrees of freedom (DoF), even in line-of-sight (LoS) channels. In this context, the research community has shown a growing interest in characterizing the fundamental limits of this technology. In this paper, we compare the two analytical methods commonly utilized in the literature for this purpose: the cut-set integral and the self-adjoint operator. We provide a detailed description of both methods and discuss their advantages and limitations.","authors":["Juan Carlos Ruiz-Sicilia","Marco Di Renzo","Placido Mursia","Vincenzo Sciancalepore","Merouane Debbah"],"url":"https://arxiv.org/abs/2504.13031"}
{"created":"2025-04-18","title":"InstructRAG: Leveraging Retrieval-Augmented Generation on Instruction Graphs for LLM-Based Task Planning","abstract":"Recent advancements in large language models (LLMs) have enabled their use as agents for planning complex tasks. Existing methods typically rely on a thought-action-observation (TAO) process to enhance LLM performance, but these approaches are often constrained by the LLMs' limited knowledge of complex tasks. Retrieval-augmented generation (RAG) offers new opportunities by leveraging external databases to ground generation in retrieved information. In this paper, we identify two key challenges (enlargability and transferability) in applying RAG to task planning. We propose InstructRAG, a novel solution within a multi-agent meta-reinforcement learning framework, to address these challenges. InstructRAG includes a graph to organize past instruction paths (sequences of correct actions), an RL-Agent with Reinforcement Learning to expand graph coverage for enlargability, and an ML-Agent with Meta-Learning to improve task generalization for transferability. The two agents are trained end-to-end to optimize overall planning performance. Our experiments on four widely used task planning datasets demonstrate that InstructRAG significantly enhances performance and adapts efficiently to new tasks, achieving up to a 19.2% improvement over the best existing approach.","authors":["Zheng Wang","Shu Xian Teo","Jun Jie Chew","Wei Shi"],"url":"https://arxiv.org/abs/2504.13032"}
{"created":"2025-04-18","title":"Inference-friendly Graph Compression for Graph Neural Networks","abstract":"Graph Neural Networks (GNNs) have demonstrated promising performance in graph analysis. Nevertheless, the inference process of GNNs remains costly, hindering their applications for large graphs. This paper proposes inference-friendly graph compression (IFGC), a graph compression scheme to accelerate GNNs inference. Given a graph $G$ and a GNN $M$, an IFGC computes a small compressed graph $G_c$, to best preserve the inference results of $M$ over $G$, such that the result can be directly inferred by accessing $G_c$ with no or little decompression cost. (1) We characterize IFGC with a class of inference equivalence relation. The relation captures the node pairs in $G$ that are not distinguishable for GNN inference. (2) We introduce three practical specifications of IFGC for representative GNNs: structural preserving compression (SPGC), which computes $G_c$ that can be directly processed by GNN inference without decompression; ($\\alpha$, $r$)-compression, that allows for a configurable trade-off between compression ratio and inference quality, and anchored compression that preserves inference results for specific nodes of interest. For each scheme, we introduce compression and inference algorithms with guarantees of efficiency and quality of the inferred results. We conduct extensive experiments on diverse sets of large-scale graphs, which verifies the effectiveness and efficiency of our graph compression approaches.","authors":["Yangxin Fan","Haolai Che","Yinghui Wu"],"url":"https://arxiv.org/abs/2504.13034"}
{"created":"2025-04-18","title":"Prototypes are Balanced Units for Efficient and Effective Partially Relevant Video Retrieval","abstract":"In a retrieval system, simultaneously achieving search accuracy and efficiency is inherently challenging. This challenge is particularly pronounced in partially relevant video retrieval (PRVR), where incorporating more diverse context representations at varying temporal scales for each video enhances accuracy but increases computational and memory costs. To address this dichotomy, we propose a prototypical PRVR framework that encodes diverse contexts within a video into a fixed number of prototypes. We then introduce several strategies to enhance text association and video understanding within the prototypes, along with an orthogonal objective to ensure that the prototypes capture a diverse range of content. To keep the prototypes searchable via text queries while accurately encoding video contexts, we implement cross- and uni-modal reconstruction tasks. The cross-modal reconstruction task aligns the prototypes with textual features within a shared space, while the uni-modal reconstruction task preserves all video contexts during encoding. Additionally, we employ a video mixing technique to provide weak guidance to further align prototypes and associated textual representations. Extensive evaluations on TVR, ActivityNet-Captions, and QVHighlights validate the effectiveness of our approach without sacrificing efficiency.","authors":["WonJun Moon","Cheol-Ho Cho","Woojin Jun","Minho Shim","Taeoh Kim","Inwoong Lee","Dongyoon Wee","Jae-Pil Heo"],"url":"https://arxiv.org/abs/2504.13035"}
{"created":"2025-04-18","title":"A generalized energy-based modeling framework with application to field/circuit coupled problems","abstract":"This paper presents a generalized energy-based modeling framework extending recent formulations tailored for differential-algebraic equations. The proposed structure, inspired by the port-Hamiltonian formalism, ensures passivity, preserves the power balance, and facilitates the consistent interconnection of subsystems. A particular focus is put on low-frequency power applications in electrical engineering. Stranded, solid, and foil conductor models are investigated in the context of the eddy current problem. Each conductor model is shown to fit into the generalized energy-based structure, which allows their structure-preserving coupling with electrical circuits described by modified nodal analysis. Theoretical developments are validated through a numerical simulation of an oscillator circuit, demonstrating energy conservation in lossless scenarios and controlled dissipation when eddy currents are present.","authors":["Robert Altmann","Idoia Cortes Garcia","Elias Paakkunainen","Philipp Schulze","Sebastian Sch\\\"ops"],"url":"https://arxiv.org/abs/2504.13036"}
{"created":"2025-04-18","title":"How Large Language Models Are Changing MOOC Essay Answers: A Comparison of Pre- and Post-LLM Responses","abstract":"The release of ChatGPT in late 2022 caused a flurry of activity and concern in the academic and educational communities. Some see the tool's ability to generate human-like text that passes at least cursory inspections for factual accuracy ``often enough'' a golden age of information retrieval and computer-assisted learning. Some, on the other hand, worry the tool may lead to unprecedented levels of academic dishonesty and cheating. In this work, we quantify some of the effects of the emergence of Large Language Models (LLMs) on online education by analyzing a multi-year dataset of student essay responses from a free university-level MOOC on AI ethics. Our dataset includes essays submitted both before and after ChatGPT's release. We find that the launch of ChatGPT coincided with significant changes in both the length and style of student essays, mirroring observations in other contexts such as academic publishing. We also observe -- as expected based on related public discourse -- changes in prevalence of key content words related to AI and LLMs, but not necessarily the general themes or topics discussed in the student essays as identified through (dynamic) topic modeling.","authors":["Leo Lepp\\\"anen","Lili Aunimo","Arto Hellas","Jukka K. Nurminen","Linda Mannila"],"url":"https://arxiv.org/abs/2504.13038"}
{"created":"2025-04-18","title":"Event-Enhanced Blurry Video Super-Resolution","abstract":"In this paper, we tackle the task of blurry video super-resolution (BVSR), aiming to generate high-resolution (HR) videos from low-resolution (LR) and blurry inputs. Current BVSR methods often fail to restore sharp details at high resolutions, resulting in noticeable artifacts and jitter due to insufficient motion information for deconvolution and the lack of high-frequency details in LR frames. To address these challenges, we introduce event signals into BVSR and propose a novel event-enhanced network, Ev-DeblurVSR. To effectively fuse information from frames and events for feature deblurring, we introduce a reciprocal feature deblurring module that leverages motion information from intra-frame events to deblur frame features while reciprocally using global scene context from the frames to enhance event features. Furthermore, to enhance temporal consistency, we propose a hybrid deformable alignment module that fully exploits the complementary motion information from inter-frame events and optical flow to improve motion estimation in the deformable alignment process. Extensive evaluations demonstrate that Ev-DeblurVSR establishes a new state-of-the-art performance on both synthetic and real-world datasets. Notably, on real data, our method is +2.59 dB more accurate and 7.28$\\times$ faster than the recent best BVSR baseline FMA-Net. Code: https://github.com/DachunKai/Ev-DeblurVSR.","authors":["Dachun Kai","Yueyi Zhang","Jin Wang","Zeyu Xiao","Zhiwei Xiong","Xiaoyan Sun"],"url":"https://arxiv.org/abs/2504.13042"}
{"created":"2025-04-18","title":"Expert Kernel Generation Network Driven by Contextual Mapping for Hyperspectral Image Classification","abstract":"Deep neural networks face several challenges in hyperspectral image classification, including high-dimensional data, sparse distribution of ground objects, and spectral redundancy, which often lead to classification overfitting and limited generalization capability. To more efficiently adapt to ground object distributions while extracting image features without introducing excessive parameters and skipping redundant information, this paper proposes EKGNet based on an improved 3D-DenseNet model, consisting of a context-aware mapping network and a dynamic kernel generation module. The context-aware mapping module translates global contextual information of hyperspectral inputs into instructions for combining base convolutional kernels, while the dynamic kernels are composed of K groups of base convolutions, analogous to K different types of experts specializing in fundamental patterns across various dimensions. The mapping module and dynamic kernel generation mechanism form a tightly coupled system - the former generates meaningful combination weights based on inputs, while the latter constructs an adaptive expert convolution system using these weights. This dynamic approach enables the model to focus more flexibly on key spatial structures when processing different regions, rather than relying on the fixed receptive field of a single static convolutional kernel. EKGNet enhances model representation capability through a 3D dynamic expert convolution system without increasing network depth or width. The proposed method demonstrates superior performance on IN, UP, and KSC datasets, outperforming mainstream hyperspectral image classification approaches.","authors":["Guandong Li","Mengxia Ye"],"url":"https://arxiv.org/abs/2504.13045"}
{"created":"2025-04-18","title":"GraphAttack: Exploiting Representational Blindspots in LLM Safety Mechanisms","abstract":"Large Language Models (LLMs) have been equipped with safety mechanisms to prevent harmful outputs, but these guardrails can often be bypassed through \"jailbreak\" prompts. This paper introduces a novel graph-based approach to systematically generate jailbreak prompts through semantic transformations. We represent malicious prompts as nodes in a graph structure with edges denoting different transformations, leveraging Abstract Meaning Representation (AMR) and Resource Description Framework (RDF) to parse user goals into semantic components that can be manipulated to evade safety filters. We demonstrate a particularly effective exploitation vector by instructing LLMs to generate code that realizes the intent described in these semantic graphs, achieving success rates of up to 87% against leading commercial LLMs. Our analysis reveals that contextual framing and abstraction are particularly effective at circumventing safety measures, highlighting critical gaps in current safety alignment techniques that focus primarily on surface-level patterns. These findings provide insights for developing more robust safeguards against structured semantic attacks. Our research contributes both a theoretical framework and practical methodology for systematically stress-testing LLM safety mechanisms.","authors":["Sinan He","An Wang"],"url":"https://arxiv.org/abs/2504.13052"}
{"created":"2025-04-18","title":"Aspect-Based Summarization with Self-Aspect Retrieval Enhanced Generation","abstract":"Aspect-based summarization aims to generate summaries tailored to specific aspects, addressing the resource constraints and limited generalizability of traditional summarization approaches. Recently, large language models have shown promise in this task without the need for training. However, they rely excessively on prompt engineering and face token limits and hallucination challenges, especially with in-context learning. To address these challenges, in this paper, we propose a novel framework for aspect-based summarization: Self-Aspect Retrieval Enhanced Summary Generation. Rather than relying solely on in-context learning, given an aspect, we employ an embedding-driven retrieval mechanism to identify its relevant text segments. This approach extracts the pertinent content while avoiding unnecessary details, thereby mitigating the challenge of token limits. Moreover, our framework optimizes token usage by deleting unrelated parts of the text and ensuring that the model generates output strictly based on the given aspect. With extensive experiments on benchmark datasets, we demonstrate that our framework not only achieves superior performance but also effectively mitigates the token limitation problem.","authors":["Yichao Feng","Shuai Zhao","Yueqiu Li","Luwei Xiao","Xiaobao Wu","Anh Tuan Luu"],"url":"https://arxiv.org/abs/2504.13054"}
{"created":"2025-04-18","title":"NoisyRollout: Reinforcing Visual Reasoning with Data Augmentation","abstract":"Recent advances in reinforcement learning (RL) have strengthened the reasoning capabilities of vision-language models (VLMs). However, enhancing policy exploration to more effectively scale test-time compute remains underexplored in VLMs. In addition, VLMs continue to struggle with imperfect visual perception, which in turn affects the subsequent reasoning process. To this end, we propose NoisyRollout, a simple yet effective RL approach that mixes trajectories from both clean and moderately distorted images to introduce targeted diversity in visual perception and the resulting reasoning patterns. Without additional training cost, NoisyRollout enhances the exploration capabilities of VLMs by incorporating a vision-oriented inductive bias. Furthermore, NoisyRollout employs a noise annealing schedule that gradually reduces distortion strength over training, ensuring benefit from noisy signals early while maintaining training stability and scalability in later stages. With just 2.1K training samples, NoisyRollout achieves state-of-the-art performance among open-source RL-tuned models on 5 out-of-domain benchmarks spanning both reasoning and perception tasks, while preserving comparable or even better in-domain performance.","authors":["Xiangyan Liu","Jinjie Ni","Zijian Wu","Chao Du","Longxu Dou","Haonan Wang","Tianyu Pang","Michael Qizhe Shieh"],"url":"https://arxiv.org/abs/2504.13055"}
{"created":"2025-04-18","title":"Adaptive Task Space Non-Singular Terminal Super-Twisting Sliding Mode Control of a 7-DOF Robotic Manipulator","abstract":"This paper presents a new task-space Non-singular Terminal Super-Twisting Sliding Mode (NT-STSM) controller with adaptive gains for robust trajectory tracking of a 7-DOF robotic manipulator. The proposed approach addresses the challenges of chattering, unknown disturbances, and rotational motion tracking, making it suited for high-DOF manipulators in dexterous manipulation tasks. A rigorous boundedness proof is provided, offering gain selection guidelines for practical implementation. Simulations and hardware experiments with external disturbances demonstrate the proposed controller's robust, accurate tracking with reduced control effort under unknown disturbances compared to other NT-STSM and conventional controllers. The results demonstrated that the proposed NT-STSM controller mitigates chattering and instability in complex motions, making it a viable solution for dexterous robotic manipulations and various industrial applications.","authors":["L. Wan (Department of Mechanical Engineering","Dalhousie University","Halifax","NS","Canada)","S. Smith (Department of Mechanical Engineering","Dalhousie University","Halifax","NS","Canada","GIPSA-lab CNRS","University of Grenoble Alpes","Grenoble","France)","Y. -J. Pan (Department of Mechanical Engineering","Dalhousie University","Halifax","NS","Canada)","E. Witrant (Department of Mechanical Engineering","Dalhousie University","Halifax","NS","Canada","GIPSA-lab CNRS","University of Grenoble Alpes","Grenoble","France)"],"url":"https://arxiv.org/abs/2504.13056"}
{"created":"2025-04-18","title":"Neurodiversity in Computing Education Research: A Systematic Literature Review","abstract":"Ensuring equitable access to computing education for all students-including those with autism, dyslexia, or ADHD-is essential to developing a diverse and inclusive workforce. To understand the state of disability research in computing education, we conducted a systematic literature review of research on neurodiversity in computing education. Our search resulted in 1,943 total papers, which we filtered to 14 papers based on our inclusion criteria. Our mixed-methods approach analyzed research methods, participants, contribution types, and findings. The three main contribution types included empirical contributions based on user studies (57.1%), opinion contributions and position papers (50%), and survey contributions (21.4%). Interviews were the most common methodology (75% of empirical contributions). There were often inconsistencies in how research methods were described (e.g., number of participants and interview and survey materials). Our work shows that research on neurodivergence in computing education is still very preliminary. Most papers provided curricular recommendations that lacked empirical evidence to support those recommendations. Three areas of future work include investigating the impacts of active learning, increasing awareness and knowledge about neurodiverse students' experiences, and engaging neurodivergent students in the design of pedagogical materials and computing education research.","authors":["Cynthia Zastudil","David H. Smith IV","Yusef Tohamy","Rayhona Nasimova","Gavin Montross","Stephen MacNeil"],"url":"https://arxiv.org/abs/2504.13058"}
{"created":"2025-04-18","title":"RoboTwin: Dual-Arm Robot Benchmark with Generative Digital Twins","abstract":"In the rapidly advancing field of robotics, dual-arm coordination and complex object manipulation are essential capabilities for developing advanced autonomous systems. However, the scarcity of diverse, high-quality demonstration data and real-world-aligned evaluation benchmarks severely limits such development. To address this, we introduce RoboTwin, a generative digital twin framework that uses 3D generative foundation models and large language models to produce diverse expert datasets and provide a real-world-aligned evaluation platform for dual-arm robotic tasks. Specifically, RoboTwin creates varied digital twins of objects from single 2D images, generating realistic and interactive scenarios. It also introduces a spatial relation-aware code generation framework that combines object annotations with large language models to break down tasks, determine spatial constraints, and generate precise robotic movement code. Our framework offers a comprehensive benchmark with both simulated and real-world data, enabling standardized evaluation and better alignment between simulated training and real-world performance. We validated our approach using the open-source COBOT Magic Robot platform. Policies pre-trained on RoboTwin-generated data and fine-tuned with limited real-world samples demonstrate significant potential for enhancing dual-arm robotic manipulation systems by improving success rates by over 70% for single-arm tasks and over 40% for dual-arm tasks compared to models trained solely on real-world data.","authors":["Yao Mu","Tianxing Chen","Zanxin Chen","Shijia Peng","Zhiqian Lan","Zeyu Gao","Zhixuan Liang","Qiaojun Yu","Yude Zou","Mingkun Xu","Lunkai Lin","Zhiqiang Xie","Mingyu Ding","Ping Luo"],"url":"https://arxiv.org/abs/2504.13059"}
{"created":"2025-04-18","title":"Imaging for All-Day Wearable Smart Glasses","abstract":"In recent years smart glasses technology has rapidly advanced, opening up entirely new areas for mobile computing. We expect future smart glasses will need to be all-day wearable, adopting a small form factor to meet the requirements of volume, weight, fashionability and social acceptability, which puts significant constraints on the space of possible solutions. Additional challenges arise due to the fact that smart glasses are worn in arbitrary environments while their wearer moves and performs everyday activities. In this paper, we systematically analyze the space of imaging from smart glasses and derive several fundamental limits that govern this imaging domain. We discuss the impact of these limits on achievable image quality and camera module size -- comparing in particular to related devices such as mobile phones. We then propose a novel distributed imaging approach that allows to minimize the size of the individual camera modules when compared to a standard monolithic camera design. Finally, we demonstrate the properties of this novel approach in a series of experiments using synthetic data as well as images captured with two different prototype implementations.","authors":["Michael Goesele","Daniel Andersen","Yujia Chen","Simon Green","Eddy Ilg","Chao Li","Johnson Liu","Grace Kuo","Logan Wan","Richard Newcombe"],"url":"https://arxiv.org/abs/2504.13060"}
{"created":"2025-04-18","title":"ArtistAuditor: Auditing Artist Style Pirate in Text-to-Image Generation Models","abstract":"Text-to-image models based on diffusion processes, such as DALL-E, Stable Diffusion, and Midjourney, are capable of transforming texts into detailed images and have widespread applications in art and design. As such, amateur users can easily imitate professional-level paintings by collecting an artist's work and fine-tuning the model, leading to concerns about artworks' copyright infringement. To tackle these issues, previous studies either add visually imperceptible perturbation to the artwork to change its underlying styles (perturbation-based methods) or embed post-training detectable watermarks in the artwork (watermark-based methods). However, when the artwork or the model has been published online, i.e., modification to the original artwork or model retraining is not feasible, these strategies might not be viable.","authors":["Linkang Du","Zheng Zhu","Min Chen","Zhou Su","Shouling Ji","Peng Cheng","Jiming Chen","Zhikun Zhang"],"url":"https://arxiv.org/abs/2504.13061"}
{"created":"2025-04-18","title":"EchoWorld: Learning Motion-Aware World Models for Echocardiography Probe Guidance","abstract":"Echocardiography is crucial for cardiovascular disease detection but relies heavily on experienced sonographers. Echocardiography probe guidance systems, which provide real-time movement instructions for acquiring standard plane images, offer a promising solution for AI-assisted or fully autonomous scanning. However, developing effective machine learning models for this task remains challenging, as they must grasp heart anatomy and the intricate interplay between probe motion and visual signals. To address this, we present EchoWorld, a motion-aware world modeling framework for probe guidance that encodes anatomical knowledge and motion-induced visual dynamics, while effectively leveraging past visual-motion sequences to enhance guidance precision. EchoWorld employs a pre-training strategy inspired by world modeling principles, where the model predicts masked anatomical regions and simulates the visual outcomes of probe adjustments. Built upon this pre-trained model, we introduce a motion-aware attention mechanism in the fine-tuning stage that effectively integrates historical visual-motion data, enabling precise and adaptive probe guidance. Trained on more than one million ultrasound images from over 200 routine scans, EchoWorld effectively captures key echocardiographic knowledge, as validated by qualitative analysis. Moreover, our method significantly reduces guidance errors compared to existing visual backbones and guidance frameworks, excelling in both single-frame and sequential evaluation protocols. Code is available at https://github.com/LeapLabTHU/EchoWorld.","authors":["Yang Yue","Yulin Wang","Haojun Jiang","Pan Liu","Shiji Song","Gao Huang"],"url":"https://arxiv.org/abs/2504.13065"}
{"created":"2025-04-18","title":"Accuracy is Not Agreement: Expert-Aligned Evaluation of Crash Narrative Classification Models","abstract":"This study explores the relationship between deep learning (DL) model accuracy and expert agreement in the classification of crash narratives. We evaluate five DL models -- including BERT variants, the Universal Sentence Encoder (USE), and a zero-shot classifier -- against expert-labeled data and narrative text. The analysis is further extended to four large language models (LLMs): GPT-4, LLaMA 3, Qwen, and Claude. Our results reveal a counterintuitive trend: models with higher technical accuracy often exhibit lower agreement with domain experts, whereas LLMs demonstrate greater expert alignment despite relatively lower accuracy scores. To quantify and interpret model-expert agreement, we employ Cohen's Kappa, Principal Component Analysis (PCA), and SHAP-based explainability techniques. Findings indicate that expert-aligned models tend to rely more on contextual and temporal language cues, rather than location-specific keywords. These results underscore that accuracy alone is insufficient for evaluating models in safety-critical NLP applications. We advocate for incorporating expert agreement as a complementary metric in model evaluation frameworks and highlight the promise of LLMs as interpretable, scalable tools for crash analysis pipelines.","authors":["Sudesh Ramesh Bhagat","Ibne Farabi Shihab","Anuj Sharma"],"url":"https://arxiv.org/abs/2504.13068"}
{"created":"2025-04-18","title":"Early Accessibility: Automating Alt-Text Generation for UI Icons During App Development","abstract":"Alt-text is essential for mobile app accessibility, yet UI icons often lack meaningful descriptions, limiting accessibility for screen reader users. Existing approaches either require extensive labeled datasets, struggle with partial UI contexts, or operate post-development, increasing technical debt. We first conduct a formative study to determine when and how developers prefer to generate icon alt-text. We then explore the ALTICON approach for generating alt-text for UI icons during development using two fine-tuned models: a text-only large language model that processes extracted UI metadata and a multi-modal model that jointly analyzes icon images and textual context. To improve accuracy, the method extracts relevant UI information from the DOM tree, retrieves in-icon text via OCR, and applies structured prompts for alt-text generation. Our empirical evaluation with the most closely related deep-learning and vision-language models shows that ALTICON generates alt-text that is of higher quality while not requiring a full-screen input.","authors":["Sabrina Haque","Christoph Csallner"],"url":"https://arxiv.org/abs/2504.13069"}
{"created":"2025-04-18","title":"HiScene: Creating Hierarchical 3D Scenes with Isometric View Generation","abstract":"Scene-level 3D generation represents a critical frontier in multimedia and computer graphics, yet existing approaches either suffer from limited object categories or lack editing flexibility for interactive applications. In this paper, we present HiScene, a novel hierarchical framework that bridges the gap between 2D image generation and 3D object generation and delivers high-fidelity scenes with compositional identities and aesthetic scene content. Our key insight is treating scenes as hierarchical \"objects\" under isometric views, where a room functions as a complex object that can be further decomposed into manipulatable items. This hierarchical approach enables us to generate 3D content that aligns with 2D representations while maintaining compositional structure. To ensure completeness and spatial alignment of each decomposed instance, we develop a video-diffusion-based amodal completion technique that effectively handles occlusions and shadows between objects, and introduce shape prior injection to ensure spatial coherence within the scene. Experimental results demonstrate that our method produces more natural object arrangements and complete object instances suitable for interactive applications, while maintaining physical plausibility and alignment with user inputs.","authors":["Wenqi Dong","Bangbang Yang","Zesong Yang","Yuan Li","Tao Hu","Hujun Bao","Yuewen Ma","Zhaopeng Cui"],"url":"https://arxiv.org/abs/2504.13072"}
{"created":"2025-04-18","title":"SkyReels-V2: Infinite-length Film Generative Model","abstract":"Recent advances in video generation have been driven by diffusion models and autoregressive frameworks, yet critical challenges persist in harmonizing prompt adherence, visual quality, motion dynamics, and duration: compromises in motion dynamics to enhance temporal visual quality, constrained video duration (5-10 seconds) to prioritize resolution, and inadequate shot-aware generation stemming from general-purpose MLLMs' inability to interpret cinematic grammar, such as shot composition, actor expressions, and camera motions. These intertwined limitations hinder realistic long-form synthesis and professional film-style generation. To address these limitations, we propose SkyReels-V2, an Infinite-length Film Generative Model, that synergizes Multi-modal Large Language Model (MLLM), Multi-stage Pretraining, Reinforcement Learning, and Diffusion Forcing Framework. Firstly, we design a comprehensive structural representation of video that combines the general descriptions by the Multi-modal LLM and the detailed shot language by sub-expert models. Aided with human annotation, we then train a unified Video Captioner, named SkyCaptioner-V1, to efficiently label the video data. Secondly, we establish progressive-resolution pretraining for the fundamental video generation, followed by a four-stage post-training enhancement: Initial concept-balanced Supervised Fine-Tuning (SFT) improves baseline quality; Motion-specific Reinforcement Learning (RL) training with human-annotated and synthetic distortion data addresses dynamic artifacts; Our diffusion forcing framework with non-decreasing noise schedules enables long-video synthesis in an efficient search space; Final high-quality SFT refines visual fidelity. All the code and models are available at https://github.com/SkyworkAI/SkyReels-V2.","authors":["Guibin Chen","Dixuan Lin","Jiangping Yang","Chunze Lin","Juncheng Zhu","Mingyuan Fan","Hao Zhang","Sheng Chen","Zheng Chen","Chengchen Ma","Weiming Xiong","Wei Wang","Nuo Pang","Kang Kang","Zhiheng Xu","Yuzhe Jin","Yupeng Liang","Yubing Song","Peng Zhao","Boyuan Xu","Di Qiu","Debang Li","Zhengcong Fei","Yang Li","Yahui Zhou"],"url":"https://arxiv.org/abs/2504.13074"}
{"created":"2025-04-18","title":"An All-Atom Generative Model for Designing Protein Complexes","abstract":"Proteins typically exist in complexes, interacting with other proteins or biomolecules to perform their specific biological roles. Research on single-chain protein modeling has been extensively and deeply explored, with advancements seen in models like the series of ESM and AlphaFold. Despite these developments, the study and modeling of multi-chain proteins remain largely uncharted, though they are vital for understanding biological functions. Recognizing the importance of these interactions, we introduce APM (All-Atom Protein Generative Model), a model specifically designed for modeling multi-chain proteins. By integrating atom-level information and leveraging data on multi-chain proteins, APM is capable of precisely modeling inter-chain interactions and designing protein complexes with binding capabilities from scratch. It also performs folding and inverse-folding tasks for multi-chain proteins. Moreover, APM demonstrates versatility in downstream applications: it achieves enhanced performance through supervised fine-tuning (SFT) while also supporting zero-shot sampling in certain tasks, achieving state-of-the-art results. Code will be released at https://github.com/bytedance/apm.","authors":["Ruizhe Chen","Dongyu Xue","Xiangxin Zhou","Zaixiang Zheng","Xiangxiang Zeng","Quanquan Gu"],"url":"https://arxiv.org/abs/2504.13075"}
{"created":"2025-04-18","title":"Effective Dual-Region Augmentation for Reduced Reliance on Large Amounts of Labeled Data","abstract":"This paper introduces a novel dual-region augmentation approach designed to reduce reliance on large-scale labeled datasets while improving model robustness and adaptability across diverse computer vision tasks, including source-free domain adaptation (SFDA) and person re-identification (ReID). Our method performs targeted data transformations by applying random noise perturbations to foreground objects and spatially shuffling background patches. This effectively increases the diversity of the training data, improving model robustness and generalization. Evaluations on the PACS dataset for SFDA demonstrate that our augmentation strategy consistently outperforms existing methods, achieving significant accuracy improvements in both single-target and multi-target adaptation settings. By augmenting training data through structured transformations, our method enables model generalization across domains, providing a scalable solution for reducing reliance on manually annotated datasets. Furthermore, experiments on Market-1501 and DukeMTMC-reID datasets validate the effectiveness of our approach for person ReID, surpassing traditional augmentation techniques.","authors":["Prasanna Reddy Pulakurthi","Majid Rabbani","Celso M. de Melo","Sohail A. Dianat","Raghuveer M. Rao"],"url":"https://arxiv.org/abs/2504.13077"}
{"created":"2025-04-18","title":"Enhancing Person-to-Person Virtual Try-On with Multi-Garment Virtual Try-Off","abstract":"Computer vision is transforming fashion through Virtual Try-On (VTON) and Virtual Try-Off (VTOFF). VTON generates images of a person in a specified garment using a target photo and a standardized garment image, while a more challenging variant, Person-to-Person Virtual Try-On (p2p-VTON), uses a photo of another person wearing the garment. VTOFF, on the other hand, extracts standardized garment images from clothed individuals. We introduce TryOffDiff, a diffusion-based VTOFF model. Built on a latent diffusion framework with SigLIP image conditioning, it effectively captures garment properties like texture, shape, and patterns. TryOffDiff achieves state-of-the-art results on VITON-HD and strong performance on DressCode dataset, covering upper-body, lower-body, and dresses. Enhanced with class-specific embeddings, it pioneers multi-garment VTOFF, the first of its kind. When paired with VTON models, it improves p2p-VTON by minimizing unwanted attribute transfer, such as skin color. Code is available at: https://rizavelioglu.github.io/tryoffdiff/","authors":["Riza Velioglu","Petra Bevandic","Robin Chan","Barbara Hammer"],"url":"https://arxiv.org/abs/2504.13078"}
{"created":"2025-04-18","title":"Retrieval-Augmented Generation with Conflicting Evidence","abstract":"Large language model (LLM) agents are increasingly employing retrieval-augmented generation (RAG) to improve the factuality of their responses. However, in practice, these systems often need to handle ambiguous user queries and potentially conflicting information from multiple sources while also suppressing inaccurate information from noisy or irrelevant documents. Prior work has generally studied and addressed these challenges in isolation, considering only one aspect at a time, such as handling ambiguity or robustness to noise and misinformation. We instead consider multiple factors simultaneously, proposing (i) RAMDocs (Retrieval with Ambiguity and Misinformation in Documents), a new dataset that simulates complex and realistic scenarios for conflicting evidence for a user query, including ambiguity, misinformation, and noise; and (ii) MADAM-RAG, a multi-agent approach in which LLM agents debate over the merits of an answer over multiple rounds, allowing an aggregator to collate responses corresponding to disambiguated entities while discarding misinformation and noise, thereby handling diverse sources of conflict jointly. We demonstrate the effectiveness of MADAM-RAG using both closed and open-source models on AmbigDocs -- which requires presenting all valid answers for ambiguous queries -- improving over strong RAG baselines by up to 11.40% and on FaithEval -- which requires suppressing misinformation -- where we improve by up to 15.80% (absolute) with Llama3.3-70B-Instruct. Furthermore, we find that RAMDocs poses a challenge for existing RAG baselines (Llama3.3-70B-Instruct only obtains 32.60 exact match score). While MADAM-RAG begins to address these conflicting factors, our analysis indicates that a substantial gap remains especially when increasing the level of imbalance in supporting evidence and misinformation.","authors":["Han Wang","Archiki Prasad","Elias Stengel-Eskin","Mohit Bansal"],"url":"https://arxiv.org/abs/2504.13079"}
{"created":"2025-04-18","title":"Tackling Social Bias against the Poor: A Dataset and Taxonomy on Aporophobia","abstract":"Eradicating poverty is the first goal in the United Nations Sustainable Development Goals. However, aporophobia -- the societal bias against people living in poverty -- constitutes a major obstacle to designing, approving and implementing poverty-mitigation policies. This work presents an initial step towards operationalizing the concept of aporophobia to identify and track harmful beliefs and discriminative actions against poor people on social media. In close collaboration with non-profits and governmental organizations, we conduct data collection and exploration. Then we manually annotate a corpus of English tweets from five world regions for the presence of (1) direct expressions of aporophobia, and (2) statements referring to or criticizing aporophobic views or actions of others, to comprehensively characterize the social media discourse related to bias and discrimination against the poor. Based on the annotated data, we devise a taxonomy of categories of aporophobic attitudes and actions expressed through speech on social media. Finally, we train several classifiers and identify the main challenges for automatic detection of aporophobia in social networks. This work paves the way towards identifying, tracking, and mitigating aporophobic views on social media at scale.","authors":["Georgina Curto","Svetlana Kiritchenko","Muhammad Hammad Fahim Siddiqui","Isar Nejadgholi","Kathleen C. Fraser"],"url":"https://arxiv.org/abs/2504.13085"}
{"created":"2025-04-18","title":"Imperative MPC: An End-to-End Self-Supervised Learning with Differentiable MPC for UAV Attitude Control","abstract":"Modeling and control of nonlinear dynamics are critical in robotics, especially in scenarios with unpredictable external influences and complex dynamics. Traditional cascaded modular control pipelines often yield suboptimal performance due to conservative assumptions and tedious parameter tuning. Pure data-driven approaches promise robust performance but suffer from low sample efficiency, sim-to-real gaps, and reliance on extensive datasets. Hybrid methods combining learning-based and traditional model-based control in an end-to-end manner offer a promising alternative. This work presents a self-supervised learning framework combining learning-based inertial odometry (IO) module and differentiable model predictive control (d-MPC) for Unmanned Aerial Vehicle (UAV) attitude control. The IO denoises raw IMU measurements and predicts UAV attitudes, which are then optimized by MPC for control actions in a bi-level optimization (BLO) setup, where the inner MPC optimizes control actions and the upper level minimizes discrepancy between real-world and predicted performance. The framework is thus end-to-end and can be trained in a self-supervised manner. This approach combines the strength of learning-based perception with the interpretable model-based control. Results show the effectiveness even under strong wind. It can simultaneously enhance both the MPC parameter learning and IMU prediction performance.","authors":["Haonan He","Yuheng Qiu","Junyi Geng"],"url":"https://arxiv.org/abs/2504.13088"}
{"created":"2025-04-18","title":"EventVAD: Training-Free Event-Aware Video Anomaly Detection","abstract":"Video Anomaly Detection~(VAD) focuses on identifying anomalies within videos. Supervised methods require an amount of in-domain training data and often struggle to generalize to unseen anomalies. In contrast, training-free methods leverage the intrinsic world knowledge of large language models (LLMs) to detect anomalies but face challenges in localizing fine-grained visual transitions and diverse events. Therefore, we propose EventVAD, an event-aware video anomaly detection framework that combines tailored dynamic graph architectures and multimodal LLMs through temporal-event reasoning. Specifically, EventVAD first employs dynamic spatiotemporal graph modeling with time-decay constraints to capture event-aware video features. Then, it performs adaptive noise filtering and uses signal ratio thresholding to detect event boundaries via unsupervised statistical features. The statistical boundary detection module reduces the complexity of processing long videos for MLLMs and improves their temporal reasoning through event consistency. Finally, it utilizes a hierarchical prompting strategy to guide MLLMs in performing reasoning before determining final decisions. We conducted extensive experiments on the UCF-Crime and XD-Violence datasets. The results demonstrate that EventVAD with a 7B MLLM achieves state-of-the-art (SOTA) in training-free settings, outperforming strong baselines that use 7B or larger MLLMs.","authors":["Yihua Shao","Haojin He","Sijie Li","Siyu Chen","Xinwei Long","Fanhu Zeng","Yuxuan Fan","Muyang Zhang","Ziyang Yan","Ao Ma","Xiaochen Wang","Hao Tang","Yan Wang","Shuyan Li"],"url":"https://arxiv.org/abs/2504.13092"}
{"created":"2025-04-18","title":"Should We Tailor the Talk? Understanding the Impact of Conversational Styles on Preference Elicitation in Conversational Recommender Systems","abstract":"Conversational recommender systems (CRSs) provide users with an interactive means to express preferences and receive real-time personalized recommendations. The success of these systems is heavily influenced by the preference elicitation process. While existing research mainly focuses on what questions to ask during preference elicitation, there is a notable gap in understanding what role broader interaction patterns including tone, pacing, and level of proactiveness play in supporting users in completing a given task. This study investigates the impact of different conversational styles on preference elicitation, task performance, and user satisfaction with CRSs. We conducted a controlled experiment in the context of scientific literature recommendation, contrasting two distinct conversational styles, high involvement (fast paced, direct, and proactive with frequent prompts) and high considerateness (polite and accommodating, prioritizing clarity and user comfort) alongside a flexible experimental condition where users could switch between the two. Our results indicate that adapting conversational strategies based on user expertise and allowing flexibility between styles can enhance both user satisfaction and the effectiveness of recommendations in CRSs. Overall, our findings hold important implications for the design of future CRSs.","authors":["Ivica Kostric","Krisztian Balog","Ujwal Gadiraju"],"url":"https://arxiv.org/abs/2504.13095"}
{"created":"2025-04-18","title":"RF-DETR Object Detection vs YOLOv12 : A Study of Transformer-based and CNN-based Architectures for Single-Class and Multi-Class Greenfruit Detection in Complex Orchard Environments Under Label Ambiguity","abstract":"This study conducts a detailed comparison of RF-DETR object detection base model and YOLOv12 object detection model configurations for detecting greenfruits in a complex orchard environment marked by label ambiguity, occlusions, and background blending. A custom dataset was developed featuring both single-class (greenfruit) and multi-class (occluded and non-occluded greenfruits) annotations to assess model performance under dynamic real-world conditions. RF-DETR object detection model, utilizing a DINOv2 backbone and deformable attention, excelled in global context modeling, effectively identifying partially occluded or ambiguous greenfruits. In contrast, YOLOv12 leveraged CNN-based attention for enhanced local feature extraction, optimizing it for computational efficiency and edge deployment. RF-DETR achieved the highest mean Average Precision (mAP50) of 0.9464 in single-class detection, proving its superior ability to localize greenfruits in cluttered scenes. Although YOLOv12N recorded the highest mAP@50:95 of 0.7620, RF-DETR consistently outperformed in complex spatial scenarios. For multi-class detection, RF-DETR led with an mAP@50 of 0.8298, showing its capability to differentiate between occluded and non-occluded fruits, while YOLOv12L scored highest in mAP@50:95 with 0.6622, indicating better classification in detailed occlusion contexts. Training dynamics analysis highlighted RF-DETR's swift convergence, particularly in single-class settings where it plateaued within 10 epochs, demonstrating the efficiency of transformer-based architectures in adapting to dynamic visual data. These findings validate RF-DETR's effectiveness for precision agricultural applications, with YOLOv12 suited for fast-response scenarios. >Index Terms: RF-DETR object detection, YOLOv12, YOLOv13, YOLOv14, YOLOv15, YOLOE, YOLO World, YOLO, You Only Look Once, Roboflow, Detection Transformers, CNNs","authors":["Ranjan Sapkota","Rahul Harsha Cheppally","Ajay Sharda","Manoj Karkee"],"url":"https://arxiv.org/abs/2504.13099"}
{"created":"2025-04-18","title":"An Empirically Grounded Identifiability Theory Will Accelerate Self-Supervised Learning Research","abstract":"Self-Supervised Learning (SSL) powers many current AI systems. As research interest and investment grow, the SSL design space continues to expand. The Platonic view of SSL, following the Platonic Representation Hypothesis (PRH), suggests that despite different methods and engineering approaches, all representations converge to the same Platonic ideal. However, this phenomenon lacks precise theoretical explanation. By synthesizing evidence from Identifiability Theory (IT), we show that the PRH can emerge in SSL. However, current IT cannot explain SSL's empirical success. To bridge the gap between theory and practice, we propose expanding IT into what we term Singular Identifiability Theory (SITh), a broader theoretical framework encompassing the entire SSL pipeline. SITh would allow deeper insights into the implicit data assumptions in SSL and advance the field towards learning more interpretable and generalizable representations. We highlight three critical directions for future research: 1) training dynamics and convergence properties of SSL; 2) the impact of finite samples, batch size, and data diversity; and 3) the role of inductive biases in architecture, augmentations, initialization schemes, and optimizers.","authors":["Patrik Reizinger","Randall Balestriero","David Klindt","Wieland Brendel"],"url":"https://arxiv.org/abs/2504.13101"}
{"created":"2025-04-18","title":"A Multi-task Learning Balanced Attention Convolutional Neural Network Model for Few-shot Underwater Acoustic Target Recognition","abstract":"Underwater acoustic target recognition (UATR) is of great significance for the protection of marine diversity and national defense security. The development of deep learning provides new opportunities for UATR, but faces challenges brought by the scarcity of reference samples and complex environmental interference. To address these issues, we proposes a multi-task balanced channel attention convolutional neural network (MT-BCA-CNN). The method integrates a channel attention mechanism with a multi-task learning strategy, constructing a shared feature extractor and multi-task classifiers to jointly optimize target classification and feature reconstruction tasks. The channel attention mechanism dynamically enhances discriminative acoustic features such as harmonic structures while suppressing noise. Experiments on the Watkins Marine Life Dataset demonstrate that MT-BCA-CNN achieves 97\\% classification accuracy and 95\\% $F1$-score in 27-class few-shot scenarios, significantly outperforming traditional CNN and ACNN models, as well as popular state-of-the-art UATR methods. Ablation studies confirm the synergistic benefits of multi-task learning and attention mechanisms, while a dynamic weighting adjustment strategy effectively balances task contributions. This work provides an efficient solution for few-shot underwater acoustic recognition, advancing research in marine bioacoustics and sonar signal processing.","authors":["Wei Huang","Shumeng Sun","Junpeng Lu","Zhenpeng Xu","Zhengyang Xiu","Hao Zhang"],"url":"https://arxiv.org/abs/2504.13102"}
{"created":"2025-04-18","title":"A Bad Example for Jain's Iterative Rounding Theorem for the Cover Small Cuts Problem","abstract":"Jain's iterative rounding theorem is a well-known result in the area of approximation algorithms and, more broadly, in combinatorial optimization. The theorem asserts that LP relaxations of several problems in network design and combinatorial optimization have the following key property: for every basic solution $x$ there exists a variable $x_e$ that has value at least a constant (e.g., $x_e\\geq\\frac12$).","authors":["Miles Simmons (University of Waterloo)","Ishan Bansal (Amazon)","Joe Cheriyan (University of Waterloo)"],"url":"https://arxiv.org/abs/2504.13105"}
{"created":"2025-04-18","title":"UniEdit-Flow: Unleashing Inversion and Editing in the Era of Flow Models","abstract":"Flow matching models have emerged as a strong alternative to diffusion models, but existing inversion and editing methods designed for diffusion are often ineffective or inapplicable to them. The straight-line, non-crossing trajectories of flow models pose challenges for diffusion-based approaches but also open avenues for novel solutions. In this paper, we introduce a predictor-corrector-based framework for inversion and editing in flow models. First, we propose Uni-Inv, an effective inversion method designed for accurate reconstruction. Building on this, we extend the concept of delayed injection to flow models and introduce Uni-Edit, a region-aware, robust image editing approach. Our methodology is tuning-free, model-agnostic, efficient, and effective, enabling diverse edits while ensuring strong preservation of edit-irrelevant regions. Extensive experiments across various generative models demonstrate the superiority and generalizability of Uni-Inv and Uni-Edit, even under low-cost settings. Project page: https://uniedit-flow.github.io/","authors":["Guanlong Jiao","Biqing Huang","Kuan-Chieh Wang","Renjie Liao"],"url":"https://arxiv.org/abs/2504.13109"}
{"created":"2025-04-18","title":"Uncertainty-Aware Trajectory Prediction via Rule-Regularized Heteroscedastic Deep Classification","abstract":"Deep learning-based trajectory prediction models have demonstrated promising capabilities in capturing complex interactions. However, their out-of-distribution generalization remains a significant challenge, particularly due to unbalanced data and a lack of enough data and diversity to ensure robustness and calibration. To address this, we propose SHIFT (Spectral Heteroscedastic Informed Forecasting for Trajectories), a novel framework that uniquely combines well-calibrated uncertainty modeling with informative priors derived through automated rule extraction. SHIFT reformulates trajectory prediction as a classification task and employs heteroscedastic spectral-normalized Gaussian processes to effectively disentangle epistemic and aleatoric uncertainties. We learn informative priors from training labels, which are automatically generated from natural language driving rules, such as stop rules and drivability constraints, using a retrieval-augmented generation framework powered by a large language model. Extensive evaluations over the nuScenes dataset, including challenging low-data and cross-location scenarios, demonstrate that SHIFT outperforms state-of-the-art methods, achieving substantial gains in uncertainty calibration and displacement metrics. In particular, our model excels in complex scenarios, such as intersections, where uncertainty is inherently higher. Project page: https://kumarmanas.github.io/SHIFT/.","authors":["Kumar Manas","Christian Schlauch","Adrian Paschke","Christian Wirth","Nadja Klein"],"url":"https://arxiv.org/abs/2504.13111"}
{"created":"2025-04-18","title":"Hadamard product in deep learning: Introduction, Advances and Challenges","abstract":"While convolution and self-attention mechanisms have dominated architectural design in deep learning, this survey examines a fundamental yet understudied primitive: the Hadamard product. Despite its widespread implementation across various applications, the Hadamard product has not been systematically analyzed as a core architectural primitive. We present the first comprehensive taxonomy of its applications in deep learning, identifying four principal domains: higher-order correlation, multimodal data fusion, dynamic representation modulation, and efficient pairwise operations. The Hadamard product's ability to model nonlinear interactions with linear computational complexity makes it particularly valuable for resource-constrained deployments and edge computing scenarios. We demonstrate its natural applicability in multimodal fusion tasks, such as visual question answering, and its effectiveness in representation masking for applications including image inpainting and pruning. This systematic review not only consolidates existing knowledge about the Hadamard product's role in deep learning architectures but also establishes a foundation for future architectural innovations. Our analysis reveals the Hadamard product as a versatile primitive that offers compelling trade-offs between computational efficiency and representational power, positioning it as a crucial component in the deep learning toolkit.","authors":["Grigorios G Chrysos","Yongtao Wu","Razvan Pascanu","Philip Torr","Volkan Cevher"],"url":"https://arxiv.org/abs/2504.13112"}
{"created":"2025-04-18","title":"Quorum: Zero-Training Unsupervised Anomaly Detection using Quantum Autoencoders","abstract":"Detecting mission-critical anomalous events and data is a crucial challenge across various industries, including finance, healthcare, and energy. Quantum computing has recently emerged as a powerful tool for tackling several machine learning tasks, but training quantum machine learning models remains challenging, particularly due to the difficulty of gradient calculation. The challenge is even greater for anomaly detection, where unsupervised learning methods are essential to ensure practical applicability. To address these issues, we propose Quorum, the first quantum anomaly detection framework designed for unsupervised learning that operates without requiring any training.","authors":["Jason Zev Ludmir","Sophia Rebello","Jacob Ruiz","Tirthak Patel"],"url":"https://arxiv.org/abs/2504.13113"}
{"created":"2025-04-18","title":"Predicting BVD Re-emergence in Irish Cattle From Highly Imbalanced Herd-Level Data Using Machine Learning Algorithms","abstract":"Bovine Viral Diarrhoea (BVD) has been the focus of a successful eradication programme in Ireland, with the herd-level prevalence declining from 11.3% in 2013 to just 0.2% in 2023. As the country moves toward BVD freedom, the development of predictive models for targeted surveillance becomes increasingly important to mitigate the risk of disease re-emergence. In this study, we evaluate the performance of a range of machine learning algorithms, including binary classification and anomaly detection techniques, for predicting BVD-positive herds using highly imbalanced herd-level data. We conduct an extensive simulation study to assess model performance across varying sample sizes and class imbalance ratios, incorporating resampling, class weighting, and appropriate evaluation metrics (sensitivity, positive predictive value, F1-score and AUC values). Random forests and XGBoost models consistently outperformed other methods, with the random forest model achieving the highest sensitivity and AUC across scenarios, including real-world prediction of 2023 herd status, correctly identifying 219 of 250 positive herds while halving the number of herds that require compared to a blanket-testing strategy.","authors":["Niamh Mimnagh","Andrew Parnell","Conor McAloon","Jaden Carlson","Maria Guelbenzu","Jonas Brock","Damien Barrett","Guy McGrath","Jamie Tratalos","Rafael Moral"],"url":"https://arxiv.org/abs/2504.13116"}
{"created":"2025-04-18","title":"Object-Driven Narrative in AR: A Scenario-Metaphor Framework with VLM Integration","abstract":"Most adaptive AR storytelling systems define environmental semantics using simple object labels and spatial coordinates, limiting narratives to rigid, pre-defined logic. This oversimplification overlooks the contextual significance of object relationships-for example, a wedding ring on a nightstand might suggest marital conflict, yet is treated as just \"two objects\" in space. To address this, we explored integrating Vision Language Models (VLMs) into AR pipelines. However, several challenges emerged: First, stories generated with simple prompt guidance lacked narrative depth and spatial usage. Second, spatial semantics were underutilized, failing to support meaningful storytelling. Third, pre-generated scripts struggled to align with AR Foundation's object naming and coordinate systems. We propose a scene-driven AR storytelling framework that reimagines environments as active narrative agents, built on three innovations: 1. State-aware object semantics: We decompose object meaning into physical, functional, and metaphorical layers, allowing VLMs to distinguish subtle narrative cues between similar objects. 2. Structured narrative interface: A bidirectional JSON layer maps VLM-generated metaphors to AR anchors, maintaining spatial and semantic coherence. 3. STAM evaluation framework: A three-part experimental design evaluates narrative quality, highlighting both strengths and limitations of VLM-AR integration. Our findings show that the system can generate stories from the environment itself, not just place them on top of it. In user studies, 70% of participants reported seeing real-world objects differently when narratives were grounded in environmental symbolism. By merging VLMs' generative creativity with AR's spatial precision, this framework introduces a novel object-driven storytelling paradigm, transforming passive spaces into active narrative landscapes.","authors":["Yusi Sun","Haoyan Guan","leith Kin Yep Chan","Yong Hong Kuo"],"url":"https://arxiv.org/abs/2504.13119"}
{"created":"2025-04-18","title":"Probing and Inducing Combinational Creativity in Vision-Language Models","abstract":"The ability to combine existing concepts into novel ideas stands as a fundamental hallmark of human intelligence. Recent advances in Vision-Language Models (VLMs) like GPT-4V and DALLE-3 have sparked debate about whether their outputs reflect combinational creativity--defined by M. A. Boden (1998) as synthesizing novel ideas through combining existing concepts--or sophisticated pattern matching of training data. Drawing inspiration from cognitive science, we investigate the combinational creativity of VLMs from the lens of concept blending. We propose the Identification-Explanation-Implication (IEI) framework, which decomposes creative processes into three levels: identifying input spaces, extracting shared attributes, and deriving novel semantic implications. To validate this framework, we curate CreativeMashup, a high-quality dataset of 666 artist-generated visual mashups annotated according to the IEI framework. Through extensive experiments, we demonstrate that in comprehension tasks, best VLMs have surpassed average human performance while falling short of expert-level understanding; in generation tasks, incorporating our IEI framework into the generation pipeline significantly enhances the creative quality of VLMs outputs. Our findings establish both a theoretical foundation for evaluating artificial creativity and practical guidelines for improving creative generation in VLMs.","authors":["Yongqian Peng","Yuxi Ma","Mengmeng Wang","Yuxuan Wang","Yizhou Wang","Chi Zhang","Yixin Zhu","Zilong Zheng"],"url":"https://arxiv.org/abs/2504.13120"}
{"created":"2025-04-18","title":"VistaDPO: Video Hierarchical Spatial-Temporal Direct Preference Optimization for Large Video Models","abstract":"Large Video Models (LVMs) built upon Large Language Models (LLMs) have shown promise in video understanding but often suffer from misalignment with human intuition and video hallucination issues. To address these challenges, we introduce VistaDPO, a novel framework for Video Hierarchical Spatial-Temporal Direct Preference Optimization. VistaDPO enhances text-video preference alignment across three hierarchical levels: i) Instance Level, aligning overall video content with responses; ii) Temporal Level, aligning video temporal semantics with event descriptions; and iii) Perceptive Level, aligning spatial objects with language tokens. Given the lack of datasets for fine-grained video-language preference alignment, we construct VistaDPO-7k, a dataset of 7.2K QA pairs annotated with chosen and rejected responses, along with spatial-temporal grounding information such as timestamps, keyframes, and bounding boxes. Extensive experiments on benchmarks such as Video Hallucination, Video QA, and Captioning performance tasks demonstrate that VistaDPO significantly improves the performance of existing LVMs, effectively mitigating video-language misalignment and hallucination. The code and data are available at https://github.com/HaroldChen19/VistaDPO.","authors":["Haojian Huang","Haodong Chen","Shengqiong Wu","Meng Luo","Jinlan Fu","Xinya Du","Hanwang Zhang","Hao Fei"],"url":"https://arxiv.org/abs/2504.13122"}
{"created":"2025-04-18","title":"Low-hallucination Synthetic Captions for Large-Scale Vision-Language Model Pre-training","abstract":"In recent years, the field of vision-language model pre-training has experienced rapid advancements, driven primarily by the continuous enhancement of textual capabilities in large language models. However, existing training paradigms for multimodal large language models heavily rely on high-quality image-text pairs. As models and data scales grow exponentially, the availability of such meticulously curated data has become increasingly scarce and saturated, thereby severely limiting further advancements in this domain. This study investigates scalable caption generation techniques for vision-language model pre-training and demonstrates that large-scale low-hallucination synthetic captions can serve dual purposes: 1) acting as a viable alternative to real-world data for pre-training paradigms and 2) achieving superior performance enhancement when integrated into vision-language models through empirical validation. This paper presents three key contributions: 1) a novel pipeline for generating high-quality, low-hallucination, and knowledge-rich synthetic captions. Our continuous DPO methodology yields remarkable results in reducing hallucinations. Specifically, the non-hallucination caption rate on a held-out test set increases from 48.2% to 77.9% for a 7B-size model. 2) Comprehensive empirical validation reveals that our synthetic captions confer superior pre-training advantages over their counterparts. Across 35 vision language tasks, the model trained with our data achieves a significant performance gain of at least 6.2% compared to alt-text pairs and other previous work. Meanwhile, it also offers considerable support in the text-to-image domain. With our dataset, the FID score is reduced by 17.1 on a real-world validation benchmark and 13.3 on the MSCOCO validation benchmark. 3) We will release Hunyuan-Recap100M, a low-hallucination and knowledge-intensive synthetic caption dataset.","authors":["Xinsong Zhang","Yarong Zeng","Xinting Huang","Hu Hu","Runquan Xie","Han Hu","Zhanhui Kang"],"url":"https://arxiv.org/abs/2504.13123"}
{"created":"2025-04-18","title":"LLMs Meet Finance: Fine-Tuning Foundation Models for the Open FinLLM Leaderboard","abstract":"This paper investigates the application of large language models (LLMs) to financial tasks. We fine-tuned foundation models using the Open FinLLM Leaderboard as a benchmark. Building on Qwen2.5 and Deepseek-R1, we employed techniques including supervised fine-tuning (SFT), direct preference optimization (DPO), and reinforcement learning (RL) to enhance their financial capabilities. The fine-tuned models demonstrated substantial performance gains across a wide range of financial tasks. Moreover, we measured the data scaling law in the financial domain. Our work demonstrates the potential of large language models (LLMs) in financial applications.","authors":["Varun Rao","Youran Sun","Mahendra Kumar","Tejas Mutneja","Agastya Mukherjee","Haizhao Yang"],"url":"https://arxiv.org/abs/2504.13125"}
{"created":"2025-04-18","title":"Force and Speed in a Soft Stewart Platform","abstract":"Many soft robots struggle to produce dynamic motions with fast, large displacements. We develop a parallel 6 degree-of-freedom (DoF) Stewart-Gough mechanism using Handed Shearing Auxetic (HSA) actuators. By using soft actuators, we are able to use one third as many mechatronic components as a rigid Stewart platform, while retaining a working payload of 2kg and an open-loop bandwidth greater than 16Hx. We show that the platform is capable of both precise tracing and dynamic disturbance rejection when controlling a ball and sliding puck using a Proportional Integral Derivative (PID) controller. We develop a machine-learning-based kinematics model and demonstrate a functional workspace of roughly 10cm in each translation direction and 28 degrees in each orientation. This 6DoF device has many of the characteristics associated with rigid components - power, speed, and total workspace - while capturing the advantages of soft mechanisms.","authors":["Jake Ketchum","James Avtges","Millicent Schlafly","Helena Young","Taekyoung Kim","Ryan L. Truby","Todd D. Murphey"],"url":"https://arxiv.org/abs/2504.13127"}
{"created":"2025-04-18","title":"FreshStack: Building Realistic Benchmarks for Evaluating Retrieval on Technical Documents","abstract":"We introduce FreshStack, a reusable framework for automatically building information retrieval (IR) evaluation benchmarks from community-asked questions and answers. FreshStack conducts the following steps: (1) automatic corpus collection from code and technical documentation, (2) nugget generation from community-asked questions and answers, and (3) nugget-level support, retrieving documents using a fusion of retrieval techniques and hybrid architectures. We use FreshStack to build five datasets on fast-growing, recent, and niche topics to ensure the tasks are sufficiently challenging. On FreshStack, existing retrieval models, when applied out-of-the-box, significantly underperform oracle approaches on all five topics, denoting plenty of headroom to improve IR quality. In addition, we identify cases where rerankers do not clearly improve first-stage retrieval accuracy (two out of five topics). We hope that FreshStack will facilitate future work toward constructing realistic, scalable, and uncontaminated IR and RAG evaluation benchmarks. FreshStack datasets are available at: https://fresh-stack.github.io.","authors":["Nandan Thakur","Jimmy Lin","Sam Havens","Michael Carbin","Omar Khattab","Andrew Drozdov"],"url":"https://arxiv.org/abs/2504.13128"}
{"created":"2025-04-18","title":"Science-T2I: Addressing Scientific Illusions in Image Synthesis","abstract":"We present a novel approach to integrating scientific knowledge into generative models, enhancing their realism and consistency in image synthesis. First, we introduce Science-T2I, an expert-annotated adversarial dataset comprising adversarial 20k image pairs with 9k prompts, covering wide distinct scientific knowledge categories. Leveraging Science-T2I, we present SciScore, an end-to-end reward model that refines the assessment of generated images based on scientific knowledge, which is achieved by augmenting both the scientific comprehension and visual capabilities of pre-trained CLIP model. Additionally, based on SciScore, we propose a two-stage training framework, comprising a supervised fine-tuning phase and a masked online fine-tuning phase, to incorporate scientific knowledge into existing generative models. Through comprehensive experiments, we demonstrate the effectiveness of our framework in establishing new standards for evaluating the scientific realism of generated content. Specifically, SciScore attains performance comparable to human-level, demonstrating a 5% improvement similar to evaluations conducted by experienced human evaluators. Furthermore, by applying our proposed fine-tuning method to FLUX, we achieve a performance enhancement exceeding 50% on SciScore.","authors":["Jialuo Li","Wenhao Chai","Xingyu Fu","Haiyang Xu","Saining Xie"],"url":"https://arxiv.org/abs/2504.13129"}
{"created":"2025-04-18","title":"Energy-Based Reward Models for Robust Language Model Alignment","abstract":"Reward models (RMs) are essential for aligning Large Language Models (LLMs) with human preferences. However, they often struggle with capturing complex human preferences and generalizing to unseen data. To address these challenges, we introduce Energy-Based Reward Model (EBRM), a lightweight post-hoc refinement framework that enhances RM robustness and generalization. EBRM models the reward distribution explicitly, capturing uncertainty in human preferences and mitigating the impact of noisy or misaligned annotations. It achieves this through conflict-aware data filtering, label-noise-aware contrastive training, and hybrid initialization. Notably, EBRM enhances RMs without retraining, making it computationally efficient and adaptable across different models and tasks. Empirical evaluations on RM benchmarks demonstrate significant improvements in both robustness and generalization, achieving up to a 5.97% improvement in safety-critical alignment tasks compared to standard RMs. Furthermore, reinforcement learning experiments confirm that our refined rewards enhance alignment quality, effectively delaying reward hacking. These results demonstrate our approach as a scalable and effective enhancement for existing RMs and alignment pipelines. The code is available at EBRM.","authors":["Anamika Lochab","Ruqi Zhang"],"url":"https://arxiv.org/abs/2504.13134"}
{"created":"2025-04-18","title":"Syntactic and Semantic Control of Large Language Models via Sequential Monte Carlo","abstract":"A wide range of LM applications require generating text that conforms to syntactic or semantic constraints. Imposing such constraints can be naturally framed as probabilistic conditioning, but exact generation from the resulting distribution -- which can differ substantially from the LM's base distribution -- is generally intractable. In this work, we develop an architecture for controlled LM generation based on sequential Monte Carlo (SMC). Our SMC framework allows us to flexibly incorporate domain- and problem-specific constraints at inference time, and efficiently reallocate computational resources in light of new information during the course of generation. By comparing to a number of alternatives and ablations on four challenging domains -- Python code generation for data science, text-to-SQL, goal inference, and molecule synthesis -- we demonstrate that, with little overhead, our approach allows small open-source language models to outperform models over 8x larger, as well as closed-source, fine-tuned ones. In support of the probabilistic perspective, we show that these performance improvements are driven by better approximation to the posterior distribution. Our system builds on the framework of Lew et al. (2023) and integrates with its language model probabilistic programming language, giving users a simple, programmable way to apply SMC to a broad variety of controlled generation problems.","authors":["Jo\\~ao Loula","Benjamin LeBrun","Li Du","Ben Lipkin","Clemente Pasti","Gabriel Grand","Tianyu Liu","Yahya Emara","Marjorie Freedman","Jason Eisner","Ryan Cotterel","Vikash Mansinghka","Alexander K. Lew","Tim Vieira","Timothy J. O'Donnell"],"url":"https://arxiv.org/abs/2504.13139"}
{"created":"2025-04-18","title":"PCBEAR: Pose Concept Bottleneck for Explainable Action Recognition","abstract":"Human action recognition (HAR) has achieved impressive results with deep learning models, but their decision-making process remains opaque due to their black-box nature. Ensuring interpretability is crucial, especially for real-world applications requiring transparency and accountability. Existing video XAI methods primarily rely on feature attribution or static textual concepts, both of which struggle to capture motion dynamics and temporal dependencies essential for action understanding. To address these challenges, we propose Pose Concept Bottleneck for Explainable Action Recognition (PCBEAR), a novel concept bottleneck framework that introduces human pose sequences as motion-aware, structured concepts for video action recognition. Unlike methods based on pixel-level features or static textual descriptions, PCBEAR leverages human skeleton poses, which focus solely on body movements, providing robust and interpretable explanations of motion dynamics. We define two types of pose-based concepts: static pose concepts for spatial configurations at individual frames, and dynamic pose concepts for motion patterns across multiple frames. To construct these concepts, PCBEAR applies clustering to video pose sequences, allowing for automatic discovery of meaningful concepts without manual annotation. We validate PCBEAR on KTH, Penn-Action, and HAA500, showing that it achieves high classification performance while offering interpretable, motion-driven explanations. Our method provides both strong predictive performance and human-understandable insights into the model's reasoning process, enabling test-time interventions for debugging and improving model behavior.","authors":["Jongseo Lee","Wooil Lee","Gyeong-Moon Park","Seong Tae Kim","Jinwoo Choi"],"url":"https://arxiv.org/abs/2504.13140"}
{"created":"2025-04-18","title":"Complexity at Scale: A Quantitative Analysis of an Alibaba Microservice Deployment","abstract":"Microservice architectures are increasingly prevalent in organisations providing online applications. Recent studies have begun to explore the characteristics of real-world large-scale microservice deployments; however, their operational complexities, and the degree to which this complexities are consistent across different deployments, remains under-explored. In this paper, we analyse a microservice dataset released by Alibaba along three dimensions of complexity: scale, heterogeneity, and dynamicity. We find that large-scale deployments can consist of tens of thousands of microservices, that support an even broader array of front-end functionality. Moreover, our analysis shows wide-spread long-tailed distributions of characteristics between microservices, such as share of workload and dependencies, highlighting inequality across the deployment. This diversity is also reflected in call graphs, where we find that whilst front-end services produce dominant call graphs, rarer non-dominant call graphs are prevalent and could involve dissimilar microservice calls. We also find that runtime dependencies between microservices deviate from the static view of system dependencies, and that the deployment undergoes daily changes to microservices. We discuss the implications of our findings for state-of-the-art research in microservice management and research testbed realism, and compare our results to previous descriptions of large-scale microservice deployments to begin to build an understanding of their commonalities.","authors":["Giles Winchester","George Parisis","Luc Berthouze"],"url":"https://arxiv.org/abs/2504.13141"}
{"created":"2025-04-18","title":"Transfer Learning via Auxiliary Labels with Application to Cold-Hardiness Prediction","abstract":"Cold temperatures can cause significant frost damage to fruit crops depending on their resilience, or cold hardiness, which changes throughout the dormancy season. This has led to the development of predictive cold-hardiness models, which help farmers decide when to deploy expensive frost-mitigation measures. Unfortunately, cold-hardiness data for model training is only available for some fruit cultivars due to the need for specialized equipment and expertise. Rather, farmers often do have years of phenological data (e.g. date of budbreak) that they regularly collect for their crops. In this work, we introduce a new transfer-learning framework, Transfer via Auxiliary Labels (TAL), that allows farmers to leverage the phenological data to produce more accurate cold-hardiness predictions, even when no cold-hardiness data is available for their specific crop. The framework assumes a set of source tasks (cultivars) where each has associated primary labels (cold hardiness) and auxiliary labels (phenology). However, the target task (new cultivar) is assumed to only have the auxiliary labels. The goal of TAL is to predict primary labels for the target task via transfer from the source tasks. Surprisingly, despite the vast literature on transfer learning, to our knowledge, the TAL formulation has not been previously addressed. Thus, we propose several new TAL approaches based on model selection and averaging that can leverage recent deep multi-task models for cold-hardiness prediction. Our results on real-world cold-hardiness and phenological data for multiple grape cultivars demonstrate that TAL can leverage the phenological data to improve cold-hardiness predictions in the absence of cold-hardiness data.","authors":["Kristen Goebel","Paola Pesantez-Cabrera","Markus Keller","Alan Fern"],"url":"https://arxiv.org/abs/2504.13142"}
{"created":"2025-04-18","title":"$\\texttt{Complex-Edit}$: CoT-Like Instruction Generation for Complexity-Controllable Image Editing Benchmark","abstract":"We introduce $\\texttt{Complex-Edit}$, a comprehensive benchmark designed to systematically evaluate instruction-based image editing models across instructions of varying complexity. To develop this benchmark, we harness GPT-4o to automatically collect a diverse set of editing instructions at scale. Our approach follows a well-structured ``Chain-of-Edit'' pipeline: we first generate individual atomic editing tasks independently and then integrate them to form cohesive, complex instructions. Additionally, we introduce a suite of metrics to assess various aspects of editing performance, along with a VLM-based auto-evaluation pipeline that supports large-scale assessments. Our benchmark yields several notable insights: 1) Open-source models significantly underperform relative to proprietary, closed-source models, with the performance gap widening as instruction complexity increases; 2) Increased instructional complexity primarily impairs the models' ability to retain key elements from the input images and to preserve the overall aesthetic quality; 3) Decomposing a complex instruction into a sequence of atomic steps, executed in a step-by-step manner, substantially degrades performance across multiple metrics; 4) A straightforward Best-of-N selection strategy improves results for both direct editing and the step-by-step sequential approach; and 5) We observe a ``curse of synthetic data'': when synthetic data is involved in model training, the edited images from such models tend to appear increasingly synthetic as the complexity of the editing instructions rises -- a phenomenon that intriguingly also manifests in the latest GPT-4o outputs.","authors":["Siwei Yang","Mude Hui","Bingchen Zhao","Yuyin Zhou","Nataniel Ruiz","Cihang Xie"],"url":"https://arxiv.org/abs/2504.13143"}
{"created":"2025-04-18","title":"Exploring Expert Failures Improves LLM Agent Tuning","abstract":"Large Language Models (LLMs) have shown tremendous potential as agents, excelling at tasks that require multiple rounds of reasoning and interactions. Rejection Sampling Fine-Tuning (RFT) has emerged as an effective method for finetuning LLMs as agents: it first imitates expert-generated successful trajectories and further improves agentic skills through iterative fine-tuning on successful, self-generated trajectories. However, since the expert (e.g., GPT-4) succeeds primarily on simpler subtasks and RFT inherently favors simpler scenarios, many complex subtasks remain unsolved and persistently out-of-distribution (OOD). Upon investigating these challenging subtasks, we discovered that previously failed expert trajectories can often provide valuable guidance, e.g., plans and key actions, that can significantly improve agent exploration efficiency and acquisition of critical skills. Motivated by these observations, we propose Exploring Expert Failures (EEF), which identifies beneficial actions from failed expert trajectories and integrates them into the training dataset. Potentially harmful actions are meticulously excluded to prevent contamination of the model learning process. By leveraging the beneficial actions in expert failures, EEF successfully solves some previously unsolvable subtasks and improves agent tuning performance. Remarkably, our approach achieved a 62\\% win rate in WebShop, outperforming RFT (53. 6\\%) and GPT-4 (35. 6\\%), and to the best of our knowledge, setting a new state-of-the-art as the first method to surpass a score of 0.81 in WebShop and exceed 81 in SciWorld.","authors":["Li-Cheng Lan","Andrew Bai","Minhao Cheng","Ruochen Wang","Cho-Jui Hsieh","Tianyi Zhou"],"url":"https://arxiv.org/abs/2504.13145"}
{"created":"2025-04-18","title":"Antidistillation Sampling","abstract":"Frontier models that generate extended reasoning traces inadvertently produce rich token sequences that can facilitate model distillation. Recognizing this vulnerability, model owners may seek sampling strategies that limit the effectiveness of distillation without compromising model performance. \\emph{Antidistillation sampling} provides exactly this capability. By strategically modifying a model's next-token probability distribution, antidistillation sampling poisons reasoning traces, rendering them significantly less effective for distillation while preserving the model's practical utility. For further details, see https://antidistillation.com.","authors":["Yash Savani","Asher Trockman","Zhili Feng","Avi Schwarzschild","Alexander Robey","Marc Finzi","J. Zico Kolter"],"url":"https://arxiv.org/abs/2504.13146"}
{"created":"2025-04-18","title":"Long Range Navigator (LRN): Extending robot planning horizons beyond metric maps","abstract":"A robot navigating an outdoor environment with no prior knowledge of the space must rely on its local sensing to perceive its surroundings and plan. This can come in the form of a local metric map or local policy with some fixed horizon. Beyond that, there is a fog of unknown space marked with some fixed cost. A limited planning horizon can often result in myopic decisions leading the robot off course or worse, into very difficult terrain. Ideally, we would like the robot to have full knowledge that can be orders of magnitude larger than a local cost map. In practice, this is intractable due to sparse sensing information and often computationally expensive. In this work, we make a key observation that long-range navigation only necessitates identifying good frontier directions for planning instead of full map knowledge. To this end, we propose Long Range Navigator (LRN), that learns an intermediate affordance representation mapping high-dimensional camera images to `affordable' frontiers for planning, and then optimizing for maximum alignment with the desired goal. LRN notably is trained entirely on unlabeled ego-centric videos making it easy to scale and adapt to new platforms. Through extensive off-road experiments on Spot and a Big Vehicle, we find that augmenting existing navigation stacks with LRN reduces human interventions at test-time and leads to faster decision making indicating the relevance of LRN. https://personalrobotics.github.io/lrn","authors":["Matt Schmittle","Rohan Baijal","Nathan Hatch","Rosario Scalise","Mateo Guaman Castro","Sidharth Talia","Khimya Khetarpal","Byron Boots","Siddhartha Srinivasa"],"url":"https://arxiv.org/abs/2504.13149"}
{"created":"2025-04-18","title":"Readable Twins of Unreadable Models","abstract":"Creating responsible artificial intelligence (AI) systems is an important issue in contemporary research and development of works on AI. One of the characteristics of responsible AI systems is their explainability. In the paper, we are interested in explainable deep learning (XDL) systems. On the basis of the creation of digital twins of physical objects, we introduce the idea of creating readable twins (in the form of imprecise information flow models) for unreadable deep learning models. The complete procedure for switching from the deep learning model (DLM) to the imprecise information flow model (IIFM) is presented. The proposed approach is illustrated with an example of a deep learning classification model for image recognition of handwritten digits from the MNIST data set.","authors":["Krzysztof Pancerz","Piotr Kulicki","Micha{\\l} Kalisz","Andrzej Burda","Maciej Stanis{\\l}awski","Jaromir Sarzy\\'nski"],"url":"https://arxiv.org/abs/2504.13150"}
{"created":"2025-04-18","title":"MIB: A Mechanistic Interpretability Benchmark","abstract":"How can we know whether new mechanistic interpretability methods achieve real improvements? In pursuit of meaningful and lasting evaluation standards, we propose MIB, a benchmark with two tracks spanning four tasks and five models. MIB favors methods that precisely and concisely recover relevant causal pathways or specific causal variables in neural language models. The circuit localization track compares methods that locate the model components - and connections between them - most important for performing a task (e.g., attribution patching or information flow routes). The causal variable localization track compares methods that featurize a hidden vector, e.g., sparse autoencoders (SAEs) or distributed alignment search (DAS), and locate model features for a causal variable relevant to the task. Using MIB, we find that attribution and mask optimization methods perform best on circuit localization. For causal variable localization, we find that the supervised DAS method performs best, while SAE features are not better than neurons, i.e., standard dimensions of hidden vectors. These findings illustrate that MIB enables meaningful comparisons of methods, and increases our confidence that there has been real progress in the field.","authors":["Aaron Mueller","Atticus Geiger","Sarah Wiegreffe","Dana Arad","Iv\\'an Arcuschin","Adam Belfki","Yik Siu Chan","Jaden Fiotto-Kaufman","Tal Haklay","Michael Hanna","Jing Huang","Rohan Gupta","Yaniv Nikankin","Hadas Orgad","Nikhil Prakash","Anja Reusch","Aruna Sankaranarayanan","Shun Shao","Alessandro Stolfo","Martin Tutek","Amir Zur","David Bau","Yonatan Belinkov"],"url":"https://arxiv.org/abs/2504.13151"}
{"created":"2025-04-18","title":"St4RTrack: Simultaneous 4D Reconstruction and Tracking in the World","abstract":"Dynamic 3D reconstruction and point tracking in videos are typically treated as separate tasks, despite their deep connection. We propose St4RTrack, a feed-forward framework that simultaneously reconstructs and tracks dynamic video content in a world coordinate frame from RGB inputs. This is achieved by predicting two appropriately defined pointmaps for a pair of frames captured at different moments. Specifically, we predict both pointmaps at the same moment, in the same world, capturing both static and dynamic scene geometry while maintaining 3D correspondences. Chaining these predictions through the video sequence with respect to a reference frame naturally computes long-range correspondences, effectively combining 3D reconstruction with 3D tracking. Unlike prior methods that rely heavily on 4D ground truth supervision, we employ a novel adaptation scheme based on a reprojection loss. We establish a new extensive benchmark for world-frame reconstruction and tracking, demonstrating the effectiveness and efficiency of our unified, data-driven framework. Our code, model, and benchmark will be released.","authors":["Haiwen Feng","Junyi Zhang","Qianqian Wang","Yufei Ye","Pengcheng Yu","Michael J. Black","Trevor Darrell","Angjoo Kanazawa"],"url":"https://arxiv.org/abs/2504.13152"}
{"created":"2025-04-18","title":"Training-Free Hierarchical Scene Understanding for Gaussian Splatting with Superpoint Graphs","abstract":"Bridging natural language and 3D geometry is a crucial step toward flexible, language-driven scene understanding. While recent advances in 3D Gaussian Splatting (3DGS) have enabled fast and high-quality scene reconstruction, research has also explored incorporating open-vocabulary understanding into 3DGS. However, most existing methods require iterative optimization over per-view 2D semantic feature maps, which not only results in inefficiencies but also leads to inconsistent 3D semantics across views. To address these limitations, we introduce a training-free framework that constructs a superpoint graph directly from Gaussian primitives. The superpoint graph partitions the scene into spatially compact and semantically coherent regions, forming view-consistent 3D entities and providing a structured foundation for open-vocabulary understanding. Based on the graph structure, we design an efficient reprojection strategy that lifts 2D semantic features onto the superpoints, avoiding costly multi-view iterative training. The resulting representation ensures strong 3D semantic coherence and naturally supports hierarchical understanding, enabling both coarse- and fine-grained open-vocabulary perception within a unified semantic field. Extensive experiments demonstrate that our method achieves state-of-the-art open-vocabulary segmentation performance, with semantic field reconstruction completed over $30\\times$ faster. Our code will be available at https://github.com/Atrovast/THGS.","authors":["Shaohui Dai","Yansong Qu","Zheyan Li","Xinyang Li","Shengchuan Zhang","Liujuan Cao"],"url":"https://arxiv.org/abs/2504.13153"}
{"created":"2025-04-18","title":"AerialMegaDepth: Learning Aerial-Ground Reconstruction and View Synthesis","abstract":"We explore the task of geometric reconstruction of images captured from a mixture of ground and aerial views. Current state-of-the-art learning-based approaches fail to handle the extreme viewpoint variation between aerial-ground image pairs. Our hypothesis is that the lack of high-quality, co-registered aerial-ground datasets for training is a key reason for this failure. Such data is difficult to assemble precisely because it is difficult to reconstruct in a scalable way. To overcome this challenge, we propose a scalable framework combining pseudo-synthetic renderings from 3D city-wide meshes (e.g., Google Earth) with real, ground-level crowd-sourced images (e.g., MegaDepth). The pseudo-synthetic data simulates a wide range of aerial viewpoints, while the real, crowd-sourced images help improve visual fidelity for ground-level images where mesh-based renderings lack sufficient detail, effectively bridging the domain gap between real images and pseudo-synthetic renderings. Using this hybrid dataset, we fine-tune several state-of-the-art algorithms and achieve significant improvements on real-world, zero-shot aerial-ground tasks. For example, we observe that baseline DUSt3R localizes fewer than 5% of aerial-ground pairs within 5 degrees of camera rotation error, while fine-tuning with our data raises accuracy to nearly 56%, addressing a major failure point in handling large viewpoint changes. Beyond camera estimation and scene reconstruction, our dataset also improves performance on downstream tasks like novel-view synthesis in challenging aerial-ground scenarios, demonstrating the practical value of our approach in real-world applications.","authors":["Khiem Vuong","Anurag Ghosh","Deva Ramanan","Srinivasa Narasimhan","Shubham Tulsiani"],"url":"https://arxiv.org/abs/2504.13157"}
{"created":"2025-04-18","title":"Digital Twin Generation from Visual Data: A Survey","abstract":"This survey explores recent developments in generating digital twins from videos. Such digital twins can be used for robotics application, media content creation, or design and construction works. We analyze various approaches, including 3D Gaussian Splatting, generative in-painting, semantic segmentation, and foundation models highlighting their advantages and limitations. Additionally, we discuss challenges such as occlusions, lighting variations, and scalability, as well as potential future research directions. This survey aims to provide a comprehensive overview of state-of-the-art methodologies and their implications for real-world applications. Awesome list: https://github.com/ndrwmlnk/awesome-digital-twins","authors":["Andrew Melnik","Benjamin Alt","Giang Nguyen","Artur Wilkowski","Maciej Stefa\\'nczyk","Qirui Wu","Sinan Harms","Helge Rhodin","Manolis Savva","Michael Beetz"],"url":"https://arxiv.org/abs/2504.13159"}
{"created":"2025-04-18","title":"CLIMB: CLustering-based Iterative Data Mixture Bootstrapping for Language Model Pre-training","abstract":"Pre-training datasets are typically collected from web content and lack inherent domain divisions. For instance, widely used datasets like Common Crawl do not include explicit domain labels, while manually curating labeled datasets such as The Pile is labor-intensive. Consequently, identifying an optimal pre-training data mixture remains a challenging problem, despite its significant benefits for pre-training performance. To address these challenges, we propose CLustering-based Iterative Data Mixture Bootstrapping (CLIMB), an automated framework that discovers, evaluates, and refines data mixtures in a pre-training setting. Specifically, CLIMB embeds and clusters large-scale datasets in a semantic space and then iteratively searches for optimal mixtures using a smaller proxy model and a predictor. When continuously trained on 400B tokens with this mixture, our 1B model exceeds the state-of-the-art Llama-3.2-1B by 2.0%. Moreover, we observe that optimizing for a specific domain (e.g., Social Sciences) yields a 5% improvement over random sampling. Finally, we introduce ClimbLab, a filtered 1.2-trillion-token corpus with 20 clusters as a research playground, and ClimbMix, a compact yet powerful 400-billion-token dataset designed for efficient pre-training that delivers superior performance under an equal token budget. We analyze the final data mixture, elucidating the characteristics of an optimal data mixture. Our data is available at: https://research.nvidia.com/labs/lpr/climb/","authors":["Shizhe Diao (Celine)","Yu Yang (Celine)","Yonggan Fu (Celine)","Xin Dong (Celine)","Dan Su (Celine)","Markus Kliegl (Celine)","Zijia Chen (Celine)","Peter Belcak (Celine)","Yoshi Suhara (Celine)","Hongxu Yin (Celine)","Mostofa Patwary (Celine)","Yingyan (Celine)","Lin","Jan Kautz","Pavlo Molchanov"],"url":"https://arxiv.org/abs/2504.13161"}
{"created":"2025-04-18","title":"Personalized Text-to-Image Generation with Auto-Regressive Models","abstract":"Personalized image synthesis has emerged as a pivotal application in text-to-image generation, enabling the creation of images featuring specific subjects in diverse contexts. While diffusion models have dominated this domain, auto-regressive models, with their unified architecture for text and image modeling, remain underexplored for personalized image generation. This paper investigates the potential of optimizing auto-regressive models for personalized image synthesis, leveraging their inherent multimodal capabilities to perform this task. We propose a two-stage training strategy that combines optimization of text embeddings and fine-tuning of transformer layers. Our experiments on the auto-regressive model demonstrate that this method achieves comparable subject fidelity and prompt following to the leading diffusion-based personalization methods. The results highlight the effectiveness of auto-regressive models in personalized image generation, offering a new direction for future research in this area.","authors":["Kaiyue Sun","Xian Liu","Yao Teng","Xihui Liu"],"url":"https://arxiv.org/abs/2504.13162"}
{"created":"2025-04-18","title":"RUKA: Rethinking the Design of Humanoid Hands with Learning","abstract":"Dexterous manipulation is a fundamental capability for robotic systems, yet progress has been limited by hardware trade-offs between precision, compactness, strength, and affordability. Existing control methods impose compromises on hand designs and applications. However, learning-based approaches present opportunities to rethink these trade-offs, particularly to address challenges with tendon-driven actuation and low-cost materials. This work presents RUKA, a tendon-driven humanoid hand that is compact, affordable, and capable. Made from 3D-printed parts and off-the-shelf components, RUKA has 5 fingers with 15 underactuated degrees of freedom enabling diverse human-like grasps. Its tendon-driven actuation allows powerful grasping in a compact, human-sized form factor. To address control challenges, we learn joint-to-actuator and fingertip-to-actuator models from motion-capture data collected by the MANUS glove, leveraging the hand's morphological accuracy. Extensive evaluations demonstrate RUKA's superior reachability, durability, and strength compared to other robotic hands. Teleoperation tasks further showcase RUKA's dexterous movements. The open-source design and assembly instructions of RUKA, code, and data are available at https://ruka-hand.github.io/.","authors":["Anya Zorin","Irmak Guzey","Billy Yan","Aadhithya Iyer","Lisa Kondrich","Nikhil X. Bhattasali","Lerrel Pinto"],"url":"https://arxiv.org/abs/2504.13165"}
{"created":"2025-04-18","title":"ODHSR: Online Dense 3D Reconstruction of Humans and Scenes from Monocular Videos","abstract":"Creating a photorealistic scene and human reconstruction from a single monocular in-the-wild video figures prominently in the perception of a human-centric 3D world. Recent neural rendering advances have enabled holistic human-scene reconstruction but require pre-calibrated camera and human poses, and days of training time. In this work, we introduce a novel unified framework that simultaneously performs camera tracking, human pose estimation and human-scene reconstruction in an online fashion. 3D Gaussian Splatting is utilized to learn Gaussian primitives for humans and scenes efficiently, and reconstruction-based camera tracking and human pose estimation modules are designed to enable holistic understanding and effective disentanglement of pose and appearance. Specifically, we design a human deformation module to reconstruct the details and enhance generalizability to out-of-distribution poses faithfully. Aiming to learn the spatial correlation between human and scene accurately, we introduce occlusion-aware human silhouette rendering and monocular geometric priors, which further improve reconstruction quality. Experiments on the EMDB and NeuMan datasets demonstrate superior or on-par performance with existing methods in camera tracking, human pose estimation, novel view synthesis and runtime. Our project page is at https://eth-ait.github.io/ODHSR.","authors":["Zetong Zhang","Manuel kaufmann","Lixin Xue","Jie Song","Martin R. Oswald"],"url":"https://arxiv.org/abs/2504.13167"}
{"created":"2025-04-18","title":"Generate, but Verify: Reducing Hallucination in Vision-Language Models with Retrospective Resampling","abstract":"Vision-Language Models (VLMs) excel at visual understanding but often suffer from visual hallucinations, where they generate descriptions of nonexistent objects, actions, or concepts, posing significant risks in safety-critical applications. Existing hallucination mitigation methods typically follow one of two paradigms: generation adjustment, which modifies decoding behavior to align text with visual inputs, and post-hoc verification, where external models assess and correct outputs. While effective, generation adjustment methods often rely on heuristics and lack correction mechanisms, while post-hoc verification is complicated, typically requiring multiple models and tending to reject outputs rather than refine them. In this work, we introduce REVERSE, a unified framework that integrates hallucination-aware training with on-the-fly self-verification. By leveraging a new hallucination-verification dataset containing over 1.3M semi-synthetic samples, along with a novel inference-time retrospective resampling technique, our approach enables VLMs to both detect hallucinations during generation and dynamically revise those hallucinations. Our evaluations show that REVERSE achieves state-of-the-art hallucination reduction, outperforming the best existing methods by up to 12% on CHAIR-MSCOCO and 28% on HaloQuest. Our dataset, model, and code are available at: https://reverse-vlm.github.io.","authors":["Tsung-Han Wu","Heekyung Lee","Jiaxin Ge","Joseph E. Gonzalez","Trevor Darrell","David M. Chan"],"url":"https://arxiv.org/abs/2504.13169"}
{"created":"2025-04-18","title":"A New Semidefinite Relaxation for Linear and Piecewise-Affine Optimal Control with Time Scaling","abstract":"We introduce a semidefinite relaxation for optimal control of linear systems with time scaling. These problems are inherently nonconvex, since the system dynamics involves bilinear products between the discretization time step and the system state and controls. The proposed relaxation is closely related to the standard second-order semidefinite relaxation for quadratic constraints, but we carefully select a subset of the possible bilinear terms and apply a change of variables to achieve empirically tight relaxations while keeping the computational load light. We further extend our method to handle piecewise-affine (PWA) systems by formulating the PWA optimal-control problem as a shortest-path problem in a graph of convex sets (GCS). In this GCS, different paths represent different mode sequences for the PWA system, and the convex sets model the relaxed dynamics within each mode. By combining a tight convex relaxation of the GCS problem with our semidefinite relaxation with time scaling, we can solve PWA optimal-control problems through a single semidefinite program.","authors":["Lujie Yang","Tobia Marcucci","Pablo A. Parrilo","Russ Tedrake"],"url":"https://arxiv.org/abs/2504.13170"}
{"created":"2025-04-18","title":"Sleep-time Compute: Beyond Inference Scaling at Test-time","abstract":"Scaling test-time compute has emerged as a key ingredient for enabling large language models (LLMs) to solve difficult problems, but comes with high latency and inference cost. We introduce sleep-time compute, which allows models to \"think\" offline about contexts before queries are presented: by anticipating what queries users might ask and pre-computing useful quantities, we can significantly reduce the compute requirements at test-time. To demonstrate the efficacy of our method, we create modified versions of two reasoning tasks - Stateful GSM-Symbolic and Stateful AIME. We find that sleep-time compute can reduce the amount of test-time compute needed to achieve the same accuracy by ~ 5x on Stateful GSM-Symbolic and Stateful AIME and that by scaling sleep-time compute we can further increase accuracy by up to 13% on Stateful GSM-Symbolic and 18% on Stateful AIME. Furthermore, we introduce Multi-Query GSM-Symbolic, which extends GSM-Symbolic by including multiple related queries per context. By amortizing sleep-time compute across related queries about the same context using Multi-Query GSM-Symbolic, we can decrease the average cost per query by 2.5x. We then conduct additional analysis to understand when sleep-time compute is most effective, finding the predictability of the user query to be well correlated with the efficacy of sleep-time compute. Finally, we conduct a case-study of applying sleep-time compute to a realistic agentic SWE task.","authors":["Kevin Lin","Charlie Snell","Yu Wang","Charles Packer","Sarah Wooders","Ion Stoica","Joseph E. Gonzalez"],"url":"https://arxiv.org/abs/2504.13171"}
{"created":"2025-04-18","title":"SemCORE: A Semantic-Enhanced Generative Cross-Modal Retrieval Framework with MLLMs","abstract":"Cross-modal retrieval (CMR) is a fundamental task in multimedia research, focused on retrieving semantically relevant targets across different modalities. While traditional CMR methods match text and image via embedding-based similarity calculations, recent advancements in pre-trained generative models have established generative retrieval as a promising alternative. This paradigm assigns each target a unique identifier and leverages a generative model to directly predict identifiers corresponding to input queries without explicit indexing. Despite its great potential, current generative CMR approaches still face semantic information insufficiency in both identifier construction and generation processes. To address these limitations, we propose a novel unified Semantic-enhanced generative Cross-mOdal REtrieval framework (SemCORE), designed to unleash the semantic understanding capabilities in generative cross-modal retrieval task. Specifically, we first construct a Structured natural language IDentifier (SID) that effectively aligns target identifiers with generative models optimized for natural language comprehension and generation. Furthermore, we introduce a Generative Semantic Verification (GSV) strategy enabling fine-grained target discrimination. Additionally, to the best of our knowledge, SemCORE is the first framework to simultaneously consider both text-to-image and image-to-text retrieval tasks within generative cross-modal retrieval. Extensive experiments demonstrate that our framework outperforms state-of-the-art generative cross-modal retrieval methods. Notably, SemCORE achieves substantial improvements across benchmark datasets, with an average increase of 8.65 points in Recall@1 for text-to-image retrieval.","authors":["Haoxuan Li","Yi Bin","Yunshan Ma","Guoqing Wang","Yang Yang","See-Kiong Ng","Tat-Seng Chua"],"url":"https://arxiv.org/abs/2504.13172"}
{"created":"2025-04-18","title":"It's All Connected: A Journey Through Test-Time Memorization, Attentional Bias, Retention, and Online Optimization","abstract":"Designing efficient and effective architectural backbones has been in the core of research efforts to enhance the capability of foundation models. Inspired by the human cognitive phenomenon of attentional bias-the natural tendency to prioritize certain events or stimuli-we reconceptualize neural architectures, including Transformers, Titans, and modern linear recurrent neural networks as associative memory modules that learn a mapping of keys and values using an internal objective, referred to as attentional bias. Surprisingly, we observed that most existing sequence models leverage either (1) dot-product similarity, or (2) L2 regression objectives as their attentional bias. Going beyond these objectives, we present a set of alternative attentional bias configurations along with their effective approximations to stabilize their training procedure. We then reinterpret forgetting mechanisms in modern deep learning architectures as a form of retention regularization, providing a novel set of forget gates for sequence models. Building upon these insights, we present Miras, a general framework to design deep learning architectures based on four choices of: (i) associative memory architecture, (ii) attentional bias objective, (iii) retention gate, and (iv) memory learning algorithm. We present three novel sequence models-Moneta, Yaad, and Memora-that go beyond the power of existing linear RNNs while maintaining a fast parallelizable training process. Our experiments show different design choices in Miras yield models with varying strengths. For example, certain instances of Miras achieve exceptional performance in special tasks such as language modeling, commonsense reasoning, and recall intensive tasks, even outperforming Transformers and other modern linear recurrent models.","authors":["Ali Behrouz","Meisam Razaviyayn","Peilin Zhong","Vahab Mirrokni"],"url":"https://arxiv.org/abs/2504.13173"}
{"created":"2025-04-18","title":"Novel Demonstration Generation with Gaussian Splatting Enables Robust One-Shot Manipulation","abstract":"Visuomotor policies learned from teleoperated demonstrations face challenges such as lengthy data collection, high costs, and limited data diversity. Existing approaches address these issues by augmenting image observations in RGB space or employing Real-to-Sim-to-Real pipelines based on physical simulators. However, the former is constrained to 2D data augmentation, while the latter suffers from imprecise physical simulation caused by inaccurate geometric reconstruction. This paper introduces RoboSplat, a novel method that generates diverse, visually realistic demonstrations by directly manipulating 3D Gaussians. Specifically, we reconstruct the scene through 3D Gaussian Splatting (3DGS), directly edit the reconstructed scene, and augment data across six types of generalization with five techniques: 3D Gaussian replacement for varying object types, scene appearance, and robot embodiments; equivariant transformations for different object poses; visual attribute editing for various lighting conditions; novel view synthesis for new camera perspectives; and 3D content generation for diverse object types. Comprehensive real-world experiments demonstrate that RoboSplat significantly enhances the generalization of visuomotor policies under diverse disturbances. Notably, while policies trained on hundreds of real-world demonstrations with additional 2D data augmentation achieve an average success rate of 57.2%, RoboSplat attains 87.8% in one-shot settings across six types of generalization in the real world.","authors":["Sizhe Yang","Wenye Yu","Jia Zeng","Jun Lv","Kerui Ren","Cewu Lu","Dahua Lin","Jiangmiao Pang"],"url":"https://arxiv.org/abs/2504.13175"}
{"created":"2025-04-18","title":"IMAGGarment-1: Fine-Grained Garment Generation for Controllable Fashion Design","abstract":"This paper presents IMAGGarment-1, a fine-grained garment generation (FGG) framework that enables high-fidelity garment synthesis with precise control over silhouette, color, and logo placement. Unlike existing methods that are limited to single-condition inputs, IMAGGarment-1 addresses the challenges of multi-conditional controllability in personalized fashion design and digital apparel applications. Specifically, IMAGGarment-1 employs a two-stage training strategy to separately model global appearance and local details, while enabling unified and controllable generation through end-to-end inference. In the first stage, we propose a global appearance model that jointly encodes silhouette and color using a mixed attention module and a color adapter. In the second stage, we present a local enhancement model with an adaptive appearance-aware module to inject user-defined logos and spatial constraints, enabling accurate placement and visual consistency. To support this task, we release GarmentBench, a large-scale dataset comprising over 180K garment samples paired with multi-level design conditions, including sketches, color references, logo placements, and textual prompts. Extensive experiments demonstrate that our method outperforms existing baselines, achieving superior structural stability, color fidelity, and local controllability performance. The code and model are available at https://github.com/muzishen/IMAGGarment-1.","authors":["Fei Shen","Jian Yu","Cong Wang","Xin Jiang","Xiaoyu Du","Jinhui Tang"],"url":"https://arxiv.org/abs/2504.13176"}
{"created":"2025-04-18","title":"Single-Shot Shape and Reflectance with Spatial Polarization Multiplexing","abstract":"We propose spatial polarization multiplexing (SPM) for reconstructing object shape and reflectance from a single polarimetric image and demonstrate its application to dynamic surface recovery. Although single-pattern structured light enables single-shot shape reconstruction, the reflectance is challenging to recover due to the lack of angular sampling of incident light and the entanglement of the projected pattern and the surface color texture. We design a spatially multiplexed pattern of polarization that can be robustly and uniquely decoded for shape reconstruction by quantizing the AoLP values. At the same time, our spatial-multiplexing enables single-shot ellipsometry of linear polarization by projecting differently polarized light within a local region, which separates the specular and diffuse reflections for BRDF estimation. We achieve this spatial polarization multiplexing with a constrained de Bruijn sequence. Unlike single-pattern structured light with intensity and color, our polarization pattern is invisible to the naked eye and retains the natural surface appearance which is essential for accurate appearance modeling and also interaction with people. We experimentally validate our method on real data. The results show that our method can recover the shape, the Mueller matrix, and the BRDF from a single-shot polarimetric image. We also demonstrate the application of our method to dynamic surfaces.","authors":["Tomoki Ichikawa","Ryo Kawahara","Ko Nishino"],"url":"https://arxiv.org/abs/2504.13177"}
{"created":"2025-04-18","title":"Aligning Constraint Generation with Design Intent in Parametric CAD","abstract":"We adapt alignment techniques from reasoning LLMs to the task of generating engineering sketch constraints found in computer-aided design (CAD) models. Engineering sketches consist of geometric primitives (e.g. points, lines) connected by constraints (e.g. perpendicular, tangent) that define the relationships between them. For a design to be easily editable, the constraints must effectively capture design intent, ensuring the geometry updates predictably when parameters change. Although current approaches can generate CAD designs, an open challenge remains to align model outputs with design intent, we label this problem `design alignment'. A critical first step towards aligning generative CAD models is to generate constraints which fully-constrain all geometric primitives, without over-constraining or distorting sketch geometry. Using alignment techniques to train an existing constraint generation model with feedback from a constraint solver, we are able to fully-constrain 93% of sketches compared to 34% when using a na\\\"ive supervised fine-tuning (SFT) baseline and only 8.9% without alignment. Our approach can be applied to any existing constraint generation model and sets the stage for further research bridging alignment strategies between the language and design domains.","authors":["Evan Casey","Tianyu Zhang","Shu Ishida","John Roger Thompson","Amir Khasahmadi","Joseph George Lambourne","Pradeep Kumar Jayaraman","Karl D. D. Willis"],"url":"https://arxiv.org/abs/2504.13178"}
{"created":"2025-04-18","title":"ViTa-Zero: Zero-shot Visuotactile Object 6D Pose Estimation","abstract":"Object 6D pose estimation is a critical challenge in robotics, particularly for manipulation tasks. While prior research combining visual and tactile (visuotactile) information has shown promise, these approaches often struggle with generalization due to the limited availability of visuotactile data. In this paper, we introduce ViTa-Zero, a zero-shot visuotactile pose estimation framework. Our key innovation lies in leveraging a visual model as its backbone and performing feasibility checking and test-time optimization based on physical constraints derived from tactile and proprioceptive observations. Specifically, we model the gripper-object interaction as a spring-mass system, where tactile sensors induce attractive forces, and proprioception generates repulsive forces. We validate our framework through experiments on a real-world robot setup, demonstrating its effectiveness across representative visual backbones and manipulation scenarios, including grasping, object picking, and bimanual handover. Compared to the visual models, our approach overcomes some drastic failure modes while tracking the in-hand object pose. In our experiments, our approach shows an average increase of 55% in AUC of ADD-S and 60% in ADD, along with an 80% lower position error compared to FoundationPose.","authors":["Hongyu Li","James Akl","Srinath Sridhar","Tye Brady","Taskin Padir"],"url":"https://arxiv.org/abs/2504.13179"}
{"created":"2025-04-18","title":"PerceptionLM: Open-Access Data and Models for Detailed Visual Understanding","abstract":"Vision-language models are integral to computer vision research, yet many high-performing models remain closed-source, obscuring their data, design and training recipe. The research community has responded by using distillation from black-box models to label training data, achieving strong benchmark results, at the cost of measurable scientific progress. However, without knowing the details of the teacher model and its data sources, scientific progress remains difficult to measure. In this paper, we study building a Perception Language Model (PLM) in a fully open and reproducible framework for transparent research in image and video understanding. We analyze standard training pipelines without distillation from proprietary models and explore large-scale synthetic data to identify critical data gaps, particularly in detailed video understanding. To bridge these gaps, we release 2.8M human-labeled instances of fine-grained video question-answer pairs and spatio-temporally grounded video captions. Additionally, we introduce PLM-VideoBench, a suite for evaluating challenging video understanding tasks focusing on the ability to reason about \"what\", \"where\", \"when\", and \"how\" of a video. We make our work fully reproducible by providing data, training recipes, code & models.","authors":["Jang Hyun Cho","Andrea Madotto","Effrosyni Mavroudi","Triantafyllos Afouras","Tushar Nagarajan","Muhammad Maaz","Yale Song","Tengyu Ma","Shuming Hu","Suyog Jain","Miguel Martin","Huiyu Wang","Hanoona Rasheed","Peize Sun","Po-Yao Huang","Daniel Bolya","Nikhila Ravi","Shashank Jain","Tammy Stark","Shane Moon","Babak Damavandi","Vivian Lee","Andrew Westbury","Salman Khan","Philipp Kr\\\"ahenb\\\"uhl","Piotr Doll\\'ar","Lorenzo Torresani","Kristen Grauman","Christoph Feichtenhofer"],"url":"https://arxiv.org/abs/2504.13180"}
{"created":"2025-04-18","title":"Perception Encoder: The best visual embeddings are not at the output of the network","abstract":"We introduce Perception Encoder (PE), a state-of-the-art encoder for image and video understanding trained via simple vision-language learning. Traditionally, vision encoders have relied on a variety of pretraining objectives, each tailored to specific downstream tasks such as classification, captioning, or localization. Surprisingly, after scaling our carefully tuned image pretraining recipe and refining with our robust video data engine, we find that contrastive vision-language training alone can produce strong, general embeddings for all of these downstream tasks. There is only one caveat: these embeddings are hidden within the intermediate layers of the network. To draw them out, we introduce two alignment methods, language alignment for multimodal language modeling, and spatial alignment for dense prediction. Together with the core contrastive checkpoint, our PE family of models achieves state-of-the-art performance on a wide variety of tasks, including zero-shot image and video classification and retrieval; document, image, and video Q&amp;A and spatial tasks such as detection, depth estimation, and tracking. To foster further research, we are releasing our models, code, and a novel dataset of synthetically and human-annotated videos.","authors":["Daniel Bolya","Po-Yao Huang","Peize Sun","Jang Hyun Cho","Andrea Madotto","Chen Wei","Tengyu Ma","Jiale Zhi","Jathushan Rajasegaran","Hanoona Rasheed","Junke Wang","Marco Monteiro","Hu Xu","Shiyu Dong","Nikhila Ravi","Daniel Li","Piotr Doll\\'ar","Christoph Feichtenhofer"],"url":"https://arxiv.org/abs/2504.13181"}
{"created":"2025-04-18","title":"TRIDIS: A Comprehensive Medieval and Early Modern Corpus for HTR and NER","abstract":"This paper introduces TRIDIS (Tria Digita Scribunt), an open-source corpus of medieval and early modern manuscripts. TRIDIS aggregates multiple legacy collections (all published under open licenses) and incorporates large metadata descriptions. While prior publications referenced some portions of this corpus, here we provide a unified overview with a stronger focus on its constitution. We describe (i) the narrative, chronological, and editorial background of each major sub-corpus, (ii) its semi-diplomatic transcription rules (expansion, normalization, punctuation), (iii) a strategy for challenging out-of-domain test splits driven by outlier detection in a joint embedding space, and (iv) preliminary baseline experiments using TrOCR and MiniCPM2.5 comparing random and outlier-based test partitions. Overall, TRIDIS is designed to stimulate joint robust Handwritten Text Recognition (HTR) and Named Entity Recognition (NER) research across medieval and early modern textual heritage.","authors":["Sergio Torres Aguilar"],"url":"https://arxiv.org/abs/2503.22714"}
{"created":"2025-04-18","title":"Deep Generative Model-Based Generation of Synthetic Individual-Specific Brain MRI Segmentations","abstract":"To the best of our knowledge, all existing methods that can generate synthetic brain magnetic resonance imaging (MRI) scans for a specific individual require detailed structural or volumetric information about the individual's brain. However, such brain information is often scarce, expensive, and difficult to obtain. In this paper, we propose the first approach capable of generating synthetic brain MRI segmentations -- specifically, 3D white matter (WM), gray matter (GM), and cerebrospinal fluid (CSF) segmentations -- for individuals using their easily obtainable and often readily available demographic, interview, and cognitive test information. Our approach features a novel deep generative model, CSegSynth, which outperforms existing prominent generative models, including conditional variational autoencoder (C-VAE), conditional generative adversarial network (C-GAN), and conditional latent diffusion model (C-LDM). We demonstrate the high quality of our synthetic segmentations through extensive evaluations. Also, in assessing the effectiveness of the individual-specific generation, we achieve superior volume prediction, with Pearson correlation coefficients reaching 0.80, 0.82, and 0.70 between the ground-truth WM, GM, and CSF volumes of test individuals and those volumes predicted based on generated individual-specific segmentations, respectively.","authors":["Ruijie Wang","Luca Rossetto","Susan M\\'erillat","Christina R\\\"ocke","Mike Martin","Abraham Bernstein"],"url":"https://arxiv.org/abs/2504.12352"}
{"created":"2025-04-18","title":"TransST: Transfer Learning Embedded Spatial Factor Modeling of Spatial Transcriptomics Data","abstract":"Background: Spatial transcriptomics have emerged as a powerful tool in biomedical research because of its ability to capture both the spatial contexts and abundance of the complete RNA transcript profile in organs of interest. However, limitations of the technology such as the relatively low resolution and comparatively insufficient sequencing depth make it difficult to reliably extract real biological signals from these data. To alleviate this challenge, we propose a novel transfer learning framework, referred to as TransST, to adaptively leverage the cell-labeled information from external sources in inferring cell-level heterogeneity of a target spatial transcriptomics data.","authors":["Shuo Shuo Liu","Shikun Wang","Yuxuan Chen","Anil K. Rustgi","Ming Yuan","Jianhua Hu"],"url":"https://arxiv.org/abs/2504.12353"}
{"created":"2025-04-18","title":"WaterFlow: Learning Fast & Robust Watermarks using Stable Diffusion","abstract":"The ability to embed watermarks in images is a fundamental problem of interest for computer vision, and is exacerbated by the rapid rise of generated imagery in recent times. Current state-of-the-art techniques suffer from computational and statistical challenges such as the slow execution speed for practical deployments. In addition, other works trade off fast watermarking speeds but suffer greatly in their robustness or perceptual quality. In this work, we propose WaterFlow (WF), a fast and extremely robust approach for high fidelity visual watermarking based on a learned latent-dependent watermark. Our approach utilizes a pretrained latent diffusion model to encode an arbitrary image into a latent space and produces a learned watermark that is then planted into the Fourier Domain of the latent. The transformation is specified via invertible flow layers that enhance the expressivity of the latent space of the pre-trained model to better preserve image quality while permitting robust and tractable detection. Most notably, WaterFlow demonstrates state-of-the-art performance on general robustness and is the first method capable of effectively defending against difficult combination attacks. We validate our findings on three widely used real and generated datasets: MS-COCO, DiffusionDB, and WikiArt.","authors":["Vinay Shukla","Prachee Sharma","Ryan Rossi","Sungchul Kim","Tong Yu","Aditya Grover"],"url":"https://arxiv.org/abs/2504.12354"}
{"created":"2025-04-18","title":"Regist3R: Incremental Registration with Stereo Foundation Model","abstract":"Multi-view 3D reconstruction has remained an essential yet challenging problem in the field of computer vision. While DUSt3R and its successors have achieved breakthroughs in 3D reconstruction from unposed images, these methods exhibit significant limitations when scaling to multi-view scenarios, including high computational cost and cumulative error induced by global alignment. To address these challenges, we propose Regist3R, a novel stereo foundation model tailored for efficient and scalable incremental reconstruction. Regist3R leverages an incremental reconstruction paradigm, enabling large-scale 3D reconstructions from unordered and many-view image collections. We evaluate Regist3R on public datasets for camera pose estimation and 3D reconstruction. Our experiments demonstrate that Regist3R achieves comparable performance with optimization-based methods while significantly improving computational efficiency, and outperforms existing multi-view reconstruction models. Furthermore, to assess its performance in real-world applications, we introduce a challenging oblique aerial dataset which has long spatial spans and hundreds of views. The results highlight the effectiveness of Regist3R. We also demonstrate the first attempt to reconstruct large-scale scenes encompassing over thousands of views through pointmap-based foundation models, showcasing its potential for practical applications in large-scale 3D reconstruction tasks, including urban modeling, aerial mapping, and beyond.","authors":["Sidun Liu","Wenyu Li","Peng Qiao","Yong Dou"],"url":"https://arxiv.org/abs/2504.12356"}
{"created":"2025-04-18","title":"Resonances in reflective Hamiltonian Monte Carlo","abstract":"In high dimensions, reflective Hamiltonian Monte Carlo with inexact reflections exhibits slow mixing when the particle ensemble is initialised from a Dirac delta distribution and the uniform distribution is targeted. By quantifying the instantaneous non-uniformity of the distribution with the Sinkhorn divergence, we elucidate the principal mechanisms underlying the mixing problems. In spheres and cubes, we show that the collective motion transitions between fluid-like and discretisation-dominated behaviour, with the critical step size scaling as a power law in the dimension. In both regimes, the particles can spontaneously unmix, leading to resonances in the particle density and the aforementioned problems. Additionally, low-dimensional toy models of the dynamics are constructed which reproduce the dominant features of the high-dimensional problem. Finally, the dynamics is contrasted with the exact Hamiltonian particle flow and tuning practices are discussed.","authors":["Namu Kroupa","G\\'abor Cs\\'anyi","Will Handley"],"url":"https://arxiv.org/abs/2504.12374"}
{"created":"2025-04-18","title":"Predictive control of blast furnace temperature in steelmaking with hybrid depth-infused quantum neural networks","abstract":"Accurate prediction and stabilization of blast furnace temperatures are crucial for optimizing the efficiency and productivity of steel production. Traditional methods often struggle with the complex and non-linear nature of the temperature fluctuations within blast furnaces. This paper proposes a novel approach that combines hybrid quantum machine learning with pulverized coal injection control to address these challenges. By integrating classical machine learning techniques with quantum computing algorithms, we aim to enhance predictive accuracy and achieve more stable temperature control. For this we utilized a unique prediction-based optimization method. Our method leverages quantum-enhanced feature space exploration and the robustness of classical regression models to forecast temperature variations and optimize pulverized coal injection values. Our results demonstrate a significant improvement in prediction accuracy over 25 percent and our solution improved temperature stability to +-7.6 degrees of target range from the earlier variance of +-50 degrees, highlighting the potential of hybrid quantum machine learning models in industrial steel production applications.","authors":["Nayoung Lee","Minsoo Shin","Asel Sagingalieva","Ayush Joshi Tripathi","Karan Pinto","Alexey Melnikov"],"url":"https://arxiv.org/abs/2504.12389"}
{"created":"2025-04-18","title":"A Survey on Archetypal Analysis","abstract":"Archetypal analysis (AA) was originally proposed in 1994 by Adele Cutler and Leo Breiman as a computational procedure to extract the distinct aspects called archetypes in observations with each observational record approximated as a mixture (i.e., convex combination) of these archetypes. AA thereby provides straightforward, interpretable, and explainable representations for feature extraction and dimensionality reduction, facilitating the understanding of the structure of high-dimensional data with wide applications throughout the sciences. However, AA also faces challenges, particularly as the associated optimization problem is non-convex. This survey provides researchers and data mining practitioners an overview of methodologies and opportunities that AA has to offer surveying the many applications of AA across disparate fields of science, as well as best practices for modeling data using AA and limitations. The survey concludes by explaining important future research directions concerning AA.","authors":["Aleix Alcacer","Irene Epifanio","Sebastian Mair","Morten M{\\o}rup"],"url":"https://arxiv.org/abs/2504.12392"}
{"created":"2025-04-18","title":"Corner Gradient Descent","abstract":"We consider SGD-type optimization on infinite-dimensional quadratic problems with power law spectral conditions. It is well-known that on such problems deterministic GD has loss convergence rates $L_t=O(t^{-\\zeta})$, which can be improved to $L_t=O(t^{-2\\zeta})$ by using Heavy Ball with a non-stationary Jacobi-based schedule (and the latter rate is optimal among fixed schedules). However, in the mini-batch Stochastic GD setting, the sampling noise causes the Jacobi HB to diverge; accordingly no $O(t^{-2\\zeta})$ algorithm is known. In this paper we show that rates up to $O(t^{-2\\zeta})$ can be achieved by a generalized stationary SGD with infinite memory. We start by identifying generalized (S)GD algorithms with contours in the complex plane. We then show that contours that have a corner with external angle $\\theta\\pi$ accelerate the plain GD rate $O(t^{-\\zeta})$ to $O(t^{-\\theta\\zeta})$. For deterministic GD, increasing $\\theta$ allows to achieve rates arbitrarily close to $O(t^{-2\\zeta})$. However, in Stochastic GD, increasing $\\theta$ also amplifies the sampling noise, so in general $\\theta$ needs to be optimized by balancing the acceleration and noise effects. We prove that the optimal rate is given by $\\theta_{\\max}=\\min(2,\\nu,\\tfrac{2}{\\zeta+1/\\nu})$, where $\\nu,\\zeta$ are the exponents appearing in the capacity and source spectral conditions. Furthermore, using fast rational approximations of the power functions, we show that ideal corner algorithms can be efficiently approximated by finite-memory algorithms, and demonstrate their practical efficiency on a synthetic problem and MNIST.","authors":["Dmitry Yarotsky"],"url":"https://arxiv.org/abs/2504.12519"}
{"created":"2025-04-18","title":"Interpreting Network Differential Privacy","abstract":"How do we interpret the differential privacy (DP) guarantee for network data? We take a deep dive into a popular form of network DP ($\\varepsilon$--edge DP) to find that many of its common interpretations are flawed. Drawing on prior work for privacy with correlated data, we interpret DP through the lens of adversarial hypothesis testing and demonstrate a gap between the pairs of hypotheses actually protected under DP (tests of complete networks) and the sorts of hypotheses implied to be protected by common claims (tests of individual edges). We demonstrate some conditions under which this gap can be bridged, while leaving some questions open. While some discussion is specific to edge DP, we offer selected results in terms of abstract DP definitions and provide discussion of the implications for other forms of network DP.","authors":["Jonathan Hehir","Xiaoyue Niu","Aleksandra Slavkovic"],"url":"https://arxiv.org/abs/2504.12520"}
{"created":"2025-04-18","title":"Robust and Scalable Variational Bayes","abstract":"We propose a robust and scalable framework for variational Bayes (VB) that effectively handles outliers and contamination of arbitrary nature in large datasets. Our approach divides the dataset into disjoint subsets, computes the posterior for each subset, and applies VB approximation independently to these posteriors. The resulting variational posteriors with respect to the subsets are then aggregated using the geometric median of probability measures, computed with respect to the Wasserstein distance. This novel aggregation method yields the Variational Median Posterior (VM-Posterior) distribution. We rigorously demonstrate that the VM-Posterior preserves contraction properties akin to those of the true posterior, while accounting for approximation errors or the variational gap inherent in VB methods. We also provide provable robustness guarantee of the VM-Posterior. Furthermore, we establish a variational Bernstein-von Mises theorem for both multivariate Gaussian distributions with general covariance structures and the mean-field variational family. To facilitate practical implementation, we adapt existing algorithms for computing the VM-Posterior and evaluate its performance through extensive numerical experiments. The results highlight its robustness and scalability, making it a reliable tool for Bayesian inference in the presence of complex, contaminated datasets.","authors":["Carlos Misael Madrid Padilla","Shitao Fan","Lizhen Lin"],"url":"https://arxiv.org/abs/2504.12528"}
{"created":"2025-04-18","title":"Fast Computation of the Discrete Fourier Transform Rectangular Index Coefficients","abstract":"In~\\cite{sic-magazine-2025}, the authors show that the square index coefficients (SICs) of the \\(N\\)-point discrete Fourier transform (DFT) -- that is, the coefficients \\(X_{k\\sqrt{N}}\\) for \\(k = 0, 1, \\ldots, \\sqrt{N} - 1\\) -- can be losslessly compressed from \\(N\\) to \\(\\sqrt{N}\\) points, thereby accelerating the computation of these specific DFT coefficients accordingly. Following up on that, in this article we generalize SICs into what we refer to as rectangular index coefficients (RICs) of the DFT, formalized as $X_{kL}, k=0,1,\\cdots,C-1$, in which the integers $C$ and $L$ are generic roots of $N$ such that $N=LC$. We present an algorithm to compress the $N$-point input signal $\\mathbf{x}$ into a $C$-point signal $\\mathbf{\\hat{x}}$ at the expense of $\\mathcal{O}(N)$ complex sums and no complex multiplication. We show that a DFT on $\\mathbf{\\hat{x}}$ is equivalent to a DFT on the RICs of $\\mathbf{x}$. In cases where specific frequencies of \\(\\mathbf{x}\\) are of interest -- as in harmonic analysis -- one can conveniently adjust the signal parameters (e.g., frequency resolution) to align the RICs with those frequencies, and use the proposed algorithm to compute them significantly faster. If $N$ is a power of two -- as required by the fast Fourier transform (FFT) algorithm -- then $C$ can be any power of two in the range $[2, N/2]$ and one can use our algorithm along with FFT to compute all RICs in $\\mathcal{O}(C\\log C)$ time complexity.","authors":["Saulo Queiroz","Jo\\~ao P. Vilela","Benjamin Koon Kei Ng","Chan-Tong Lam","Edmundo Monteiro"],"url":"https://arxiv.org/abs/2504.12551"}
{"created":"2025-04-18","title":"Acoustic Analysis of Uneven Blade Spacing and Toroidal Geometry for Reducing Propeller Annoyance","abstract":"Unmanned aerial vehicles (UAVs) are becoming more commonly used in populated areas, raising concerns about noise pollution generated from their propellers. This study investigates the acoustic performance of unconventional propeller designs, specifically toroidal and uneven-blade spaced propellers, for their potential in reducing psychoacoustic annoyance. Our experimental results show that these designs noticeably reduced acoustic characteristics associated with noise annoyance.","authors":["Nikhil Vijay","Will C. Forte","Ishan Gajjar","Sarvesh Patham","Syon Gupta","Sahil Shah","Prathamesh Trivedi","Rishit Arora"],"url":"https://arxiv.org/abs/2504.12554"}
{"created":"2025-04-18","title":"Featuremetric benchmarking: Quantum computer benchmarks based on circuit features","abstract":"Benchmarks that concisely summarize the performance of many-qubit quantum computers are essential for measuring progress towards the goal of useful quantum computation. In this work, we present a benchmarking framework that is based on quantifying how a quantum computer's performance on quantum circuits varies as a function of features of those circuits, such as circuit depth, width, two-qubit gate density, problem input size, or algorithmic depth. Our featuremetric benchmarking framework generalizes volumetric benchmarking -- a widely-used methodology that quantifies performance versus circuit width and depth -- and we show that it enables richer and more faithful models of quantum computer performance. We demonstrate featuremetric benchmarking with example benchmarks run on IBM Q and IonQ systems of up to 27 qubits, and we show how to produce performance summaries from the data using Gaussian process regression. Our data analysis methods are also of interest in the special case of volumetric benchmarking, as they enable the creation of intuitive two-dimensional capability regions using data from few circuits.","authors":["Timothy Proctor","Anh Tran","Xingxin Liu","Aditya Dhumuntarao","Stefan Seritan","Alaina Green","Norbert M Linke"],"url":"https://arxiv.org/abs/2504.12575"}
{"created":"2025-04-18","title":"Quantum Search on Bipartite Multigraphs","abstract":"Quantum walks provide a powerful framework for achieving algorithmic speedup in quantum computing. This paper presents a quantum search algorithm for 2-tessellable graphs, a generalization of bipartite graphs, achieving a quadratic speedup over classical Markov chain-based search methods. Our approach employs an adapted version of the Szegedy quantum walk model (adapted SzQW), which takes place on bipartite graphs, and an adapted version of Staggered Quantum Walks (Adapted StQW), which takes place on 2-tessellable graphs, with the goal of efficiently finding a marked vertex by querying an oracle. The Ambainis, Gily\\'en, Jeffery, and Kokainis' algorithm (AGJK), which provides a quadratic speedup on balanced bipartite graphs, is used as a subroutine in our algorithm. Our approach generalizes existing quantum walk techniques and offers a quadratic speedup in the number of queries needed, demonstrating the utility of our adapted quantum walk models in a broader class of graphs.","authors":["Gustavo Alves Bezerra","Andris Ambainis","Renato Portugal"],"url":"https://arxiv.org/abs/2504.12586"}
{"created":"2025-04-18","title":"Discrepancy of Arithmetic Progressions in Boxes and Convex Bodies","abstract":"The combinatorial discrepancy of arithmetic progressions inside $[N] := \\{1, \\ldots, N\\}$ is the smallest integer $D$ for which $[N]$ can be colored with two colors so that any arithmetic progression in $[N]$ contains at most $D$ more elements from one color class than the other. Bounding the discrepancy of such set systems is a classical problem in discrepancy theory. More recently, this problem was generalized to arithmetic progressions in grids like $[N]^d$ (Valk{\\'o}) and $[N_1]\\times \\ldots \\times [N_d]$ (Fox, Xu, and Zhou). In the latter setting, Fox, Xu, and Zhou gave upper and lower bounds on the discrepancy that match within a $\\frac{\\log |\\Omega|}{\\log \\log |\\Omega|}$ factor, where $\\Omega := [N_1]\\times \\ldots \\times [N_d]$ is the ground set. In this work, we use the connection between factorization norms and discrepancy to improve their upper bound to be within a $\\sqrt{\\log|\\Omega|}$ factor from the lower bound. We also generalize Fox, Xu, and Zhou's lower bound, and our upper bounds to arithmetic progressions in arbitrary convex bodies.","authors":["Lily Li","Aleksandar Nikolov"],"url":"https://arxiv.org/abs/2504.12598"}
{"created":"2025-04-18","title":"Spectral Algorithms under Covariate Shift","abstract":"Spectral algorithms leverage spectral regularization techniques to analyze and process data, providing a flexible framework for addressing supervised learning problems. To deepen our understanding of their performance in real-world scenarios where the distributions of training and test data may differ, we conduct a rigorous investigation into the convergence behavior of spectral algorithms under distribution shifts, specifically within the framework of reproducing kernel Hilbert spaces. Our study focuses on the case of covariate shift. In this scenario, the marginal distributions of the input data differ between the training and test datasets, while the conditional distribution of the output given the input remains unchanged. Under this setting, we analyze the generalization error of spectral algorithms and show that they achieve minimax optimality when the density ratios between the training and test distributions are uniformly bounded. However, we also identify a critical limitation: when the density ratios are unbounded, the spectral algorithms may become suboptimal. To address this limitation, we propose a weighted spectral algorithm that incorporates density ratio information into the learning process. Our theoretical analysis shows that this weighted approach achieves optimal capacity-independent convergence rates. Furthermore, by introducing a weight clipping technique, we demonstrate that the convergence rates of the weighted spectral algorithm can approach the optimal capacity-dependent convergence rates arbitrarily closely. This improvement resolves the suboptimality issue in unbounded density ratio scenarios and advances the state-of-the-art by refining existing theoretical results.","authors":["Jun Fan","Zheng-Chu Guo","Lei Shi"],"url":"https://arxiv.org/abs/2504.12625"}
{"created":"2025-04-18","title":"Temporal Attention Pooling for Frequency Dynamic Convolution in Sound Event Detection","abstract":"Recent advances in deep learning, particularly frequency dynamic convolution (FDY conv), have significantly improved sound event detection (SED) by enabling frequency-adaptive feature extraction. However, FDY conv relies on temporal average pooling, which treats all temporal frames equally, limiting its ability to capture transient sound events such as alarm bells, door knocks, and speech plosives. To address this limitation, we propose temporal attention pooling frequency dynamic convolution (TFD conv) to replace temporal average pooling with temporal attention pooling (TAP). TAP adaptively weights temporal features through three complementary mechanisms: time attention pooling (TA) for emphasizing salient features, velocity attention pooling (VA) for capturing transient changes, and conventional average pooling for robustness to stationary signals. Ablation studies show that TFD conv improves average PSDS1 by 3.02% over FDY conv with only a 14.8% increase in parameter count. Classwise ANOVA and Tukey HSD analysis further demonstrate that TFD conv significantly enhances detection performance for transient-heavy events, outperforming existing FDY conv models. Notably, TFD conv achieves a maximum PSDS1 score of 0.456, surpassing previous state-of-the-art SED systems. We also explore the compatibility of TAP with other FDY conv variants, including dilated FDY conv (DFD conv), partial FDY conv (PFD conv), and multi-dilated FDY conv (MDFD conv). Among these, the integration of TAP with MDFD conv achieves the best result with a PSDS1 score of 0.459, validating the complementary strengths of temporal attention and multi-scale frequency adaptation. These findings establish TFD conv as a powerful and generalizable framework for enhancing both transient sensitivity and overall feature robustness in SED.","authors":["Hyeonuk Nam","Yong-Hwa Park"],"url":"https://arxiv.org/abs/2504.12670"}
{"created":"2025-04-18","title":"Post-processing improves accuracy of Artificial Intelligence weather forecasts","abstract":"Artificial Intelligence (AI) weather models are now reaching operational-grade performance for some variables, but like traditional Numerical Weather Prediction (NWP) models, they exhibit systematic biases and reliability issues. We test the application of the Bureau of Meteorology's existing statistical post-processing system, IMPROVER, to ECMWF's deterministic Artificial Intelligence Forecasting System (AIFS), and compare results against post-processed outputs from the ECMWF HRES and ENS models. Without any modification to configuration or processing workflows, post-processing yields comparable accuracy improvements for AIFS as for traditional NWP forecasts, in both expected value and probabilistic outputs. We show that blending AIFS with NWP models improves overall forecast skill, even when AIFS alone is not the most accurate component. These findings show that statistical post-processing methods developed for NWP are directly applicable to AI models, enabling national meteorological centres to incorporate AI forecasts into existing workflows in a low-risk, incremental fashion.","authors":["Belinda Trotta","Robert Johnson","Catherine de Burgh-Day","Debra Hudson","Esteban Abellan","James Canvin","Andrew Kelly","Daniel Mentiplay","Benjamin Owen","Jennifer Whelan"],"url":"https://arxiv.org/abs/2504.12672"}
{"created":"2025-04-18","title":"Cluster weighted models with multivariate skewed distributions for functional data","abstract":"We propose a clustering method, funWeightClustSkew, based on mixtures of functional linear regression models and three skewed multivariate distributions: the variance-gamma distribution, the skew-t distribution, and the normal-inverse Gaussian distribution. Our approach follows the framework of the functional high dimensional data clustering (funHDDC) method, and we extend to functional data the cluster weighted models based on skewed distributions used for finite dimensional multivariate data. We consider several parsimonious models, and to estimate the parameters we construct an expectation maximization (EM) algorithm. We illustrate the performance of funWeightClustSkew for simulated data and for the Air Quality dataset.","authors":["Cristina Anton","Roy Shivam Ram Shreshtth"],"url":"https://arxiv.org/abs/2504.12683"}
{"created":"2025-04-18","title":"Attractor-merging Crises and Intermittency in Reservoir Computing","abstract":"Reservoir computing can embed attractors into random neural networks (RNNs), generating a ``mirror'' of a target attractor because of its inherent symmetrical constraints. In these RNNs, we report that an attractor-merging crisis accompanied by intermittency emerges simply by adjusting the global parameter. We further reveal its underlying mechanism through a detailed analysis of the phase-space structure and demonstrate that this bifurcation scenario is intrinsic to a general class of RNNs, independent of training data.","authors":["Tempei Kabayama","Motomasa Komuro","Yasuo Kuniyoshi","Kazuyuki Aihara","Kohei Nakajima"],"url":"https://arxiv.org/abs/2504.12695"}
{"created":"2025-04-18","title":"A Two-Phase Perspective on Deep Learning Dynamics","abstract":"We propose that learning in deep neural networks proceeds in two phases: a rapid curve fitting phase followed by a slower compression or coarse graining phase. This view is supported by the shared temporal structure of three phenomena: grokking, double descent and the information bottleneck, all of which exhibit a delayed onset of generalization well after training error reaches zero. We empirically show that the associated timescales align in two rather different settings. Mutual information between hidden layers and input data emerges as a natural progress measure, complementing circuit-based metrics such as local complexity and the linear mapping number. We argue that the second phase is not actively optimized by standard training algorithms and may be unnecessarily prolonged. Drawing on an analogy with the renormalization group, we suggest that this compression phase reflects a principled form of forgetting, critical for generalization.","authors":["Robert de Mello Koch","Animik Ghosh"],"url":"https://arxiv.org/abs/2504.12700"}
{"created":"2025-04-18","title":"TUMLS: Trustful Fully Unsupervised Multi-Level Segmentation for Whole Slide Images of Histology","abstract":"Digital pathology, augmented by artificial intelligence (AI), holds significant promise for improving the workflow of pathologists. However, challenges such as the labor-intensive annotation of whole slide images (WSIs), high computational demands, and trust concerns arising from the absence of uncertainty estimation in predictions hinder the practical application of current AI methodologies in histopathology. To address these issues, we present a novel trustful fully unsupervised multi-level segmentation methodology (TUMLS) for WSIs. TUMLS adopts an autoencoder (AE) as a feature extractor to identify the different tissue types within low-resolution training data. It selects representative patches from each identified group based on an uncertainty measure and then does unsupervised nuclei segmentation in their respective higher-resolution space without using any ML algorithms. Crucially, this solution integrates seamlessly into clinicians workflows, transforming the examination of a whole WSI into a review of concise, interpretable cross-level insights. This integration significantly enhances and accelerates the workflow while ensuring transparency. We evaluated our approach using the UPENN-GBM dataset, where the AE achieved a mean squared error (MSE) of 0.0016. Additionally, nucleus segmentation is assessed on the MoNuSeg dataset, outperforming all unsupervised approaches with an F1 score of 77.46% and a Jaccard score of 63.35%. These results demonstrate the efficacy of TUMLS in advancing the field of digital pathology.","authors":["Walid Rehamnia","Alexandra Getmanskaya","Evgeniy Vasilyev","Vadim Turlapov"],"url":"https://arxiv.org/abs/2504.12718"}
{"created":"2025-04-18","title":"Dead Gate Elimination","abstract":"Hybrid quantum algorithms combine the strengths of quantum and classical computing. Many quantum algorithms, such as the variational quantum eigensolver (VQE), leverage this synergy. However, quantum circuits are executed in full, even when only subsets of measurement outcomes contribute to subsequent classical computations. In this manuscript, we propose a novel circuit optimization technique that identifies and removes dead gates. We prove that the removal of dead gates has no influence on the probability distribution of the measurement outcomes that contribute to the subsequent calculation result. We implemented and evaluated our optimization on a VQE instance, a quantum phase estimation (QPE) instance, and hybrid programs embedded with random circuits of varying circuit width, confirming its capability to remove a non-trivial number of dead gates in real-world algorithms. The effect of our optimization scales up as more measurement outcomes are identified as non-contributory, resulting in a proportionally greater reduction of dead gates.","authors":["Yanbin Chen","Christian B. Mendl","Helmut Seidl"],"url":"https://arxiv.org/abs/2504.12729"}
{"created":"2025-04-18","title":"Universal Approximation with XL MIMO Systems: OTA Classification via Trainable Analog Combining","abstract":"In this paper, we demonstrate that an eXtremely Large (XL) Multiple-Input Multiple-Output (MIMO) wireless system with appropriate analog combining components exhibits the properties of a universal function approximator, similar to a feedforward neural network. By treating the XL MIMO channel coefficients as the random nodes of a hidden layer, and the receiver's analog combiner as a trainable output layer, we cast the end-to-end system to the Extreme Learning Machine (ELM) framework, leading to a novel formulation for Over-The-Air (OTA) edge inference without requiring traditional digital processing nor pre-processing at the transmitter. Through theoretical analysis and numerical evaluation, we showcase that XL-MIMO-ELM enables near-instantaneous training and efficient classification, suggesting the paradigm shift of beyond massive MIMO systems as neural networks alongside their profound communications role. Compared to deep learning approaches and conventional ELMs, the proposed framework achieves on par performance with orders of magnitude lower complexity, making it highly attractive for ultra low power wireless devices.","authors":["Kyriakos Stylianopoulos","George C. Alexandropoulos"],"url":"https://arxiv.org/abs/2504.12758"}
{"created":"2025-04-18","title":"Integral control of the proximal gradient method for unbiased sparse optimization","abstract":"Proximal gradient methods are popular in sparse optimization as they are straightforward to implement. Nevertheless, they achieve biased solutions, requiring many iterations to converge. This work addresses these issues through a suitable feedback control of the algorithm's hyperparameter. Specifically, by designing an integral control that does not substantially impact the computational complexity, we can reach an unbiased solution in a reasonable number of iterations. In the paper, we develop and analyze the convergence of the proposed approach for strongly-convex problems. Moreover, numerical simulations validate and extend the theoretical results to the non-strongly convex framework.","authors":["V. Cerone","S. M. Fosson","A. Re","D. Regruto"],"url":"https://arxiv.org/abs/2504.12814"}
{"created":"2025-04-18","title":"Inverse iteration method for higher eigenvalues of the $p$-Laplacian","abstract":"We propose a characterization of a $p$-Laplace higher eigenvalue based on the inverse iteration method with balancing the Rayleigh quotients of the positive and negative parts of solutions to consecutive $p$-Poisson equations. The approach relies on the second eigenvalue's minimax properties, but the actual limiting eigenvalue depends on the choice of initial function. The well-posedness and convergence of the iterative scheme are proved. Moreover, we provide the corresponding numerical computations. As auxiliary results, which also have an independent interest, we provide several properties of certain $p$-Poisson problems.","authors":["Vladimir Bobkov","Timur Galimov"],"url":"https://arxiv.org/abs/2504.12836"}
{"created":"2025-04-18","title":"Timing via Pinwheel Double Categories","abstract":"We discuss string diagrams for timed process theories -- represented by duoidally-graded symmetric strict monoidal categories -- built upon the string diagrams of pinwheel double categories.","authors":["Elena Di Lavore","Mario Rom\\'an"],"url":"https://arxiv.org/abs/2504.12846"}
{"created":"2025-04-18","title":"A note on distance-hereditary graphs whose complement is also distance-hereditary","abstract":"Distance-hereditary graphs are known to be the graphs that are totally decomposable for the split decomposition. We characterise distance-hereditary graphs whose complement is also distance-hereditary by their split decomposition and by their modular decomposition.","authors":["Hugo Jacob"],"url":"https://arxiv.org/abs/2504.12857"}
{"created":"2025-04-18","title":"When do Random Forests work?","abstract":"We study the effectiveness of randomizing split-directions in random forests. Prior literature has shown that, on the one hand, randomization can reduce variance through decorrelation, and, on the other hand, randomization regularizes and works in low signal-to-noise ratio (SNR) environments. First, we bring together and revisit decorrelation and regularization by presenting a systematic analysis of out-of-sample mean-squared error (MSE) for different SNR scenarios based on commonly-used data-generating processes. We find that variance reduction tends to increase with the SNR and forests outperform bagging when the SNR is low because, in low SNR cases, variance dominates bias for both methods. Second, we show that the effectiveness of randomization is a question that goes beyond the SNR. We present a simulation study with fixed and moderate SNR, in which we examine the effectiveness of randomization for other data characteristics. In particular, we find that (i) randomization can increase bias in the presence of fat tails in the distribution of covariates; (ii) in the presence of irrelevant covariates randomization is ineffective because bias dominates variance; and (iii) when covariates are mutually correlated randomization tends to be effective because variance dominates bias. Beyond randomization, we find that, for both bagging and random forests, bias can be significantly reduced in the presence of correlated covariates. This last finding goes beyond the prevailing view that averaging mostly works by variance reduction. Given that in practice covariates are often correlated, our findings on correlated covariates could open the way for a better understanding of why random forests work well in many applications.","authors":["C. Revelas","O. Boldea","B. J. M. Werker"],"url":"https://arxiv.org/abs/2504.12860"}
{"created":"2025-04-18","title":"EmoVoice: LLM-based Emotional Text-To-Speech Model with Freestyle Text Prompting","abstract":"Human speech goes beyond the mere transfer of information; it is a profound exchange of emotions and a connection between individuals. While Text-to-Speech (TTS) models have made huge progress, they still face challenges in controlling the emotional expression in the generated speech. In this work, we propose EmoVoice, a novel emotion-controllable TTS model that exploits large language models (LLMs) to enable fine-grained freestyle natural language emotion control, and a phoneme boost variant design that makes the model output phoneme tokens and audio tokens in parallel to enhance content consistency, inspired by chain-of-thought (CoT) and modality-of-thought (CoM) techniques. Besides, we introduce EmoVoice-DB, a high-quality 40-hour English emotion dataset featuring expressive speech and fine-grained emotion labels with natural language descriptions. EmoVoice achieves state-of-the-art performance on the English EmoVoice-DB test set using only synthetic training data, and on the Chinese Secap test set using our in-house data. We further investigate the reliability of existing emotion evaluation metrics and their alignment with human perceptual preferences, and explore using SOTA multimodal LLMs GPT-4o-audio and Gemini to assess emotional speech. Demo samples are available at https://anonymous.4open.science/r/EmoVoice-DF55. Dataset, code, and checkpoints will be released.","authors":["Guanrou Yang","Chen Yang","Qian Chen","Ziyang Ma","Wenxi Chen","Wen Wang","Tianrui Wang","Yifan Yang","Zhikang Niu","Wenrui Liu","Fan Yu","Zhihao Du","Zhifu Gao","ShiLiang Zhang","Xie Chen"],"url":"https://arxiv.org/abs/2504.12867"}
{"created":"2025-04-18","title":"RIS-Assisted Beamfocusing in Near-Field IoT Communication Systems: A Transformer-Based Approach","abstract":"The massive number of antennas in extremely large aperture array (ELAA) systems shifts the propagation regime of signals in internet of things (IoT) communication systems towards near-field spherical wave propagation. We propose a reconfigurable intelligent surfaces (RIS)-assisted beamfocusing mechanism, where the design of the two-dimensional beam codebook that contains both the angular and distance domains is challenging. To address this issue, we introduce a novel Transformer-based two-stage beam training algorithm, which includes the coarse and fine search phases. The proposed mechanism provides a fine-grained codebook with enhanced spatial resolution, enabling precise beamfocusing. Specifically, in the first stage, the beam training is performed to estimate the approximate location of the device by using a simple codebook, determining whether it is within the beamfocusing range (BFR) or the none-beamfocusing range (NBFR). In the second stage, by using a more precise codebook, a fine-grained beam search strategy is conducted. Experimental results unveil that the precision of the RIS-assisted beamfocusing is greatly improved. The proposed method achieves beam selection accuracy up to 97% at signal-to-noise ratio (SNR) of 20 dB, and improves 10% to 50% over the baseline method at different SNRs.","authors":["Quan Zhou","Jingjing Zhao","Kaiquan Cai","Yanbo Zhu"],"url":"https://arxiv.org/abs/2504.12889"}
{"created":"2025-04-18","title":"OntoPortal-Astro, a Semantic Artefact Catalogue for Astronomy","abstract":"The astronomy communities are widely recognised as mature communities for their open science practices. However, while their data ecosystems are rather advanced and permit efficient data interoperability, there are still gaps between these ecosystems. Semantic artefacts (e.g., ontologies, thesauri, vocabularies or metadata schemas) are a means to bridge that gap as they allow to semantically described the data and map the underlying concepts. The increasing use of semantic artefacts in astronomy presents challenges in description, selection, evaluation, trust, and mappings. The landscape remains fragmented, with semantic artefacts scattered across various registries in diverse formats and structures -- not yet fully developed or encoded with rich semantic web standards like OWL or SKOS -- and often with overlapping scopes. Enhancing data semantic interoperability requires common platforms to catalog, align, and facilitate the sharing of FAIR semantic artefacts. In the frame of the FAIR-IMPACT project, we prototyped a semantic artefact catalogue for astronomy, heliophysics and planetary sciences. This exercise resulted in improved vocabulary and ontology management in the communities, and is now paving the way for better interdisciplinary data discovery and reuse. This article presents current practices in our discipline, reviews candidate SAs for such a catalogue, presents driving use cases and the perspective of a real production service for the astronomy community based on the OntoPortal technology, that will be called OntoPortal-Astro.","authors":["Baptiste Cecconi","Laura Debisschop","S\\'ebastien Derri\\`ere","Mireille Louys","Carmen Corre","Nina Grau","Cl\\'ement Jonquet"],"url":"https://arxiv.org/abs/2504.12897"}
{"created":"2025-04-18","title":"On the asymptotic behaviour of stochastic processes, with applications to supermartingale convergence, Dvoretzky's approximation theorem, and stochastic quasi-Fej\\'er monotonicity","abstract":"We prove a novel and general result on the asymptotic behavior of stochastic processes which conform to a certain relaxed supermartingale condition. Our result provides quantitative information in the form of an explicit and effective construction of a rate of convergence for this process, both in mean and almost surely, that is moreover highly uniform in the sense that it only depends on very few data of the surrounding objects involved in the iteration. We then apply this result to derive new quantitative versions of well-known concepts and theorems from stochastic approximation, in particular providing effective rates for a variant of the Robbins-Siegmund theorem, Dvoretzky's convergence theorem, as well as the convergence of stochastic quasi-Fej\\'er monotone sequences, the latter of which formulated in a novel and highly general metric context. We utilize the classic and widely studied Robbins-Monro procedure as a template to evaluate our quantitative results and their applicability in greater detail. We conclude by illustrating the breadth of potential further applications with a brief discussion on a variety of other well-known iterative procedures from stochastic approximation, covering a range of different applied scenarios to which our methods can be immediately applied. Throughout, we isolate and discuss special cases of our results which even allow for the construction of fast, and in particular linear, rates.","authors":["Morenikeji Neri","Nicholas Pischke","Thomas Powell"],"url":"https://arxiv.org/abs/2504.12922"}
{"created":"2025-04-18","title":"Efficient Chebyshev Reconstruction for the Anisotropic Equilibrium Model in Magnetic Particle Imaging","abstract":"Magnetic Particle Imaging (MPI) is a tomographic imaging modality capable of real-time, high-sensitivity mapping of superparamagnetic iron oxide nanoparticles. Model-based image reconstruction provides an alternative to conventional methods that rely on a measured system matrix, eliminating the need for laborious calibration measurements. Nevertheless, model-based approaches must account for the complexities of the imaging chain to maintain high image quality. A recently proposed direct reconstruction method leverages weighted Chebyshev polynomials in the frequency domain, removing the need for a simulated system matrix. However, the underlying model neglects key physical effects, such as nanoparticle anisotropy, leading to distortions in reconstructed images. To mitigate these artifacts, an adapted direct Chebyshev reconstruction (DCR) method incorporates a spatially variant deconvolution step, significantly improving reconstruction accuracy at the cost of increased computational demands. In this work, we evaluate the adapted DCR on six experimental phantoms, demonstrating enhanced reconstruction quality in real measurements and achieving image fidelity comparable to or exceeding that of simulated system matrix reconstruction. Furthermore, we introduce an efficient approximation for the spatially variable deconvolution, reducing both runtime and memory consumption while maintaining accuracy. This method achieves computational complexity of O(N log N ), making it particularly beneficial for high-resolution and three-dimensional imaging. Our results highlight the potential of the adapted DCR approach for improving model-based MPI reconstruction in practical applications.","authors":["Christine Droigk","Daniel Hern\\'andez Dur\\'an","Marco Maass","Tobias Knopp","Konrad Scheffler"],"url":"https://arxiv.org/abs/2504.12981"}
{"created":"2025-04-18","title":"Query Complexity of Classical and Quantum Channel Discrimination","abstract":"Quantum channel discrimination has been studied from an information-theoretic perspective, wherein one is interested in the optimal decay rate of error probabilities as a function of the number of unknown channel accesses. In this paper, we study the query complexity of quantum channel discrimination, wherein the goal is to determine the minimum number of channel uses needed to reach a desired error probability. To this end, we show that the query complexity of binary channel discrimination depends logarithmically on the inverse error probability and inversely on the negative logarithm of the (geometric and Holevo) channel fidelity. As a special case of these findings, we precisely characterize the query complexity of discriminating between two classical channels. We also provide lower and upper bounds on the query complexity of binary asymmetric channel discrimination and multiple quantum channel discrimination. For the former, the query complexity depends on the geometric R\\'enyi and Petz R\\'enyi channel divergences, while for the latter, it depends on the negative logarithm of (geometric and Uhlmann) channel fidelity. For multiple channel discrimination, the upper bound scales as the logarithm of the number of channels.","authors":["Theshani Nuradha","Mark M. Wilde"],"url":"https://arxiv.org/abs/2504.12989"}
{"created":"2025-04-18","title":"Towards Cardiac MRI Foundation Models: Comprehensive Visual-Tabular Representations for Whole-Heart Assessment and Beyond","abstract":"Cardiac magnetic resonance imaging is the gold standard for non-invasive cardiac assessment, offering rich spatio-temporal views of the cardiac anatomy and physiology. Patient-level health factors, such as demographics, metabolic, and lifestyle, are known to substantially influence cardiovascular health and disease risk, yet remain uncaptured by CMR alone. To holistically understand cardiac health and to enable the best possible interpretation of an individual's disease risk, CMR and patient-level factors must be jointly exploited within an integrated framework. Recent multi-modal approaches have begun to bridge this gap, yet they often rely on limited spatio-temporal data and focus on isolated clinical tasks, thereby hindering the development of a comprehensive representation for cardiac health evaluation. To overcome these limitations, we introduce ViTa, a step toward foundation models that delivers a comprehensive representation of the heart and a precise interpretation of individual disease risk. Leveraging data from 42,000 UK Biobank participants, ViTa integrates 3D+T cine stacks from short-axis and long-axis views, enabling a complete capture of the cardiac cycle. These imaging data are then fused with detailed tabular patient-level factors, enabling context-aware insights. This multi-modal paradigm supports a wide spectrum of downstream tasks, including cardiac phenotype and physiological feature prediction, segmentation, and classification of cardiac and metabolic diseases within a single unified framework. By learning a shared latent representation that bridges rich imaging features and patient context, ViTa moves beyond traditional, task-specific models toward a universal, patient-specific understanding of cardiac health, highlighting its potential to advance clinical utility and scalability in cardiac analysis.","authors":["Yundi Zhang","Paul Hager","Che Liu","Suprosanna Shit","Chen Chen","Daniel Rueckert","Jiazhen Pan"],"url":"https://arxiv.org/abs/2504.13037"}
{"created":"2025-04-18","title":"The Dissipation Theory of Aging: A Quantitative Analysis Using a Cellular Aging Map","abstract":"We propose a new theory for aging based on dynamical systems and provide a data-driven computational method to quantify the changes at the cellular level. We use ergodic theory to decompose the dynamics of changes during aging and show that aging is fundamentally a dissipative process within biological systems, akin to dynamical systems where dissipation occurs due to non-conservative forces. To quantify the dissipation dynamics, we employ a transformer-based machine learning algorithm to analyze gene expression data, incorporating age as a token to assess how age-related dissipation is reflected in the embedding space. By evaluating the dynamics of gene and age embeddings, we provide a cellular aging map (CAM) and identify patterns indicative of divergence in gene embedding space, nonlinear transitions, and entropy variations during aging for various tissues and cell types. Our results provide a novel perspective on aging as a dissipative process and introduce a computational framework that enables measuring age-related changes with molecular resolution.","authors":["Farhan Khodaee","Rohola Zandie","Yufan Xia","Elazer R. Edelman"],"url":"https://arxiv.org/abs/2504.13044"}
{"created":"2025-04-18","title":"Design Topological Materials by Reinforcement Fine-Tuned Generative Model","abstract":"Topological insulators (TIs) and topological crystalline insulators (TCIs) are materials with unconventional electronic properties, making their discovery highly valuable for practical applications. However, such materials, particularly those with a full band gap, remain scarce. Given the limitations of traditional approaches that scan known materials for candidates, we focus on the generation of new topological materials through a generative model. Specifically, we apply reinforcement fine-tuning (ReFT) to a pre-trained generative model, thereby aligning the model's objectives with our material design goals. We demonstrate that ReFT is effective in enhancing the model's ability to generate TIs and TCIs, with minimal compromise on the stability of the generated materials. Using the fine-tuned model, we successfully identify a large number of new topological materials, with Ge$_2$Bi$_2$O$_6$ serving as a representative example--a TI with a full band gap of 0.26 eV, ranking among the largest known in this category.","authors":["Haosheng Xu","Dongheng Qian","Zhixuan Liu","Yadong Jiang","Jing Wang"],"url":"https://arxiv.org/abs/2504.13048"}
{"created":"2025-04-18","title":"An exact approach for the multi-depot electric vehicle scheduling problem","abstract":"The \"avoid - shift - improve\" framework and the European Clean Vehicles Directive set the path for improving the efficiency and ultimately decarbonizing the transport sector. While electric buses have already been adopted in several cities, regional bus lines may pose additional challenges due to the potentially longer distances they have to travel. In this work, we model and solve the electric bus scheduling problem, lexicographically minimizing the size of the bus fleet, the number of charging stops, and the total energy consumed, to provide decision support for bus operators planning to replace their diesel-powered fleet with zero emission vehicles. We propose a graph representation which allows partial charging without explicitly relying on time variables and derive 3-index and 2-index mixed-integer linear programming formulations for the multi-depot electric vehicle scheduling problem. While the 3-index model can be solved by an off-the-shelf solver directly, the 2-index model relies on an exponential number of constraints to ensure the correct depot pairing. These are separated in a cutting plane fashion. We propose a set of instances with up to 80 service trips to compare the two approaches, showing that, with a small number of depots, the compact 3-index model performs very well. However, as the number of depots increases the developed branch-and-cut algorithm proves to be of value. These findings not only offer algorithmic insights but the developed approaches also provide actionable guidance for transit agencies and operators, allowing to quantify trade-offs between fleet size, energy efficiency, and infrastructure needs under realistic operational conditions.","authors":["Xenia Haslinger","Elisabeth Gaar","Sophie N. Parragh"],"url":"https://arxiv.org/abs/2504.13063"}
{"created":"2025-04-18","title":"Propagation of Chaos in One-hidden-layer Neural Networks beyond Logarithmic Time","abstract":"We study the approximation gap between the dynamics of a polynomial-width neural network and its infinite-width counterpart, both trained using projected gradient descent in the mean-field scaling regime. We demonstrate how to tightly bound this approximation gap through a differential equation governed by the mean-field dynamics. A key factor influencing the growth of this ODE is the local Hessian of each particle, defined as the derivative of the particle's velocity in the mean-field dynamics with respect to its position. We apply our results to the canonical feature learning problem of estimating a well-specified single-index model; we permit the information exponent to be arbitrarily large, leading to convergence times that grow polynomially in the ambient dimension $d$. We show that, due to a certain ``self-concordance'' property in these problems -- where the local Hessian of a particle is bounded by a constant times the particle's velocity -- polynomially many neurons are sufficient to closely approximate the mean-field dynamics throughout training.","authors":["Margalit Glasgow","Denny Wu","Joan Bruna"],"url":"https://arxiv.org/abs/2504.13110"}
{"created":"2025-04-18","title":"NTIRE 2025 Challenge on Short-form UGC Video Quality Assessment and Enhancement: Methods and Results","abstract":"This paper presents a review for the NTIRE 2025 Challenge on Short-form UGC Video Quality Assessment and Enhancement. The challenge comprises two tracks: (i) Efficient Video Quality Assessment (KVQ), and (ii) Diffusion-based Image Super-Resolution (KwaiSR). Track 1 aims to advance the development of lightweight and efficient video quality assessment (VQA) models, with an emphasis on eliminating reliance on model ensembles, redundant weights, and other computationally expensive components in the previous IQA/VQA competitions. Track 2 introduces a new short-form UGC dataset tailored for single image super-resolution, i.e., the KwaiSR dataset. It consists of 1,800 synthetically generated S-UGC image pairs and 1,900 real-world S-UGC images, which are split into training, validation, and test sets using a ratio of 8:1:1. The primary objective of the challenge is to drive research that benefits the user experience of short-form UGC platforms such as Kwai and TikTok. This challenge attracted 266 participants and received 18 valid final submissions with corresponding fact sheets, significantly contributing to the progress of short-form UGC VQA and image superresolution. The project is publicly available at https://github.com/lixinustc/KVQE- ChallengeCVPR-NTIRE2025.","authors":["Xin Li","Kun Yuan","Bingchen Li","Fengbin Guan","Yizhen Shao","Zihao Yu","Xijun Wang","Yiting Lu","Wei Luo","Suhang Yao","Ming Sun","Chao Zhou","Zhibo Chen","Radu Timofte","Yabin Zhang","Ao-Xiang Zhang","Tianwu Zhi","Jianzhao Liu","Yang Li","Jingwen Xu","Yiting Liao","Yushen Zuo","Mingyang Wu","Renjie Li","Shengyun Zhong","Zhengzhong Tu","Yufan Liu","Xiangguang Chen","Zuowei Cao","Minhao Tang","Shan Liu","Kexin Zhang","Jingfen Xie","Yan Wang","Kai Chen","Shijie Zhao","Yunchen Zhang","Xiangkai Xu","Hong Gao","Ji Shi","Yiming Bao","Xiugang Dong","Xiangsheng Zhou","Yaofeng Tu","Ying Liang","Yiwen Wang","Xinning Chai","Yuxuan Zhang","Zhengxue Cheng","Yingsheng Qin","Yucai Yang","Rong Xie","Li Song","Wei Sun","Kang Fu","Linhan Cao","Dandan Zhu","Kaiwei Zhang","Yucheng Zhu","Zicheng Zhang","Menghan Hu","Xiongkuo Min","Guangtao Zhai","Zhi Jin","Jiawei Wu","Wei Wang","Wenjian Zhang","Yuhai Lan","Gaoxiong Yi","Hengyuan Na","Wang Luo","Di Wu","MingYin Bai","Jiawang Du","Zilong Lu","Zhenyu Jiang","Hui Zeng","Ziguan Cui","Zongliang Gan","Guijin Tang","Xinglin Xie","Kehuan Song","Xiaoqiang Lu","Licheng Jiao","Fang Liu","Xu Liu","Puhua Chen","Ha Thu Nguyen","Katrien De Moor","Seyed Ali Amirshahi","Mohamed-Chaker Larabi","Qi Tang","Linfeng He","Zhiyong Gao","Zixuan Gao","Guohua Zhang","Zhiye Huang","Yi Deng","Qingmiao Jiang","Lu Chen","Yi Yang","Xi Liao","Nourine Mohammed Nadir","Yuxuan Jiang","Qiang Zhu","Siyue Teng","Fan Zhang","Shuyuan Zhu","Bing Zeng","David Bull","Meiqin Liu","Chao Yao","Yao Zhao"],"url":"https://arxiv.org/abs/2504.13131"}
{"created":"2025-04-18","title":"Learning spatial hearing via innate mechanisms","abstract":"The acoustic cues used by humans and other animals to localise sounds are subtle, and change during and after development. This means that we need to constantly relearn or recalibrate the auditory spatial map throughout our lifetimes. This is often thought of as a \"supervised\" learning process where a \"teacher\" (for example, a parent, or your visual system) tells you whether or not you guessed the location correctly, and you use this information to update your map. However, there is not always an obvious teacher (for example in babies or blind people). Using computational models, we showed that approximate feedback from a simple innate circuit, such as that can distinguish left from right (e.g. the auditory orienting response), is sufficient to learn an accurate full-range spatial auditory map. Moreover, using this mechanism in addition to supervised learning can more robustly maintain the adaptive neural representation. We find several possible neural mechanisms that could underlie this type of learning, and hypothesise that multiple mechanisms may be present and interact with each other. We conclude that when studying spatial hearing, we should not assume that the only source of learning is from the visual system or other supervisory signal. Further study of the proposed mechanisms could allow us to design better rehabilitation programmes to accelerate relearning/recalibration of spatial maps.","authors":["Yang Chu","Wayne Luk","Dan Goodman"],"url":"https://arxiv.org/abs/2001.10605"}
{"created":"2025-04-18","title":"K\\\"ahler information manifolds of signal processing filters in weighted Hardy spaces","abstract":"We extend the framework of K\\\"ahler information manifolds for complex-valued signal processing filters by introducing weighted Hardy spaces and smooth transformations of transfer functions. We demonstrate that the Riemannian geometry induced from weighted Hardy norms for the smooth transformations of its transfer function is a K\\\"ahler manifold. In this setting, the K\\\"ahler potential of the linear system geometry corresponds to the squared weighted Hardy norm of the composite transfer function. With the inherent structure of K\\\"ahler manifolds, geometric quantities on the manifold of linear systems in weighted Hardy spaces can be computed more efficiently and elegantly. Moreover, this generalized framework unifies a variety of well-known information manifolds within the structure of K\\\"ahler information manifolds for signal filters. Several illustrative examples from time series models are provided, wherein the metric tensor, Levi-Civita connection, and K\\\"ahler potentials are explicitly expressed in terms of polylogarithmic functions of the poles and zeros of transfer functions parameterized by weight vectors.","authors":["Jaehyung Choi"],"url":"https://arxiv.org/abs/2108.07746"}
{"created":"2025-04-18","title":"Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study on Out-of-Distribution Generalisation","abstract":"Combining deep learning with symbolic logic reasoning aims to capitalize on the success of both fields and is drawing increasing attention. Inspired by DeepLogic, an end-to-end model trained to perform inference on logic programs, we introduce IMA-GloVe-GA, an iterative neural inference network for multi-step reasoning expressed in natural language. In our model, reasoning is performed using an iterative memory neural network based on RNN with a gated attention mechanism. We evaluate IMA-GloVe-GA on three datasets: PARARULES, CONCEPTRULES V1 and CONCEPTRULES V2. Experimental results show DeepLogic with gated attention can achieve higher test accuracy than DeepLogic and other RNN baseline models. Our model achieves better out-of-distribution generalisation than RoBERTa-Large when the rules have been shuffled. Furthermore, to address the issue of unbalanced distribution of reasoning depths in the current multi-step reasoning datasets, we develop PARARULE-Plus, a large dataset with more examples that require deeper reasoning steps. Experimental results show that the addition of PARARULE-Plus can increase the model's performance on examples requiring deeper reasoning depths. The source code and data are available at https://github.com/Strong-AI-Lab/Multi-Step-Deductive-Reasoning-Over-Natural-Language.","authors":["Qiming Bao","Alex Yuxuan Peng","Tim Hartill","Neset Tan","Zhenyun Deng","Michael Witbrock","Jiamou Liu"],"url":"https://arxiv.org/abs/2207.14000"}
{"created":"2025-04-18","title":"ARES: An Efficient Algorithm with Recurrent Evaluation and Sampling-Driven Inference for Maximum Independent Set","abstract":"The Maximum Independent Set (MIS) problem is a well-known NP-complete problem with a wide range of applications across various fields. Heuristic approaches are commonly utilized to efficiently tackle large instances of this problem, yielding high-quality solutions within a reasonable time. However, heuristics face challenges such as falling into local optima and redundant searches within the solution space. This paper introduces an efficient heuristic algorithm for the MIS problem, incorporating two innovative techniques. The first technique features a recurrent evaluation mechanism that monitors the progress of solutions and identifies local optima, triggering restarts to avoid convergence on suboptimal outcomes. The second technique utilizes a sampling-driven inference rule to selectively fix vertices based on sampled solutions, thereby narrowing the search space and enhancing efficiency. Comprehensive experimental evaluations across multiple well-established real-world benchmarks demonstrate that the proposed algorithm outperforms state-of-the-art algorithms in terms of solution quality, computational efficiency, and stability.","authors":["Enqiang Zhu","Yu Zhang","Witold Pedrycz","Chanjuan Liu"],"url":"https://arxiv.org/abs/2208.07777"}
{"created":"2025-04-18","title":"SAIF: Sparse Adversarial and Imperceptible Attack Framework","abstract":"Adversarial attacks hamper the decision-making ability of neural networks by perturbing the input signal. The addition of calculated small distortion to images, for instance, can deceive a well-trained image classification network. In this work, we propose a novel attack technique called Sparse Adversarial and Interpretable Attack Framework (SAIF). Specifically, we design imperceptible attacks that contain low-magnitude perturbations at a small number of pixels and leverage these sparse attacks to reveal the vulnerability of classifiers. We use the Frank-Wolfe (conditional gradient) algorithm to simultaneously optimize the attack perturbations for bounded magnitude and sparsity with $O(1/\\sqrt{T})$ convergence. Empirical results show that SAIF computes highly imperceptible and interpretable adversarial examples, and outperforms state-of-the-art sparse attack methods on the ImageNet dataset.","authors":["Tooba Imtiaz","Morgan Kohler","Jared Miller","Zifeng Wang","Masih Eskander","Mario Sznaier","Octavia Camps","Jennifer Dy"],"url":"https://arxiv.org/abs/2212.07495"}
{"created":"2025-04-18","title":"Uncertainty Calibration for Counterfactual Propensity Estimation in Recommendation","abstract":"Post-click conversion rate (CVR) is a reliable indicator of online customers' preferences, making it crucial for developing recommender systems. A major challenge in predicting CVR is severe selection bias, arising from users' inherent self-selection behavior and the system's item selection process. To mitigate this issue, the inverse propensity score (IPS) is employed to weight the prediction error of each observed instance. However, current propensity score estimations are unreliable due to the lack of a quality measure. To address this, we evaluate the quality of propensity scores from the perspective of uncertainty calibration, proposing the use of Expected Calibration Error (ECE) as a measure of propensity-score quality, which quantifies the extent to which predicted probabilities are overconfident by assessing the difference between predicted probabilities and actual observed frequencies. Miscalibrated propensity scores can lead to distorted IPS weights, thereby compromising the debiasing process in CVR prediction. In this paper, we introduce a model-agnostic calibration framework for propensity-based debiasing of CVR predictions. Theoretical analysis on bias and generalization bounds demonstrates the superiority of calibrated propensity estimates over uncalibrated ones. Experiments conducted on the Coat, Yahoo and KuaiRand datasets show improved uncertainty calibration, as evidenced by lower ECE values, leading to enhanced CVR prediction outcomes.","authors":["Wenbo Hu","Xin Sun","Qiang liu","Le Wu","Liang Wang"],"url":"https://arxiv.org/abs/2303.12973"}
{"created":"2025-04-18","title":"Challenges and Opportunities in Improving Worst-Group Generalization in Presence of Spurious Features","abstract":"Deep neural networks often exploit *spurious* features that are present in the majority of examples within a class during training. This leads to *poor worst-group test accuracy*, i.e., poor accuracy for minority groups that lack these spurious features. Despite the growing body of recent efforts to address spurious correlations (SC), several challenging settings remain unexplored.In this work, we propose studying methods to mitigate SC in settings with: 1) spurious features that are learned more slowly, 2) a larger number of classes, and 3) a larger number of groups. We introduce two new datasets, Animals and SUN, to facilitate this study and conduct a systematic benchmarking of 8 state-of-the-art (SOTA) methods across a total of 5 vision datasets, training over 5,000 models. Through this, we highlight how existing group inference methods struggle in the presence of spurious features that are learned later in training. Additionally, we demonstrate how all existing methods struggle in settings with more groups and/or classes. Finally, we show the importance of careful model selection (hyperparameter tuning) in extracting optimal performance, especially in the more challenging settings we introduced, and propose more cost-efficient strategies for model selection. Overall, through extensive and systematic experiments, this work uncovers a suite of new challenges and opportunities for improving worst-group generalization in the presence of spurious features. Our datasets, methods and scripts available at https://github.com/BigML-CS-UCLA/SpuCo.","authors":["Siddharth Joshi","Yu Yang","Yihao Xue","Wenhan Yang","Baharan Mirzasoleiman"],"url":"https://arxiv.org/abs/2306.11957"}
{"created":"2025-04-18","title":"A Comprehensive Study of Machine Learning Techniques for Log-Based Anomaly Detection","abstract":"Growth in system complexity increases the need for automated log analysis techniques, such as Log-based Anomaly Detection (LAD). While deep learning (DL) methods have been widely used for LAD, traditional machine learning (ML) techniques can also perform well depending on the context and dataset. Semi-supervised techniques deserve the same attention as they offer practical advantages over fully supervised methods. Current evaluations mainly focus on detection accuracy, but this alone is insufficient to determine the suitability of a technique for a given LAD task. Other aspects to consider include training and prediction times as well as the sensitivity to hyperparameter tuning, which in practice matters to engineers.","authors":["Shan Ali","Chaima Boufaied","Domenico Bianculli","Paula Branco","Lionel Briand"],"url":"https://arxiv.org/abs/2307.16714"}
{"created":"2025-04-18","title":"Baichuan 2: Open Large-scale Language Models","abstract":"Large language models (LLMs) have demonstrated remarkable performance on a variety of natural language tasks based on just a few examples of natural language instructions, reducing the need for extensive feature engineering. However, most powerful LLMs are closed-source or limited in their capability for languages other than English. In this technical report, we present Baichuan 2, a series of large-scale multilingual language models containing 7 billion and 13 billion parameters, trained from scratch, on 2.6 trillion tokens. Baichuan 2 matches or outperforms other open-source models of similar size on public benchmarks like MMLU, CMMLU, GSM8K, and HumanEval. Furthermore, Baichuan 2 excels in vertical domains such as medicine and law. We will release all pre-training model checkpoints to benefit the research community in better understanding the training dynamics of Baichuan 2.","authors":["Aiyuan Yang","Bin Xiao","Bingning Wang","Borong Zhang","Ce Bian","Chao Yin","Chenxu Lv","Da Pan","Dian Wang","Dong Yan","Fan Yang","Fei Deng","Feng Wang","Feng Liu","Guangwei Ai","Guosheng Dong","Haizhou Zhao","Hang Xu","Haoze Sun","Hongda Zhang","Hui Liu","Jiaming Ji","Jian Xie","JunTao Dai","Kun Fang","Lei Su","Liang Song","Lifeng Liu","Liyun Ru","Luyao Ma","Mang Wang","Mickel Liu","MingAn Lin","Nuolan Nie","Peidong Guo","Ruiyang Sun","Tao Zhang","Tianpeng Li","Tianyu Li","Wei Cheng","Weipeng Chen","Xiangrong Zeng","Xiaochuan Wang","Xiaoxi Chen","Xin Men","Xin Yu","Xuehai Pan","Yanjun Shen","Yiding Wang","Yiyu Li","Youxin Jiang","Yuchen Gao","Yupeng Zhang","Zenan Zhou","Zhiying Wu"],"url":"https://arxiv.org/abs/2309.10305"}
{"created":"2025-04-18","title":"Asynchronous Graph Generator","abstract":"We introduce the asynchronous graph generator (AGG), a novel graph attention network for imputation and prediction of multi-channel time series. Free from recurrent components or assumptions about temporal/spatial regularity, AGG encodes measurements, timestamps and channel-specific features directly in the nodes via learnable embeddings. Through an attention mechanism, these embeddings allow for discovering expressive relationships among the variables of interest in the form of a homogeneous graph. Once trained, AGG performs imputation by \\emph{conditional attention generation}, i.e., by creating a new node conditioned on given timestamps and channel specification. The proposed AGG is compared to related methods in the literature and its performance is analysed from a data augmentation perspective. Our experiments reveal that AGG achieved state-of-the-art results in time series imputation, classification and prediction for the benchmark datasets \\emph{Beijing Air Quality}, \\emph{PhysioNet ICU 2012} and \\emph{UCI localisation}, outperforming other recent attention-based networks.","authors":["Christopher P. Ley","Felipe Tobar"],"url":"https://arxiv.org/abs/2309.17335"}
{"created":"2025-04-18","title":"Accelerating Non-Conjugate Gaussian Processes By Trading Off Computation For Uncertainty","abstract":"Non-conjugate Gaussian processes (NCGPs) define a flexible probabilistic framework to model categorical, ordinal and continuous data, and are widely used in practice. However, exact inference in NCGPs is prohibitively expensive for large datasets, thus requiring approximations in practice. The approximation error adversely impacts the reliability of the model and is not accounted for in the uncertainty of the prediction. We introduce a family of iterative methods that explicitly model this error. They are uniquely suited to parallel modern computing hardware, efficiently recycle computations, and compress information to reduce both the time and memory requirements for NCGPs. As we demonstrate on large-scale classification problems, our method significantly accelerates posterior inference compared to competitive baselines by trading off reduced computation for increased uncertainty.","authors":["Lukas Tatzel","Jonathan Wenger","Frank Schneider","Philipp Hennig"],"url":"https://arxiv.org/abs/2310.20285"}
{"created":"2025-04-18","title":"Randomized Strong Recursive Skeletonization: Simultaneous Compression and LU Factorization of Hierarchical Matrices using Matrix-Vector Products","abstract":"The hierarchical matrix framework partitions matrices into subblocks that are either small or of low numerical rank, enabling linear storage complexity and efficient matrix-vector multiplication. This work focuses on the $\\mathcal{H}^2$-matrix format, whose defining feature is the nested basis property which allows basis matrices to be reused across different levels of the hierarchy. While $\\mathcal{H}^2$-matrices support fast Cholesky and LU factorizations, implementing these methods is challenging -- especially for 3D PDE discretizations -- due to the complexity of nested recursions and recompressions. Moreover, compressing $\\mathcal{H}^2$-matrices becomes particularly difficult when only matrix-vector multiplication operations are available.","authors":["Anna Yesypenko","Per-Gunnar Martinsson"],"url":"https://arxiv.org/abs/2311.01451"}
{"created":"2025-04-18","title":"Generating Pragmatic Examples to Train Neural Program Synthesizers","abstract":"Programming-by-example is the task of synthesizing a program that is consistent with a set of user-provided input-output examples. As examples are often an under-specification of one's intent, a good synthesizer must choose the intended program from the many that are consistent with the given set of examples. Prior work frames program synthesis as a cooperative game between a listener (that synthesizes programs) and a speaker (a user choosing examples), and shows that models of computational pragmatic inference are effective in choosing the user intended programs. However, these models require counterfactual reasoning over a large set of programs and examples, which is infeasible in realistic program spaces. In this paper, we propose PraX, a novel way to amortize this search with neural networks. We sample pairs of programs and examples via self-play between listener and speaker models, and use pragmatic inference to choose informative training examples from this sample. We then use the informative dataset to train models to improve the synthesizer's ability to disambiguate user-provided examples without human supervision. We validate PraX on the challenging task of synthesizing regular expressions from example strings, and find that our method (1) outperforms models trained without choosing pragmatic examples by 23% (a 51% relative increase) (2) matches the performance of supervised learning on a dataset of pragmatic examples provided by humans, despite using no human data in training.","authors":["Saujas Vaduguru","Daniel Fried","Yewen Pu"],"url":"https://arxiv.org/abs/2311.05740"}
{"created":"2025-04-18","title":"Scalable Multi-Robot Motion Planning Using Guidance-Informed Hypergraphs","abstract":"In this work, we propose a method for multiple mobile robot motion planning that efficiently plans for robot teams up to an order of magnitude larger than existing state-of-the-art methods in congested settings with narrow passages in the environment. We achieve this improvement in scalability by adapting the state-of-the-art Decomposable State Space Hypergraph (DaSH) planning framework to expand the set of problems it can support to include those without a highly structured planning space and those with kinodynamic constraints. We accomplish this by exploiting guidance about a problem's structure to limit exploration of the planning space and through modifying DaSH's conflict resolution scheme. This guidance captures when coordination between robots is necessary, allowing us to decompose the intractably large multi-robot search space while limiting risk of inter-robot conflicts by composing relevant robot groups together while planning.","authors":["Courtney McBeth","James Motes","Isaac Ngui","Marco Morales","Nancy M. Amato"],"url":"https://arxiv.org/abs/2311.10176"}
{"created":"2025-04-18","title":"Unified Domain Adaptive Semantic Segmentation","abstract":"Unsupervised Domain Adaptive Semantic Segmentation (UDA-SS) aims to transfer the supervision from a labeled source domain to an unlabeled target domain. The majority of existing UDA-SS works typically consider images whilst recent attempts have extended further to tackle videos by modeling the temporal dimension. Although the two lines of research share the major challenges -- overcoming the underlying domain distribution shift, their studies are largely independent, resulting in fragmented insights, a lack of holistic understanding, and missed opportunities for cross-pollination of ideas. This fragmentation prevents the unification of methods, leading to redundant efforts and suboptimal knowledge transfer across image and video domains. Under this observation, we advocate unifying the study of UDA-SS across video and image scenarios, enabling a more comprehensive understanding, synergistic advancements, and efficient knowledge sharing. To that end, we explore the unified UDA-SS from a general data augmentation perspective, serving as a unifying conceptual framework, enabling improved generalization, and potential for cross-pollination of ideas, ultimately contributing to the overall progress and practical impact of this field of research. Specifically, we propose a Quad-directional Mixup (QuadMix) method, characterized by tackling distinct point attributes and feature inconsistencies through four-directional paths for intra- and inter-domain mixing in a feature space. To deal with temporal shifts with videos, we incorporate optical flow-guided feature aggregation across spatial and temporal dimensions for fine-grained domain alignment. Extensive experiments show that our method outperforms the state-of-the-art works by large margins on four challenging UDA-SS benchmarks. Our source code and models will be released at https://github.com/ZHE-SAPI/UDASS.","authors":["Zhe Zhang","Gaochang Wu","Jing Zhang","Xiatian Zhu","Dacheng Tao","Tianyou Chai"],"url":"https://arxiv.org/abs/2311.13254"}
{"created":"2025-04-18","title":"StructRe: Rewriting for Structured Shape Modeling","abstract":"Man-made 3D shapes are naturally organized in parts and hierarchies; such structures provide important constraints for shape reconstruction and generation. Modeling shape structures is difficult, because there can be multiple hierarchies for a given shape, causing ambiguity, and across different categories the shape structures are correlated with semantics, limiting generalization. We present StructRe, a structure rewriting system, as a novel approach to structured shape modeling. Given a 3D object represented by points and components, StructRe can rewrite it upward into more concise structures, or downward into more detailed structures; by iterating the rewriting process, hierarchies are obtained. Such a localized rewriting process enables probabilistic modeling of ambiguous structures and robust generalization across object categories. We train StructRe on PartNet data and show its generalization to cross-category and multiple object hierarchies, and test its extension to ShapeNet. We also demonstrate the benefits of probabilistic and generalizable structure modeling for shape reconstruction, generation and editing tasks.","authors":["Jiepeng Wang","Hao Pan","Yang Liu","Xin Tong","Taku Komura","Wenping Wang"],"url":"https://arxiv.org/abs/2311.17510"}
{"created":"2025-04-18","title":"A Saturation-Based Unification Algorithm for Higher-Order Rational Patterns","abstract":"Higher-order unification has been shown to be undecidable. Miller discovered the pattern fragment and subsequently showed that higher-order pattern unification is decidable and has most general unifiers. We extend the algorithm to higher-order rational terms (a.k.a. regular B\\\"{o}hm trees, a form of cyclic $\\lambda$-terms) and show that pattern unification on higher-order rational terms is decidable and has most general unifiers. We prove the soundness and completeness of the algorithm.","authors":["Zhibo Chen","Frank Pfenning"],"url":"https://arxiv.org/abs/2312.07263"}
{"created":"2025-04-18","title":"Dynamic Electromagnetic Navigation","abstract":"Magnetic navigation offers wireless control over magnetic objects, which has important medical applications, such as targeted drug delivery and minimally invasive surgery. Magnetic navigation systems are categorized into systems using permanent magnets and systems based on electromagnets. Electromagnetic Navigation Systems (eMNSs) are believed to have a superior actuation bandwidth, facilitating trajectory tracking and disturbance rejection. This greatly expands the range of potential medical applications and includes even dynamic environments as encountered in cardiovascular interventions. To showcase the dynamic capabilities of eMNSs, we successfully stabilize a (non-magnetic) inverted pendulum on the tip of a magnetically driven arm. Our approach employs a model-based framework that leverages Lagrangian mechanics to capture the interaction between the mechanical dynamics and the magnetic field. Using system identification, we estimate unknown parameters, the actuation bandwidth, and characterize the system's nonlinearity. To explore the limits of electromagnetic navigation and evaluate its scalability, we characterize the electrical system dynamics and perform reference measurements on a clinical-scale eMNS, affirming that the proposed dynamic control methodologies effectively translate to larger coil configurations. A state-feedback controller stabilizes the inherently unstable pendulum, and an iterative learning control scheme enables accurate tracking of non-equilibrium trajectories. Furthermore, to understand structural limitations of our control strategy, we analyze the influence of magnetic field gradients on the motion of the system. To our knowledge, this is the first demonstration to stabilize a 3D inverted pendulum through electromagnetic navigation.","authors":["Jasan Zughaibi","Bradley J. Nelson","Michael Muehlebach"],"url":"https://arxiv.org/abs/2402.06012"}
{"created":"2025-04-18","title":"HyperMagNet: A Magnetic Laplacian based Hypergraph Neural Network","abstract":"In data science, hypergraphs are natural models for data exhibiting multi-way relations, whereas graphs only capture pairwise. Nonetheless, many proposed hypergraph neural networks effectively reduce hypergraphs to undirected graphs via symmetrized matrix representations, potentially losing important information. We propose an alternative approach to hypergraph neural networks in which the hypergraph is represented as a non-reversible Markov chain. We use this Markov chain to construct a complex Hermitian Laplacian matrix - the magnetic Laplacian - which serves as the input to our proposed hypergraph neural network. We study HyperMagNet for the task of node classification, and demonstrate its effectiveness over graph-reduction based hypergraph neural networks.","authors":["Tatyana Benko","Martin Buck","Ilya Amburg","Stephen J. Young","Sinan G. Aksoy"],"url":"https://arxiv.org/abs/2402.09676"}
{"created":"2025-04-18","title":"Why Lift so Heavy? Slimming Large Language Models by Cutting Off the Layers","abstract":"Large Language Models (LLMs) possess outstanding capabilities in addressing various natural language processing (NLP) tasks. However, the sheer size of these models poses challenges in terms of storage, training and inference due to the inclusion of billions of parameters through layer stacking. While traditional approaches such as model pruning or distillation offer ways for reducing model size, they often come at the expense of performance retention. In our investigation, we systematically explore the approach of reducing the number of layers in LLMs. Surprisingly, we observe that even with fewer layers, LLMs maintain similar or better performance levels, particularly in prompt-based fine-tuning for text classification tasks. Remarkably, in certain cases, models with a single layer outperform their fully layered counterparts. These findings offer valuable insights for future work aimed at mitigating the size constraints of LLMs while preserving their performance, thereby opening avenues for significantly more efficient use of LLMs.","authors":["Shuzhou Yuan","Ercong Nie","Bolei Ma","Michael F\\\"arber"],"url":"https://arxiv.org/abs/2402.11700"}
{"created":"2025-04-18","title":"Citation-Enhanced Generation for LLM-based Chatbots","abstract":"Large language models (LLMs) exhibit powerful general intelligence across diverse scenarios, including their integration into chatbots. However, a vital challenge of LLM-based chatbots is that they may produce hallucinated content in responses, which significantly limits their applicability. Various efforts have been made to alleviate hallucination, such as retrieval augmented generation and reinforcement learning with human feedback, but most of them require additional training and data annotation. In this paper, we propose a novel post-hoc Citation-Enhanced Generation (CEG) approach combined with retrieval argumentation. Unlike previous studies that focus on preventing hallucinations during generation, our method addresses this issue in a post-hoc way. It incorporates a retrieval module to search for supporting documents relevant to the generated content, and employs a natural language inference-based citation generation module. Once the statements in the generated content lack of reference, our model can regenerate responses until all statements are supported by citations. Note that our method is a training-free plug-and-play plugin that is capable of various LLMs. Experiments on various hallucination-related datasets show our framework outperforms state-of-the-art methods in both hallucination detection and response regeneration on three benchmarks. Our codes and dataset will be publicly available.","authors":["Weitao Li","Junkai Li","Weizhi Ma","Yang Liu"],"url":"https://arxiv.org/abs/2402.16063"}
{"created":"2025-04-18","title":"Perceive With Confidence: Statistical Safety Assurances for Navigation with Learning-Based Perception","abstract":"Rapid advances in perception have enabled large pre-trained models to be used out of the box for transforming high-dimensional, noisy, and partial observations of the world into rich occupancy representations. However, the reliability of these models and consequently their safe integration onto robots remains unknown when deployed in environments unseen during training. To provide safety guarantees, we rigorously quantify the uncertainty of pre-trained perception systems for object detection and scene completion via a novel calibration technique based on conformal prediction. Crucially, this procedure guarantees robustness to distribution shifts in states when perception outputs are used in conjunction with a planner. As a result, the calibrated perception system can be used in combination with any safe planner to provide an end-to-end statistical assurance on safety in unseen environments. We evaluate the resulting approach, Perceive with Confidence (PwC), in simulation and on hardware where a quadruped robot navigates through previously unseen indoor, static environments. These experiments validate the safety assurances for obstacle avoidance provided by PwC. In simulation, our method reduces obstacle misdetection by $70\\%$ compared to uncalibrated perception models. While misdetections lead to collisions for baseline methods, our approach consistently achieves $100\\%$ safety. We further demonstrate reducing the conservatism of our method without sacrificing safety, achieving a $46\\%$ increase in success rates in challenging environments while maintaining $100\\%$ safety. In hardware experiments, our method improves empirical safety by $40\\%$ over baselines and reduces obstacle misdetection by $93.3\\%$. The safety gap widens to $46.7\\%$ when navigation speed increases, highlighting our approach's robustness under more demanding conditions.","authors":["Zhiting Mei","Anushri Dixit","Meghan Booker","Emily Zhou","Mariko Storey-Matsutani","Allen Z. Ren","Ola Shorinwa","Anirudha Majumdar"],"url":"https://arxiv.org/abs/2403.08185"}
{"created":"2025-04-18","title":"ExploRLLM: Guiding Exploration in Reinforcement Learning with Large Language Models","abstract":"In robot manipulation, Reinforcement Learning (RL) often suffers from low sample efficiency and uncertain convergence, especially in large observation and action spaces. Foundation Models (FMs) offer an alternative, demonstrating promise in zero-shot and few-shot settings. However, they can be unreliable due to limited physical and spatial understanding. We introduce ExploRLLM, a method that combines the strengths of both paradigms. In our approach, FMs improve RL convergence by generating policy code and efficient representations, while a residual RL agent compensates for the FMs' limited physical understanding. We show that ExploRLLM outperforms both policies derived from FMs and RL baselines in table-top manipulation tasks. Additionally, real-world experiments show that the policies exhibit promising zero-shot sim-to-real transfer. Supplementary material is available at https://explorllm.github.io.","authors":["Runyu Ma","Jelle Luijkx","Zlatan Ajanovic","Jens Kober"],"url":"https://arxiv.org/abs/2403.09583"}
{"created":"2025-04-18","title":"Detecting Origin Attribution for Text-to-Image Diffusion Models","abstract":"Modern text-to-image (T2I) diffusion models can generate images with remarkable realism and creativity. These advancements have sparked research in fake image detection and attribution, yet prior studies have not fully explored the practical and scientific dimensions of this task. In addition to attributing images to 12 state-of-the-art T2I generators, we provide extensive analyses on what inference stage hyperparameters and image modifications are discernible. Our experiments reveal that initialization seeds are highly detectable, along with other subtle variations in the image generation process to some extent. We further investigate what visual traces are leveraged in image attribution by perturbing high-frequency details and employing mid-level representations of image style and structure. Notably, altering high-frequency information causes only slight reductions in accuracy, and training an attributor on style representations outperforms training on RGB images. Our analyses underscore that fake images are detectable and attributable at various levels of visual granularity.","authors":["Katherine Xu","Lingzhi Zhang","Jianbo Shi"],"url":"https://arxiv.org/abs/2403.19653"}
{"created":"2025-04-18","title":"Constructing Decision Trees from Data Streams","abstract":"In this work, we present data stream algorithms to compute optimal splits for decision tree learning. In particular, given a data stream of observations \\(x_i\\) and their corresponding labels \\(y_i\\), without the i.i.d. assumption, the objective is to identify the optimal split \\(j\\) that partitions the data into two sets, minimizing the mean squared error (for regression) or the misclassification rate and Gini impurity (for classification). We propose several efficient streaming algorithms that require sublinear space and use a small number of passes to solve these problems. These algorithms can also be extended to the MapReduce model. Our results, while not directly comparable, complements the seminal work of Domingos-Hulten (KDD 2000) and Hulten-Spencer-Domingos (KDD 2001).","authors":["Huy Pham","Hoang Ta","Hoa T. Vu"],"url":"https://arxiv.org/abs/2403.19867"}
{"created":"2025-04-18","title":"An Analysis of Malicious Packages in Open-Source Software in the Wild","abstract":"The open-source software (OSS) ecosystem suffers from security threats caused by malware.However, OSS malware research has three limitations: a lack of high-quality datasets, a lack of malware diversity, and a lack of attack campaign contexts. In this paper, we first build the largest dataset of 24,356 malicious packages from online sources, then propose a knowledge graph to represent the OSS malware corpus and conduct malware analysis in the wild.Our main findings include (1) it is essential to collect malicious packages from various online sources because their data overlapping degrees are small;(2) despite the sheer volume of malicious packages, many reuse similar code, leading to a low diversity of malware;(3) only 28 malicious packages were repeatedly hidden via dependency libraries of 1,354 malicious packages, and dependency-hidden malware has a shorter active time;(4) security reports are the only reliable source for disclosing the malware-based context. Index Terms: Malicious Packages, Software Analysis","authors":["Xiaoyan Zhou","Ying Zhang","Wenjia Niu","Jiqiang Liu","Haining Wang","Qiang Li"],"url":"https://arxiv.org/abs/2404.04991"}
{"created":"2025-04-18","title":"QMix: Quality-aware Learning with Mixed Noise for Robust Retinal Disease Diagnosis","abstract":"Due to the complexity of medical image acquisition and the difficulty of annotation, medical image datasets inevitably contain noise. Noisy data with wrong labels affects the robustness and generalization ability of deep neural networks. Previous noise learning methods mainly considered noise arising from images being mislabeled, i.e. label noise, assuming that all mislabeled images are of high image quality. However, medical images are prone to suffering extreme quality issues, i.e. data noise, where discriminative visual features are missing for disease diagnosis. In this paper, we propose a noise learning framework, termed as QMix, that learns a robust disease diagnosis model under mixed noise. QMix alternates between sample separation and quality-aware semisupervised training in each training epoch. In the sample separation phase, we design a joint uncertainty-loss criterion to effectively separate (1) correctly labeled images; (2) mislabeled images with high quality and (3) mislabeled images with low quality. In the semi-supervised training phase, we train a disease diagnosis model to learn robust feature representation from the separated samples. Specifically, we devise a sample-reweighing loss to mitigate the effect of mislabeled images with low quality during training. Meanwhile, a contrastive enhancement loss is proposed to further distinguish mislabeled images with low quality from correctly labeled images. QMix achieved state-of-the-art disease diagnosis performance on five public retinal image datasets and exhibited substantial improvement on robustness against mixed noise.","authors":["Junlin Hou","Jilan Xu","Rui Feng","Hao Chen"],"url":"https://arxiv.org/abs/2404.05169"}
{"created":"2025-04-18","title":"What Are the Odds? Improving the foundations of Statistical Model Checking","abstract":"Markov decision processes (MDPs) are a fundamental model for decision making under uncertainty. They exhibit non-deterministic choice as well as probabilistic uncertainty. Traditionally, verification algorithms assume exact knowledge of the probabilities that govern the behaviour of an MDP. As this assumption is often unrealistic in practice, statistical model checking (SMC) was developed in the past two decades. It allows to analyse MDPs with unknown transition probabilities and provide probably approximately correct (PAC) guarantees on the result. Model-based SMC algorithms sample the MDP and build a model of it by estimating all transition probabilities, essentially for every transition answering the question: ``What are the odds?'' However, so far the statistical methods employed by the state of the art SMC algorithms are quite naive. Our contribution are several fundamental improvements to those methods: On the one hand, we survey statistics literature for better concentration inequalities; on the other hand, we propose specialised approaches that exploit our knowledge of the MDP. Our improvements are generally applicable to many kinds of problem statements because they are largely independent of the setting. Moreover, our experimental evaluation shows that they lead to significant gains, reducing the number of samples that the SMC algorithm has to collect by up to two orders of magnitude.","authors":["Tobias Meggendorfer","Maximilian Weininger","Patrick Wienh\\\"oft"],"url":"https://arxiv.org/abs/2404.05424"}
{"created":"2025-04-18","title":"Missing Pieces: How Do Designs that Expose Uncertainty Longitudinally Impact Trust in AI Decision Aids? An In Situ Study of Gig Drivers","abstract":"Decision aids based on artificial intelligence (AI) induce a wide range of outcomes when they are deployed in uncertain environments. In this paper, we investigate how users' trust in recommendations from an AI decision aid is impacted over time by designs that expose uncertainty in predicted outcomes. Unlike previous work, we focus on gig driving - a real-world, repeated decision-making context. We report on a longitudinal mixed-methods study ($n=51$) where we measured gig drivers' trust as they interacted with an AI-based schedule recommendation tool. Our results show that participants' trust in the tool was shaped by both their first impressions of its accuracy and their longitudinal interactions with it; and that task-aligned framings of uncertainty improved trust by allowing participants to incorporate uncertainty into their decision-making processes. Additionally, we observed that trust depended on their characteristics as drivers, underscoring the need for more in situ studies of AI decision aids.","authors":["Rex Chen","Ruiyi Wang","Norman Sadeh","Fei Fang"],"url":"https://arxiv.org/abs/2404.06432"}
{"created":"2025-04-18","title":"Taxonomy and Analysis of Sensitive User Queries in Generative AI Search","abstract":"Although there has been a growing interest among industries in integrating generative LLMs into their services, limited experience and scarcity of resources act as a barrier in launching and servicing large-scale LLM-based services. In this paper, we share our experiences in developing and operating generative AI models within a national-scale search engine, with a specific focus on the sensitiveness of user queries. We propose a taxonomy for sensitive search queries, outline our approaches, and present a comprehensive analysis report on sensitive queries from actual users. We believe that our experiences in launching generative AI search systems can contribute to reducing the barrier in building generative LLM-based services.","authors":["Hwiyeol Jo","Taiwoo Park","Hyunwoo Lee","Nayoung Choi","Changbong Kim","Ohjoon Kwon","Donghyeon Jeon","Eui-Hyeon Lee","Kyoungho Shin","Sun Suk Lim","Kyungmi Kim","Jihye Lee","Sun Kim"],"url":"https://arxiv.org/abs/2404.08672"}
{"created":"2025-04-18","title":"SparseDM: Toward Sparse Efficient Diffusion Models","abstract":"Diffusion models represent a powerful family of generative models widely used for image and video generation. However, the time-consuming deployment, long inference time, and requirements on large memory hinder their applications on resource constrained devices. In this paper, we propose a method based on the improved Straight-Through Estimator to improve the deployment efficiency of diffusion models. Specifically, we add sparse masks to the Convolution and Linear layers in a pre-trained diffusion model, then transfer learn the sparse model during the fine-tuning stage and turn on the sparse masks during inference. Experimental results on a Transformer and UNet-based diffusion models demonstrate that our method reduces MACs by 50% while maintaining FID. Sparse models are accelerated by approximately 1.2x on the GPU. Under other MACs conditions, the FID is also lower than 1 compared to other methods.","authors":["Kafeng Wang","Jianfei Chen","He Li","Zhenpeng Mi","Jun Zhu"],"url":"https://arxiv.org/abs/2404.10445"}
{"created":"2025-04-18","title":"MemLLM: Finetuning LLMs to Use An Explicit Read-Write Memory","abstract":"While current large language models (LLMs) perform well on many knowledge-related tasks, they are limited by relying on their parameters as an implicit storage mechanism. As a result, they struggle with memorizing rare events and with updating their memory as facts change over time. In addition, the uninterpretable nature of parametric memory makes it challenging to prevent hallucination. Model editing and augmenting LLMs with parameters specialized for memory are only partial solutions. In this paper, we introduce MemLLM, a novel method of enhancing LLMs by integrating a structured and explicit read-and-write memory module. MemLLM tackles the aforementioned challenges by enabling dynamic interaction with the memory and improving the LLM's capabilities in using stored knowledge. Our experiments indicate that MemLLM enhances the LLM's performance and interpretability, in language modeling in general and knowledge-intensive tasks in particular. We see MemLLM as an important step towards making LLMs more grounded and factual through memory augmentation. The project repository is publicly available at https://github.com/amodaresi/MemLLM","authors":["Ali Modarressi","Abdullatif K\\\"oksal","Ayyoob Imani","Mohsen Fayyaz","Hinrich Sch\\\"utze"],"url":"https://arxiv.org/abs/2404.11672"}
{"created":"2025-04-18","title":"Look Before You Decide: Prompting Active Deduction of MLLMs for Assumptive Reasoning","abstract":"Recently, Multimodal Large Language Models (MLLMs) have achieved significant success across multiple disciplines due to their exceptional instruction-following capabilities and extensive world knowledge. However, whether these MLLMs possess human-like compositional reasoning abilities remains an open problem. To unveil their reasoning behaviors, we first curate a \\textbf{M}ultimodal \\textbf{A}ssumptive \\textbf{R}ea\\textbf{s}oning Benchmark (MARS-Bench) in this paper. Interestingly, we find that most prevalent MLLMs can be easily fooled by the introduction of a presupposition into the question, whereas such presuppositions appear naive to human reasoning. Besides, we also propose a simple yet effective method, Active Deduction (AD), a novel reinforcement learning paradigm to encourage the model to actively perform composite deduction before reaching a final decision. Equipped with the proposed AD method, a MLLM demonstrates significant improvements in assumptive reasoning abilities without compromising its general-purpose question-answering performance. We also provide extensive evaluations of both open-source and private MLLMs on MARS-Bench, along with experimental analyses of the AD method.","authors":["Yian Li","Wentao Tian","Yang Jiao","Jingjing Chen","Tianwen Qian","Bin Zhu","Na Zhao","Yu-Gang Jiang"],"url":"https://arxiv.org/abs/2404.12966"}
{"created":"2025-04-18","title":"Improved impedance inversion by the iterated graph Laplacian","abstract":"We introduce a data-adaptive inversion method that integrates classical or deep learning-based approaches with iterative graph Laplacian regularization, specifically targeting acoustic impedance inversion - a critical task in seismic exploration. Our method initiates from an impedance estimate derived using either traditional inversion techniques or neural network-based methods. This initial estimate guides the construction of a graph Laplacian operator, effectively capturing structural characteristics of the impedance profile. Utilizing a Tikhonov-inspired variational framework with this graph-informed prior, our approach iteratively updates and refines the impedance estimate while continuously recalibrating the graph Laplacian. This iterative refinement shows rapid convergence, increased accuracy, and enhanced robustness to noise compared to initial reconstructions alone. Extensive validation performed on synthetic and real seismic datasets across varying noise levels confirms the effectiveness of our method. Performance evaluations include four initial inversion methods: two classical techniques and two neural networks - previously established in the literature.","authors":["Davide Bianchi","Florian Bossmann","Wenlong Wang","Mingming Liu"],"url":"https://arxiv.org/abs/2404.16324"}
{"created":"2025-04-18","title":"Graph Attention Reinforcement Learning for Multicast Routing and Age-Optimal Scheduling","abstract":"Age of Information (AoI) has emerged as a prominent metric for evaluating the timeliness of information in time-critical applications, such as video streaming, virtual reality, and metaverse platforms, which often rely on multicast communication. Optimizing AoI in multicast networks is challenging due to the coupling of multicast routing and scheduling decisions, the complexity of the multicast, and the graph representation. This paper focuses on dynamic multicast networks and aims to minimize the expected average AoI by integrating multicast routing and scheduling. To address the inherent complexity of the problem, we first decompose the original problem into two subtasks amenable to hierarchical reinforcement learning (RL) methods. We propose the first RL framework to address the multicast routing problem, also known as the Steiner Tree problem, by incorporating graph embedding and the successive addition of nodes and links. For graph embedding, we propose the Normalized Graph Attention mechanism (NGAT) framework with a proven contraction mapping property, enabling effective graph information capture and superior generalization within the hierarchical RL framework. We validate our framework through experiments on four datasets, including the real-world AS-733 dataset. The results demonstrate that our proposed scheme can be $11.56\\times$ more computationally efficient than traditional multicast routing algorithms while achieving approximation ratios of 1.1-1.3, comparable to state-of-the-art (SOTA) methods. Additionally, our age-optimal TGMS algorithm reduces the average weighted Age of Information (AoI) by 25.6% and the weighted peak age by 29.2% in low-energy scenarios.","authors":["Yanning Zhang","Guocheng Liao","Shengbin Cao","Ning Yang","Nikolaos Pappas","Meng Zhang"],"url":"https://arxiv.org/abs/2404.18084"}
{"created":"2025-04-18","title":"ALCM: Autonomous LLM-Augmented Causal Discovery Framework","abstract":"To perform effective causal inference in high-dimensional datasets, initiating the process with causal discovery is imperative, wherein a causal graph is generated based on observational data. However, obtaining a complete and accurate causal graph poses a formidable challenge, recognized as an NP- hard problem. Recently, the advent of Large Language Models (LLMs) has ushered in a new era, indicating their emergent capabilities and widespread applicability in facilitating causal reasoning across diverse domains, such as medicine, finance, and science. The expansive knowledge base of LLMs holds the potential to elevate the field of causal reasoning by offering interpretability, making inferences, generalizability, and uncovering novel causal structures. In this paper, we introduce a new framework, named Autonomous LLM-Augmented Causal Discovery Framework (ALCM), to synergize data-driven causal discovery algorithms and LLMs, automating the generation of a more resilient, accurate, and explicable causal graph. The ALCM consists of three integral components: causal structure learning, causal wrapper, and LLM-driven causal refiner. These components autonomously collaborate within a dynamic environment to address causal discovery questions and deliver plausible causal graphs. We evaluate the ALCM framework by implementing two demonstrations on seven well-known datasets. Experimental results demonstrate that ALCM outperforms existing LLM methods and conventional data-driven causal reasoning mechanisms. This study not only shows the effectiveness of the ALCM but also underscores new research directions in leveraging the causal reasoning capabilities of LLMs.","authors":["Elahe Khatibi","Mahyar Abbasian","Zhongqi Yang","Iman Azimi","Amir M. Rahmani"],"url":"https://arxiv.org/abs/2405.01744"}
{"created":"2025-04-18","title":"Fleet of Agents: Coordinated Problem Solving with Large Language Models","abstract":"While numerous frameworks have been developed to enhance the reasoning abilities of large language models (LLMs), there is a scarcity of methods that effectively balance the trade-off between cost and quality. In this paper, we introduce Fleet of Agents (FoA), a novel and intuitive yet principled framework utilizing LLMs as agents to navigate through dynamic tree searches, employing a genetic-type particle filtering approach. FoA spawns a multitude of agents, each exploring the search space autonomously, followed by a selection phase where resampling based on a heuristic value function optimizes the balance between exploration and exploitation. This mechanism enables dynamic branching, adapting the exploration strategy based on discovered solutions. We conduct extensive experiments on three benchmark tasks, ``Game of 24'', ``Mini-Crosswords'', and ``WebShop'', utilizing four different LLMs, ``GPT-3.5'', ``GPT-4'', ``LLaMA3.2-11B'', and ``LLaMA3.2-90B''. On average across all tasks and LLMs, FoA obtains a quality improvement of ~5% while requiring only ~40% of the cost of previous SOTA methods. Notably, our analyses reveal that (1) FoA achieves the best cost-quality trade-off among all benchmarked methods and (2) FoA + LLaMA3.2-11B surpasses the Llama3.2-90B model. FoA is publicly available at https://github.com/au-clan/FoA.","authors":["Nearchos Potamitis","Lars Klein","Roland Aydin","Robert West","Caglar Gulcehre","Akhil Arora"],"url":"https://arxiv.org/abs/2405.06691"}
{"created":"2025-04-18","title":"Why Larp?! A Synthesis Paper on Live Action Roleplay in Relation to HCI Research and Practice","abstract":"Live action roleplay (larp) has a wide range of applications, and can be relevant in relation to HCI. While there has been research about larp in relation to topics such as embodied interaction, playfulness and futuring published in HCI venues since the early 2000s, there is not yet a compilation of this knowledge. In this paper, we synthesise knowledge about larp and larp-adjacent work within the domain of HCI. We present a practitioner overview from an expert group of larp researchers, the results of a literature review, and highlight particular larp research exemplars which all work together to showcase the diverse set of ways that larp can be utilised in relation to HCI topics and research. This paper identifies the need for further discussions toward establishing best practices for utilising larp in relation to HCI research, as well as advocating for increased engagement with larps outside academia.","authors":["Karin Johansson","Raquel Breejon Robinson","Jon Back","Sarah Lynne Bowman","James Fey","Elena M\\'arquez Segura","Annika Waern","Katherine Isbister"],"url":"https://arxiv.org/abs/2405.08526"}
{"created":"2025-04-18","title":"A Systematic Review on Sleep Stage Classification and Sleep Disorder Detection Using Artificial Intelligence","abstract":"Sleep is vital for people's physical and mental health, and sound sleep can help them focus on daily activities. Therefore, a sleep study that includes sleep patterns and sleep disorders is crucial to enhancing our knowledge about individuals' health status. This study aims to provide a comprehensive, systematic review of the recent literature to analyze the different approaches and their outcomes in sleep studies, which includes works on \"sleep stages classification\" and \"sleep disorder detection\" using AI. In this review, 183 articles were initially selected from different journals, among which 80 records were enlisted for explicit review, ranging from 2016 to 2023. Brain waves were the most commonly employed body parameters for sleep staging and disorder studies (almost 29% of the research used brain activity signals exclusively, and 77% combined with the other signals). The convolutional neural network (CNN), the most widely used of the 34 distinct artificial intelligence models, comprised 27%. The other models included the long short-term memory (LSTM), support vector machine (SVM), random forest (RF), and recurrent neural network (RNN), which consisted of 11%, 6%, 6%, and 5% sequentially. For performance metrics, accuracy was widely used for a maximum of 83.75% of the cases, the F1 score of 45%, Kappa of 36.25%, Sensitivity of 31.25%, and Specificity of 30% of cases, along with the other metrics. This article would help physicians and researchers get the gist of AI's contribution to sleep studies and the feasibility of their intended work.","authors":["Tayab Uddin Wara","Ababil Hossain Fahad","Adri Shankar Das","Md. Mehedi Hasan Shawon"],"url":"https://arxiv.org/abs/2405.11008"}
{"created":"2025-04-18","title":"Towards Translating Real-World Code with LLMs: A Study of Translating to Rust","abstract":"Large language models (LLMs) show promise in code translation - the task of translating code written in one programming language to another language - due to their ability to write code in most programming languages. However, LLM's effectiveness on translating real-world code remains largely unstudied. In this work, we perform the first substantial study on LLM-based translation to Rust by assessing the ability of five state-of-the-art LLMs, GPT4, Claude 3, Claude 2.1, Gemini Pro, and Mixtral. We conduct our study on code extracted from real-world open source projects. To enable our study, we develop FLOURINE, an end-to-end code translation tool that uses differential fuzzing to check if a Rust translation is I/O equivalent to the original source program, eliminating the need for pre-existing test cases. As part of our investigation, we assess both the LLM's ability to produce an initially successful translation, as well as their capacity to fix a previously generated buggy one. If the original and the translated programs are not I/O equivalent, we apply a set of automated feedback strategies, including feedback to the LLM with counterexamples. Our results show that the most successful LLM can translate 47% of our benchmarks, and also provides insights into next steps for improvements.","authors":["Hasan Ferit Eniser","Hanliang Zhang","Cristina David","Meng Wang","Maria Christakis","Brandon Paulsen","Joey Dodds","Daniel Kroening"],"url":"https://arxiv.org/abs/2405.11514"}
{"created":"2025-04-18","title":"Design Editing for Offline Model-based Optimization","abstract":"Offline model-based optimization (MBO) aims to maximize a black-box objective function using only an offline dataset of designs and scores. These tasks span various domains, such as robotics, material design, and protein and molecular engineering. A common approach involves training a surrogate model using existing designs and their corresponding scores, and then generating new designs through gradient-based updates with respect to the surrogate model. This method suffers from the out-of-distribution issue, where the surrogate model may erroneously predict high scores for unseen designs. To address this challenge, we introduce a novel method, Design Editing for Offline Model-based Optimization (DEMO), which leverages a diffusion prior to calibrate overly optimized designs. DEMO first generates pseudo design candidates by performing gradient ascent with respect to a surrogate model. While these pseudo design candidates contain information beyond the offline dataset, they might be invalid or have erroneously high predicted scores. Therefore, to address this challenge while utilizing the information provided by pseudo design candidates, we propose an editing process to refine these pseudo design candidates. We introduce noise to the pseudo design candidates and subsequently denoise them with a diffusion prior trained on the offline dataset, ensuring they align with the distribution of valid designs. Empirical evaluations on seven offline MBO tasks show that, with properly tuned hyperparameters, DEMOs score is competitive with the best previously reported scores in the literature.","authors":["Ye Yuan","Youyuan Zhang","Can Chen","Haolun Wu","Zixuan Li","Jianmo Li","James J. Clark","Xue Liu"],"url":"https://arxiv.org/abs/2405.13964"}
{"created":"2025-04-18","title":"Good Seed Makes a Good Crop: Discovering Secret Seeds in Text-to-Image Diffusion Models","abstract":"Recent advances in text-to-image (T2I) diffusion models have facilitated creative and photorealistic image synthesis. By varying the random seeds, we can generate many images for a fixed text prompt. Technically, the seed controls the initial noise and, in multi-step diffusion inference, the noise used for reparameterization at intermediate timesteps in the reverse diffusion process. However, the specific impact of the random seed on the generated images remains relatively unexplored. In this work, we conduct a large-scale scientific study into the impact of random seeds during diffusion inference. Remarkably, we reveal that the best 'golden' seed achieved an impressive FID of 21.60, compared to the worst 'inferior' seed's FID of 31.97. Additionally, a classifier can predict the seed number used to generate an image with over 99.9% accuracy in just a few epochs, establishing that seeds are highly distinguishable based on generated images. Encouraged by these findings, we examined the influence of seeds on interpretable visual dimensions. We find that certain seeds consistently produce grayscale images, prominent sky regions, or image borders. Seeds also affect image composition, including object location, size, and depth. Moreover, by leveraging these 'golden' seeds, we demonstrate improved image generation such as high-fidelity inference and diversified sampling. Our investigation extends to inpainting tasks, where we uncover some seeds that tend to insert unwanted text artifacts. Overall, our extensive analyses highlight the importance of selecting good seeds and offer practical utility for image generation.","authors":["Katherine Xu","Lingzhi Zhang","Jianbo Shi"],"url":"https://arxiv.org/abs/2405.14828"}
{"created":"2025-04-18","title":"On the completeness of several fortification-interdiction games in the Polynomial Hierarchy","abstract":"Fortification-interdiction games are tri-level adversarial games where two opponents act in succession to protect, disrupt and simply use an infrastructure for a specific purpose. Many such games have been formulated and tackled in the literature through specific algorithmic methods, however very few investigations exist on the completeness of such fortification problems in order to locate them rigorously in the polynomial hierarchy. We clarify the completeness status of several well-known fortification problems, such as the Tri-level Interdiction Knapsack Problem with unit fortification and attack weights, the Max-flow Interdiction Problem and Shortest Path Interdiction Problem with Fortification, the Multi-level Critical Node Problem with unit weights, as well as a well-studied electric grid defence planning problem. For all of these problems, we prove their completeness either for the $\\Sigma^p_2$ or the $\\Sigma^p_3$ class of the polynomial hierarchy. We also prove that the Multi-level Fortification-Interdiction Knapsack Problem with an arbitrary number of protection and interdiction rounds and unit fortification and attack weights is complete for any level of the polynomial hierarchy, therefore providing a useful basis for further attempts at proving the completeness of protection-interdiction games at any level of said hierarchy.","authors":["Alberto Boggio Tomasaz","Margarida Carvalho","Roberto Cordone","Pierre Hosteins"],"url":"https://arxiv.org/abs/2406.01756"}
{"created":"2025-04-18","title":"Interventional Imbalanced Multi-Modal Representation Learning via $\\beta$-Generalization Front-Door Criterion","abstract":"Multi-modal methods establish comprehensive superiority over uni-modal methods. However, the imbalanced contributions of different modalities to task-dependent predictions constantly degrade the discriminative performance of canonical multi-modal methods. Based on the contribution to task-dependent predictions, modalities can be identified as predominant and auxiliary modalities. Benchmark methods raise a tractable solution: augmenting the auxiliary modality with a minor contribution during training. However, our empirical explorations challenge the fundamental idea behind such behavior, and we further conclude that benchmark approaches suffer from certain defects: insufficient theoretical interpretability and limited exploration capability of discriminative knowledge. To this end, we revisit multi-modal representation learning from a causal perspective and build the Structural Causal Model. Following the empirical explorations, we determine to capture the true causality between the discriminative knowledge of predominant modality and predictive label while considering the auxiliary modality. Thus, we introduce the $\\beta$-generalization front-door criterion. Furthermore, we propose a novel network for sufficiently exploring multi-modal discriminative knowledge. Rigorous theoretical analyses and various empirical evaluations are provided to support the effectiveness of the innate mechanism behind our proposed method.","authors":["Yi Li","Fei Song","Changwen Zheng","Jiangmeng Li","Fuchun Sun","Hui Xiong"],"url":"https://arxiv.org/abs/2406.11490"}
{"created":"2025-04-18","title":"Visually Consistent Hierarchical Image Classification","abstract":"Hierarchical classification predicts labels across multiple levels of a taxonomy, e.g., from coarse-level 'Bird' to mid-level 'Hummingbird' to fine-level 'Green hermit', allowing flexible recognition under varying visual conditions. It is commonly framed as multiple single-level tasks, but each level may rely on different visual cues: Distinguishing 'Bird' from 'Plant' relies on global features like feathers or leaves, while separating 'Anna's hummingbird' from 'Green hermit' requires local details such as head coloration. Prior methods improve accuracy using external semantic supervision, but such statistical learning criteria fail to ensure consistent visual grounding at test time, resulting in incorrect hierarchical classification. We propose, for the first time, to enforce internal visual consistency by aligning fine-to-coarse predictions through intra-image segmentation. Our method outperforms zero-shot CLIP and state-of-the-art baselines on hierarchical classification benchmarks, achieving both higher accuracy and more consistent predictions. It also improves internal image segmentation without requiring pixel-level annotations.","authors":["Seulki Park","Youren Zhang","Stella X. Yu","Sara Beery","Jonathan Huang"],"url":"https://arxiv.org/abs/2406.11608"}
{"created":"2025-04-18","title":"Large-Scale Contextual Market Equilibrium Computation through Deep Learning","abstract":"Market equilibrium is one of the most fundamental solution concepts in economics and social optimization analysis. Existing works on market equilibrium computation primarily focus on settings with relatively few buyers. Motivated by this, our paper investigates the computation of market equilibrium in scenarios with a large-scale buyer population, where buyers and goods are represented by their contexts. Building on this realistic and generalized contextual market model, we introduce MarketFCNet, a deep learning-based method for approximating market equilibrium. We start by parameterizing the allocation of each good to each buyer using a neural network, which depends solely on the context of the buyer and the good. Next, we propose an efficient method to unbiasedly estimate the loss function of the training algorithm, enabling us to optimize the network parameters through gradient. To evaluate the approximated solution, we propose a metric called Nash Gap, which quantifies the deviation of the given allocation and price pair from the market equilibrium. Experimental results indicate that MarketFCNet delivers competitive performance and significantly lower running times compared to existing methods as the market scale expands, demonstrating the potential of deep learning-based methods to accelerate the approximation of large-scale contextual market equilibrium.","authors":["Yunxuan Ma","Yide Bian","Hao Xu","Weitao Yang","Jingshu Zhao","Zhijian Duan","Feng Wang","Xiaotie Deng"],"url":"https://arxiv.org/abs/2406.15459"}
{"created":"2025-04-18","title":"HiDe-PET: Continual Learning via Hierarchical Decomposition of Parameter-Efficient Tuning","abstract":"The deployment of pre-trained models (PTMs) has greatly advanced the field of continual learning (CL), enabling positive knowledge transfer and resilience to catastrophic forgetting. To sustain these advantages for sequentially arriving tasks, a promising direction involves keeping the pre-trained backbone frozen while employing parameter-efficient tuning (PET) techniques to instruct representation learning. Despite the popularity of Prompt-based PET for CL, its empirical design often leads to sub-optimal performance in our evaluation of different PTMs and target tasks. To this end, we propose a unified framework for CL with PTMs and PET that provides both theoretical and empirical advancements. We first perform an in-depth theoretical analysis of the CL objective in a pre-training context, decomposing it into hierarchical components namely within-task prediction, task-identity inference and task-adaptive prediction. We then present Hierarchical Decomposition PET (HiDe-PET), an innovative approach that explicitly optimizes the decomposed objective through incorporating task-specific and task-shared knowledge via mainstream PET techniques along with efficient recovery of pre-trained representations. Leveraging this framework, we delve into the distinct impacts of implementation strategy, PET technique and PET architecture, as well as adaptive knowledge accumulation amidst pronounced distribution changes. Finally, across various CL scenarios, our approach demonstrates remarkably superior performance over a broad spectrum of recent strong baselines.","authors":["Liyuan Wang","Jingyi Xie","Xingxing Zhang","Hang Su","Jun Zhu"],"url":"https://arxiv.org/abs/2407.05229"}
{"created":"2025-04-18","title":"A Coding-Theoretic Analysis of Hyperspherical Prototypical Learning Geometry","abstract":"Hyperspherical Prototypical Learning (HPL) is a supervised approach to representation learning that designs class prototypes on the unit hypersphere. The prototypes bias the representations to class separation in a scale invariant and known geometry. Previous approaches to HPL have either of the following shortcomings: (i) they follow an unprincipled optimisation procedure; or (ii) they are theoretically sound, but are constrained to only one possible latent dimension. In this paper, we address both shortcomings. To address (i), we present a principled optimisation procedure whose solution we show is optimal. To address (ii), we construct well-separated prototypes in a wide range of dimensions using linear block codes. Additionally, we give a full characterisation of the optimal prototype placement in terms of achievable and converse bounds, showing that our proposed methods are near-optimal.","authors":["Martin Lindstr\\\"om","Borja Rodr\\'iguez-G\\'alvez","Ragnar Thobaben","Mikael Skoglund"],"url":"https://arxiv.org/abs/2407.07664"}
{"created":"2025-04-18","title":"Exploring the Boundaries of On-Device Inference: When Tiny Falls Short, Go Hierarchical","abstract":"On-device inference holds great potential for increased energy efficiency, responsiveness, and privacy in edge ML systems. However, due to less capable ML models that can be embedded in resource-limited devices, use cases are limited to simple inference tasks such as visual keyword spotting, gesture recognition, and predictive analytics. In this context, the Hierarchical Inference (HI) system has emerged as a promising solution that augments the capabilities of the local ML by offloading selected samples to an edge server or cloud for remote ML inference. Existing works demonstrate through simulation that HI improves accuracy. However, they do not account for the latency and energy consumption on the device, nor do they consider three key heterogeneous dimensions that characterize ML systems: hardware, network connectivity, and models. In contrast, this paper systematically compares the performance of HI with on-device inference based on measurements of accuracy, latency, and energy for running embedded ML models on five devices with different capabilities and three image classification datasets. For a given accuracy requirement, the HI systems we designed achieved up to 73% lower latency and up to 77% lower device energy consumption than an on-device inference system. The key to building an efficient HI system is the availability of small-size, reasonably accurate on-device models whose outputs can be effectively differentiated for samples that require remote inference. Despite the performance gains, HI requires on-device inference for all samples, which adds a fixed overhead to its latency and energy consumption. Therefore, we design a hybrid system, Early Exit with HI (EE-HI), and demonstrate that compared to HI, EE-HI reduces the latency by up to 59.7% and lowers the device's energy consumption by up to 60.4%.","authors":["Adarsh Prasad Behera","Paulius Daubaris","I\\~naki Bravo","Jos\\'e Gallego","Roberto Morabito","Joerg Widmer","Jaya Prakash Varma Champati"],"url":"https://arxiv.org/abs/2407.11061"}
{"created":"2025-04-18","title":"Unipa-GPT: Large Language Models for university-oriented QA in Italian","abstract":"This paper illustrates the architecture and training of Unipa-GPT, a chatbot relying on a Large Language Model, developed for assisting students in choosing a bachelor/master degree course at the University of Palermo. Unipa-GPT relies on gpt-3.5-turbo, it was presented in the context of the European Researchers' Night (SHARPER night). In our experiments we adopted both the Retrieval Augmented Generation (RAG) approach and fine-tuning to develop the system. The whole architecture of Unipa-GPT is presented, both the RAG and the fine-tuned systems are compared, and a brief discussion on their performance is reported. Further comparison with other Large Language Models and the experimental results during the SHARPER night are illustrated. Corpora and code are available on GitHub","authors":["Irene Siragusa","Roberto Pirrone"],"url":"https://arxiv.org/abs/2407.14246"}
{"created":"2025-04-18","title":"From Sands to Mansions: Towards Automated Cyberattack Emulation with Classical Planning and Large Language Models","abstract":"As attackers continually advance their tools, skills, and techniques during cyberattacks - particularly in modern Advanced Persistence Threats (APT) campaigns - there is a pressing need for a comprehensive and up-to-date cyberattack dataset to support threat-informed defense and enable benchmarking of defense systems in both academia and commercial solutions. However, there is a noticeable scarcity of cyberattack datasets: recent academic studies continue to rely on outdated benchmarks, while cyberattack emulation in industry remains limited due to the significant human effort and expertise required. Creating datasets by emulating advanced cyberattacks presents several challenges, such as limited coverage of attack techniques, the complexity of chaining multiple attack steps, and the difficulty of realistically mimicking actual threat groups. In this paper, we introduce modularized Attack Action and Attack Action Linking Model as a structured way to organizing and chaining individual attack steps into multi-step cyberattacks. Building on this, we propose Aurora, a system that autonomously emulates cyberattacks using third-party attack tools and threat intelligence reports with the help of classical planning and large language models. Aurora can automatically generate detailed attack plans, set up emulation environments, and semi-automatically execute the attacks. We utilize Aurora to create a dataset containing over 1,000 attack chains. To our best knowledge, Aurora is the only system capable of automatically constructing such a large-scale cyberattack dataset with corresponding attack execution scripts and environments. Our evaluation further demonstrates that Aurora outperforms the previous similar work and even the most advanced generative AI models in cyberattack emulation. To support further research, we published the cyberattack dataset and will publish the source code of Aurora.","authors":["Lingzhi Wang","Zhenyuan Li","Yi Jiang","Zhengkai Wang","Zonghan Guo","Jiahui Wang","Yangyang Wei","Xiangmin Shen","Wei Ruan","Yan Chen"],"url":"https://arxiv.org/abs/2407.16928"}
{"created":"2025-04-18","title":"A Survey and Evaluation of Adversarial Attacks for Object Detection","abstract":"Deep learning models achieve remarkable accuracy in computer vision tasks, yet remain vulnerable to adversarial examples--carefully crafted perturbations to input images that can deceive these models into making confident but incorrect predictions. This vulnerability pose significant risks in high-stakes applications such as autonomous vehicles, security surveillance, and safety-critical inspection systems. While the existing literature extensively covers adversarial attacks in image classification, comprehensive analyses of such attacks on object detection systems remain limited. This paper presents a novel taxonomic framework for categorizing adversarial attacks specific to object detection architectures, synthesizes existing robustness metrics, and provides a comprehensive empirical evaluation of state-of-the-art attack methodologies on popular object detection models, including both traditional detectors and modern detectors with vision-language pretraining. Through rigorous analysis of open-source attack implementations and their effectiveness across diverse detection architectures, we derive key insights into attack characteristics. Furthermore, we delineate critical research gaps and emerging challenges to guide future investigations in securing object detection systems against adversarial threats. Our findings establish a foundation for developing more robust detection models while highlighting the urgent need for standardized evaluation protocols in this rapidly evolving domain.","authors":["Khoi Nguyen Tiet Nguyen","Wenyu Zhang","Kangkang Lu","Yuhuan Wu","Xingjian Zheng","Hui Li Tan","Liangli Zhen"],"url":"https://arxiv.org/abs/2408.01934"}
{"created":"2025-04-18","title":"The Impact of Environment Configurations on the Stability of AI-Enabled Systems","abstract":"Nowadays, software systems tend to include Artificial Intelligence (AI) components. Changes in the operational environment have been known to negatively impact the stability of AI-enabled software systems by causing unintended changes in behavior. However, how an environment configuration impacts the behavior of such systems has yet to be explored. Understanding and quantifying the degree of instability caused by different environment settings can help practitioners decide the best environment configuration for the most stable AI systems. To achieve this goal, we performed experiments with eight different combinations of three key environment variables (operating system, Python version, and CPU architecture) on $30$ open-source AI-enabled systems using the Travis CI platform. We determine the existence and the degree of instability introduced by each configuration using three metrics: the output of an AI component of the system (model performance), the time required to build and run the system (processing time), and the cost associated with building and running the system (expense). Our results indicate that changes in environment configurations lead to instability across all three metrics; however, it is observed more frequently with respect to processing time and expense rather than model performance. For example, between Linux and MacOS, instability is observed in 23\\%, 96.67\\%, and 100\\% of the studied projects in model performance, processing time, and expense, respectively. Our findings underscore the importance of identifying the optimal combination of configuration settings to mitigate drops in model performance and reduce the processing time and expense before deploying an AI-enabled system.","authors":["Musfiqur Rahman","SayedHassan Khatoonabadi","Ahmad Abdellatif","Haya Samaana","Emad Shihab"],"url":"https://arxiv.org/abs/2408.02825"}
{"created":"2025-04-18","title":"ToolSandbox: A Stateful, Conversational, Interactive Evaluation Benchmark for LLM Tool Use Capabilities","abstract":"Recent large language models (LLMs) advancements sparked a growing research interest in tool assisted LLMs solving real-world challenges, which calls for comprehensive evaluation of tool-use capabilities. While previous works focused on either evaluating over stateless web services (RESTful API), based on a single turn user prompt, or an off-policy dialog trajectory, ToolSandbox includes stateful tool execution, implicit state dependencies between tools, a built-in user simulator supporting on-policy conversational evaluation and a dynamic evaluation strategy for intermediate and final milestones over an arbitrary trajectory. We show that open source and proprietary models have a significant performance gap, and complex tasks like State Dependency, Canonicalization and Insufficient Information defined in ToolSandbox are challenging even the most capable SOTA LLMs, providing brand-new insights into tool-use LLM capabilities. ToolSandbox evaluation framework is released at https://github.com/apple/ToolSandbox","authors":["Jiarui Lu","Thomas Holleis","Yizhe Zhang","Bernhard Aumayer","Feng Nan","Felix Bai","Shuang Ma","Shen Ma","Mengyu Li","Guoli Yin","Zirui Wang","Ruoming Pang"],"url":"https://arxiv.org/abs/2408.04682"}
{"created":"2025-04-18","title":"PhishLang: A Real-Time, Fully Client-Side Phishing Detection Framework Using MobileBERT","abstract":"In this paper, we introduce PhishLang, the first fully client-side anti-phishing framework built on a lightweight ensemble framework that utilizes advanced language models to analyze the contextual features of a website's source code and URL. Unlike traditional heuristic or machine learning approaches that rely on static features and struggle to adapt to evolving threats, or deep learning models that are computationally intensive, our approach utilizes MobileBERT, a fast and memory-efficient variant of the BERT architecture, to capture nuanced features indicative of phishing attacks. To further enhance detection accuracy, PhishLang employs a multi-modal ensemble approach, combining both the URL and Source detection models. This architecture ensures robustness by allowing one model to compensate for scenarios where the other may fail, or if both models provide ambiguous inferences. As a result, PhishLang excels at detecting both regular and evasive phishing threats, including zero-day attacks, outperforming popular anti-phishing tools, while operating without relying on external blocklists and safeguarding user privacy by ensuring that browser history remains entirely local and unshared. We release PhishLang as a Chromium browser extension and also open-source the framework to aid the research community.","authors":["Sayak Saha Roy","Shirin Nilizadeh"],"url":"https://arxiv.org/abs/2408.05667"}
{"created":"2025-04-18","title":"Learn2Decompose: Learning Problem Decomposition for Efficient Sequential Multi-object Manipulation Planning","abstract":"We present a Reactive Task and Motion Planning (TAMP) approach for efficient sequential multi-object manipulation in dynamic environments. Conventional TAMP solvers experience an exponential increase in planning time as the planning horizon and number of objects grow, limiting their applicability in real-world scenarios. To address this, we propose learning problem decomposition from demonstrations to accelerate TAMP solvers. Our approach consists of three key components: goal decomposition learning, temporal distance learning, and object reduction. Goal decomposition identifies the necessary sequences of states that the system must pass through before reaching the final goal, treating them as subgoal sequences. Temporal distance learning predicts the temporal distance between two states, enabling the system to identify the closest subgoal from a disturbed state. Object reduction minimizes the set of active objects considered during replanning, further improving efficiency. We evaluate our approach on three benchmarks, demonstrating its effectiveness in improving replanning efficiency for sequential multi-object manipulation tasks in dynamic environments.","authors":["Yan Zhang","Teng Xue","Amirreza Razmjoo","Sylvain Calinon"],"url":"https://arxiv.org/abs/2408.06843"}
{"created":"2025-04-18","title":"ChemVLM: Exploring the Power of Multimodal Large Language Models in Chemistry Area","abstract":"Large Language Models (LLMs) have achieved remarkable success and have been applied across various scientific fields, including chemistry. However, many chemical tasks require the processing of visual information, which cannot be successfully handled by existing chemical LLMs. This brings a growing need for models capable of integrating multimodal information in the chemical domain. In this paper, we introduce \\textbf{ChemVLM}, an open-source chemical multimodal large language model specifically designed for chemical applications. ChemVLM is trained on a carefully curated bilingual multimodal dataset that enhances its ability to understand both textual and visual chemical information, including molecular structures, reactions, and chemistry examination questions. We develop three datasets for comprehensive evaluation, tailored to Chemical Optical Character Recognition (OCR), Multimodal Chemical Reasoning (MMCR), and Multimodal Molecule Understanding tasks. We benchmark ChemVLM against a range of open-source and proprietary multimodal large language models on various tasks. Experimental results demonstrate that ChemVLM achieves competitive performance across all evaluated tasks. Our model can be found at https://huggingface.co/AI4Chem/ChemVLM-26B.","authors":["Junxian Li","Di Zhang","Xunzhi Wang","Zeying Hao","Jingdi Lei","Qian Tan","Cai Zhou","Wei Liu","Yaotian Yang","Xinrui Xiong","Weiyun Wang","Zhe Chen","Wenhai Wang","Wei Li","Shufei Zhang","Mao Su","Wanli Ouyang","Yuqiang Li","Dongzhan Zhou"],"url":"https://arxiv.org/abs/2408.07246"}
{"created":"2025-04-18","title":"How Do Social Bots Participate in Misinformation Spread? A Comprehensive Dataset and Analysis","abstract":"The social media platform is an ideal medium to spread misinformation, where social bots might accelerate the spread. This paper is the first to explore the interplay between social bots and misinformation on the Sina Weibo platform. We construct a large-scale dataset that contains annotations of misinformation and social bots. From the misinformation perspective, this dataset is multimodal, containing 11,393 pieces of misinformation and 16,416 pieces of real information. From the social bot perspective, this dataset contains 65,749 social bots and 345,886 genuine accounts, where we propose a weak-supervised annotator to annotate automatically. Extensive experiments prove that the dataset is the most comprehensive, misinformation and real information are distinguishable, and social bots have high annotation quality. Further analysis illustrates that: (i) social bots are deeply involved in information spread; (ii) misinformation with the same topics has similar content, providing the basis of echo chambers, and social bots amplify this phenomenon; and (iii) social bots generate similar content aiming to manipulate public opinions.","authors":["Herun Wan","Minnan Luo","Zihan Ma","Guang Dai","Xiang Zhao"],"url":"https://arxiv.org/abs/2408.09613"}
{"created":"2025-04-18","title":"Near, far: Patch-ordering enhances vision foundation models' scene understanding","abstract":"We introduce NeCo: Patch Neighbor Consistency, a novel self-supervised training loss that enforces patch-level nearest neighbor consistency across a student and teacher model. Compared to contrastive approaches that only yield binary learning signals, i.e., 'attract' and 'repel', this approach benefits from the more fine-grained learning signal of sorting spatially dense features relative to reference patches. Our method leverages differentiable sorting applied on top of pretrained representations, such as DINOv2-registers to bootstrap the learning signal and further improve upon them. This dense post-pretraining leads to superior performance across various models and datasets, despite requiring only 19 hours on a single GPU. This method generates high-quality dense feature encoders and establishes several new state-of-the-art results such as +5.5% and +6% for non-parametric in-context semantic segmentation on ADE20k and Pascal VOC, +7.2% and +5.7% for linear segmentation evaluations on COCO-Things and -Stuff and improvements in the 3D understanding of multi-view consistency on SPair-71k, by more than 1.5%.","authors":["Valentinos Pariza","Mohammadreza Salehi","Gertjan Burghouts","Francesco Locatello","Yuki M. Asano"],"url":"https://arxiv.org/abs/2408.11054"}
{"created":"2025-04-18","title":"Distribution Backtracking Builds A Faster Convergence Trajectory for Diffusion Distillation","abstract":"Accelerating the sampling speed of diffusion models remains a significant challenge. Recent score distillation methods distill a heavy teacher model into a student generator to achieve one-step generation, which is optimized by calculating the difference between the two score functions on the samples generated by the student model. However, there is a score mismatch issue in the early stage of the distillation process, because existing methods mainly focus on using the endpoint of pre-trained diffusion models as teacher models, overlooking the importance of the convergence trajectory between the student generator and the teacher model. To address this issue, we extend the score distillation process by introducing the entire convergence trajectory of teacher models and propose Distribution Backtracking Distillation (DisBack). DisBask is composed of two stages: Degradation Recording and Distribution Backtracking. Degradation Recording is designed to obtain the convergence trajectory of the teacher model, which records the degradation path from the trained teacher model to the untrained initial student generator. The degradation path implicitly represents the teacher model's intermediate distributions, and its reverse can be viewed as the convergence trajectory from the student generator to the teacher model. Then Distribution Backtracking trains a student generator to backtrack the intermediate distributions along the path to approximate the convergence trajectory of teacher models. Extensive experiments show that DisBack achieves faster and better convergence than the existing distillation method and accomplishes comparable generation performance, with FID score of 1.38 on ImageNet 64x64 dataset. Notably, DisBack is easy to implement and can be generalized to existing distillation methods to boost performance. Our code is publicly available on https://github.com/SYZhang0805/DisBack.","authors":["Shengyuan Zhang","Ling Yang","Zejian Li","An Zhao","Chenye Meng","Changyuan Yang","Guang Yang","Zhiyuan Yang","Lingyun Sun"],"url":"https://arxiv.org/abs/2408.15991"}
{"created":"2025-04-18","title":"Relevance for Human Robot Collaboration","abstract":"Inspired by the human ability to selectively focus on relevant information, this paper introduces relevance, a novel dimensionality reduction process for human-robot collaboration (HRC). Our approach incorporates a continuously operating perception module, evaluates cue sufficiency within the scene, and applies a flexible formulation and computation framework. To accurately and efficiently quantify relevance, we developed an event-based framework that maintains a continuous perception of the scene and selectively triggers relevance determination. Within this framework, we developed a probabilistic methodology, which considers various factors and is built on a novel structured scene representation. Simulation results demonstrate that the relevance framework and methodology accurately predict the relevance of a general HRC setup, achieving a precision of 0.99, a recall of 0.94, an F1 score of 0.96, and an object ratio of 0.94. Relevance can be broadly applied to several areas in HRC to accurately improve task planning time by 79.56% compared with pure planning for a cereal task, reduce perception latency by up to 26.53% for an object detector, improve HRC safety by up to 13.50% and reduce the number of inquiries for HRC by 80.84%. A real-world demonstration showcases the relevance framework's ability to intelligently and seamlessly assist humans in everyday tasks.","authors":["Xiaotong Zhang","Dean Huang","Kamal Youcef-Toumi"],"url":"https://arxiv.org/abs/2409.07753"}
{"created":"2025-04-18","title":"ValueCompass: A Framework for Measuring Contextual Value Alignment Between Human and LLMs","abstract":"As AI systems become more advanced, ensuring their alignment with a diverse range of individuals and societal values becomes increasingly critical. But how can we capture fundamental human values and assess the degree to which AI systems align with them? We introduce ValueCompass, a framework of fundamental values, grounded in psychological theory and a systematic review, to identify and evaluate human-AI alignment. We apply ValueCompass to measure the value alignment of humans and large language models (LLMs) across four real-world scenarios: collaborative writing, education, public sectors, and healthcare. Our findings reveal concerning misalignments between humans and LLMs, such as humans frequently endorse values like \"National Security\" which were largely rejected by LLMs. We also observe that values differ across scenarios, highlighting the need for context-aware AI alignment strategies. This work provides valuable insights into the design space of human-AI alignment, laying the foundations for developing AI systems that responsibly reflect societal values and ethics.","authors":["Hua Shen","Tiffany Knearem","Reshmi Ghosh","Yu-Ju Yang","Nicholas Clark","Tanushree Mitra","Yun Huang"],"url":"https://arxiv.org/abs/2409.09586"}
{"created":"2025-04-18","title":"Exploring the Trade-Offs: Quantization Methods, Task Difficulty, and Model Size in Large Language Models From Edge to Giant","abstract":"Quantization has gained attention as a promising solution for the cost-effective deployment of large and small language models. However, most prior work has been limited to perplexity or basic knowledge tasks and lacks a comprehensive evaluation of recent models like Llama-3.3. In this paper, we conduct a comprehensive evaluation of instruction-tuned models spanning 1B to 405B parameters, applying four quantization methods across 13 datasets. Our findings reveal that (1) quantized models generally surpass smaller FP16 baselines, yet they often struggle with instruction-following and hallucination detection; (2) FP8 consistently emerges as the most robust option across tasks, and AWQ tends to outperform GPTQ in weight-only quantization; (3) smaller models can suffer severe accuracy drops at 4-bit quantization, while 70B-scale models maintain stable performance; (4) notably, \\textit{hard} tasks do not always experience the largest accuracy losses, indicating that quantization magnifies a model's inherent weaknesses rather than simply correlating with task difficulty; and (5) an LLM-based judge (MT-Bench) highlights significant performance declines in coding and STEM tasks, though reasoning may sometimes improve.","authors":["Jemin Lee","Sihyeong Park","Jinse Kwon","Jihun Oh","Yongin Kwon"],"url":"https://arxiv.org/abs/2409.11055"}
{"created":"2025-04-18","title":"The Incredible Shrinking Context... in a Decompiler Near You","abstract":"Decompilation of binary code has arisen as a highly-important application in the space of Ethereum VM (EVM) smart contracts. Major new decompilers appear nearly every year and attain popularity, for a multitude of reverse-engineering or tool-building purposes. Technically, the problem is fundamental: it consists of recovering high-level control flow from a highly-optimized continuation-passing-style (CPS) representation. Architecturally, decompilers can be built using either static analysis or symbolic execution techniques.","authors":["Sifis Lagouvardos","Yannis Bollanos","Neville Grech","Yannis Smaragdakis"],"url":"https://arxiv.org/abs/2409.11157"}
{"created":"2025-04-18","title":"Robotic Optimization of Powdered Beverages Leveraging Computer Vision and Bayesian Optimization","abstract":"The growing demand for innovative research in the food industry is driving the adoption of robots in large-scale experimentation, as it offers increased precision, replicability, and efficiency in product manufacturing and evaluation. To this end, we introduce a robotic system designed to optimize food product quality, focusing on powdered cappuccino preparation as a case study. By leveraging optimization algorithms and computer vision, the robot explores the parameter space to identify the ideal conditions for producing a cappuccino with the best foam quality. The system also incorporates computer vision-driven feedback in a closed-loop control to further improve the beverage. Our findings demonstrate the effectiveness of robotic automation in achieving high repeatability and extensive parameter exploration, paving the way for more advanced and reliable food product development.","authors":["Emilia Szymanska","Josie Hughes"],"url":"https://arxiv.org/abs/2409.11499"}
{"created":"2025-04-18","title":"Analysis of Deep Learning-Based Colorization and Super-Resolution Techniques for Lidar Imagery","abstract":"Modern lidar systems can produce not only dense point clouds but also 360 degrees low-resolution images. This advancement facilitates the application of deep learning (DL) techniques initially developed for conventional RGB cameras and simplifies fusion of point cloud data and images without complex processes like lidar-camera calibration. Compared to RGB images from traditional cameras, lidar-generated images show greater robustness under low-light and harsh conditions, such as foggy weather. However, these images typically have lower resolution and often appear overly dark. While various studies have explored DL-based computer vision tasks such as object detection, segmentation, and keypoint detection on lidar imagery, other potentially valuable techniques remain underexplored. This paper provides a comprehensive review and qualitative analysis of DL-based colorization and super-resolution methods applied to lidar imagery. Additionally, we assess the computational performance of these approaches, offering insights into their suitability for downstream robotic and autonomous system applications like odometry and 3D reconstruction.","authors":["Sier Ha","Honghao Du","Xianjia Yu","Jian Song","Tomi Westerlund"],"url":"https://arxiv.org/abs/2409.11532"}
{"created":"2025-04-18","title":"MalMixer: Few-Shot Malware Classification with Retrieval-Augmented Semi-Supervised Learning","abstract":"Recent growth and proliferation of malware have tested practitioners ability to promptly classify new samples according to malware families. In contrast to labor-intensive reverse engineering efforts, machine learning approaches have demonstrated increased speed and accuracy. However, most existing deep-learning malware family classifiers must be calibrated using a large number of samples that are painstakingly manually analyzed before training. Furthermore, as novel malware samples arise that are beyond the scope of the training set, additional reverse engineering effort must be employed to update the training set. The sheer volume of new samples found in the wild creates substantial pressure on practitioners ability to reverse engineer enough malware to adequately train modern classifiers. In this paper, we present MalMixer, a malware family classifier using semi-supervised learning that achieves high accuracy with sparse training data. We present a domain-knowledge-aware data augmentation technique for malware feature representations, enhancing few-shot performance of semi-supervised malware family classification. We show that MalMixer achieves state-of-the-art performance in few-shot malware family classification settings. Our research confirms the feasibility and effectiveness of lightweight, domain-knowledge-aware data augmentation methods for malware features and shows the capabilities of similar semi-supervised classifiers in addressing malware classification issues.","authors":["Jiliang Li","Yifan Zhang","Yu Huang","Kevin Leach"],"url":"https://arxiv.org/abs/2409.13213"}
{"created":"2025-04-18","title":"Scene-Text Grounding for Text-Based Video Question Answering","abstract":"Existing efforts in text-based video question answering (TextVideoQA) are criticized for their opaque decisionmaking and heavy reliance on scene-text recognition. In this paper, we propose to study Grounded TextVideoQA by forcing models to answer questions and spatio-temporally localize the relevant scene-text regions, thus decoupling QA from scenetext recognition and promoting research towards interpretable QA. The task has three-fold significance. First, it encourages scene-text evidence versus other short-cuts for answer predictions. Second, it directly accepts scene-text regions as visual answers, thus circumventing the problem of ineffective answer evaluation by stringent string matching. Third, it isolates the challenges inherited in VideoQA and scene-text recognition. This enables the diagnosis of the root causes for failure predictions, e.g., wrong QA or wrong scene-text recognition? To achieve Grounded TextVideoQA, we propose the T2S-QA model that highlights a disentangled temporal-to-spatial contrastive learning strategy for weakly-supervised scene-text grounding and grounded TextVideoQA. To facilitate evaluation, we construct a new dataset ViTXT-GQA which features 52K scene-text bounding boxes within 2.2K temporal segments related to 2K questions and 729 videos. With ViTXT-GQA, we perform extensive experiments and demonstrate the severe limitations of existing techniques in Grounded TextVideoQA. While T2S-QA achieves superior results, the large performance gap with human leaves ample space for improvement. Our further analysis of oracle scene-text inputs posits that the major challenge is scene-text recognition. To advance the research of Grounded TextVideoQA, our dataset and code are at https://github.com/zhousheng97/ViTXT-GQA.git","authors":["Sheng Zhou","Junbin Xiao","Xun Yang","Peipei Song","Dan Guo","Angela Yao","Meng Wang","Tat-Seng Chua"],"url":"https://arxiv.org/abs/2409.14319"}
{"created":"2025-04-18","title":"Robust Data-Driven Tube-Based Zonotopic Predictive Control with Closed-Loop Guarantees","abstract":"This work proposes a robust data-driven tube-based zonotopic predictive control (TZPC) approach for discrete-time linear systems, designed to ensure stability and recursive feasibility in the presence of bounded noise. The proposed approach consists of two phases. In an initial learning phase, we provide an over-approximation of all models consistent with past input and noisy state data using zonotope properties. Subsequently, in a control phase, we formulate an optimization problem, which by integrating terminal ingredients is proven to be recursively feasible. Moreover, we prove that implementing this data-driven predictive control approach guarantees robust exponential stability of the closed-loop system. The effectiveness and competitive performance of the proposed control strategy, compared to recent data-driven predictive control methods, are illustrated through numerical simulations.","authors":["Mahsa Farjadnia","Angela Fontan","Amr Alanwar","Marco Molinari","Karl Henrik Johansson"],"url":"https://arxiv.org/abs/2409.14366"}
{"created":"2025-04-18","title":"Learning Diverse Robot Striking Motions with Diffusion Models and Kinematically Constrained Gradient Guidance","abstract":"Advances in robot learning have enabled robots to generate skills for a variety of tasks. Yet, robot learning is typically sample inefficient, struggles to learn from data sources exhibiting varied behaviors, and does not naturally incorporate constraints. These properties are critical for fast, agile tasks such as playing table tennis. Modern techniques for learning from demonstration improve sample efficiency and scale to diverse data, but are rarely evaluated on agile tasks. In the case of reinforcement learning, achieving good performance requires training on high-fidelity simulators. To overcome these limitations, we develop a novel diffusion modeling approach that is offline, constraint-guided, and expressive of diverse agile behaviors. The key to our approach is a kinematic constraint gradient guidance (KCGG) technique that computes gradients through both the forward kinematics of the robot arm and the diffusion model to direct the sampling process. KCGG minimizes the cost of violating constraints while simultaneously keeping the sampled trajectory in-distribution of the training data. We demonstrate the effectiveness of our approach for time-critical robotic tasks by evaluating KCGG in two challenging domains: simulated air hockey and real table tennis. In simulated air hockey, we achieved a 25.4% increase in block rate, while in table tennis, we saw a 17.3% increase in success rate compared to imitation learning baselines.","authors":["Kin Man Lee","Sean Ye","Qingyu Xiao","Zixuan Wu","Zulfiqar Zaidi","David B. D'Ambrosio","Pannag R. Sanketi","Matthew Gombolay"],"url":"https://arxiv.org/abs/2409.15528"}
{"created":"2025-04-18","title":"Effect of electric vehicles, heat pumps, and solar panels on low-voltage feeders: Evidence from smart meter profiles","abstract":"Electric vehicles (EVs), heat pumps (HPs) and solar panels are low-carbon technologies (LCTs) that are being connected to the low-voltage grid (LVG) at a rapid pace. One of the main hurdles to understand their impact on the LVG is the lack of recent, large electricity consumption datasets, measured in real-world conditions. We investigated the contribution of LCTs to the size and timing of peaks on LV feeders by using a large dataset of 42,089 smart meter profiles of residential LVG customers. These profiles were measured in 2022 by Fluvius, the distribution system operator (DSO) of Flanders, Belgium. The dataset contains customers that proactively requested higher-resolution smart metering data, and hence is biased towards energy-interested people. LV feeders of different sizes were statistically modelled with a profile sampling approach. For feeders with 40 connections, we found a contribution to the feeder peak of 1.2 kW for a HP, 1.4 kW for an EV and 2.0 kW for an EV charging faster than 6.5 kW. A visual analysis of the feeder-level loads shows that the classical duck curve is replaced by a night-camel curve for feeders with only HPs and a night-dromedary curve for feeders with only EVs charging faster than 6.5 kW. Consumption patterns will continue to change as the energy transition is carried out, because of e.g. dynamic electricity tariffs or increased battery capacities. Our introduced methods are simple to implement, making it a useful tool for DSOs that have access to smart meter data to monitor changing consumption patterns.","authors":["T. Becker","R. Smet","B. Macharis","K. Vanthournout"],"url":"https://arxiv.org/abs/2409.18105"}
{"created":"2025-04-18","title":"Small Space Encoding and Recognition of $k$-Palindromic Prefixes","abstract":"Palindromes are non-empty strings that read the same forward and backward. The problem of recognizing strings that can be represented as the concatenation of even-length palindromes, the concatenation of palindromes of length at least two, and the concatenation of exactly $k$ palindromes was introduced in the seminal paper of Knuth, Morris, and Pratt [SIAM J. Comput., 1977].","authors":["Gabriel Bathie","Jonas Ellert","Tatiana Starikovskaya"],"url":"https://arxiv.org/abs/2410.03309"}
{"created":"2025-04-18","title":"Presto! Distilling Steps and Layers for Accelerating Music Generation","abstract":"Despite advances in diffusion-based text-to-music (TTM) methods, efficient, high-quality generation remains a challenge. We introduce Presto!, an approach to inference acceleration for score-based diffusion transformers via reducing both sampling steps and cost per step. To reduce steps, we develop a new score-based distribution matching distillation (DMD) method for the EDM-family of diffusion models, the first GAN-based distillation method for TTM. To reduce the cost per step, we develop a simple, but powerful improvement to a recent layer distillation method that improves learning via better preserving hidden state variance. Finally, we combine our step and layer distillation methods together for a dual-faceted approach. We evaluate our step and layer distillation methods independently and show each yield best-in-class performance. Our combined distillation method can generate high-quality outputs with improved diversity, accelerating our base model by 10-18x (230/435ms latency for 32 second mono/stereo 44.1kHz, 15x faster than comparable SOTA) -- the fastest high-quality TTM to our knowledge. Sound examples can be found at https://presto-music.github.io/web/.","authors":["Zachary Novack","Ge Zhu","Jonah Casebeer","Julian McAuley","Taylor Berg-Kirkpatrick","Nicholas J. Bryan"],"url":"https://arxiv.org/abs/2410.05167"}
{"created":"2025-04-18","title":"Submodular Optimization for Keyframe Selection & Usage in SLAM","abstract":"Keyframes are LiDAR scans saved for future reference in Simultaneous Localization And Mapping (SLAM), but despite their central importance most algorithms leave choices of which scans to save and how to use them to wasteful heuristics. This work proposes two novel keyframe selection strategies for localization and map summarization, as well as a novel approach to submap generation which selects keyframes that best constrain localization. Our results show that online keyframe selection and submap generation reduce the number of saved keyframes and improve per scan computation time without compromising localization performance. We also present a map summarization feature for quickly capturing environments under strict map size constraints.","authors":["David Thorne","Nathan Chan","Yanlong Ma","Christa S. Robison","Philip R. Osteen","Brett T. Lopez"],"url":"https://arxiv.org/abs/2410.05576"}
{"created":"2025-04-18","title":"Control the GNN: Utilizing Neural Controller with Lyapunov Stability for Test-Time Feature Reconstruction","abstract":"The performance of graph neural networks (GNNs) is susceptible to discrepancies between training and testing sample distributions. Prior studies have attempted to mitigating the impact of distribution shift by reconstructing node features during the testing phase without modifying the model parameters. However, these approaches lack theoretical analysis of the proximity between predictions and ground truth at test time. In this paper, we propose a novel node feature reconstruction method grounded in Lyapunov stability theory. Specifically, we model the GNN as a control system during the testing phase, considering node features as control variables. A neural controller that adheres to the Lyapunov stability criterion is then employed to reconstruct these node features, ensuring that the predictions progressively approach the ground truth at test time. We validate the effectiveness of our approach through extensive experiments across multiple datasets, demonstrating significant performance improvements.","authors":["Jielong Yang","Rui Ding","Feng Ji","Hongbin Wang","Linbo Xie"],"url":"https://arxiv.org/abs/2410.09708"}
{"created":"2025-04-18","title":"Evaluating Semantic Variation in Text-to-Image Synthesis: A Causal Perspective","abstract":"Accurate interpretation and visualization of human instructions are crucial for text-to-image (T2I) synthesis. However, current models struggle to capture semantic variations from word order changes, and existing evaluations, relying on indirect metrics like text-image similarity, fail to reliably assess these challenges. This often obscures poor performance on complex or uncommon linguistic patterns by the focus on frequent word combinations. To address these deficiencies, we propose a novel metric called SemVarEffect and a benchmark named SemVarBench, designed to evaluate the causality between semantic variations in inputs and outputs in T2I synthesis. Semantic variations are achieved through two types of linguistic permutations, while avoiding easily predictable literal variations. Experiments reveal that the CogView-3-Plus and Ideogram 2 performed the best, achieving a score of 0.2/1. Semantic variations in object relations are less understood than attributes, scoring 0.07/1 compared to 0.17-0.19/1. We found that cross-modal alignment in UNet or Transformers plays a crucial role in handling semantic variations, a factor previously overlooked by a focus on textual encoders. Our work establishes an effective evaluation framework that advances the T2I synthesis community's exploration of human instruction understanding. Our benchmark and code are available at https://github.com/zhuxiangru/SemVarBench .","authors":["Xiangru Zhu","Penglei Sun","Yaoxian Song","Yanghua Xiao","Zhixu Li","Chengyu Wang","Jun Huang","Bei Yang","Xiaoxiao Xu"],"url":"https://arxiv.org/abs/2410.10291"}
{"created":"2025-04-18","title":"Comprehending Knowledge Graphs with Large Language Models for Recommender Systems","abstract":"In recent years, the introduction of knowledge graphs (KGs) has significantly advanced recommender systems by facilitating the discovery of potential associations between items. However, existing methods still face several limitations. First, most KGs suffer from missing facts or limited scopes. Second, existing methods convert textual information in KGs into IDs, resulting in the loss of natural semantic connections between different items. Third, existing methods struggle to capture high-order connections in the global KG. To address these limitations, we propose a novel method called CoLaKG, which leverages large language models (LLMs) to improve KG-based recommendations. The extensive knowledge and remarkable reasoning capabilities of LLMs enable our method to supplement missing facts in KGs, and their powerful text understanding abilities allow for better utilization of semantic information. Specifically, CoLaKG extracts useful information from KGs at both local and global levels. By employing the item-centered subgraph extraction and prompt engineering, it can accurately understand the local information. In addition, through the semantic-based retrieval module, each item is enriched by related items from the entire knowledge graph, effectively harnessing global information. Furthermore, the local and global information are effectively integrated into the recommendation model through a representation fusion module and a retrieval-augmented representation learning module, respectively. Extensive experiments on four real-world datasets demonstrate the superiority of our method.","authors":["Ziqiang Cui","Yunpeng Weng","Xing Tang","Fuyuan Lyu","Dugang Liu","Xiuqiang He","Chen Ma"],"url":"https://arxiv.org/abs/2410.12229"}
{"created":"2025-04-18","title":"Nash equilibria in scalar discrete-time linear quadratic games","abstract":"An open problem in linear quadratic (LQ) games has been characterizing the Nash equilibria. This problem has renewed relevance given the surge of work on understanding the convergence of learning algorithms in dynamic games. This paper investigates scalar discrete-time infinite-horizon LQ games with two agents. Even in this arguably simple setting, there are no results for finding $\\textit{all}$ Nash equilibria. By analyzing the best response map, we formulate a polynomial system of equations characterizing the linear feedback Nash equilibria. This enables us to bring in tools from algebraic geometry, particularly the Gr\\\"obner basis, to study the roots of this polynomial system. Consequently, we can not only compute all Nash equilibria numerically, but we can also characterize their number with explicit conditions. For instance, we prove that the LQ games under consideration admit at most three Nash equilibria. We further provide sufficient conditions for the existence of at most two Nash equilibria and sufficient conditions for the uniqueness of the Nash equilibrium. Our numerical experiments demonstrate the tightness of our bounds and showcase the increased complexity in settings with more than two agents.","authors":["Giulio Salizzoni","Reda Ouhamma","Maryam Kamgarpour"],"url":"https://arxiv.org/abs/2410.12544"}
{"created":"2025-04-18","title":"In-context KV-Cache Eviction for LLMs via Attention-Gate","abstract":"The KV-Cache technique has become the standard for the inference of large language models (LLMs). Yet, it is widely criticized that KV-Cache can become a bottleneck of the LLM inference system. This paper enables a novel dynamic KV-Cache eviction policy by injecting a lightweight module called Attention-Gate to the model. It accepts the global context as input and yields eviction flags for each token. The self-attention modules in the model proceed according to the flags and cache only a subset of the KV states for next token prediction. The Attention-Gates can yield various flags for different heads and layers and be easily tuned on top of a pre-trained LLM via continual pre-training or supervised fine-tuning. The computational and memory overhead introduced by Attention-Gates can be minimal. We empirically evaluate the proposed approach across multiple scenarios, showing that effective eviction of redundant tokens can not only improve efficiency but also enhance performance.","authors":["Zihao Zeng","Bokai Lin","Tianqi Hou","Hao Zhang","Zhijie Deng"],"url":"https://arxiv.org/abs/2410.12876"}
{"created":"2025-04-18","title":"Systems with Switching Causal Relations: A Meta-Causal Perspective","abstract":"Most work on causality in machine learning assumes that causal relationships are driven by a constant underlying process. However, the flexibility of agents' actions or tipping points in the environmental process can change the qualitative dynamics of the system. As a result, new causal relationships may emerge, while existing ones change or disappear, resulting in an altered causal graph. To analyze these qualitative changes on the causal graph, we propose the concept of meta-causal states, which groups classical causal models into clusters based on equivalent qualitative behavior and consolidates specific mechanism parameterizations. We demonstrate how meta-causal states can be inferred from observed agent behavior, and discuss potential methods for disentangling these states from unlabeled data. Finally, we direct our analysis towards the application of a dynamical system, showing that meta-causal states can also emerge from inherent system dynamics, and thus constitute more than a context-dependent framework in which mechanisms emerge only as a result of external factors.","authors":["Moritz Willig","Tim Nelson Tobiasch","Florian Peter Busch","Jonas Seng","Devendra Singh Dhami","Kristian Kersting"],"url":"https://arxiv.org/abs/2410.13054"}
{"created":"2025-04-18","title":"Arithmetic Transformers Can Length-Generalize in Both Operand Length and Count","abstract":"Transformers often struggle with length generalization, meaning they fail to generalize to sequences longer than those encountered during training. While arithmetic tasks are commonly used to study length generalization, certain tasks are considered notoriously difficult, e.g., multi-operand addition (requiring generalization over both the number of operands and their lengths) and multiplication (requiring generalization over both operand lengths). In this work, we achieve approximately 2-3x length generalization on both tasks, which is the first such achievement in arithmetic Transformers. We design task-specific scratchpads enabling the model to focus on a fixed number of tokens per each next-token prediction step, and apply multi-level versions of \\Position Coupling (Cho et al., 2024; McLeish et al., 2024) to let Transformers know the right position to attend to. On the theory side, we prove that a 1-layer Transformer using our method can solve multi-operand addition, up to operand length and operand count that are exponential in embedding dimension.","authors":["Hanseul Cho","Jaeyoung Cha","Srinadh Bhojanapalli","Chulhee Yun"],"url":"https://arxiv.org/abs/2410.15787"}
{"created":"2025-04-18","title":"Trustworthy XAI and Application","abstract":"Artificial Intelligence (AI) is an important part of our everyday lives. We use it in self-driving cars and smartphone assistants. People often call it a \"black box\" because its complex systems, especially deep neural networks, are hard to understand. This complexity raises concerns about accountability, bias, and fairness, even though AI can be quite accurate. Explainable Artificial Intelligence (XAI) is important for building trust. It helps ensure that AI systems work reliably and ethically. This article looks at XAI and its three main parts: transparency, explainability, and trustworthiness. We will discuss why these components matter in real-life situations. We will also review recent studies that show how XAI is used in different fields. Ultimately, gaining trust in AI systems is crucial for their successful use in society.","authors":["MD Abdullah Al Nasim","A. S. M Anas Ferdous","Abdur Rashid","Fatema Tuj Johura Soshi","Parag Biswas","Angona Biswas","Kishor Datta Gupta"],"url":"https://arxiv.org/abs/2410.17139"}
{"created":"2025-04-18","title":"Minimum-Violation Temporal Logic Planning for Heterogeneous Robots under Robot Skill Failures","abstract":"In this paper, we consider teams of robots with heterogeneous skills (e.g., sensing and manipulation) tasked with collaborative missions described by Linear Temporal Logic (LTL) formulas. These LTL-encoded tasks require robots to apply their skills to specific regions and objects in a temporal and logical order. While existing temporal logic planning algorithms can synthesize correct-by-construction plans, they typically lack reactivity to unexpected failures of robot skills, which can compromise mission performance. This paper addresses this challenge by proposing a reactive LTL planning algorithm that adapts to unexpected failures during deployment. Specifically, the proposed algorithm reassigns sub-tasks to robots based on their functioning skills and locally revises team plans to accommodate these new assignments and ensure mission completion. The main novelty of the proposed algorithm is its ability to handle cases where mission completion becomes impossible due to limited functioning robots. Instead of reporting mission failure, the algorithm strategically prioritizes the most crucial sub-tasks and locally revises the team's plans, as per user-specified priorities, to minimize mission violations. We provide theoretical conditions under which the proposed framework computes the minimum-violation task reassignments and team plans. We provide numerical and hardware experiments to demonstrate the efficiency of the proposed method.","authors":["Samarth Kalluraya","Beichen Zhou","Yiannis Kantaros"],"url":"https://arxiv.org/abs/2410.17188"}
{"created":"2025-04-18","title":"Do Vision-Language Models Represent Space and How? Evaluating Spatial Frame of Reference Under Ambiguities","abstract":"Spatial expressions in situated communication can be ambiguous, as their meanings vary depending on the frames of reference (FoR) adopted by speakers and listeners. While spatial language understanding and reasoning by vision-language models (VLMs) have gained increasing attention, potential ambiguities in these models are still under-explored. To address this issue, we present the COnsistent Multilingual Frame Of Reference Test (COMFORT), an evaluation protocol to systematically assess the spatial reasoning capabilities of VLMs. We evaluate nine state-of-the-art VLMs using COMFORT. Despite showing some alignment with English conventions in resolving ambiguities, our experiments reveal significant shortcomings of VLMs: notably, the models (1) exhibit poor robustness and consistency, (2) lack the flexibility to accommodate multiple FoRs, and (3) fail to adhere to language-specific or culture-specific conventions in cross-lingual tests, as English tends to dominate other languages. With a growing effort to align vision-language models with human cognitive intuitions, we call for more attention to the ambiguous nature and cross-cultural diversity of spatial reasoning.","authors":["Zheyuan Zhang","Fengyuan Hu","Jayjun Lee","Freda Shi","Parisa Kordjamshidi","Joyce Chai","Ziqiao Ma"],"url":"https://arxiv.org/abs/2410.17385"}
{"created":"2025-04-18","title":"Deterministic $(2/3-\\varepsilon)$-Approximation of Matroid Intersection Using Nearly-Linear Independence-Oracle Queries","abstract":"In the matroid intersection problem, we are given two matroids $\\mathcal{M}_1 = (V, \\mathcal{I}_1)$ and $\\mathcal{M}_2 = (V, \\mathcal{I}_2)$ defined on the same ground set $V$ of $n$ elements, and the objective is to find a common independent set $S \\in \\mathcal{I}_1 \\cap \\mathcal{I}_2$ of largest possible cardinality, denoted by $r$. In this paper, we consider a deterministic matroid intersection algorithm with only a nearly linear number of independence oracle queries. Our contribution is to present a deterministic $O(\\frac{n}{\\varepsilon} + r \\log r)$-independence-query $(2/3-\\varepsilon)$-approximation algorithm for any $\\varepsilon > 0$. Our idea is very simple: we apply a recent $\\tilde{O}(n \\sqrt{r}/\\varepsilon)$-independence-query $(1 - \\varepsilon)$-approximation algorithm of Blikstad [ICALP 2021], but terminate it before completion. Moreover, we also present a semi-streaming algorithm for $(2/3 -\\varepsilon)$-approximation of matroid intersection in $O(1/\\varepsilon)$ passes.","authors":["Tatsuya Terao"],"url":"https://arxiv.org/abs/2410.18820"}
{"created":"2025-04-18","title":"Multi-Field Adaptive Retrieval","abstract":"Document retrieval for tasks such as search and retrieval-augmented generation typically involves datasets that are unstructured: free-form text without explicit internal structure in each document. However, documents can have a structured form, consisting of fields such as an article title, message body, or HTML header. To address this gap, we introduce Multi-Field Adaptive Retrieval (MFAR), a flexible framework that accommodates any number of and any type of document indices on structured data. Our framework consists of two main steps: (1) the decomposition of an existing document into fields, each indexed independently through dense and lexical methods, and (2) learning a model which adaptively predicts the importance of a field by conditioning on the document query, allowing on-the-fly weighting of the most likely field(s). We find that our approach allows for the optimized use of dense versus lexical representations across field types, significantly improves in document ranking over a number of existing retrievers, and achieves state-of-the-art performance for multi-field structured data.","authors":["Millicent Li","Tongfei Chen","Benjamin Van Durme","Patrick Xia"],"url":"https://arxiv.org/abs/2410.20056"}
{"created":"2025-04-18","title":"Harmless Backdoor-based Client-side Watermarking in Federated Learning","abstract":"Protecting intellectual property (IP) in federated learning (FL) is increasingly important as clients contribute proprietary data to collaboratively train models. Model watermarking, particularly through backdoor-based methods, has emerged as a popular approach for verifying ownership and contributions in deep neural networks trained via FL. By manipulating their datasets, clients can embed a secret pattern, resulting in non-intuitive predictions that serve as proof of participation, useful for claiming incentives or IP co-ownership. However, this technique faces practical challenges: (i) client watermarks can collide, leading to ambiguous ownership claims, and (ii) malicious clients may exploit watermarks to manipulate model predictions for harmful purposes. To address these issues, we propose Sanitizer, a server-side method that ensures client-embedded backdoors can only be activated in harmless environments but not natural queries. It identifies subnets within client-submitted models, extracts backdoors throughout the FL process, and confines them to harmless, client-specific input subspaces. This approach not only enhances Sanitizer's efficiency but also resolves conflicts when clients use similar triggers with different target labels. Our empirical results demonstrate that Sanitizer achieves near-perfect success verifying client contributions while mitigating the risks of malicious watermark use. Additionally, it reduces GPU memory consumption by 85% and cuts processing time by at least 5x compared to the baseline. Our code is open-sourced at https://hku-tasr.github.io/Sanitizer/.","authors":["Kaijing Luo","Ka-Ho Chow"],"url":"https://arxiv.org/abs/2410.21179"}
{"created":"2025-04-18","title":"Backward error analysis of stochastic Poisson integrators","abstract":"We address our attention to the numerical time discretization of stochastic Poisson systems via Poisson integrators. The aim of the investigation regards the backward error analysis of such integrators to reveal their ability of being structure-preserving, for long times of integration. In particular, we first provide stochastic modified equations suitable for such integrators and then we rigorously study them to prove accurate estimates on the long-term numerical error along the dynamics generated by stochastic Poisson integrators, with reference to the preservation of the random Hamiltonian conserved along the exact flow of the approximating Wong-Zakai Poisson system. Finally, selected numerical experiments confirm the effectiveness of the theoretical analysis.","authors":["Raffaele D'Ambrosio","Stefano Di Giovacchino"],"url":"https://arxiv.org/abs/2410.21817"}
{"created":"2025-04-18","title":"Understanding the Limits of Vision Language Models Through the Lens of the Binding Problem","abstract":"Recent work has documented striking heterogeneity in the performance of state-of-the-art vision language models (VLMs), including both multimodal language models and text-to-image models. These models are able to describe and generate a diverse array of complex, naturalistic images, yet they exhibit surprising failures on basic multi-object reasoning tasks -- such as counting, localization, and simple forms of visual analogy -- that humans perform with near perfect accuracy. To better understand this puzzling pattern of successes and failures, we turn to theoretical accounts of the binding problem in cognitive science and neuroscience, a fundamental problem that arises when a shared set of representational resources must be used to represent distinct entities (e.g., to represent multiple objects in an image), necessitating the use of serial processing to avoid interference. We find that many of the puzzling failures of state-of-the-art VLMs can be explained as arising due to the binding problem, and that these failure modes are strikingly similar to the limitations exhibited by rapid, feedforward processing in the human brain.","authors":["Declan Campbell","Sunayana Rane","Tyler Giallanza","Nicol\\`o De Sabbata","Kia Ghods","Amogh Joshi","Alexander Ku","Steven M. Frankland","Thomas L. Griffiths","Jonathan D. Cohen","Taylor W. Webb"],"url":"https://arxiv.org/abs/2411.00238"}
{"created":"2025-04-18","title":"Uncertainty Quantification via H\\\"older Divergence for Multi-View Representation Learning","abstract":"Evidence-based deep learning represents a burgeoning paradigm for uncertainty estimation, offering reliable predictions with negligible extra computational overheads. Existing methods usually adopt Kullback-Leibler divergence to estimate the uncertainty of network predictions, ignoring domain gaps among various modalities. To tackle this issue, this paper introduces a novel algorithm based on H\\\"older Divergence (HD) to enhance the reliability of multi-view learning by addressing inherent uncertainty challenges from incomplete or noisy data. Generally, our method extracts the representations of multiple modalities through parallel network branches, and then employs HD to estimate the prediction uncertainties. Through the Dempster-Shafer theory, integration of uncertainty from different modalities, thereby generating a comprehensive result that considers all available representations. Mathematically, HD proves to better measure the ``distance'' between real data distribution and predictive distribution of the model and improve the performances of multi-class recognition tasks.","authors":["Yan Zhang","Ming Li","Chun Li","Zhaoxia Liu","Ye Zhang","Fei Richard Yu"],"url":"https://arxiv.org/abs/2411.00826"}
{"created":"2025-04-18","title":"Know Where You're Uncertain When Planning with Multimodal Foundation Models: A Formal Framework","abstract":"Multimodal foundation models offer a promising framework for robotic perception and planning by processing sensory inputs to generate actionable plans. However, addressing uncertainty in both perception (sensory interpretation) and decision-making (plan generation) remains a critical challenge for ensuring task reliability. We present a comprehensive framework to disentangle, quantify, and mitigate these two forms of uncertainty. We first introduce a framework for uncertainty disentanglement, isolating perception uncertainty arising from limitations in visual understanding and decision uncertainty relating to the robustness of generated plans.","authors":["Neel P. Bhatt","Yunhao Yang","Rohan Siva","Daniel Milan","Ufuk Topcu","Zhangyang Wang"],"url":"https://arxiv.org/abs/2411.01639"}
{"created":"2025-04-18","title":"EmoSphere++: Emotion-Controllable Zero-Shot Text-to-Speech via Emotion-Adaptive Spherical Vector","abstract":"Emotional text-to-speech (TTS) technology has achieved significant progress in recent years; however, challenges remain owing to the inherent complexity of emotions and limitations of the available emotional speech datasets and models. Previous studies typically relied on limited emotional speech datasets or required extensive manual annotations, restricting their ability to generalize across different speakers and emotional styles. In this paper, we present EmoSphere++, an emotion-controllable zero-shot TTS model that can control emotional style and intensity to resemble natural human speech. We introduce a novel emotion-adaptive spherical vector that models emotional style and intensity without human annotation. Moreover, we propose a multi-level style encoder that can ensure effective generalization for both seen and unseen speakers. We also introduce additional loss functions to enhance the emotion transfer performance for zero-shot scenarios. We employ a conditional flow matching-based decoder to achieve high-quality and expressive emotional TTS in a few sampling steps. Experimental results demonstrate the effectiveness of the proposed framework.","authors":["Deok-Hyeon Cho","Hyung-Seok Oh","Seung-Bin Kim","Seong-Whan Lee"],"url":"https://arxiv.org/abs/2411.02625"}
{"created":"2025-04-18","title":"Efficient Fourier Filtering Network with Contrastive Learning for UAV-based Unaligned Bi-modal Salient Object Detection","abstract":"Unmanned aerial vehicle (UAV)-based bi-modal salient object detection (BSOD) aims to segment salient objects in a scene utilizing complementary cues in unaligned RGB and thermal image pairs. However, the high computational expense of existing UAV-based BSOD models limits their applicability to real-world UAV devices. To address this problem, we propose an efficient Fourier filter network with contrastive learning that achieves both real-time and accurate performance. Specifically, we first design a semantic contrastive alignment loss to align the two modalities at the semantic level, which facilitates mutual refinement in a parameter-free way. Second, inspired by the fast Fourier transform that obtains global relevance in linear complexity, we propose synchronized alignment fusion, which aligns and fuses bi-modal features in the channel and spatial dimensions by a hierarchical filtering mechanism. Our proposed model, AlignSal, reduces the number of parameters by 70.0%, decreases the floating point operations by 49.4%, and increases the inference speed by 152.5% compared to the cutting-edge BSOD model (i.e., MROS). Extensive experiments on the UAV RGB-T 2400 and seven bi-modal dense prediction datasets demonstrate that AlignSal achieves both real-time inference speed and better performance and generalizability compared to nineteen state-of-the-art models across most evaluation metrics. In addition, our ablation studies further verify AlignSal's potential in boosting the performance of existing aligned BSOD models on UAV-based unaligned data. The code is available at: https://github.com/JoshuaLPF/AlignSal.","authors":["Pengfei Lyu","Pak-Hei Yeung","Xiaosheng Yu","Xiufei Cheng","Chengdong Wu","Jagath C. Rajapakse"],"url":"https://arxiv.org/abs/2411.03728"}
{"created":"2025-04-18","title":"Predicting and Publishing Accurate Imbalance Prices Using Monte Carlo Tree Search","abstract":"The growing reliance on renewable energy sources, particularly solar and wind, has introduced challenges due to their uncontrollable production. This complicates maintaining the electrical grid balance, prompting some transmission system operators in Western Europe to implement imbalance tariffs that penalize unsustainable power deviations. These tariffs create an implicit demand response framework to mitigate grid instability. Yet, several challenges limit active participation. In Belgium, for example, imbalance prices are only calculated at the end of each 15-minute settlement period, creating high risk due to price uncertainty. This risk is further amplified by the inherent volatility of imbalance prices, discouraging participation. Although transmission system operators provide minute-based price predictions, the system imbalance volatility makes accurate price predictions challenging to obtain and requires sophisticated techniques. Moreover, publishing price estimates can prompt participants to adjust their schedules, potentially affecting the system balance and the final price, adding further complexity. To address these challenges, we propose a Monte Carlo Tree Search method that publishes accurate imbalance prices while accounting for potential response actions. Our approach models the system dynamics using a neural network forecaster and a cluster of virtual batteries controlled by reinforcement learning agents. Compared to Belgium's current publication method, our technique improves price accuracy by 20.4% under ideal conditions and by 12.8% in more realistic scenarios. This research addresses an unexplored, yet crucial problem, positioning this paper as a pioneering work in analyzing the potential of more advanced imbalance price publishing techniques.","authors":["Fabio Pavirani","Jonas Van Gompel","Seyed Soroush Karimi Madahi","Bert Claessens","Chris Develder"],"url":"https://arxiv.org/abs/2411.04011"}
{"created":"2025-04-18","title":"Planning for quasi-static manipulation tasks via an intrinsic haptic metric: a book insertion case study","abstract":"Contact-rich manipulation often requires strategic interactions with objects, such as pushing to accomplish specific tasks. We propose a novel scenario where a robot inserts a book into a crowded shelf by pushing aside neighboring books to create space before slotting the new book into place. Classical planning algorithms fail in this context due to limited space and their tendency to avoid contact. Additionally, they do not handle indirectly manipulable objects or consider force interactions. Our key contributions are: i) reframing quasi-static manipulation as a planning problem on an implicit manifold derived from equilibrium conditions; ii) utilizing an intrinsic haptic metric instead of ad-hoc cost functions; and iii) proposing an adaptive algorithm that simultaneously updates robot states, object positions, contact points, and haptic distances. We evaluate our method on a crowded bookshelf insertion task, and it can be generally applied to rigid body manipulation tasks. We propose proxies to capture contact points and forces, with superellipses to represent objects. This simplified model guarantees differentiability. Our framework autonomously discovers strategic wedging-in policies while our simplified contact model achieves behavior similar to real world scenarios. We also vary the stiffness and initial positions to analyze our framework comprehensively. The video can be found at https://youtu.be/eab8umZ3AQ0.","authors":["Lin Yang","Sri Harsha Turlapati","Chen Lv","Domenico Campolo"],"url":"https://arxiv.org/abs/2411.04374"}
{"created":"2025-04-18","title":"ViTOC: Vision Transformer and Object-aware Captioner","abstract":"This paper presents ViTOC (Vision Transformer and Object-aware Captioner), a novel vision-language model for image captioning that addresses the challenges of accuracy and diversity in generated descriptions. Unlike conventional approaches, ViTOC employs a dual-path architecture based on Vision Transformer and object detector, effectively fusing global visual features and local object information through learnable vectors. The model introduces an innovative object-aware prompting strategy that significantly enhances its capability in handling long-tail data. Experiments on the standard COCO dataset demonstrate that ViTOC outperforms baseline models across all evaluation metrics. Additionally, we propose a reference-free evaluation method based on CLIP to further validate the model's effectiveness. By utilizing pretrained visual model parameters, ViTOC achieves efficient end-to-end training.","authors":["Feiyang Huang"],"url":"https://arxiv.org/abs/2411.07265"}
{"created":"2025-04-18","title":"Optimizing LLM Inference for Database Systems: Cost-Aware Scheduling for Concurrent Requests","abstract":"LLMs are increasingly used inside database systems and in database applications for better complexity management and decision-making, where LLM inferences require significant GPU costs. LLM inference systems, however, are slow compared to database systems, limiting the expansion of the use of LLMs inside database systems. This paper first analyzes the LLM inference performance and focuses on a data management issue in LLM inference. We reveal that the root of the problem is the lack of an adequate resource cost model and optimization strategy when executing multiple concurrent inference requests. We adapt classic database multi-query optimization techniques by introducing cost models for concurrent inference requests and new scheduling strategies to optimize the use of memory resources by concurrent requests, thereby substantially improving performance.","authors":["Kyoungmin Kim","Kijae Hong","Caglar Gulcehre","Anastasia Ailamaki"],"url":"https://arxiv.org/abs/2411.07447"}
{"created":"2025-04-18","title":"IdentifyMe: A Challenging Long-Context Mention Resolution Benchmark for LLMs","abstract":"Recent evaluations of LLMs on coreference resolution have revealed that traditional output formats and evaluation metrics do not fully capture the models' referential understanding. To address this, we introduce IdentifyMe, a new benchmark for mention resolution presented in a multiple-choice question (MCQ) format, commonly used for evaluating LLMs. IdentifyMe features long narratives and employs heuristics to exclude easily identifiable mentions, creating a more challenging task. The benchmark also consists of a curated mixture of different mention types and corresponding entities, allowing for a fine-grained analysis of model performance. We evaluate both closed- and open source LLMs on IdentifyMe and observe a significant performance gap (20-30%) between the state-of-the-art sub-10B open models vs. closed ones. We observe that pronominal mentions, which have limited surface information, are typically much harder for models to resolve than nominal mentions. Additionally, we find that LLMs often confuse entities when their mentions overlap in nested structures. The highest-scoring model, GPT-4o, achieves 81.9% accuracy, highlighting the strong referential capabilities of state-of-the-art LLMs while also indicating room for further improvement.","authors":["Kawshik Manikantan","Makarand Tapaswi","Vineet Gandhi","Shubham Toshniwal"],"url":"https://arxiv.org/abs/2411.07466"}
{"created":"2025-04-18","title":"CDXLSTM: Boosting Remote Sensing Change Detection with Extended Long Short-Term Memory","abstract":"In complex scenes and varied conditions, effectively integrating spatial-temporal context is crucial for accurately identifying changes. However, current RS-CD methods lack a balanced consideration of performance and efficiency. CNNs lack global context, Transformers are computationally expensive, and Mambas face CUDA dependence and local correlation loss. In this paper, we propose CDXLSTM, with a core component that is a powerful XLSTM-based feature enhancement layer, integrating the advantages of linear computational complexity, global context perception, and strong interpret-ability. Specifically, we introduce a scale-specific Feature Enhancer layer, incorporating a Cross-Temporal Global Perceptron customized for semantic-accurate deep features, and a Cross-Temporal Spatial Refiner customized for detail-rich shallow features. Additionally, we propose a Cross-Scale Interactive Fusion module to progressively interact global change representations with spatial responses. Extensive experimental results demonstrate that CDXLSTM achieves state-of-the-art performance across three benchmark datasets, offering a compelling balance between efficiency and accuracy. Code is available at https://github.com/xwmaxwma/rschange.","authors":["Zhenkai Wu","Xiaowen Ma","Rongrong Lian","Kai Zheng","Wei Zhang"],"url":"https://arxiv.org/abs/2411.07863"}
{"created":"2025-04-18","title":"Balancing Passenger Transport and Power Distribution: A Distributed Dispatch Policy for Shared Autonomous Electric Vehicles","abstract":"Shared autonomous electric vehicles can provide on-demand transportation for passengers while also interacting extensively with the electric distribution system. This interaction is especially beneficial after a disaster when the large battery capacity of the fleet can be used to restore critical electric loads. We develop a dispatch policy that balances the need to continue serving passengers (especially critical workers) and the ability to transfer energy across the network. The model predictive control policy tracks both passenger and energy flows and provides maximum passenger throughput if any policy can. The resulting mixed integer linear programming problem is difficult to solve for large-scale problems, so a distributed solution approach is developed to improve scalability, privacy, and resilience. We demonstrate that the proposed heuristic, based on the alternating direction method of multipliers, is effective in achieving near-optimal solutions quickly. The dispatch policy is examined in simulation to demonstrate the ability of vehicles to balance these competing objectives with benefits to both systems. Finally, we compare several dispatch behaviors, demonstrating the importance of including operational constraints and objectives from both the transportation and electric systems in the model.","authors":["Jake Robbennolt","Meiyi Li","Javad Mohammadi","Stephen D. Boyles"],"url":"https://arxiv.org/abs/2411.10444"}
{"created":"2025-04-18","title":"Integrating Physics and Topology in Neural Networks for Learning Rigid Body Dynamics","abstract":"Rigid body interactions are fundamental to numerous scientific disciplines, but remain challenging to simulate due to their abrupt nonlinear nature and sensitivity to complex, often unknown environmental factors. These challenges call for adaptable learning-based methods capable of capturing complex interactions beyond explicit physical models and simulations. While graph neural networks can handle simple scenarios, they struggle with complex scenes and long-term predictions. We introduce a novel framework for modeling rigid body dynamics and learning collision interactions, addressing key limitations of existing graph-based methods. Our approach extends the traditional representation of meshes by incorporating higher-order topology complexes, offering a physically consistent representation. Additionally, we propose a physics-informed message-passing neural architecture, embedding physical laws directly in the model. Our method demonstrates superior accuracy, even during long rollouts, and exhibits strong generalization to unseen scenarios. Importantly, this work addresses the challenge of multi-entity dynamic interactions, with applications spanning diverse scientific and engineering domains.","authors":["Amaury Wei","Olga Fink"],"url":"https://arxiv.org/abs/2411.11467"}
{"created":"2025-04-18","title":"Human-Activity AGV Quality Assessment: A Benchmark Dataset and an Objective Evaluation Metric","abstract":"AI-driven video generation techniques have made significant progress in recent years. However, AI-generated videos (AGVs) involving human activities often exhibit substantial visual and semantic distortions, hindering the practical application of video generation technologies in real-world scenarios. To address this challenge, we conduct a pioneering study on human activity AGV quality assessment, focusing on visual quality evaluation and the identification of semantic distortions. First, we construct the AI-Generated Human activity Video Quality Assessment (Human-AGVQA) dataset, consisting of 6,000 AGVs derived from 15 popular text-to-video (T2V) models using 400 text prompts that describe diverse human activities. We conduct a subjective study to evaluate the human appearance quality, action continuity quality, and overall video quality of AGVs, and identify semantic issues of human body parts. Based on Human-AGVQA, we benchmark the performance of T2V models and analyze their strengths and weaknesses in generating different categories of human activities. Second, we develop an objective evaluation metric, named AI-Generated Human activity Video Quality metric (GHVQ), to automatically analyze the quality of human activity AGVs. GHVQ systematically extracts human-focused quality features, AI-generated content-aware quality features, and temporal continuity features, making it a comprehensive and explainable quality metric for human activity AGVs. The extensive experimental results show that GHVQ outperforms existing quality metrics on the Human-AGVQA dataset by a large margin, demonstrating its efficacy in assessing the quality of human activity AGVs. The Human-AGVQA dataset and GHVQ metric will be released publicly.","authors":["Zhichao Zhang","Wei Sun","Xinyue Li","Yunhao Li","Qihang Ge","Jun Jia","Zicheng Zhang","Zhongpeng Ji","Fengyu Sun","Shangling Jui","Xiongkuo Min","Guangtao Zhai"],"url":"https://arxiv.org/abs/2411.16619"}
{"created":"2025-04-18","title":"AMPS: ASR with Multimodal Paraphrase Supervision","abstract":"Spontaneous or conversational multilingual speech presents many challenges for state-of-the-art automatic speech recognition (ASR) systems. In this work, we present a new technique AMPS that augments a multilingual multimodal ASR system with paraphrase-based supervision for improved conversational ASR in multiple languages, including Hindi, Marathi, Malayalam, Kannada, and Nyanja. We use paraphrases of the reference transcriptions as additional supervision while training the multimodal ASR model and selectively invoke this paraphrase objective for utterances with poor ASR performance. Using AMPS with a state-of-the-art multimodal model SeamlessM4T, we obtain significant relative reductions in word error rates (WERs) of up to 5%. We present detailed analyses of our system using both objective and human evaluation metrics.","authors":["Abhishek Gupta","Amruta Parulekar","Sameep Chattopadhyay","Preethi Jyothi"],"url":"https://arxiv.org/abs/2411.18368"}
{"created":"2025-04-18","title":"Think-to-Talk or Talk-to-Think? When LLMs Come Up with an Answer in Multi-Step Arithmetic Reasoning","abstract":"This study investigates the internal reasoning process of language models during arithmetic multi-step reasoning, motivated by the question of when they internally form their answers during reasoning. Particularly, we inspect whether the answer is determined before or after chain-of-thought (CoT) begins to determine whether models follow a post-hoc Think-to-Talk mode or a step-by-step Talk-to-Think mode of explanation. Through causal probing experiments in controlled arithmetic reasoning tasks, we found systematic internal reasoning patterns across models in our case study; for example, single-step subproblems are solved before CoT begins, and more complicated multi-step calculations are performed during CoT.","authors":["Keito Kudo","Yoichi Aoki","Tatsuki Kuribayashi","Shusaku Sone","Masaya Taniguchi","Ana Brassard","Keisuke Sakaguchi","Kentaro Inui"],"url":"https://arxiv.org/abs/2412.01113"}
{"created":"2025-04-18","title":"Structured 3D Latents for Scalable and Versatile 3D Generation","abstract":"We introduce a novel 3D generation method for versatile and high-quality 3D asset creation. The cornerstone is a unified Structured LATent (SLAT) representation which allows decoding to different output formats, such as Radiance Fields, 3D Gaussians, and meshes. This is achieved by integrating a sparsely-populated 3D grid with dense multiview visual features extracted from a powerful vision foundation model, comprehensively capturing both structural (geometry) and textural (appearance) information while maintaining flexibility during decoding. We employ rectified flow transformers tailored for SLAT as our 3D generation models and train models with up to 2 billion parameters on a large 3D asset dataset of 500K diverse objects. Our model generates high-quality results with text or image conditions, significantly surpassing existing methods, including recent ones at similar scales. We showcase flexible output format selection and local 3D editing capabilities which were not offered by previous models. Code, model, and data will be released.","authors":["Jianfeng Xiang","Zelong Lv","Sicheng Xu","Yu Deng","Ruicheng Wang","Bowen Zhang","Dong Chen","Xin Tong","Jiaolong Yang"],"url":"https://arxiv.org/abs/2412.01506"}
{"created":"2025-04-18","title":"SEAL: Semantic Attention Learning for Long Video Representation","abstract":"Long video understanding presents challenges due to the inherent high computational complexity and redundant temporal information. An effective representation for long videos must efficiently process such redundancy while preserving essential contents for downstream tasks. This paper introduces SEmantic Attention Learning (SEAL), a novel unified representation for long videos. To reduce computational complexity, long videos are decomposed into three distinct types of semantic entities: scenes, objects, and actions, allowing models to operate on a compact set of entities rather than a large number of frames or pixels. To further address redundancy, we propose an attention learning module that balances token relevance with diversity, formulated as a subset selection optimization problem. Our representation is versatile and applicable across various long video understanding tasks. Extensive experiments demonstrate that SEAL significantly outperforms state-of-the-art methods in video question answering and temporal grounding tasks across diverse benchmarks, including LVBench, MovieChat-1K, and Ego4D.","authors":["Lan Wang","Yujia Chen","Du Tran","Vishnu Naresh Boddeti","Wen-Sheng Chu"],"url":"https://arxiv.org/abs/2412.01798"}
{"created":"2025-04-18","title":"Wavelet Diffusion Neural Operator","abstract":"Simulating and controlling physical systems described by partial differential equations (PDEs) are crucial tasks across science and engineering. Recently, diffusion generative models have emerged as a competitive class of methods for these tasks due to their ability to capture long-term dependencies and model high-dimensional states. However, diffusion models typically struggle with handling system states with abrupt changes and generalizing to higher resolutions. In this work, we propose Wavelet Diffusion Neural Operator (WDNO), a novel PDE simulation and control framework that enhances the handling of these complexities. WDNO comprises two key innovations. Firstly, WDNO performs diffusion-based generative modeling in the wavelet domain for the entire trajectory to handle abrupt changes and long-term dependencies effectively. Secondly, to address the issue of poor generalization across different resolutions, which is one of the fundamental tasks in modeling physical systems, we introduce multi-resolution training. We validate WDNO on five physical systems, including 1D advection equation, three challenging physical systems with abrupt changes (1D Burgers' equation, 1D compressible Navier-Stokes equation and 2D incompressible fluid), and a real-world dataset ERA5, which demonstrates superior performance on both simulation and control tasks over state-of-the-art methods, with significant improvements in long-term and detail prediction accuracy. Remarkably, in the challenging context of the 2D high-dimensional and indirect control task aimed at reducing smoke leakage, WDNO reduces the leakage by 33.2% compared to the second-best baseline. The code can be found at https://github.com/AI4Science-WestlakeU/wdno.git.","authors":["Peiyan Hu","Rui Wang","Xiang Zheng","Tao Zhang","Haodong Feng","Ruiqi Feng","Long Wei","Yue Wang","Zhi-Ming Ma","Tailin Wu"],"url":"https://arxiv.org/abs/2412.04833"}
{"created":"2025-04-18","title":"Listen to Your Map: An Online Representation for Spatial Sonification","abstract":"Robotic perception is becoming a key technology for navigation aids, especially helping individuals with visual impairments through spatial sonification. This paper introduces a mapping representation that accurately captures scene geometry for sonification, turning physical spaces into auditory experiences. Using depth sensors, we encode an incrementally built 3D scene into a compact 360-degree representation with angular and distance information, aligning this way with human auditory spatial perception. The proposed framework performs localisation and mapping via VDB-Gaussian Process Distance Fields for efficient online scene reconstruction. The key aspect is a sensor-centric structure that maintains either a 2D-circular or 3D-cylindrical raster-based projection. This spatial representation is then converted into binaural auditory signals using simple pre-recorded responses from a representative room. Quantitative and qualitative evaluations show improvements in accuracy, coverage, timing and suitability for sonification compared to other approaches, with effective handling of dynamic objects as well. An accompanying video demonstrates spatial sonification in room-like environments. https://tinyurl.com/ListenToYourMap","authors":["Lan Wu","Craig Jin","Monisha Mushtary Uttsha","Teresa Vidal-Calleja"],"url":"https://arxiv.org/abs/2412.05486"}
{"created":"2025-04-18","title":"UMSPU: Universal Multi-Size Phase Unwrapping via Mutual Self-Distillation and Adaptive Boosting Ensemble Segmenters","abstract":"Spatial phase unwrapping is a key technique for extracting phase information to obtain 3D morphology and other features. Modern industrial measurement scenarios demand high precision, large image sizes, and high speed. However, conventional methods struggle with noise resistance and processing speed. Current deep learning methods are limited by the receptive field size and sparse semantic information, making them ineffective for large size images. To address this issue, we propose a mutual self-distillation (MSD) mechanism and adaptive boosting ensemble segmenters to construct a universal multi-size phase unwrapping network (UMSPU). MSD performs hierarchical attention refinement and achieves cross-layer collaborative learning through bidirectional distillation, ensuring fine-grained semantic representation across image sizes. The adaptive boosting ensemble segmenters combine weak segmenters with different receptive fields into a strong one, ensuring stable segmentation across spatial frequencies. Experimental results show that UMSPU overcomes image size limitations, achieving high precision across image sizes ranging from 256*256 to 2048*2048 (an 8 times increase). It also outperforms existing methods in speed, robustness, and generalization. Its practicality is further validated in structured light imaging and InSAR. We believe that UMSPU offers a universal solution for phase unwrapping, with broad potential for industrial applications.","authors":["Lintong Du","Huazhen Liu","Yijia Zhang","ShuXin Liu","Yuan Qu","Zenghui Zhang","Jiamiao Yang"],"url":"https://arxiv.org/abs/2412.05584"}
{"created":"2025-04-18","title":"VariFace: Fair and Diverse Synthetic Dataset Generation for Face Recognition","abstract":"The use of large-scale, web-scraped datasets to train face recognition models has raised significant privacy and bias concerns. Synthetic methods mitigate these concerns and provide scalable and controllable face generation to enable fair and accurate face recognition. However, existing synthetic datasets display limited intraclass and interclass diversity and do not match the face recognition performance obtained using real datasets. Here, we propose VariFace, a two-stage diffusion-based pipeline to create fair and diverse synthetic face datasets to train face recognition models. Specifically, we introduce three methods: Face Recognition Consistency to refine demographic labels, Face Vendi Score Guidance to improve interclass diversity, and Divergence Score Conditioning to balance the identity preservation-intraclass diversity trade-off. When constrained to the same dataset size, VariFace considerably outperforms previous synthetic datasets (0.9200 $\\rightarrow$ 0.9405) and achieves comparable performance to face recognition models trained with real data (Real Gap = -0.0065). In an unconstrained setting, VariFace not only consistently achieves better performance compared to previous synthetic methods across dataset sizes but also, for the first time, outperforms the real dataset (CASIA-WebFace) across six evaluation datasets. This sets a new state-of-the-art performance with an average face verification accuracy of 0.9567 (Real Gap = +0.0097) across LFW, CFP-FP, CPLFW, AgeDB, and CALFW datasets and 0.9366 (Real Gap = +0.0380) on the RFW dataset.","authors":["Michael Yeung","Toya Teramoto","Songtao Wu","Tatsuo Fujiwara","Kenji Suzuki","Tamaki Kojima"],"url":"https://arxiv.org/abs/2412.06235"}
{"created":"2025-04-18","title":"AHSG: Adversarial Attack on High-level Semantics in Graph Neural Networks","abstract":"Adversarial attacks on Graph Neural Networks aim to perturb the performance of the learner by carefully modifying the graph topology and node attributes. Existing methods achieve attack stealthiness by constraining the modification budget and differences in graph properties. However, these methods typically disrupt task-relevant primary semantics directly, which results in low defensibility and detectability of the attack. In this paper, we propose an Adversarial Attack on High-level Semantics for Graph Neural Networks (AHSG), which is a graph structure attack model that ensures the retention of primary semantics. By combining latent representations with shared primary semantics, our model retains detectable attributes and relational patterns of the original graph while leveraging more subtle changes to carry out the attack. Then we use the Projected Gradient Descent algorithm to map the latent representations with attack effects to the adversarial graph. Through experiments on robust graph deep learning models equipped with defense strategies, we demonstrate that AHSG outperforms other state-of-the-art methods in attack effectiveness. Additionally, using Contextual Stochastic Block Models to detect the attacked graph further validates that our method preserves the primary semantics of the graph.","authors":["Kai Yuan","Jiahao Zhang","Yidi Wang","Xiaobing Pei"],"url":"https://arxiv.org/abs/2412.07468"}
{"created":"2025-04-18","title":"Protecting Confidentiality, Privacy and Integrity in Collaborative Learning","abstract":"A collaboration between dataset owners and model owners is needed to facilitate effective machine learning (ML) training. During this collaboration, however, dataset owners and model owners want to protect the confidentiality of their respective assets (i.e., datasets, models and training code), with the dataset owners also caring about the privacy of individual users whose data is in their datasets. Existing solutions either provide limited confidentiality for models and training code, or suffer from privacy issues due to collusion.","authors":["Dong Chen","Alice Dethise","Istemi Ekin Akkus","Ivica Rimac","Klaus Satzke","Antti Koskela","Marco Canini","Wei Wang","Ruichuan Chen"],"url":"https://arxiv.org/abs/2412.08534"}
{"created":"2025-04-18","title":"Improving Multiresource Job Scheduling with Markovian Service Rate Policies","abstract":"Modern cloud computing workloads are composed of multiresource jobs that require a variety of computational resources in order to run, such as CPU cores, memory, disk space, or hardware accelerators. A single cloud server can typically run many multiresource jobs in parallel, but only if the server has sufficient resources to satisfy the demands of every job. A scheduling policy must therefore select sets of multiresource jobs to run in parallel in order to minimize the mean response time across jobs -- the average time from when a job arrives to the system until it is completed. Unfortunately, achieving low response times by selecting sets of jobs that fully utilize the available server resources has proven to be a difficult problem.","authors":["Zhongrui Chen","Isaac Grosof","Benjamin Berg"],"url":"https://arxiv.org/abs/2412.08915"}
{"created":"2025-04-18","title":"Unexpected but informative: What fixation-related potentials tell us about the processing of confusing program code","abstract":"As software pervades more and more areas of our professional and personal lives, there is an ever-increasing need to maintain software, and for programmers to be able to efficiently write and understand program code. In the first study of its kind, we analyze fixation-related potentials (FRPs) to explore the online processing of program code patterns that are ambiguous to programmers, but not the computer (so-called atoms of confusion), and their underlying neurocognitive mechanisms in an ecologically valid setting. Relative to unambiguous counterparts in program code, atoms of confusion elicit a late frontal positivity with a duration of about 400 to 700 ms after first looking at the atom of confusion. As the frontal positivity shows high resemblance with an event-related potential (ERP) component found during natural language processing that is elicited by unexpected but plausible words in sentence context, we take these data to suggest that the brain engages similar neurocognitive mechanisms in response to unexpected and informative inputs in program code and in natural language. In both domains, these inputs lead to an update of a comprehender's situation model that is essential for information extraction from a quickly unfolding input.","authors":["Annabelle Bergum","Anna-Maria Maurer","Norman Peitek","Regine Bader","Axel Mecklinger","Vera Demberg","Janet Siegmund","Sven Apel"],"url":"https://arxiv.org/abs/2412.10099"}
{"created":"2025-04-18","title":"unPIC: A Geometric Multiview Prior for Image to 3D Synthesis","abstract":"We introduce a hierarchical probabilistic approach to go from a 2D image to multiview 3D: a diffusion \"prior\" predicts the unseen 3D geometry, which then conditions a diffusion \"decoder\" to generate novel views of the subject. We use a pointmap-based geometric representation to coordinate the generation of multiple target views simultaneously. We construct a predictable distribution of geometric features per target view to enable learnability across examples, and generalization to arbitrary inputs images. Our modular, geometry-driven approach to novel-view synthesis (called \"unPIC\") beats competing baselines such as CAT3D, EscherNet, Free3D, and One-2-3-45 on held-out objects from ObjaverseXL, as well as unseen real-world objects from Google Scanned Objects, Amazon Berkeley Objects, and the Digital Twin Catalog.","authors":["Rishabh Kabra","Drew A. Hudson","Sjoerd van Steenkiste","Joao Carreira","Niloy J. Mitra"],"url":"https://arxiv.org/abs/2412.10273"}
{"created":"2025-04-18","title":"RegMixMatch: Optimizing Mixup Utilization in Semi-Supervised Learning","abstract":"Consistency regularization and pseudo-labeling have significantly advanced semi-supervised learning (SSL). Prior works have effectively employed Mixup for consistency regularization in SSL. However, our findings indicate that applying Mixup for consistency regularization may degrade SSL performance by compromising the purity of artificial labels. Moreover, most pseudo-labeling based methods utilize thresholding strategy to exclude low-confidence data, aiming to mitigate confirmation bias; however, this approach limits the utility of unlabeled samples. To address these challenges, we propose RegMixMatch, a novel framework that optimizes the use of Mixup with both high- and low-confidence samples in SSL. First, we introduce semi-supervised RegMixup, which effectively addresses reduced artificial labels purity by using both mixed samples and clean samples for training. Second, we develop a class-aware Mixup technique that integrates information from the top-2 predicted classes into low-confidence samples and their artificial labels, reducing the confirmation bias associated with these samples and enhancing their effective utilization. Experimental results demonstrate that RegMixMatch achieves state-of-the-art performance across various SSL benchmarks.","authors":["Haorong Han","Jidong Yuan","Chixuan Wei","Zhongyang Yu"],"url":"https://arxiv.org/abs/2412.10741"}
{"created":"2025-04-18","title":"Predicting Change, Not States: An Alternate Framework for Neural PDE Surrogates","abstract":"Neural surrogates for partial differential equations (PDEs) have become popular due to their potential to quickly simulate physics. With a few exceptions, neural surrogates generally treat the forward evolution of time-dependent PDEs as a black box by directly predicting the next state. While this is a natural and easy framework for applying neural surrogates, it can be an over-simplified and rigid framework for predicting physics. In this work, we evaluate an alternate framework in which neural solvers predict the temporal derivative and an ODE integrator forwards the solution in time, which has little overhead and is broadly applicable across model architectures and PDEs. We find that by simply changing the training target and introducing numerical integration during inference, neural surrogates can gain accuracy and stability in finely-discretized regimes. Predicting temporal derivatives also allows models to not be constrained to a specific temporal discretization, allowing for flexible time-stepping during inference or training on higher-resolution PDE data. Lastly, we investigate why this framework can be beneficial and in what situations does it work well.","authors":["Anthony Zhou","Amir Barati Farimani"],"url":"https://arxiv.org/abs/2412.13074"}
{"created":"2025-04-18","title":"Embedding high-resolution touch across robotic hands enables adaptive human-like grasping","abstract":"Developing robotic hands that adapt to real-world dynamics remains a fundamental challenge in robotics and machine intelligence. Despite significant advances in replicating human hand kinematics and control algorithms, robotic systems still struggle to match human capabilities in dynamic environments, primarily due to inadequate tactile feedback. To bridge this gap, we present F-TAC Hand, a biomimetic hand featuring high-resolution tactile sensing (0.1mm spatial resolution) across 70% of its surface area. Through optimized hand design, we overcome traditional challenges in integrating high-resolution tactile sensors while preserving the full range of motion. The hand, powered by our generative algorithm that synthesizes human-like hand configurations, demonstrates robust grasping capabilities in dynamic real-world conditions. Extensive evaluation across 600 real-world trials demonstrates that this tactile-embodied system significantly outperforms non-tactile-informed alternatives in complex manipulation tasks (p<0.0001). These results provide empirical evidence for the critical role of rich tactile embodiment in developing advanced robotic intelligence, offering new perspectives on the relationship between physical sensing capabilities and intelligent behavior.","authors":["Zihang Zhao","Wanlin Li","Yuyang Li","Tengyu Liu","Boren Li","Meng Wang","Kai Du","Hangxin Liu","Yixin Zhu","Qining Wang","Kaspar Althoefer","Song-Chun Zhu"],"url":"https://arxiv.org/abs/2412.14482"}
{"created":"2025-04-18","title":"A Robust Prototype-Based Network with Interpretable RBF Classifier Foundations","abstract":"Prototype-based classification learning methods are known to be inherently interpretable. However, this paradigm suffers from major limitations compared to deep models, such as lower performance. This led to the development of the so-called deep Prototype-Based Networks (PBNs), also known as prototypical parts models. In this work, we analyze these models with respect to different properties, including interpretability. In particular, we focus on the Classification-by-Components (CBC) approach, which uses a probabilistic model to ensure interpretability and can be used as a shallow or deep architecture. We show that this model has several shortcomings, like creating contradicting explanations. Based on these findings, we propose an extension of CBC that solves these issues. Moreover, we prove that this extension has robustness guarantees and derive a loss that optimizes robustness. Additionally, our analysis shows that most (deep) PBNs are related to (deep) RBF classifiers, which implies that our robustness guarantees generalize to shallow RBF classifiers. The empirical evaluation demonstrates that our deep PBN yields state-of-the-art classification accuracy on different benchmarks while resolving the interpretability shortcomings of other approaches. Further, our shallow PBN variant outperforms other shallow PBNs while being inherently interpretable and exhibiting provable robustness guarantees.","authors":["Sascha Saralajew","Ashish Rana","Thomas Villmann","Ammar Shaker"],"url":"https://arxiv.org/abs/2412.15499"}
{"created":"2025-04-18","title":"Unifying Feature-Based Explanations with Functional ANOVA and Cooperative Game Theory","abstract":"Feature-based explanations, using perturbations or gradients, are a prevalent tool to understand decisions of black box machine learning models. Yet, differences between these methods still remain mostly unknown, which limits their applicability for practitioners. In this work, we introduce a unified framework for local and global feature-based explanations using two well-established concepts: functional ANOVA (fANOVA) from statistics, and the notion of value and interaction from cooperative game theory. We introduce three fANOVA decompositions that determine the influence of feature distributions, and use game-theoretic measures, such as the Shapley value and interactions, to specify the influence of higher-order interactions. Our framework combines these two dimensions to uncover similarities and differences between a wide range of explanation techniques for features and groups of features. We then empirically showcase the usefulness of our framework on synthetic and real-world datasets.","authors":["Fabian Fumagalli","Maximilian Muschalik","Eyke H\\\"ullermeier","Barbara Hammer","Julia Herbinger"],"url":"https://arxiv.org/abs/2412.17152"}
{"created":"2025-04-18","title":"De Novo Generation of Hit-like Molecules from Gene Expression Profiles via Deep Learning","abstract":"De novo generation of hit-like molecules is a challenging task in the drug discovery process. Most methods in previous studies learn the semantics and syntax of molecular structures by analyzing molecular graphs or simplified molecular input line entry system (SMILES) strings; however, they do not take into account the drug responses of the biological systems consisting of genes and proteins. In this study we propose a hybrid neural network, HNN2Mol, which utilizes gene expression profiles to generate molecular structures with desirable phenotypes for arbitrary target proteins. In the algorithm, a variational autoencoder is employed as a feature extractor to learn the latent feature distribution of the gene expression profiles. Then, a long short-term memory is leveraged as the chemical generator to produce syntactically valid SMILES strings that satisfy the feature conditions of the gene expression profile extracted by the feature extractor. Experimental results and case studies demonstrate that the proposed HNN2Mol model can produce new molecules with potential bioactivities and drug-like properties.","authors":["Chen Li","Yoshihiro Yamanishi"],"url":"https://arxiv.org/abs/2412.19422"}
{"created":"2025-04-18","title":"Online Video Understanding: OVBench and VideoChat-Online","abstract":"Multimodal Large Language Models (MLLMs) have significantly progressed in offline video understanding. However, applying these models to real-world scenarios, such as autonomous driving and human-computer interaction, presents unique challenges due to the need for real-time processing of continuous online video streams. To this end, this paper presents systematic efforts from three perspectives: evaluation benchmark, model architecture, and training strategy. First, we introduce OVBench, a comprehensive question-answering benchmark designed to evaluate models' ability to perceive, memorize, and reason within online video contexts. It features 6 core task types across three temporal contexts-past, current, and future-forming 16 subtasks from diverse datasets. Second, we propose a new Pyramid Memory Bank (PMB) that effectively retains key spatiotemporal information in video streams. Third, we proposed an offline-to-online learning paradigm, designing an interleaved dialogue format for online video data and constructing an instruction-tuning dataset tailored for online video training. This framework led to the development of VideoChat-Online, a robust and efficient model for online video understanding. Despite the lower computational cost and higher efficiency, VideoChat-Online outperforms existing state-of-the-art offline and online models across popular offline video benchmarks and OVBench, demonstrating the effectiveness of our model architecture and training strategy. % Our approach surpasses existing state-of-the-art offline models Qwen2-VL 7B and online models Flash-VStream, by 4.19% and 23.7% on OVBench, respectively.","authors":["Zhenpeng Huang","Xinhao Li","Jiaqi Li","Jing Wang","Xiangyu Zeng","Cheng Liang","Tao Wu","Xi Chen","Liang Li","Limin Wang"],"url":"https://arxiv.org/abs/2501.00584"}
{"created":"2025-04-18","title":"MADGEN: Mass-Spec attends to De Novo Molecular generation","abstract":"The annotation (assigning structural chemical identities) of MS/MS spectra remains a significant challenge due to the enormous molecular diversity in biological samples and the limited scope of reference databases. Currently, the vast majority of spectral measurements remain in the \"dark chemical space\" without structural annotations. To improve annotation, we propose MADGEN (Mass-spec Attends to De Novo Molecular GENeration), a scaffold-based method for de novo molecular structure generation guided by mass spectrometry data. MADGEN operates in two stages: scaffold retrieval and spectra-conditioned molecular generation starting with the scaffold. In the first stage, given an MS/MS spectrum, we formulate scaffold retrieval as a ranking problem and employ contrastive learning to align mass spectra with candidate molecular scaffolds. In the second stage, starting from the retrieved scaffold, we employ the MS/MS spectrum to guide an attention-based generative model to generate the final molecule. Our approach constrains the molecular generation search space, reducing its complexity and improving generation accuracy. We evaluate MADGEN on three datasets (NIST23, CANOPUS, and MassSpecGym) and evaluate MADGEN's performance with a predictive scaffold retriever and with an oracle retriever. We demonstrate the effectiveness of using attention to integrate spectral information throughout the generation process to achieve strong results with the oracle retriever.","authors":["Yinkai Wang","Xiaohui Chen","Liping Liu","Soha Hassoun"],"url":"https://arxiv.org/abs/2501.01950"}
{"created":"2025-04-18","title":"ArtCrafter: Text-Image Aligning Style Transfer via Embedding Reframing","abstract":"Recent years have witnessed significant advancements in text-guided style transfer, primarily attributed to innovations in diffusion models. These models excel in conditional guidance, utilizing text or images to direct the sampling process. However, despite their capabilities, direct conditional guidance approaches often face challenges in balancing the expressiveness of textual semantics with the diversity of output results while capturing stylistic features. To address these challenges, we introduce ArtCrafter, a novel framework for text-to-image style transfer. Specifically, we introduce an attention-based style extraction module, meticulously engineered to capture the subtle stylistic elements within an image. This module features a multi-layer architecture that leverages the capabilities of perceiver attention mechanisms to integrate fine-grained information. Additionally, we present a novel text-image aligning augmentation component that adeptly balances control over both modalities, enabling the model to efficiently map image and text embeddings into a shared feature space. We achieve this through attention operations that enable smooth information flow between modalities. Lastly, we incorporate an explicit modulation that seamlessly blends multimodal enhanced embeddings with original embeddings through an embedding reframing design, empowering the model to generate diverse outputs. Extensive experiments demonstrate that ArtCrafter yields impressive results in visual stylization, exhibiting exceptional levels of stylistic intensity, controllability, and diversity.","authors":["Nisha Huang","Kaer Huang","Yifan Pu","Jiangshan Wang","Jie Guo","Yiqiang Yan","Xiu Li","Tong-Yee Lee"],"url":"https://arxiv.org/abs/2501.02064"}
{"created":"2025-04-18","title":"Test-time Alignment of Diffusion Models without Reward Over-optimization","abstract":"Diffusion models excel in generative tasks, but aligning them with specific objectives while maintaining their versatility remains challenging. Existing fine-tuning methods often suffer from reward over-optimization, while approximate guidance approaches fail to optimize target rewards effectively. Addressing these limitations, we propose a training-free, test-time method based on Sequential Monte Carlo (SMC) to sample from the reward-aligned target distribution. Our approach, tailored for diffusion sampling and incorporating tempering techniques, achieves comparable or superior target rewards to fine-tuning methods while preserving diversity and cross-reward generalization. We demonstrate its effectiveness in single-reward optimization, multi-objective scenarios, and online black-box optimization. This work offers a robust solution for aligning diffusion models with diverse downstream objectives without compromising their general capabilities. Code is available at https://github.com/krafton-ai/DAS.","authors":["Sunwoo Kim","Minkyu Kim","Dongmin Park"],"url":"https://arxiv.org/abs/2501.05803"}
{"created":"2025-04-18","title":"CBS with Continuous-Time Revisit","abstract":"Multi-Agent Path Finding in Continuous Time (\\mapfr) extends the classical MAPF problem by allowing agents to operate in continuous time. Conflict-Based Search with Continuous Time (CCBS) is a foundational algorithm for solving \\mapfr optimally. In this paper, we revisit the theoretical claims of CCBS and show the algorithm is incomplete, due to an uncountably infinite state space created by continuous wait durations. Through theoretical analysis and counter-examples, we examine the inherent challenges of extending existing MAPF solvers to address \\mapfr while preserving optimality guarantees. By restricting waiting duration to fixed amounts, we identify a related sub-problem on graphs, \\mapfrdt which we show is optimally solvable, including by CCBS. It remains an open question whether similar models exist for \\mapfrct, a generalised version of \\mapfrdt that allows arbitrary wait times, and \\mapfrcs, which further allows arbitrary movements in continuous space.","authors":["Andy Li","Zhe Chen","Danial Harabor","Mor Vered"],"url":"https://arxiv.org/abs/2501.07744"}
{"created":"2025-04-18","title":"Multimodal Fake News Video Explanation: Dataset, Analysis and Evaluation","abstract":"Multimodal fake news videos are difficult to interpret because they require comprehensive consideration of the correlation and consistency between multiple modes. Existing methods deal with fake news videos as a classification problem, but it's not clear why news videos are identified as fake. Without proper explanation, the end user may not understand the underlying meaning of the falsehood. Therefore, we propose a new problem - Fake news video Explanation (FNVE) - given a multimodal news post containing a video and title, our goal is to generate natural language explanations to reveal the falsity of the news video. To that end, we developed FakeVE, a new dataset of 2,672 fake news video posts that can definitively explain four real-life fake news video aspects. In order to understand the characteristics of fake news video explanation, we conducted an exploratory analysis of FakeVE from different perspectives. In addition, we propose a Multimodal Relation Graph Transformer (MRGT) based on the architecture of multimodal Transformer to benchmark FakeVE. The empirical results show that the results of the various benchmarks (adopted by FakeVE) are convincing and provide a detailed analysis of the differences in explanation generation of the benchmark models.","authors":["Lizhi Chen","Zhong Qian","Peifeng Li","Qiaoming Zhu"],"url":"https://arxiv.org/abs/2501.08514"}
{"created":"2025-04-18","title":"Multimodal LLMs Can Reason about Aesthetics in Zero-Shot","abstract":"The rapid progress of generative art has democratized the creation of visually pleasing imagery. However, achieving genuine artistic impact - the kind that resonates with viewers on a deeper, more meaningful level - requires a sophisticated aesthetic sensibility. This sensibility involves a multi-faceted reasoning process extending beyond mere visual appeal, which is often overlooked by current computational models. This paper pioneers an approach to capture this complex process by investigating how the reasoning capabilities of Multimodal LLMs (MLLMs) can be effectively elicited for aesthetic judgment. Our analysis reveals a critical challenge: MLLMs exhibit a tendency towards hallucinations during aesthetic reasoning, characterized by subjective opinions and unsubstantiated artistic interpretations. We further demonstrate that these limitations can be overcome by employing an evidence-based, objective reasoning process, as substantiated by our proposed baseline, ArtCoT. MLLMs prompted by this principle produce multi-faceted and in-depth aesthetic reasoning that aligns significantly better with human judgment. These findings have direct applications in areas such as AI art tutoring and as reward models for generative art. Ultimately, our work paves the way for AI systems that can truly understand, appreciate, and generate artworks that align with the sensible human aesthetic standard.","authors":["Ruixiang Jiang","Changwen Chen"],"url":"https://arxiv.org/abs/2501.09012"}
{"created":"2025-04-18","title":"Learning from Mistakes: Understanding Ad-hoc Logs through Analyzing Accidental Commits","abstract":"Developers often insert temporary \"print\" or \"log\" instructions into their code to help them better understand runtime behavior, usually when the code is not behaving as they expected. Despite the fact that such monitoring instructions, or \"ad-hoc logs,\" are so commonly used by developers, there is almost no existing literature that studies developers' practices in how they use them. This paucity of knowledge of the use of these ephemeral logs may be largely due to the fact that they typically only exist in the developers' local environments and are removed before they commit their code to their revision control system. In this work, we overcome this challenge by observing that developers occasionally mistakenly forget to remove such instructions before committing, and then they remove them shortly later. Additionally, we further study such developer logging practices by watching and analyzing live-streamed coding videos. Through these empirical approaches, we study where, how, and why developers use ad-hoc logs to better understand their code and its execution. We collect 27 GB of accidental commits that removed 548,880 ad-hoc logs in JavaScript from GitHub Archive repositories to provide the first large-scale dataset and empirical studies on ad-hoc logging practices. Our results reveal several illuminating findings, including a particular propensity for developers to use ad-hoc logs in asynchronous and callback functions. Our findings provide both empirical evidence and a valuable dataset for researchers and tool developers seeking to enhance ad-hoc logging practices, and potentially deepen our understanding of developers' practices towards understanding of software's runtime behaviors.","authors":["Yi-Hung Chou","Yiyang Min","April Yi Wang","James A. Jones"],"url":"https://arxiv.org/abs/2501.09892"}
{"created":"2025-04-18","title":"Learning to Help in Multi-Class Settings","abstract":"Deploying complex machine learning models on resource-constrained devices is challenging due to limited computational power, memory, and model retrainability. To address these limitations, a hybrid system can be established by augmenting the local model with a server-side model, where samples are selectively deferred by a rejector and then sent to the server for processing. The hybrid system enables efficient use of computational resources while minimizing the overhead associated with server usage. The recently proposed Learning to Help (L2H) model trains a server model given a fixed local (client) model, differing from the Learning to Defer (L2D) framework, which trains the client for a fixed (expert) server. In both L2D and L2H, the training includes learning a rejector at the client to determine when to query the server. In this work, we extend the L2H model from binary to multi-class classification problems and demonstrate its applicability in a number of different scenarios of practical interest in which access to the server may be limited by cost, availability, or policy. We derive a stage-switching surrogate loss function that is differentiable, convex, and consistent with the Bayes rule corresponding to the 0-1 loss for the L2H model. Experiments show that our proposed methods offer an efficient and practical solution for multi-class classification in resource-constrained environments.","authors":["Yu Wu","Yansong Li","Zeyu Dong","Nitya Sathyavageeswaran","Anand D. Sarwate"],"url":"https://arxiv.org/abs/2501.13810"}
{"created":"2025-04-18","title":"Which Optimizer Works Best for Physics-Informed Neural Networks and Kolmogorov-Arnold Networks?","abstract":"Physics-Informed Neural Networks (PINNs) have revolutionized the computation of PDE solutions by integrating partial differential equations (PDEs) into the neural network's training process as soft constraints, becoming an important component of the scientific machine learning (SciML) ecosystem. More recently, physics-informed Kolmogorv-Arnold networks (PIKANs) have also shown to be effective and comparable in accuracy with PINNs. In their current implementation, both PINNs and PIKANs are mainly optimized using first-order methods like Adam, as well as quasi-Newton methods such as BFGS and its low-memory variant, L-BFGS. However, these optimizers often struggle with highly non-linear and non-convex loss landscapes, leading to challenges such as slow convergence, local minima entrapment, and (non)degenerate saddle points. In this study, we investigate the performance of Self-Scaled BFGS (SSBFGS), Self-Scaled Broyden (SSBroyden) methods and other advanced quasi-Newton schemes, including BFGS and L-BFGS with different line search strategies approaches. These methods dynamically rescale updates based on historical gradient information, thus enhancing training efficiency and accuracy. We systematically compare these optimizers -- using both PINNs and PIKANs -- on key challenging linear, stiff, multi-scale and non-linear PDEs, including the Burgers, Allen-Cahn, Kuramoto-Sivashinsky, and Ginzburg-Landau equations. Our findings provide state-of-the-art results with orders-of-magnitude accuracy improvements without the use of adaptive weights or any other enhancements typically employed in PINNs. More broadly, our results reveal insights into the effectiveness of second-order optimization strategies in significantly improving the convergence and accurate generalization of PINNs and PIKANs.","authors":["Elham Kiyani","Khemraj Shukla","Jorge F. Urb\\'an","J\\'er\\^ome Darbon","George Em Karniadakis"],"url":"https://arxiv.org/abs/2501.16371"}
{"created":"2025-04-18","title":"Contextual Agent Security: A Policy for Every Purpose","abstract":"Judging an action's safety requires knowledge of the context in which the action takes place. To human agents who act in various contexts, this may seem obvious: performing an action such as email deletion may or may not be appropriate depending on the email's content, the goal (e.g., to erase sensitive emails or to clean up trash), and the type of email address (e.g., work or personal). Unlike people, computational systems have often had only limited agency in limited contexts. Thus, manually crafted policies and user confirmation (e.g., smartphone app permissions or network access control lists), while imperfect, have sufficed to restrict harmful actions. However, with the upcoming deployment of generalist agents that support a multitude of tasks (e.g., an automated personal assistant), we argue that we must rethink security designs to adapt to the scale of contexts and capabilities of these systems. As a first step, this paper explores contextual security in the domain of agents and proposes contextual agent security (Conseca), a framework to generate just-in-time, contextual, and human-verifiable security policies.","authors":["Lillian Tsai","Eugene Bagdasarian"],"url":"https://arxiv.org/abs/2501.17070"}
{"created":"2025-04-18","title":"SemML: Enhancing Automata-Theoretic LTL Synthesis with Machine Learning","abstract":"Synthesizing a reactive system from specifications given in linear temporal logic (LTL) is a classical problem, finding its applications in safety-critical systems design. We present our tool SemML, which won this year's LTL realizability tracks of SYNTCOMP, after years of domination by Strix. While both tools are based on the automata-theoretic approach, ours relies heavily on (i) Semantic labelling, additional information of logical nature, coming from recent LTL-to-automata translations and decorating the resulting parity game, and (ii) Machine Learning approaches turning this information into a guidance oracle for on-the-fly exploration of the parity game (whence the name SemML). Our tool fills the missing gaps of previous suggestions to use such an oracle and provides an efficeint implementation with additional algorithmic improvements. We evaluate SemML both on the entire set of SYNTCOMP as well as a synthetic data set, compare it to Strix, and analyze the advantages and limitations. As SemML solves more instances on SYNTCOMP and does so significantly faster on larger instances, this demonstrates for the first time that machine-learning-aided approaches can out-perform state-of-the-art tools in real LTL synthesis.","authors":["Jan Kretinsky","Tobias Meggendorfer","Maximilian Prokop","Ashkan Zarkhah"],"url":"https://arxiv.org/abs/2501.17496"}
{"created":"2025-04-18","title":"Towards Training-Free Open-World Classification with 3D Generative Models","abstract":"3D open-world classification is a challenging yet essential task in dynamic and unstructured real-world scenarios, requiring both open-category and open-pose recognition. To address these challenges, recent wisdom often takes sophisticated 2D pre-trained models to provide enriched and stable representations. However, these methods largely rely on how 3D objects can be projected into 2D space, which is unfortunately not well solved, and thus significantly limits their performance. Unlike these present efforts, in this paper we make a pioneering exploration of 3D generative models for 3D open-world classification. Drawing on abundant prior knowledge from 3D generative models, we additionally craft a rotation-invariant feature extractor. This innovative synergy endows our pipeline with the advantages of being training-free, open-category, and pose-invariant, thus well suited to 3D open-world classification. Extensive experiments on benchmark datasets demonstrate the potential of generative models in 3D open-world classification, achieving state-of-the-art performance on ModelNet10 and McGill with 32.0% and 8.7% overall accuracy improvement, respectively.","authors":["Xinzhe Xia","Weiguang Zhao","Yuyao Yan","Guanyu Yang","Rui Zhang","Kaizhu Huang","Xi Yang"],"url":"https://arxiv.org/abs/2501.17547"}
{"created":"2025-04-18","title":"Semaphores Augmented with a Waiting Array","abstract":"Semaphores are a widely used and foundational synchronization and coordination construct used for shared memory multithreaded programming. They are a keystone concept, in the sense that most other synchronization constructs can be implemented in terms of semaphores, although the converse does not generally hold. Semaphores and the quality of their implementation are of consequence as they remain heavily used in the Linux kernel and are also available for application programming via the pthreads programming interface.","authors":["Dave Dice","Alex Kogan"],"url":"https://arxiv.org/abs/2501.18447"}
{"created":"2025-04-18","title":"Curriculum-based Sample Efficient Reinforcement Learning for Robust Stabilization of a Quadrotor","abstract":"This article introduces a curriculum learning approach to develop a reinforcement learning-based robust stabilizing controller for a Quadrotor that meets predefined performance criteria. The learning objective is to achieve desired positions from random initial conditions while adhering to both transient and steady-state performance specifications. This objective is challenging for conventional one-stage end-to-end reinforcement learning, due to the strong coupling between position and orientation dynamics, the complexity in designing and tuning the reward function, and poor sample efficiency, which necessitates substantial computational resources and leads to extended convergence times. To address these challenges, this work decomposes the learning objective into a three-stage curriculum that incrementally increases task complexity. The curriculum begins with learning to achieve stable hovering from a fixed initial condition, followed by progressively introducing randomization in initial positions, orientations and velocities. A novel additive reward function is proposed, to incorporate transient and steady-state performance specifications. The results demonstrate that the Proximal Policy Optimization (PPO)-based curriculum learning approach, coupled with the proposed reward structure, achieves superior performance compared to a single-stage PPO-trained policy with the same reward function, while significantly reducing computational resource requirements and convergence time. The curriculum-trained policy's performance and robustness are thoroughly validated under random initial conditions and in the presence of disturbances.","authors":["Fausto Mauricio Lagos Suarez","Akshit Saradagi","Vidya Sumathy","Shruti Kotpaliwar","George Nikolakopoulos"],"url":"https://arxiv.org/abs/2501.18490"}
{"created":"2025-04-18","title":"AI, Jobs, and the Automation Trap: Where Is HCI?","abstract":"As artificial intelligence (AI) continues to reshape the workforce, its current trajectory raises pressing questions about its ultimate purpose. Why does job automation dominate the agenda, even at the expense of human agency and equity? This paper critiques the automation-centric paradigm, arguing that current reward structures, which largely focus on cost reduction, drive the overwhelming emphasis on task replacement in AI patents. Meanwhile, Human-Centered AI (HCAI), which envisions AI as a collaborator augmenting human capabilities and aligning with societal values, remains a fugitive from the mainstream narrative. Despite its promise, HCAI has gone ``missing'', with little evidence of its principles translating into patents or real-world impact. To increase impact, actionable interventions are needed to disrupt existing incentive structures within the HCI community. We call for a shift in priorities to support translational research, foster cross-disciplinary collaboration, and promote metrics that reward tangible and real-world impact.","authors":["Marios Constantinides","Daniele Quercia"],"url":"https://arxiv.org/abs/2501.18948"}
{"created":"2025-04-18","title":"Extending the Applicability of Bloom Filters by Relaxing their Parameter Constraints","abstract":"These days, Key-Value Stores are widely used for scalable data storage. In this environment, Bloom filters serve as an efficient probabilistic data structure for the representation of sets of keys as they allow for set membership queries with controllable false positive rates and no false negatives. For optimal error rates, the right choice of the main parameters, namely the length of the Bloom filter array, the number of hash functions used to map an element to the array's indices, and the number of elements to be inserted in one filter, is crucial. However, these parameters are constrained: The number of hash functions is bounded to integer values, and the length of a Bloom filter is usually chosen to be a power-of-two to allow for efficient modulo operations using binary arithmetics. These modulo calculations are necessary to map from the output universe of the applied universal hash functions, like Murmur, to the set of indices of the Bloom filter. In this paper, we relax these constraints by proposing the Rational Bloom filter, which allows for non-integer numbers of hash functions. This results in optimized fraction-of-zero values for a known number of elements to be inserted. Based on this, we construct the Variably-Sized Block Bloom filters to allow for a flexible filter length, especially for large filters, while keeping computation efficient.","authors":["Paul Walther","Wejdene Mansour","Martin Werner"],"url":"https://arxiv.org/abs/2502.02193"}
{"created":"2025-04-18","title":"Machine learning-based hybrid dynamic modeling and economic predictive control of carbon capture process for ship decarbonization","abstract":"Implementing carbon capture technology on-board ships holds promise as a solution to facilitate the reduction of carbon intensity in international shipping, as mandated by the International Maritime Organization. In this work, we address the energy-efficient operation of shipboard carbon capture processes by proposing a hybrid modeling-based economic predictive control scheme. Specifically, we consider a comprehensive shipboard carbon capture process that encompasses the ship engine system and the shipboard post-combustion carbon capture plant. To accurately and robustly characterize the dynamic behaviors of this shipboard plant, we develop a hybrid dynamic process model that integrates available imperfect physical knowledge with neural networks trained using process operation data. An economic model predictive control approach is proposed based on the hybrid model to ensure carbon capture efficiency while minimizing energy consumption required for the carbon capture process operation. The cross-entropy method is employed to efficiently solve the complex non-convex optimization problem associated with the proposed hybrid model-based economic model predictive control method. Extensive simulations, analyses, and comparisons are conducted to verify the effectiveness and illustrate the superiority of the proposed framework.","authors":["Xuewen Zhang","Kuniadi Wandy Huang","Dat-Nguyen Vo","Minghao Han","Benjamin Decardi-Nelson","Xunyuan Yin"],"url":"https://arxiv.org/abs/2502.05833"}
{"created":"2025-04-18","title":"Principles and Framework for the Operationalisation of Meaningful Human Control over Autonomous Systems","abstract":"This paper proposes an alignment for the operationalisation of Meaningful Human Control (MHC) for autonomous systems by proposing operational principles for MHC and introducing a generic framework for its application. With a plethora of different seemingly diverging expansions for use of MHC in practice, this work aims to bring alignment and convergence use in practice. The increasing integration of autonomous systems in various domains emphasises a critical need to maintain human control to ensure responsible safety, accountability, and ethical operation of these systems. The concept of MHC offers an ideal concept for the design and evaluation of human control over autonomous systems, while considering human and technology capabilities. Through analysis of existing literature and investigation across various domains and related concepts, principles for the operationalisation of MHC are set out to provide tangible guidelines for researchers and practitioners aiming to implement MHC in their systems. The proposed framework dissects generic components of systems and their subsystems aligned with different agents, stakeholders and processes at different levels of proximity to an autonomous technology. The framework is domain-agnostic, emphasizing the universal applicability of the MHC principles irrespective of the technological context, paving the way for safer and more responsible autonomous systems.","authors":["Simeon C. Calvert"],"url":"https://arxiv.org/abs/2502.08255"}
{"created":"2025-04-18","title":"Registration, Detection, and Deregistration: Analyzing DNS Abuse for Phishing Attacks","abstract":"Phishing continues to pose a significant cybersecurity threat. While blocklists currently serve as a primary defense, due to their reactive, passive nature, these delayed responses leave phishing websites operational long enough to harm potential victims. It is essential to address this fundamental challenge at the root, particularly in phishing domains. Domain registration presents a crucial intervention point, as domains serve as the primary gateway between users and websites. We conduct a comprehensive longitudinal analysis of 690,502 unique phishing domains, spanning a 39 month period, to examine their characteristics and behavioral patterns throughout their lifecycle-from initial registration to detection and eventual deregistration. We find that 66.1% of the domains in our dataset are maliciously registered, leveraging cost-effective TLDs and targeting brands by mimicking their domain names under alternative TLDs (e.g., .top and .tk) instead of the TLDs under which the brand domains are registered (e.g., .com and .ru). We also observe minimal improvements in detection speed for maliciously registered domains compared to compromised domains. Detection times vary widely across blocklists, and phishing domains remain accessible for an average of 11.5 days after detection, prolonging their potential impact. Our systematic investigation uncovers key patterns from registration through detection to deregistration, which could be leveraged to enhance anti-phishing active defenses at the DNS level.","authors":["Kyungchan Lim","Raffaele Sommese","Mattis Jonker","Ricky Mok","kc claffy","Doowon Kim"],"url":"https://arxiv.org/abs/2502.09549"}
{"created":"2025-04-18","title":"A Self-Supervised Reinforcement Learning Approach for Fine-Tuning Large Language Models Using Cross-Attention Signals","abstract":"We propose a novel reinforcement learning framework for post training large language models that does not rely on human in the loop feedback. Instead, our approach uses cross attention signals within the model itself to derive a self supervised reward, thereby guiding iterative fine tuning of the model policy. By analyzing how the model attends to the input prompt during generation, we construct measures of prompt coverage, focus, and coherence. We then use these measures to rank or score candidate responses, providing a reward signal that encourages the model to produce well aligned, on topic text. In empirical comparisons against standard policy gradient methods and RL fine tuning with synthetic preference models, our method shows significant gains in prompt relevance and consistency over a non RL baseline. While it does not yet match the performance of fully human supervised RLHF systems, it highlights an important direction for scaling alignment with minimal human labeling. We provide a detailed analysis, discuss potential limitations, and outline future work for combining cross-attention based signals with smaller amounts of human feedback.","authors":["Andrew Kiruluta","Andreas Lemos","Priscilla Burity"],"url":"https://arxiv.org/abs/2502.10482"}
{"created":"2025-04-18","title":"RealSyn: An Effective and Scalable Multimodal Interleaved Document Transformation Paradigm","abstract":"After pre-training on extensive image-text pairs, Contrastive Language-Image Pre-training (CLIP) demonstrates promising performance on a wide variety of benchmarks. However, a substantial volume of multimodal interleaved documents remains underutilized for contrastive vision-language representation learning. To fully leverage these unpaired documents, we initially establish a Real-World Data Extraction pipeline to extract high-quality images and texts. Then we design a hierarchical retrieval method to efficiently associate each image with multiple semantically relevant realistic texts. To further enhance fine-grained visual information, we propose an image semantic augmented generation module for synthetic text production. Furthermore, we employ a semantic balance sampling strategy to improve dataset diversity, enabling better learning of long-tail concepts. Based on these innovations, we construct RealSyn, a dataset combining realistic and synthetic texts, available in three scales: 15M, 30M, and 100M. We compare our dataset with other widely used datasets of equivalent scale for CLIP training. Models pre-trained on RealSyn consistently achieve state-of-the-art performance across various downstream tasks, including linear probe, zero-shot transfer, zero-shot robustness, and zero-shot retrieval. Furthermore, extensive experiments confirm that RealSyn significantly enhances contrastive vision-language representation learning and demonstrates robust scalability. To facilitate future research, the RealSyn dataset and pretrained model weights are released at https://github.com/deepglint/RealSyn.","authors":["Tiancheng Gu","Kaicheng Yang","Chaoyi Zhang","Yin Xie","Xiang An","Ziyong Feng","Dongnan Liu","Weidong Cai","Jiankang Deng"],"url":"https://arxiv.org/abs/2502.12513"}
{"created":"2025-04-18","title":"AI and the Transformation of Accountability and Discretion in Urban Governance","abstract":"This paper offers a conceptual analysis of the transformative role of Artificial Intelligence (AI) in urban governance, focusing on how AI reshapes governance approaches, oversight mechanisms, and the relationship between bureaucratic discretion and accountability. Drawing on public administration theory, tech-driven governance practices, and data ethics, the study synthesizes insights to propose guiding principles for responsible AI integration in decision-making processes. While primarily conceptual, the paper draws on illustrative empirical cases to demonstrate how AI is reshaping discretion and accountability in real-world settings. The analysis argues that AI does not simply restrict or enhance discretion but redistributes it across institutional levels. It may simultaneously strengthen managerial oversight, enhance decision-making consistency, and improve operational efficiency. These changes affect different forms of accountability: political, professional, and participatory, while introducing new risks, such as data bias, algorithmic opacity, and fragmented responsibility across actors. In response, the paper proposes guiding principles: equitable AI access, adaptive administrative structures, robust data governance, and proactive human-led decision-making, citizen-engaged oversight. This study contributes to the AI governance literature by moving beyond narrow concerns with perceived discretion at the street level, highlighting instead how AI transforms rule-based discretion across governance systems. By bridging perspectives on efficiency and ethical risk, the paper presents a comprehensive framework for understanding the evolving relationship between discretion and accountability in AI-assisted governance.","authors":["Stephen Goldsmith (Tony)","Juncheng Yang (Tony)"],"url":"https://arxiv.org/abs/2502.13101"}
{"created":"2025-04-18","title":"Geolocation with Real Human Gameplay Data: A Large-Scale Dataset and Human-Like Reasoning Framework","abstract":"Geolocation, the task of identifying an image's location, requires complex reasoning and is crucial for navigation, monitoring, and cultural preservation. However, current methods often produce coarse, imprecise, and non-interpretable localization. A major challenge lies in the quality and scale of existing geolocation datasets. These datasets are typically small-scale and automatically constructed, leading to noisy data and inconsistent task difficulty, with images that either reveal answers too easily or lack sufficient clues for reliable inference. To address these challenges, we introduce a comprehensive geolocation framework with three key components: GeoComp, a large-scale dataset; GeoCoT, a novel reasoning method; and GeoEval, an evaluation metric, collectively designed to address critical challenges and drive advancements in geolocation research. At the core of this framework is GeoComp (Geolocation Competition Dataset), a large-scale dataset collected from a geolocation game platform involving 740K users over two years. It comprises 25 million entries of metadata and 3 million geo-tagged locations spanning much of the globe, with each location annotated thousands to tens of thousands of times by human users. The dataset offers diverse difficulty levels for detailed analysis and highlights key gaps in current models. Building on this dataset, we propose Geographical Chain-of-Thought (GeoCoT), a novel multi-step reasoning framework designed to enhance the reasoning capabilities of Large Vision Models (LVMs) in geolocation tasks. GeoCoT improves performance by integrating contextual and spatial cues through a multi-step process that mimics human geolocation reasoning. Finally, using the GeoEval metric, we demonstrate that GeoCoT significantly boosts geolocation accuracy by up to 25% while enhancing interpretability.","authors":["Zirui Song","Jingpu Yang","Yuan Huang","Jonathan Tonglet","Zeyu Zhang","Tao Cheng","Meng Fang","Iryna Gurevych","Xiuying Chen"],"url":"https://arxiv.org/abs/2502.13759"}
{"created":"2025-04-18","title":"CoDiff: Conditional Diffusion Model for Collaborative 3D Object Detection","abstract":"Collaborative 3D object detection holds significant importance in the field of autonomous driving, as it greatly enhances the perception capabilities of each individual agent by facilitating information exchange among multiple agents. However, in practice, due to pose estimation errors and time delays, the fusion of information across agents often results in feature representations with spatial and temporal noise, leading to detection errors. Diffusion models naturally have the ability to denoise noisy samples to the ideal data, which motivates us to explore the use of diffusion models to address the noise problem between multi-agent systems. In this work, we propose CoDiff, a novel robust collaborative perception framework that leverages the potential of diffusion models to generate more comprehensive and clearer feature representations. To the best of our knowledge, this is the first work to apply diffusion models to multi-agent collaborative perception. Specifically, we project high-dimensional feature map into the latent space of a powerful pre-trained autoencoder. Within this space, individual agent information serves as a condition to guide the diffusion model's sampling. This process denoises coarse feature maps and progressively refines the fused features. Experimental study on both simulated and real-world datasets demonstrates that the proposed framework CoDiff consistently outperforms existing relevant methods in terms of the collaborative object detection performance, and exhibits highly desired robustness when the pose and delay information of agents is with high-level noise. The code is released at https://github.com/HuangZhe885/CoDiff","authors":["Zhe Huang","Shuo Wang","Yongcai Wang","Lei Wang"],"url":"https://arxiv.org/abs/2502.14891"}
{"created":"2025-04-18","title":"EDA-Q: Electronic Design Automation for Superconducting Quantum Chip","abstract":"Electronic Design Automation (EDA) plays a crucial role in classical chip design and significantly influences the development of quantum chip design. However, traditional EDA tools cannot be directly applied to quantum chip design due to vast differences compared to the classical realm. Several EDA products tailored for quantum chip design currently exist, yet they only cover partial stages of the quantum chip design process instead of offering a fully comprehensive solution. Additionally, they often encounter issues such as limited automation, steep learning curves, challenges in integrating with actual fabrication processes, and difficulties in expanding functionality. To address these issues, we developed a full-stack EDA tool specifically for quantum chip design, called EDA-Q. The design workflow incorporates functionalities present in existing quantum EDA tools while supplementing critical design stages such as device mapping and fabrication process mapping, which users expect. EDA-Q utilizes a unique architecture to achieve exceptional scalability and flexibility. The integrated design mode guarantees algorithm compatibility with different chip components, while employing a specialized interactive processing mode to offer users a straightforward and adaptable command interface. Application examples demonstrate that EDA-Q significantly reduces chip design cycles, enhances automation levels, and decreases the time required for manual intervention. Multiple rounds of testing on the designed chip have validated the effectiveness of EDA-Q in practical applications.","authors":["Bo Zhao","Zhihang Li","Xiaohan Yu","Benzheng Yuan","Chaojie Zhang","Yimin Gao","Weilong Wang","Qing Mu","Shuya Wang","Huihui Sun","Tian Yang","Mengfan Zhang","Chuanbing Han","Peng Xu","Wenqing Wang","Zheng Shan"],"url":"https://arxiv.org/abs/2502.15386"}
{"created":"2025-04-18","title":"Beyond Tools: Understanding How Heavy Users Integrate LLMs into Everyday Tasks and Decision-Making","abstract":"Large language models (LLMs) are increasingly used for both everyday and specialized tasks. While HCI research focuses on domain-specific applications, little is known about how heavy users integrate LLMs into everyday decision-making. Through qualitative interviews with heavy LLM users (n=7) who employ these systems for both intuitive and analytical thinking tasks, our findings show that participants use LLMs for social validation, self-regulation, and interpersonal guidance, seeking to build self-confidence and optimize cognitive resources. These users viewed LLMs either as rational, consistent entities or average human decision-makers. Our findings suggest that heavy LLM users develop nuanced interaction patterns beyond simple delegation, highlighting the need to reconsider how we study LLM integration in decision-making processes.","authors":["Eunhye Kim","Kiroong Choe","Minju Yoo","Sadat Shams Chowdhury","Jinwook Seo"],"url":"https://arxiv.org/abs/2502.15395"}
{"created":"2025-04-18","title":"A general language model for peptide identification","abstract":"Advances in peptide identification are revolutionizing our ability to decipher protein functions and accelerate therapeutic discovery. We present PDeepPP, a deep learning framework that integrates pretrained protein language models with parallel transformer-CNN architectures, achieving state-of-the-art performance in peptide characterization tasks. The model's hybrid architecture demonstrates unique capabilities in capturing both local sequence motifs and global structural features, as evidenced by 29% improved cluster separation in UMAP visualizations compared to conventional approaches. Evaluated across 33 biological recognition tasks - including post-translational modification site prediction and bioactive peptide identification - PDeepPP outperformed existing methods in 25 tasks with average AUC improvements of 4.2%. Notably, it achieved 0.9726 accuracy with PR AUC 0.9977 in antimicrobial peptide detection while reducing false negatives by 37.5% in antimalarial recognition scenarios. This framework enables accurate large-scale peptide analysis, achieving 218* acceleration over sequence-alignment-based methods while maintaining 99.5% specificity in critical glycosylation site detection.PDeepPP establishes a new paradigm for computational peptide analysis through its synergistic architecture design, enabling rapid yet precise functional annotation that bridges molecular pattern recognition with translational biomedical applications.We have made our implementation, including code, data, and pretrained models, publicly available via GitHub (https://github.com/fondress/PDeepPP) and Hugging Face (https://huggingface.co/fondress/PDeppPP).","authors":["Jixiu Zhai","Tianchi Lu","Haitian Zhong","Ziyang Xu","Yuhuan Liu","Shengrui Xu","Jingwan Wang","Dan Huang"],"url":"https://arxiv.org/abs/2502.15610"}
{"created":"2025-04-18","title":"FLAP: Fully-controllable Audio-driven Portrait Video Generation through 3D head conditioned diffusion model","abstract":"Diffusion-based video generation techniques have significantly improved zero-shot talking-head avatar generation, enhancing the naturalness of both head motion and facial expressions. However, existing methods suffer from poor controllability, making them less applicable to real-world scenarios such as filmmaking and live streaming for e-commerce. To address this limitation, we propose FLAP, a novel approach that integrates explicit 3D intermediate parameters (head poses and facial expressions) into the diffusion model for end-to-end generation of realistic portrait videos. The proposed architecture allows the model to generate vivid portrait videos from audio while simultaneously incorporating additional control signals, such as head rotation angles and eye-blinking frequency. Furthermore, the decoupling of head pose and facial expression allows for independent control of each, offering precise manipulation of both the avatar's pose and facial expressions. We also demonstrate its flexibility in integrating with existing 3D head generation methods, bridging the gap between 3D model-based approaches and end-to-end diffusion techniques. Extensive experiments show that our method outperforms recent audio-driven portrait video models in both naturalness and controllability.","authors":["Lingzhou Mu","Baiji Liu"],"url":"https://arxiv.org/abs/2502.19455"}
{"created":"2025-04-18","title":"Large Language Models as Attribution Regularizers for Efficient Model Training","abstract":"Large Language Models (LLMs) have demonstrated remarkable performance across diverse domains. However, effectively leveraging their vast knowledge for training smaller downstream models remains an open challenge, especially in domains like tabular data learning, where simpler models are often preferred due to interpretability and efficiency.","authors":["Davor Vukadin","Marin \\v{S}ili\\'c","Goran Dela\\v{c}"],"url":"https://arxiv.org/abs/2502.20268"}
{"created":"2025-04-18","title":"Arabizi vs LLMs: Can the Genie Understand the Language of Aladdin?","abstract":"In this era of rapid technological advancements, communication continues to evolve as new linguistic phenomena emerge. Among these is Arabizi, a hybrid form of Arabic that incorporates Latin characters and numbers to represent the spoken dialects of Arab communities. Arabizi is widely used on social media and allows people to communicate in an informal and dynamic way, but it poses significant challenges for machine translation due to its lack of formal structure and deeply embedded cultural nuances. This case study arises from a growing need to translate Arabizi for gisting purposes. It evaluates the capacity of different LLMs to decode and translate Arabizi, focusing on multiple Arabic dialects that have rarely been studied up until now. Using a combination of human evaluators and automatic metrics, this research project investigates the model's performance in translating Arabizi into both Modern Standard Arabic and English. Key questions explored include which dialects are translated most effectively and whether translations into English surpass those into Arabic.","authors":["Perla Al Almaoui","Pierrette Bouillon","Simon Hengchen"],"url":"https://arxiv.org/abs/2502.20973"}
{"created":"2025-04-18","title":"A Demo of Radar Sensing Aided Rotatable Antenna for Wireless Communication System","abstract":"Rotatable antenna (RA) represents a novel antenna architecture that enhances wireless communication system performance by independently or collectively adjusting each antenna's boresight/orientation. In this demonstration, we develop a prototype of radar sensing-aided rotatable antenna that integrates radar sensing with dynamic antenna orientation to enhance wireless communication performance while maintaining low hardware costs. The proposed prototype consists of a transmitter (TX) module and a receiver (RX) module, both of which employ universal software radio peripherals (USRPs) for transmitting and receiving signals. Specifically, the TX utilizes a laser radar to detect the RX's location and conveys the angle of arrival (AoA) information to its antenna servo, which enables the RA to align its boresight direction with the identified RX. Experimental results examine the effectiveness of the proposed prototype and indicate that the RA significantly outperforms the traditional fixed-antenna system in terms of increasing received signal-to-noise ratio (SNR).","authors":["Qi Dai","Beixiong Zheng","Qiyao Wang","Xue Xiong","Xiaodan Shao","Lipeng Zhu","Rui Zhang"],"url":"https://arxiv.org/abs/2502.21036"}
{"created":"2025-04-18","title":"Elastic Restaking Networks","abstract":"Many blockchain-based decentralized services require their validators (operators) to deposit stake (collateral), which is forfeited (slashed) if they misbehave. Restaking networks let validators secure multiple services by reusing stake. These networks have quickly gained traction, leveraging over~\\$20 billion in stake. However, restaking introduces a new attack vector where validators can coordinate to misbehave across multiple services simultaneously, extracting digital assets while forfeiting their stake only once.","authors":["Roi Bar-Zur","Ittay Eyal"],"url":"https://arxiv.org/abs/2503.00170"}
{"created":"2025-04-18","title":"Transferable Foundation Models for Geometric Tasks on Point Cloud Representations: Geometric Neural Operators","abstract":"We introduce methods for obtaining pretrained Geometric Neural Operators (GNPs) that can serve as basal foundation models for use in obtaining geometric features. These can be used within data processing pipelines for machine learning tasks and numerical methods. We show how our GNPs can be trained to learn robust latent representations for the differential geometry of point-clouds to provide estimates of metric, curvature, and other shape-related features. We demonstrate how our pre-trained GNPs can be used (i) to estimate the geometric properties of surfaces of arbitrary shape and topologies with robustness in the presence of noise, (ii) to approximate solutions of geometric partial differential equations (PDEs) on manifolds, and (iii) to solve equations for shape deformations such as curvature driven flows. We release codes and weights for using GNPs in the package geo_neural_op. This allows for incorporating our pre-trained GNPs as components for reuse within existing and new data processing pipelines. The GNPs also can be used as part of numerical solvers involving geometry or as part of methods for performing inference and other geometric tasks.","authors":["Blaine Quackenbush","Paul J. Atzberger"],"url":"https://arxiv.org/abs/2503.04649"}
{"created":"2025-04-18","title":"Efficient Adaptive Bandwidth Allocation for Deadline-Aware Online Admission Control in Time-Sensitive Networking","abstract":"With the growing demand for dynamic real-time applications, online admission control for time-critical event-triggered (ET) traffic in Time-Sensitive Networking (TSN) has become a critical challenge. The main issue lies in dynamically allocating bandwidth with real-time guarantees in response to traffic changes while also meeting the requirements for rapid response, scalability, and high resource utilization in online scenarios. To address this challenge, we propose an online admission control method for ET traffic based on the TSN/ATS+CBS (asynchronous traffic shaper and credit-based shaper) architecture. This method provides a flexible framework for real-time guaranteed online admission control, supporting dynamic bandwidth allocation and reclamation at runtime without requiring global reconfiguration, thus improving scalability. Within this framework, we further integrate a novel strategy based on network calculus (NC) theory for efficient and high-utilization bandwidth reallocation. On the one hand, the strategy focuses on adaptively balancing residual bandwidth with deadline awareness to prevent bottleneck egress ports, thereby improving admission capacity. On the other hand, it employs a non-trivial analytical result to reduce the search space, accelerating the solving process. Experimental results from both large-scale synthetic and realistic test cases show that, compared to the state-of-the-art, our method achieves an average 56% increase in admitted flows and an average 92% reduction in admission time. Additionally, it postpones the occurrence of bottleneck egress ports and the first rejection of admission requests, thereby enhancing adaptability.","authors":["Sifan Yu","Feng He","Anlan Xie","Luxi Zhao"],"url":"https://arxiv.org/abs/2503.09093"}
{"created":"2025-04-18","title":"DeepSeek-Inspired Exploration of RL-based LLMs and Synergy with Wireless Networks: A Survey","abstract":"Reinforcement learning (RL)-based large language models (LLMs), such as ChatGPT, DeepSeek, and Grok-3, have gained significant attention for their exceptional capabilities in natural language processing and multimodal data understanding. Meanwhile, the rapid expansion of information services has driven the growing need for intelligence, efficient, and adaptable wireless networks. Wireless networks require the empowerment of RL-based LLMs while these models also benefit from wireless networks to broaden their application scenarios. Specifically, RL-based LLMs can enhance wireless communication systems through intelligent resource allocation, adaptive network optimization, and real-time decision-making. Conversely, wireless networks provide a vital infrastructure for the efficient training, deployment, and distributed inference of RL-based LLMs, especially in decentralized and edge computing environments. This mutual empowerment highlights the need for a deeper exploration of the interplay between these two domains. We first review recent advancements in wireless communications, highlighting the associated challenges and potential solutions. We then discuss the progress of RL-based LLMs, focusing on key technologies for LLM training, challenges, and potential solutions. Subsequently, we explore the mutual empowerment between these two fields, highlighting key motivations, open challenges, and potential solutions. Finally, we provide insights into future directions, applications, and their societal impact to further explore this intersection, paving the way for next-generation intelligent communication systems. Overall, this survey provides a comprehensive overview of the relationship between RL-based LLMs and wireless networks, offering a vision where these domains empower each other to drive innovations.","authors":["Yu Qiao","Phuong-Nam Tran","Ji Su Yoon","Loc X. Nguyen","Eui-Nam Huh","Dusit Niyato","Choong Seon Hong"],"url":"https://arxiv.org/abs/2503.09956"}
{"created":"2025-04-18","title":"Demoting Security via Exploitation of Cache Demote Operation in Intel's Latest ISA Extension","abstract":"ISA extensions are increasingly adopted to boost the performance of specialized workloads without requiring an entire architectural redesign. However, these enhancements can inadvertently expose new attack surfaces in the microarchitecture. In this paper, we investigate Intel's recently introduced cldemote extension, which promotes efficient data sharing by transferring cache lines from upper-level caches to the Last Level Cache (LLC). Despite its performance benefits, we uncover critical properties-unprivileged access, inter-cache state transition, and fault suppression-that render cldemote exploitable for microarchitectural attacks. We propose two new attack primitives, Flush+Demote and Demote+Time, built on our analysis. Flush+Demote constructs a covert channel with a bandwidth of 2.84 Mbps and a bit error rate of 0.018%, while Demote+Time derandomizes the kernel base address in 2.49 ms on Linux. Furthermore, we show that leveraging cldemote accelerates eviction set construction in non-inclusive LLC designs by obviating the need for helper threads or extensive cache conflicts, thereby reducing construction time by 36% yet retaining comparable success rates. Finally, we examine how ISA extensions contribute to broader microarchitectural attacks, identifying five key exploitable characteristics and categorizing four distinct attack types. We also discuss potential countermeasures, highlighting the far-reaching security implications of emerging ISA extensions.","authors":["Taehun Kim","Hyerean Jang","Youngjoo Shin"],"url":"https://arxiv.org/abs/2503.10074"}
{"created":"2025-04-18","title":"ZeroSumEval: An Extensible Framework For Scaling LLM Evaluation with Inter-Model Competition","abstract":"We introduce ZeroSumEval, a dynamic, competition-based, and evolving evaluation framework for Large Language Models (LLMs) that leverages competitive games. ZeroSumEval encompasses a diverse suite of games, including security challenges (Capture the Flag), classic board games (chess), and knowledge tests (MathQuiz). These games are designed to evaluate a range of capabilities such as strategic reasoning, planning, knowledge application, safety, and adaptability. Building upon recent studies that highlight the effectiveness of game-based evaluations for LLMs, ZeroSumEval enhances these approaches by providing a standardized and extensible framework for easily implementing games and leverages DSPy to provide a better abstraction for LLM player strategies.","authors":["Hisham A. Alyahya","Haidar Khan","Yazeed Alnumay","M Saiful Bari","B\\\"ulent Yener"],"url":"https://arxiv.org/abs/2503.10673"}
{"created":"2025-04-18","title":"High-entropy Advantage in Neural Networks' Generalizability","abstract":"One of the central challenges in modern machine learning is understanding how neural networks generalize knowledge learned from training data to unseen test data. While numerous empirical techniques have been proposed to improve generalization, a theoretical understanding of the mechanism of generalization remains elusive. Here we introduce the concept of Boltzmann entropy into neural networks by re-conceptualizing such networks as hypothetical molecular systems where weights and biases are atomic coordinates, and the loss function is the potential energy. By employing molecular simulation algorithms, we compute entropy landscapes as functions of both training loss and test accuracy (or test loss), on networks with up to 1 million parameters, across four distinct machine learning tasks: arithmetic question, real-world tabular data, image recognition, and language modeling. Our results reveal the existence of high-entropy advantage, wherein high-entropy network states generally outperform those reached via conventional training techniques like stochastic gradient descent. This entropy advantage provides a thermodynamic explanation for neural network generalizability: the generalizable states occupy a larger part of the parameter space than its non-generalizable analog at low train loss. Furthermore, we find this advantage more pronounced in narrower neural networks, indicating a need for different training optimizers tailored to different sizes of networks.","authors":["Entao Yang","Xiaotian Zhang","Yue Shang","Ge Zhang"],"url":"https://arxiv.org/abs/2503.13145"}
{"created":"2025-04-18","title":"Employing Continuous Integration inspired workflows for benchmarking of scientific software -- a use case on numerical cut cell quadrature","abstract":"Scientific software often offers numerous (open or closed-source) alternatives for a given problem. A user needs to make an informed choice by selecting the best option based on specific metrics. However, setting up benchmarks ad-hoc can become overwhelming as the parameter space expands rapidly. Very often, the design of the benchmark is also not fully set at the start of some project. For instance, adding new libraries, adapting metrics, or introducing new benchmark cases during the project can significantly increase complexity and necessitate laborious re-evaluation of previous results. This paper presents a proven approach that utilizes established Continuous Integration tools and practices to achieve high automation of benchmark execution and reporting. Our use case is the numerical integration (quadrature) on arbitrary domains, which are bounded by implicitly or parametrically defined curves or surfaces in 2D or 3D.","authors":["Teoman Toprak","Michael Loibl","Guilherme Teixeira","Irina Shiskina","Chen Miao","Josef Kiendl","Benjamin Marussig","Florian Kummer"],"url":"https://arxiv.org/abs/2503.17192"}
{"created":"2025-04-18","title":"Feature Calibration enhanced Parameter Synthesis for CLIP-based Class-incremental Learning","abstract":"Class-Incremental Learning (CIL) enables models to continuously learn new class knowledge while retaining previous classes, facilitating adaptation and evolution in dynamic, real-world environments. Traditional CIL methods primarily rely on visual features, which limits their effectiveness in complex, multimodal scenarios. In contrast, VLMs show promising potential for enhancing CIL by leveraging pre-trained knowledge and integrating multi-modal semantic cues such as text and vision. However, existing approaches struggle to mitigate catastrophic forgetting while preserving the generalization strengths of VLMs across diverse modalities. To address these challenges, we propose a Feature Calibration Enhanced Parameter Synthesis (FCPS) framework. Specifically, FCPS introduces a dynamic parameter adjustment mechanism that iteratively calibrates the contribution of original visual features to the final class decision, thus preserving the model's intrinsic generalization capability across modalities. Simultaneously, parameter integration enables effective knowledge transfer, maintaining a balance between acquiring new class representations and preserving old knowledge. Experimental results on popular benchmarks (e.g., CIFAR100 and ImageNet100) validate the superiority of the proposed method.","authors":["Juncen Guo","Yang Liu","Xiaoguang Zhu","Lianlong Sun","Liangyu Teng","Jingyi Wu","Di Li","Wei Zhou","Liang Song"],"url":"https://arxiv.org/abs/2503.18672"}
{"created":"2025-04-18","title":"Least Squares with Equality constraints Extreme Learning Machines for the resolution of PDEs","abstract":"In this paper, we investigate the use of single hidden-layer neural networks as a family of ansatz functions for the resolution of partial differential equations (PDEs). In particular, we train the network via Extreme Learning Machines (ELMs) on the residual of the equation collocated on -- eventually randomly chosen -- points. Because the approximation is done directly in the formulation, such a method falls into the framework of Physically Informed Neural Networks (PINNs) and has been named PIELM. Since its first introduction, the method has been refined variously, and one successful variant is the Extreme Theory of Functional Connections (XTFC). However, XTFC strongly takes advantage of the description of the domain as a tensor product. Our aim is to extend XTFC to domains with general shapes. The novelty of the procedure proposed in the present paper is related to the treatment of boundary conditions via constrained imposition, so that our method is named Least Squares with Equality constraints ELM (LSEELM). An in-depth analysis and comparison with the cited methods is performed, again with the analysis of the convergence of the method in various scenarios. We show the efficiency of the procedure both in terms of computational cost and in terms of overall accuracy.","authors":["Davide Elia De Falco","Enrico Schiassi","Francesco Calabr\\`o"],"url":"https://arxiv.org/abs/2503.19185"}
{"created":"2025-04-18","title":"Long-Context Autoregressive Video Modeling with Next-Frame Prediction","abstract":"Long-context autoregressive modeling has significantly advanced language generation, but video generation still struggles to fully utilize extended temporal contexts. To investigate long-context video modeling, we introduce Frame AutoRegressive (FAR), a strong baseline for video autoregressive modeling. Just as language models learn causal dependencies between tokens (i.e., Token AR), FAR models temporal causal dependencies between continuous frames, achieving better convergence than Token AR and video diffusion transformers. Building on FAR, we observe that long-context video modeling faces challenges due to visual redundancy. Training on long videos is computationally expensive, as vision tokens grow much faster than language tokens. To tackle this issue, we propose balancing locality and long-range dependency through long short-term context modeling. A high-resolution short-term context window ensures fine-grained temporal consistency, while an unlimited long-term context window encodes long-range information using fewer tokens. With this approach, we can train on long video sequences with a manageable token context length, thereby significantly reducing training time and memory usage. Furthermore, we propose a multi-level KV cache designed to support the long short-term context modeling, which accelerating inference on long video sequences. We demonstrate that FAR achieves state-of-the-art performance in both short- and long-video generation, providing a simple yet effective baseline for video autoregressive modeling. The code is released at https://github.com/showlab/FAR.","authors":["Yuchao Gu","Weijia Mao","Mike Zheng Shou"],"url":"https://arxiv.org/abs/2503.19325"}
{"created":"2025-04-18","title":"Unlocking LLM Repair Capabilities in Low-Resource Programming Languages Through Cross-Language Translation and Multi-Agent Refinement","abstract":"Recent advances in leveraging LLMs for APR have demonstrated impressive capabilities in fixing software defects. However, current LLM-based approaches predominantly focus on mainstream programming languages like Java and Python, neglecting less prevalent but emerging languages such as Rust due to expensive training resources, limited datasets, and insufficient community support. This narrow focus creates a significant gap in repair capabilities across the programming language spectrum, where the full potential of LLMs for comprehensive multilingual program repair remains largely unexplored. To address this limitation, we introduce a novel cross-language program repair approach LANTERN that leverages LLMs' differential proficiency across languages through a multi-agent iterative repair paradigm. Our technique strategically translates defective code from languages where LLMs exhibit weaker repair capabilities to languages where they demonstrate stronger performance, without requiring additional training. A key innovation of our approach is an LLM-based decision-making system that dynamically selects optimal target languages based on bug characteristics and continuously incorporates feedback from previous repair attempts. We evaluate our method on xCodeEval, a comprehensive multilingual benchmark comprising 5,068 bugs across 11 programming languages. Results demonstrate significant enhancement in repair effectiveness, particularly for underrepresented languages, with Rust showing a 22.09% improvement in Pass@10 metrics. Our research provides the first empirical evidence that cross-language translation significantly expands the repair capabilities of LLMs and effectively bridges the performance gap between programming languages with different levels of popularity, opening new avenues for truly language-agnostic automated program repair.","authors":["Wenqiang Luo","Jacky Wai Keung","Boyang Yang","Jacques Klein","Tegawende F. Bissyande","Haoye Tian","Bach Le"],"url":"https://arxiv.org/abs/2503.22512"}
{"created":"2025-04-18","title":"A Centralized Planning and Distributed Execution Method for Shape Filling with Homogeneous Mobile Robots","abstract":"The pattern formation task is commonly seen in a multi-robot system. In this paper, we study the problem of forming complex shapes with functionally limited mobile robots, which have to rely on other robots to precisely locate themselves. The goal is to decide whether a given shape can be filled by a given set of robots; in case the answer is yes, to complete a shape formation process as fast as possible with a minimum amount of communication. Traditional approaches either require global coordinates for each robot or are prone to failure when attempting to form complex shapes beyond the capability of given approaches - the latter calls for a decision procedure that can tell whether a target shape can be formed before the actual shape-forming process starts. In this paper, we develop a method that does not require global coordinate information during the execution process and can effectively decide whether it is feasible to form the desired shape. The latter is achieved via a planning procedure that is capable of handling a variety of complex shapes, in particular, those with holes, and assigning a simple piece of scheduling information to each robot, facilitating subsequent distributed execution, which does not rely on the coordinates of all robots but only those of neighboring ones. The effectiveness of our shape-forming approach is vividly illustrated in several simulation case studies.","authors":["Shuqing Liu","Rong Su","Karl H. Johansson"],"url":"https://arxiv.org/abs/2503.22522"}
{"created":"2025-04-18","title":"StrokeFusion: Vector Sketch Generation via Joint Stroke-UDF Encoding and Latent Sequence Diffusion","abstract":"In the field of sketch generation, raster-format trained models often produce non-stroke artifacts, while vector-format trained models typically lack a holistic understanding of sketches, leading to compromised recognizability. Moreover, existing methods struggle to extract common features from similar elements (e.g., eyes of animals) appearing at varying positions across sketches. To address these challenges, we propose StrokeFusion, a two-stage framework for vector sketch generation. It contains a dual-modal sketch feature learning network that maps strokes into a high-quality latent space. This network decomposes sketches into normalized strokes and jointly encodes stroke sequences with Unsigned Distance Function (UDF) maps, representing sketches as sets of stroke feature vectors. Building upon this representation, our framework exploits a stroke-level latent diffusion model that simultaneously adjusts stroke position, scale, and trajectory during generation. This enables high-fidelity sketch generation while supporting stroke interpolation editing. Extensive experiments on the QuickDraw dataset demonstrate that our framework outperforms state-of-the-art techniques, validating its effectiveness in preserving structural integrity and semantic features. Code and models will be made publicly available upon publication.","authors":["Jin Zhou","Yi Zhou","Pengfei Xu","Hui Huang"],"url":"https://arxiv.org/abs/2503.23752"}
{"created":"2025-04-18","title":"Towards Scientific Intelligence: A Survey of LLM-based Scientific Agents","abstract":"As scientific research becomes increasingly complex, innovative tools are needed to manage vast data, facilitate interdisciplinary collaboration, and accelerate discovery. Large language models (LLMs) are now evolving into LLM-based scientific agents that automate critical tasks, ranging from hypothesis generation and experiment design to data analysis and simulation. Unlike general-purpose LLMs, these specialized agents integrate domain-specific knowledge, advanced tool sets, and robust validation mechanisms, enabling them to handle complex data types, ensure reproducibility, and drive scientific breakthroughs. This survey provides a focused review of the architectures, design, benchmarks, applications, and ethical considerations surrounding LLM-based scientific agents. We highlight why they differ from general agents and the ways in which they advance research across various scientific fields. By examining their development and challenges, this survey offers a comprehensive roadmap for researchers and practitioners to harness these agents for more efficient, reliable, and ethically sound scientific discovery.","authors":["Shuo Ren","Pu Jian","Zhenjiang Ren","Chunlin Leng","Can Xie","Jiajun Zhang"],"url":"https://arxiv.org/abs/2503.24047"}
{"created":"2025-04-18","title":"Multi-Stakeholder Disaster Insights from Social Media Using Large Language Models","abstract":"In recent years, social media has emerged as a primary channel for users to promptly share feedback and issues during disasters and emergencies, playing a key role in crisis management. While significant progress has been made in collecting and analyzing social media content, there remains a pressing need to enhance the automation, aggregation, and customization of this data to deliver actionable insights tailored to diverse stakeholders, including the press, police, EMS, and firefighters. This effort is essential for improving the coordination of activities such as relief efforts, resource distribution, and media communication. This paper presents a methodology that leverages the capabilities of LLMs to enhance disaster response and management. Our approach combines classification techniques with generative AI to bridge the gap between raw user feedback and stakeholder-specific reports. Social media posts shared during catastrophic events are analyzed with a focus on user-reported issues, service interruptions, and encountered challenges. We employ full-spectrum LLMs, using analytical models like BERT for precise, multi-dimensional classification of content type, sentiment, emotion, geolocation, and topic. Generative models such as ChatGPT are then used to produce human-readable, informative reports tailored to distinct audiences, synthesizing insights derived from detailed classifications. We compare standard approaches, which analyze posts directly using prompts in ChatGPT, to our advanced method, which incorporates multi-dimensional classification, sub-event selection, and tailored report generation. Our methodology demonstrates superior performance in both quantitative metrics, such as text coherence scores and latent representations, and qualitative assessments by automated tools and field experts, delivering precise insights for diverse disaster response stakeholders.","authors":["Loris Belcastro","Cristian Cosentino","Fabrizio Marozzo","Merve G\\\"und\\\"uz-C\\\"ure","Sule \\\"Ozt\\\"urk-Birim"],"url":"https://arxiv.org/abs/2504.00046"}
{"created":"2025-04-18","title":"Impact of Data Duplication on Deep Neural Network-Based Image Classifiers: Robust vs. Standard Models","abstract":"The accuracy and robustness of machine learning models against adversarial attacks are significantly influenced by factors such as training data quality, model architecture, the training process, and the deployment environment. In recent years, duplicated data in training sets, especially in language models, has attracted considerable attention. It has been shown that deduplication enhances both training performance and model accuracy in language models. While the importance of data quality in training image classifier Deep Neural Networks (DNNs) is widely recognized, the impact of duplicated images in the training set on model generalization and performance has received little attention.","authors":["Alireza Aghabagherloo","Aydin Abadi","Sumanta Sarkar","Vishnu Asutosh Dasu","Bart Preneel"],"url":"https://arxiv.org/abs/2504.00638"}
{"created":"2025-04-18","title":"Benchmarking the Spatial Robustness of DNNs via Natural and Adversarial Localized Corruptions","abstract":"The robustness of DNNs is a crucial factor in safety-critical applications, particularly in complex and dynamic environments where localized corruptions can arise. While previous studies have evaluated the robustness of semantic segmentation (SS) models under whole-image natural or adversarial corruptions, a comprehensive investigation into the spatial robustness of dense vision models under localized corruptions remained underexplored. This paper fills this gap by introducing specialized metrics for benchmarking the spatial robustness of segmentation models, alongside with an evaluation framework to assess the impact of localized corruptions. Furthermore, we uncover the inherent complexity of characterizing worst-case robustness using a single localized adversarial perturbation. To address this, we propose region-aware multi-attack adversarial analysis, a method that enables a deeper understanding of model robustness against adversarial perturbations applied to specific regions. The proposed metrics and analysis were exploited to evaluate 14 segmentation models in driving scenarios, uncovering key insights into the effects of localized corruption in both natural and adversarial forms. The results reveal that models respond to these two types of threats differently; for instance, transformer-based segmentation models demonstrate notable robustness to localized natural corruptions but are highly vulnerable to adversarial ones and vice-versa for CNN-based models. Consequently, we also address the challenge of balancing robustness to both natural and adversarial localized corruptions by means of ensemble models, thereby achieving a broader threat coverage and improved reliability for dense vision tasks.","authors":["Giulia Marchiori Pietrosanti","Giulio Rossolini","Alessandro Biondi","Giorgio Buttazzo"],"url":"https://arxiv.org/abs/2504.01632"}
{"created":"2025-04-18","title":"Rethinking industrial artificial intelligence: a unified foundation framework","abstract":"Recent advancements in industrial artificial intelligence (AI) are reshaping the industry by driving smarter manufacturing, predictive maintenance, and intelligent decision-making. However, existing approaches often focus primarily on algorithms and models while overlooking the importance of systematically integrating domain knowledge, data, and models to develop more comprehensive and effective AI solutions. Therefore, the effective development and deployment of industrial AI require a more comprehensive and systematic approach. To address this gap, this paper reviews previous research, rethinks the role of industrial AI, and proposes a unified industrial AI foundation framework comprising three core modules: the knowledge module, data module, and model module. These modules help to extend and enhance the industrial AI methodology platform, supporting various industrial applications. In addition, a case study on rotating machinery diagnosis is presented to demonstrate the effectiveness of the proposed framework, and several future directions are highlighted for the development of the industrial AI foundation framework.","authors":["Jay Lee","Hanqi Su"],"url":"https://arxiv.org/abs/2504.01797"}
{"created":"2025-04-18","title":"Engineering Artificial Intelligence: Framework, Challenges, and Future Direction","abstract":"Over the past ten years, the application of artificial intelligence (AI) and machine learning (ML) in engineering domains has gained significant popularity, showcasing their potential in data-driven contexts. However, the complexity and diversity of engineering problems often require the development of domain-specific AI approaches, which are frequently hindered by a lack of systematic methodologies, scalability, and robustness during the development process. To address this gap, this paper introduces the \"ABCDE\" as the key elements of Engineering AI and proposes a unified, systematic engineering AI ecosystem framework, including eight essential layers, along with attributes, goals, and applications, to guide the development and deployment of AI solutions for specific engineering needs. Additionally, key challenges are examined, and eight future research directions are highlighted. By providing a comprehensive perspective, this paper aims to advance the strategic implementation of AI, fostering the development of next-generation engineering AI solutions.","authors":["Jay Lee","Hanqi Su","Dai-Yan Ji","Takanobu Minami"],"url":"https://arxiv.org/abs/2504.02269"}
{"created":"2025-04-18","title":"Koney: A Cyber Deception Orchestration Framework for Kubernetes","abstract":"System operators responsible for protecting software applications remain hesitant to implement cyber deception technology, including methods that place traps to catch attackers, despite its proven benefits. Overcoming their concerns removes a barrier that currently hinders industry adoption of deception technology. Our work introduces deception policy documents to describe deception technology \"as code\" and pairs them with Koney, a Kubernetes operator, which facilitates the setup, rotation, monitoring, and removal of traps in Kubernetes. We leverage cloud-native technologies, such as service meshes and eBPF, to automatically add traps to containerized software applications, without having access to the source code. We focus specifically on operational properties, such as maintainability, scalability, and simplicity, which we consider essential to accelerate the adoption of cyber deception technology and to facilitate further research on cyber deception.","authors":["Mario Kahlhofer","Matteo Golinelli","Stefan Rass"],"url":"https://arxiv.org/abs/2504.02431"}
{"created":"2025-04-18","title":"GPG: A Simple and Strong Reinforcement Learning Baseline for Model Reasoning","abstract":"Reinforcement Learning (RL) can directly enhance the reasoning capabilities of large language models without extensive reliance on Supervised Fine-Tuning (SFT). In this work, we revisit the traditional Policy Gradient (PG) mechanism and propose a minimalist RL approach termed Group Policy Gradient (GPG). Unlike conventional methods, GPG directly optimize the original RL objective, thus obviating the need for surrogate loss functions. By eliminating the critic and reference models, avoiding KL divergence constraints, and addressing the advantage and gradient estimation bias, our approach significantly simplifies the training process compared to Group Relative Policy Optimization (GRPO). Our approach achieves superior performance without relying on auxiliary techniques or adjustments. As illustrated in Figure 1, extensive experiments demonstrate that our method not only reduces computational costs but also consistently outperforms GRPO across various unimodal and multimodal tasks. Our code is available at https://github.com/AMAP-ML/GPG.","authors":["Xiangxiang Chu","Hailang Huang","Xiao Zhang","Fei Wei","Yong Wang"],"url":"https://arxiv.org/abs/2504.02546"}
{"created":"2025-04-18","title":"Unified World Models: Coupling Video and Action Diffusion for Pretraining on Large Robotic Datasets","abstract":"Imitation learning has emerged as a promising approach towards building generalist robots. However, scaling imitation learning for large robot foundation models remains challenging due to its reliance on high-quality expert demonstrations. Meanwhile, large amounts of video data depicting a wide range of environments and diverse behaviors are readily available. This data provides a rich source of information about real-world dynamics and agent-environment interactions. Leveraging this data directly for imitation learning, however, has proven difficult due to the lack of action annotation required for most contemporary methods. In this work, we present Unified World Models (UWM), a framework that allows for leveraging both video and action data for policy learning. Specifically, a UWM integrates an action diffusion process and a video diffusion process within a unified transformer architecture, where independent diffusion timesteps govern each modality. By simply controlling each diffusion timestep, UWM can flexibly represent a policy, a forward dynamics, an inverse dynamics, and a video generator. Through simulated and real-world experiments, we show that: (1) UWM enables effective pretraining on large-scale multitask robot datasets with both dynamics and action predictions, resulting in more generalizable and robust policies than imitation learning, (2) UWM naturally facilitates learning from action-free video data through independent control of modality-specific diffusion timesteps, further improving the performance of finetuned policies. Our results suggest that UWM offers a promising step toward harnessing large, heterogeneous datasets for scalable robot learning, and provides a simple unification between the often disparate paradigms of imitation learning and world modeling. Videos and code are available at https://weirdlabuw.github.io/uwm/.","authors":["Chuning Zhu","Raymond Yu","Siyuan Feng","Benjamin Burchfiel","Paarth Shah","Abhishek Gupta"],"url":"https://arxiv.org/abs/2504.02792"}
{"created":"2025-04-18","title":"OnRL-RAG: Real-Time Personalized Mental Health Dialogue System","abstract":"Large language models (LLMs) have been widely used for various tasks and applications. However, LLMs and fine-tuning are limited to the pre-trained data. For example, ChatGPT's world knowledge until 2021 can be outdated or inaccurate. To enhance the capabilities of LLMs, Retrieval-Augmented Generation (RAG), is proposed to augment LLMs with additional, new, latest details and information to LLMs. While RAG offers the correct information, it may not best present it, especially to different population groups with personalizations. Reinforcement Learning from Human Feedback (RLHF) adapts to user needs by aligning model responses with human preference through feedback loops. In real-life applications, such as mental health problems, a dynamic and feedback-based model would continuously adapt to new information and offer personalized assistance due to complex factors fluctuating in a daily environment. Thus, we propose an Online Reinforcement Learning-based Retrieval-Augmented Generation (OnRL-RAG) system to detect and personalize the responding systems to mental health problems, such as stress, anxiety, and depression. We use an open-source dataset collected from 2028 College Students with 28 survey questions for each student to demonstrate the performance of our proposed system with the existing systems. Our system achieves superior performance compared to standard RAG and simple LLM via GPT-4o, GPT-4o-mini, Gemini-1.5, and GPT-3.5. This work would open up the possibilities of real-life applications of LLMs for personalized services in the everyday environment. The results will also help researchers in the fields of sociology, psychology, and neuroscience to align their theories more closely with the actual human daily environment.","authors":["Ahsan Bilal","Beiyu Lin"],"url":"https://arxiv.org/abs/2504.02894"}
{"created":"2025-04-18","title":"DeepResearcher: Scaling Deep Research via Reinforcement Learning in Real-world Environments","abstract":"Large Language Models (LLMs) equipped with web search capabilities have demonstrated impressive potential for deep research tasks. However, current approaches predominantly rely on either manually engineered prompts (prompt engineering-based) with brittle performance or reinforcement learning within controlled Retrieval-Augmented Generation (RAG) environments (RAG-based) that fail to capture the complexities of real-world interaction. In this paper, we introduce DeepResearcher, the first comprehensive framework for end-to-end training of LLM-based deep research agents through scaling reinforcement learning (RL) in real-world environments with authentic web search interactions. Unlike RAG-based approaches that assume all necessary information exists within a fixed corpus, our method trains agents to navigate the noisy, unstructured, and dynamic nature of the open web. We implement a specialized multi-agent architecture where browsing agents extract relevant information from various webpage structures and overcoming significant technical challenges. Extensive experiments on open-domain research tasks demonstrate that DeepResearcher achieves substantial improvements of up to 28.9 points over prompt engineering-based baselines and up to 7.2 points over RAG-based RL agents. Our qualitative analysis reveals emergent cognitive behaviors from end-to-end RL training, including the ability to formulate plans, cross-validate information from multiple sources, engage in self-reflection to redirect research, and maintain honesty when unable to find definitive answers. Our results highlight that end-to-end training in real-world web environments is not merely an implementation detail but a fundamental requirement for developing robust research capabilities aligned with real-world applications. We release DeepResearcher at https://github.com/GAIR-NLP/DeepResearcher.","authors":["Yuxiang Zheng","Dayuan Fu","Xiangkun Hu","Xiaojie Cai","Lyumanshan Ye","Pengrui Lu","Pengfei Liu"],"url":"https://arxiv.org/abs/2504.03160"}
{"created":"2025-04-18","title":"RealProbe: An Automated and Lightweight Performance Profiler for In-FPGA Execution of High-Level Synthesis Designs","abstract":"High-level synthesis (HLS) accelerates FPGA design by rapidly generating diverse implementations using optimization directives. However, even with cycle-accurate C/RTL co-simulation, the reported clock cycles often differ significantly from actual FPGA performance. This discrepancy hampers accurate bottleneck identification, leading to suboptimal design choices. Existing in-FPGA profiling tools, such as the Integrated Logic Analyzer (ILA), require tedious inspection of HLS-generated RTL and manual signal monitoring, reducing productivity. To address these challenges, we introduce RealProbe, the first fully automated, lightweight in-FPGA profiling tool for HLS designs. With a single directive--#pragma HLS RealProbe--the tool automatically generates all necessary code to profile cycle counts across the full function hierarchy, including submodules and loops. RealProbe extracts, records, and visualizes cycle counts with high precision, providing actionable insights into on-board performance. RealProbe is non-intrusive, implemented as independent logic to ensure minimal impact on kernel functionality or timing. It also supports automated design space exploration (DSE), optimizing resource allocation based on FPGA constraints and module complexity. By leveraging incremental synthesis and implementation, DSE runs independently of the original HLS kernel. Evaluated across 28 diverse test cases, including a large-scale design, RealProbe achieves 100% accuracy in capturing cycle counts with minimal logic overhead-just 16.98% LUTs, 43.15% FFs, and 0% BRAM usage. The tool, with full documentation and examples, is available on GitHub at https://github.com/sharc-lab/RealProbe .","authors":["Jiho Kim","Cong Hao"],"url":"https://arxiv.org/abs/2504.03879"}
{"created":"2025-04-18","title":"Meta-Learning Driven Movable-Antenna-assisted Full-Duplex RSMA for Multi-User Communication: Performance and Optimization","abstract":"Full-duplex (FD) radios at base station (BS) have gained significant interest because of their ability to simultaneously transmit and receive signals on the same frequency band. However, FD communication is hindered by self-interference (SI) and intra-cell interference caused by simultaneous uplink (UL) transmissions affecting downlink (DL) reception. These interferences significantly limit the ability to fully exploit FD's potential. Recently, movable antenna (MA) technology has emerged as a groundbreaking innovation, offering an effective way to mitigate interference by adjusting the position of each MA within the transmitter or receiver region. This dynamic repositioning allows MAs to move away from high-interference zones to areas with minimal interference, thereby enhancing multiplexing gain and improving spectral efficiency (SE). In light of this, in this paper, we investigate an FD communication system by integrating it with MAs to evaluate and investigate its effectiveness in handling SI and intra-cell interference. Moreover, we utilize rate-splitting multiple access (RSMA) as our multiple access technique in both UL and DL transmission. To achieve the full potential of the system, we evaluated three different scenarios with FD-BS-RSMA with MAs where our goal is to maximize the total sum rate of the system by jointly optimizing the transmitting and receiving beamforming vectors, UL user equipment (UE) transmission power, MA positions, and common stream split ratio of RSMA while satisfying the minimum data rate requirements of all UEs, common stream constraint, power budget requirements of BS and UL UEs, and inter-MA distance. The formulated optimization problem is highly non-convex in nature, and hence, we propose a gradient-based meta-learning (GML) approach which can handle the non-convexity in a discrete manner by optimizing each variable in a different neural network.","authors":["Shreya Khisa","Ali Amhaz","Mohamed Elhattab","Chadi Assi","Sanaa Sharafeddine"],"url":"https://arxiv.org/abs/2504.03982"}
{"created":"2025-04-18","title":"Prescribed-Time Boresight Control of Spacecraft Under Pointing Constraints","abstract":"This article proposes an integrated boresight guidance and control (IBGC) scheme to address the boresight reorientation problem of spacecraft under temporal and pointing constraints. A $C^1$ continuous, saturated prescribed-time adjustment (PPTA) function is presented, along with the establishment of a practical prescribed-time stability criterion. Utilizing the time scale transformation technique and the PPTA function, we propose a prescribed-time guidance law that guides the boresight vector from almost any initial orientation in free space to a small neighborhood of the goal orientation within a preassigned time, while avoiding all forbidden zones augmented with safety margins. Subsequently, a prescribed-time disturbance observer (PTDO) is derived to reconstruct the external disturbances. By leveraging barrier and PPTA functions, a PTDO-based reduced-attitude tracking controller is developed, which ensures prescribed-time boresight tracking within a ``safe tube''. By judiciously setting the safety margins, settling times, and safe tube for the guidance and control laws, the proposed IBGC scheme achieves pointing-constrained boresight reorientation within a required task completion time. Simulation and experimental results demonstrate the efficacy of the proposed IBGC scheme.","authors":["Xiaodong Shao","Haoyang Yang","Haoran Li","Zongyu Zuo","Jose Guadalupe Romero","Qinglei Hu"],"url":"https://arxiv.org/abs/2504.04312"}
{"created":"2025-04-18","title":"Decentralized Federated Domain Generalization with Style Sharing: A Formal Modeling and Convergence Analysis","abstract":"Much of the federated learning (FL) literature focuses on settings where local dataset statistics remain the same between training and testing time. Recent advances in domain generalization (DG) aim to use data from source (training) domains to train a model that generalizes well to data from unseen target (testing) domains. In this paper, we are motivated by two major gaps in existing work on FL and DG: (1) the lack of formal mathematical analysis of DG objectives and training processes; and (2) DG research in FL being limited to the conventional star-topology architecture. Addressing the second gap, we develop $\\textit{Decentralized Federated Domain Generalization with Style Sharing}$ ($\\texttt{StyleDDG}$), a fully decentralized DG algorithm designed to allow devices in a peer-to-peer network to achieve DG based on sharing style information inferred from their datasets. Additionally, we fill the first gap by providing the first systematic approach to mathematically analyzing style-based DG training optimization. We cast existing centralized DG algorithms within our framework, and employ their formalisms to model $\\texttt{StyleDDG}$. Based on this, we obtain analytical conditions under which a sub-linear convergence rate of $\\texttt{StyleDDG}$ can be obtained. Through experiments on two popular DG datasets, we demonstrate that $\\texttt{StyleDDG}$ can obtain significant improvements in accuracy across target domains with minimal added communication overhead compared to decentralized gradient methods that do not employ style sharing.","authors":["Shahryar Zehtabi","Dong-Jun Han","Seyyedali Hosseinalipour","Christopher G. Brinton"],"url":"https://arxiv.org/abs/2504.06235"}
{"created":"2025-04-18","title":"FuseRL: Dense Preference Optimization for Heterogeneous Model Fusion","abstract":"Heterogeneous model fusion enhances the performance of LLMs by integrating the knowledge and capabilities of multiple structurally diverse models. However, existing approaches often rely solely on selecting the best output for each prompt from source models, which underutilizes their full potential due to limited source knowledge and results in sparse optimization signals. To address this limitation, we propose FuseRL, a novel two-stage framework comprising FuseSFT and FusePO to maximize the utilization of source LLMs. FuseSFT establishes a robust initialization by integrating the strengths of heterogeneous source models through weighted supervised fine-tuning (SFT) on diverse outputs for each prompt. FusePO optimizes weighted preferences based on the outputs of multiple source models to enable superior alignment performance. Extensive experiments demonstrate the effectiveness of our framework across various preference alignment methods, including RLOO, DPO, and SimPO. Using Llama-3.1-8B-Instruct as the target model, our approach achieves state-of-the-art performance among 8B LLMs on the AlpacaEval-2 and Arena-Hard benchmarks. Further analysis suggests that FuseSFT regularizes the training process to reduce overfitting, while FusePO introduces dense and diverse signals for preference optimization.","authors":["Longguang Zhong","Fanqi Wan","Ziyi Yang","Guosheng Liang","Tianyuan Shi","Xiaojun Quan"],"url":"https://arxiv.org/abs/2504.06562"}
{"created":"2025-04-18","title":"FANeRV: Frequency Separation and Augmentation based Neural Representation for Video","abstract":"Neural representations for video (NeRV) have gained considerable attention for their strong performance across various video tasks. However, existing NeRV methods often struggle to capture fine spatial details, resulting in vague reconstructions. In this paper, we present a Frequency Separation and Augmentation based Neural Representation for video (FANeRV), which addresses these limitations with its core Wavelet Frequency Upgrade Block. This block explicitly separates input frames into high and low-frequency components using discrete wavelet transform, followed by targeted enhancement using specialized modules. Finally, a specially designed gated network effectively fuses these frequency components for optimal reconstruction. Additionally, convolutional residual enhancement blocks are integrated into the later stages of the network to balance parameter distribution and improve the restoration of high-frequency details. Experimental results demonstrate that FANeRV significantly improves reconstruction performance and excels in multiple tasks, including video compression, inpainting, and interpolation, outperforming existing NeRV methods.","authors":["Li Yu","Zhihui Li","Jimin Xiao","Moncef Gabbouj"],"url":"https://arxiv.org/abs/2504.06755"}
{"created":"2025-04-18","title":"CAFA: a Controllable Automatic Foley Artist","abstract":"Foley is a key element in video production, refers to the process of adding an audio signal to a silent video while ensuring semantic and temporal alignment. In recent years, the rise of personalized content creation and advancements in automatic video-to-audio models have increased the demand for greater user control in the process. One possible approach is to incorporate text to guide audio generation. While supported by existing methods, challenges remain in ensuring compatibility between modalities, particularly when the text introduces additional information or contradicts the sounds naturally inferred from the visuals. In this work, we introduce CAFA (Controllable Automatic Foley Artist) a video-and-text-to-audio model that generates semantically and temporally aligned audio for a given video, guided by text input. CAFA is built upon a text-to-audio model and integrates video information through a modality adapter mechanism. By incorporating text, users can refine semantic details and introduce creative variations, guiding the audio synthesis beyond the expected video contextual cues. Experiments show that besides its superior quality in terms of semantic alignment and audio-visual synchronization the proposed method enable high textual controllability as demonstrated in subjective and objective evaluations.","authors":["Roi Benita","Michael Finkelson","Tavi Halperin","Gleb Sterkin","Yossi Adi"],"url":"https://arxiv.org/abs/2504.06778"}
{"created":"2025-04-18","title":"A Krylov projection algorithm for large symmetric matrices with dense spectra","abstract":"We consider the approximation of $B^T (A+sI)^{-1} B$ for large s.p.d. $A\\in\\mathbb{R}^{n\\times n}$ with dense spectrum and $B\\in\\mathbb{R}^{n\\times p}$, $p\\ll n$. We target the computations of Multiple-Input Multiple-Output (MIMO) transfer functions for large-scale discretizations of problems with continuous spectral measures, such as linear time-invariant (LTI) PDEs on unbounded domains. Traditional Krylov methods, such as the Lanczos or CG algorithm, are known to be optimal for the computation of $(A+sI)^{-1}B$ with real positive $s$, resulting in an adaptation to the distinctively discrete and nonuniform spectra. However, the adaptation is damped for matrices with dense spectra. It was demonstrated in [Zimmerling, Druskin, Simoncini, Journal of Scientific Computing 103(1), 5 (2025)] that averaging Gau{\\ss} and Gau\\ss -Radau quadratures computed using the block-Lanczos method significantly reduces approximation errors for such problems. Here, we introduce an adaptive Kre\\u{i}n-Nudelman extension to the (block) Lanczos recursions, allowing further acceleration at negligible $o(n)$ cost. Similar to the Gau\\ss -Radau quadrature, a low-rank modification is applied to the (block) Lanczos matrix. However, unlike the Gau\\ss -Radau quadrature, this modification depends on $\\sqrt{s}$ and can be considered in the framework of the Hermite-Pad\\'e approximants, which are known to be efficient for problems with branch-cuts, that can be good approximations to dense spectral intervals. Numerical results for large-scale discretizations of heat-diffusion and quasi-magnetostatic Maxwell's operators in unbounded domains confirm the efficiency of the proposed approach.","authors":["Vladimir Druskin","J\\\"orn Zimmerling"],"url":"https://arxiv.org/abs/2504.06998"}
{"created":"2025-04-18","title":"Context Switching for Secure Multi-programming of Near-Term Quantum Computers","abstract":"Multi-programming quantum computers improve device utilization and throughput. However, crosstalk from concurrent two-qubit CNOT gates poses security risks, compromising the fidelity and output of co-running victim programs. We design Zero Knowledge Tampering Attacks (ZKTAs), using which attackers can exploit crosstalk without knowledge of the hardware error profile. ZKTAs can alter victim program outputs in 40% of cases on commercial systems.","authors":["Avinash Kumar","Meng Wang","Chenxu Liu","Ang Li","Prashant J. Nair","Poulami Das"],"url":"https://arxiv.org/abs/2504.07048"}
{"created":"2025-04-18","title":"Why We Feel: Breaking Boundaries in Emotional Reasoning with Multimodal Large Language Models","abstract":"Most existing emotion analysis emphasizes which emotion arises (e.g., happy, sad, angry) but neglects the deeper why. We propose Emotion Interpretation (EI), focusing on causal factors-whether explicit (e.g., observable objects, interpersonal interactions) or implicit (e.g., cultural context, off-screen events)-that drive emotional responses. Unlike traditional emotion recognition, EI tasks require reasoning about triggers instead of mere labeling. To facilitate EI research, we present EIBench, a large-scale benchmark encompassing 1,615 basic EI samples and 50 complex EI samples featuring multifaceted emotions. Each instance demands rationale-based explanations rather than straightforward categorization. We further propose a Coarse-to-Fine Self-Ask (CFSA) annotation pipeline, which guides Vision-Language Models (VLLMs) through iterative question-answer rounds to yield high-quality labels at scale. Extensive evaluations on open-source and proprietary large language models under four experimental settings reveal consistent performance gaps-especially for more intricate scenarios-underscoring EI's potential to enrich empathetic, context-aware AI applications. Our benchmark and methods are publicly available at: https://github.com/Lum1104/EIBench, offering a foundation for advanced multimodal causal analysis and next-generation affective computing.","authors":["Yuxiang Lin","Jingdong Sun","Zhi-Qi Cheng","Jue Wang","Haomin Liang","Zebang Cheng","Yifei Dong","Jun-Yan He","Xiaojiang Peng","Xian-Sheng Hua"],"url":"https://arxiv.org/abs/2504.07521"}
{"created":"2025-04-18","title":"PR-Attack: Coordinated Prompt-RAG Attacks on Retrieval-Augmented Generation in Large Language Models via Bilevel Optimization","abstract":"Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of applications, e.g., medical question-answering, mathematical sciences, and code generation. However, they also exhibit inherent limitations, such as outdated knowledge and susceptibility to hallucinations. Retrieval-Augmented Generation (RAG) has emerged as a promising paradigm to address these issues, but it also introduces new vulnerabilities. Recent efforts have focused on the security of RAG-based LLMs, yet existing attack methods face three critical challenges: (1) their effectiveness declines sharply when only a limited number of poisoned texts can be injected into the knowledge database, (2) they lack sufficient stealth, as the attacks are often detectable by anomaly detection systems, which compromises their effectiveness, and (3) they rely on heuristic approaches to generate poisoned texts, lacking formal optimization frameworks and theoretic guarantees, which limits their effectiveness and applicability. To address these issues, we propose coordinated Prompt-RAG attack (PR-attack), a novel optimization-driven attack that introduces a small number of poisoned texts into the knowledge database while embedding a backdoor trigger within the prompt. When activated, the trigger causes the LLM to generate pre-designed responses to targeted queries, while maintaining normal behavior in other contexts. This ensures both high effectiveness and stealth. We formulate the attack generation process as a bilevel optimization problem leveraging a principled optimization framework to develop optimal poisoned texts and triggers. Extensive experiments across diverse LLMs and datasets demonstrate the effectiveness of PR-Attack, achieving a high attack success rate even with a limited number of poisoned texts and significantly improved stealth compared to existing methods.","authors":["Yang Jiao","Xiaodong Wang","Kai Yang"],"url":"https://arxiv.org/abs/2504.07717"}
{"created":"2025-04-18","title":"Beyond the Frame: Generating 360{\\deg} Panoramic Videos from Perspective Videos","abstract":"360{\\deg} videos have emerged as a promising medium to represent our dynamic visual world. Compared to the \"tunnel vision\" of standard cameras, their borderless field of view offers a more complete perspective of our surroundings. While existing video models excel at producing standard videos, their ability to generate full panoramic videos remains elusive. In this paper, we investigate the task of video-to-360{\\deg} generation: given a perspective video as input, our goal is to generate a full panoramic video that is consistent with the original video. Unlike conventional video generation tasks, the output's field of view is significantly larger, and the model is required to have a deep understanding of both the spatial layout of the scene and the dynamics of objects to maintain spatio-temporal consistency. To address these challenges, we first leverage the abundant 360{\\deg} videos available online and develop a high-quality data filtering pipeline to curate pairwise training data. We then carefully design a series of geometry- and motion-aware operations to facilitate the learning process and improve the quality of 360{\\deg} video generation. Experimental results demonstrate that our model can generate realistic and coherent 360{\\deg} videos from in-the-wild perspective video. In addition, we showcase its potential applications, including video stabilization, camera viewpoint control, and interactive visual question answering.","authors":["Rundong Luo","Matthew Wallingford","Ali Farhadi","Noah Snavely","Wei-Chiu Ma"],"url":"https://arxiv.org/abs/2504.07940"}
{"created":"2025-04-18","title":"Variational quantum and neural quantum states algorithms for the linear complementarity problem","abstract":"Variational quantum algorithms (VQAs) are promising hybrid quantum-classical methods designed to leverage the computational advantages of quantum computing while mitigating the limitations of current noisy intermediate-scale quantum (NISQ) hardware. Although VQAs have been demonstrated as proofs of concept, their practical utility in solving real-world problems -- and whether quantum-inspired classical algorithms can match their performance -- remains an open question. We present a novel application of the variational quantum linear solver (VQLS) and its classical neural quantum states-based counterpart, the variational neural linear solver (VNLS), as key components within a minimum map Newton solver for a complementarity-based rigid body contact model. We demonstrate using the VNLS that our solver accurately simulates the dynamics of rigid spherical bodies during collision events. These results suggest that quantum and quantum-inspired linear algebra algorithms can serve as viable alternatives to standard linear algebra solvers for modeling certain physical systems.","authors":["Saibal De","Oliver Knitter","Rohan Kodati","Paramsothy Jayakumar","James Stokes","Shravan Veerapaneni"],"url":"https://arxiv.org/abs/2504.08141"}
{"created":"2025-04-18","title":"Evaluating the Bias in LLMs for Surveying Opinion and Decision Making in Healthcare","abstract":"Generative agents have been increasingly used to simulate human behaviour in silico, driven by large language models (LLMs). These simulacra serve as sandboxes for studying human behaviour without compromising privacy or safety. However, it remains unclear whether such agents can truly represent real individuals. This work compares survey data from the Understanding America Study (UAS) on healthcare decision-making with simulated responses from generative agents. Using demographic-based prompt engineering, we create digital twins of survey respondents and analyse how well different LLMs reproduce real-world behaviours. Our findings show that some LLMs fail to reflect realistic decision-making, such as predicting universal vaccine acceptance. However, Llama 3 captures variations across race and Income more accurately but also introduces biases not present in the UAS data. This study highlights the potential of generative agents for behavioural research while underscoring the risks of bias from both LLMs and prompting strategies.","authors":["Yonchanok Khaokaew","Flora D. Salim","Andreas Z\\\"ufle","Hao Xue","Taylor Anderson","C. Raina MacIntyre","Matthew Scotch","David J Heslop"],"url":"https://arxiv.org/abs/2504.08260"}
{"created":"2025-04-18","title":"Graph Reduction with Unsupervised Learning in Column Generation: A Routing Application","abstract":"Column Generation (CG) is a popular method dedicated to enhancing computational efficiency in large scale Combinatorial Optimization (CO) problems. It reduces the number of decision variables in a problem by solving a pricing problem. For many CO problems, the pricing problem is an Elementary Shortest Path Problem with Resource Constraints (ESPPRC). Large ESPPRC instances are difficult to solve to near-optimality. Consequently, we use a Graph neural Network (GNN) to reduces the size of the ESPPRC such that it becomes computationally tractable with standard solving techniques. Our GNN is trained by Unsupervised Learning and outputs a distribution for the arcs to be retained in the reduced PP. The reduced PP is solved by a local search that finds columns with large reduced costs and speeds up convergence. We apply our method on a set of Capacitated Vehicle Routing Problems with Time Windows and show significant improvements in convergence compared to simple reduction techniques from the literature. For a fixed computational budget, we improve the objective values by over 9\\% for larger instances. We also analyze the performance of our CG algorithm and test the generalization of our method to different classes of instances than the training data.","authors":["Abdo Abouelrous","Laurens Bliek","Adriana F. Gabor","Yaoxin Wu","Yingqian Zhang"],"url":"https://arxiv.org/abs/2504.08401"}
{"created":"2025-04-18","title":"Rethinking Few-Shot Image Fusion: Granular Ball Priors Enable General-Purpose Deep Fusion","abstract":"In image fusion tasks, the absence of real fused images as priors presents a fundamental challenge. Most deep learning-based fusion methods rely on large-scale paired datasets to extract global weighting features from raw images, thereby generating fused outputs that approximate real fused images. In contrast to previous studies, this paper explores few-shot training of neural networks under the condition of having prior knowledge. We propose a novel fusion framework named GBFF, and a Granular Ball Significant Extraction algorithm specifically designed for the few-shot prior setting. All pixel pairs involved in the fusion process are initially modeled as a Coarse-Grained Granular Ball. At the local level, Fine-Grained Granular Balls are used to slide through the brightness space to extract Non-Salient Pixel Pairs, and perform splitting operations to obtain Salient Pixel Pairs. Pixel-wise weights are then computed to generate a pseudo-supervised image. At the global level, pixel pairs with significant contributions to the fusion process are categorized into the Positive Region, while those whose contributions cannot be accurately determined are assigned to the Boundary Region. The Granular Ball performs modality-aware adaptation based on the proportion of the positive region, thereby adjusting the neural network's loss function and enabling it to complement the information of the boundary region. Extensive experiments demonstrate the effectiveness of both the proposed algorithm and the underlying theory. Compared with state-of-the-art (SOTA) methods, our approach shows strong competitiveness in terms of both fusion time and image expressiveness. Our code is publicly available at:","authors":["Minjie Deng","Yan Wei","Hao Zhai","An Wu","Yuncan Ouyang","Qianyao Peng"],"url":"https://arxiv.org/abs/2504.08937"}
{"created":"2025-04-18","title":"CAShift: Benchmarking Log-Based Cloud Attack Detection under Normality Shift","abstract":"With the rapid advancement of cloud-native computing, securing cloud environments has become an important task. Log-based Anomaly Detection (LAD) is the most representative technique used in different systems for attack detection and safety guarantee, where multiple LAD methods and relevant datasets have been proposed. However, even though some of these datasets are specifically prepared for cloud systems, they only cover limited cloud behaviors and lack information from a whole-system perspective. Besides, another critical issue to consider is normality shift, which implies the test distribution could differ from the training distribution and highly affects the performance of LAD. Unfortunately, existing works only focus on simple shift types such as chronological changes, while other important and cloud-specific shift types are ignored, e.g., the distribution shift introduced by different deployed cloud architectures. Therefore, creating a new dataset that covers diverse behaviors of cloud systems and normality shift types is necessary.","authors":["Jiongchi Yu","Xiaofei Xie","Qiang Hu","Bowen Zhang","Ziming Zhao","Yun Lin","Lei Ma","Ruitao Feng","Frank Liauw"],"url":"https://arxiv.org/abs/2504.09115"}
{"created":"2025-04-18","title":"Scaling up Reversible Logic with HKI Superconducting Inductors","abstract":"Researchers developed about a dozen semiconductor reversible (or adiabatic) logic chips since the early 1990s, validating circuit designs and proving the concept--but scale up required a further advance. This document shows that cryogenic inductors made of a new High Kinetic Inductance (HKI) material provide the advance. This material can be deposited as an integrated circuit layer, where it has enough energy recycling capacity to power a reversible circuit of the same size. This allows a designer to replicate and scale a complete reversible logic subsystem in accordance with Moore's law.","authors":["Erik P. DeBenedictis"],"url":"https://arxiv.org/abs/2504.09229"}
{"created":"2025-04-18","title":"Causal integration of chemical structures improves representations of microscopy images for morphological profiling","abstract":"Recent advances in self-supervised deep learning have improved our ability to quantify cellular morphological changes in high-throughput microscopy screens, a process known as morphological profiling. However, most current methods only learn from images, despite many screens being inherently multimodal, as they involve both a chemical or genetic perturbation as well as an image-based readout. We hypothesized that incorporating chemical compound structure during self-supervised pre-training could improve learned representations of images in high-throughput microscopy screens. We introduce a representation learning framework, MICON (Molecular-Image Contrastive Learning), that models chemical compounds as treatments that induce counterfactual transformations of cell phenotypes. MICON significantly outperforms classical hand-crafted features such as CellProfiler and existing deep-learning-based representation learning methods in challenging evaluation settings where models must identify reproducible effects of drugs across independent replicates and data-generating centers. We demonstrate that incorporating chemical compound information into the learning process provides consistent improvements in our evaluation setting and that modeling compounds specifically as treatments in a causal framework outperforms approaches that directly align images and compounds in a single representation space. Our findings point to a new direction for representation learning in morphological profiling, suggesting that methods should explicitly account for the multimodal nature of microscopy screening data.","authors":["Yemin Yu","Neil Tenenholtz","Lester Mackey","Ying Wei","David Alvarez-Melis","Ava P. Amini","Alex X. Lu"],"url":"https://arxiv.org/abs/2504.09544"}
{"created":"2025-04-18","title":"ControlNET: A Firewall for RAG-based LLM System","abstract":"Retrieval-Augmented Generation (RAG) has significantly enhanced the factual accuracy and domain adaptability of Large Language Models (LLMs). This advancement has enabled their widespread deployment across sensitive domains such as healthcare, finance, and enterprise applications. RAG mitigates hallucinations by integrating external knowledge, yet introduces privacy risk and security risk, notably data breaching risk and data poisoning risk. While recent studies have explored prompt injection and poisoning attacks, there remains a significant gap in comprehensive research on controlling inbound and outbound query flows to mitigate these threats. In this paper, we propose an AI firewall, ControlNET, designed to safeguard RAG-based LLM systems from these vulnerabilities. ControlNET controls query flows by leveraging activation shift phenomena to detect adversarial queries and mitigate their impact through semantic divergence. We conduct comprehensive experiments on four different benchmark datasets including Msmarco, HotpotQA, FinQA, and MedicalSys using state-of-the-art open source LLMs (Llama3, Vicuna, and Mistral). Our results demonstrate that ControlNET achieves over 0.909 AUROC in detecting and mitigating security threats while preserving system harmlessness. Overall, ControlNET offers an effective, robust, harmless defense mechanism, marking a significant advancement toward the secure deployment of RAG-based LLM systems.","authors":["Hongwei Yao","Haoran Shi","Yidou Chen","Yixin Jiang","Cong Wang","Zhan Qin"],"url":"https://arxiv.org/abs/2504.09593"}
{"created":"2025-04-18","title":"Understanding LLM Behaviors via Compression: Data Generation, Knowledge Acquisition and Scaling Laws","abstract":"Large Language Models (LLMs) have demonstrated remarkable capabilities across numerous tasks, yet principled explanations for their underlying mechanisms and several phenomena, such as scaling laws, hallucinations, and related behaviors, remain elusive. In this work, we revisit the classical relationship between compression and prediction, grounded in Kolmogorov complexity and Shannon information theory, to provide deeper insights into LLM behaviors. By leveraging the Kolmogorov Structure Function and interpreting LLM compression as a two-part coding process, we offer a detailed view of how LLMs acquire and store information across increasing model and data scales -- from pervasive syntactic patterns to progressively rarer knowledge elements. Motivated by this theoretical perspective and natural assumptions inspired by Heap's and Zipf's laws, we introduce a simplified yet representative hierarchical data-generation framework called the Syntax-Knowledge model. Under the Bayesian setting, we show that prediction and compression within this model naturally lead to diverse learning and scaling behaviors of LLMs. In particular, our theoretical analysis offers intuitive and principled explanations for both data and model scaling laws, the dynamics of knowledge acquisition during training and fine-tuning, factual knowledge hallucinations in LLMs. The experimental results validate our theoretical predictions.","authors":["Zhixuan Pan","Shaowen Wang","Jian Li"],"url":"https://arxiv.org/abs/2504.09597"}
{"created":"2025-04-18","title":"HDC: Hierarchical Distillation for Multi-level Noisy Consistency in Semi-Supervised Fetal Ultrasound Segmentation","abstract":"Transvaginal ultrasound is a critical imaging modality for evaluating cervical anatomy and detecting physiological changes. However, accurate segmentation of cervical structures remains challenging due to low contrast, shadow artifacts, and indistinct boundaries. While convolutional neural networks (CNNs) have demonstrated efficacy in medical image segmentation, their reliance on large-scale annotated datasets presents a significant limitation in clinical ultrasound imaging. Semi-supervised learning (SSL) offers a potential solution by utilizing unlabeled data, yet existing teacher-student frameworks often encounter confirmation bias and high computational costs. In this paper, a novel semi-supervised segmentation framework, called HDC, is proposed incorporating adaptive consistency learning with a single-teacher architecture. The framework introduces a hierarchical distillation mechanism with two objectives: Correlation Guidance Loss for aligning feature representations and Mutual Information Loss for stabilizing noisy student learning. The proposed approach reduces model complexity while enhancing generalization. Experiments on fetal ultrasound datasets, FUGC and PSFH, demonstrate competitive performance with reduced computational overhead compared to multi-teacher models.","authors":["Tran Quoc Khanh Le","Nguyen Lan Vi Vu","Ha-Hieu Pham","Xuan-Loc Huynh","Tien-Huy Nguyen","Minh Huu Nhat Le","Quan Nguyen","Hien D. Nguyen"],"url":"https://arxiv.org/abs/2504.09876"}
{"created":"2025-04-18","title":"CameraBench: Benchmarking Visual Reasoning in MLLMs via Photography","abstract":"Large language models (LLMs) and multimodal large language models (MLLMs) have significantly advanced artificial intelligence. However, visual reasoning, reasoning involving both visual and textual inputs, remains underexplored. Recent advancements, including the reasoning models like OpenAI o1 and Gemini 2.0 Flash Thinking, which incorporate image inputs, have opened this capability. In this ongoing work, we focus specifically on photography-related tasks because a photo is a visual snapshot of the physical world where the underlying physics (i.e., illumination, blur extent, etc.) interplay with the camera parameters. Successfully reasoning from the visual information of a photo to identify these numerical camera settings requires the MLLMs to have a deeper understanding of the underlying physics for precise visual comprehension, representing a challenging and intelligent capability essential for practical applications like photography assistant agents. We aim to evaluate MLLMs on their ability to distinguish visual differences related to numerical camera settings, extending a methodology previously proposed for vision-language models (VLMs). Our preliminary results demonstrate the importance of visual reasoning in photography-related tasks. Moreover, these results show that no single MLLM consistently dominates across all evaluation tasks, demonstrating ongoing challenges and opportunities in developing MLLMs with better visual reasoning.","authors":["I-Sheng Fang","Jun-Cheng Chen"],"url":"https://arxiv.org/abs/2504.10090"}
{"created":"2025-04-18","title":"Emotion Alignment: Discovering the Gap Between Social Media and Real-World Sentiments in Persian Tweets and Images","abstract":"In contemporary society, widespread social media usage is evident in people's daily lives. Nevertheless, disparities in emotional expressions between the real world and online platforms can manifest. We comprehensively analyzed Persian community on X to explore this phenomenon. An innovative pipeline was designed to measure the similarity between emotions in the real world compared to social media. Accordingly, recent tweets and images of participants were gathered and analyzed using Transformers-based text and image sentiment analysis modules. Each participant's friends also provided insights into the their real-world emotions. A distance criterion was used to compare real-world feelings with virtual experiences. Our study encompassed N=105 participants, 393 friends who contributed their perspectives, over 8,300 collected tweets, and 2,000 media images. Results indicated a 28.67% similarity between images and real-world emotions, while tweets exhibited a 75.88% alignment with real-world feelings. Additionally, the statistical significance confirmed that the observed disparities in sentiment proportions.","authors":["Sina Elahimanesh","Mohammadali Mohammadkhani","Shohreh Kasaei"],"url":"https://arxiv.org/abs/2504.10662"}
{"created":"2025-04-18","title":"Frozen Layers: Memory-efficient Many-fidelity Hyperparameter Optimization","abstract":"As model sizes grow, finding efficient and cost-effective hyperparameter optimization (HPO) methods becomes increasingly crucial for deep learning pipelines. While multi-fidelity HPO (MF-HPO) trades off computational resources required for DL training with lower fidelity estimations, existing fidelity sources often fail under lower compute and memory constraints. We propose a novel fidelity source: the number of layers that are trained or frozen during training. For deep networks, this approach offers significant compute and memory savings while preserving rank correlations between hyperparameters at low fidelities compared to full model training. We demonstrate this in our empirical evaluation across ResNets and Transformers and additionally analyze the utility of frozen layers as a fidelity in using GPU resources as a fidelity in HPO, and for a combined MF-HPO with other fidelity sources. This contribution opens new applications for MF-HPO with hardware resources as a fidelity and creates opportunities for improved algorithms navigating joint fidelity spaces.","authors":["Timur Carstensen","Neeratyoy Mallik","Frank Hutter","Martin Rapp"],"url":"https://arxiv.org/abs/2504.10735"}
{"created":"2025-04-18","title":"CSPLADE: Learned Sparse Retrieval with Causal Language Models","abstract":"In recent years, dense retrieval has been the focus of information retrieval (IR) research. While effective, dense retrieval produces uninterpretable dense vectors, and suffers from the drawback of large index size. Learned sparse retrieval (LSR) has emerged as promising alternative, achieving competitive retrieval performance while also being able to leverage the classical inverted index data structure for efficient retrieval. However, limited works have explored scaling LSR beyond BERT scale. In this work, we identify two challenges in training large language models (LLM) for LSR: (1) training instability during the early stage of contrastive training; (2) suboptimal performance due to pre-trained LLM's unidirectional attention. To address these challenges, we propose two corresponding techniques: (1) a lightweight adaptation training phase to eliminate training instability; (2) two model variants to enable bidirectional information. With these techniques, we are able to train LSR models with 8B scale LLM, and achieve competitive retrieval performance with reduced index size. Furthermore, we are among the first to analyze the performance-efficiency tradeoff of LLM-based LSR model through the lens of model quantization. Our findings provide insights into adapting LLMs for efficient retrieval modeling.","authors":["Zhichao Xu","Aosong Feng","Yijun Tian","Haibo Ding","Lin Lee Cheong"],"url":"https://arxiv.org/abs/2504.10816"}
{"created":"2025-04-18","title":"Transfer Learning for Temporal Link Prediction","abstract":"Link prediction on graphs has applications spanning from recommender systems to drug discovery. Temporal link prediction (TLP) refers to predicting future links in a temporally evolving graph and adds additional complexity related to the dynamic nature of graphs. State-of-the-art TLP models incorporate memory modules alongside graph neural networks to learn both the temporal mechanisms of incoming nodes and the evolving graph topology. However, memory modules only store information about nodes seen at train time, and hence such models cannot be directly transferred to entirely new graphs at test time and deployment. In this work, we study a new transfer learning task for temporal link prediction, and develop transfer-effective methods for memory-laden models. Specifically, motivated by work showing the informativeness of structural signals for the TLP task, we augment a structural mapping module to the existing TLP model architectures, which learns a mapping from graph structural (topological) features to memory embeddings. Our work paves the way for a memory-free foundation model for TLP.","authors":["Ayan Chatterjee","Barbara Ikica","Babak Ravandi","John Palowitch"],"url":"https://arxiv.org/abs/2504.10925"}
{"created":"2025-04-18","title":"Adaptive Decision Boundary for Few-Shot Class-Incremental Learning","abstract":"Few-Shot Class-Incremental Learning (FSCIL) aims to continuously learn new classes from a limited set of training samples without forgetting knowledge of previously learned classes. Conventional FSCIL methods typically build a robust feature extractor during the base training session with abundant training samples and subsequently freeze this extractor, only fine-tuning the classifier in subsequent incremental phases. However, current strategies primarily focus on preventing catastrophic forgetting, considering only the relationship between novel and base classes, without paying attention to the specific decision spaces of each class. To address this challenge, we propose a plug-and-play Adaptive Decision Boundary Strategy (ADBS), which is compatible with most FSCIL methods. Specifically, we assign a specific decision boundary to each class and adaptively adjust these boundaries during training to optimally refine the decision spaces for the classes in each session. Furthermore, to amplify the distinctiveness between classes, we employ a novel inter-class constraint loss that optimizes the decision boundaries and prototypes for each class. Extensive experiments on three benchmarks, namely CIFAR100, miniImageNet, and CUB200, demonstrate that incorporating our ADBS method with existing FSCIL techniques significantly improves performance, achieving overall state-of-the-art results.","authors":["Linhao Li","Yongzhang Tan","Siyuan Yang","Hao Cheng","Yongfeng Dong","Liang Yang"],"url":"https://arxiv.org/abs/2504.10976"}
{"created":"2025-04-18","title":"CAP-Net: A Unified Network for 6D Pose and Size Estimation of Categorical Articulated Parts from a Single RGB-D Image","abstract":"This paper tackles category-level pose estimation of articulated objects in robotic manipulation tasks and introduces a new benchmark dataset. While recent methods estimate part poses and sizes at the category level, they often rely on geometric cues and complex multi-stage pipelines that first segment parts from the point cloud, followed by Normalized Part Coordinate Space (NPCS) estimation for 6D poses. These approaches overlook dense semantic cues from RGB images, leading to suboptimal accuracy, particularly for objects with small parts. To address these limitations, we propose a single-stage Network, CAP-Net, for estimating the 6D poses and sizes of Categorical Articulated Parts. This method combines RGB-D features to generate instance segmentation and NPCS representations for each part in an end-to-end manner. CAP-Net uses a unified network to simultaneously predict point-wise class labels, centroid offsets, and NPCS maps. A clustering algorithm then groups points of the same predicted class based on their estimated centroid distances to isolate each part. Finally, the NPCS region of each part is aligned with the point cloud to recover its final pose and size. To bridge the sim-to-real domain gap, we introduce the RGBD-Art dataset, the largest RGB-D articulated dataset to date, featuring photorealistic RGB images and depth noise simulated from real sensors. Experimental evaluations on the RGBD-Art dataset demonstrate that our method significantly outperforms the state-of-the-art approach. Real-world deployments of our model in robotic tasks underscore its robustness and exceptional sim-to-real transfer capabilities, confirming its substantial practical utility. Our dataset, code and pre-trained models are available on the project page.","authors":["Jingshun Huang","Haitao Lin","Tianyu Wang","Yanwei Fu","Xiangyang Xue","Yi Zhu"],"url":"https://arxiv.org/abs/2504.11230"}
{"created":"2025-04-18","title":"UI-E2I-Synth: Advancing GUI Grounding with Large-Scale Instruction Synthesis","abstract":"Recent advancements in Large Vision-Language Models are accelerating the development of Graphical User Interface (GUI) agents that utilize human-like vision perception capabilities to enhance productivity on digital devices. Compared to approaches predicated on GUI metadata, which are platform-dependent and vulnerable to implementation variations, vision-based approaches offer broader applicability. In this vision-based paradigm, the GUI instruction grounding, which maps user instruction to the location of corresponding element on the given screenshot, remains a critical challenge, particularly due to limited public training dataset and resource-intensive manual instruction data annotation. In this paper, we delve into unexplored challenges in this task including element-to-screen ratio, unbalanced element type, and implicit instruction. To address these challenges, we introduce a large-scale data synthesis pipeline UI-E2I-Synth for generating varying complex instruction datasets using GPT-4o instead of human annotators. Furthermore, we propose a new GUI instruction grounding benchmark UI-I2E-Bench, which is designed to address the limitations of existing benchmarks by incorporating diverse annotation aspects. Our model, trained on the synthesized data, achieves superior performance in GUI instruction grounding, demonstrating the advancements of proposed data synthesis pipeline. The proposed benchmark, accompanied by extensive analyses, provides practical insights for future research in GUI grounding. We will release corresponding artifacts at https://colmon46.github.io/i2e-bench-leaderboard/ .","authors":["Xinyi Liu","Xiaoyi Zhang","Ziyun Zhang","Yan Lu"],"url":"https://arxiv.org/abs/2504.11257"}
{"created":"2025-04-18","title":"PATFinger: Prompt-Adapted Transferable Fingerprinting against Unauthorized Multimodal Dataset Usage","abstract":"The multimodal datasets can be leveraged to pre-train large-scale vision-language models by providing cross-modal semantics. Current endeavors for determining the usage of datasets mainly focus on single-modal dataset ownership verification through intrusive methods and non-intrusive techniques, while cross-modal approaches remain under-explored. Intrusive methods can adapt to multimodal datasets but degrade model accuracy, while non-intrusive methods rely on label-driven decision boundaries that fail to guarantee stable behaviors for verification. To address these issues, we propose a novel prompt-adapted transferable fingerprinting scheme from a training-free perspective, called PATFinger, which incorporates the global optimal perturbation (GOP) and the adaptive prompts to capture dataset-specific distribution characteristics. Our scheme utilizes inherent dataset attributes as fingerprints instead of compelling the model to learn triggers. The GOP is derived from the sample distribution to maximize embedding drifts between different modalities. Subsequently, our PATFinger re-aligns the adaptive prompt with GOP samples to capture the cross-modal interactions on the carefully crafted surrogate model. This allows the dataset owner to check the usage of datasets by observing specific prediction behaviors linked to the PATFinger during retrieval queries. Extensive experiments demonstrate the effectiveness of our scheme against unauthorized multimodal dataset usage on various cross-modal retrieval architectures by 30% over state-of-the-art baselines.","authors":["Wenyi Zhang","Ju Jia","Xiaojun Jia","Yihao Huang","Xinfeng Li","Cong Wu","Lina Wang"],"url":"https://arxiv.org/abs/2504.11509"}
{"created":"2025-04-18","title":"Multi-output Classification Framework and Frequency Layer Normalization for Compound Fault Diagnosis in Motor","abstract":"This work introduces a multi-output classification (MOC) framework designed for domain adaptation in fault diagnosis, particularly under partially labeled (PL) target domain scenarios and compound fault conditions in rotating machinery. Unlike traditional multi-class classification (MCC) methods that treat each fault combination as a distinct class, the proposed approach independently estimates the severity of each fault type, improving both interpretability and diagnostic accuracy. The model incorporates multi-kernel maximum mean discrepancy (MK-MMD) and entropy minimization (EM) losses to facilitate feature transfer from the source to the target domain. In addition, frequency layer normalization (FLN) is applied to preserve structural properties in the frequency domain, which are strongly influenced by system dynamics and are often stationary with respect to changes in rpm. Evaluations across six domain adaptation cases with PL data demonstrate that MOC outperforms baseline models in macro F1 score. Moreover, MOC consistently achieves better classification performance for individual fault types, and FLN shows superior adaptability compared to other normalization techniques.","authors":["Wonjun Yi","Yong-Hwa Park"],"url":"https://arxiv.org/abs/2504.11513"}
{"created":"2025-04-18","title":"ReTool: Reinforcement Learning for Strategic Tool Use in LLMs","abstract":"While reasoning models (e.g., DeepSeek R1) trained with reinforcement learning (RL), excel in textual reasoning, they struggle in scenarios requiring structured problem-solving, such as geometric reasoning, concise computation, or complex equation solving-areas where computational tools like code interpreters (CI) demonstrate distinct advantages. To bridge this gap, we propose ReTool, which enhances long-form reasoning with tool-integrated learning, including two key features: (1) dynamic interleaving of real-time code execution within natural language reasoning processes, and (2) an automated RL paradigm that allows policy rollouts with multi-turn real-time code execution and teaches the model in learning when and how to invoke tools based on outcome feedback. ReTool employs a systematic training framework, beginning with synthetic cold-start data generation to produce code-augmented long-form reasoning traces for fine-tuning base models. Subsequent RL training leverages task outcomes as rewards to iteratively refine the model's tool use strategy, enabling autonomous discovery of optimal tool invocation patterns without human priors. Experiments on the challenging MATH Olympiad benchmark AIME demonstrate ReTool's superiority: Our 32B model achieves 67% accuracy with 400 training steps, outperforming text-based RL baseline (40% accuracy, 1080 steps) in efficiency and performance. Remarkably, ReTool-32B attains 72.5% accuracy in extended settings, surpassing OpenAI's o1-preview by 27.9%. Further analysis reveals emergent behaviors such as code self-correction, signaling an ''aha moment'' in which the model autonomously masters adaptive tool use. These findings highlight the promise of outcome-driven tool integration for advancing complex mathematical reasoning and offer new insights into hybrid neuro-symbolic systems.","authors":["Jiazhan Feng","Shijue Huang","Xingwei Qu","Ge Zhang","Yujia Qin","Baoquan Zhong","Chengquan Jiang","Jinxin Chi","Wanjun Zhong"],"url":"https://arxiv.org/abs/2504.11536"}
{"created":"2025-04-18","title":"REAL: Benchmarking Autonomous Agents on Deterministic Simulations of Real Websites","abstract":"We introduce REAL, a benchmark and framework for multi-turn agent evaluations on deterministic simulations of real-world websites. REAL comprises high-fidelity, deterministic replicas of 11 widely-used websites across domains such as e-commerce, travel, communication, and professional networking. We also release a benchmark consisting of 112 practical tasks that mirror everyday complex user interactions requiring both accurate information retrieval and state-changing actions. All interactions occur within this fully controlled setting, eliminating safety risks and enabling robust, reproducible evaluation of agent capability and reliability. Our novel evaluation framework combines programmatic checks of website state for action-based tasks with rubric-guided LLM-based judgments for information retrieval. The framework supports both open-source and proprietary agent systems through a flexible evaluation harness that accommodates black-box commands within browser environments, allowing research labs to test agentic systems without modification. Our empirical results show that frontier language models achieve at most a 41% success rate on REAL, highlighting critical gaps in autonomous web navigation and task completion capabilities. Our framework supports easy integration of new tasks, reproducible evaluation, and scalable post-training data generation, marking a significant step forward in evaluating and advancing agent capabilities.","authors":["Divyansh Garg","Shaun VanWeelden","Diego Caples","Andis Draguns","Nikil Ravi","Pranav Putta","Naman Garg","Tomas Abraham","Michael Lara","Federico Lopez","James Liu","Atharva Gundawar","Prannay Hebbar","Youngchul Joo","Jindong Gu","Charles London","Christian Schroeder de Witt","Sumeet Motwani"],"url":"https://arxiv.org/abs/2504.11543"}
{"created":"2025-04-18","title":"The Hitchhiker's Guide to Program Analysis, Part II: Deep Thoughts by LLMs","abstract":"Static analysis is a cornerstone for software vulnerability detection, yet it often struggles with the classic precision-scalability trade-off. In practice, such tools often produce high false positive rates, particularly in large codebases like the Linux kernel. This imprecision can arise from simplified vulnerability modeling and over-approximation of path and data constraints. While large language models (LLMs) show promise in code understanding, their naive application to program analysis yields unreliable results due to inherent reasoning limitations. We introduce BugLens, a post-refinement framework that significantly improves static analysis precision. BugLens guides an LLM to follow traditional analysis steps by assessing buggy code patterns for security impact and validating the constraints associated with static warnings. Evaluated on real-world Linux kernel bugs, BugLens raises precision from 0.10 (raw) and 0.50 (semi-automated refinement) to 0.72, substantially reducing false positives and revealing four previously unreported vulnerabilities. Our results suggest that a structured LLM-based workflow can meaningfully enhance the effectiveness of static analysis tools.","authors":["Haonan Li","Hang Zhang","Kexin Pei","Zhiyun Qian"],"url":"https://arxiv.org/abs/2504.11711"}
{"created":"2025-04-18","title":"Safety with Agency: Human-Centered Safety Filter with Application to AI-Assisted Motorsports","abstract":"We propose a human-centered safety filter (HCSF) for shared autonomy that significantly enhances system safety without compromising human agency. Our HCSF is built on a neural safety value function, which we first learn scalably through black-box interactions and then use at deployment to enforce a novel state-action control barrier function (Q-CBF) safety constraint. Since this Q-CBF safety filter does not require any knowledge of the system dynamics for both synthesis and runtime safety monitoring and intervention, our method applies readily to complex, black-box shared autonomy systems. Notably, our HCSF's CBF-based interventions modify the human's actions minimally and smoothly, avoiding the abrupt, last-moment corrections delivered by many conventional safety filters. We validate our approach in a comprehensive in-person user study using Assetto Corsa-a high-fidelity car racing simulator with black-box dynamics-to assess robustness in \"driving on the edge\" scenarios. We compare both trajectory data and drivers' perceptions of our HCSF assistance against unassisted driving and a conventional safety filter. Experimental results show that 1) compared to having no assistance, our HCSF improves both safety and user satisfaction without compromising human agency or comfort, and 2) relative to a conventional safety filter, our proposed HCSF boosts human agency, comfort, and satisfaction while maintaining robustness.","authors":["Donggeon David Oh","Justin Lidard","Haimin Hu","Himani Sinhmar","Elle Lazarski","Deepak Gopinath","Emily S. Sumner","Jonathan A. DeCastro","Guy Rosman","Naomi Ehrich Leonard","Jaime Fern\\'andez Fisac"],"url":"https://arxiv.org/abs/2504.11717"}
{"created":"2025-04-18","title":"DVLTA-VQA: Decoupled Vision-Language Modeling with Text-Guided Adaptation for Blind Video Quality Assessment","abstract":"Inspired by the dual-stream theory of the human visual system (HVS) - where the ventral stream is responsible for object recognition and detail analysis, while the dorsal stream focuses on spatial relationships and motion perception - an increasing number of video quality assessment (VQA) works built upon this framework are proposed. Recent advancements in large multi-modal models, notably Contrastive Language-Image Pretraining (CLIP), have motivated researchers to incorporate CLIP into dual-stream-based VQA methods. This integration aims to harness the model's superior semantic understanding capabilities to replicate the object recognition and detail analysis in ventral stream, as well as spatial relationship analysis in dorsal stream. However, CLIP is originally designed for images and lacks the ability to capture temporal and motion information inherent in videos.To address the limitation, this paper propose a Decoupled Vision-Language Modeling with Text-Guided Adaptation for Blind Video Quality Assessment (DVLTA-VQA), which decouples CLIP's visual and textual components, and integrates them into different stages of the NR-VQA pipeline. Specifically, a Video-Based Temporal CLIP module is proposed to explicitly model temporal dynamics and enhance motion perception, aligning with the dorsal stream. Additionally, a Temporal Context Module is developed to refine inter-frame dependencies, further improving motion modeling. On the ventral stream side, a Basic Visual Feature Extraction Module is employed to strengthen detail analysis. Finally, a text-guided adaptive fusion strategy is proposed to enable dynamic weighting of features, facilitating more effective integration of spatial and temporal information.","authors":["Li Yu","Situo Wang","Wei Zhou","Moncef Gabbouj"],"url":"https://arxiv.org/abs/2504.11733"}
{"created":"2025-04-18","title":"Selective Attention Federated Learning: Improving Privacy and Efficiency for Clinical Text Classification","abstract":"Federated Learning (FL) faces major challenges regarding communication overhead and model privacy when training large language models (LLMs), especially in healthcare applications. To address these, we introduce Selective Attention Federated Learning (SAFL), a novel approach that dynamically fine-tunes only those transformer layers identified as attention-critical. By employing attention patterns to determine layer importance, SAFL significantly reduces communication bandwidth and enhances differential privacy resilience. Evaluations on clinical NLP benchmarks (i2b2 Clinical Concept Extraction and MIMIC-III discharge summaries) demonstrate that SAFL achieves competitive performance with centralized models while substantially improving communication efficiency and privacy preservation.","authors":["Yue Li","Lihong Zhang"],"url":"https://arxiv.org/abs/2504.11793"}
{"created":"2025-04-18","title":"Causality-enhanced Decision-Making for Autonomous Mobile Robots in Dynamic Environments","abstract":"The growing integration of robots in shared environments -- such as warehouses, shopping centres, and hospitals -- demands a deep understanding of the underlying dynamics and human behaviours, including how, when, and where individuals engage in various activities and interactions. This knowledge goes beyond simple correlation studies and requires a more comprehensive causal analysis. By leveraging causal inference to model cause-and-effect relationships, we can better anticipate critical environmental factors and enable autonomous robots to plan and execute tasks more effectively. To this end, we propose a novel causality-based decision-making framework that reasons over a learned causal model to predict battery usage and human obstructions, understanding how these factors could influence robot task execution. Such reasoning framework assists the robot in deciding when and how to complete a given task. To achieve this, we developed also PeopleFlow, a new Gazebo-based simulator designed to model context-sensitive human-robot spatial interactions in shared workspaces. PeopleFlow features realistic human and robot trajectories influenced by contextual factors such as time, environment layout, and robot state, and can simulate a large number of agents. While the simulator is general-purpose, in this paper we focus on a warehouse-like environment as a case study, where we conduct an extensive evaluation benchmarking our causal approach against a non-causal baseline. Our findings demonstrate the efficacy of the proposed solutions, highlighting how causal reasoning enables autonomous robots to operate more efficiently and safely in dynamic environments shared with humans.","authors":["Luca Castri","Gloria Beraldo","Nicola Bellotto"],"url":"https://arxiv.org/abs/2504.11901"}
{"created":"2025-04-18","title":"Securing the Skies: A Comprehensive Survey on Anti-UAV Methods, Benchmarking, and Future Directions","abstract":"Unmanned Aerial Vehicles (UAVs) are indispensable for infrastructure inspection, surveillance, and related tasks, yet they also introduce critical security challenges. This survey provides a wide-ranging examination of the anti-UAV domain, centering on three core objectives-classification, detection, and tracking-while detailing emerging methodologies such as diffusion-based data synthesis, multi-modal fusion, vision-language modeling, self-supervised learning, and reinforcement learning. We systematically evaluate state-of-the-art solutions across both single-modality and multi-sensor pipelines (spanning RGB, infrared, audio, radar, and RF) and discuss large-scale as well as adversarially oriented benchmarks. Our analysis reveals persistent gaps in real-time performance, stealth detection, and swarm-based scenarios, underscoring pressing needs for robust, adaptive anti-UAV systems. By highlighting open research directions, we aim to foster innovation and guide the development of next-generation defense strategies in an era marked by the extensive use of UAVs.","authors":["Yifei Dong","Fengyi Wu","Sanjian Zhang","Guangyu Chen","Yuzhi Hu","Masumi Yano","Jingdong Sun","Siyu Huang","Feng Liu","Qi Dai","Zhi-Qi Cheng"],"url":"https://arxiv.org/abs/2504.11967"}
{"created":"2025-04-18","title":"Dynamical reweighting for estimation of fluctuation formulas","abstract":"We propose a variance reduction method for calculating transport coefficients in molecular dynamics using an importance sampling method via Girsanov's theorem applied to Green--Kubo's formula. We optimize the magnitude of the perturbation applied to the reference dynamics by means of a scalar parameter~$\\alpha$ and propose an asymptotic analysis to fully characterize the long-time behavior in order to evaluate the possible variance reduction. Theoretical results corroborated by numerical results show that this method allows for some reduction in variance, although rather modest in most situations.","authors":["Rapha\\\"el Gastaldello","Gabriel Stoltz","Urbain Vaes"],"url":"https://arxiv.org/abs/2504.11968"}
{"created":"2025-04-18","title":"Understanding Attention Mechanism in Video Diffusion Models","abstract":"Text-to-video (T2V) synthesis models, such as OpenAI's Sora, have garnered significant attention due to their ability to generate high-quality videos from a text prompt. In diffusion-based T2V models, the attention mechanism is a critical component. However, it remains unclear what intermediate features are learned and how attention blocks in T2V models affect various aspects of video synthesis, such as image quality and temporal consistency. In this paper, we conduct an in-depth perturbation analysis of the spatial and temporal attention blocks of T2V models using an information-theoretic approach. Our results indicate that temporal and spatial attention maps affect not only the timing and layout of the videos but also the complexity of spatiotemporal elements and the aesthetic quality of the synthesized videos. Notably, high-entropy attention maps are often key elements linked to superior video quality, whereas low-entropy attention maps are associated with the video's intra-frame structure. Based on our findings, we propose two novel methods to enhance video quality and enable text-guided video editing. These methods rely entirely on lightweight manipulation of the attention matrices in T2V models. The efficacy and effectiveness of our methods are further validated through experimental evaluation across multiple datasets.","authors":["Bingyan Liu","Chengyu Wang","Tongtong Su","Huan Ten","Jun Huang","Kailing Guo","Kui Jia"],"url":"https://arxiv.org/abs/2504.12027"}
{"created":"2025-04-18","title":"Bayesian dynamic borrowing considering semantic similarity between outcomes for disproportionality analysis in FAERS","abstract":"We present a Bayesian dynamic borrowing (BDB) approach to enhance the quantitative identification of adverse events (AEs) in spontaneous reporting systems (SRSs). The method embeds a robust meta-analytic predictive (MAP) prior within a Bayesian hierarchical model and incorporates semantic similarity measures (SSMs) to enable weighted information sharing from MedDRA Preferred Terms (PTs) that are clinically similar to the target PT. This continuous similarity-based borrowing addresses limitation of rigid hierarchical grouping in current disproportionality analysis (DPA).","authors":["Fran\\c{c}ois Haguinet","Jeffery L Painter","Gregory E Powell","Andrea Callegaro","Andrew Bate"],"url":"https://arxiv.org/abs/2504.12052"}
{"created":"2025-04-18","title":"DC-SAM: In-Context Segment Anything in Images and Videos via Dual Consistency","abstract":"Given a single labeled example, in-context segmentation aims to segment corresponding objects. This setting, known as one-shot segmentation in few-shot learning, explores the segmentation model's generalization ability and has been applied to various vision tasks, including scene understanding and image/video editing. While recent Segment Anything Models have achieved state-of-the-art results in interactive segmentation, these approaches are not directly applicable to in-context segmentation. In this work, we propose the Dual Consistency SAM (DC-SAM) method based on prompt-tuning to adapt SAM and SAM2 for in-context segmentation of both images and videos. Our key insights are to enhance the features of the SAM's prompt encoder in segmentation by providing high-quality visual prompts. When generating a mask prior, we fuse the SAM features to better align the prompt encoder. Then, we design a cycle-consistent cross-attention on fused features and initial visual prompts. Next, a dual-branch design is provided by using the discriminative positive and negative prompts in the prompt encoder. Furthermore, we design a simple mask-tube training strategy to adopt our proposed dual consistency method into the mask tube. Although the proposed DC-SAM is primarily designed for images, it can be seamlessly extended to the video domain with the support of SAM2. Given the absence of in-context segmentation in the video domain, we manually curate and construct the first benchmark from existing video segmentation datasets, named In-Context Video Object Segmentation (IC-VOS), to better assess the in-context capability of the model. Extensive experiments demonstrate that our method achieves 55.5 (+1.4) mIoU on COCO-20i, 73.0 (+1.1) mIoU on PASCAL-5i, and a J&amp;F score of 71.52 on the proposed IC-VOS benchmark. Our source code and benchmark are available at https://github.com/zaplm/DC-SAM.","authors":["Mengshi Qi","Pengfei Zhu","Xiangtai Li","Xiaoyang Bi","Lu Qi","Huadong Ma","Ming-Hsuan Yang"],"url":"https://arxiv.org/abs/2504.12080"}
{"created":"2025-04-18","title":"Second-order Conditional Gradient Sliding","abstract":"Constrained second-order convex optimization algorithms are the method of choice when a high accuracy solution to a problem is needed, due to their local quadratic convergence. These algorithms require the solution of a constrained quadratic subproblem at every iteration. We present the \\emph{Second-Order Conditional Gradient Sliding} (SOCGS) algorithm, which uses a projection-free algorithm to solve the constrained quadratic subproblems inexactly. When the feasible region is a polytope the algorithm converges quadratically in primal gap after a finite number of linearly convergent iterations. Once in the quadratic regime the SOCGS algorithm requires $\\mathcal{O}(\\log(\\log 1/\\varepsilon))$ first-order and Hessian oracle calls and $\\mathcal{O}(\\log (1/\\varepsilon) \\log(\\log1/\\varepsilon))$ linear minimization oracle calls to achieve an $\\varepsilon$-optimal solution. This algorithm is useful when the feasible region can only be accessed efficiently through a linear optimization oracle, and computing first-order information of the function, although possible, is costly.","authors":["Alejandro Carderera","Sebastian Pokutta"],"url":"https://arxiv.org/abs/2002.08907"}
{"created":"2025-04-18","title":"Avoidability beyond paths","abstract":"The concept of avoidable paths in graphs was introduced by Beisegel, Chudnovsky, Gurvich, Milani\\v{c}, and Servatius in 2019 as a common generalization of avoidable vertices and simplicial paths. In 2020, Bonamy, Defrain, Hatzel, and Thiebaut proved that every graph containing an induced path of order $k$ also contains an avoidable induced path of the same order. They also asked whether one could generalize this result to other avoidable structures, leaving the notion of avoidability up to interpretation. In this paper we address this question: we specify the concept of avoidability for arbitrary graphs equipped with two terminal vertices. We provide both positive and negative results, some of which appear to be related to the recent work by Chudnovsky, Norin, Seymour, and Turcotte [arXiv:2301.13175].","authors":["Vladimir Gurvich","Matja\\v{z} Krnc","Martin Milani\\v{c}","Mikhail Vyalyi"],"url":"https://arxiv.org/abs/2208.12803"}
{"created":"2025-04-18","title":"Learning from Similar Linear Representations: Adaptivity, Minimaxity, and Robustness","abstract":"Representation multi-task learning (MTL) has achieved tremendous success in practice. However, the theoretical understanding of these methods is still lacking. Most existing theoretical works focus on cases where all tasks share the same representation, and claim that MTL almost always improves performance. Nevertheless, as the number of tasks grows, assuming all tasks share the same representation is unrealistic. Furthermore, empirical findings often indicate that a shared representation does not necessarily improve single-task learning performance. In this paper, we aim to understand how to learn from tasks with \\textit{similar but not exactly the same} linear representations, while dealing with outlier tasks. Assuming a known intrinsic dimension, we propose a penalized empirical risk minimization method and a spectral method that are \\textit{adaptive} to the similarity structure and \\textit{robust} to outlier tasks. Both algorithms outperform single-task learning when representations across tasks are sufficiently similar and the proportion of outlier tasks is small. Moreover, they always perform at least as well as single-task learning, even when the representations are dissimilar. We provide information-theoretic lower bounds to demonstrate that both methods are nearly \\textit{minimax} optimal in a large regime, with the spectral method being optimal in the absence of outlier tasks. Additionally, we introduce a thresholding algorithm to adapt to an unknown intrinsic dimension. We conduct extensive numerical experiments to validate our theoretical findings.","authors":["Ye Tian","Yuqi Gu","Yang Feng"],"url":"https://arxiv.org/abs/2303.17765"}
{"created":"2025-04-18","title":"Evaluation of Active Feature Acquisition Methods for Time-varying Feature Settings","abstract":"Machine learning methods often assume that input features are available at no cost. However, in domains like healthcare, where acquiring features could be expensive or harmful, it is necessary to balance a feature's acquisition cost against its predictive value. The task of training an AI agent to decide which features to acquire is called active feature acquisition (AFA). By deploying an AFA agent, we effectively alter the acquisition strategy and trigger a distribution shift. To safely deploy AFA agents under this distribution shift, we present the problem of active feature acquisition performance evaluation (AFAPE). We examine AFAPE under i) a no direct effect (NDE) assumption, stating that acquisitions do not affect the underlying feature values; and ii) a no unobserved confounding (NUC) assumption, stating that retrospective feature acquisition decisions were only based on observed features. We show that one can apply missing data methods under the NDE assumption and offline reinforcement learning under the NUC assumption. When NUC and NDE hold, we propose a novel semi-offline reinforcement learning framework. This framework requires a weaker positivity assumption and introduces three new estimators: A direct method (DM), an inverse probability weighting (IPW), and a double reinforcement learning (DRL) estimator.","authors":["Henrik von Kleist","Alireza Zamanian","Ilya Shpitser","Narges Ahmidi"],"url":"https://arxiv.org/abs/2312.01530"}
{"created":"2025-04-18","title":"MCANet: Medical Image Segmentation with Multi-Scale Cross-Axis Attention","abstract":"Efficiently capturing multi-scale information and building long-range dependencies among pixels are essential for medical image segmentation because of the various sizes and shapes of the lesion regions or organs. In this paper, we present Multi-scale Cross-axis Attention (MCA) to solve the above challenging issues based on the efficient axial attention. Instead of simply connecting axial attention along the horizontal and vertical directions sequentially, we propose to calculate dual cross attentions between two parallel axial attentions to capture global information better. To process the significant variations of lesion regions or organs in individual sizes and shapes, we also use multiple convolutions of strip-shape kernels with different kernel sizes in each axial attention path to improve the efficiency of the proposed MCA in encoding spatial information. We build the proposed MCA upon the MSCAN backbone, yielding our network, termed MCANet. Our MCANet with only 4M+ parameters performs even better than most previous works with heavy backbones (e.g., Swin Transformer) on four challenging tasks, including skin lesion segmentation, nuclei segmentation, abdominal multi-organ segmentation, and polyp segmentation. Code is available at https://github.com/haoshao-nku/medical_seg.","authors":["Hao Shao","Quansheng Zeng","Qibin Hou","Jufeng Yang"],"url":"https://arxiv.org/abs/2312.08866"}
{"created":"2025-04-18","title":"Cluster-based classification with neural ODEs via control","abstract":"We address binary classification using neural ordinary differential equations from the perspective of simultaneous control of $N$ data points. We consider a single-neuron architecture with parameters fixed as piecewise constant functions of time. In this setting, the model complexity can be quantified by the number of control switches. Previous work has shown that classification can be achieved using a point-by-point strategy that requires $O(N)$ switches. We propose a new control method that classifies any arbitrary dataset by sequentially steering clusters of $d$ points, thereby reducing the complexity to $O(N/d)$ switches. The optimality of this result, particularly in high dimensions, is supported by some numerical experiments. Our complexity bound is sufficient but often conservative because same-class points tend to appear in larger clusters, simplifying classification. This motivates studying the probability distribution of the number of switches required. We introduce a simple control method that imposes a collinearity constraint on the parameters, and analyze a worst-case scenario where both classes have the same size and all points are i.i.d. Our results highlight the benefits of high-dimensional spaces, showing that classification using constant controls becomes more probable as $d$ increases.","authors":["Antonio \\'Alvarez-L\\'opez","Rafael Orive-Illera","Enrique Zuazua"],"url":"https://arxiv.org/abs/2312.13807"}
{"created":"2025-04-18","title":"Growing Trees and Amoebas' Replications","abstract":"An amoeba is a tree together with instructions how to iteratively grow trees by adding paths of a fixed length $\\ell$. This paper analyses such a growth process. An amoeba is mortal if all versions of the process are finite, and it is immortal if they are all infinite. We obtain some necessary and some sufficient conditions for mortality. In particular, for growing caterpillars in the case $\\ell=1$ we characterize mortal amoebas. We discuss variations of the mortality concept, conjecture that some of them are equivalent, and support this conjecture for $\\ell\\in\\{1,2\\}$.","authors":["Vladimir Gurvich","Matja\\v{z} Krnc","Mikhail Vyalyi"],"url":"https://arxiv.org/abs/2401.07484"}
{"created":"2025-04-18","title":"Lower Bounds for Unitary Property Testing with Proofs and Advice","abstract":"In unitary property testing a quantum algorithm, also known as a tester, is given query access to a black-box unitary and has to decide whether it satisfies some property. We propose a new technique for proving lower bounds on the quantum query complexity of unitary property testing and related problems, which utilises its connection to unitary channel discrimination. The main advantage of this technique is that all obtained lower bounds hold for any $\\mathsf{C}$-tester with $\\mathsf{C} \\subseteq \\mathsf{QMA}(2)/\\mathsf{qpoly}$, showing that even having access to both (unentangled) quantum proofs and advice does not help for many unitary property testing problems. We apply our technique to prove lower bounds for problems like quantum phase estimation, the entanglement entropy problem, quantum Gibbs sampling and more, removing all logarithmic factors in the lower bounds obtained by the sample-to-query lifting theorem of Wang and Zhang (2023). As a direct corollary, we show that there exist quantum oracles relative to which $\\mathsf{QMA}(2) \\not\\supset \\mathsf{SBQP}$ and $\\mathsf{QMA}/\\mathsf{qpoly} \\not\\supset \\mathsf{SBQP}$. The former shows that, at least in a black-box way, having unentangled quantum proofs does not help in solving problems that require high precision.","authors":["Jordi Weggemans"],"url":"https://arxiv.org/abs/2401.07912"}
{"created":"2025-04-18","title":"The weakness of finding descending sequences in ill-founded linear orders","abstract":"We explore the Weihrauch degree of the problems ``find a bad sequence in a non-well quasi order'' ($\\mathsf{BS}$) and ``find a descending sequence in an ill-founded linear order'' ($\\mathsf{DS}$). We prove that $\\mathsf{DS}$ is strictly Weihrauch reducible to $\\mathsf{BS}$, correcting our mistaken claim in [arXiv:2010.03840]. This is done by separating their respective first-order parts. On the other hand, we show that $\\mathsf{BS}$ and $\\mathsf{DS}$ have the same finitary and deterministic parts, confirming that $\\mathsf{BS}$ and $\\mathsf{DS}$ have very similar uniform computational strength. We prove that K\\\"onig's lemma $\\mathsf{KL}$ and the problem $\\mathsf{wList}_{2^{\\mathbb{N}},\\leq\\omega}$ of enumerating a given non-empty countable closed subset of $2^{\\mathbb{N}}$ are not Weihrauch reducible to $\\mathsf{DS}$ or $\\mathsf{BS}$, resolving two main open questions raised in [arXiv:2010.03840]. We also answer the question, raised in [arXiv:1804.10968], on the existence of a ``parallel quotient'' operator, and study the behavior of $\\mathsf{BS}$ and $\\mathsf{DS}$ under the quotient with some known problems.","authors":["Jun Le Goh","Arno Pauly","Manlio Valenti"],"url":"https://arxiv.org/abs/2401.11807"}
{"created":"2025-04-18","title":"Unveiling Molecular Moieties through Hierarchical Grad-CAM Graph Explainability","abstract":"Background: Virtual Screening (VS) has become an essential tool in drug discovery, enabling the rapid and cost-effective identification of potential bioactive molecules. Among recent advancements, Graph Neural Networks (GNNs) have gained prominence for their ability to model complex molecular structures using graph-based representations. However, the integration of explainable methods to elucidate the specific contributions of molecular substructures to biological activity remains a significant challenge. This limitation hampers both the interpretability of predictive models and the rational design of novel therapeutics.\\\\ Results: We trained 20 GNN models on a dataset of small molecules with the goal of predicting their activity on 20 distinct protein targets from the Kinase family. These classifiers achieved state-of-the-art performance in virtual screening tasks, demonstrating high accuracy and robustness on different targets. Building upon these models, we implemented the Hierarchical Grad-CAM graph Explainer (HGE) framework, enabling an in-depth analysis of the molecular moieties driving protein-ligand binding stabilization. HGE exploits Grad-CAM explanations at the atom, ring, and whole-molecule levels, leveraging the message-passing mechanism to highlight the most relevant chemical moieties. Validation against experimental data from the literature confirmed the ability of the explainer to recognize a molecular pattern of drugs and correctly annotate them to the known target. Conclusion: Our approach may represent a valid support to shorten both the screening and the hit discovery process. Detailed knowledge of the molecular substructures that play a role in the binding process can help the computational chemist to gain insights into the structure optimization, as well as in drug repurposing tasks.","authors":["Salvatore Contino","Paolo Sortino","Maria Rita Gulotta","Ugo Perricone","Roberto Pirrone"],"url":"https://arxiv.org/abs/2402.01744"}
{"created":"2025-04-18","title":"Spectral Antisymmetry of Twisted Graph Adjacency","abstract":"We address a prime counting problem across the homology classes of a graph, presenting a graph-theoretical Dirichlet-type analogue of the prime number theorem. The main machinery we have developed and employed is a spectral antisymmetry theorem, revealing that the spectra of the twisted graph adjacency matrices have an antisymmetric distribution over the character group of the graph with a special character called the canonical character being an extremum. Additionally, we derive some trace formulas based on the twisted adjacency matrices as part of our analysis.","authors":["Ye Luo","Arindam Roy"],"url":"https://arxiv.org/abs/2403.01550"}
{"created":"2025-04-18","title":"Mining higher-order triadic interactions","abstract":"Complex systems often involve higher-order interactions which require us to go beyond their description in terms of pairwise networks. Triadic interactions are a fundamental type of higher-order interaction that occurs when one node regulates the interaction between two other nodes. Triadic interactions are found in a large variety of biological systems, from neuron-glia interactions to gene-regulation and ecosystems. However, triadic interactions have so far been mostly neglected. In this article, we propose a theoretical model that demonstrates that triadic interactions can modulate the mutual information between the dynamical state of two linked nodes. Leveraging this result, we propose the Triadic Interaction Mining (TRIM) algorithm to mine triadic interactions from node metadata, and we apply this framework to gene expression data, finding new candidates for triadic interactions relevant for Acute Myeloid Leukemia. Our work reveals important aspects of higher-order triadic interactions that are often ignored, yet can transform our understanding of complex systems and be applied to a large variety of systems ranging from biology to the climate.","authors":["Marta Niedostatek","Anthony Baptista","Jun Yamamoto","Jurgen Kurths","Ruben Sanchez Garcia","Ben MacArthur","Ginestra Bianconi"],"url":"https://arxiv.org/abs/2404.14997"}
{"created":"2025-04-18","title":"Dynamic angular synchronization under smoothness constraints","abstract":"Given an undirected measurement graph $\\mathcal{H} = ([n], \\mathcal{E})$, the classical angular synchronization problem consists of recovering unknown angles $\\theta_1^*,\\dots,\\theta_n^*$ from a collection of noisy pairwise measurements of the form $(\\theta_i^* - \\theta_j^*) \\mod 2\\pi$, for all $\\{i,j\\} \\in \\mathcal{E}$. This problem arises in a variety of applications, including computer vision, time synchronization of distributed networks, and ranking from pairwise comparisons. In this paper, we consider a dynamic version of this problem where the angles, and also the measurement graphs evolve over $T$ time points. Assuming a smoothness condition on the evolution of the latent angles, we derive three algorithms for joint estimation of the angles over all time points. Moreover, for one of the algorithms, we establish non-asymptotic recovery guarantees for the mean-squared error (MSE) under different statistical models. In particular, we show that the MSE converges to zero as $T$ increases under milder conditions than in the static setting. This includes the setting where the measurement graphs are highly sparse and disconnected, and also when the measurement noise is large and can potentially increase with $T$. We complement our theoretical results with experiments on synthetic data.","authors":["Ernesto Araya","Mihai Cucuringu","Hemant Tyagi"],"url":"https://arxiv.org/abs/2406.04071"}
{"created":"2025-04-18","title":"ScoreFusion: Fusing Score-based Generative Models via Kullback-Leibler Barycenters","abstract":"We introduce ScoreFusion, a theoretically grounded method for fusing multiple pre-trained diffusion models that are assumed to generate from auxiliary populations. ScoreFusion is particularly useful for enhancing the generative modeling of a target population with limited observed data. Our starting point considers the family of KL barycenters of the auxiliary populations, which is proven to be an optimal parametric class in the KL sense, but difficult to learn. Nevertheless, by recasting the learning problem as score matching in denoising diffusion, we obtain a tractable way of computing the optimal KL barycenter weights. We prove a dimension-free sample complexity bound in total variation distance, provided that the auxiliary models are well-fitted for their own task and the auxiliary tasks combined capture the target well. The sample efficiency of ScoreFusion is demonstrated by learning handwritten digits. We also provide a simple adaptation of a Stable Diffusion denoising pipeline that enables sampling from the KL barycenter of two auxiliary checkpoints; on a portrait generation task, our method produces faces that enhance population heterogeneity relative to the auxiliary distributions.","authors":["Hao Liu","Junze Tony Ye","Jose Blanchet","Nian Si"],"url":"https://arxiv.org/abs/2406.19619"}
{"created":"2025-04-18","title":"DrivAerML: High-Fidelity Computational Fluid Dynamics Dataset for Road-Car External Aerodynamics","abstract":"Machine Learning (ML) has the potential to revolutionise the field of automotive aerodynamics, enabling split-second flow predictions early in the design process. However, the lack of open-source training data for realistic road cars, using high-fidelity CFD methods, represents a barrier to their development. To address this, a high-fidelity open-source (CC-BY-SA) public dataset for automotive aerodynamics has been generated, based on 500 parametrically morphed variants of the widely-used DrivAer notchback generic vehicle. Mesh generation and scale-resolving CFD was executed using consistent and validated automatic workflows representative of the industrial state-of-the-art. Geometries and rich aerodynamic data are published in open-source formats. To our knowledge, this is the first large, public-domain dataset for complex automotive configurations generated using high-fidelity CFD.","authors":["Neil Ashton","Charles Mockett","Marian Fuchs","Louis Fliessbach","Hendrik Hetmann","Thilo Knacke","Norbert Schonwald","Vangelis Skaperdas","Grigoris Fotiadis","Astrid Walle","Burkhard Hupertz","Danielle Maddix"],"url":"https://arxiv.org/abs/2408.11969"}
{"created":"2025-04-18","title":"Sequential Kernelized Stein Discrepancy","abstract":"We present a sequential version of the kernelized Stein discrepancy goodness-of-fit test, which allows for conducting goodness-of-fit tests for unnormalized densities that are continuously monitored and adaptively stopped. That is, the sample size need not be fixed prior to data collection; the practitioner can choose whether to stop the test or continue to gather evidence at any time while controlling the false discovery rate. In stark contrast to related literature, we do not impose uniform boundedness on the Stein kernel. Instead, we exploit the potential boundedness of the Stein kernel at arbitrary point evaluations to define test martingales, that give way to the subsequent novel sequential tests. We prove the validity of the test, as well as an asymptotic lower bound for the logarithmic growth of the wealth process under the alternative. We further illustrate the empirical performance of the test with a variety of distributions, including restricted Boltzmann machines.","authors":["Diego Martinez-Taboada","Aaditya Ramdas"],"url":"https://arxiv.org/abs/2409.17505"}
{"created":"2025-04-18","title":"Mesh-Informed Reduced Order Models for Aneurysm Rupture Risk Prediction","abstract":"The complexity of the cardiovascular system needs to be accurately reproduced in order to promptly acknowledge health conditions; to this aim, advanced multifidelity and multiphysics numerical models are crucial. On one side, Full Order Models (FOMs) deliver accurate hemodynamic assessments, but their high computational demands hinder their real-time clinical application. In contrast, Reduced Order Models (ROMs) provide more efficient yet accurate solutions, essential for personalized healthcare and timely clinical decision-making. In this work, we explore the application of computational fluid dynamics (CFD) in cardiovascular medicine by integrating FOMs with ROMs for predicting the risk of aortic aneurysm growth and rupture. Wall Shear Stress (WSS) and the Oscillatory Shear Index (OSI), sampled at different growth stages of the thoracic aortic aneurysm, are predicted by means of Graph Neural Networks (GNNs). GNNs exploit the natural graph structure of the mesh obtained by the Finite Volume (FV) discretization, taking into account the spatial local information, regardless of the dimension of the input graph. Our experimental validation framework yields promising results, confirming our method as a valid alternative that overcomes the curse of dimensionality.","authors":["Giuseppe Alessio D'Inverno","Saeid Moradizadeh","Sajad Salavatidezfouli","Pasquale Claudio Africa","Gianluigi Rozza"],"url":"https://arxiv.org/abs/2410.03802"}
{"created":"2025-04-18","title":"dsld: A Socially Relevant Tool for Teaching Statistics","abstract":"The growing power of data science can play a crucial role in addressing social discrimination, necessitating nuanced understanding and effective mitigation strategies for biases. \"Data Science Looks At Discrimination\" (DSLD) is an R and Python package designed to provide users with a comprehensive toolkit of statistical and graphical methods for assessing possible discrimination related to protected groups such as race, gender, and age. The package addresses critical issues by identifying and mitigating confounders and reducing bias against protected groups in prediction algorithms.","authors":["Taha Abdullah","Arjun Ashok","Brandon Zarate","Shubhada Martha","Billy Ouattara","Norman Matloff","Aditya Mittal"],"url":"https://arxiv.org/abs/2411.04228"}
{"created":"2025-04-18","title":"Multi-Parameter Molecular MRI Quantification using Physics-Informed Self-Supervised Learning","abstract":"Biophysical model fitting plays a key role in obtaining quantitative parameters from physiological signals and images. However, the model complexity for molecular magnetic resonance imaging (MRI) often translates into excessive computation time, which makes clinical use impractical. Here, we present a generic computational approach for solving the parameter extraction inverse problem posed by ordinary differential equation (ODE) modeling coupled with experimental measurement of the system dynamics. This is achieved by formulating a numerical ODE solver to function as a step-wise analytical one, thereby making it compatible with automatic differentiation-based optimization. This enables efficient gradient-based model fitting, and provides a new approach to parameter quantification based on self-supervised learning from a single data observation. The neural-network-based train-by-fit pipeline was used to quantify semisolid magnetization transfer (MT) and chemical exchange saturation transfer (CEST) amide proton exchange parameters in the human brain, in an in-vivo molecular MRI study (n = 4). The entire pipeline of the first whole brain quantification was completed in 18.3 $\\pm$ 8.3 minutes. Reusing the single-subject-trained network for inference in new subjects took 1.0 $\\pm$ 0.2 s, to provide results in agreement with literature values and scan-specific fit results.","authors":["Alex Finkelstein","Nikita Vladimirov","Moritz Zaiss","Or Perlman"],"url":"https://arxiv.org/abs/2411.06447"}
{"created":"2025-04-18","title":"Training a neural netwok for data reduction and better generalization","abstract":"At the time of environmental concerns about artificial intelligence, in particular its need for greedy storage and computation, sparsity inducing neural networks offer a promising path towards frugality and solution for less waste.","authors":["Sylvain Sardy","Maxime van Cutsem","Xiaoyu Ma"],"url":"https://arxiv.org/abs/2411.17180"}
{"created":"2025-04-18","title":"Governance as a complex, networked, democratic, satisfiability problem","abstract":"Democratic governments comprise a subset of a population whose goal is to produce coherent decisions, solving societal challenges while respecting the will of the people. New governance frameworks represent this as a social network rather than as a hierarchical pyramid with centralized authority. But how should this network be structured? We model the decisions a population must make as a satisfiability problem and the structure of information flow involved in decision-making as a social hypergraph. This framework allows to consider different governance structures, from dictatorships to direct democracy. Between these extremes, we find a regime of effective governance where small overlapping decision groups make specific decisions and share information. Effective governance allows even incoherent or polarized populations to make coherent decisions at low coordination costs. Beyond simulations, our conceptual framework can explore a wide range of governance strategies and their ability to tackle decision problems that challenge standard governments.","authors":["Laurent H\\'ebert-Dufresne","Nicholas W. Landry","Juniper Lovato","Jonathan St-Onge","Jean-Gabriel Young","Marie-\\`Eve Couture-M\\'enard","St\\'ephane Bernatchez","Catherine Choquette","Alan A. Cohen"],"url":"https://arxiv.org/abs/2412.03421"}
{"created":"2025-04-18","title":"Reconfigurable Holographic Surface-aided Distributed MIMO Radar Systems","abstract":"Distributed phased Multiple-Input Multiple-Output (phased-MIMO) radar systems have attracted wide attention in target detection and tracking. However, the phase-shifting circuits in phased subarrays contribute to high power consumption and hardware cost. To address this issue, an energy-efficient and cost-efficient metamaterial antenna array, i.e., reconfigurable holographic surface (RHS), has been developed. In this letter, we propose RHS-aided distributed MIMO radar systems to achieve more accurate multi-target detection under equivalent power consumption and hardware cost as that of distributed phased-MIMO radar systems. Different from phased arrays, the RHS achieves beam steering by regulating the radiation amplitude of its elements, and thus conventional beamforming schemes designed for phased arrays are no longer applicable. Aiming to maximize detection accuracy, we design an amplitude-controlled beamforming scheme for multiple RHS transceiver subarrays. The simulations validate the superiority of the proposed scheme over the distributed phased-MIMO radar scheme and reveal the optimal allocation of spatial diversity and coherent processing gain that leads to the best system performance when hardware resources are fixed.","authors":["Qian Li","Ziang Yang","Dou Li","Hongliang Zhang"],"url":"https://arxiv.org/abs/2412.06279"}
{"created":"2025-04-18","title":"AI and Deep Learning for THz Ultra-Massive MIMO: From Model-Driven Approaches to Foundation Models","abstract":"In this paper, we explore the potential of artificial intelligence (AI) to address challenges in terahertz ultra-massive multiple-input multiple-output (THz UM-MIMO) systems. We identify three key challenges for transceiver design: \"hard to compute,\" \"hard to model,\" and \"hard to measure,\" and argue that AI can provide promising solutions. We propose three research roadmaps for AI algorithms tailored to THz UM-MIMO systems. The first, model-driven deep learning (DL), emphasizes leveraging domain knowledge and using AI to enhance bottleneck modules in established signal processing or optimization frameworks. We discuss four steps: algorithmic frameworks, basis algorithms, loss function design, and neural architecture design. The second roadmap presents channel station information (CSI) foundation models to unify transceiver module design by focusing on the wireless channel. We propose a compact foundation model to estimate wireless channel score functions, serving as a prior for designing transceiver modules. We outline four steps: general frameworks, conditioning, site-specific adaptation, and joint design of CSI models and model-driven DL. The third roadmap explores applying pre-trained large language models (LLMs) to THz UM-MIMO systems, with applications in estimation, optimization, searching, network management, and protocol understanding. Finally, we discuss open problems and future research directions.","authors":["Wentao Yu","Hengtao He","Shenghui Song","Jun Zhang","Linglong Dai","Lizhong Zheng","Khaled B. Letaief"],"url":"https://arxiv.org/abs/2412.09839"}
{"created":"2025-04-18","title":"A Shapley Value Estimation Speedup for Efficient Explainable Quantum AI","abstract":"This work focuses on developing efficient post-hoc explanations for quantum AI algorithms. In classical contexts, the cooperative game theory concept of the Shapley value adapts naturally to post-hoc explanations, where it can be used to identify which factors are important in an AI's decision-making process. An interesting question is how to translate Shapley values to the quantum setting and whether quantum effects could be used to accelerate their calculation. We propose quantum algorithms that can extract Shapley values within some confidence interval. Our method is capable of quadratically outperforming classical Monte Carlo approaches to approximating Shapley values up to polylogarithmic factors in various circumstances. We demonstrate the validity of our approach empirically with specific voting games and provide rigorous proofs of performance for general cooperative games.","authors":["Iain Burge","Michel Barbeau","Joaquin Garcia-Alfaro"],"url":"https://arxiv.org/abs/2412.14639"}
{"created":"2025-04-18","title":"SymmCD: Symmetry-Preserving Crystal Generation with Diffusion Models","abstract":"Generating novel crystalline materials has the potential to lead to advancements in fields such as electronics, energy storage, and catalysis. The defining characteristic of crystals is their symmetry, which plays a central role in determining their physical properties. However, existing crystal generation methods either fail to generate materials that display the symmetries of real-world crystals, or simply replicate the symmetry information from examples in a database. To address this limitation, we propose SymmCD, a novel diffusion-based generative model that explicitly incorporates crystallographic symmetry into the generative process. We decompose crystals into two components and learn their joint distribution through diffusion: 1) the asymmetric unit, the smallest subset of the crystal which can generate the whole crystal through symmetry transformations, and; 2) the symmetry transformations needed to be applied to each atom in the asymmetric unit. We also use a novel and interpretable representation for these transformations, enabling generalization across different crystallographic symmetry groups. We showcase the competitive performance of SymmCD on a subset of the Materials Project, obtaining diverse and valid crystals with realistic symmetries and predicted properties.","authors":["Daniel Levy","Siba Smarak Panigrahi","S\\'ekou-Oumar Kaba","Qiang Zhu","Kin Long Kelvin Lee","Mikhail Galkin","Santiago Miret","Siamak Ravanbakhsh"],"url":"https://arxiv.org/abs/2502.03638"}
{"created":"2025-04-18","title":"C2GM: Cascading conditional generative cartography framework for multi-scale tile map generation with geographic feature constraints","abstract":"Multi-scale maps are essential representations of surveying and cartographic results, serving as fundamental components of geographic services. Current image generation networks can quickly produce map tiles from remote-sensing images. However, generative models designed for natural images often focus on texture features, neglecting the unique characteristics of remote-sensing features and the scale attributes of tile maps. This limitation in generative models impairs the accurate representation of geographic information, and the quality of tile map generation still needs improvement. Diffusion models have demonstrated remarkable success in various image generation tasks, highlighting their potential to address this challenge. This paper presents C2GM, a novel framework for generating multi-scale tile maps through conditional guided diffusion and multi-scale cascade generation. Specifically, we implement a conditional feature fusion encoder to extract object priors from remote sensing images and cascade reference double branch input, ensuring an accurate representation of complex features. Low-level generated tiles act as constraints for high-level map generation, enhancing visual continuity. Moreover, we incorporate map scale modality information using CLIP to simulate the relationship between map scale and cartographic generalization in tile maps. Extensive experimental evaluations demonstrate that C2GM consistently achieves the state-of-the-art (SOTA) performance on all metrics, facilitating the rapid and effective generation of multi-scale large-format maps for emergency response and remote mapping applications.","authors":["Chenxing Sun","Yongyang Xu","Xuwei Xu","Xixi Fan","Jing Bai","Xiechun Lu","Zhanlong Chen"],"url":"https://arxiv.org/abs/2502.04991"}
{"created":"2025-04-18","title":"Polygraphic resolutions for operated algebras","abstract":"This paper introduces the structure of operated polygraphs as a categorical model for rewriting in operated algebras, generalizing Gr\\\"obner-Shirshov bases with non-monomial termination orders. We provide a combinatorial description of critical branchings of operated polygraphs using the structure of polyautomata that we introduce in this paper. Polyautomata extend linear polygraphs equipped with an operator structure formalized by a pushdown automaton. We show how to construct polygraphic resolutions of free operated algebras from their confluent and terminating presentations. Finally, we apply our constructions to several families of operated algebras, including Rota-Baxter algebras, differential algebras, and differential Rota-Baxter algebras.","authors":["Zuan Liu","Philippe Malbos"],"url":"https://arxiv.org/abs/2502.16304"}
{"created":"2025-04-18","title":"Applications of Statistical Field Theory in Deep Learning","abstract":"Deep learning algorithms have made incredible strides in the past decade, yet due to their complexity, the science of deep learning remains in its early stages. Being an experimentally driven field, it is natural to seek a theory of deep learning within the physics paradigm. As deep learning is largely about learning functions and distributions over functions, statistical field theory, a rich and versatile toolbox for tackling complex distributions over functions (fields) is an obvious choice of formalism. Research efforts carried out in the past few years have demonstrated the ability of field theory to provide useful insights on generalization, implicit bias, and feature learning effects. Here we provide a pedagogical review of this emerging line of research.","authors":["Zohar Ringel","Noa Rubin","Edo Mor","Moritz Helias","Inbar Seroussi"],"url":"https://arxiv.org/abs/2502.18553"}
{"created":"2025-04-18","title":"RiboGen: RNA Sequence and Structure Co-Generation with Equivariant MultiFlow","abstract":"Ribonucleic acid (RNA) plays fundamental roles in biological systems, from carrying genetic information to performing enzymatic function. Understanding and designing RNA can enable novel therapeutic application and biotechnological innovation. To enhance RNA design, in this paper we introduce RiboGen, the first deep learning model to simultaneously generate RNA sequence and all-atom 3D structure. RiboGen leverages the standard Flow Matching with Discrete Flow Matching in a multimodal data representation. RiboGen is based on Euclidean Equivariant neural networks for efficiently processing and learning three-dimensional geometry. Our experiments show that RiboGen can efficiently generate chemically plausible and self-consistent RNA samples, suggesting that co-generation of sequence and structure is a competitive approach for modeling RNA.","authors":["Dana Rubin","Allan dos Santos Costa","Manvitha Ponnapati","Joseph Jacobson"],"url":"https://arxiv.org/abs/2503.02058"}
{"created":"2025-04-18","title":"RGB-Phase Speckle: Cross-Scene Stereo 3D Reconstruction via Wrapped Pre-Normalization","abstract":"3D reconstruction garners increasing attention alongside the advancement of high-level image applications, where dense stereo matching (DSM) serves as a pivotal technique. Previous studies often rely on publicly available datasets for training, focusing on modifying network architectures or incorporating specialized modules to extract domain-invariant features and thus improve model robustness. In contrast, inspired by single-frame structured-light phase-shifting encoding, this study introduces RGB-Speckle, a cross-scene 3D reconstruction framework based on an active stereo camera system, designed to enhance robustness. Specifically, we propose a novel phase pre-normalization encoding-decoding method: first, we randomly perturb phase-shift maps and embed them into the three RGB channels to generate color speckle patterns; subsequently, the camera captures phase-encoded images modulated by objects as input to a stereo matching network. This technique effectively mitigates external interference and ensures consistent input data for RGB-Speckle, thereby bolstering cross-domain 3D reconstruction stability. To validate the proposed method, we conduct complex experiments: (1) construct a color speckle dataset for complex scenarios based on the proposed encoding scheme; (2) evaluate the impact of the phase pre-normalization encoding-decoding technique on 3D reconstruction accuracy; and (3) further investigate its robustness across diverse conditions. Experimental results demonstrate that the proposed RGB-Speckle model offers significant advantages in cross-domain and cross-scene 3D reconstruction tasks, enhancing model generalization and reinforcing robustness in challenging environments, thus providing a novel solution for robust 3D reconstruction research.","authors":["Kai Yang","Zijian Bai","Yang Xiao","Xinyu Li","Xiaohan Shi"],"url":"https://arxiv.org/abs/2503.06125"}
{"created":"2025-04-18","title":"Digital Zero-Noise Extrapolation with Quantum Circuit Unoptimization","abstract":"Quantum circuit unoptimization is an algorithm that transforms a quantum circuit into a different circuit that uses more gate operations while maintaining the same unitary transformation. We demonstrate that this method can implement digital zero-noise extrapolation (ZNE), a quantum error mitigation technique. By employing quantum circuit unoptimization as a form of circuit folding, noise can be systematically amplified. The key advantages of this approach are twofold. First, its ability to generate an exponentially increasing number of distinct circuit variants as the noise level is amplified, which allows noise averaging over many circuit instances with slightly different circuit structure which mitigates the effect of biased error propagation because of the significantly altered circuit structure from quantum circuit unoptimization, or highly biased local noise on a quantum processor. Second, quantum circuit unoptimization by design resists circuit simplification back to the original unmodified circuit, making it plausible to use ZNE in contexts where circuit compiler optimization is applied server-side. We evaluate the effectiveness of quantum circuit unoptimization as a noise-scaling method for ZNE in two test cases using depolarizing noise numerical simulations: random quantum volume circuits, where the observable is the heavy output probability, and QAOA circuits for the (unweighted) maximum cut problem on random 3-regular graphs, where the observable is the cut value. We show that using quantum circuit unoptimization to perform ZNE can approximately recover signal from noisy quantum simulations.","authors":["Elijah Pelofske","Vincent Russo"],"url":"https://arxiv.org/abs/2503.06341"}
{"created":"2025-04-18","title":"Error bounds for composite quantum hypothesis testing and a new characterization of the weighted Kubo-Ando geometric means","abstract":"The optimal error exponents of binary composite i.i.d. state discrimination are trivially bounded by the worst-case pairwise exponents of discriminating individual elements of the sets representing the two hypotheses, and in the finite-dimensional classical case, these bounds in fact give exact single-copy expressions for the error exponents. In contrast, in the non-commutative case, the optimal exponents are only known to be expressible in terms of regularized divergences, resulting in formulas that, while conceptually relevant, practically not very useful. In this paper, we develop further an approach initiated in [Mosonyi, Szil\\'agyi, Weiner, IEEE Trans. Inf. Th. 68(2):1032--1067, 2022] to give improved single-copy bounds on the error exponents by comparing not only individual states from the two hypotheses, but also various unnormalized positive semi-definite operators associated to them. Here, we show a number of equivalent characterizations of such operators giving valid bounds, and show that in the commutative case, considering weighted geometric means of the states, and in the case of two states per hypothesis, considering weighted Kubo-Ando geometric means, are optimal for this approach. As a result, we give a new characterization of the weighted Kubo-Ando geometric means as the only $2$-variable operator geometric means that are block additive, tensor multiplicative, and satisfy the arithmetic-geometric mean inequality. We also extend our results to composite quantum channel discrimination, and show an analogous optimality property of the weighted Kubo-Ando geometric means of two quantum channels, a notion that seems to be new. We extend this concept to defining the notion of superoperator perspective function and establish some of its basic properties, which may be of independent interest.","authors":["P\\'eter E. Frenkel","Mil\\'an Mosonyi","P\\'eter Vrana","Mih\\'aly Weiner"],"url":"https://arxiv.org/abs/2503.13379"}
{"created":"2025-04-18","title":"Deep Reinforcement Learning Algorithms for Option Hedging","abstract":"Dynamic hedging is a financial strategy that consists in periodically transacting one or multiple financial assets to offset the risk associated with a correlated liability. Deep Reinforcement Learning (DRL) algorithms have been used to find optimal solutions to dynamic hedging problems by framing them as sequential decision-making problems. However, most previous work assesses the performance of only one or two DRL algorithms, making an objective comparison across algorithms difficult. In this paper, we compare the performance of eight DRL algorithms in the context of dynamic hedging; Monte Carlo Policy Gradient (MCPG), Proximal Policy Optimization (PPO), along with four variants of Deep Q-Learning (DQL) and two variants of Deep Deterministic Policy Gradient (DDPG). Two of these variants represent a novel application to the task of dynamic hedging. In our experiments, we use the Black-Scholes delta hedge as a baseline and simulate the dataset using a GJR-GARCH(1,1) model. Results show that MCPG, followed by PPO, obtain the best performance in terms of the root semi-quadratic penalty. Moreover, MCPG is the only algorithm to outperform the Black-Scholes delta hedge baseline with the allotted computational budget, possibly due to the sparsity of rewards in our environment.","authors":["Andrei Neagu","Fr\\'ed\\'eric Godin","Leila Kosseim"],"url":"https://arxiv.org/abs/2504.05521"}
{"created":"2025-04-18","title":"AI-Assisted Transport of Radioactive Ion Beams","abstract":"Beams of radioactive heavy ions allow researchers to study rare and unstable atomic nuclei, shedding light into the internal structure of exotic nuclei and on how chemical elements are formed in stars. However, the extraction and transport of radioactive beams rely on time-consuming expert-driven tuning methods, where hundreds of parameters are manually optimized. Here, we introduce a system that employs Artificial Intelligence (AI), specifically utilizing Bayesian Optimization, to assist in the transport process of radioactive beams. We apply our methodology to real-life scenarios showing advantages when compared with standard tuning methods. This AI-assisted approach can be extended to other radioactive beam facilities around the world to improve operational efficiency and enhance scientific output.","authors":["Sergio Lopez-Caceres","Daniel Santiago-Gonzalez"],"url":"https://arxiv.org/abs/2504.06469"}
{"created":"2025-04-18","title":"Maximizing Battery Storage Profits via High-Frequency Intraday Trading","abstract":"Maximizing revenue for grid-scale battery energy storage systems in continuous intraday electricity markets requires strategies that are able to seize trading opportunities as soon as new information arrives. This paper introduces and evaluates an automated high-frequency trading strategy for battery energy storage systems trading on the intraday market for power while explicitly considering the dynamics of the limit order book, market rules, and technical parameters. The standard rolling intrinsic strategy is adapted for continuous intraday electricity markets and solved using a dynamic programming approximation that is two to three orders of magnitude faster than an exact mixed-integer linear programming solution. A detailed backtest over a full year of German order book data demonstrates that the proposed dynamic programming formulation does not reduce trading profits and enables the policy to react to every relevant order book update, enabling realistic rapid backtesting. Our results show the significant revenue potential of high-frequency trading: our policy earns 58% more than when re-optimizing only once every hour and 14% more than when re-optimizing once per minute, highlighting that profits critically depend on trading speed. Furthermore, we leverage the speed of our algorithm to train a parametric extension of the rolling intrinsic, increasing yearly revenue by 8.4% out of sample.","authors":["David Schaurecker","David Wozabal","Nils L\\\"ohndorf","Thorsten Staake"],"url":"https://arxiv.org/abs/2504.06932"}
{"created":"2025-04-18","title":"Is Productivity in Quantum Programming Equivalent to Expressiveness?","abstract":"The expressiveness of quantum programming languages plays a crucial role in the efficient and comprehensible representation of quantum algorithms. Unlike classical programming languages, which offer mature and well-defined abstraction mechanisms, quantum languages must integrate cognitively challenging concepts such as superposition, interference and entanglement while maintaining clarity and usability. However, identifying and characterizing differences in expressiveness between quantum programming paradigms remains an open area of study. Our work investigates the landscape of expressiveness through a comparative analysis of hosted quantum programming languages such as Qiskit, Cirq, Qrisp, and quAPL, and standalone languages including Q# and Qmod. We focused on evaluating how different quantum programming languages support the implementation of core quantum algorithms -- Deutsch-Jozsa, Simon, Bernstein-Vazirani, and Grover -- using expressiveness metrics: Lines of Code (LOC), Cyclomatic Complexity (CC), and Halstead Complexity (HC) metrics as proxies for developer productivity. Our findings suggest that different quantum programming paradigms offer distinct trade-offs between expressiveness and productivity, highlighting the importance of language design in quantum software development.","authors":["Francini Corrales-Garro","Danny Valerio-Ram\\'irez","Santiago N\\'u\\~nez-Corrales"],"url":"https://arxiv.org/abs/2504.08876"}
{"created":"2025-04-18","title":"SIFT-50M: A Large-Scale Multilingual Dataset for Speech Instruction Fine-Tuning","abstract":"We introduce SIFT (Speech Instruction Fine-Tuning), a 50M-example dataset designed for instruction fine-tuning and pre-training of speech-text large language models (LLMs). SIFT-50M is built from publicly available speech corpora, which collectively contain 14K hours of speech, and leverages LLMs along with off-the-shelf expert models. The dataset spans five languages, encompassing a diverse range of speech understanding as well as controllable speech generation instructions. Using SIFT-50M, we train SIFT-LLM, which outperforms existing speech-text LLMs on instruction-following benchmarks while achieving competitive performance on foundational speech tasks. To support further research, we also introduce EvalSIFT, a benchmark dataset specifically designed to evaluate the instruction-following capabilities of speech-text LLMs.","authors":["Prabhat Pandey","Rupak Vignesh Swaminathan","K V Vijay Girish","Arunasish Sen","Jian Xie","Grant P. Strimel","Andreas Schwarz"],"url":"https://arxiv.org/abs/2504.09081"}
{"created":"2025-04-18","title":"Computing the Tropical Abel--Jacobi Transform and Tropical Distances for Metric Graphs","abstract":"Metric graphs are important models for capturing the structure of complex data across various domains. While much effort has been devoted to extracting geometric and topological features from graph data, computational aspects of metric graphs as abstract tropical curves remains unexplored. In this paper, we present the first computational and machine learning-driven study of metric graphs from the perspective of tropical algebraic geometry. Specifically, we study the tropical Abel--Jacobi transform, a vectorization of points on a metric graph via the tropical Abel--Jacobi map into its associated flat torus, the tropical Jacobian. We develop algorithms to compute this transform and investigate how the resulting embeddings depend on different combinatorial models of the same metric graph.","authors":["Yueqi Cao","Anthea Monod"],"url":"https://arxiv.org/abs/2504.11619"}
