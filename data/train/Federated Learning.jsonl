{"created": "2025-04-11", "title": "Genetic Programming for Explainable Manifold Learning", "abstract": "Manifold learning techniques play a pivotal role in machine learning by revealing lower-dimensional embeddings within high-dimensional data, thus enhancing both the efficiency and interpretability of data analysis by transforming the data into a lower-dimensional representation. However, a notable challenge with current manifold learning methods is their lack of explicit functional mappings, crucial for explainability in many real-world applications. Genetic programming, known for its interpretable functional tree-based models, has emerged as a promising approach to address this challenge. Previous research leveraged multi-objective GP to balance manifold quality against embedding dimensionality, producing functional mappings across a range of embedding sizes. Yet, these mapping trees often became complex, hindering explainability. In response, in this paper, we introduce Genetic Programming for Explainable Manifold Learning (GP-EMaL), a novel approach that directly penalises tree complexity. Our new method is able to maintain high manifold quality while significantly enhancing explainability and also allows customisation of complexity measures, such as symmetry balancing, scaling, and node complexity, catering to diverse application needs. Our experimental analysis demonstrates that GP-EMaL is able to match the performance of the existing approach in most cases, while using simpler, smaller, and more interpretable tree structures. This advancement marks a significant step towards achieving interpretable manifold learning.", "authors": ["Ben Cravens", "Andrew Lensen", "Paula Maddigan", "Bing Xue"], "url": "https://arxiv.org/abs/2403.14139"}
{"title": "The Key of Parameter Skew in Federated Learning", "url": "https://arxiv.org/abs/2408.11278", "authors": ["Junfeng Liao", "Sifan Wang", "Ye Yuan", "Riquan Zhang"], "created": "2025-04-14", "abstract": "Federated Learning (FL) has emerged as an excellent solution for performing deep learning on different data owners without exchanging raw data. However, statistical heterogeneity in FL presents a key challenge, leading to a phenomenon of skewness in local model parameter distributions that researchers have largely overlooked. In this work, we propose the concept of parameter skew to describe the phenomenon that can substantially affect the accuracy of global model parameter estimation. Additionally, we introduce FedSA, an aggregation strategy to obtain a high-quality global model, to address the implication from parameter skew. Specifically, we categorize parameters into high-dispersion and low-dispersion groups based on the coefficient of variation. For high-dispersion parameters, Micro-Classes (MIC) and Macro-Classes (MAC) represent the dispersion at the micro and macro levels, respectively, forming the foundation of FedSA. To evaluate the effectiveness of FedSA, we conduct extensive experiments with different FL algorithms on three computer vision datasets. FedSA outperforms eight state-of-the-art baselines by about 4.7% in test accuracy."}
{"abstract": "Non-convex Machine Learning problems typically do not adhere to the standard smoothness assumption. Based on empirical findings, Zhang et al. (2020b) proposed a more realistic generalized $(L_0, L_1)$-smoothness assumption, though it remains largely unexplored. Many existing algorithms designed for standard smooth problems need to be revised. However, in the context of Federated Learning, only a few works address this problem but rely on additional limiting assumptions. In this paper, we address this gap in the literature: we propose and analyze new methods with local steps, partial participation of clients, and Random Reshuffling without extra restrictive assumptions beyond generalized smoothness. The proposed methods are based on the proper interplay between clients' and server's stepsizes and gradient clipping. Furthermore, we perform the first analysis of these methods under the Polyak-{\\L} ojasiewicz condition. Our theory is consistent with the known results for standard smooth problems, and our experimental results support the theoretical insights.", "authors": ["Yury Demidovich", "Petr Ostroukhov", "Grigory Malinovsky", "Samuel Horv\\'ath", "Martin Tak\\'a\\v{c}", "Peter Richt\\'arik", "Eduard Gorbunov"], "created": "2025-04-11", "title": "Methods with Local Steps and Random Reshuffling for Generally Smooth Non-Convex Federated Optimization", "url": "https://arxiv.org/abs/2412.02781"}
{"created": "2025-05-01", "title": "Testing CPS with Design Assumptions-Based Metamorphic Relations and Genetic Programming", "abstract": "Cyber-Physical Systems (CPSs) software is used to enforce desired behaviours on physical systems. To test the interaction between the CPS software and the system's physics, engineers provide traces of desired physical states and observe traces of the actual physical states. CPS requirements describe how closely the actual physical traces should track the desired traces. These requirements are typically defined for specific, simple input traces such as step or ramp sequences, and thus are not applicable to arbitrary inputs. This limits the availability of oracles for CPSs. Our recent work proposes an approach to testing CPS using control-theoretical design assumptions instead of requirements. This approach circumvents the oracle problem by leveraging the control-theoretical guarantees that are provided when the design assumptions are satisfied. To address the test case generation and oracle problems, researchers have proposed metamorphic testing, which is based on the study of relations across tests, i.e., metamorphic relations (MRs). In this work, we define MRs based on the design assumptions and explore combinations of these MRs using genetic programming to generate CPS test cases. This enables the generation of CPS input traces with potentially arbitrary shapes, together with associated expected output traces. We use the deviation from the expected output traces to guide the generation of input traces that falsify the MRs. Our experiment results show that the MR-falsification provides engineers with new information, helping them identify passed and failed test cases. Furthermore, we show that the generation of traces that falsify the MRs is a non-trivial problem, which is successfully addressed by our genetic search.", "authors": ["Claudio Mandrioli", "Seung Yeob Shin", "Domenico Bianculli", "Lionel Briand"], "url": "https://arxiv.org/abs/2412.03330"}
{"created": "2025-04-15", "title": "A Benchmarking Environment for Worker Flexibility in Flexible Job Shop Scheduling Problems", "abstract": "In Production Scheduling, the Flexible Job Shop Scheduling Problem (FJSSP) aims to optimize a sequence of operations and assign each to an eligible machine with varying processing times. For integration of the workforce, each machine also requires a worker to be present to process an operation which additionally affects the processing times. The resulting problem is called Flexible Job Shop Scheduling Problem with Worker Flexibility (FJSSP-W). The FJSSP has been approached with various problem representations, including Mixed Integer Linear Programming (MILP), Constrained Programming (CP), and Simulation-based Optimization (SBO). In the latter area in particular, there exists a large number of specialized Evolutionary Algorithms (EA) like Particle Swarm Optimization (PSO) or Genetic Algorithms (GA). Yet, the solvers are often developed for single use cases only, and validated on a few selected test instances, let alone compared with results from solvers using other problem representations. While suitable approaches do also exist, the design of the FJSSP-W instances is not standardized and the algorithms are hardly comparable. This calls for a systematic benchmarking environment that provides a comprehensive set of FJSSP(-W) instances and supports targeted algorithm development. It will facilitate the comparison of algorithmic performance in the face of different problem characteristics. The present paper presents a collection of 402 commonly accepted FJSSP instances and proposes an approach to extend these with worker flexibility. In addition, we present a detailed procedure for the evaluation of scheduling algorithms on these problem sets and provide suitable model representations for this purpose. We provide complexity characteristics for all presented instances as well as baseline results of common commercial solvers to facilitate the validation of new algorithmic developments.", "authors": ["David Hutter", "Thomas Steinberger", "Michael Hellwig"], "url": "https://arxiv.org/abs/2501.16159"}
{"title": "FedRIR: Rethinking Information Representation in Federated Learning", "url": "https://arxiv.org/abs/2502.00859", "authors": ["Yongqiang Huang", "Zerui Shao", "Ziyuan Yang", "Zexin Lu", "Yi Zhang"], "created": "2025-04-15", "abstract": "Mobile and Web-of-Things (WoT) devices at the network edge generate vast amounts of data for machine learning applications, yet privacy concerns hinder centralized model training. Federated Learning (FL) allows clients (devices) to collaboratively train a shared model coordinated by a central server without transfer private data, but inherent statistical heterogeneity among clients presents challenges, often leading to a dilemma between clients' needs for personalized local models and the server's goal of building a generalized global model. Existing FL methods typically prioritize either global generalization or local personalization, resulting in a trade-off between these two objectives and limiting the full potential of diverse client data. To address this challenge, we propose a novel framework that simultaneously enhances global generalization and local personalization by Rethinking Information Representation in the Federated learning process (FedRIR). Specifically, we introduce Masked Client-Specific Learning (MCSL), which isolates and extracts fine-grained client-specific features tailored to each client's unique data characteristics, thereby enhancing personalization. Concurrently, the Information Distillation Module (IDM) refines the global shared features by filtering out redundant client-specific information, resulting in a purer and more robust global representation that enhances generalization. By integrating the refined global features with the isolated client-specific features, we construct enriched representations that effectively capture both global patterns and local nuances, thereby improving the performance of downstream tasks on the client. The code is available at https://github.com/Deep-Imaging-Group/FedRIR."}
{"created": "2025-04-16", "title": "Kozax: Flexible and Scalable Genetic Programming in JAX", "abstract": "Genetic programming is an optimization algorithm inspired by evolution which automatically evolves the structure of interpretable computer programs. The fitness evaluation in genetic programming suffers from high computational requirements, limiting the performance on difficult problems. Consequently, there is no efficient genetic programming framework that is usable for a wide range of tasks. To this end, we developed Kozax, a genetic programming framework that evolves symbolic expressions for arbitrary problems. We implemented Kozax using JAX, a framework for high-performance and scalable machine learning, which allows the fitness evaluation to scale efficiently to large populations or datasets on GPU. Furthermore, Kozax offers constant optimization, custom operator definition and simultaneous evolution of multiple trees. We demonstrate successful applications of Kozax to discover equations of natural laws, recover equations of hidden dynamic variables, evolve a control policy and optimize an objective function. Overall, Kozax provides a general, fast, and scalable library to optimize white-box solutions in the realm of scientific computing.", "authors": ["Sigur de Vries", "Sander W. Keemink", "Marcel A. J. van Gerven"], "url": "https://arxiv.org/abs/2502.03047"}
{"abstract": "As an emerging paradigm of federated learning, asynchronous federated learning offers significant speed advantages over traditional synchronous federated learning. Unlike synchronous federated learning, which requires waiting for all clients to complete updates before aggregation, asynchronous federated learning aggregates the models that have arrived in realtime, greatly improving training speed. However, this mechanism also introduces the issue of client model version inconsistency. When the differences between models of different versions during aggregation become too large, it may lead to conflicts, thereby reducing the models accuracy. To address this issue, this paper proposes an asynchronous federated learning version correction algorithm based on knowledge distillation, named FedADT. FedADT applies knowledge distillation before aggregating gradients, using the latest global model to correct outdated information, thus effectively reducing the negative impact of outdated gradients on the training process. Additionally, FedADT introduces an adaptive weighting function that adjusts the knowledge distillation weight according to different stages of training, helps mitigate the misleading effects caused by the poorer performance of the global model in the early stages of training. This method significantly improves the overall performance of asynchronous federated learning without adding excessive computational overhead. We conducted experimental comparisons with several classical algorithms, and the results demonstrate that FedADT achieves significant improvements over other asynchronous methods and outperforms all methods in terms of convergence speed.", "authors": ["Chaoyi Lu", "Yiding Sun", "Pengbo Li", "Zhichuan Yang"], "created": "2025-04-11", "title": "Corrected with the Latest Version: Make Robust Asynchronous Federated Learning Possible", "url": "https://arxiv.org/abs/2504.04081"}
{"abstract": "Federated Learning (FL) often struggles with data heterogeneity due to the naturally uneven distribution of user data across devices. Federated Neural Architecture Search (NAS) enables collaborative search for optimal model architectures tailored to heterogeneous data to achieve higher accuracy. However, this process is time-consuming due to extensive search space and retraining. To overcome this, we introduce FedMetaNAS, a framework that integrates meta-learning with NAS within the FL context to expedite the architecture search by pruning the search space and eliminating the retraining stage. Our approach first utilizes the Gumbel-Softmax reparameterization to facilitate relaxation of the mixed operations in the search space. We then refine the local search process by incorporating Model-Agnostic Meta-Learning, where a task-specific learner adapts both weights and architecture parameters (alphas) for individual tasks, while a meta learner adjusts the overall model weights and alphas based on the gradient information from task learners. Following the meta-update, we propose soft pruning using the same trick on search space to gradually sparsify the architecture, ensuring that the performance of the chosen architecture remains robust after pruning which allows for immediate use of the model without retraining. Experimental evaluations demonstrate that FedMetaNAS significantly accelerates the search process by more than 50\\% with higher accuracy compared to FedNAS.", "authors": ["Xinyuan Huang", "Jiechao Gao"], "created": "2025-04-11", "title": "Federated Neural Architecture Search with Model-Agnostic Meta Learning", "url": "https://arxiv.org/abs/2504.06457"}
{"abstract": "One global model in federated learning (FL) might not be sufficient to serve many clients with non-IID tasks and distributions. While there has been advances in FL to train multiple global models for better personalization, they only provide limited choices to clients so local finetuning is still indispensable. In this paper, we propose a novel ``FedMerge'' approach that can create a personalized model per client by simply merging multiple global models with automatically optimized and customized weights. In FedMerge, a few global models can serve many non-IID clients, even without further local finetuning. We formulate this problem as a joint optimization of global models and the merging weights for each client. Unlike existing FL approaches where the server broadcasts one or multiple global models to all clients, the server only needs to send a customized, merged model to each client. Moreover, instead of periodically interrupting the local training and re-initializing it to a global model, the merged model aligns better with each client's task and data distribution, smoothening the local-global gap between consecutive rounds caused by client drift. We evaluate FedMerge on three different non-IID settings applied to different domains with diverse tasks and data types, in which FedMerge consistently outperforms existing FL approaches, including clustering-based and mixture-of-experts (MoE) based methods.", "authors": ["Shutong Chen", "Tianyi Zhou", "Guodong Long", "Jing Jiang", "Chengqi Zhang"], "created": "2025-04-11", "title": "FedMerge: Federated Personalization via Model Merging", "url": "https://arxiv.org/abs/2504.06768"}
{"created": "2025-04-16", "title": "GAAPO: Genetic Algorithmic Applied to Prompt Optimization", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across various tasks, with their performance heavily dependent on the quality of input prompts. While prompt engineering has proven effective, it typically relies on manual adjustments, making it time-consuming and potentially suboptimal. This paper introduces GAAPO (Genetic Algorithm Applied to Prompt Optimization), a novel hybrid optimization framework that leverages genetic algorithm principles to evolve prompts through successive generations. Unlike traditional genetic approaches that rely solely on mutation and crossover operations, GAAPO integrates multiple specialized prompt generation strategies within its evolutionary framework. Through extensive experimentation on diverse datasets including ETHOS, MMLU-Pro, and GPQA, our analysis reveals several important point for the future development of automatic prompt optimization methods: importance of the tradeoff between the population size and the number of generations, effect of selection methods on stability results, capacity of different LLMs and especially reasoning models to be able to automatically generate prompts from similar queries... Furthermore, we provide insights into the relative effectiveness of different prompt generation strategies and their evolution across optimization phases. These findings contribute to both the theoretical understanding of prompt optimization and practical applications in improving LLM performance.", "authors": ["Xavier S\\'echeresse", "Jacques-Yves Guilbert--Ly", "Antoine Villedieu de Torcy"], "url": "https://arxiv.org/abs/2504.07157"}
{"created": "2025-05-02", "title": "Probability Estimation and Scheduling Optimization for Battery Swap Stations via LRU-Enhanced Genetic Algorithm and Dual-Factor Decision System", "abstract": "To address the challenges of limited Battery Swap Stations datasets, high operational costs, and fluctuating user charging demand, this research proposes a probability estimation model based on charging pile data and constructs nine scenario-specific battery swap demand datasets. In addition, this study combines Least Recently Used strategy with Genetic Algorithm and incorporates a guided search mechanism, which effectively enhances the global optimization capability. Thus, a dual-factor decision-making based charging schedule optimization system is constructed. Experimental results show that the constructed datasets exhibit stable trend characteristics, adhering to 24-hour and 168-hour periodicity patterns, with outlier ratios consistently below 3.26%, confirming data validity. Compared to baseline, the improved algorithm achieves better fitness individuals in 80% of test regions under the same iterations. When benchmarked against immediate swap-and-charge strategy, our algorithm achieves a peak cost reduction of 13.96%. Moreover, peak user satisfaction reaches 98.57%, while the average iteration time remains below 0.6 seconds, demonstrating good computational efficiency. The complete datasets and optimization algorithm are open-sourced at https://github.com/qingshufan/GA-EVLRU.", "authors": ["Anzhen Li", "Shufan Qing", "Xiaochang Li", "Rui Mao", "Mingchen Feng"], "url": "https://arxiv.org/abs/2504.07453"}
{"created": "2025-04-14", "title": "A Case Study on Evaluating Genetic Algorithms for Early Building Design Optimization: Comparison with Random and Grid Searches", "abstract": "In early-stage architectural design, optimization algorithms are essential for efficiently exploring large and complex design spaces under tight computational constraints. While prior research has benchmarked various optimization methods, their findings often lack generalizability to real-world, domain-specific problems, particularly in early building design optimization for energy performance. This study evaluates the effectiveness of Genetic Algorithms (GAs) for early design optimization, focusing on their ability to find near-optimal solutions within limited timeframes. Using a constrained case study, we compare a simple GA to two baseline methods, Random Search (RS) and Grid Search (GS), with each algorithm tested 10 times to enhance the reliability of the conclusions. Our findings show that while RS may miss optimal solutions due to its stochastic nature, it was unexpectedly effective under tight computational limits. Despite being more systematic, GS was outperformed by RS, likely due to the irregular design search space. This suggests that, under strict computational constraints, lightweight methods like RS can sometimes outperform more complex approaches like GA. As this study is limited to a single case under specific constraints, future research should investigate a broader range of design scenarios and computational settings to validate and generalize the findings. Additionally, the potential of Random Search or hybrid optimization methods should be further investigated, particularly in contexts with strict computational limitations.", "authors": ["Farnaz Nazari", "Wei Yan"], "url": "https://arxiv.org/abs/2504.08106"}
{"created": "2025-04-15", "title": "TinyverseGP: Towards a Modular Cross-domain Benchmarking Framework for Genetic Programming", "abstract": "Over the years, genetic programming (GP) has evolved, with many proposed variations, especially in how they represent a solution. Being essentially a program synthesis algorithm, it is capable of tackling multiple problem domains. Current benchmarking initiatives are fragmented, as the different representations are not compared with each other and their performance is not measured across the different domains. In this work, we propose a unified framework, dubbed TinyverseGP (inspired by tinyGP), which provides support to multiple representations and problem domains, including symbolic regression, logic synthesis and policy search.", "authors": ["Roman Kalkreuth", "Fabricio Olivetti de Fran\\c{c}a", "Julian Dierkes", "Marie Anastacio", "Anja Jankovic", "Zdenek Vasicek", "Holger Hoos"], "url": "https://arxiv.org/abs/2504.10253"}
{"created": "2025-04-18", "title": "Accurate Tracking of Arabidopsis Root Cortex Cell Nuclei in 3D Time-Lapse Microscopy Images Based on Genetic Algorithm", "abstract": "Arabidopsis is a widely used model plant to gain basic knowledge on plant physiology and development. Live imaging is an important technique to visualize and quantify elemental processes in plant development. To uncover novel theories underlying plant growth and cell division, accurate cell tracking on live imaging is of utmost importance. The commonly used cell tracking software, TrackMate, adopts tracking-by-detection fashion, which applies Laplacian of Gaussian (LoG) for blob detection, and Linear Assignment Problem (LAP) tracker for tracking. However, they do not perform sufficiently when cells are densely arranged. To alleviate the problems mentioned above, we propose an accurate tracking method based on Genetic algorithm (GA) using knowledge of Arabidopsis root cellular patterns and spatial relationship among volumes. Our method can be described as a coarse-to-fine method, in which we first conducted relatively easy line-level tracking of cell nuclei, then performed complicated nuclear tracking based on known linear arrangement of cell files and their spatial relationship between nuclei. Our method has been evaluated on a long-time live imaging dataset of Arabidopsis root tips, and with minor manual rectification, it accurately tracks nuclei. To the best of our knowledge, this research represents the first successful attempt to address a long-standing problem in the field of time-lapse microscopy in the root meristem by proposing an accurate tracking method for Arabidopsis root nuclei.", "authors": ["Yu Song", "Tatsuaki Goh", "Yinhao Li", "Jiahua Dong", "Shunsuke Miyashima", "Yutaro Iwamoto", "Yohei Kondo", "Keiji Nakajima", "Yen-wei Chen"], "url": "https://arxiv.org/abs/2504.12676"}
{"title": "VLLFL: A Vision-Language Model Based Lightweight Federated Learning Framework for Smart Agriculture", "url": "https://arxiv.org/abs/2504.13365", "authors": ["Long Li", "Jiajia Li", "Dong Chen", "Lina Pu", "Haibo Yao", "Yanbo Huang"], "created": "2025-04-21", "abstract": "In modern smart agriculture, object detection plays a crucial role by enabling automation, precision farming, and monitoring of resources. From identifying crop health and pest infestations to optimizing harvesting processes, accurate object detection enhances both productivity and sustainability. However, training object detection models often requires large-scale data collection and raises privacy concerns, particularly when sensitive agricultural data is distributed across farms. To address these challenges, we propose VLLFL, a vision-language model-based lightweight federated learning framework (VLLFL). It harnesses the generalization and context-aware detection capabilities of the vision-language model (VLM) and leverages the privacy-preserving nature of federated learning. By training a compact prompt generator to boost the performance of the VLM deployed across different farms, VLLFL preserves privacy while reducing communication overhead. Experimental results demonstrate that VLLFL achieves 14.53% improvement in the performance of VLM while reducing 99.3% communication overhead. Spanning tasks from identifying a wide variety of fruits to detecting harmful animals in agriculture, the proposed framework offers an efficient, scalable, and privacy-preserving solution specifically tailored to agricultural applications."}
{"created": "2025-04-21", "title": "Generating new coordination compounds via multireference simulations, genetic algorithms and machine learning: the case of Co(II) molecular magnets", "abstract": "The design of coordination compounds with target properties often requires years of continuous feedback loop between theory, simulations and experiments. In the case of magnetic molecules, this conventional strategy has indeed led to the breakthrough of single-molecule magnets with working temperatures above nitrogen's boiling point, but at significant costs in terms of resources and time. Here, we propose a computational strategy able to accelerate the discovery of new coordination compounds with desired electronic and magnetic properties. Our approach is based on a combination of high-throughput multireference ab initio methods, genetic algorithms and machine learning. While genetic algorithms allow for an intelligent sampling of the vast chemical space available, machine learning reduces the computational cost by pre-screening molecular properties in advance of their accurate and automated multireference ab initio characterization. Importantly, the presented framework is able to generate novel organic ligands and explore chemical motifs beyond those available in pre-existing structural databases. We showcase the power of this approach by automatically generating new Co(II) mononuclear coordination compounds with record magnetic properties in a fraction of the time required by either experiments or brute-force ab initio approaches", "authors": ["Lion Frangoulis", "Zahra Khatibi", "Lorenzo A. Mariano", "Alessandro Lunghi"], "url": "https://arxiv.org/abs/2504.13749"}
{"created": "2025-04-23", "title": "Comparative Analysis of Evolutionary Algorithms for Energy-Aware Production Scheduling", "abstract": "The energy transition is driving rapid growth in renewable energy generation, creating the need to balance energy supply and demand with energy price awareness. One such approach for manufacturers to balance their energy demand with available energy is energyaware production planning. Through energy-aware production planning, manufacturers can align their energy demand with dynamic grid conditions, supporting renewable energy integration while benefiting from lower prices and reduced emissions. Energy-aware production planning can be modeled as a multi-criteria scheduling problem, where the objectives extend beyond traditional metrics like makespan or required workers to also include minimizing energy costs and emissions. Due to market dynamics and the NP-hard multi-objective nature of the problem, evolutionary algorithms are widely used for energy-aware scheduling. However, existing research focuses on the design and analysis of single algorithms, with limited comparisons between different approaches. In this study, we adapt NSGA-III, HypE, and $\\theta$-DEA as memetic metaheuristics for energy-aware scheduling to minimize makespan, energy costs, emissions, and the number of workers, within a real-time energy market context. These adapted metaheuristics present different approaches for environmental selection. In a comparative analysis, we explore differences in solution efficiency and quality across various scenarios which are based on benchmark instances from the literature and real-world energy market data. Additionally, we estimate upper bounds on the distance between objective values obtained with our memetic metaheuristics and reference sets obtained via an exact solver.", "authors": ["Sascha C Burmeister", "Till N Rogalski", "Guido Schryen"], "url": "https://arxiv.org/abs/2504.15672"}
{"created": "2025-04-24", "title": "Neuro-Evolutionary Approach to Physics-Aware Symbolic Regression", "abstract": "Symbolic regression is a technique that can automatically derive analytic models from data. Traditionally, symbolic regression has been implemented primarily through genetic programming that evolves populations of candidate solutions sampled by genetic operators, crossover and mutation. More recently, neural networks have been employed to learn the entire analytical model, i.e., its structure and coefficients, using regularized gradient-based optimization. Although this approach tunes the model's coefficients better, it is prone to premature convergence to suboptimal model structures. Here, we propose a neuro-evolutionary symbolic regression method that combines the strengths of evolutionary-based search for optimal neural network (NN) topologies with gradient-based tuning of the network's parameters. Due to the inherent high computational demand of evolutionary algorithms, it is not feasible to learn the parameters of every candidate NN topology to full convergence. Thus, our method employs a memory-based strategy and population perturbations to enhance exploitation and reduce the risk of being trapped in suboptimal NNs. In this way, each NN topology can be trained using only a short sequence of backpropagation iterations. The proposed method was experimentally evaluated on three real-world test problems and has been shown to outperform other NN-based approaches regarding the quality of the models obtained.", "authors": ["Ji\\v{r}\\'i Kubal\\'ik", "Robert Babu\\v{s}ka"], "url": "https://arxiv.org/abs/2504.16503"}
{"created": "2025-04-25", "title": "A Systematic Study on the Design of Odd-Sized Highly Nonlinear Boolean Functions via Evolutionary Algorithms", "abstract": "This paper focuses on the problem of evolving Boolean functions of odd sizes with high nonlinearity, a property of cryptographic relevance. Despite its simple formulation, this problem turns out to be remarkably difficult. We perform a systematic evaluation by considering three solution encodings and four problem instances, analyzing how well different types of evolutionary algorithms behave in finding a maximally nonlinear Boolean function. Our results show that genetic programming generally outperforms other evolutionary algorithms, although it falls short of the best-known results achieved by ad-hoc heuristics. Interestingly, by adding local search and restricting the space to rotation symmetric Boolean functions, we show that a genetic algorithm with the bitstring encoding manages to evolve a $9$-variable Boolean function with nonlinearity 241.", "authors": ["Claude Carlet", "Marko {\\DJ}urasevic", "Domagoj Jakobovic", "Stjepan Picek", "Luca Mariot"], "url": "https://arxiv.org/abs/2504.17666"}
{"created": "2025-04-25", "title": "Optimized Cloud Resource Allocation Using Genetic Algorithms for Energy Efficiency and QoS Assurance", "abstract": "Cloud computing environments demand dynamic and efficient resource management to ensure optimal performance, reduced energy consumption, and adherence to Service Level Agreements (SLAs). This paper presents a Genetic Algorithm (GA)-based approach for Virtual Machine (VM) placement and consolidation, aiming to minimize power usage while maintaining QoS constraints. The proposed method dynamically adjusts VM allocation based on real-time workload variations, outperforming traditional heuristics such as First Fit Decreasing (FFD) and Best Fit Decreasing (BFD). Experimental results show notable reductions in energy consumption, VM migrations, SLA violation rates, and execution time. A correlation heatmap further illustrates strong relationships among these key performance indicators, confirming the effectiveness of our approach in optimizing cloud resource utilization.", "authors": ["Caroline Panggabean", "Devaraj Verma C", "Bhagyashree Gogoi", "Ranju Limbu", "Rhythm Sarker"], "url": "https://arxiv.org/abs/2504.17675"}
{"created": "2025-04-29", "title": "A Comparison-Relationship-Surrogate Evolutionary Algorithm for Multi-Objective Optimization", "abstract": "Evolutionary algorithms often struggle to find high-quality solutions to multi-objective optimization problems on a limited budget of function evaluations (here, a few hundred). A promising direction to improve the efficiency of these methods is to augment the objective functions with a data-driven surrogate model. These ``surrogate-assisted'' optimization algorithms can achieve better solutions than conventional algorithms for the same number of function evaluations on a wide variety of test problems. In this work, we continue to explore the area of surrogate-assisted multi-objective optimization by introducing and testing an algorithm driven by a new type of surrogate model: a comparison-relationship-surrogate model. This model predicts the truth values of the comparison operator evaluated on the objective functions for two candidate solutions. These predictions can be used to infer the domination relationships that power the non-dominated sorting mechanism used by many multi-objective genetic algorithms to select fit individuals. Several numerical experiments are performed on this algorithm using well-known test suites plus a real-world problem from the field of accelerator physics. Statistical analysis of the results demonstrates that the new algorithm can, on average, achieve better-converged solutions to many medium-scale, biobjective problems than existing state-of-the-art methods for a limited budget of function evaluations.", "authors": ["Christopher M. Pierce", "Young-Kee Kim", "Ivan Bazarov"], "url": "https://arxiv.org/abs/2504.19411"}
{"title": "A federated Kaczmarz algorithm", "url": "https://arxiv.org/abs/2505.09061", "authors": ["Halyun Jeong", "Deanna Needell", "Chi-Hao Wu"], "created": "2025-05-15", "abstract": "In this paper, we propose a federated algorithm for solving large linear systems that is inspired by the classic randomized Kaczmarz algorithm. We provide convergence guarantees of the proposed method, and as a corollary of our analysis, we provide a new proof for the convergence of the classic randomized Kaczmarz method. We demonstrate experimentally the behavior of our method when applied to related problems. For underdetermined systems, we demonstrate that our algorithm can be used for sparse approximation. For inconsistent systems, we demonstrate that our algorithm converges to a horizon of the least squares solution. Finally, we apply our algorithm to real data and show that it is consistent with the selection of Lasso, while still offering the computational advantages of the Kaczmarz framework and thresholding-based algorithms in the federated setting."}
