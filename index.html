<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv Frontpage</title>
    <style>
        body {
            font-family: sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
        }
        .paper {
            margin-bottom: 30px;
            margin-top: 30px;
            padding: 20px;
            border: 1px solid #ddd;
            border-radius: 5px;
        }
        .paper-title {
            font-size: 1.2em;
            font-weight: bold;
            margin-bottom: 10px;
        }
        .paper-meta {
            color: #666;
            font-size: 0.9em;
            margin-bottom: 10px;
        }
        .paper-abstract {
            margin-bottom: 10px;
        }
        .abstract-short {
            display: inline;
        }
        .abstract-full {
            display: none;
        }
        .more-link {
            color: blue;
            cursor: pointer;
            text-decoration: underline;
        }
        .tag-badge {
            display: inline-block;
            padding: 3px 8px;
            margin-right: 5px;
            margin-bottom: 5px;
            border-radius: 3px;
            font-size: 0.8em;
            color: white;
        }
        .tag-badge.high-confidence {
            opacity: 1;
        }
        .tag-badge.low-confidence {
            opacity: 0.6;
            display: none;
        }
        .interestingness-score {
            display: inline-block;
            padding: 3px 8px;
            margin-right: 10px;
            color: white;
            border-radius: 3px;
            font-weight: bold;
        }
        .interestingness-positive {
            background-color: #4CAF50;
        }
        .interestingness-negative {
            background-color: #f44336;
        }
        .interestingness-neutral {
            background-color: #9e9e9e;
        }
        .last-updated {
            text-align: right;
            color: #666;
            font-size: 0.9em;
            margin-top: 20px;
            margin-bottom: 20px;
        }
        .intro {
            text-align: center;
            max-width: 60em;
            margin: 0 auto;
            color: #888;
        }
        .copy-icon {
            display: inline-block;
            width: 16px;
            height: 16px;
            cursor: pointer;
            margin-left: 5px;
            opacity: 0.5;
        }
        .copy-icon:hover {
            opacity: 1;
        }
        .json-popup {
            display: none;
            position: fixed;
            top: 20px;
            right: 20px;
            background: white;
            padding: 20px;
            border: 1px solid #ddd;
            border-radius: 5px;
            max-width: 500px;
            max-height: 300px;
            overflow: auto;
            box-shadow: 0 0 10px rgba(0,0,0,0.1);
        }
        a {
            color: inherit;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        h1 {
            text-align: center;
        }
        h1 a {
            text-decoration: underline;
        }
        .date-section {
            margin-bottom: 40px;
        }
        .date-header {
            color: #666;
            font-size: 1.5em;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 2px solid #eee;
        }
    </style>
</head>
<body>
    <h1>
        <a href="https://github.com/DataWraith/arxiv-frontpage">DataWraith's</a> ArXiv Frontpage
    </h1>

    <div class="last-updated">
        Last updated: 2025-05-26
    </div>

    <p class="intro">
        This frontpage is made by scraping ArXiv's computer science RSS feed and tagging papers with a classifier.
    </p>

    <p class="intro">
        Each tag is weighted according to my preferences to compute a paper's <i>interestingness</i> score.
    </p>
    
    
    <div class="date-section">
        <h2 class="date-header">2025-05-26</h2>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    7.1175
                </span>
                <a href="https://arxiv.org/abs/2504.13241" target="_blank" rel="noopener noreferrer">Recursive Deep Inverse Reinforcement Learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Paul Ghanem, Michael Potter, Owen Howell, Pau Closas, Alireza Ramezani, Deniz Erdogmus, Tales Imbiriba
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Inferring an adversary's goals from exhibited behavior is crucial for counterplanning and non-cooperative multi-agent systems in domains like cybersecurity, military, and strategy games. Deep Inverse Reinforcement Learning (IRL) methods based on maximum entropy principles show promise in recovering </span>
                
                <span class="abstract-full" style="display: none;">Inferring an adversary's goals from exhibited behavior is crucial for counterplanning and non-cooperative multi-agent systems in domains like cybersecurity, military, and strategy games. Deep Inverse Reinforcement Learning (IRL) methods based on maximum entropy principles show promise in recovering adversaries' goals but are typically offline, require large batch sizes with gradient descent, and rely on first-order updates, limiting their applicability in real-time scenarios. We propose an online Recursive Deep Inverse Reinforcement Learning (RDIRL) approach to recover the cost function governing the adversary actions and goals. Specifically, we minimize an upper bound on the standard Guided Cost Learning (GCL) objective using sequential second-order Newton updates, akin to the Extended Kalman Filter (EKF), leading to a fast (in terms of convergence) learning algorithm. We demonstrate that RDIRL is able to recover cost and reward functions of expert agents in standard and adversarial benchmark tasks. Experiments on benchmark tasks show that our proposed approach outperforms several leading IRL algorithms.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge high-confidence" style="background-color: #44f899" title="Confidence: 75.9%">
                            Reinforcement Learning
                        </span>
                <!-- LLMs: 3.5 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- Medicine: 2.1 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- HPO and AutoML: 1.8 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Datasets: 1.0 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    6.9515
                </span>
                <a href="https://arxiv.org/abs/2504.19229" target="_blank" rel="noopener noreferrer">Robust Nash equilibrium seeking based on semi-Markov switching topologies</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jianing Chen, Sitian Qin, Chuangyin Dang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper investigates a distributed robust Nash Equilibrium (NE) seeking problem in fluctuating environments. Specifically, the players, subject to the second-order dynamics, are considered to be influenced by external disturbances and uncertain dynamics while communicating via semi-Markov switchi</span>
                
                <span class="abstract-full" style="display: none;">This paper investigates a distributed robust Nash Equilibrium (NE) seeking problem in fluctuating environments. Specifically, the players, subject to the second-order dynamics, are considered to be influenced by external disturbances and uncertain dynamics while communicating via semi-Markov switching topologies. In such constantly changing network circumstances, the existence of disturbances and uncertain dynamics may directly affect the performance of most existing NE seeking algorithms. Moreover, the semi-Markov switching topologies may cause communication uncertainty, which are considered in NE seeking for the first time. To accommodate the above concerns, the following targets require to be reached simultaneously: (1) Disturbances and uncertain dynamics rejection in finite time; (2) Distributed estimation on unknown information required for players' cost functions; (3) A reasonable estimation consensus protocol under semi-Markov switching; (4) NE seeking for the second-order players. By combining supertwisting-based Integral Sliding-Mode Control (ISMC) with average consensus tracking, a novel robust NE seeking algorithm is constructed, incorporating an effective leader-follower consensus protocol. Furthermore, to lessen dispensable information transmission, a sampled-data-based event-triggered mechanism is introduced. Incorporating the advantages of both semi-Markov switching and event-triggered mechanism, another NE seeking algorithm is proposed. Through designing an appropriate Lyapunov-Krasovskii functional, it is shown that the leader-follower consensus can be achieved in the mean-square sense under event-triggered mechanism. Finally, a connectivity control game is formulated to illustrate the validity of the designed algorithms.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #546bc5" title="Confidence: 62.6%">
                            Game Theory
                        </span>
                <!-- Math: 3.7 -->
                    
                <!-- Networks: 3.2 -->
                    
                <!-- Cryptography: 2.7 -->
                    
                <!-- Finance: 2.4 -->
                    
                <!-- Pathfinding: 1.8 -->
                    
                <!-- Fuzzy Logic: 1.2 -->
                    
                <!-- Multi-armed Bandit: 1.1 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    2.7675
                </span>
                <a href="https://arxiv.org/abs/2504.10165" target="_blank" rel="noopener noreferrer">WildLive: Near Real-time Visual Wildlife Tracking onboard UAVs</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Nguyen Ngoc Dat, Tom Richardson, Matthew Watson, Kilian Meier, Jenna Kline, Sid Reid, Guy Maalouf, Duncan Hine, Majid Mirmehdi, Tilo Burghardt
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Live tracking of wildlife via high-resolution video processing directly onboard drones is widely unexplored and most existing solutions rely on streaming video to ground stations to support navigation. Yet, both autonomous animal-reactive flight control beyond visual line of sight and/or mission-spe</span>
                
                <span class="abstract-full" style="display: none;">Live tracking of wildlife via high-resolution video processing directly onboard drones is widely unexplored and most existing solutions rely on streaming video to ground stations to support navigation. Yet, both autonomous animal-reactive flight control beyond visual line of sight and/or mission-specific individual and behaviour recognition tasks rely to some degree on this capability. In response, we introduce WildLive - a near real-time animal detection and tracking framework for high-resolution imagery running directly onboard uncrewed aerial vehicles (UAVs). The system performs multi-animal detection and tracking at 17.81fps for HD and 7.53fps on 4K video streams suitable for operation during higher altitude flights to minimise animal disturbance. Our system is optimised for Jetson Orin AGX onboard hardware. It integrates the efficiency of sparse optical flow tracking and mission-specific sampling with device-optimised and proven YOLO-driven object detection and segmentation techniques. Essentially, computational resource is focused onto spatio-temporal regions of high uncertainty to significantly improve UAV processing speeds. Alongside, we introduce our WildLive dataset, which comprises 200K+ annotated animal instances across 19K+ frames from 4K UAV videos collected at the Ol Pejeta Conservancy in Kenya. All frames contain ground truth bounding boxes, segmentation masks, as well as individual tracklets and tracking point trajectories. We compare our system against current object tracking approaches including OC-SORT, ByteTrack, and SORT. Our multi-animal tracking experiments with onboard hardware confirm that near real-time high-resolution wildlife tracking is possible on UAVs whilst maintaining high accuracy levels as needed for future navigational and mission-specific animal-centric operational autonomy. Our materials are available at: https://dat-nguyenvn.github.io/WildLive/</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge high-confidence" style="background-color: #753a22" title="Confidence: 78.0%">
                            Computer Vision
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.2%">
                            Medicine
                        </span>
                <!-- LLMs: 3.3 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- HPO and AutoML: 1.8 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    1.071
                </span>
                <a href="https://arxiv.org/abs/2505.17732" target="_blank" rel="noopener noreferrer">RQR3D: Reparametrizing the regression targets for BEV-based 3D object detection</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ozsel Kilinc, Cem Tarhan
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Accurate, fast, and reliable 3D perception is essential for autonomous driving. Recently, bird's-eye view (BEV)-based perception approaches have emerged as superior alternatives to perspective-based solutions, offering enhanced spatial understanding and more natural outputs for planning. Existing BE</span>
                
                <span class="abstract-full" style="display: none;">Accurate, fast, and reliable 3D perception is essential for autonomous driving. Recently, bird's-eye view (BEV)-based perception approaches have emerged as superior alternatives to perspective-based solutions, offering enhanced spatial understanding and more natural outputs for planning. Existing BEV-based 3D object detection methods, typically adhering to angle-based representation, directly estimate the size and orientation of rotated bounding boxes. We observe that BEV-based 3D object detection is analogous to aerial oriented object detection, where angle-based methods are recognized for being affected by discontinuities in their loss functions. Drawing inspiration from this domain, we propose Restricted Quadrilateral Representation to define 3D regression targets. RQR3D regresses the smallest horizontal bounding box encapsulating the oriented box, along with the offsets between the corners of these two boxes, thereby transforming the oriented object detection problem into a keypoint regression task. RQR3D is compatible with any 3D object detection approach. We employ RQR3D within an anchor-free single-stage object detection method and introduce an objectness head to address class imbalance problem. Furthermore, we introduce a simplified radar fusion backbone that eliminates the need for voxel grouping and processes the BEV-mapped point cloud with standard 2D convolutions, rather than sparse convolutions. Extensive evaluations on the nuScenes dataset demonstrate that RQR3D achieves state-of-the-art performance in camera-radar 3D object detection, outperforming the previous best method by +4% in NDS and +2.4% in mAP, and significantly reducing the translation and orientation errors, which are crucial for safe autonomous driving. These consistent gains highlight the robustness, precision, and real-world readiness of our approach.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 18.4%">
                            Computer Vision
                        </span>
                <!-- Medicine: 3.8 -->
                    
                <!-- 3D: 2.6 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- LLMs: 1.5 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Hardware: 1.1 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                <!-- Evolutionary Algorithms: 1.0 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.5733
                </span>
                <a href="https://arxiv.org/abs/2503.01468" target="_blank" rel="noopener noreferrer">Overcoming Non-stationary Dynamics with Evidential Proximal Policy Optimization</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Abdullah Akg\"ul, Gulcin Baykal, Manuel Hau{\ss}mann, Melih Kandemir
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Continuous control of non-stationary environments is a major challenge for deep reinforcement learning algorithms. The time-dependency of the state transition dynamics aggravates the notorious stability problems of model-free deep actor-critic architectures. We posit that two properties will play a </span>
                
                <span class="abstract-full" style="display: none;">Continuous control of non-stationary environments is a major challenge for deep reinforcement learning algorithms. The time-dependency of the state transition dynamics aggravates the notorious stability problems of model-free deep actor-critic architectures. We posit that two properties will play a key role in overcoming non-stationarity in transition dynamics: (i) preserving the plasticity of the critic network, (ii) directed exploration for rapid adaptation to the changing dynamics. We show that performing on-policy reinforcement learning with an evidential critic provides both of these properties. The evidential design ensures a fast and sufficiently accurate approximation to the uncertainty around the state-value, which maintains the plasticity of the critic network by detecting the distributional shifts caused by the change in dynamics. The probabilistic critic also makes the actor training objective a random variable, enabling the use of directed exploration approaches as a by-product. We name the resulting algorithm as $\textit{ Evidential Proximal Policy Optimization (EPPO)}$ due to the integral role of evidential uncertainty quantification in both policy evaluation and policy improvement stages. Through experiments on non-stationary continuous control tasks, where the environment dynamics change at regular intervals, we demonstrate that our algorithm outperforms state-of-the-art on-policy reinforcement learning variants in both task-specific and overall return.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #44f899" title="Confidence: 6.5%">
                            Reinforcement Learning
                        </span>
                <!-- Bayesian Optimization: 2.9 -->
                    
                <!-- Math: 2.3 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Networks: 1.7 -->
                    
                <!-- Medicine: 1.6 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Cryptography: 1.4 -->
                    
                <!-- Game Theory: 1.4 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Finance: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- LLMs: 1.1 -->
                    
                <!-- Computer Vision: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.3423
                </span>
                <a href="https://arxiv.org/abs/2505.17473" target="_blank" rel="noopener noreferrer">OrionBench: A Benchmark for Chart and Human-Recognizable Object Detection in Infographics</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jiangning Zhu, Yuxing Zhou, Zheng Wang, Juntao Yao, Yima Gu, Yuhui Yuan, Shixia Liu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Given the central role of charts in scientific, business, and communication contexts, enhancing the chart understanding capabilities of vision-language models (VLMs) has become increasingly critical. A key limitation of existing VLMs lies in their inaccurate visual grounding of infographic elements,</span>
                
                <span class="abstract-full" style="display: none;">Given the central role of charts in scientific, business, and communication contexts, enhancing the chart understanding capabilities of vision-language models (VLMs) has become increasingly critical. A key limitation of existing VLMs lies in their inaccurate visual grounding of infographic elements, including charts and human-recognizable objects (HROs) such as icons and images. However, chart understanding often requires identifying relevant elements and reasoning over them. To address this limitation, we introduce OrionBench, a benchmark designed to support the development of accurate object detection models for charts and HROs in infographics. It contains 26,250 real and 78,750 synthetic infographics, with over 6.9 million bounding box annotations. These annotations are created by combining the model-in-the-loop and programmatic methods. We demonstrate the usefulness of OrionBench through three applications: 1) constructing a Thinking-with-Boxes scheme to boost the chart understanding performance of VLMs, 2) comparing existing object detection models, and 3) applying the developed detection model to document layout and UI element detection.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.6%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.1%">
                            Computer Vision
                        </span>
                <!-- Medicine: 4.1 -->
                    
                <!-- Hardware: 2.2 -->
                    
                <!-- Datasets: 2.1 -->
                    
                <!-- Blockchain: 2.1 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.3095
                </span>
                <a href="https://arxiv.org/abs/2505.11532" target="_blank" rel="noopener noreferrer">Revisiting Adversarial Perception Attacks and Defense Methods on Autonomous Driving Systems</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Cheng Chen, Yuhong Wang, Nafis S Munir, Xiangwei Zhou, Xugui Zhou
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Autonomous driving systems (ADS) increasingly rely on deep learning-based perception models, which remain vulnerable to adversarial attacks. In this paper, we revisit adversarial attacks and defense methods, focusing on road sign recognition and lead object detection and prediction (e.g., relative d</span>
                
                <span class="abstract-full" style="display: none;">Autonomous driving systems (ADS) increasingly rely on deep learning-based perception models, which remain vulnerable to adversarial attacks. In this paper, we revisit adversarial attacks and defense methods, focusing on road sign recognition and lead object detection and prediction (e.g., relative distance). Using a Level-2 production ADS, OpenPilot by Comma$.$ai, and the widely adopted YOLO model, we systematically examine the impact of adversarial perturbations and assess defense techniques, including adversarial training, image processing, contrastive learning, and diffusion models. Our experiments highlight both the strengths and limitations of these methods in mitigating complex attacks. Through targeted evaluations of model robustness, we aim to provide deeper insights into the vulnerabilities of ADS perception systems and contribute guidance for developing more resilient defense strategies.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.6%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 6.2%">
                            Computer Vision
                        </span>
                <!-- Medicine: 5.0 -->
                    
                <!-- Blockchain: 2.6 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2852
                </span>
                <a href="https://arxiv.org/abs/2505.17692" target="_blank" rel="noopener noreferrer">ViP$^2$-CLIP: Visual-Perception Prompting with Unified Alignment for Zero-Shot Anomaly Detection</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ziteng Yang, Jingzehua Xu, Yanshu Li, Zepeng Li, Yeqiang Wang, Xinghui Li
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Zero-shot anomaly detection (ZSAD) aims to detect anomalies without any target domain training samples, relying solely on external auxiliary data. Existing CLIP-based methods attempt to activate the model's ZSAD potential via handcrafted or static learnable prompts. The former incur high engineering</span>
                
                <span class="abstract-full" style="display: none;">Zero-shot anomaly detection (ZSAD) aims to detect anomalies without any target domain training samples, relying solely on external auxiliary data. Existing CLIP-based methods attempt to activate the model's ZSAD potential via handcrafted or static learnable prompts. The former incur high engineering costs and limited semantic coverage, whereas the latter apply identical descriptions across diverse anomaly types, thus fail to adapt to complex variations. Furthermore, since CLIP is originally pretrained on large-scale classification tasks, its anomaly segmentation quality is highly sensitive to the exact wording of class names, severely constraining prompting strategies that depend on class labels. To address these challenges, we introduce ViP$^{2}$-CLIP. The key insight of ViP$^{2}$-CLIP is a Visual-Perception Prompting (ViP-Prompt) mechanism, which fuses global and multi-scale local visual context to adaptively generate fine-grained textual prompts, eliminating manual templates and class-name priors. This design enables our model to focus on precise abnormal regions, making it particularly valuable when category labels are ambiguous or privacy-constrained. Extensive experiments on 15 industrial and medical benchmarks demonstrate that ViP$^{2}$-CLIP achieves state-of-the-art performance and robust cross-domain generalization.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.3%">
                            Computer Vision
                        </span>
                <!-- LLMs: 3.6 -->
                    
                <!-- Medicine: 3.1 -->
                    
                <!-- GNN: 3.1 -->
                    
                <!-- Federated Learning: 3.0 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2801
                </span>
                <a href="https://arxiv.org/abs/2505.17364" target="_blank" rel="noopener noreferrer">Optimizing YOLOv8 for Parking Space Detection: Comparative Analysis of Custom YOLOv8 Architecture</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Apar Pokhrel, Gia Dao
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Parking space occupancy detection is a critical component in the development of intelligent parking management systems. Traditional object detection approaches, such as YOLOv8, provide fast and accurate vehicle detection across parking lots but can struggle with borderline cases, such as partially v</span>
                
                <span class="abstract-full" style="display: none;">Parking space occupancy detection is a critical component in the development of intelligent parking management systems. Traditional object detection approaches, such as YOLOv8, provide fast and accurate vehicle detection across parking lots but can struggle with borderline cases, such as partially visible vehicles, small vehicles (e.g., motorcycles), and poor lighting conditions. In this work, we perform a comprehensive comparative analysis of customized backbone architectures integrated with YOLOv8. Specifically, we evaluate various backbones -- ResNet-18, VGG16, EfficientNetV2, Ghost -- on the PKLot dataset in terms of detection accuracy and computational efficiency. Experimental results highlight each architecture's strengths and trade-offs, providing insight into selecting suitable models for parking occupancy.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.9%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.6%">
                            Computer Vision
                        </span>
                <!-- Medicine: 4.6 -->
                    
                <!-- Blockchain: 2.4 -->
                    
                <!-- Datasets: 2.1 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2413
                </span>
                <a href="https://arxiv.org/abs/2505.17245" target="_blank" rel="noopener noreferrer">Extending Dataset Pruning to Object Detection: A Variance-based Approach</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ryota Yagi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Dataset pruning -- selecting a small yet informative subset of training data -- has emerged as a promising strategy for efficient machine learning, offering significant reductions in computational cost and storage compared to alternatives like dataset distillation. While pruning methods have shown s</span>
                
                <span class="abstract-full" style="display: none;">Dataset pruning -- selecting a small yet informative subset of training data -- has emerged as a promising strategy for efficient machine learning, offering significant reductions in computational cost and storage compared to alternatives like dataset distillation. While pruning methods have shown strong performance in image classification, their extension to more complex computer vision tasks, particularly object detection, remains relatively underexplored. In this paper, we present the first principled extension of classification pruning techniques to the object detection domain, to the best of our knowledge. We identify and address three key challenges that hinder this transition: the Object-Level Attribution Problem, the Scoring Strategy Problem, and the Image-Level Aggregation Problem. To overcome these, we propose tailored solutions, including a novel scoring method called Variance-based Prediction Score (VPS). VPS leverages both Intersection over Union (IoU) and confidence scores to effectively identify informative training samples specific to detection tasks. Extensive experiments on PASCAL VOC and MS COCO demonstrate that our approach consistently outperforms prior dataset pruning methods in terms of mean Average Precision (mAP). We also show that annotation count and class distribution shift can influence detection performance, but selecting informative examples is a more critical factor than dataset size or balance. Our work bridges dataset pruning and object detection, paving the way for dataset pruning in complex vision tasks.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.3%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.4%">
                            Computer Vision
                        </span>
                <!-- GNN: 2.1 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Medicine: 2.0 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Hardware: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2226
                </span>
                <a href="https://arxiv.org/abs/2412.11803" target="_blank" rel="noopener noreferrer">UAlign: Leveraging Uncertainty Estimations for Factuality Alignment on Large Language Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Boyang Xue, Fei Mi, Qi Zhu, Hongru Wang, Rui Wang, Sheng Wang, Erxin Yu, Xuming Hu, Kam-Fai Wong
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Despite demonstrating impressive capabilities, Large Language Models (LLMs) still often struggle to accurately express the factual knowledge they possess, especially in cases where the LLMs' knowledge boundaries are ambiguous. To improve LLMs' factual expressions, we propose the UAlign framework, wh</span>
                
                <span class="abstract-full" style="display: none;">Despite demonstrating impressive capabilities, Large Language Models (LLMs) still often struggle to accurately express the factual knowledge they possess, especially in cases where the LLMs' knowledge boundaries are ambiguous. To improve LLMs' factual expressions, we propose the UAlign framework, which leverages Uncertainty estimations to represent knowledge boundaries, and then explicitly incorporates these representations as input features into prompts for LLMs to Align with factual knowledge. First, we prepare the dataset on knowledge question-answering (QA) samples by calculating two uncertainty estimations, including confidence score and semantic entropy, to represent the knowledge boundaries for LLMs. Subsequently, using the prepared dataset, we train a reward model that incorporates uncertainty estimations and then employ the Proximal Policy Optimization (PPO) algorithm for factuality alignment on LLMs. Experimental results indicate that, by integrating uncertainty representations in LLM alignment, the proposed UAlign can significantly enhance the LLMs' capacities to confidently answer known questions and refuse unknown questions on both in-domain and out-of-domain tasks, showing reliability improvements and good generalizability over various prompt- and training-based baselines.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 11.0%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.7%">
                            Computer Vision
                        </span>
                <!-- Medicine: 2.8 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- 3D: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2125
                </span>
                <a href="https://arxiv.org/abs/2505.17460" target="_blank" rel="noopener noreferrer">Learning to Focus: Context Extraction for Efficient Code Vulnerability Detection with Language Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Xinran Zheng, Xingzhi Qian, Huichi Zhou, Shuo Yang, Yiling He, Suman Jana, Lorenzo Cavallaro
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Language models (LMs) show promise for vulnerability detection but struggle with long, real-world code due to sparse and uncertain vulnerability locations. These issues, exacerbated by token limits, often cause models to miss vulnerability-related signals, thereby impairing effective learning. A key</span>
                
                <span class="abstract-full" style="display: none;">Language models (LMs) show promise for vulnerability detection but struggle with long, real-world code due to sparse and uncertain vulnerability locations. These issues, exacerbated by token limits, often cause models to miss vulnerability-related signals, thereby impairing effective learning. A key intuition is to enhance LMs with concise, information-rich context. Commit-based annotations offer precise, CWE-agnostic supervision, but are unavailable during inference, as they depend on historical code changes. Moreover, their extreme sparsity, often covering only a few lines, makes it difficult for LMs to process directly. In this paper, we propose FocusVul, a model-agnostic framework that improves LM-based vulnerability detection by learning to select sensitive context. FocusVul learns commit-based annotation patterns through hierarchical semantic modeling and generalizes them to identify line-level vulnerability-relevant regions during inference. It then extracts LM-oriented context via both dependency and execution flows surrounding selected regions, yielding semantically rich inputs for effective vulnerability detection. Experiments on real-world benchmarks show that FocusVul consistently outperforms heuristic-based and full-function fine-tuning approaches, improving classification performance by 164.04% and reducing FLOPs by 19.12% on average.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.8%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.1%">
                            Computer Vision
                        </span>
                <!-- Medicine: 2.9 -->
                    
                <!-- HPO and AutoML: 2.8 -->
                    
                <!-- Federated Learning: 2.8 -->
                    
                <!-- GNN: 2.3 -->
                    
                <!-- Decision Trees: 2.3 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- 3D: 1.8 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2109
                </span>
                <a href="https://arxiv.org/abs/2411.14503" target="_blank" rel="noopener noreferrer">Planning-Driven Programming: A Large Language Model Programming Workflow</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Chao Lei, Yanchuan Chang, Nir Lipovetzky, Krista A. Ehinger
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The strong performance of large language models (LLMs) raises extensive discussion on their application to code generation. Recent research suggests continuous program refinements through visible tests to improve code generation accuracy in LLMs. However, these methods suffer from LLMs' inefficiency</span>
                
                <span class="abstract-full" style="display: none;">The strong performance of large language models (LLMs) raises extensive discussion on their application to code generation. Recent research suggests continuous program refinements through visible tests to improve code generation accuracy in LLMs. However, these methods suffer from LLMs' inefficiency and limited reasoning capacity. In this work, we propose an LLM programming workflow (LPW) designed to improve both initial code generation and subsequent refinements within a structured two-phase workflow. Specifically, the solution generation phase formulates a solution plan, which is then verified through visible tests to specify the intended natural language solution. Subsequently, the code implementation phase drafts an initial code according to the solution plan and its verification. If the generated code fails the visible tests, the plan verification serves as the intended solution to consistently inform the refinement process for correcting bugs. Compared to state-of-the-art methods across various existing LLMs, LPW significantly improves the Pass@1 accuracy by up to 16.4% on well-established text-to-code generation benchmarks. LPW also sets new state-of-the-art Pass@1 accuracy, achieving 98.2% on HumanEval, 84.8% on MBPP, 59.3% on LiveCode, 62.6% on APPS, and 34.7% on CodeContest, using GPT-4o as the backbone. Our code is publicly available at: https://github.com/you68681/lpw</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.9%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.0%">
                            Computer Vision
                        </span>
                <!-- Federated Learning: 2.4 -->
                    
                <!-- GNN: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 2.2 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Medicine: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.1969
                </span>
                <a href="https://arxiv.org/abs/2505.17654" target="_blank" rel="noopener noreferrer">EVADE: Multimodal Benchmark for Evasive Content Detection in E-Commerce Applications</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ancheng Xu, Zhihao Yang, Jingpeng Li, Guanghu Yuan, Longze Chen, Liang Yan, Jiehui Zhou, Zhen Qin, Hengyun Chang, Hamid Alinejad-Rokny, Bo Zheng, Min Yang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">E-commerce platforms increasingly rely on Large Language Models (LLMs) and Vision-Language Models (VLMs) to detect illicit or misleading product content. However, these models remain vulnerable to evasive content: inputs (text or images) that superficially comply with platform policies while covertl</span>
                
                <span class="abstract-full" style="display: none;">E-commerce platforms increasingly rely on Large Language Models (LLMs) and Vision-Language Models (VLMs) to detect illicit or misleading product content. However, these models remain vulnerable to evasive content: inputs (text or images) that superficially comply with platform policies while covertly conveying prohibited claims. Unlike traditional adversarial attacks that induce overt failures, evasive content exploits ambiguity and context, making it far harder to detect. Existing robustness benchmarks provide little guidance for this demanding, real-world challenge. We introduce EVADE, the first expert-curated, Chinese, multimodal benchmark specifically designed to evaluate foundation models on evasive content detection in e-commerce. The dataset contains 2,833 annotated text samples and 13,961 images spanning six demanding product categories, including body shaping, height growth, and health supplements. Two complementary tasks assess distinct capabilities: Single-Violation, which probes fine-grained reasoning under short prompts, and All-in-One, which tests long-context reasoning by merging overlapping policy rules into unified instructions. Notably, the All-in-One setting significantly narrows the performance gap between partial and full-match accuracy, suggesting that clearer rule definitions improve alignment between human and model judgment. We benchmark 26 mainstream LLMs and VLMs and observe substantial performance gaps: even state-of-the-art models frequently misclassify evasive samples. By releasing EVADE and strong baselines, we provide the first rigorous standard for evaluating evasive-content detection, expose fundamental limitations in current multimodal reasoning, and lay the groundwork for safer and more transparent content moderation systems in e-commerce. The dataset is publicly available at https://huggingface.co/datasets/koenshen/EVADE-Bench.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 15.0%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.2%">
                            Computer Vision
                        </span>
                <!-- Medicine: 4.6 -->
                    
                <!-- Datasets: 2.2 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Decision Trees: 2.0 -->
                    
                <!-- HPO and AutoML: 1.9 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.1188
                </span>
                <a href="https://arxiv.org/abs/2505.17393" target="_blank" rel="noopener noreferrer">Spectral Mixture Kernels for Bayesian Optimization</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yi Zhang, Cheng Hua
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Bayesian Optimization (BO) is a widely used approach for solving expensive black-box optimization tasks. However, selecting an appropriate probabilistic surrogate model remains an important yet challenging problem. In this work, we introduce a novel Gaussian Process (GP)-based BO method that incorpo</span>
                
                <span class="abstract-full" style="display: none;">Bayesian Optimization (BO) is a widely used approach for solving expensive black-box optimization tasks. However, selecting an appropriate probabilistic surrogate model remains an important yet challenging problem. In this work, we introduce a novel Gaussian Process (GP)-based BO method that incorporates spectral mixture kernels, derived from spectral densities formed by scale-location mixtures of Cauchy and Gaussian distributions. This method achieves a significant improvement in both efficiency and optimization performance, matching the computational speed of simpler kernels while delivering results that outperform more complex models and automatic BO methods. We provide bounds on the information gain and cumulative regret associated with obtaining the optimum. Extensive numerical experiments demonstrate that our method consistently outperforms existing baselines across a diverse range of synthetic and real-world problems, including both low- and high-dimensional settings.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.4%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #31bb31" title="Confidence: 5.2%">
                            Bayesian Optimization
                        </span>
                <!-- Medicine: 3.5 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- 3D: 2.0 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17025" target="_blank" rel="noopener noreferrer">Locally Adaptive Non-Hydrostatic Shallow Water Extension for Moving Bottom-Generated Waves</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Kemal Firdaus, J\"orn Behrens
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We propose a locally adaptive non-hydrostatic model and apply it to wave propagation generated by a moving bottom. This model is based on the non-hydrostatic extension of the shallow water equations (SWE) with a quadratic pressure relation, which is suitable for weakly dispersive waves. The approxim</span>
                
                <span class="abstract-full" style="display: none;">We propose a locally adaptive non-hydrostatic model and apply it to wave propagation generated by a moving bottom. This model is based on the non-hydrostatic extension of the shallow water equations (SWE) with a quadratic pressure relation, which is suitable for weakly dispersive waves. The approximation is mathematically equivalent to the Green-Naghdi equations. Applied globally, the extension requires solving an elliptic system of equations in the whole domain at each time step. Therefore, we develop an adaptive model that reduces the application area of the extension and by that the computational time. The elliptic problem is only solved in the area where the dispersive effect might play a crucial role. To define the non-hydrostatic area, we investigate several potential criteria based on the hydrostatic SWE solution. We validate and illustrate how our adaptive model works by first applying it to simulate a simple propagating solitary wave, where exact solutions are known. Following that, we demonstrate the accuracy and efficiency of our approach in more complicated cases involving moving bottom-generated waves, where measured laboratory data serve as reference solutions. The adaptive model yields similar accuracy as the global application of the non-hydrostatic extension while reducing the computational time by more than 50%.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 3.1 -->
                    
                <!-- Medicine: 2.6 -->
                    
                <!-- Cryptography: 2.3 -->
                    
                <!-- Networks: 2.2 -->
                    
                <!-- Finance: 2.2 -->
                    
                <!-- Computer Vision: 2.0 -->
                    
                <!-- Math: 1.9 -->
                    
                <!-- Reinforcement Learning: 1.9 -->
                    
                <!-- Bayesian Optimization: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- LLMs: 1.1 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- Hardware: 1.0 -->
                    
                <!-- Pathfinding: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17044" target="_blank" rel="noopener noreferrer">Thermal quasi-geostrophic model on the sphere: derivation and structure-preserving simulation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Michael Roop, Sagy Ephrati
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We derive the global model of thermal quasi-geostrophy on the sphere via asymptotic expansion of the thermal rotating shallow water equations. The model does not rely on the asymptotic expansion of the Coriolis force and extends the quasi-geostrophic model on the sphere by including an additional tr</span>
                
                <span class="abstract-full" style="display: none;">We derive the global model of thermal quasi-geostrophy on the sphere via asymptotic expansion of the thermal rotating shallow water equations. The model does not rely on the asymptotic expansion of the Coriolis force and extends the quasi-geostrophic model on the sphere by including an additional transported buoyancy field acting as a source term for the potential vorticity. We give its Hamiltonian description in terms of semidirect product Lie--Poisson brackets. The Hamiltonian formulation reveals the existence of an infinite number of conservation laws, Casimirs, parameterized by two arbitrary smooth functions. A structure-preserving discretization is provided based on Zeitlin's self-consistent matrix approximation for hydrodynamics. A Casimir-preserving time integrator is employed to numerically fully preserve the resulting finite-dimensional Lie--Poisson structure. Simulations reveal the formation of vorticity and buoyancy fronts, and large-scale structures in the buoyancy dynamics induced by the buoyancy-bathymetry interaction.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.2 -->
                    
                <!-- Federated Learning: 3.4 -->
                    
                <!-- Hardware: 2.6 -->
                    
                <!-- Math: 2.2 -->
                    
                <!-- Blockchain: 2.2 -->
                    
                <!-- Computer Vision: 2.1 -->
                    
                <!-- Finance: 2.1 -->
                    
                <!-- Reinforcement Learning: 2.0 -->
                    
                <!-- Bayesian Optimization: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Cryptography: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- LLMs: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17067" target="_blank" rel="noopener noreferrer">Unveil Multi-Picture Descriptions for Multilingual Mild Cognitive Impairment Detection via Contrastive Learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Kristin Qi, Jiali Cheng, Youxiang Zhu, Hadi Amiri, Xiaohui Liang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Detecting Mild Cognitive Impairment from picture descriptions is critical yet challenging, especially in multilingual and multiple picture settings. Prior work has primarily focused on English speakers describing a single picture (e.g., the 'Cookie Theft'). The TAUKDIAL-2024 challenge expands this s</span>
                
                <span class="abstract-full" style="display: none;">Detecting Mild Cognitive Impairment from picture descriptions is critical yet challenging, especially in multilingual and multiple picture settings. Prior work has primarily focused on English speakers describing a single picture (e.g., the 'Cookie Theft'). The TAUKDIAL-2024 challenge expands this scope by introducing multilingual speakers and multiple pictures, which presents new challenges in analyzing picture-dependent content. To address these challenges, we propose a framework with three components: (1) enhancing discriminative representation learning via supervised contrastive learning, (2) involving image modality rather than relying solely on speech and text modalities, and (3) applying a Product of Experts (PoE) strategy to mitigate spurious correlations and overfitting. Our framework improves MCI detection performance, achieving a +7.1% increase in Unweighted Average Recall (UAR) (from 68.1% to 75.2%) and a +2.9% increase in F1 score (from 80.6% to 83.5%) compared to the text unimodal baseline. Notably, the contrastive learning component yields greater gains for the text modality compared to speech. These results highlight our framework's effectiveness in multilingual and multi-picture MCI detection.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 3.9 -->
                    
                <!-- Medicine: 3.7 -->
                    
                <!-- Computer Vision: 3.0 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- 3D: 1.8 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17069" target="_blank" rel="noopener noreferrer">Blindfolded Spider-man Optimization: A Single-Point Metaheuristics Suitable for Continuous and Discrete Spaces</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Satyam Mittal
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In this study, we introduce a new single point metaheuristic optimization approach suitable for both continuous and discrete domains. The proposed algorithm, entitled Blindfolded Spiderman Optimization, follows a piecewise linear search trajectory where each line segment considers a move to an impro</span>
                
                <span class="abstract-full" style="display: none;">In this study, we introduce a new single point metaheuristic optimization approach suitable for both continuous and discrete domains. The proposed algorithm, entitled Blindfolded Spiderman Optimization, follows a piecewise linear search trajectory where each line segment considers a move to an improved solution point. The trajectory resembles spiderman jumping from one building to the highest neighbor building in a blindfolded manner. Blindfolded Spiderman Optimization builds on top of the Buggy Pinball Optimization algorithm. Blindfolded Spiderman Optimization is tested on 16 mathematical optimization functions and one discrete problem of Unbounded Knapsack. We perform a thorough evaluation of Blindfolded Spiderman Optimization against established and state-of-the-art metaheuristic optimization methods, including Whale Optimization, Grey Wolf Optimization, Particle Swarm Optimization, Simulated Annealing, Threshold Accepting, and Buggy Pinball Optimization considering various optimization domains and dimensions. We show that Blindfolded Spiderman Optimization achieves great performance on both continuous and discrete spaces, and superior performance compared to all single-point metaheuristic approaches considered.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.0 -->
                    
                <!-- Medicine: 3.4 -->
                    
                <!-- Evolutionary Algorithms: 2.6 -->
                    
                <!-- Federated Learning: 2.3 -->
                    
                <!-- Bayesian Optimization: 2.2 -->
                    
                <!-- 3D: 1.8 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- GNN: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17070" target="_blank" rel="noopener noreferrer">Improving endpoint detection in end-to-end streaming ASR for conversational speech</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Anandh C, Karthik Pandia Durai, Jeena Prakash, Manickavela Arumugam, Kadri Hacioglu, S. Pavankumar Dubagunta, Andreas Stolcke, Shankar Venkatesan, Aravind Ganapathiraju
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">ASR endpointing (EP) plays a major role in delivering a good user experience in products supporting human or artificial agents in human-human/machine conversations. Transducer-based ASR (T-ASR) is an end-to-end (E2E) ASR modelling technique preferred for streaming. A major limitation of T-ASR is del</span>
                
                <span class="abstract-full" style="display: none;">ASR endpointing (EP) plays a major role in delivering a good user experience in products supporting human or artificial agents in human-human/machine conversations. Transducer-based ASR (T-ASR) is an end-to-end (E2E) ASR modelling technique preferred for streaming. A major limitation of T-ASR is delayed emission of ASR outputs, which could lead to errors or delays in EP. Inaccurate EP will cut the user off while speaking, returning incomplete transcript while delays in EP will increase the perceived latency, degrading the user experience. We propose methods to improve EP by addressing delayed emission along with EP mistakes. To address the delayed emission problem, we introduce an end-of-word token at the end of each word, along with a delay penalty. The EP delay is addressed by obtaining a reliable frame-level speech activity detection using an auxiliary network. We apply the proposed methods on Switchboard conversational speech corpus and evaluate it against a delay penalty method.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Networks: 2.7 -->
                    
                <!-- LLMs: 2.6 -->
                    
                <!-- Medicine: 2.2 -->
                    
                <!-- Game Theory: 1.8 -->
                    
                <!-- Cryptography: 1.8 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Math: 1.4 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Hardware: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17076" target="_blank" rel="noopener noreferrer">Impact of Frame Rates on Speech Tokenizer: A Case Study on Mandarin and English</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Haoyang Zhang, Hexin Liu, Xiangyu Zhang, Qiquan Zhang, Yuchen Hu, Junqi Zhao, Fei Tian, Xuerui Yang, Eng Siong Chng
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The speech tokenizer plays a crucial role in recent speech tasks, generally serving as a bridge between speech signals and language models. While low-frame-rate codecs are widely employed as speech tokenizers, the impact of frame rates on speech tokens remains underexplored. In this study, we invest</span>
                
                <span class="abstract-full" style="display: none;">The speech tokenizer plays a crucial role in recent speech tasks, generally serving as a bridge between speech signals and language models. While low-frame-rate codecs are widely employed as speech tokenizers, the impact of frame rates on speech tokens remains underexplored. In this study, we investigate how varying frame rates affect speech tokenization by examining Mandarin and English, two typologically distinct languages. We encode speech at different frame rates and evaluate the resulting semantic tokens in the speech recognition task. Our findings reveal that frame rate variations influence speech tokenization differently for each language, highlighting the interplay between frame rates, phonetic density, and language-specific acoustic features. The results provide insights into optimizing frame rate selection for speech tokenizers, with implications for automatic speech recognition, text-to-speech, and other speech-related applications.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.4 -->
                    
                <!-- Medicine: 4.0 -->
                    
                <!-- Blockchain: 3.5 -->
                    
                <!-- Computer Vision: 2.7 -->
                    
                <!-- Hardware: 2.6 -->
                    
                <!-- Quantum Computing: 2.1 -->
                    
                <!-- Datasets: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Federated Learning: 1.6 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- T2I: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17077" target="_blank" rel="noopener noreferrer">Streamlining HTTP Flooding Attack Detection through Incremental Feature Selection</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Upasana Sarmah, Parthajit Borah, D. K. Bhattacharyya
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Applications over the Web primarily rely on the HTTP protocol to transmit web pages to and from systems. There are a variety of application layer protocols, but among all, HTTP is the most targeted because of its versatility and ease of integration with online services. The attackers leverage the fa</span>
                
                <span class="abstract-full" style="display: none;">Applications over the Web primarily rely on the HTTP protocol to transmit web pages to and from systems. There are a variety of application layer protocols, but among all, HTTP is the most targeted because of its versatility and ease of integration with online services. The attackers leverage the fact that by default no detection system blocks any HTTP traffic. Thus, by exploiting such characteristics of the protocol, attacks are launched against web applications. HTTP flooding attacks are one such attack in the application layer of the OSI model. In this paper, a method for the detection of such an attack is proposed. The heart of the detection method is an incremental feature subset selection method based on mutual information and correlation. INFS-MICC helps in identifying a subset of highly relevant and independent feature subset so as to detect HTTP Flooding attacks with best possible classification performance in near-real time.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 2.2 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- Hardware: 2.2 -->
                    
                <!-- LLMs: 2.1 -->
                    
                <!-- Blockchain: 2.0 -->
                    
                <!-- Computer Vision: 2.0 -->
                    
                <!-- Math: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- Networks: 1.4 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Cryptography: 1.1 -->
                    
                <!-- Game Theory: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17083" target="_blank" rel="noopener noreferrer">Scale-invariant Attention</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ben Anson, Xi Wang, Laurence Aitchison
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">One persistent challenge in LLM research is the development of attention mechanisms that are able to generalise from training on shorter contexts to inference on longer contexts. We propose two conditions that we expect all effective long context attention mechanisms to have: scale-invariant total a</span>
                
                <span class="abstract-full" style="display: none;">One persistent challenge in LLM research is the development of attention mechanisms that are able to generalise from training on shorter contexts to inference on longer contexts. We propose two conditions that we expect all effective long context attention mechanisms to have: scale-invariant total attention, and scale-invariant attention sparsity. Under a Gaussian assumption, we show that a simple position-dependent transformation of the attention logits is sufficient for these conditions to hold. Experimentally we find that the resulting scale-invariant attention scheme gives considerable benefits in terms of validation loss when zero-shot generalising from training on short contexts to validation on longer contexts, and is effective at long-context retrieval.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.9 -->
                    
                <!-- GNN: 3.5 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Bayesian Optimization: 1.9 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Medicine: 1.6 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Networks: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17085" target="_blank" rel="noopener noreferrer">GSDFuse: Capturing Cognitive Inconsistencies from Multi-Dimensional Weak Signals in Social Media Steganalysis</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Kaibo Huang, Zipei Zhang, Yukun Wei, TianXin Zhang, Zhongliang Yang, Linna Zhou
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The ubiquity of social media platforms facilitates malicious linguistic steganography, posing significant security risks. Steganalysis is profoundly hindered by the challenge of identifying subtle cognitive inconsistencies arising from textual fragmentation and complex dialogue structures, and the d</span>
                
                <span class="abstract-full" style="display: none;">The ubiquity of social media platforms facilitates malicious linguistic steganography, posing significant security risks. Steganalysis is profoundly hindered by the challenge of identifying subtle cognitive inconsistencies arising from textual fragmentation and complex dialogue structures, and the difficulty in achieving robust aggregation of multi-dimensional weak signals, especially given extreme steganographic sparsity and sophisticated steganography. These core detection difficulties are compounded by significant data imbalance. This paper introduces GSDFuse, a novel method designed to systematically overcome these obstacles. GSDFuse employs a holistic approach, synergistically integrating hierarchical multi-modal feature engineering to capture diverse signals, strategic data augmentation to address sparsity, adaptive evidence fusion to intelligently aggregate weak signals, and discriminative embedding learning to enhance sensitivity to subtle inconsistencies. Experiments on social media datasets demonstrate GSDFuse's state-of-the-art (SOTA) performance in identifying sophisticated steganography within complex dialogue environments. The source code for GSDFuse is available at https://github.com/NebulaEmmaZh/GSDFuse.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.6 -->
                    
                <!-- Medicine: 3.0 -->
                    
                <!-- GNN: 2.6 -->
                    
                <!-- Blockchain: 2.6 -->
                    
                <!-- Computer Vision: 2.5 -->
                    
                <!-- Decision Trees: 1.9 -->
                    
                <!-- Datasets: 1.8 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Robotics: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17092" target="_blank" rel="noopener noreferrer">Covert Attacks on Machine Learning Training in Passively Secure MPC</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Matthew Jagielski, Daniel Escudero, Rahul Rachuri, Peter Scholl
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Secure multiparty computation (MPC) allows data owners to train machine learning models on combined data while keeping the underlying training data private. The MPC threat model either considers an adversary who passively corrupts some parties without affecting their overall behavior, or an adversar</span>
                
                <span class="abstract-full" style="display: none;">Secure multiparty computation (MPC) allows data owners to train machine learning models on combined data while keeping the underlying training data private. The MPC threat model either considers an adversary who passively corrupts some parties without affecting their overall behavior, or an adversary who actively modifies the behavior of corrupt parties. It has been argued that in some settings, active security is not a major concern, partly because of the potential risk of reputation loss if a party is detected cheating.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 3.4 -->
                    
                <!-- Medicine: 3.4 -->
                    
                <!-- Federated Learning: 2.9 -->
                    
                <!-- Blockchain: 2.6 -->
                    
                <!-- GNN: 2.5 -->
                    
                <!-- Quantum Computing: 2.3 -->
                    
                <!-- Bayesian Optimization: 2.2 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Cryptography: 1.4 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Networks: 1.1 -->
                    
                <!-- Game Theory: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17108" target="_blank" rel="noopener noreferrer">REMS: a unified solution representation, problem modeling and metaheuristic algorithm design for general combinatorial optimization problems</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Aijuan Song, Guohua Wu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Combinatorial optimization problems (COPs) with discrete variables and finite search space are critical across numerous fields, and solving them in metaheuristic algorithms is popular. However, addressing a specific COP typically requires developing a tailored and handcrafted algorithm. Even minor a</span>
                
                <span class="abstract-full" style="display: none;">Combinatorial optimization problems (COPs) with discrete variables and finite search space are critical across numerous fields, and solving them in metaheuristic algorithms is popular. However, addressing a specific COP typically requires developing a tailored and handcrafted algorithm. Even minor adjustments, such as constraint changes, may necessitate algorithm redevelopment. Therefore, establishing a framework for formulating diverse COPs into a unified paradigm and designing reusable metaheuristic algorithms is valuable. A COP can be typically viewed as the process of giving resources to perform specific tasks, subjecting to given constraints. Motivated by this, a resource-centered modeling and solving framework (REMS) is introduced for the first time. We first extract and define resources and tasks from a COP. Subsequently, given predetermined resources, the solution structure is unified as assigning tasks to resources, from which variables, objectives, and constraints can be derived and a problem model is constructed. To solve the modeled COPs, several fundamental operators are designed based on the unified solution structure, including the initial solution, neighborhood structure, destruction and repair, crossover, and ranking. These operators enable the development of various metaheuristic algorithms. Specially, 4 single-point-based algorithms and 1 population-based algorithm are configured herein. Experiments on 10 COPs, covering routing, location, loading, assignment, scheduling, and graph coloring problems, show that REMS can model these COPs within the unified paradigm and effectively solve them with the designed metaheuristic algorithms. Furthermore, REMS is more competitive than GUROBI and SCIP in tackling large-scale instances and complex COPs, and outperforms OR-TOOLS on several challenging COPs.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.7 -->
                    
                <!-- LLMs: 2.5 -->
                    
                <!-- Evolutionary Algorithms: 2.3 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- 3D: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17150" target="_blank" rel="noopener noreferrer">Efficient Training of Neural SDEs Using Stochastic Optimal Control</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Rembert Daems, Manfred Opper, Guillaume Crevecoeur, Tolga Birdal
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We present a hierarchical, control theory inspired method for variational inference (VI) for neural stochastic differential equations (SDEs). While VI for neural SDEs is a promising avenue for uncertainty-aware reasoning in time-series, it is computationally challenging due to the iterative nature o</span>
                
                <span class="abstract-full" style="display: none;">We present a hierarchical, control theory inspired method for variational inference (VI) for neural stochastic differential equations (SDEs). While VI for neural SDEs is a promising avenue for uncertainty-aware reasoning in time-series, it is computationally challenging due to the iterative nature of maximizing the ELBO. In this work, we propose to decompose the control term into linear and residual non-linear components and derive an optimal control term for linear SDEs, using stochastic optimal control. Modeling the non-linear component by a neural network, we show how to efficiently train neural SDEs without sacrificing their expressive power. Since the linear part of the control term is optimal and does not need to be learned, the training is initialized at a lower cost and we observe faster convergence.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 2.9 -->
                    
                <!-- LLMs: 2.4 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- Computer Vision: 1.9 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Networks: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17151" target="_blank" rel="noopener noreferrer">Bayesian Optimization for Enhanced Language Models: Optimizing Acquisition Functions</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zishuo Bao, Yibo Liu, Changyutao Qiu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">With the rise of different language model architecture, fine-tuning is becoming even more important for down stream tasks Model gets messy, finding proper hyperparameters for fine-tuning. Although BO has been tried for hyperparameter tuning, most of the existing methods are oblivious to the fact tha</span>
                
                <span class="abstract-full" style="display: none;">With the rise of different language model architecture, fine-tuning is becoming even more important for down stream tasks Model gets messy, finding proper hyperparameters for fine-tuning. Although BO has been tried for hyperparameter tuning, most of the existing methods are oblivious to the fact that BO relies on careful choices of acquisition functions, which are essential components of BO that guide how much to explore versus exploit during the optimization process; Different acquisition functions have different levels of sensitivity towards training loss and validation performance; existing methods often just apply an acquisition function no matter if the training and validation performance are sensitive to the acquisition function or not. This work introduces{Bilevel - BO - SWA}, a model fusion approach coupled with a bilevel BO strategy to improve the fine - tunning of large language models. Our work on mixture of acquisition functions like EI and UCB into nested opt loops, where inner loop perform minimization of training loss while outer loops optimized w.r.t. val metric. Experiments on GLUE tasks using RoBERTA - base show that when using EI and UCB, there is an improvement in generalization, and fine - tuning can be improved by up to 2.7%.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.7 -->
                    
                <!-- Bayesian Optimization: 4.0 -->
                    
                <!-- Evolutionary Algorithms: 3.1 -->
                    
                <!-- Medicine: 3.1 -->
                    
                <!-- Federated Learning: 2.7 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17165" target="_blank" rel="noopener noreferrer">A Toolkit for Compliance, a Toolkit for Justice: Drawing on Cross-sectoral Expertise to Develop a Pro-justice EU AI Act Toolkit</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Tomasz Hollanek, Yulu Pi, Cosimo Fiorini, Virginia Vignali, Dorian Peters, Eleanor Drage
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The introduction of the AI Act in the European Union presents the AI research and practice community with a set of new challenges related to compliance. While it is certain that AI practitioners will require additional guidance and tools to meet these requirements, previous research on toolkits that</span>
                
                <span class="abstract-full" style="display: none;">The introduction of the AI Act in the European Union presents the AI research and practice community with a set of new challenges related to compliance. While it is certain that AI practitioners will require additional guidance and tools to meet these requirements, previous research on toolkits that aim to translate the theory of AI ethics into development and deployment practice suggests that such resources suffer from multiple limitations. These limitations stem, in part, from the fact that the toolkits are either produced by industry-based teams or by academics whose work tends to be abstract and divorced from the realities of industry. In this paper, we discuss the challenge of developing an AI ethics toolkit for practitioners that helps them comply with new AI-focused regulation, but that also moves beyond mere compliance to consider broader socio-ethical questions throughout development and deployment. The toolkit was created through a cross-sectoral collaboration between an academic team based in the UK and an industry team in Italy. We outline the background and rationale for creating a pro-justice AI Act compliance toolkit, detail the process undertaken to develop it, and describe the collaboration and negotiation efforts that shaped its creation. We aim for the described process to serve as a blueprint for other teams navigating the challenges of academia-industry partnerships and aspiring to produce usable and meaningful AI ethics resources.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 3.2 -->
                    
                <!-- LLMs: 3.0 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Federated Learning: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- GNN: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17191" target="_blank" rel="noopener noreferrer">An Adaptive-rank Approach with Greedy Sampling for Multi-scale BGK Equations</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: William A. Sands, Jing-Mei Qiu, Daniel Hayes, Nanyi Zheng
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In this paper, we propose a novel adaptive-rank method for simulating multi-scale BGK equations, based on a greedy sampling strategy. The method adaptively selects important rows and columns of the solution matrix and updates them using a local semi-Lagrangian solver. An adaptive cross approximation</span>
                
                <span class="abstract-full" style="display: none;">In this paper, we propose a novel adaptive-rank method for simulating multi-scale BGK equations, based on a greedy sampling strategy. The method adaptively selects important rows and columns of the solution matrix and updates them using a local semi-Lagrangian solver. An adaptive cross approximation then reconstructs the full solution matrix. This extends our prior semi-Lagrangian adaptive-rank framework, developed for the Vlasov-Poisson system, to nonlinear collisional kinetic equations. Unlike step-and-truncate low-rank integrators, our greedy sampling approach avoids explicit low-rank decompositions of nonlinear terms, such as the local Maxwellian in the BGK operator. To ensure conservation, we introduce a locally macroscopic conservative correction that implicitly couples the kinetic and macroscopic systems, enforcing mass, momentum, and energy conservation. Through asymptotic analysis, we show that this correction preserves the full-grid scheme's asymptotic behavior, and that the proposed method is conditionally asymptotic-preserving in the low-rank setting. A key advantage of our approach is its use of a local semi-Lagrangian solver, which allows large time steps. This flexibility is retained in the macroscopic solver using high-order stiffly accurate diagonally implicit Runge-Kutta methods. The resulting nonlinear systems are solved efficiently using a Jacobian-free Newton-Krylov method, avoiding the need for preconditioning at modest CFL numbers. Each nonlinear iteration provides a self-consistent correction to a provisional kinetic solution, which serves as a dynamic closure for the macroscopic model. Numerical results demonstrate the method's accuracy in capturing shocks and its robustness across mixed-regime problems with wide-ranging Knudsen numbers.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 2.8 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- LLMs: 2.1 -->
                    
                <!-- Reinforcement Learning: 1.9 -->
                    
                <!-- Networks: 1.7 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Math: 1.1 -->
                    
                <!-- Cryptography: 1.0 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17206" target="_blank" rel="noopener noreferrer">FB-RAG: Improving RAG with Forward and Backward Lookup</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Kushal Chawla, Alfy Samuel, Anoop Kumar, Daben Liu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The performance of Retrieval Augmented Generation (RAG) systems relies heavily on the retriever quality and the size of the retrieved context. A large enough context ensures that the relevant information is present in the input context for the LLM, but also incorporates irrelevant content that has b</span>
                
                <span class="abstract-full" style="display: none;">The performance of Retrieval Augmented Generation (RAG) systems relies heavily on the retriever quality and the size of the retrieved context. A large enough context ensures that the relevant information is present in the input context for the LLM, but also incorporates irrelevant content that has been shown to confuse the models. On the other hand, a smaller context reduces the irrelevant information, but it often comes at the risk of losing important information necessary to answer the input question. This duality is especially challenging to manage for complex queries that contain little information to retrieve the relevant chunks from the full context. To address this, we present a novel framework, called FB-RAG, which enhances the RAG pipeline by relying on a combination of backward lookup (overlap with the query) and forward lookup (overlap with candidate reasons and answers) to retrieve specific context chunks that are the most relevant for answering the input query. Our evaluations on 9 datasets from two leading benchmarks show that FB-RAG consistently outperforms RAG and Long Context baselines developed recently for these benchmarks. We further show that FB-RAG can improve performance while reducing latency. We perform qualitative analysis of the strengths and shortcomings of our approach, providing specific insights to guide future work.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 3.3 -->
                    
                <!-- Medicine: 2.9 -->
                    
                <!-- Reinforcement Learning: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Computer Vision: 1.9 -->
                    
                <!-- Bayesian Optimization: 1.6 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Math: 1.5 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- LLMs: 1.4 -->
                    
                <!-- Networks: 1.2 -->
                    
                <!-- Hardware: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17223" target="_blank" rel="noopener noreferrer">REACT 2025: the Third Multiple Appropriate Facial Reaction Generation Challenge</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Siyang Song, Micol Spitale, Xiangyu Kong, Hengde Zhu, Cheng Luo, Cristina Palmero, German Barquero, Sergio Escalera, Michel Valstar, Mohamed Daoudi, Tobias Baur, Fabien Ringeval, Andrew Howes, Elisabeth Andre, Hatice Gunes
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In dyadic interactions, a broad spectrum of human facial reactions might be appropriate for responding to each human speaker behaviour. Following the successful organisation of the REACT 2023 and REACT 2024 challenges, we are proposing the REACT 2025 challenge encouraging the development and benchma</span>
                
                <span class="abstract-full" style="display: none;">In dyadic interactions, a broad spectrum of human facial reactions might be appropriate for responding to each human speaker behaviour. Following the successful organisation of the REACT 2023 and REACT 2024 challenges, we are proposing the REACT 2025 challenge encouraging the development and benchmarking of Machine Learning (ML) models that can be used to generate multiple appropriate, diverse, realistic and synchronised human-style facial reactions expressed by human listeners in response to an input stimulus (i.e., audio-visual behaviours expressed by their corresponding speakers). As a key of the challenge, we provide challenge participants with the first natural and large-scale multi-modal MAFRG dataset (called MARS) recording 137 human-human dyadic interactions containing a total of 2856 interaction sessions covering five different topics. In addition, this paper also presents the challenge guidelines and the performance of our baselines on the two proposed sub-challenges: Offline MAFRG and Online MAFRG, respectively. The challenge baseline code is publicly available at https://github.com/reactmultimodalchallenge/baseline_react2025</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 3.8 -->
                    
                <!-- LLMs: 3.2 -->
                    
                <!-- Medicine: 2.9 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Reinforcement Learning: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.4 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17226" target="_blank" rel="noopener noreferrer">Secure and Private Federated Learning: Achieving Adversarial Resilience through Robust Aggregation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Kun Yang, Neena Imam
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Federated Learning (FL) enables collaborative machine learning across decentralized data sources without sharing raw data. It offers a promising approach to privacy-preserving AI. However, FL remains vulnerable to adversarial threats from malicious participants, referred to as Byzantine clients, who</span>
                
                <span class="abstract-full" style="display: none;">Federated Learning (FL) enables collaborative machine learning across decentralized data sources without sharing raw data. It offers a promising approach to privacy-preserving AI. However, FL remains vulnerable to adversarial threats from malicious participants, referred to as Byzantine clients, who can send misleading updates to corrupt the global model. Traditional aggregation methods, such as simple averaging, are not robust to such attacks. More resilient approaches, like the Krum algorithm, require prior knowledge of the number of malicious clients, which is often unavailable in real-world scenarios. To address these limitations, we propose Average-rKrum (ArKrum), a novel aggregation strategy designed to enhance both the resilience and privacy guarantees of FL systems. Building on our previous work (rKrum), ArKrum introduces two key innovations. First, it includes a median-based filtering mechanism that removes extreme outliers before estimating the number of adversarial clients. Second, it applies a multi-update averaging scheme to improve stability and performance, particularly when client data distributions are not identical. We evaluate ArKrum on benchmark image and text datasets under three widely studied Byzantine attack types. Results show that ArKrum consistently achieves high accuracy and stability. It performs as well as or better than other robust aggregation methods. These findings demonstrate that ArKrum is an effective and practical solution for secure FL systems in adversarial environments.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 3.7 -->
                    
                <!-- LLMs: 3.2 -->
                    
                <!-- GNN: 2.6 -->
                    
                <!-- Computer Vision: 2.2 -->
                    
                <!-- Quantum Computing: 2.0 -->
                    
                <!-- Decision Trees: 1.8 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Medicine: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.4 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Datasets: 1.0 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17234" target="_blank" rel="noopener noreferrer">Quantifying Global Networks of Exchange through the Louvain Method</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Aryan Sharma, Jaden Li, Christina Chu, Anna Sisk
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Congressional Research Service (CRS) reports provide detailed analyses of major policy issues to members of the US Congress. We extract and analyze data from 2,010 CRS reports written between 1996 and 2024 in order to quantify the relationships between countries. The data is processed and converted </span>
                
                <span class="abstract-full" style="display: none;">Congressional Research Service (CRS) reports provide detailed analyses of major policy issues to members of the US Congress. We extract and analyze data from 2,010 CRS reports written between 1996 and 2024 in order to quantify the relationships between countries. The data is processed and converted into a weighted graph, representing 172 unique countries as nodes and 4,137 interests as bidirectional edges. Through the Louvain method, we use a greedy algorithm to extract non-overlapping communities from our network and identify clusters with shared interests. We then compute the eigenvector centrality of countries, effectively highlighting their network influence. The results of this work could enable improvements in sourcing evidence for analytic products and understanding the connectivity of our world.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.5 -->
                    
                <!-- LLMs: 3.3 -->
                    
                <!-- Hardware: 2.2 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- GNN: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17236" target="_blank" rel="noopener noreferrer">LogStamping: A blockchain-based log auditing approach for large-scale systems</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Md Shariful Islam, M. Sohel Rahman
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Log management is crucial for ensuring the security, integrity, and compliance of modern information systems. Traditional log management solutions face challenges in achieving tamper-proofing, scalability, and real-time processing in distributed environments. This paper presents a blockchain-based l</span>
                
                <span class="abstract-full" style="display: none;">Log management is crucial for ensuring the security, integrity, and compliance of modern information systems. Traditional log management solutions face challenges in achieving tamper-proofing, scalability, and real-time processing in distributed environments. This paper presents a blockchain-based log management framework that addresses these limitations by leveraging blockchain's decentralized, immutable, and transparent features. The framework integrates a hybrid on-chain and off-chain storage model, combining blockchain's integrity guarantees with the scalability of distributed storage solutions like IPFS. Smart contracts automate log validation and access control, while cryptographic techniques ensure privacy and confidentiality. With a focus on real-time log processing, the framework is designed to handle the high-volume log generation typical in large-scale systems, such as data centers and network infrastructure. Performance evaluations demonstrate the framework's scalability, low latency, and ability to manage millions of log entries while maintaining strong security guarantees. Additionally, the paper discusses challenges like blockchain storage overhead and energy consumption, offering insights for enhancing future systems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.7 -->
                    
                <!-- LLMs: 3.7 -->
                    
                <!-- Blockchain: 2.7 -->
                    
                <!-- Hardware: 2.6 -->
                    
                <!-- Computer Vision: 2.2 -->
                    
                <!-- Datasets: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17240" target="_blank" rel="noopener noreferrer">Sequent Calculi for Data-Aware Modal Logics</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Carlos Areces, Valentin Cassano, Danae Dutto, Raul Fervari
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This document serves as a companion to the paper of the same title, wherein we introduce a Gentzen-style sequent calculus for HXPathD. It provides full technical details and proofs from the main paper. As such, it is intended as a reference for readers seeking a deeper understanding of the formal re</span>
                
                <span class="abstract-full" style="display: none;">This document serves as a companion to the paper of the same title, wherein we introduce a Gentzen-style sequent calculus for HXPathD. It provides full technical details and proofs from the main paper. As such, it is intended as a reference for readers seeking a deeper understanding of the formal results, including soundness, completeness, invertibility, and cut elimination for the calculus.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 3.6 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Networks: 1.9 -->
                    
                <!-- LLMs: 1.7 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Cryptography: 1.4 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- Math: 1.1 -->
                    
                <!-- Finance: 1.1 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17243" target="_blank" rel="noopener noreferrer">Finite element spaces of double forms</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yakov Berchenko-Kogan, Evan S. Gawlik
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The tensor product of two differential forms of degree $p$ and $q$ is a multilinear form that is alternating in its first $p$ arguments and alternating in its last $q$ arguments. These forms, which are known as double forms or $(p,q)$-forms, play a central role in certain differential complexes that</span>
                
                <span class="abstract-full" style="display: none;">The tensor product of two differential forms of degree $p$ and $q$ is a multilinear form that is alternating in its first $p$ arguments and alternating in its last $q$ arguments. These forms, which are known as double forms or $(p,q)$-forms, play a central role in certain differential complexes that arise when studying partial differential equations. We construct piecewise polynomial finite element spaces for all of the natural subspaces of the space of $(p,q)$-forms, excluding one subspace which fails to admit a piecewise constant discretization. As special cases, our construction recovers known finite element spaces for symmetric matrices with tangential-tangential continuity (the Regge finite elements), symmetric matrices with normal-normal continuity, and trace-free matrices with normal-tangential continuity. It also gives rise to new spaces, like a finite element space for tensors possessing the symmetries of the Riemann curvature tensor.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 3.7 -->
                    
                <!-- Medicine: 3.6 -->
                    
                <!-- Quantum Computing: 2.1 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Bayesian Optimization: 1.8 -->
                    
                <!-- Math: 1.8 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Networks: 1.6 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Game Theory: 1.3 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- Cryptography: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17248" target="_blank" rel="noopener noreferrer">Backdoors in DRL: Four Environments Focusing on In-distribution Triggers</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Chace Ashcraft, Ted Staley, Josh Carney, Cameron Hickert, Derek Juba, Kiran Karra, Nathan Drenkow
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Backdoor attacks, or trojans, pose a security risk by concealing undesirable behavior in deep neural network models. Open-source neural networks are downloaded from the internet daily, possibly containing backdoors, and third-party model developers are common. To advance research on backdoor attack </span>
                
                <span class="abstract-full" style="display: none;">Backdoor attacks, or trojans, pose a security risk by concealing undesirable behavior in deep neural network models. Open-source neural networks are downloaded from the internet daily, possibly containing backdoors, and third-party model developers are common. To advance research on backdoor attack mitigation, we develop several trojans for deep reinforcement learning (DRL) agents. We focus on in-distribution triggers, which occur within the agent's natural data distribution, since they pose a more significant security threat than out-of-distribution triggers due to their ease of activation by the attacker during model deployment. We implement backdoor attacks in four reinforcement learning (RL) environments: LavaWorld, Randomized LavaWorld, Colorful Memory, and Modified Safety Gymnasium. We train various models, both clean and backdoored, to characterize these attacks. We find that in-distribution triggers can require additional effort to implement and be more challenging for models to learn, but are nevertheless viable threats in DRL even using basic data poisoning attacks.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.3 -->
                    
                <!-- Medicine: 2.9 -->
                    
                <!-- Computer Vision: 2.6 -->
                    
                <!-- GNN: 2.2 -->
                    
                <!-- Quantum Computing: 2.2 -->
                    
                <!-- Blockchain: 2.1 -->
                    
                <!-- Reinforcement Learning: 1.9 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- 3D: 1.1 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17253" target="_blank" rel="noopener noreferrer">Understanding the Security Landscape of Embedded Non-Volatile Memories: A Comprehensive Survey</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zakia Tamanna Tisha, Ujjwal Guin
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The modern semiconductor industry requires memory solutions that can keep pace with the high-speed demands of high-performance computing. Embedded non-volatile memories (eNVMs) address these requirements by offering faster access to stored data at an improved computational throughput and efficiency.</span>
                
                <span class="abstract-full" style="display: none;">The modern semiconductor industry requires memory solutions that can keep pace with the high-speed demands of high-performance computing. Embedded non-volatile memories (eNVMs) address these requirements by offering faster access to stored data at an improved computational throughput and efficiency. Furthermore, these technologies offer numerous appealing features, including limited area-energy-runtime budget and data retention capabilities. Among these, the data retention feature of eNVMs has garnered particular interest within the semiconductor community. Although this property allows eNVMs to retain data even in the absence of a continuous power supply, it also introduces some vulnerabilities, prompting security concerns. These concerns have sparked increased interest in examining the broader security implications associated with eNVM technologies. This paper examines the security aspects of eNVMs by discussing the reasons for vulnerabilities in specific memories from an architectural point of view. Additionally, this paper extensively reviews eNVM-based security primitives, such as physically unclonable functions and true random number generators, as well as techniques like logic obfuscation. The paper also explores a broad spectrum of security threats to eNVMs, including physical attacks such as side-channel attacks, fault injection, and probing, as well as logical threats like information leakage, denial-of-service, and thermal attacks. Finally, the paper presents a study of publication trends in the eNVM domain since the early 2000s, reflecting the rising momentum and research activity in this field.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Blockchain: 3.9 -->
                    
                <!-- Hardware: 3.2 -->
                    
                <!-- LLMs: 3.2 -->
                    
                <!-- Datasets: 2.2 -->
                    
                <!-- Medicine: 2.2 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Networks: 1.3 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- Cryptography: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17268" target="_blank" rel="noopener noreferrer">IAE Optimized PID Tuning via Second Order Step Response Target Matching</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Senol Gulgonul
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper presents SOSTIAE (Second-Order System Target IAE), a novel PID tuning method that combines IAE minimization with explicit transient response shaping for practical control applications. The algorithm generates optimal PID parameters by matching the closed-loop response to a target second-o</span>
                
                <span class="abstract-full" style="display: none;">This paper presents SOSTIAE (Second-Order System Target IAE), a novel PID tuning method that combines IAE minimization with explicit transient response shaping for practical control applications. The algorithm generates optimal PID parameters by matching the closed-loop response to a target second-order system with user-defined settling time (T_s) and percent overshoot (PO), while maintaining the conventional IAE performance metric. Comparative evaluations on first to third-order systems demonstrate that SOSTIAE consistently outperforms MATLAB's proprietary pidtune() function, achieving 47-67% lower overshoot and up to 26% better IAE performance for higher-order plants. The constrained optimization framework ensures physically realizable controllers by enforcing non-negative PID gains and stability criteria, addressing known limitations of unconstrained IAE methods. Results indicate that SOSTIAE provides engineers with a systematic alternative for PID tuning when transient specifications and practical implementation constraints are critical.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.0 -->
                    
                <!-- Medicine: 3.9 -->
                    
                <!-- HPO and AutoML: 2.3 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- Computer Vision: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- Quantum Computing: 2.0 -->
                    
                <!-- 3D: 1.9 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- Networks: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17270" target="_blank" rel="noopener noreferrer">Navigating Polytopes with Safety: A Control Barrier Function Approach</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Tamas G. Molnar
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Collision-free motion is a fundamental requirement for many autonomous systems. This paper develops a safety-critical control approach for the collision-free navigation of polytope-shaped agents in polytope-shaped environments. A systematic method is proposed to generate control barrier function can</span>
                
                <span class="abstract-full" style="display: none;">Collision-free motion is a fundamental requirement for many autonomous systems. This paper develops a safety-critical control approach for the collision-free navigation of polytope-shaped agents in polytope-shaped environments. A systematic method is proposed to generate control barrier function candidates in closed form that lead to controllers with formal safety guarantees. The proposed approach is demonstrated through simulation, with obstacle avoidance examples in 2D and 3D, including dynamically changing environments.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.7 -->
                    
                <!-- Networks: 2.3 -->
                    
                <!-- HPO and AutoML: 2.2 -->
                    
                <!-- Medicine: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Bayesian Optimization: 1.6 -->
                    
                <!-- Federated Learning: 1.6 -->
                    
                <!-- Game Theory: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Cryptography: 1.2 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Hardware: 1.1 -->
                    
                <!-- Math: 1.1 -->
                    
                <!-- RAG: 1.1 -->
                    
                <!-- Robotics: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17271" target="_blank" rel="noopener noreferrer">Distribution through Repeated Market with Buying Rights</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: David Sychrovsk\'y, Jakub \v{C}ern\'y, Martin Loebl
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Resource distribution is a fundamental problem in economic and policy design, particularly when demand and supply are not naturally aligned. Without regulation, wealthier individuals may monopolize this resource, leaving the needs of others unsatisfied. While centralized distribution can ensure fair</span>
                
                <span class="abstract-full" style="display: none;">Resource distribution is a fundamental problem in economic and policy design, particularly when demand and supply are not naturally aligned. Without regulation, wealthier individuals may monopolize this resource, leaving the needs of others unsatisfied. While centralized distribution can ensure fairer division, it can struggle to manage logistics efficiently, and adapt to changing conditions, often leading to shortages, surpluses, and bureaucratic inefficiencies. Building on previous research on market-based redistribution, we examine a repeated hybrid market that incorporates buying rights. These rights, distributed iteratively by a central authority (for instance, as digital tokens), are intended to enhance fairness in the system - a unit of right is required to acquire a unit of the resource, but the rights themselves can also be traded alongside the resource in the market. We analyze how this regulatory mechanism influences the distribution of the scarce resource in the hybrid market over time. Unlike past works that relied on empirical methods, we explore the exact analytical properties of a system in which traders optimize over multiple rounds. We identify its market equilibrium, which is a natural generalization of the free market equilibrium, and show that it is coalition-proof. To assess the fairness in the system, we use the concept of frustration, which measures the gap between the resources a buyer is entitled to through their buying rights and what they actually obtain through trading. Our main theoretical result shows that using buying rights reduces the frustration by at least half compared to the free market. Empirical evaluations further support our findings, suggesting the system performs well even beyond the theoretically studied assumptions.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Networks: 2.9 -->
                    
                <!-- Math: 2.4 -->
                    
                <!-- Federated Learning: 2.3 -->
                    
                <!-- Cryptography: 2.1 -->
                    
                <!-- Finance: 2.0 -->
                    
                <!-- Reinforcement Learning: 1.8 -->
                    
                <!-- Game Theory: 1.8 -->
                    
                <!-- Pathfinding: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- LLMs: 1.3 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                <!-- Robotics: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17274" target="_blank" rel="noopener noreferrer">Vehicular Intrusion Detection System for Controller Area Network: A Comprehensive Survey and Evaluation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yangyang Liu, Lei Xue, Sishan Wang, Xiapu Luo, Kaifa Zhao, Pengfei Jing, Xiaobo Ma, Yajuan Tang, Haiying Zhou
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The progress of automotive technologies has made cybersecurity a crucial focus, leading to various cyber attacks. These attacks primarily target the Controller Area Network (CAN) and specialized Electronic Control Units (ECUs). In order to mitigate these attacks and bolster the security of vehicular</span>
                
                <span class="abstract-full" style="display: none;">The progress of automotive technologies has made cybersecurity a crucial focus, leading to various cyber attacks. These attacks primarily target the Controller Area Network (CAN) and specialized Electronic Control Units (ECUs). In order to mitigate these attacks and bolster the security of vehicular systems, numerous defense solutions have been proposed.These solutions aim to detect diverse forms of vehicular attacks. However, the practical implementation of these solutions still presents certain limitations and challenges. In light of these circumstances, this paper undertakes a thorough examination of existing vehicular attacks and defense strategies employed against the CAN and ECUs. The objective is to provide valuable insights and inform the future design of Vehicular Intrusion Detection Systems (VIDS). The findings of our investigation reveal that the examined VIDS primarily concentrate on particular categories of attacks, neglecting the broader spectrum of potential threats. Moreover, we provide a comprehensive overview of the significant challenges encountered in implementing a robust and feasible VIDS. Additionally, we put forth several defense recommendations based on our study findings, aiming to inform and guide the future design of VIDS in the context of vehicular security.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.5 -->
                    
                <!-- Federated Learning: 3.8 -->
                    
                <!-- Medicine: 3.3 -->
                    
                <!-- Hardware: 3.0 -->
                    
                <!-- Blockchain: 2.6 -->
                    
                <!-- Evolutionary Algorithms: 2.2 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.4 -->
                    
                <!-- Computer Vision: 1.2 -->
                    
                <!-- GNN: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17275" target="_blank" rel="noopener noreferrer">ConvoyNext: A Scalable Testbed Platform for Cooperative Autonomous Vehicle Systems</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Hossein Maghsoumi, Yaser Fallah
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The advancement of cooperative autonomous vehicle systems depends heavily on effective coordination between multiple agents, aiming to enhance traffic efficiency, fuel economy, and road safety. Despite these potential benefits, real-world testing of such systems remains a major challenge and is esse</span>
                
                <span class="abstract-full" style="display: none;">The advancement of cooperative autonomous vehicle systems depends heavily on effective coordination between multiple agents, aiming to enhance traffic efficiency, fuel economy, and road safety. Despite these potential benefits, real-world testing of such systems remains a major challenge and is essential for validating control strategies, trajectory modeling methods, and communication robustness across diverse environments. To address this need, we introduce ConvoyNext, a scalable, modular, and extensible platform tailored for the real-world evaluation of cooperative driving behaviors. We demonstrate the capabilities of ConvoyNext through a series of experiments involving convoys of autonomous vehicles navigating complex trajectories. These tests highlight the platform's robustness across heterogeneous vehicle configurations and its effectiveness in assessing convoy behavior under varying communication conditions, including intentional packet loss. Our results validate ConvoyNext as a comprehensive, open-access testbed for advancing research in cooperative autonomous vehicle systems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.7 -->
                    
                <!-- Medicine: 4.3 -->
                    
                <!-- Hardware: 2.5 -->
                    
                <!-- Blockchain: 2.5 -->
                    
                <!-- Datasets: 2.3 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17277" target="_blank" rel="noopener noreferrer">Comparator-Adaptive $\Phi$-Regret: Improved Bounds, Simpler Algorithms, and Applications to Games</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Soumita Hait, Ping Li, Haipeng Luo, Mengxiao Zhang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In the classic expert problem, $\Phi$-regret measures the gap between the learner's total loss and that achieved by applying the best action transformation $\phi \in \Phi$. A recent work by Lu et al., [2025] introduces an adaptive algorithm whose regret against a comparator $\phi$ depends on a certa</span>
                
                <span class="abstract-full" style="display: none;">In the classic expert problem, $\Phi$-regret measures the gap between the learner's total loss and that achieved by applying the best action transformation $\phi \in \Phi$. A recent work by Lu et al., [2025] introduces an adaptive algorithm whose regret against a comparator $\phi$ depends on a certain sparsity-based complexity measure of $\phi$, (almost) recovering and interpolating optimal bounds for standard regret notions such as external, internal, and swap regret. In this work, we propose a general idea to achieve an even better comparator-adaptive $\Phi$-regret bound via much simpler algorithms compared to Lu et al., [2025]. Specifically, we discover a prior distribution over all possible binary transformations and show that it suffices to achieve prior-dependent regret against these transformations. Then, we propose two concrete and efficient algorithms to achieve so, where the first one learns over multiple copies of a prior-aware variant of the Kernelized MWU algorithm of Farina et al., [2022], and the second one learns over multiple copies of a prior-aware variant of the BM-reduction [Blum and Mansour, 2007]. To further showcase the power of our methods and the advantages over Lu et al., [2025] besides the simplicity and better regret bounds, we also show that our second approach can be extended to the game setting to achieve accelerated and adaptive convergence rate to $\Phi$-equilibria for a class of general-sum games. When specified to the special case of correlated equilibria, our bound improves over the existing ones from Anagnostides et al., [2022a,b]</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 4.9 -->
                    
                <!-- LLMs: 3.5 -->
                    
                <!-- Reinforcement Learning: 2.2 -->
                    
                <!-- Medicine: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 2.2 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Hardware: 1.1 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17278" target="_blank" rel="noopener noreferrer">Construction of an Impedance Control Test Bench</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Elisa G. Vergamini (S\~ao Carlos School of Engineering - University of S\~ao Paulo), Leonardo F. Dos Santos (S\~ao Carlos School of Engineering - University of S\~ao Paulo), C\'icero Zanette (S\~ao Carlos School of Engineering - University of S\~ao Paulo), Yecid Moreno (S\~ao Carlos School of Engineering - University of S\~ao Paulo), Felix M. Escalante (Institute of Science and Technology Sorocaba - S\~ao Paulo State University), Thiago Boaventura (S\~ao Carlos School of Engineering - University of S\~ao Paulo)
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Controlling the physical interaction with the environment or objects, as humans do, is a shared requirement across different types of robots. To effectively control this interaction, it is necessary to control the power delivered to the load, that is, the interaction force and the interaction veloci</span>
                
                <span class="abstract-full" style="display: none;">Controlling the physical interaction with the environment or objects, as humans do, is a shared requirement across different types of robots. To effectively control this interaction, it is necessary to control the power delivered to the load, that is, the interaction force and the interaction velocity. However, it is not possible to control these two quantities independently at the same time. An alternative is to control the relation between them, with Impedance and Admittance control, for example. The Impedance Control 2 Dimensions (IC2D) bench is a test bench designed to allow the performance analysis of different actuators and controllers at the joint level. Therefore, it was designed to be as versatile as possible, to allow the combination of linear and/or rotational motions, to use electric and/or hydraulic actuators, with loads known and defined by the user. The bench adheres to a set of requirements defined by the demands of the research group, to be a reliable, backlash-free mechatronic system to validate system dynamics models and controller designs, as well as a valuable experimental setup for benchmarking electric and hydraulic actuators. This article presents the mechanical, electrical, and hydraulic configurations used to ensure the robustness and reliability of the test bench. Benches similar to this one are commonly found in robotics laboratories around the world. However, the IC2D stands out for its versatility and reliability, as well as for supporting hydraulic and electric actuators.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 4.4 -->
                    
                <!-- Evolutionary Algorithms: 3.8 -->
                    
                <!-- Medicine: 2.4 -->
                    
                <!-- Robotics: 2.2 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- LLMs: 1.6 -->
                    
                <!-- Bayesian Optimization: 1.4 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17280" target="_blank" rel="noopener noreferrer">Mitigate One, Skew Another? Tackling Intersectional Biases in Text-to-Image Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Pushkar Shukla, Aditya Chinchure, Emily Diana, Alexander Tolbert, Kartik Hosanagar, Vineeth N Balasubramanian, Leonid Sigal, Matthew Turk
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The biases exhibited by text-to-image (TTI) models are often treated as independent, though in reality, they may be deeply interrelated. Addressing bias along one dimension - such as ethnicity or age - can inadvertently affect another, like gender, either mitigating or exacerbating existing disparit</span>
                
                <span class="abstract-full" style="display: none;">The biases exhibited by text-to-image (TTI) models are often treated as independent, though in reality, they may be deeply interrelated. Addressing bias along one dimension - such as ethnicity or age - can inadvertently affect another, like gender, either mitigating or exacerbating existing disparities. Understanding these interdependencies is crucial for designing fairer generative models, yet measuring such effects quantitatively remains a challenge. To address this, we introduce BiasConnect, a novel tool for analyzing and quantifying bias interactions in TTI models. BiasConnect uses counterfactual interventions along different bias axes to reveal the underlying structure of these interactions and estimates the effect of mitigating one bias axis on another. These estimates show strong correlation (+0.65) with observed post-mitigation outcomes. Building on BiasConnect, we propose InterMit, an intersectional bias mitigation algorithm guided by user-defined target distributions and priority weights. InterMit achieves lower bias (0.33 vs. 0.52) with fewer mitigation steps (2.38 vs. 3.15 average steps), and yields superior image quality compared to traditional techniques. Although our implementation is training-free, InterMit is modular and can be integrated with many existing debiasing approaches for TTI models, making it a flexible and extensible solution.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.6 -->
                    
                <!-- Medicine: 3.7 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- Blockchain: 2.2 -->
                    
                <!-- HPO and AutoML: 2.2 -->
                    
                <!-- Quantum Computing: 2.1 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Decision Trees: 1.9 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- T2I: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17282" target="_blank" rel="noopener noreferrer">Attention with Trained Embeddings Provably Selects Important Tokens</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Diyuan Wu, Aleksandr Shevchenko, Samet Oymak, Marco Mondelli
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Token embeddings play a crucial role in language modeling but, despite this practical relevance, their theoretical understanding remains limited. Our paper addresses the gap by characterizing the structure of embeddings obtained via gradient descent. Specifically, we consider a one-layer softmax att</span>
                
                <span class="abstract-full" style="display: none;">Token embeddings play a crucial role in language modeling but, despite this practical relevance, their theoretical understanding remains limited. Our paper addresses the gap by characterizing the structure of embeddings obtained via gradient descent. Specifically, we consider a one-layer softmax attention model with a linear head for binary classification, i.e., $\texttt{Softmax}( p^\top E_X^\top ) E_X v = \frac{ \sum_{i=1}^T \exp(p^\top E_{x_i}) E_{x_i}^\top v}{\sum_{j=1}^T \exp(p^\top E_{x_{j}}) }$, where $E_X = [ E_{x_1} , \dots, E_{x_T} ]^\top$ contains the embeddings of the input sequence, $p$ is the embedding of the $\mathrm{\langle cls \rangle}$ token and $v$ the output vector. First, we show that, already after a single step of gradient training with the logistic loss, the embeddings $E_X$ capture the importance of tokens in the dataset by aligning with the output vector $v$ proportionally to the frequency with which the corresponding tokens appear in the dataset. Then, after training $p$ via gradient flow until convergence, the softmax selects the important tokens in the sentence (i.e., those that are predictive of the label), and the resulting $\mathrm{\langle cls \rangle}$ embedding maximizes the margin for such a selection. Experiments on real-world datasets (IMDB, Yelp) exhibit a phenomenology close to that unveiled by our theory.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Math: 3.1 -->
                    
                <!-- Federated Learning: 2.9 -->
                    
                <!-- Reinforcement Learning: 2.4 -->
                    
                <!-- Cryptography: 2.4 -->
                    
                <!-- Medicine: 2.2 -->
                    
                <!-- Networks: 2.0 -->
                    
                <!-- Bayesian Optimization: 1.9 -->
                    
                <!-- Finance: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                <!-- Pathfinding: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Hardware: 1.1 -->
                    
                <!-- Game Theory: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17296" target="_blank" rel="noopener noreferrer">SELF: Self-Extend the Context Length With Logistic Growth Function</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Phat Thanh Dang, Saahil Thoppay, Wang Yang, Qifan Wang, Vipin Chaudhary, Xiaotian Han
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Large language models suffer issues when operated on long contexts that are larger than their training context length due to the standard position encoding for tokens in the attention layer. Tokens a long distance apart will rarely have an effect on each other and long prompts yield unexpected resul</span>
                
                <span class="abstract-full" style="display: none;">Large language models suffer issues when operated on long contexts that are larger than their training context length due to the standard position encoding for tokens in the attention layer. Tokens a long distance apart will rarely have an effect on each other and long prompts yield unexpected results. To solve this problem, we propose SELF (Self-Extend the Context Length With Logistic Growth Function): a solution of grouping consecutive tokens at varying group sizes using a logistic capacity equation combined with a constant group size at smaller relative distances. Our model had an increase in performance of up to 12% compared to the LongLM extension method in LEval (specifically on the Qwen model). On summarization related tasks in LongBench, our model performed up to 6.4% better than LongLM (specifically on the Llama-2-7b model). On reading comprehension tasks from LEval, our model performed up to 5.4% better than the LongLM. Our code is available at https://github.com/alexeipc/SELF-LLM.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.2 -->
                    
                <!-- GNN: 3.1 -->
                    
                <!-- Computer Vision: 2.5 -->
                    
                <!-- Federated Learning: 2.3 -->
                    
                <!-- Medicine: 2.0 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Cryptography: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Networks: 1.1 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17303" target="_blank" rel="noopener noreferrer">UAV Control with Vision-based Hand Gesture Recognition over Edge-Computing</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Sousannah Abdalla, Sabur Baidya
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Gesture recognition presents a promising avenue for interfacing with unmanned aerial vehicles (UAVs) due to its intuitive nature and potential for precise interaction. This research conducts a comprehensive comparative analysis of vision-based hand gesture detection methodologies tailored for UAV Co</span>
                
                <span class="abstract-full" style="display: none;">Gesture recognition presents a promising avenue for interfacing with unmanned aerial vehicles (UAVs) due to its intuitive nature and potential for precise interaction. This research conducts a comprehensive comparative analysis of vision-based hand gesture detection methodologies tailored for UAV Control. The existing gesture recognition approaches involving cropping, zooming, and color-based segmentation, do not work well for this kind of applications in dynamic conditions and suffer in performance with increasing distance and environmental noises. We propose to use a novel approach leveraging hand landmarks drawing and classification for gesture recognition based UAV control. With experimental results we show that our proposed method outperforms the other existing methods in terms of accuracy, noise resilience, and efficacy across varying distances, thus providing robust control decisions. However, implementing the deep learning based compute intensive gesture recognition algorithms on the UAV's onboard computer is significantly challenging in terms of performance. Hence, we propose to use a edge-computing based framework to offload the heavier computing tasks, thus achieving closed-loop real-time performance. With implementation over AirSim simulator as well as over a real-world UAV, we showcase the advantage of our end-to-end gesture recognition based UAV control system.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 3.4 -->
                    
                <!-- LLMs: 3.0 -->
                    
                <!-- Computer Vision: 2.5 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                <!-- Networks: 1.0 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17305" target="_blank" rel="noopener noreferrer">Data-driven Closure Strategies for Parametrized Reduced Order Models via Deep Operator Networks</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Anna Ivagnes, Giovanni Stabile, Gianluigi Rozza
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In this paper, we propose an equation-based parametric Reduced Order Model (ROM), whose accuracy is improved with data-driven terms added into the reduced equations. These additions have the aim of reintroducing contributions that in standard reduced-order approaches are not taken into account. In p</span>
                
                <span class="abstract-full" style="display: none;">In this paper, we propose an equation-based parametric Reduced Order Model (ROM), whose accuracy is improved with data-driven terms added into the reduced equations. These additions have the aim of reintroducing contributions that in standard reduced-order approaches are not taken into account. In particular, in this work we focus on a Proper Orthogonal Decomposition (POD)-based formulation and our goal is to build a closure or correction model, aimed to re-introduce the contribution of the discarded modes. The approach has been investigated in previous works, and the goal of this manuscript is to extend the model to a parametric setting making use of machine learning procedures, and, in particular, of deep operator networks. More in detail, we model the closure terms through a deep operator network taking as input the reduced variables and the parameters of the problem. We tested the methods on three test cases with different behaviors: the periodic turbulent flow past a circular cylinder, the unsteady turbulent flow in a channel-driven cavity, and the geometrically-parametrized backstep flow. The performance of the machine learning-enhanced ROM is deeply studied in different modal regimes, and considerably improved the pressure and velocity accuracy with respect to the standard POD-Galerkin approach.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 3.1 -->
                    
                <!-- Medicine: 2.7 -->
                    
                <!-- Reinforcement Learning: 2.6 -->
                    
                <!-- Bayesian Optimization: 2.0 -->
                    
                <!-- LLMs: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Hardware: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17314" target="_blank" rel="noopener noreferrer">The Role of Regularity in (Hyper-)Clique Detection and Implications for Optimizing Boolean CSPs</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Nick Fischer, Marvin K\"unnemann, Mirza Red\v{z}i\'c, Julian Stie{\ss}
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Is detecting a $k$-clique in $k$-partite regular (hyper-)graphs as hard as in the general case? Intuition suggests yes, but proving this -- especially for hypergraphs -- poses notable challenges. Concretely, we consider a strong notion of regularity in $h$-uniform hypergraphs, where we essentially r</span>
                
                <span class="abstract-full" style="display: none;">Is detecting a $k$-clique in $k$-partite regular (hyper-)graphs as hard as in the general case? Intuition suggests yes, but proving this -- especially for hypergraphs -- poses notable challenges. Concretely, we consider a strong notion of regularity in $h$-uniform hypergraphs, where we essentially require that any subset of at most $h-1$ is incident to a uniform number of hyperedges. Such notions are studied intensively in the combinatorial block design literature. We show that any $f(k)n^{g(k)}$-time algorithm for detecting $k$-cliques in such graphs transfers to an $f'(k)n^{g(k)}$-time algorithm for the general case, establishing a fine-grained equivalence between the $h$-uniform hyperclique hypothesis and its natural regular analogue.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 3.9 -->
                    
                <!-- Game Theory: 2.0 -->
                    
                <!-- Quantum Computing: 2.0 -->
                    
                <!-- Networks: 1.8 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Medicine: 1.7 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Math: 1.4 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.4 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17333" target="_blank" rel="noopener noreferrer">Temporal Differential Fields for 4D Motion Modeling via Image-to-Video Synthesis</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Xin You, Minghui Zhang, Hanxiao Zhang, Jie Yang, Nassir Navab
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Temporal modeling on regular respiration-induced motions is crucial to image-guided clinical applications. Existing methods cannot simulate temporal motions unless high-dose imaging scans including starting and ending frames exist simultaneously. However, in the preoperative data acquisition stage, </span>
                
                <span class="abstract-full" style="display: none;">Temporal modeling on regular respiration-induced motions is crucial to image-guided clinical applications. Existing methods cannot simulate temporal motions unless high-dose imaging scans including starting and ending frames exist simultaneously. However, in the preoperative data acquisition stage, the slight movement of patients may result in dynamic backgrounds between the first and last frames in a respiratory period. This additional deviation can hardly be removed by image registration, thus affecting the temporal modeling. To address that limitation, we pioneeringly simulate the regular motion process via the image-to-video (I2V) synthesis framework, which animates with the first frame to forecast future frames of a given length. Besides, to promote the temporal consistency of animated videos, we devise the Temporal Differential Diffusion Model to generate temporal differential fields, which measure the relative differential representations between adjacent frames. The prompt attention layer is devised for fine-grained differential fields, and the field augmented layer is adopted to better interact these fields with the I2V framework, promoting more accurate temporal variation of synthesized videos. Extensive results on ACDC cardiac and 4D Lung datasets reveal that our approach simulates 4D videos along the intrinsic motion trajectory, rivaling other competitive methods on perceptual similarity and temporal consistency. Codes will be available soon.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Computer Vision: 3.1 -->
                    
                <!-- Federated Learning: 2.8 -->
                    
                <!-- Medicine: 2.6 -->
                    
                <!-- LLMs: 2.1 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Networks: 1.2 -->
                    
                <!-- Cryptography: 1.2 -->
                    
                <!-- Math: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17340" target="_blank" rel="noopener noreferrer">Conformal Predictive Distributions for Order Fulfillment Time Forecasting</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Tinghan Ye, Amira Hijazi, Pascal Van Hentenryck
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Accurate estimation of order fulfillment time is critical for e-commerce logistics, yet traditional rule-based approaches often fail to capture the inherent uncertainties in delivery operations. This paper introduces a novel framework for distributional forecasting of order fulfillment time, leverag</span>
                
                <span class="abstract-full" style="display: none;">Accurate estimation of order fulfillment time is critical for e-commerce logistics, yet traditional rule-based approaches often fail to capture the inherent uncertainties in delivery operations. This paper introduces a novel framework for distributional forecasting of order fulfillment time, leveraging Conformal Predictive Systems and Cross Venn-Abers Predictors--model-agnostic techniques that provide rigorous coverage or validity guarantees. The proposed machine learning methods integrate granular spatiotemporal features, capturing fulfillment location and carrier performance dynamics to enhance predictive accuracy. Additionally, a cost-sensitive decision rule is developed to convert probabilistic forecasts into reliable point predictions. Experimental evaluation on a large-scale industrial dataset demonstrates that the proposed methods generate competitive distributional forecasts, while machine learning-based point predictions significantly outperform the existing rule-based system--achieving up to 14% higher prediction accuracy and up to 75% improvement in identifying late deliveries.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 3.4 -->
                    
                <!-- LLMs: 2.9 -->
                    
                <!-- GNN: 2.6 -->
                    
                <!-- Computer Vision: 2.4 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Decision Trees: 1.8 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Networks: 1.5 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17341" target="_blank" rel="noopener noreferrer">TI-DeepONet: Learnable Time Integration for Stable Long-Term Extrapolation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Dibyajyoti Nayak, Somdatta Goswami
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Accurate temporal extrapolation presents a fundamental challenge for neural operators in modeling dynamical systems, where reliable predictions must extend significantly beyond the training time horizon. Conventional Deep Operator Network (DeepONet) approaches employ two inherently limited training </span>
                
                <span class="abstract-full" style="display: none;">Accurate temporal extrapolation presents a fundamental challenge for neural operators in modeling dynamical systems, where reliable predictions must extend significantly beyond the training time horizon. Conventional Deep Operator Network (DeepONet) approaches employ two inherently limited training paradigms - fixed-horizon rollouts that predict complete spatiotemporal solutions while disregarding temporal causality, and autoregressive formulations that accumulate errors through sequential predictions. We introduce TI-DeepONet, a framework that integrates neural operators with adaptive numerical time-stepping techniques to preserve the Markovian structure of dynamical systems while mitigating error propagation in extended temporal forecasting. Our approach reformulates the learning objective from direct state prediction to the approximation of instantaneous time-derivative fields, which are then integrated using established numerical schemes. This architecture supports continuous-time prediction and enables deployment of higher-precision integrators during inference than those used during training, balancing computational efficiency with predictive accuracy. We further develop TI(L)-DeepONet, which incorporates learnable coefficients for intermediate slopes in the integration process, adapting to solution-specific variations and enhancing fidelity. Evaluation across three canonical PDEs shows that TI(L)-DeepONet marginally outperforms TI-DeepONet, with both reducing relative L2 extrapolation errors: approximately 81% over autoregressive and 70% over fixed-horizon methods. Notably, both maintain prediction stability for temporal domains extending to about twice the training interval. This research establishes a physics-aware operator learning paradigm that bridges neural approximation with numerical analysis while preserving the causal structure of dynamical systems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.8 -->
                    
                <!-- Medicine: 4.4 -->
                    
                <!-- Quantum Computing: 2.4 -->
                    
                <!-- GNN: 2.2 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Networks: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17342" target="_blank" rel="noopener noreferrer">A Survey of Safe Reinforcement Learning and Constrained MDPs: A Technical Survey on Single-Agent and Multi-Agent Safety</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ankita Kushwaha, Kiran Ravish, Preeti Lamba, Pawan Kumar
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Safe Reinforcement Learning (SafeRL) is the subfield of reinforcement learning that explicitly deals with safety constraints during the learning and deployment of agents. This survey provides a mathematically rigorous overview of SafeRL formulations based on Constrained Markov Decision Processes (CM</span>
                
                <span class="abstract-full" style="display: none;">Safe Reinforcement Learning (SafeRL) is the subfield of reinforcement learning that explicitly deals with safety constraints during the learning and deployment of agents. This survey provides a mathematically rigorous overview of SafeRL formulations based on Constrained Markov Decision Processes (CMDPs) and extensions to Multi-Agent Safe RL (SafeMARL). We review theoretical foundations of CMDPs, covering definitions, constrained optimization techniques, and fundamental theorems. We then summarize state-of-the-art algorithms in SafeRL for single agents, including policy gradient methods with safety guarantees and safe exploration strategies, as well as recent advances in SafeMARL for cooperative and competitive settings. Additionally, we propose five open research problems to advance the field, with three focusing on SafeMARL. Each problem is described with motivation, key challenges, and related prior work. This survey is intended as a technical guide for researchers interested in SafeRL and SafeMARL, highlighting key concepts, methods, and open future research directions.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.5 -->
                    
                <!-- LLMs: 4.0 -->
                    
                <!-- Datasets: 2.3 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17343" target="_blank" rel="noopener noreferrer">Ocular Authentication: Fusion of Gaze and Periocular Modalities</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Dillon Lohr, Michael J. Proulx, Mehedi Hasan Raju, Oleg V. Komogortsev
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper investigates the feasibility of fusing two eye-centric authentication modalities-eye movements and periocular images-within a calibration-free authentication system. While each modality has independently shown promise for user authentication, their combination within a unified gaze-estima</span>
                
                <span class="abstract-full" style="display: none;">This paper investigates the feasibility of fusing two eye-centric authentication modalities-eye movements and periocular images-within a calibration-free authentication system. While each modality has independently shown promise for user authentication, their combination within a unified gaze-estimation pipeline has not been thoroughly explored at scale. In this report, we propose a multimodal authentication system and evaluate it using a large-scale in-house dataset comprising 9202 subjects with an eye tracking (ET) signal quality equivalent to a consumer-facing virtual reality (VR) device. Our results show that the multimodal approach consistently outperforms both unimodal systems across all scenarios, surpassing the FIDO benchmark. The integration of a state-of-the-art machine learning architecture contributed significantly to the overall authentication performance at scale, driven by the model's ability to capture authentication representations and the complementary discriminative characteristics of the fused modalities.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.1 -->
                    
                <!-- Federated Learning: 3.5 -->
                    
                <!-- LLMs: 3.4 -->
                    
                <!-- Evolutionary Algorithms: 2.5 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Networks: 1.3 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17350" target="_blank" rel="noopener noreferrer">From a Constraint Logic Programming Language to a Formal Verification Tool</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Maximiliano Cristi\'a, Alfredo Capozucca, Gianfranco Rossi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">{log} (read 'setlog') was born as a Constraint Logic Programming (CLP) language where sets and binary relations are first-class citizens, thus fostering set programming. Internally, {log} is a constraint satisfiability solver implementing decision procedures for several fragments of set theory. Henc</span>
                
                <span class="abstract-full" style="display: none;">{log} (read 'setlog') was born as a Constraint Logic Programming (CLP) language where sets and binary relations are first-class citizens, thus fostering set programming. Internally, {log} is a constraint satisfiability solver implementing decision procedures for several fragments of set theory. Hence, {log} can be used as a declarative, set, logic programming language and as an automated theorem prover for set theory. Over time {log} has been extended with some components integrated to the satisfiability solver thus providing a formal verification environment. In this paper we make a comprehensive presentation of this environment which includes a language for the description of state machines based on set theory, an interactive environment for the execution of functional scenarios over state machines, a generator of verification conditions for state machines, automated verification of state machines, and test case generation. State machines are both, programs and specifications; exactly the same code works as a program and as its specification. In this way, with a few additions, a CLP language turned into a seamlessly integrated programming and automated proof system.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 3.8 -->
                    
                <!-- LLMs: 3.3 -->
                    
                <!-- Evolutionary Algorithms: 3.2 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Reinforcement Learning: 1.8 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Networks: 1.4 -->
                    
                <!-- 3D: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17351" target="_blank" rel="noopener noreferrer">FLEX: A Backbone for Diffusion-Based Modeling of Spatio-temporal Physical Systems</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: N. Benjamin Erichson, Vinicius Mikuni, Dongwei Lyu, Yang Gao, Omri Azencot, Soon Hoe Lim, Michael W. Mahoney
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We introduce FLEX (FLow EXpert), a backbone architecture for generative modeling of spatio-temporal physical systems using diffusion models. FLEX operates in the residual space rather than on raw data, a modeling choice that we motivate theoretically, showing that it reduces the variance of the velo</span>
                
                <span class="abstract-full" style="display: none;">We introduce FLEX (FLow EXpert), a backbone architecture for generative modeling of spatio-temporal physical systems using diffusion models. FLEX operates in the residual space rather than on raw data, a modeling choice that we motivate theoretically, showing that it reduces the variance of the velocity field in the diffusion model, which helps stabilize training. FLEX integrates a latent Transformer into a U-Net with standard convolutional ResNet layers and incorporates a redesigned skip connection scheme. This hybrid design enables the model to capture both local spatial detail and long-range dependencies in latent space. To improve spatio-temporal conditioning, FLEX uses a task-specific encoder that processes auxiliary inputs such as coarse or past snapshots. Weak conditioning is applied to the shared encoder via skip connections to promote generalization, while strong conditioning is applied to the decoder through both skip and bottleneck features to ensure reconstruction fidelity. FLEX achieves accurate predictions for super-resolution and forecasting tasks using as few as two reverse diffusion steps. It also produces calibrated uncertainty estimates through sampling. Evaluations on high-resolution 2D turbulence data show that FLEX outperforms strong baselines and generalizes to out-of-distribution settings, including unseen Reynolds numbers, physical observables (e.g., fluid flow velocity fields), and boundary conditions.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 3.6 -->
                    
                <!-- LLMs: 3.3 -->
                    
                <!-- Quantum Computing: 2.0 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Networks: 1.3 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Datasets: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17353" target="_blank" rel="noopener noreferrer">Dual Ascent Diffusion for Inverse Problems</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Minseo Kim, Axel Levy, Gordon Wetzstein
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Ill-posed inverse problems are fundamental in many domains, ranging from astrophysics to medical imaging. Emerging diffusion models provide a powerful prior for solving these problems. Existing maximum-a-posteriori (MAP) or posterior sampling approaches, however, rely on different computational appr</span>
                
                <span class="abstract-full" style="display: none;">Ill-posed inverse problems are fundamental in many domains, ranging from astrophysics to medical imaging. Emerging diffusion models provide a powerful prior for solving these problems. Existing maximum-a-posteriori (MAP) or posterior sampling approaches, however, rely on different computational approximations, leading to inaccurate or suboptimal samples. To address this issue, we introduce a new approach to solving MAP problems with diffusion model priors using a dual ascent optimization framework. Our framework achieves better image quality as measured by various metrics for image restoration problems, it is more robust to high levels of measurement noise, it is faster, and it estimates solutions that represent the observations more faithfully than the state of the art.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 4.4 -->
                    
                <!-- Evolutionary Algorithms: 3.7 -->
                    
                <!-- LLMs: 3.4 -->
                    
                <!-- Medicine: 3.2 -->
                    
                <!-- Bayesian Optimization: 2.3 -->
                    
                <!-- Quantum Computing: 2.0 -->
                    
                <!-- Computer Vision: 2.0 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17356" target="_blank" rel="noopener noreferrer">Adversarial Robustness of Nonparametric Regression</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Parsa Moradi, Hanzaleh Akabrinodehi, Mohammad Ali Maddah-Ali
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In this paper, we investigate the adversarial robustness of regression, a fundamental problem in machine learning, under the setting where an adversary can arbitrarily corrupt a subset of the input data. While the robustness of parametric regression has been extensively studied, its nonparametric co</span>
                
                <span class="abstract-full" style="display: none;">In this paper, we investigate the adversarial robustness of regression, a fundamental problem in machine learning, under the setting where an adversary can arbitrarily corrupt a subset of the input data. While the robustness of parametric regression has been extensively studied, its nonparametric counterpart remains largely unexplored. We characterize the adversarial robustness in nonparametric regression, assuming the regression function belongs to the second-order Sobolev space (i.e., it is square integrable up to its second derivative).</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Math: 3.4 -->
                    
                <!-- Cryptography: 3.3 -->
                    
                <!-- Federated Learning: 3.0 -->
                    
                <!-- Networks: 2.9 -->
                    
                <!-- Game Theory: 2.6 -->
                    
                <!-- LLMs: 2.1 -->
                    
                <!-- Bayesian Optimization: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Finance: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Pathfinding: 1.3 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                <!-- SpikingNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17358" target="_blank" rel="noopener noreferrer">Repurposing Marigold for Zero-Shot Metric Depth Estimation via Defocus Blur Cues</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Chinmay Talegaonkar, Nikhil Gandudi Suresh, Zachary Novack, Yash Belhe, Priyanka Nagasamudra, Nicholas Antipa
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Recent monocular metric depth estimation (MMDE) methods have made notable progress towards zero-shot generalization. However, they still exhibit a significant performance drop on out-of-distribution datasets. We address this limitation by injecting defocus blur cues at inference time into Marigold, </span>
                
                <span class="abstract-full" style="display: none;">Recent monocular metric depth estimation (MMDE) methods have made notable progress towards zero-shot generalization. However, they still exhibit a significant performance drop on out-of-distribution datasets. We address this limitation by injecting defocus blur cues at inference time into Marigold, a \textit{pre-trained} diffusion model for zero-shot, scale-invariant monocular depth estimation (MDE). Our method effectively turns Marigold into a metric depth predictor in a training-free manner. To incorporate defocus cues, we capture two images with a small and a large aperture from the same viewpoint. To recover metric depth, we then optimize the metric depth scaling parameters and the noise latents of Marigold at inference time using gradients from a loss function based on the defocus-blur image formation model. We compare our method against existing state-of-the-art zero-shot MMDE methods on a self-collected real dataset, showing quantitative and qualitative improvements.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.5 -->
                    
                <!-- LLMs: 3.1 -->
                    
                <!-- Computer Vision: 2.2 -->
                    
                <!-- 3D: 2.0 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Reinforcement Learning: 1.9 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- T2I: 1.1 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17359" target="_blank" rel="noopener noreferrer">Towards VM Rescheduling Optimization Through Deep Reinforcement Learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Xianzhong Ding, Yunkai Zhang, Binbin Chen, Donghao Ying, Tieying Zhang, Jianjun Chen, Lei Zhang, Alberto Cerpa, Wan Du
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Modern industry-scale data centers need to manage a large number of virtual machines (VMs). Due to the continual creation and release of VMs, many small resource fragments are scattered across physical machines (PMs). To handle these fragments, data centers periodically reschedule some VMs to altern</span>
                
                <span class="abstract-full" style="display: none;">Modern industry-scale data centers need to manage a large number of virtual machines (VMs). Due to the continual creation and release of VMs, many small resource fragments are scattered across physical machines (PMs). To handle these fragments, data centers periodically reschedule some VMs to alternative PMs, a practice commonly referred to as VM rescheduling. Despite the increasing importance of VM rescheduling as data centers grow in size, the problem remains understudied. We first show that, unlike most combinatorial optimization tasks, the inference time of VM rescheduling algorithms significantly influences their performance, due to dynamic VM state changes during this period. This causes existing methods to scale poorly. Therefore, we develop a reinforcement learning system for VM rescheduling, VM2RL, which incorporates a set of customized techniques, such as a two-stage framework that accommodates diverse constraints and workload conditions, a feature extraction module that captures relational information specific to rescheduling, as well as a risk-seeking evaluation enabling users to optimize the trade-off between latency and accuracy. We conduct extensive experiments with data from an industry-scale data center. Our results show that VM2RL can achieve a performance comparable to the optimal solution but with a running time of seconds. Code and datasets are open-sourced: https://github.com/zhykoties/VMR2L_eurosys, https://drive.google.com/drive/folders/1PfRo1cVwuhH30XhsE2Np3xqJn2GpX5qy.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 3.1 -->
                    
                <!-- LLMs: 2.6 -->
                    
                <!-- Reinforcement Learning: 2.5 -->
                    
                <!-- GNN: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- Quantum Computing: 2.1 -->
                    
                <!-- Networks: 1.6 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- Medicine: 1.4 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Hardware: 1.1 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- 3D: 1.1 -->
                    
                <!-- Computer Vision: 1.0 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17360" target="_blank" rel="noopener noreferrer">The Quasi-Polynomial Low-Degree Conjecture is False</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Rares-Darius Buhai, Jun-Ting Hsieh, Aayush Jain, Pravesh K. Kothari
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">There is a growing body of work on proving hardness results for average-case estimation problems by bounding the low-degree advantage (LDA) - a quantitative estimate of the closeness of low-degree moments - between a null distribution and a related planted distribution. Such hardness results are now</span>
                
                <span class="abstract-full" style="display: none;">There is a growing body of work on proving hardness results for average-case estimation problems by bounding the low-degree advantage (LDA) - a quantitative estimate of the closeness of low-degree moments - between a null distribution and a related planted distribution. Such hardness results are now ubiquitous not only for foundational average-case problems but also central questions in statistics and cryptography. This line of work is supported by the low-degree conjecture of Hopkins, which postulates that a vanishing degree-$D$ LDA implies the absence of any noise-tolerant distinguishing algorithm with runtime $n^{\widetilde{O}(D)}$ whenever 1) the null distribution is product on $\{0,1\}^{\binom{n}{k}}$, and 2) the planted distribution is permutation invariant, that is, invariant under any relabeling $[n] \rightarrow [n]$.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 3.9 -->
                    
                <!-- Federated Learning: 2.5 -->
                    
                <!-- Evolutionary Algorithms: 2.4 -->
                    
                <!-- Blockchain: 2.3 -->
                    
                <!-- Bayesian Optimization: 2.0 -->
                    
                <!-- LLMs: 1.9 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Math: 1.6 -->
                    
                <!-- Networks: 1.5 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17368" target="_blank" rel="noopener noreferrer">HENN: A Hierarchical Epsilon Net Navigation Graph for Approximate Nearest Neighbor Search</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Mohsen Dehghankar, Abolfazl Asudeh
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Hierarchical graph-based algorithms such as HNSW have achieved state-of-the-art performance for Approximate Nearest Neighbor (ANN) search in practice, yet they often lack theoretical guarantees on query time or recall due to their heavy use of randomized heuristic constructions. Conversely, existing</span>
                
                <span class="abstract-full" style="display: none;">Hierarchical graph-based algorithms such as HNSW have achieved state-of-the-art performance for Approximate Nearest Neighbor (ANN) search in practice, yet they often lack theoretical guarantees on query time or recall due to their heavy use of randomized heuristic constructions. Conversely, existing theoretically grounded structures are typically difficult to implement and struggle to scale in real-world scenarios. We propose the Hierarchical $\varepsilon$-Net Navigation Graph (HENN), a novel graph-based indexing structure for ANN search that combines strong theoretical guarantees with practical efficiency. Built upon the theory of $\varepsilon$-nets, HENN guarantees polylogarithmic worst-case query time while preserving high recall and incurring minimal implementation overhead. Moreover, we establish a probabilistic polylogarithmic query time bound for HNSW, providing theoretical insight into its empirical success. In contrast to these prior hierarchical methods that may degrade to linear query time under adversarial data, HENN maintains provable performance independent of the input data distribution. Empirical evaluations demonstrate that HENN achieves faster query time while maintaining competitive recall on diverse data distributions, including adversarial inputs. These results underscore the effectiveness of HENN as a robust and scalable solution for fast and accurate nearest neighbor search.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.1 -->
                    
                <!-- Medicine: 3.2 -->
                    
                <!-- GNN: 2.8 -->
                    
                <!-- Federated Learning: 2.6 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17371" target="_blank" rel="noopener noreferrer">An End-to-End Approach for Child Reading Assessment in the Xhosa Language</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Sergio Chevtchenko, Nikhil Navas, Rafaella Vale, Franco Ubaudi, Sipumelele Lucwaba, Cally Ardington, Soheil Afshar, Mark Antoniou, Saeed Afshar
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Child literacy is a strong predictor of life outcomes at the subsequent stages of an individual's life. This points to a need for targeted interventions in vulnerable low and middle income populations to help bridge the gap between literacy levels in these regions and high income ones. In this effor</span>
                
                <span class="abstract-full" style="display: none;">Child literacy is a strong predictor of life outcomes at the subsequent stages of an individual's life. This points to a need for targeted interventions in vulnerable low and middle income populations to help bridge the gap between literacy levels in these regions and high income ones. In this effort, reading assessments provide an important tool to measure the effectiveness of these programs and AI can be a reliable and economical tool to support educators with this task. Developing accurate automatic reading assessment systems for child speech in low-resource languages poses significant challenges due to limited data and the unique acoustic properties of children's voices. This study focuses on Xhosa, a language spoken in South Africa, to advance child speech recognition capabilities. We present a novel dataset composed of child speech samples in Xhosa. The dataset is available upon request and contains ten words and letters, which are part of the Early Grade Reading Assessment (EGRA) system. Each recording is labeled with an online and cost-effective approach by multiple markers and a subsample is validated by an independent EGRA reviewer. This dataset is evaluated with three fine-tuned state-of-the-art end-to-end models: wav2vec 2.0, HuBERT, and Whisper. The results indicate that the performance of these models can be significantly influenced by the amount and balancing of the available training data, which is fundamental for cost-effective large dataset collection. Furthermore, our experiments indicate that the wav2vec 2.0 performance is improved by training on multiple classes at a time, even when the number of available samples is constrained.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 3.9 -->
                    
                <!-- LLMs: 3.0 -->
                    
                <!-- Datasets: 2.5 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Computer Vision: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17379" target="_blank" rel="noopener noreferrer">Provably Efficient Algorithm for Best Scoring Rule Identification in Online Principal-Agent Information Acquisition</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zichen Wang, Chuanhao Li, Huazheng Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We investigate the problem of identifying the optimal scoring rule within the principal-agent framework for online information acquisition problem. We focus on the principal's perspective, seeking to determine the desired scoring rule through interactions with the agent. To address this challenge, w</span>
                
                <span class="abstract-full" style="display: none;">We investigate the problem of identifying the optimal scoring rule within the principal-agent framework for online information acquisition problem. We focus on the principal's perspective, seeking to determine the desired scoring rule through interactions with the agent. To address this challenge, we propose two algorithms: OIAFC and OIAFB, tailored for fixed confidence and fixed budget settings, respectively. Our theoretical analysis demonstrates that OIAFC can extract the desired $(\epsilon, \delta)$-scoring rule with a efficient instance-dependent sample complexity or an instance-independent sample complexity. Our analysis also shows that OIAFB matches the instance-independent performance bound of OIAFC, while both algorithms share the same complexity across fixed confidence and fixed budget settings.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.0 -->
                    
                <!-- Federated Learning: 3.0 -->
                    
                <!-- LLMs: 2.8 -->
                    
                <!-- Quantum Computing: 2.0 -->
                    
                <!-- Computer Vision: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Bayesian Optimization: 1.4 -->
                    
                <!-- Math: 1.3 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17404" target="_blank" rel="noopener noreferrer">Wasserstein Transfer Learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Kaicheng Zhang, Sinian Zhang, Doudou Zhou, Yidong Zhou
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Transfer learning is a powerful paradigm for leveraging knowledge from source domains to enhance learning in a target domain. However, traditional transfer learning approaches often focus on scalar or multivariate data within Euclidean spaces, limiting their applicability to complex data structures </span>
                
                <span class="abstract-full" style="display: none;">Transfer learning is a powerful paradigm for leveraging knowledge from source domains to enhance learning in a target domain. However, traditional transfer learning approaches often focus on scalar or multivariate data within Euclidean spaces, limiting their applicability to complex data structures such as probability distributions. To address this, we introduce a novel framework for transfer learning in regression models, where outputs are probability distributions residing in the Wasserstein space. When the informative subset of transferable source domains is known, we propose an estimator with provable asymptotic convergence rates, quantifying the impact of domain similarity on transfer efficiency. For cases where the informative subset is unknown, we develop a data-driven transfer learning procedure designed to mitigate negative transfer. The proposed methods are supported by rigorous theoretical analysis and are validated through extensive simulations and real-world applications.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- GNN: 3.2 -->
                    
                <!-- Medicine: 3.1 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- Reinforcement Learning: 2.2 -->
                    
                <!-- Computer Vision: 2.0 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- LLMs: 1.7 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Networks: 1.4 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- Hardware: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17414" target="_blank" rel="noopener noreferrer">A Dynamic Phasor Framework for Analysis of Grid-Forming Converter Connected to Series-Compensated Line</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Fiaz Hossain, Nilanjan Ray Chaudhuri
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">A dynamic phasor (DP) framework for time-domain and frequency-domain analyses of grid-forming converters (GFCs) connected to series-compensated transmission lines is proposed. The proposed framework can capture the behavior of GFCs subjected to unbalanced short circuit faults in presence of differen</span>
                
                <span class="abstract-full" style="display: none;">A dynamic phasor (DP) framework for time-domain and frequency-domain analyses of grid-forming converters (GFCs) connected to series-compensated transmission lines is proposed. The proposed framework can capture the behavior of GFCs subjected to unbalanced short circuit faults in presence of different current limiting strategies. Moreover, the linearizability and time invariance of this framework allows us to perform eigen decomposition, which is a powerful tool for root-cause analysis and control design. We show that a certain degree of series compensation may result in poorly-damped oscillations in presence of the grid-forming converter. A participation factor analysis using the DP model reveals that the point of interconnection voltage angle is dominant in this mode. Eigenvalue sensitivity analysis of controller parameters shows that reducing the power-frequency droop coefficient is most effective in stabilizing the poorly-damped mode. Detailed validation with electromagnetic transient model demonstrates the accuracy of the proposed framework.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.1 -->
                    
                <!-- Bayesian Optimization: 3.7 -->
                    
                <!-- Medicine: 3.5 -->
                    
                <!-- Federated Learning: 3.2 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Math: 1.5 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Game Theory: 1.3 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- Networks: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17421" target="_blank" rel="noopener noreferrer">Adaptive Implicit-Based Deep Learning Channel Estimation for 6G Communications</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zhen Qiao, Jiang Xue, Junkai Zhang, Guanzhang Liu, Xiaoqin Ma, Runhua Li, Faheem A. Khan, John S. Thompson, Zongben Xu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">With the widespread deployment of fifth-generation (5G) wireless networks, research on sixth-generation (6G) technology is gaining momentum. Artificial Intelligence (AI) is anticipated to play a significant role in 6G, particularly through integration with the physical layer for tasks such as channe</span>
                
                <span class="abstract-full" style="display: none;">With the widespread deployment of fifth-generation (5G) wireless networks, research on sixth-generation (6G) technology is gaining momentum. Artificial Intelligence (AI) is anticipated to play a significant role in 6G, particularly through integration with the physical layer for tasks such as channel estimation. Considering resource limitations in real systems, the AI algorithm should be designed to have the ability to balance the accuracy and resource consumption according to the scenarios dynamically. However, conventional explicit multilayer-stacked Deep Learning (DL) models struggle to adapt due to their heavy reliance on the structure of deep neural networks. This article proposes an adaptive Implicit-layer DL Channel Estimation Network (ICENet) with a lightweight framework for vehicle-to-everything communications. This novel approach balances computational complexity and channel estimation accuracy by dynamically adjusting computational resources based on input data conditions, such as channel quality. Unlike explicit multilayer-stacked DL-based channel estimation models, ICENet offers a flexible framework, where specific requirements can be achieved by adaptively changing the number of iterations of the iterative layer. Meanwhile, ICENet requires less memory while maintaining high performance. The article concludes by highlighting open research challenges and promising future research directions.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 3.3 -->
                    
                <!-- Evolutionary Algorithms: 2.9 -->
                    
                <!-- Medicine: 2.4 -->
                    
                <!-- Computer Vision: 2.2 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Networks: 1.8 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- LLMs: 1.6 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Cryptography: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17433" target="_blank" rel="noopener noreferrer">MemeReaCon: Probing Contextual Meme Understanding in Large Vision-Language Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zhengyi Zhao, Shubo Zhang, Yuxi Zhang, Yanxi Zhao, Yifan Zhang, Zezhong Wang, Huimin Wang, Yutian Zhao, Bin Liang, Yefeng Zheng, Binyang Li, Kam-Fai Wong, Xian Wu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Memes have emerged as a popular form of multimodal online communication, where their interpretation heavily depends on the specific context in which they appear. Current approaches predominantly focus on isolated meme analysis, either for harmful content detection or standalone interpretation, overl</span>
                
                <span class="abstract-full" style="display: none;">Memes have emerged as a popular form of multimodal online communication, where their interpretation heavily depends on the specific context in which they appear. Current approaches predominantly focus on isolated meme analysis, either for harmful content detection or standalone interpretation, overlooking a fundamental challenge: the same meme can express different intents depending on its conversational context. This oversight creates an evaluation gap: although humans intuitively recognize how context shapes meme interpretation, Large Vision Language Models (LVLMs) can hardly understand context-dependent meme intent. To address this critical limitation, we introduce MemeReaCon, a novel benchmark specifically designed to evaluate how LVLMs understand memes in their original context. We collected memes from five different Reddit communities, keeping each meme's image, the post text, and user comments together. We carefully labeled how the text and meme work together, what the poster intended, how the meme is structured, and how the community responded. Our tests with leading LVLMs show a clear weakness: models either fail to interpret critical information in the contexts, or overly focus on visual details while overlooking communicative purpose. MemeReaCon thus serves both as a diagnostic tool exposing current limitations and as a challenging benchmark to drive development toward more sophisticated LVLMs of the context-aware understanding.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.9 -->
                    
                <!-- GNN: 2.1 -->
                    
                <!-- Computer Vision: 2.1 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Networks: 1.6 -->
                    
                <!-- Cryptography: 1.6 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Medicine: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- Game Theory: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17435" target="_blank" rel="noopener noreferrer">Discretization-free Multicalibration through Loss Minimization over Tree Ensembles</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Hongyi Henry Jin, Zijun Ding, Dung Daniel Ngo, Zhiwei Steven Wu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In recent years, multicalibration has emerged as a desirable learning objective for ensuring that a predictor is calibrated across a rich collection of overlapping subpopulations. Existing approaches typically achieve multicalibration by discretizing the predictor's output space and iteratively adju</span>
                
                <span class="abstract-full" style="display: none;">In recent years, multicalibration has emerged as a desirable learning objective for ensuring that a predictor is calibrated across a rich collection of overlapping subpopulations. Existing approaches typically achieve multicalibration by discretizing the predictor's output space and iteratively adjusting its output values. However, this discretization approach departs from the standard empirical risk minimization (ERM) pipeline, introduces rounding error and additional sensitive hyperparameter, and may distort the predictor's outputs in ways that hinder downstream decision-making.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.7 -->
                    
                <!-- Medicine: 3.2 -->
                    
                <!-- Quantum Computing: 2.4 -->
                    
                <!-- Blockchain: 2.4 -->
                    
                <!-- GNN: 2.3 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Networks: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17443" target="_blank" rel="noopener noreferrer">Corporate Needs You to Find the Difference: Revisiting Submodular and Supermodular Ratio Optimization Problems</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Elfarouk Harb, Yousef Yassin, Chandra Chekuri
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We study the problem of minimizing or maximizing the average value $ f(S)/|S| $ of a submodular or supermodular set function $ f: 2^V \to \mathbb{R} $ over non-empty subsets $ S \subseteq V $. This generalizes classical problems such as Densest Subgraph (DSG), Densest Supermodular Set (DSS), and Sub</span>
                
                <span class="abstract-full" style="display: none;">We study the problem of minimizing or maximizing the average value $ f(S)/|S| $ of a submodular or supermodular set function $ f: 2^V \to \mathbb{R} $ over non-empty subsets $ S \subseteq V $. This generalizes classical problems such as Densest Subgraph (DSG), Densest Supermodular Set (DSS), and Submodular Function Minimization (SFM). Motivated by recent applications, we introduce two broad formulations: Unrestricted Sparsest Submodular Set (USSS) and Unrestricted Densest Supermodular Set (UDSS), which allow for negative and non-monotone functions.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.5 -->
                    
                <!-- Medicine: 3.3 -->
                    
                <!-- Blockchain: 2.7 -->
                    
                <!-- Quantum Computing: 2.3 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Datasets: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17448" target="_blank" rel="noopener noreferrer">Baitradar: A Multi-Model Clickbait Detection Algorithm Using Deep Learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Bhanuka Gamage, Adnan Labib, Aisha Joomun, Chern Hong Lim, KokSheik Wong
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Following the rising popularity of YouTube, there is an emerging problem on this platform called clickbait, which provokes users to click on videos using attractive titles and thumbnails. As a result, users ended up watching a video that does not have the content as publicized in the title. This iss</span>
                
                <span class="abstract-full" style="display: none;">Following the rising popularity of YouTube, there is an emerging problem on this platform called clickbait, which provokes users to click on videos using attractive titles and thumbnails. As a result, users ended up watching a video that does not have the content as publicized in the title. This issue is addressed in this study by proposing an algorithm called BaitRadar, which uses a deep learning technique where six inference models are jointly consulted to make the final classification decision. These models focus on different attributes of the video, including title, comments, thumbnail, tags, video statistics and audio transcript. The final classification is attained by computing the average of multiple models to provide a robust and accurate output even in situation where there is missing data. The proposed method is tested on 1,400 YouTube videos. On average, a test accuracy of 98% is achieved with an inference time of less than 2s.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 2.8 -->
                    
                <!-- LLMs: 2.7 -->
                    
                <!-- Evolutionary Algorithms: 2.5 -->
                    
                <!-- Medicine: 2.3 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Bayesian Optimization: 1.7 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Networks: 1.4 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Hardware: 1.1 -->
                    
                <!-- Robotics: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.17449" target="_blank" rel="noopener noreferrer">Real-time Traffic Accident Anticipation with Feature Reuse</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Inpyo Song, Jangwon Lee
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper addresses the problem of anticipating traffic accidents, which aims to forecast potential accidents before they happen. Real-time anticipation is crucial for safe autonomous driving, yet most methods rely on computationally heavy modules like optical flow and intermediate feature extracto</span>
                
                <span class="abstract-full" style="display: none;">This paper addresses the problem of anticipating traffic accidents, which aims to forecast potential accidents before they happen. Real-time anticipation is crucial for safe autonomous driving, yet most methods rely on computationally heavy modules like optical flow and intermediate feature extractors, making real-world deployment challenging. In this paper, we thus introduce RARE (Real-time Accident anticipation with Reused Embeddings), a lightweight framework that capitalizes on intermediate features from a single pre-trained object detector. By eliminating additional feature-extraction pipelines, RARE significantly reduces latency. Furthermore, we introduce a novel Attention Score Ranking Loss, which prioritizes higher attention on accident-related objects over non-relevant ones. This loss enhances both accuracy and interpretability. RARE demonstrates a 4-8 times speedup over existing approaches on the DAD and CCD benchmarks, achieving a latency of 13.6ms per frame (73.3 FPS) on an RTX 6000. Moreover, despite its reduced complexity, it attains state-of-the-art Average Precision and reliably anticipates imminent collisions in real time. These results highlight RARE's potential for safety-critical applications where timely and explainable anticipation is essential.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.0 -->
                    
                <!-- LLMs: 3.8 -->
                    
                <!-- Computer Vision: 3.6 -->
                    
                <!-- GNN: 2.3 -->
                    
                <!-- Evolutionary Algorithms: 2.3 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- Blockchain: 2.0 -->
                    
                <!-- 3D: 1.9 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.0427
                </span>
                <a href="https://arxiv.org/abs/2504.07228" target="_blank" rel="noopener noreferrer">ConceptCarve: Dynamic Realization of Evidence</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Eylon Caplan, Dan Goldwasser
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Finding evidence for human opinion and behavior at scale is a challenging task, often requiring an understanding of sophisticated thought patterns among vast online communities found on social media. For example, studying how gun ownership is related to the perception of Freedom, requires a retrieva</span>
                
                <span class="abstract-full" style="display: none;">Finding evidence for human opinion and behavior at scale is a challenging task, often requiring an understanding of sophisticated thought patterns among vast online communities found on social media. For example, studying how gun ownership is related to the perception of Freedom, requires a retrieval system that can operate at scale over social media posts, while dealing with two key challenges: (1) identifying abstract concept instances, (2) which can be instantiated differently across different communities. To address these, we introduce ConceptCarve, an evidence retrieval framework that utilizes traditional retrievers and LLMs to dynamically characterize the search space during retrieval. Our experiments show that ConceptCarve surpasses traditional retrieval systems in finding evidence within a social media community. It also produces an interpretable representation of the evidence for that community, which we use to qualitatively analyze complex thought patterns that manifest differently across the communities.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.4%">
                            LLMs
                        </span>
                <!-- GNN: 3.5 -->
                    
                <!-- Federated Learning: 3.2 -->
                    
                <!-- Medicine: 2.8 -->
                    
                <!-- Quantum Computing: 2.3 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- Bayesian Optimization: 1.7 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Hardware: 1.1 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.0595
                </span>
                <a href="https://arxiv.org/abs/2505.17049" target="_blank" rel="noopener noreferrer">Gender and Positional Biases in LLM-Based Hiring Decisions: Evidence from Comparative CV/R\'esum\'e Evaluations</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: David Rozado
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This study examines the behavior of Large Language Models (LLMs) when evaluating professional candidates based on their resumes or curricula vitae (CVs). In an experiment involving 22 leading LLMs, each model was systematically given one job description along with a pair of profession-matched CVs, o</span>
                
                <span class="abstract-full" style="display: none;">This study examines the behavior of Large Language Models (LLMs) when evaluating professional candidates based on their resumes or curricula vitae (CVs). In an experiment involving 22 leading LLMs, each model was systematically given one job description along with a pair of profession-matched CVs, one bearing a male first name, the other a female first name, and asked to select the more suitable candidate for the job. Each CV pair was presented twice, with names swapped to ensure that any observed preferences in candidate selection stemmed from gendered names cues. Despite identical professional qualifications across genders, all LLMs consistently favored female-named candidates across 70 different professions. Adding an explicit gender field (male/female) to the CVs further increased the preference for female applicants. When gendered names were replaced with gender-neutral identifiers "Candidate A" and "Candidate B", several models displayed a preference to select "Candidate A". Counterbalancing gender assignment between these gender-neutral identifiers resulted in gender parity in candidate selection. When asked to rate CVs in isolation rather than compare pairs, LLMs assigned slightly higher average scores to female CVs overall, but the effect size was negligible. Including preferred pronouns (he/him or she/her) next to a candidate's name slightly increased the odds of the candidate being selected regardless of gender. Finally, most models exhibited a substantial positional bias to select the candidate listed first in the prompt. These findings underscore the need for caution when deploying LLMs in high-stakes autonomous decision-making contexts and raise doubts about whether LLMs consistently apply principled reasoning.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.3%">
                            LLMs
                        </span>
                <!-- Medicine: 1.9 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Networks: 1.6 -->
                    
                <!-- Game Theory: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Cryptography: 1.2 -->
                    
                <!-- Robotics: 1.0 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.0621
                </span>
                <a href="https://arxiv.org/abs/2505.17695" target="_blank" rel="noopener noreferrer">SynRES: Towards Referring Expression Segmentation in the Wild via Synthetic Data</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Dong-Hee Kim, Hyunjee Song, Donghyun Kim
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Despite the advances in Referring Expression Segmentation (RES) benchmarks, their evaluation protocols remain constrained, primarily focusing on either single targets with short queries (containing minimal attributes) or multiple targets from distinctly different queries on a single domain. This lim</span>
                
                <span class="abstract-full" style="display: none;">Despite the advances in Referring Expression Segmentation (RES) benchmarks, their evaluation protocols remain constrained, primarily focusing on either single targets with short queries (containing minimal attributes) or multiple targets from distinctly different queries on a single domain. This limitation significantly hinders the assessment of more complex reasoning capabilities in RES models. We introduce WildRES, a novel benchmark that incorporates long queries with diverse attributes and non-distinctive queries for multiple targets. This benchmark spans diverse application domains, including autonomous driving environments and robotic manipulation scenarios, thus enabling more rigorous evaluation of complex reasoning capabilities in real-world settings. Our analysis reveals that current RES models demonstrate substantial performance deterioration when evaluated on WildRES. To address this challenge, we introduce SynRES, an automated pipeline generating densely paired compositional synthetic training data through three innovations: (1) a dense caption-driven synthesis for attribute-rich image-mask-expression triplets, (2) reliable semantic alignment mechanisms rectifying caption-pseudo mask inconsistencies via Image-Text Aligned Grouping, and (3) domain-aware augmentations incorporating mosaic composition and superclass replacement to emphasize generalization ability and distinguishing attributes over object categories. Experimental results demonstrate that models trained with SynRES achieve state-of-the-art performance, improving gIoU by 2.0% on WildRES-ID and 3.8% on WildRES-DS. Code and datasets are available at https://github.com/UTLLab/SynRES.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.7%">
                            LLMs
                        </span>
                <!-- Medicine: 4.2 -->
                    
                <!-- Computer Vision: 2.8 -->
                    
                <!-- GNN: 2.1 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Blockchain: 2.0 -->
                    
                <!-- Datasets: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- T2I: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.0654
                </span>
                <a href="https://arxiv.org/abs/2505.17418" target="_blank" rel="noopener noreferrer">What Needs Attention? Prioritizing Drivers of Developers' Trust and Adoption of Generative AI</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Rudrajit Choudhuri, Bianca Trinkenreich, Rahul Pandita, Eirini Kalliamvakou, Igor Steinmacher, Marco Gerosa, Christopher Sanchez, Anita Sarma
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Generative AI (genAI) tools are advertised as productivity aids. Yet, issues related to miscalibrated trust and usage friction continue to hinder their adoption. Additionally, AI can be exclusionary, failing to support diverse users adequately, further exacerbating these concerns. One such aspect of</span>
                
                <span class="abstract-full" style="display: none;">Generative AI (genAI) tools are advertised as productivity aids. Yet, issues related to miscalibrated trust and usage friction continue to hinder their adoption. Additionally, AI can be exclusionary, failing to support diverse users adequately, further exacerbating these concerns. One such aspect of diversity is cognitive diversity -- variations in users' cognitive styles -- that leads to divergence in interaction styles. When an individual's cognitive styles are unsupported, it creates additional barriers to technology adoption. Thus, to design tools that developers trust, we must first understand what factors affect their trust and intentions to use these tools in practice?</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 11.1%">
                            LLMs
                        </span>
                <!-- Blockchain: 2.5 -->
                    
                <!-- GNN: 2.4 -->
                    
                <!-- Quantum Computing: 2.2 -->
                    
                <!-- Decision Trees: 1.9 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Game Theory: 1.5 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Medicine: 1.1 -->
                    
                <!-- RAG: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.0781
                </span>
                <a href="https://arxiv.org/abs/2505.17295" target="_blank" rel="noopener noreferrer">ScanBot: Towards Intelligent Surface Scanning in Embodied Robotic Systems</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zhiling Chen, Yang Zhang, Fardin Jalil Piran, Qianyu Zhou, Jiong Tang, Farhad Imani
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We introduce ScanBot, a novel dataset designed for instruction-conditioned, high-precision surface scanning in robotic systems. In contrast to existing robot learning datasets that focus on coarse tasks such as grasping, navigation, or dialogue, ScanBot targets the high-precision demands of industri</span>
                
                <span class="abstract-full" style="display: none;">We introduce ScanBot, a novel dataset designed for instruction-conditioned, high-precision surface scanning in robotic systems. In contrast to existing robot learning datasets that focus on coarse tasks such as grasping, navigation, or dialogue, ScanBot targets the high-precision demands of industrial laser scanning, where sub-millimeter path continuity and parameter stability are critical. The dataset covers laser scanning trajectories executed by a robot across 12 diverse objects and 6 task types, including full-surface scans, geometry-focused regions, spatially referenced parts, functionally relevant structures, defect inspection, and comparative analysis. Each scan is guided by natural language instructions and paired with synchronized RGB, depth, and laser profiles, as well as robot pose and joint states. Despite recent progress, existing vision-language action (VLA) models still fail to generate stable scanning trajectories under fine-grained instructions and real-world precision demands. To investigate this limitation, we benchmark a range of multimodal large language models (MLLMs) across the full perception-planning-execution loop, revealing persistent challenges in instruction-following under realistic constraints.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 10.9%">
                            LLMs
                        </span>
                <!-- Datasets: 2.7 -->
                    
                <!-- Medicine: 2.6 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- Blockchain: 2.3 -->
                    
                <!-- HPO and AutoML: 1.8 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.1015
                </span>
                <a href="https://arxiv.org/abs/2505.17616" target="_blank" rel="noopener noreferrer">Runaway is Ashamed, But Helpful: On the Early-Exit Behavior of Large Language Model-based Agents in Embodied Environments</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Qingyu Lu, Liang Ding, Siyi Cao, Xuebo Liu, Kanjian Zhang, Jinxia Zhang, Dacheng Tao
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Agents powered by large language models (LLMs) have demonstrated strong planning and decision-making capabilities in complex embodied environments. However, such agents often suffer from inefficiencies in multi-turn interactions, frequently trapped in repetitive loops or issuing ineffective commands</span>
                
                <span class="abstract-full" style="display: none;">Agents powered by large language models (LLMs) have demonstrated strong planning and decision-making capabilities in complex embodied environments. However, such agents often suffer from inefficiencies in multi-turn interactions, frequently trapped in repetitive loops or issuing ineffective commands, leading to redundant computational overhead. Instead of relying solely on learning from trajectories, we take a first step toward exploring the early-exit behavior for LLM-based agents. We propose two complementary approaches: 1. an $\textbf{intrinsic}$ method that injects exit instructions during generation, and 2. an $\textbf{extrinsic}$ method that verifies task completion to determine when to halt an agent's trial. To evaluate early-exit mechanisms, we introduce two metrics: one measures the reduction of $\textbf{redundant steps}$ as a positive effect, and the other evaluates $\textbf{progress degradation}$ as a negative effect. Experiments with 4 different LLMs across 5 embodied environments show significant efficiency improvements, with only minor drops in agent performance. We also validate a practical strategy where a stronger agent assists after an early-exit agent, achieving better performance with the same total steps. We will release our code to support further research.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 14.2%">
                            LLMs
                        </span>
                <!-- GNN: 2.0 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Medicine: 1.8 -->
                    
                <!-- Reinforcement Learning: 1.8 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.106
                </span>
                <a href="https://arxiv.org/abs/2502.11614" target="_blank" rel="noopener noreferrer">Is Human-Like Text Liked by Humans? Multilingual Human Detection and Preference Against AI</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yuxia Wang, Rui Xing, Jonibek Mansurov, Giovanni Puccetti, Zhuohan Xie, Minh Ngoc Ta, Jiahui Geng, Jinyan Su, Mervat Abassy, Saad El Dine Ahmed, Kareem Elozeiri, Nurkhan Laiyk, Maiya Goloburda, Tarek Mahmoud, Raj Vardhan Tomar, Alexander Aziz, Ryuto Koike, Masahiro Kaneko, Artem Shelmanov, Ekaterina Artemova, Vladislav Mikhailov, Akim Tsvigun, Alham Fikri Aji, Nizar Habash, Iryna Gurevych, Preslav Nakov
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Prior studies have shown that distinguishing text generated by large language models (LLMs) from human-written one is highly challenging, and often no better than random guessing. To verify the generalizability of this finding across languages and domains, we perform an extensive case study to ident</span>
                
                <span class="abstract-full" style="display: none;">Prior studies have shown that distinguishing text generated by large language models (LLMs) from human-written one is highly challenging, and often no better than random guessing. To verify the generalizability of this finding across languages and domains, we perform an extensive case study to identify the upper bound of human detection accuracy. Across 16 datasets covering 9 languages and 9 domains, 19 annotators achieved an average detection accuracy of 87.6\%, thus challenging previous conclusions. We find that major gaps between human and machine text lie in concreteness, cultural nuances, and diversity. Prompting by explicitly explaining the distinctions in the prompts can partially bridge the gaps in over 50\% of the cases. However, we also find that humans do not always prefer human-written text, particularly when they cannot clearly identify its source.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 13.8%">
                            LLMs
                        </span>
                <!-- Blockchain: 2.6 -->
                    
                <!-- Medicine: 2.4 -->
                    
                <!-- Computer Vision: 2.4 -->
                    
                <!-- Quantum Computing: 2.0 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Datasets: 1.7 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.1238
                </span>
                <a href="https://arxiv.org/abs/2505.17037" target="_blank" rel="noopener noreferrer">Prompt Engineering: How Prompt Vocabulary affects Domain Knowledge</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Dimitri Schreiter
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Prompt engineering has emerged as a critical component in optimizing large language models (LLMs) for domain-specific tasks. However, the role of prompt specificity, especially in domains like STEM (physics, chemistry, biology, computer science and mathematics), medicine, and law, remains underexplo</span>
                
                <span class="abstract-full" style="display: none;">Prompt engineering has emerged as a critical component in optimizing large language models (LLMs) for domain-specific tasks. However, the role of prompt specificity, especially in domains like STEM (physics, chemistry, biology, computer science and mathematics), medicine, and law, remains underexplored. This thesis addresses the problem of whether increasing the specificity of vocabulary in prompts improves LLM performance in domain-specific question-answering and reasoning tasks. We developed a synonymization framework to systematically substitute nouns, verbs, and adjectives with varying specificity levels, measuring the impact on four LLMs: Llama-3.1-70B-Instruct, Granite-13B-Instruct-V2, Flan-T5-XL, and Mistral-Large 2, across datasets in STEM, law, and medicine. Our results reveal that while generally increasing the specificity of prompts does not have a significant impact, there appears to be a specificity range, across all considered models, where the LLM performs the best. Identifying this optimal specificity range offers a key insight for prompt design, suggesting that manipulating prompts within this range could maximize LLM performance and lead to more efficient applications in specialized domains.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 14.9%">
                            LLMs
                        </span>
                <!-- Medicine: 2.9 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                <!-- Game Theory: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.1267
                </span>
                <a href="https://arxiv.org/abs/2502.10440" target="_blank" rel="noopener noreferrer">Towards Copyright Protection for Knowledge Bases of Retrieval-augmented Language Models via Reasoning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Junfeng Guo, Yiming Li, Ruibo Chen, Yihan Wu, Chenxi Liu, Yanshuo Chen, Heng Huang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Large language models (LLMs) are increasingly integrated into real-world personalized applications through retrieval-augmented generation (RAG) mechanisms to supplement their responses with domain-specific knowledge. However, the valuable and often proprietary nature of the knowledge bases used in R</span>
                
                <span class="abstract-full" style="display: none;">Large language models (LLMs) are increasingly integrated into real-world personalized applications through retrieval-augmented generation (RAG) mechanisms to supplement their responses with domain-specific knowledge. However, the valuable and often proprietary nature of the knowledge bases used in RAG introduces the risk of unauthorized usage by adversaries. Existing methods that can be generalized as watermarking techniques to protect these knowledge bases typically involve poisoning or backdoor attacks. However, these methods require altering the LLM's results of verification samples, inevitably making these watermarks susceptible to anomaly detection and even introducing new security risks. To address these challenges, we propose \name{} for `harmless' copyright protection of knowledge bases. Instead of manipulating LLM's final output, \name{} implants distinct yet benign verification behaviors in the space of chain-of-thought (CoT) reasoning, maintaining the correctness of the final answer. Our method has three main stages: (1) Generating CoTs: For each verification question, we generate two `innocent' CoTs, including a target CoT for building watermark behaviors; (2) Optimizing Watermark Phrases and Target CoTs: Inspired by our theoretical analysis, we optimize them to minimize retrieval errors under the \emph{black-box} and \emph{text-only} setting of suspicious LLM, ensuring that only watermarked verification queries can retrieve their correspondingly target CoTs contained in the knowledge base; (3) Ownership Verification: We exploit a pairwise Wilcoxon test to verify whether a suspicious LLM is augmented with the protected knowledge base by comparing its responses to watermarked and benign verification queries. Our experiments on diverse benchmarks demonstrate that \name{} effectively protects knowledge bases and its resistance to adaptive attacks.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 13.9%">
                            LLMs
                        </span>
                <!-- Federated Learning: 3.9 -->
                    
                <!-- Quantum Computing: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- Medicine: 1.8 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.1379
                </span>
                <a href="https://arxiv.org/abs/2505.17760" target="_blank" rel="noopener noreferrer">But what is your honest answer? Aiding LLM-judges with honest alternatives using steering vectors</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Leon Eshuijs, Archie Chaudhury, Alan McBeth, Ethan Nguyen
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Recent safety evaluations of Large Language Models (LLMs) show that many models exhibit dishonest behavior, such as sycophancy. However, most honesty benchmarks focus exclusively on factual knowledge or explicitly harmful behavior and rely on external judges, which are often unable to detect less ob</span>
                
                <span class="abstract-full" style="display: none;">Recent safety evaluations of Large Language Models (LLMs) show that many models exhibit dishonest behavior, such as sycophancy. However, most honesty benchmarks focus exclusively on factual knowledge or explicitly harmful behavior and rely on external judges, which are often unable to detect less obvious forms of dishonesty. In this work, we introduce a new framework, Judge Using Safety-Steered Alternatives (JUSSA), which utilizes steering vectors trained on a single sample to elicit more honest responses from models, helping LLM-judges in the detection of dishonest behavior. To test our framework, we introduce a new manipulation dataset with prompts specifically designed to elicit deceptive responses. We find that JUSSA enables LLM judges to better differentiate between dishonest and benign responses, and helps them identify subtle instances of manipulative behavior.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 17.9%">
                            LLMs
                        </span>
                <!-- Federated Learning: 3.1 -->
                    
                <!-- Computer Vision: 2.4 -->
                    
                <!-- GNN: 2.3 -->
                    
                <!-- Evolutionary Algorithms: 2.3 -->
                    
                <!-- Medicine: 2.2 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.1427
                </span>
                <a href="https://arxiv.org/abs/2505.17716" target="_blank" rel="noopener noreferrer">Get Experience from Practice: LLM Agents with Record & Replay</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Erhu Feng, Wenbo Zhou, Zibin Liu, Le Chen, Yunpeng Dong, Cheng Zhang, Yisheng Zhao, Dong Du, Zhichao Hua, Yubin Xia, Haibo Chen
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">AI agents, empowered by Large Language Models (LLMs) and communication protocols such as MCP and A2A, have rapidly evolved from simple chatbots to autonomous entities capable of executing complex, multi-step tasks, demonstrating great potential. However, the LLMs' inherent uncertainty and heavy comp</span>
                
                <span class="abstract-full" style="display: none;">AI agents, empowered by Large Language Models (LLMs) and communication protocols such as MCP and A2A, have rapidly evolved from simple chatbots to autonomous entities capable of executing complex, multi-step tasks, demonstrating great potential. However, the LLMs' inherent uncertainty and heavy computational resource requirements pose four significant challenges to the development of safe and efficient agents: reliability, privacy, cost and performance. Existing approaches, like model alignment, workflow constraints and on-device model deployment, can partially alleviate some issues but often with limitations, failing to fundamentally resolve these challenges.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 18.6%">
                            LLMs
                        </span>
                <!-- Medicine: 4.6 -->
                    
                <!-- Blockchain: 2.8 -->
                    
                <!-- Computer Vision: 2.2 -->
                    
                <!-- HPO and AutoML: 2.0 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Federated Learning: 1.6 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- 3D: 1.4 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.1632
                </span>
                <a href="https://arxiv.org/abs/2505.18071" target="_blank" rel="noopener noreferrer">Extended Inductive Reasoning for Personalized Preference Inference from Behavioral Signals</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jia-Nan Li, Jian Guan, Wei Wu, Rui Yan
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Large language models (LLMs) have demonstrated significant success in complex reasoning tasks such as math and coding. In contrast to these tasks where deductive reasoning predominates, inductive reasoning\textemdash the ability to derive general rules from incomplete evidence, remains underexplored</span>
                
                <span class="abstract-full" style="display: none;">Large language models (LLMs) have demonstrated significant success in complex reasoning tasks such as math and coding. In contrast to these tasks where deductive reasoning predominates, inductive reasoning\textemdash the ability to derive general rules from incomplete evidence, remains underexplored. This paper investigates extended inductive reasoning in LLMs through the lens of personalized preference inference, a critical challenge in LLM alignment where current approaches struggle to capture diverse user preferences. The task demands strong inductive reasoning capabilities as user preferences are typically embedded implicitly across various interaction forms, requiring models to synthesize consistent preference patterns from scattered signals. We propose \textsc{AlignXplore}, a model that leverages extended reasoning chains to enable systematic preference inference from behavioral signals in users' interaction histories. We develop \textsc{AlignXplore} by combining cold-start training based on synthetic data with subsequent online reinforcement learning. Through extensive experiments, we demonstrate that \textsc{AlignXplore} achieves substantial improvements over the backbone model by an average of 11.05\% on in-domain and out-of-domain benchmarks, while maintaining strong generalization ability across different input formats and downstream models. Further analyses establish best practices for preference inference learning through systematic comparison of reward modeling strategies, while revealing the emergence of human-like inductive reasoning patterns during training.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 24.5%">
                            LLMs
                        </span>
                <!-- Medicine: 2.2 -->
                    
                <!-- GNN: 2.1 -->
                    
                <!-- Computer Vision: 2.1 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.1659
                </span>
                <a href="https://arxiv.org/abs/2502.10735" target="_blank" rel="noopener noreferrer">Beyond One-Size-Fits-All Pruning via Evolutionary Metric Search for Large Language Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Shuqi Liu, Bowei He, Han Wu, Linqi Song
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Post-training pruning has emerged as a crucial optimization technique as large language models (LLMs) continue to grow rapidly. However, the significant variations in weight distributions across different LLMs make fixed pruning strategies inadequate for multiple models. In this paper, we introduce </span>
                
                <span class="abstract-full" style="display: none;">Post-training pruning has emerged as a crucial optimization technique as large language models (LLMs) continue to grow rapidly. However, the significant variations in weight distributions across different LLMs make fixed pruning strategies inadequate for multiple models. In this paper, we introduce \textbf{\textsc{OptiShear}}, an efficient evolutionary optimization framework for adaptive LLM pruning. Our framework features two key innovations: an effective search space built on our Meta pruning metric to handle diverse weight distributions, and a model-wise reconstruction error for rapid evaluation during search trials. We employ Non-dominated Sorting Genetic Algorithm III (NSGA-III) to optimize both pruning metrics and layerwise sparsity ratios. Through extensive evaluation on LLaMA-1/2/3 and Mistral models (7B-70B) across multiple benchmarks, we demonstrate that our adaptive pruning metrics consistently outperform existing methods. Additionally, our discovered layerwise sparsity ratios enhance the effectiveness of other pruning metrics. The framework exhibits strong cross-task and cross-model generalizability, providing a cost-effective solution for model compression.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 23.2%">
                            LLMs
                        </span>
                <!-- Medicine: 3.2 -->
                    
                <!-- Federated Learning: 3.0 -->
                    
                <!-- Evolutionary Algorithms: 2.8 -->
                    
                <!-- Computer Vision: 2.6 -->
                    
                <!-- HPO and AutoML: 1.8 -->
                    
                <!-- Bayesian Optimization: 1.6 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                <!-- Datasets: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.2007
                </span>
                <a href="https://arxiv.org/abs/2505.17217" target="_blank" rel="noopener noreferrer">Mitigating Gender Bias via Fostering Exploratory Thinking in LLMs</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Kangda Wei, Hasnat Md Abdullah, Ruihong Huang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Large Language Models (LLMs) often exhibit gender bias, resulting in unequal treatment of male and female subjects across different contexts. To address this issue, we propose a novel data generation framework that fosters exploratory thinking in LLMs. Our approach prompts models to generate story p</span>
                
                <span class="abstract-full" style="display: none;">Large Language Models (LLMs) often exhibit gender bias, resulting in unequal treatment of male and female subjects across different contexts. To address this issue, we propose a novel data generation framework that fosters exploratory thinking in LLMs. Our approach prompts models to generate story pairs featuring male and female protagonists in structurally identical, morally ambiguous scenarios, then elicits and compares their moral judgments. When inconsistencies arise, the model is guided to produce balanced, gender-neutral judgments. These story-judgment pairs are used to fine-tune or optimize the models via Direct Preference Optimization (DPO). Experimental results show that our method significantly reduces gender bias while preserving or even enhancing general model capabilities. We will release the code and generated data.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 28.1%">
                            LLMs
                        </span>
                <!-- Federated Learning: 2.7 -->
                    
                <!-- Computer Vision: 2.4 -->
                    
                <!-- Medicine: 2.3 -->
                    
                <!-- Decision Trees: 2.0 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- T2I: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.2439
                </span>
                <a href="https://arxiv.org/abs/2505.17056" target="_blank" rel="noopener noreferrer">Are LLMs Ready for English Standardized Tests? A Benchmarking and Elicitation Perspective</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Luoxi Tang, Tharunya Sundar, Shuai Yang, Ankita Patra, Manohar Chippada, Giqi Zhao, Yi Li, Riteng Zhang, Tunan Zhao, Ting Yang, Yuqiao Meng, Weicheng Ma, Zhaohan Xi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">AI is transforming education by enabling powerful tools that enhance learning experiences. Among recent advancements, large language models (LLMs) hold particular promise for revolutionizing how learners interact with educational content. In this work, we investigate the potential of LLMs to support</span>
                
                <span class="abstract-full" style="display: none;">AI is transforming education by enabling powerful tools that enhance learning experiences. Among recent advancements, large language models (LLMs) hold particular promise for revolutionizing how learners interact with educational content. In this work, we investigate the potential of LLMs to support standardized test preparation by focusing on English Standardized Tests (ESTs). Specifically, we assess their ability to generate accurate and contextually appropriate solutions across a diverse set of EST question types. We introduce ESTBOOK, a comprehensive benchmark designed to evaluate the capabilities of LLMs in solving EST questions. ESTBOOK aggregates five widely recognized tests, encompassing 29 question types and over 10,576 questions across multiple modalities, including text, images, audio, tables, and mathematical symbols. Using ESTBOOK, we systematically evaluate both the accuracy and inference efficiency of LLMs. Additionally, we propose a breakdown analysis framework that decomposes complex EST questions into task-specific solution steps. This framework allows us to isolate and assess LLM performance at each stage of the reasoning process. Evaluation findings offer insights into the capability of LLMs in educational contexts and point toward targeted strategies for improving their reliability as intelligent tutoring systems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 29.3%">
                            LLMs
                        </span>
                <!-- Medicine: 3.3 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- Computer Vision: 2.1 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.3425
                </span>
                <a href="https://arxiv.org/abs/2505.11365" target="_blank" rel="noopener noreferrer">Phare: A Safety Probe for Large Language Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Pierre Le Jeune, Beno\^it Mal\'ezieux, Weixuan Xiao, Matteo Dora
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Ensuring the safety of large language models (LLMs) is critical for responsible deployment, yet existing evaluations often prioritize performance over identifying failure modes. We introduce Phare, a multilingual diagnostic framework to probe and evaluate LLM behavior across three critical dimension</span>
                
                <span class="abstract-full" style="display: none;">Ensuring the safety of large language models (LLMs) is critical for responsible deployment, yet existing evaluations often prioritize performance over identifying failure modes. We introduce Phare, a multilingual diagnostic framework to probe and evaluate LLM behavior across three critical dimensions: hallucination and reliability, social biases, and harmful content generation. Our evaluation of 17 state-of-the-art LLMs reveals patterns of systematic vulnerabilities across all safety dimensions, including sycophancy, prompt sensitivity, and stereotype reproduction. By highlighting these specific failure modes rather than simply ranking models, Phare provides researchers and practitioners with actionable insights to build more robust, aligned, and trustworthy language systems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 44.5%">
                            LLMs
                        </span>
                <!-- Medicine: 4.0 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Computer Vision: 1.9 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- HPO and AutoML: 1.8 -->
                    
                <!-- Datasets: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- GNN: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.9948
                </span>
                <a href="https://arxiv.org/abs/2505.17442" target="_blank" rel="noopener noreferrer">Reflectance Prediction-based Knowledge Distillation for Robust 3D Object Detection in Compressed Point Clouds</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Hao Jing, Anhong Wang, Yifan Zhang, Donghan Bu, Junhui Hou
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Regarding intelligent transportation systems for vehicle networking, low-bitrate transmission via lossy point cloud compression is vital for facilitating real-time collaborative perception among vehicles with restricted bandwidth. In existing compression transmission systems, the sender lossily comp</span>
                
                <span class="abstract-full" style="display: none;">Regarding intelligent transportation systems for vehicle networking, low-bitrate transmission via lossy point cloud compression is vital for facilitating real-time collaborative perception among vehicles with restricted bandwidth. In existing compression transmission systems, the sender lossily compresses point coordinates and reflectance to generate a transmission code stream, which faces transmission burdens from reflectance encoding and limited detection robustness due to information loss. To address these issues, this paper proposes a 3D object detection framework with reflectance prediction-based knowledge distillation (RPKD). We compress point coordinates while discarding reflectance during low-bitrate transmission, and feed the decoded non-reflectance compressed point clouds into a student detector. The discarded reflectance is then reconstructed by a geometry-based reflectance prediction (RP) module within the student detector for precise detection. A teacher detector with the same structure as student detector is designed for performing reflectance knowledge distillation (RKD) and detection knowledge distillation (DKD) from raw to compressed point clouds. Our RPKD framework jointly trains detectors on both raw and compressed point clouds to improve the student detector's robustness. Experimental results on the KITTI dataset and Waymo Open Dataset demonstrate that our method can boost detection accuracy for compressed point clouds across multiple code rates. Notably, at a low code rate of 2.146 Bpp on the KITTI dataset, our RPKD-PV achieves the highest mAP of 73.6, outperforming existing detection methods with the PV-RCNN baseline.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 8.4%">
                            Computer Vision
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.3%">
                            Medicine
                        </span>
                <!-- 3D: 3.2 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- LLMs: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.0543
                </span>
                <a href="https://arxiv.org/abs/2505.17321" target="_blank" rel="noopener noreferrer">Control of Renewable Energy Communities using AI and Real-World Data</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Tiago Fonseca, Clarisse Sousa, Ricardo Ven\^ancio, Pedro Pires, Ricardo Severino, Paulo Rodrigues, Pedro Paiva, Luis Lino Ferreira
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The electrification of transportation and the increased adoption of decentralized renewable energy generation have added complexity to managing Renewable Energy Communities (RECs). Integrating Electric Vehicle (EV) charging with building energy systems like heating, ventilation, air conditioning (HV</span>
                
                <span class="abstract-full" style="display: none;">The electrification of transportation and the increased adoption of decentralized renewable energy generation have added complexity to managing Renewable Energy Communities (RECs). Integrating Electric Vehicle (EV) charging with building energy systems like heating, ventilation, air conditioning (HVAC), photovoltaic (PV) generation, and battery storage presents significant opportunities but also practical challenges. Reinforcement learning (RL), particularly MultiAgent Deep Deterministic Policy Gradient (MADDPG) algorithms, have shown promising results in simulation, outperforming heuristic control strategies. However, translating these successes into real-world deployments faces substantial challenges, including incomplete and noisy data, integration of heterogeneous subsystems, synchronization issues, unpredictable occupant behavior, and missing critical EV state-of-charge (SoC) information. This paper introduces a framework designed explicitly to handle these complexities and bridge the simulation to-reality gap. The framework incorporates EnergAIze, a MADDPG-based multi-agent control strategy, and specifically addresses challenges related to real-world data collection, system integration, and user behavior modeling. Preliminary results collected from a real-world operational REC with four residential buildings demonstrate the practical feasibility of our approach, achieving an average 9% reduction in daily peak demand and a 5% decrease in energy costs through optimized load scheduling and EV charging behaviors. These outcomes underscore the framework's effectiveness, advancing the practical deployment of intelligent energy management solutions in RECs.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.3%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.1%">
                            Medicine
                        </span>
                <!-- Blockchain: 2.6 -->
                    
                <!-- Hardware: 2.4 -->
                    
                <!-- Datasets: 2.1 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                <!-- 3D: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.0793
                </span>
                <a href="https://arxiv.org/abs/2411.11171" target="_blank" rel="noopener noreferrer">LL\"aMmlein: Compact and Competitive German-Only Language Models from Scratch</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jan Pfister, Julia Wunderle, Andreas Hotho
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We create two German-only decoder models, LL\"aMmlein 120M and 1B, transparently from scratch and publish them, along with the training data, for the German NLP research community to use. The model training involved several key steps, including extensive data preprocessing, the creation of a custom </span>
                
                <span class="abstract-full" style="display: none;">We create two German-only decoder models, LL\"aMmlein 120M and 1B, transparently from scratch and publish them, along with the training data, for the German NLP research community to use. The model training involved several key steps, including extensive data preprocessing, the creation of a custom German tokenizer, the training itself, as well as the evaluation of the final models on various benchmarks. Throughout the training process, multiple checkpoints were saved and analyzed using the SuperGLEBer benchmark to monitor the models' learning dynamics. Compared to state-of-the-art models on the SuperGLEBer benchmark, both LL\"aMmlein models performed competitively, consistently matching or surpassing models with similar parameter sizes. The results show that the models' quality scales with size as expected, but performance improvements on some tasks plateaued early, offering valuable insights into resource allocation for future model development.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.0%">
                            Medicine
                        </span>
                <!-- Computer Vision: 3.9 -->
                    
                <!-- LLMs: 2.4 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- Reinforcement Learning: 1.9 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.0841
                </span>
                <a href="https://arxiv.org/abs/2505.17283" target="_blank" rel="noopener noreferrer">Deconfounded Warm-Start Thompson Sampling with Applications to Precision Medicine</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Prateek Jaiswal, Esmaeil Keyvanshokooh, Junyu Cao
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Randomized clinical trials often require large patient cohorts before drawing definitive conclusions, yet abundant observational data from parallel studies remains underutilized due to confounding and hidden biases. To bridge this gap, we propose Deconfounded Warm-Start Thompson Sampling (DWTS), a p</span>
                
                <span class="abstract-full" style="display: none;">Randomized clinical trials often require large patient cohorts before drawing definitive conclusions, yet abundant observational data from parallel studies remains underutilized due to confounding and hidden biases. To bridge this gap, we propose Deconfounded Warm-Start Thompson Sampling (DWTS), a practical approach that leverages a Doubly Debiased LASSO (DDL) procedure to identify a sparse set of reliable measured covariates and combines them with key hidden covariates to form a reduced context. By initializing Thompson Sampling (LinTS) priors with DDL-estimated means and variances on these measured features -- while keeping uninformative priors on hidden features -- DWTS effectively harnesses confounded observational data to kick-start adaptive clinical trials. Evaluated on both a purely synthetic environment and a virtual environment created using real cardiovascular risk dataset, DWTS consistently achieves lower cumulative regret than standard LinTS, showing how offline causal insights from observational data can improve trial efficiency and support more personalized treatment decisions.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.1%">
                            Medicine
                        </span>
                <!-- LLMs: 4.6 -->
                    
                <!-- 3D: 2.5 -->
                    
                <!-- GNN: 2.5 -->
                    
                <!-- Federated Learning: 2.5 -->
                    
                <!-- Decision Trees: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.137
                </span>
                <a href="https://arxiv.org/abs/2505.17137" target="_blank" rel="noopener noreferrer">Cog-TiPRO: Iterative Prompt Refinement with LLMs to Detect Cognitive Decline via Longitudinal Voice Assistant Commands</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Kristin Qi, Youxiang Zhu, Caroline Summerour, John A. Batsis, Xiaohui Liang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Early detection of cognitive decline is crucial for enabling interventions that can slow neurodegenerative disease progression. Traditional diagnostic approaches rely on labor-intensive clinical assessments, which are impractical for frequent monitoring. Our pilot study investigates voice assistant </span>
                
                <span class="abstract-full" style="display: none;">Early detection of cognitive decline is crucial for enabling interventions that can slow neurodegenerative disease progression. Traditional diagnostic approaches rely on labor-intensive clinical assessments, which are impractical for frequent monitoring. Our pilot study investigates voice assistant systems (VAS) as non-invasive tools for detecting cognitive decline through longitudinal analysis of speech patterns in voice commands. Over an 18-month period, we collected voice commands from 35 older adults, with 15 participants providing daily at-home VAS interactions. To address the challenges of analyzing these short, unstructured and noisy commands, we propose Cog-TiPRO, a framework that combines (1) LLM-driven iterative prompt refinement for linguistic feature extraction, (2) HuBERT-based acoustic feature extraction, and (3) transformer-based temporal modeling. Using iTransformer, our approach achieves 73.80% accuracy and 72.67% F1-score in detecting MCI, outperforming its baseline by 27.13%. Through our LLM approach, we identify linguistic features that uniquely characterize everyday command usage patterns in individuals experiencing cognitive decline.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.1%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.4%">
                            Medicine
                        </span>
                <!-- Quantum Computing: 2.5 -->
                    
                <!-- GNN: 2.4 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- Datasets: 1.7 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- T2I: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.1487
                </span>
                <a href="https://arxiv.org/abs/2505.17475" target="_blank" rel="noopener noreferrer">PoseBH: Prototypical Multi-Dataset Training Beyond Human Pose Estimation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Uyoung Jeong, Jonathan Freer, Seungryul Baek, Hyung Jin Chang, Kwang In Kim
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We study multi-dataset training (MDT) for pose estimation, where skeletal heterogeneity presents a unique challenge that existing methods have yet to address. In traditional domains, \eg regression and classification, MDT typically relies on dataset merging or multi-head supervision. However, the di</span>
                
                <span class="abstract-full" style="display: none;">We study multi-dataset training (MDT) for pose estimation, where skeletal heterogeneity presents a unique challenge that existing methods have yet to address. In traditional domains, \eg regression and classification, MDT typically relies on dataset merging or multi-head supervision. However, the diversity of skeleton types and limited cross-dataset supervision complicate integration in pose estimation. To address these challenges, we introduce PoseBH, a new MDT framework that tackles keypoint heterogeneity and limited supervision through two key techniques. First, we propose nonparametric keypoint prototypes that learn within a unified embedding space, enabling seamless integration across skeleton types. Second, we develop a cross-type self-supervision mechanism that aligns keypoint predictions with keypoint embedding prototypes, providing supervision without relying on teacher-student models or additional augmentations. PoseBH substantially improves generalization across whole-body and animal pose datasets, including COCO-WholeBody, AP-10K, and APT-36K, while preserving performance on standard human pose benchmarks (COCO, MPII, and AIC). Furthermore, our learned keypoint embeddings transfer effectively to hand shape estimation (InterHand2.6M) and human body shape estimation (3DPW). The code for PoseBH is available at: https://github.com/uyoung-jeong/PoseBH.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.4%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.1%">
                            Medicine
                        </span>
                <!-- 3D: 2.7 -->
                    
                <!-- Computer Vision: 2.6 -->
                    
                <!-- GNN: 2.6 -->
                    
                <!-- Decision Trees: 2.1 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- T2I: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.1711
                </span>
                <a href="https://arxiv.org/abs/2505.17259" target="_blank" rel="noopener noreferrer">Understanding the Algorithm Behind Audio Key Detection</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Henrique Perez G. Silva
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The determination of musical key is a fundamental aspect of music theory and perception, providing a harmonic context for melodies and chord progressions. Automating this process, known as automatic key detection, is a significant task in the field of Music Information Retrieval (MIR). This article </span>
                
                <span class="abstract-full" style="display: none;">The determination of musical key is a fundamental aspect of music theory and perception, providing a harmonic context for melodies and chord progressions. Automating this process, known as automatic key detection, is a significant task in the field of Music Information Retrieval (MIR). This article outlines an algorithmic methodology for estimating the musical key of an audio recording by analyzing its tonal content through digital signal processing techniques and comparison with theoretical key profiles.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.1%">
                            Medicine
                        </span>
                <!-- LLMs: 4.0 -->
                    
                <!-- Blockchain: 2.6 -->
                    
                <!-- Hardware: 2.4 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Datasets: 1.8 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Networks: 1.4 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.1784
                </span>
                <a href="https://arxiv.org/abs/2505.17618" target="_blank" rel="noopener noreferrer">Scaling Image and Video Generation via Test-Time Evolutionary Search</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Haoran He, Jiajun Liang, Xintao Wang, Pengfei Wan, Di Zhang, Kun Gai, Ling Pan
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">As the marginal cost of scaling computation (data and parameters) during model pre-training continues to increase substantially, test-time scaling (TTS) has emerged as a promising direction for improving generative model performance by allocating additional computation at inference time. While TTS h</span>
                
                <span class="abstract-full" style="display: none;">As the marginal cost of scaling computation (data and parameters) during model pre-training continues to increase substantially, test-time scaling (TTS) has emerged as a promising direction for improving generative model performance by allocating additional computation at inference time. While TTS has demonstrated significant success across multiple language tasks, there remains a notable gap in understanding the test-time scaling behaviors of image and video generative models (diffusion-based or flow-based models). Although recent works have initiated exploration into inference-time strategies for vision tasks, these approaches face critical limitations: being constrained to task-specific domains, exhibiting poor scalability, or falling into reward over-optimization that sacrifices sample diversity. In this paper, we propose \textbf{Evo}lutionary \textbf{Search} (EvoSearch), a novel, generalist, and efficient TTS method that effectively enhances the scalability of both image and video generation across diffusion and flow models, without requiring additional training or model expansion. EvoSearch reformulates test-time scaling for diffusion and flow models as an evolutionary search problem, leveraging principles from biological evolution to efficiently explore and refine the denoising trajectory. By incorporating carefully designed selection and mutation mechanisms tailored to the stochastic differential equation denoising process, EvoSearch iteratively generates higher-quality offspring while preserving population diversity. Through extensive evaluation across both diffusion and flow architectures for image and video generation tasks, we demonstrate that our method consistently outperforms existing approaches, achieves higher diversity, and shows strong generalizability to unseen evaluation metrics. Our project is available at the website https://tinnerhrhe.github.io/evosearch.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 10.6%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.1%">
                            Medicine
                        </span>
                <!-- Computer Vision: 3.1 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- T2I: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Datasets: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.218
                </span>
                <a href="https://arxiv.org/abs/2505.17985" target="_blank" rel="noopener noreferrer">AI-Driven Robotics for Free-Space Optics</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Shiekh Zia Uddin, Sachin Vaidya, Shrish Choudhary, Zhuo Chen, Raafat K. Salib, Luke Huang, Dirk R. Englund, Marin Solja\v{c}i\'c
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Tabletop optical experiments are foundational to research in many areas of science, including photonics, quantum optics, materials science, metrology, and biomedical imaging. However these experiments remain fundamentally reliant on manual design, assembly, and alignment, limiting throughput and rep</span>
                
                <span class="abstract-full" style="display: none;">Tabletop optical experiments are foundational to research in many areas of science, including photonics, quantum optics, materials science, metrology, and biomedical imaging. However these experiments remain fundamentally reliant on manual design, assembly, and alignment, limiting throughput and reproducibility. Optics currently lacks generalizable robotic systems capable of operating across a diverse range of setups in realistic laboratory environments. Here we present OptoMate, an autonomous platform that integrates generative AI, computer vision, and precision robotics to enable automation of free-space optics experiments. Our platform interprets user-defined goals to generate valid optical setups using a fine-tuned large language model (LLM), assembles the setup via robotic pick-and-place with sub-millimeter accuracy, and performs fine alignment using a robot-deployable tool. The system then executes a range of automated measurements, including laser beam characterization, polarization mapping, and spectroscopy tasks. This work demonstrates the first flexible, AI-driven automation platform for optics, offering a path toward remote operation, cloud labs, and high-throughput discovery in the optical sciences.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.1%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.4%">
                            Medicine
                        </span>
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Datasets: 1.7 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.2333
                </span>
                <a href="https://arxiv.org/abs/2505.17032" target="_blank" rel="noopener noreferrer">A brief review of the Deep BSDE method for solving high-dimensional partial differential equations</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jiequn Han, Arnulf Jentzen, Weinan E
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">High-dimensional partial differential equations (PDEs) pose significant challenges for numerical computation due to the curse of dimensionality, which limits the applicability of traditional mesh-based methods. Since 2017, the Deep BSDE method has introduced deep learning techniques that enable the </span>
                
                <span class="abstract-full" style="display: none;">High-dimensional partial differential equations (PDEs) pose significant challenges for numerical computation due to the curse of dimensionality, which limits the applicability of traditional mesh-based methods. Since 2017, the Deep BSDE method has introduced deep learning techniques that enable the effective solution of nonlinear PDEs in very high dimensions. This innovation has sparked considerable interest in using neural networks for high-dimensional PDEs, making it an active area of research. In this short review, we briefly sketch the Deep BSDE method, its subsequent developments, and future directions for the field.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.3%">
                            Medicine
                        </span>
                <!-- LLMs: 3.0 -->
                    
                <!-- Hardware: 2.8 -->
                    
                <!-- Federated Learning: 2.7 -->
                    
                <!-- Bayesian Optimization: 2.1 -->
                    
                <!-- Quantum Computing: 2.1 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Math: 1.7 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.2455
                </span>
                <a href="https://arxiv.org/abs/2410.00871" target="_blank" rel="noopener noreferrer">MAP: Unleashing Hybrid Mamba-Transformer Vision Backbone's Potential with Masked Autoregressive Pretraining</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yunze Liu, Li Yi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Hybrid Mamba-Transformer networks have recently garnered broad attention. These networks can leverage the scalability of Transformers while capitalizing on Mamba's strengths in long-context modeling and computational efficiency. However, the challenge of effectively pretraining such hybrid networks </span>
                
                <span class="abstract-full" style="display: none;">Hybrid Mamba-Transformer networks have recently garnered broad attention. These networks can leverage the scalability of Transformers while capitalizing on Mamba's strengths in long-context modeling and computational efficiency. However, the challenge of effectively pretraining such hybrid networks remains an open question. Existing methods, such as Masked Autoencoders (MAE) or autoregressive (AR) pretraining, primarily focus on single-type network architectures. In contrast, pretraining strategies for hybrid architectures must be effective for both Mamba and Transformer components. Based on this, we propose Masked Autoregressive Pretraining (MAP) to pretrain a hybrid Mamba-Transformer vision backbone network. This strategy combines the strengths of both MAE and Autoregressive pretraining, improving the performance of Mamba and Transformer modules within a unified paradigm. Experimental results show that the hybrid Mamba-Transformer vision backbone network pretrained with MAP significantly outperforms other pretraining strategies, achieving state-of-the-art performance. We validate the method's effectiveness on both 2D and 3D datasets and provide detailed ablation studies to support the design choices for each component. The code and checkpoints are available at https://github.com/yunzeliu/MAP</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.8%">
                            Medicine
                        </span>
                <!-- LLMs: 2.7 -->
                    
                <!-- Hardware: 2.6 -->
                    
                <!-- Federated Learning: 2.5 -->
                    
                <!-- Blockchain: 2.4 -->
                    
                <!-- Evolutionary Algorithms: 2.2 -->
                    
                <!-- Computer Vision: 2.2 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.248
                </span>
                <a href="https://arxiv.org/abs/2505.17862" target="_blank" rel="noopener noreferrer">Daily-Omni: Towards Audio-Visual Reasoning with Temporal Alignment across Modalities</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ziwei Zhou, Rui Wang, Zuxuan Wu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Recent Multimodal Large Language Models (MLLMs) achieve promising performance on visual and audio benchmarks independently. However, the ability of these models to process cross-modal information synchronously remains largely unexplored. In this paper, we introduce: 1) Daily-Omni, an Audio-Visual Qu</span>
                
                <span class="abstract-full" style="display: none;">Recent Multimodal Large Language Models (MLLMs) achieve promising performance on visual and audio benchmarks independently. However, the ability of these models to process cross-modal information synchronously remains largely unexplored. In this paper, we introduce: 1) Daily-Omni, an Audio-Visual Questioning and Answering benchmark comprising 684 videos of daily life scenarios from diverse sources, rich in both audio and visual information, and featuring 1197 multiple-choice QA pairs across 6 major tasks; 2) Daily-Omni QA Generation Pipeline, which includes automatic annotation, QA generation and QA optimization, significantly improves efficiency for human evaluation and scalability of the benchmark; 3) Daily-Omni-Agent, a training-free agent utilizing open-source Visual Language Model (VLM), Audio Language Model (ALM) and Automatic Speech Recognition (ASR) model to establish a baseline for this benchmark. The results show that current MLLMs still struggle significantly with tasks requiring audio-visual integration, but combining VLMs and ALMs with simple temporal alignment techniques can achieve substantially better performance. Codes and benchmark are available at \href{https://github.com/Lliar-liar/Daily-Omni}{https://github.com/Lliar-liar/Daily-Omni}.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 15.2%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.3%">
                            Medicine
                        </span>
                <!-- Computer Vision: 3.1 -->
                    
                <!-- Datasets: 2.0 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Federated Learning: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- T2I: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.2593
                </span>
                <a href="https://arxiv.org/abs/2505.17719" target="_blank" rel="noopener noreferrer">Stage-Parallel Implicit Runge--Kutta methods via low-rank matrix equation corrections</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Fabio Durastante, Mariarosa Mazza
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Implicit Runge--Kutta (IRK) methods are highly effective for solving stiff ordinary differential equations (ODEs) but can be computationally expensive for large-scale problems due to the need of solving coupled algebraic equations at each step. This study improves IRK efficiency by leveraging parall</span>
                
                <span class="abstract-full" style="display: none;">Implicit Runge--Kutta (IRK) methods are highly effective for solving stiff ordinary differential equations (ODEs) but can be computationally expensive for large-scale problems due to the need of solving coupled algebraic equations at each step. This study improves IRK efficiency by leveraging parallelism to decouple stage computations and reduce communication overhead, specifically we stably decouple a perturbed version of the stage system of equations and recover the exact solution by solving a Sylvester matrix equation with an explicitly known low-rank right-hand side. Two IRK families -- symmetric methods and collocation methods -- are analyzed, with extensions to nonlinear problems using a simplified Newton method. Implementation details, shared memory parallel code, and numerical examples, particularly for ODEs from spatially discretized PDEs, demonstrate the efficiency of the proposed IRK technique.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.0%">
                            Medicine
                        </span>
                <!-- LLMs: 2.9 -->
                    
                <!-- Federated Learning: 2.8 -->
                    
                <!-- Evolutionary Algorithms: 2.2 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Bayesian Optimization: 1.8 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.2605
                </span>
                <a href="https://arxiv.org/abs/2505.17591" target="_blank" rel="noopener noreferrer">MinkUNeXt-SI: Improving point cloud-based place recognition including spherical coordinates and LiDAR intensity</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Judith Vilella-Cantos, Juan Jos\'e Cabrera, Luis Pay\'a, M\'onica Ballesta, David Valiente
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In autonomous navigation systems, the solution of the place recognition problem is crucial for their safe functioning. But this is not a trivial solution, since it must be accurate regardless of any changes in the scene, such as seasonal changes and different weather conditions, and it must be gener</span>
                
                <span class="abstract-full" style="display: none;">In autonomous navigation systems, the solution of the place recognition problem is crucial for their safe functioning. But this is not a trivial solution, since it must be accurate regardless of any changes in the scene, such as seasonal changes and different weather conditions, and it must be generalizable to other environments. This paper presents our method, MinkUNeXt-SI, which, starting from a LiDAR point cloud, preprocesses the input data to obtain its spherical coordinates and intensity values normalized within a range of 0 to 1 for each point, and it produces a robust place recognition descriptor. To that end, a deep learning approach that combines Minkowski convolutions and a U-net architecture with skip connections is used. The results of MinkUNeXt-SI demonstrate that this method reaches and surpasses state-of-the-art performance while it also generalizes satisfactorily to other datasets. Additionally, we showcase the capture of a custom dataset and its use in evaluating our solution, which also achieves outstanding results. Both the code of our solution and the runs of our dataset are publicly available for reproducibility purposes.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.0%">
                            Medicine
                        </span>
                <!-- LLMs: 3.2 -->
                    
                <!-- Federated Learning: 3.1 -->
                    
                <!-- Evolutionary Algorithms: 2.4 -->
                    
                <!-- Datasets: 2.1 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Hardware: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.2931
                </span>
                <a href="https://arxiv.org/abs/2502.14614" target="_blank" rel="noopener noreferrer">ICA-RAG: Information Completeness Guided Adaptive Retrieval-Augmented Generation for Disease Diagnosis</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Mingyi Jia, Zhihao Jia, Junwen Duan, Yan Song, Jianxin Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Retrieval-Augmented Large Language Models~(LLMs), which integrate external knowledge, have shown remarkable performance in medical domains, including clinical diagnosis. However, existing RAG methods often struggle to tailor retrieval strategies to diagnostic difficulty and input sample informativen</span>
                
                <span class="abstract-full" style="display: none;">Retrieval-Augmented Large Language Models~(LLMs), which integrate external knowledge, have shown remarkable performance in medical domains, including clinical diagnosis. However, existing RAG methods often struggle to tailor retrieval strategies to diagnostic difficulty and input sample informativeness. This limitation leads to excessive and often unnecessary retrieval, impairing computational efficiency and increasing the risk of introducing noise that can degrade diagnostic accuracy. To address this, we propose ICA-RAG (\textbf{I}nformation \textbf{C}ompleteness Guided \textbf{A}daptive \textbf{R}etrieval-\textbf{A}ugmented \textbf{G}eneration), a novel framework for enhancing RAG reliability in disease diagnosis. ICA-RAG utilizes an adaptive control module to assess the necessity of retrieval based on the input's information completeness. By optimizing retrieval and incorporating knowledge filtering, ICA-RAG better aligns retrieval operations with clinical requirements. Experiments on three Chinese electronic medical record datasets demonstrate that ICA-RAG significantly outperforms baseline methods, highlighting its effectiveness in clinical diagnosis.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.6%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.3%">
                            Medicine
                        </span>
                <!-- Federated Learning: 2.7 -->
                    
                <!-- Computer Vision: 2.7 -->
                    
                <!-- GNN: 2.4 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.2971
                </span>
                <a href="https://arxiv.org/abs/2505.17810" target="_blank" rel="noopener noreferrer">VIBE: Vector Index Benchmark for Embeddings</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Elias J\"a\"asaari, Ville Hyv\"onen, Matteo Ceccarello, Teemu Roos, Martin Aum\"uller
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Approximate nearest neighbor (ANN) search is a performance-critical component of many machine learning pipelines. Rigorous benchmarking is essential for evaluating the performance of vector indexes for ANN search. However, the datasets of the existing benchmarks are no longer representative of the c</span>
                
                <span class="abstract-full" style="display: none;">Approximate nearest neighbor (ANN) search is a performance-critical component of many machine learning pipelines. Rigorous benchmarking is essential for evaluating the performance of vector indexes for ANN search. However, the datasets of the existing benchmarks are no longer representative of the current applications of ANN search. Hence, there is an urgent need for an up-to-date set of benchmarks. To this end, we introduce Vector Index Benchmark for Embeddings (VIBE), an open source project for benchmarking ANN algorithms. VIBE contains a pipeline for creating benchmark datasets using dense embedding models characteristic of modern applications, such as retrieval-augmented generation (RAG). To replicate real-world workloads, we also include out-of-distribution (OOD) datasets where the queries and the corpus are drawn from different distributions. We use VIBE to conduct a comprehensive evaluation of SOTA vector indexes, benchmarking 21 implementations on 12 in-distribution and 6 out-of-distribution datasets.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.6%">
                            Medicine
                        </span>
                <!-- Federated Learning: 3.3 -->
                    
                <!-- Evolutionary Algorithms: 3.2 -->
                    
                <!-- Hardware: 3.1 -->
                    
                <!-- Bayesian Optimization: 2.8 -->
                    
                <!-- Datasets: 2.1 -->
                    
                <!-- LLMs: 1.9 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.3211
                </span>
                <a href="https://arxiv.org/abs/2505.17094" target="_blank" rel="noopener noreferrer">Neuromorphic Mimicry Attacks Exploiting Brain-Inspired Computing for Covert Cyber Intrusions</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Hemanth Ravipati
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Neuromorphic computing, inspired by the human brain's neural architecture, is revolutionizing artificial intelligence and edge computing with its low-power, adaptive, and event-driven designs. However, these unique characteristics introduce novel cybersecurity risks. This paper proposes Neuromorphic</span>
                
                <span class="abstract-full" style="display: none;">Neuromorphic computing, inspired by the human brain's neural architecture, is revolutionizing artificial intelligence and edge computing with its low-power, adaptive, and event-driven designs. However, these unique characteristics introduce novel cybersecurity risks. This paper proposes Neuromorphic Mimicry Attacks (NMAs), a groundbreaking class of threats that exploit the probabilistic and non-deterministic nature of neuromorphic chips to execute covert intrusions. By mimicking legitimate neural activity through techniques such as synaptic weight tampering and sensory input poisoning, NMAs evade traditional intrusion detection systems, posing risks to applications such as autonomous vehicles, smart medical implants, and IoT networks. This research develops a theoretical framework for NMAs, evaluates their impact using a simulated neuromorphic chip dataset, and proposes countermeasures, including neural-specific anomaly detection and secure synaptic learning protocols. The findings underscore the critical need for tailored cybersecurity measures to protect brain-inspired computing, offering a pioneering exploration of this emerging threat landscape.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.7%">
                            Medicine
                        </span>
                <!-- LLMs: 4.2 -->
                    
                <!-- Blockchain: 2.5 -->
                    
                <!-- Hardware: 2.3 -->
                    
                <!-- Computer Vision: 2.1 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.3389
                </span>
                <a href="https://arxiv.org/abs/2505.17549" target="_blank" rel="noopener noreferrer">EGA: A Unified End-to-End Generative Framework for Industrial Advertising Systems</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zuowu Zheng, Ze Wang, Fan Yang, Jiangke Fan, Teng Zhang, Xingxing Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Online industrial advertising system is fundamentally constrained by the inefficiency of multi-stage cascaded architectures, which filter out high-potential candidates early and fragment business decision logic across independent modules. Although recent advances in generative recommendation offer e</span>
                
                <span class="abstract-full" style="display: none;">Online industrial advertising system is fundamentally constrained by the inefficiency of multi-stage cascaded architectures, which filter out high-potential candidates early and fragment business decision logic across independent modules. Although recent advances in generative recommendation offer end-to-end solutions, they fall short of practical advertising requirements, lacking explicit modeling of bidding, creative selection, allocation mechanism, and payment computation that are essential for real-world deployment. To overcome these limitations, we propose End-to-end Generative Advertising (EGA), a first unified generative framework that seamlessly integrates user interests modeling, POI and creative generation, position allocation, and payment optimization within a single model. EGA leverages hierarchical tokenization and multi-token prediction to jointly generate candidate POI and creative contents, while a permutation-aware reward model and token-level bidding strategy ensure alignment with both user experiences and advertiser business objectives. Meanwhile, we decouple allocation from payment via a dedicated POI-level payment network with differentiable ex-post regret minimization, guaranteeing incentive compatibility approximately. Extensive offline and large-scale online experiments on real-world advertising systems demonstrate its effectiveness and practical advantages over traditional cascading architectures, highlighting its potential as one of the industry's pioneering end-to-end generative advertising solutions.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.3%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.0%">
                            Medicine
                        </span>
                <!-- Blockchain: 2.4 -->
                    
                <!-- 3D: 1.9 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Datasets: 1.8 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- T2I: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.351
                </span>
                <a href="https://arxiv.org/abs/2410.19133" target="_blank" rel="noopener noreferrer">Hybrid Preferences: Learning to Route Instances for Human vs. AI Feedback</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Lester James V. Miranda, Yizhong Wang, Yanai Elazar, Sachin Kumar, Valentina Pyatkin, Faeze Brahman, Noah A. Smith, Hannaneh Hajishirzi, Pradeep Dasigi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Learning from human feedback has enabled the alignment of language models (LMs) with human preferences. However, collecting human preferences is expensive and time-consuming, with highly variable annotation quality. An appealing alternative is to distill preferences from LMs as a source of synthetic</span>
                
                <span class="abstract-full" style="display: none;">Learning from human feedback has enabled the alignment of language models (LMs) with human preferences. However, collecting human preferences is expensive and time-consuming, with highly variable annotation quality. An appealing alternative is to distill preferences from LMs as a source of synthetic annotations, offering a cost-effective and scalable alternative, albeit susceptible to other biases and errors. In this work, we introduce HyPER, a Hybrid Preference routER that defers an annotation to either humans or LMs, achieving better annotation quality while reducing the cost of human-only annotation. We formulate this as an optimization problem: given a preference dataset and an evaluation metric, we (1) train a performance prediction model (PPM) to predict a reward model's (RM) performance on an arbitrary combination of human and LM annotations and (2) employ a routing strategy that selects a combination that maximizes the predicted performance. We train the PPM on MultiPref, a new preference dataset with 10k instances paired with humans and LM labels. We show that the selected hybrid mixture of synthetic and direct human preferences using HyPER achieves better RM performance compared to using either one exclusively by 7-13% on RewardBench and generalizes across unseen preference datasets and other base models. We also observe the same trend in other benchmarks using Best-of-N reranking, where the hybrid mix has 2-3% better performance. Finally, we analyze features from HyPER and find that prompts with moderate safety concerns or complexity benefit the most from human feedback.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.3%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.6%">
                            Medicine
                        </span>
                <!-- Federated Learning: 2.2 -->
                    
                <!-- Reinforcement Learning: 2.1 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Computer Vision: 1.2 -->
                    
                <!-- 3D: 1.1 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.3654
                </span>
                <a href="https://arxiv.org/abs/2505.17198" target="_blank" rel="noopener noreferrer">LengthLogD: A Length-Stratified Ensemble Framework for Enhanced Peptide Lipophilicity Prediction via Multi-Scale Feature Integration</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Shuang Wu, Meijie Wang, Lun Yu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Peptide compounds demonstrate considerable potential as therapeutic agents due to their high target affinity and low toxicity, yet their drug development is constrained by their low membrane permeability. Molecular weight and peptide length have significant effects on the logD of peptides, which in </span>
                
                <span class="abstract-full" style="display: none;">Peptide compounds demonstrate considerable potential as therapeutic agents due to their high target affinity and low toxicity, yet their drug development is constrained by their low membrane permeability. Molecular weight and peptide length have significant effects on the logD of peptides, which in turn influences their ability to cross biological membranes. However, accurate prediction of peptide logD remains challenging due to the complex interplay between sequence, structure, and ionization states. This study introduces LengthLogD, a predictive framework that establishes specialized models through molecular length stratification while innovatively integrating multi-scale molecular representations. We constructed feature spaces across three hierarchical levels: atomic (10 molecular descriptors), structural (1024-bit Morgan fingerprints), and topological (3 graph-based features including Wiener index), optimized through stratified ensemble learning. An adaptive weight allocation mechanism specifically developed for long peptides significantly enhances model generalizability. Experimental results demonstrate superior performance across all categories: short peptides (R^2=0.855), medium peptides (R^2=0.816), and long peptides (R^2=0.882), with a 34.7% reduction in prediction error for long peptides compared to conventional single-model approaches. Ablation studies confirm: 1) The length-stratified strategy contributes 41.2% to performance improvement; 2) Topological features account for 28.5% of predictive importance. Compared to state-of-the-art models, our method maintains short peptide prediction accuracy while achieving a 25.7% increase in the coefficient of determination (R^2) for long peptides. This research provides a precise logD prediction tool for peptide drug development, particularly demonstrating unique value in optimizing long peptide lead compounds.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.4%">
                            Medicine
                        </span>
                <!-- LLMs: 4.6 -->
                    
                <!-- Computer Vision: 2.4 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.3707
                </span>
                <a href="https://arxiv.org/abs/2505.17568" target="_blank" rel="noopener noreferrer">JALMBench: Benchmarking Jailbreak Vulnerabilities in Audio Language Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zifan Peng, Yule Liu, Zhen Sun, Mingchen Li, Zeren Luo, Jingyi Zheng, Wenhan Dong, Xinlei He, Xuechao Wang, Yingjie Xue, Shengmin Xu, Xinyi Huang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Audio Language Models (ALMs) have made significant progress recently. These models integrate the audio modality directly into the model, rather than converting speech into text and inputting text to Large Language Models (LLMs). While jailbreak attacks on LLMs have been extensively studied, the secu</span>
                
                <span class="abstract-full" style="display: none;">Audio Language Models (ALMs) have made significant progress recently. These models integrate the audio modality directly into the model, rather than converting speech into text and inputting text to Large Language Models (LLMs). While jailbreak attacks on LLMs have been extensively studied, the security of ALMs with audio modalities remains largely unexplored. Currently, there is a lack of an adversarial audio dataset and a unified framework specifically designed to evaluate and compare attacks and ALMs. In this paper, we present JALMBench, the \textit{first} comprehensive benchmark to assess the safety of ALMs against jailbreak attacks. JALMBench includes a dataset containing 2,200 text samples and 51,381 audio samples with over 268 hours. It supports 12 mainstream ALMs, 4 text-transferred and 4 audio-originated attack methods, and 5 defense methods. Using JALMBench, we provide an in-depth analysis of attack efficiency, topic sensitivity, voice diversity, and attack representations. Additionally, we explore mitigation strategies for the attacks at both the prompt level and the response level.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 14.5%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.0%">
                            Medicine
                        </span>
                <!-- Computer Vision: 2.3 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Datasets: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.3824
                </span>
                <a href="https://arxiv.org/abs/2505.17921" target="_blank" rel="noopener noreferrer">Evaluation of Few-Shot Learning Methods for Kidney Stone Type Recognition in Ureteroscopy</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Carlos Salazar-Ruiz, Francisco Lopez-Tiro, Ivan Reyes-Amezcua, Clement Larose, Gilberto Ochoa-Ruiz, Christian Daul
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Determining the type of kidney stones is crucial for prescribing appropriate treatments to prevent recurrence. Currently, various approaches exist to identify the type of kidney stones. However, obtaining results through the reference ex vivo identification procedure can take several weeks, while in</span>
                
                <span class="abstract-full" style="display: none;">Determining the type of kidney stones is crucial for prescribing appropriate treatments to prevent recurrence. Currently, various approaches exist to identify the type of kidney stones. However, obtaining results through the reference ex vivo identification procedure can take several weeks, while in vivo visual recognition requires highly trained specialists. For this reason, deep learning models have been developed to provide urologists with an automated classification of kidney stones during ureteroscopies. Nevertheless, a common issue with these models is the lack of training data. This contribution presents a deep learning method based on few-shot learning, aimed at producing sufficiently discriminative features for identifying kidney stone types in endoscopic images, even with a very limited number of samples. This approach was specifically designed for scenarios where endoscopic images are scarce or where uncommon classes are present, enabling classification even with a limited training dataset. The results demonstrate that Prototypical Networks, using up to 25% of the training data, can achieve performance equal to or better than traditional deep learning models trained with the complete dataset.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.5%">
                            Medicine
                        </span>
                <!-- Federated Learning: 3.7 -->
                    
                <!-- Evolutionary Algorithms: 2.8 -->
                    
                <!-- GNN: 2.2 -->
                    
                <!-- Bayesian Optimization: 2.2 -->
                    
                <!-- LLMs: 1.9 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Networks: 1.3 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.3924
                </span>
                <a href="https://arxiv.org/abs/2505.17311" target="_blank" rel="noopener noreferrer">Harnessing EHRs for Diffusion-based Anomaly Detection on Chest X-rays</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Harim Kim, Yuhan Wang, Minkyu Ahn, Heeyoul Choi, Yuyin Zhou, Charmgil Hong
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Unsupervised anomaly detection (UAD) in medical imaging is crucial for identifying pathological abnormalities without requiring extensive labeled data. However, existing diffusion-based UAD models rely solely on imaging features, limiting their ability to distinguish between normal anatomical variat</span>
                
                <span class="abstract-full" style="display: none;">Unsupervised anomaly detection (UAD) in medical imaging is crucial for identifying pathological abnormalities without requiring extensive labeled data. However, existing diffusion-based UAD models rely solely on imaging features, limiting their ability to distinguish between normal anatomical variations and pathological anomalies. To address this, we propose Diff3M, a multi-modal diffusion-based framework that integrates chest X-rays and structured Electronic Health Records (EHRs) for enhanced anomaly detection. Specifically, we introduce a novel image-EHR cross-attention module to incorporate structured clinical context into the image generation process, improving the model's ability to differentiate normal from abnormal features. Additionally, we develop a static masking strategy to enhance the reconstruction of normal-like images from anomalies. Extensive evaluations on CheXpert and MIMIC-CXR/IV demonstrate that Diff3M achieves state-of-the-art performance, outperforming existing UAD methods in medical imaging. Our code is available at this http URL https://github.com/nth221/Diff3M</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.8%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.1%">
                            LLMs
                        </span>
                <!-- Computer Vision: 4.1 -->
                    
                <!-- GNN: 3.4 -->
                    
                <!-- 3D: 2.5 -->
                    
                <!-- Federated Learning: 2.5 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- T2I: 1.1 -->
                    
                <!-- Hardware: 1.0 -->
                    
                <!-- Bayesian Optimization: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4021
                </span>
                <a href="https://arxiv.org/abs/2505.17380" target="_blank" rel="noopener noreferrer">AI-Augmented LLMs Achieve Therapist-Level Responses in Motivational Interviewing</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yinghui Huang, Yuxuan Jiang, Hui Liu, Yixin Cai, Weiqing Li, Xiangen Hu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Large language models (LLMs) like GPT-4 show potential for scaling motivational interviewing (MI) in addiction care, but require systematic evaluation of therapeutic capabilities. We present a computational framework assessing user-perceived quality (UPQ) through expected and unexpected MI behaviors</span>
                
                <span class="abstract-full" style="display: none;">Large language models (LLMs) like GPT-4 show potential for scaling motivational interviewing (MI) in addiction care, but require systematic evaluation of therapeutic capabilities. We present a computational framework assessing user-perceived quality (UPQ) through expected and unexpected MI behaviors. Analyzing human therapist and GPT-4 MI sessions via human-AI collaboration, we developed predictive models integrating deep learning and explainable AI to identify 17 MI-consistent (MICO) and MI-inconsistent (MIIN) behavioral metrics. A customized chain-of-thought prompt improved GPT-4's MI performance, reducing inappropriate advice while enhancing reflections and empathy. Although GPT-4 remained marginally inferior to therapists overall, it demonstrated superior advice management capabilities. The model achieved measurable quality improvements through prompt engineering, yet showed limitations in addressing complex emotional nuances. This framework establishes a pathway for optimizing LLM-based therapeutic tools through targeted behavioral metric analysis and human-AI co-evaluation. Findings highlight both the scalability potential and current constraints of LLMs in clinical communication applications.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 24.7%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.3%">
                            Medicine
                        </span>
                <!-- Computer Vision: 2.0 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Datasets: 1.8 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.411
                </span>
                <a href="https://arxiv.org/abs/2505.14555" target="_blank" rel="noopener noreferrer">Physics-Guided Learning of Meteorological Dynamics for Weather Downscaling and Forecasting</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yingtao Luo, Shikai Fang, Binqing Wu, Qingsong Wen, Liang Sun
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Weather forecasting is essential but remains computationally intensive and physically incomplete in traditional numerical weather prediction (NWP) methods. Deep learning (DL) models offer efficiency and accuracy but often ignore physical laws, limiting interpretability and generalization. We propose</span>
                
                <span class="abstract-full" style="display: none;">Weather forecasting is essential but remains computationally intensive and physically incomplete in traditional numerical weather prediction (NWP) methods. Deep learning (DL) models offer efficiency and accuracy but often ignore physical laws, limiting interpretability and generalization. We propose PhyDL-NWP, a physics-guided deep learning framework that integrates physical equations with latent force parameterization into data-driven models. It predicts weather variables from arbitrary spatiotemporal coordinates, computes physical terms via automatic differentiation, and uses a physics-informed loss to align predictions with governing dynamics. PhyDL-NWP enables resolution-free downscaling by modeling weather as a continuous function and fine-tunes pre-trained models with minimal overhead, achieving up to 170x faster inference with only 55K parameters. Experiments show that PhyDL-NWP improves both forecasting performance and physical consistency.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.1%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.3%">
                            Medicine
                        </span>
                <!-- HPO and AutoML: 2.4 -->
                    
                <!-- 3D: 2.2 -->
                    
                <!-- Decision Trees: 2.2 -->
                    
                <!-- Quantum Computing: 2.1 -->
                    
                <!-- Computer Vision: 1.9 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Federated Learning: 1.6 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- T2I: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.413
                </span>
                <a href="https://arxiv.org/abs/2505.17544" target="_blank" rel="noopener noreferrer">FreqU-FNet: Frequency-Aware U-Net for Imbalanced Medical Image Segmentation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ruiqi Xing
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Medical image segmentation faces persistent challenges due to severe class imbalance and the frequency-specific distribution of anatomical structures. Most conventional CNN-based methods operate in the spatial domain and struggle to capture minority class signals, often affected by frequency aliasin</span>
                
                <span class="abstract-full" style="display: none;">Medical image segmentation faces persistent challenges due to severe class imbalance and the frequency-specific distribution of anatomical structures. Most conventional CNN-based methods operate in the spatial domain and struggle to capture minority class signals, often affected by frequency aliasing and limited spectral selectivity. Transformer-based models, while powerful in modeling global dependencies, tend to overlook critical local details necessary for fine-grained segmentation. To overcome these limitations, we propose FreqU-FNet, a novel U-shaped segmentation architecture operating in the frequency domain. Our framework incorporates a Frequency Encoder that leverages Low-Pass Frequency Convolution and Daubechies wavelet-based downsampling to extract multi-scale spectral features. To reconstruct fine spatial details, we introduce a Spatial Learnable Decoder (SLD) equipped with an adaptive multi-branch upsampling strategy. Furthermore, we design a frequency-aware loss (FAL) function to enhance minority class learning. Extensive experiments on multiple medical segmentation benchmarks demonstrate that FreqU-FNet consistently outperforms both CNN and Transformer baselines, particularly in handling under-represented classes, by effectively exploiting discriminative frequency bands.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.9%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.7%">
                            LLMs
                        </span>
                <!-- GNN: 3.0 -->
                    
                <!-- Computer Vision: 3.0 -->
                    
                <!-- 3D: 2.2 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- T2I: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.431
                </span>
                <a href="https://arxiv.org/abs/2505.17951" target="_blank" rel="noopener noreferrer">SplatCo: Structure-View Collaborative Gaussian Splatting for Detail-Preserving Rendering of Large-Scale Unbounded Scenes</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Haihong Xiao, Jianan Zou, Yuxin Zhou, Ying He, Wenxiong Kang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We present SplatCo, a structure-view collaborative Gaussian splatting framework for high-fidelity rendering of complex outdoor environments. SplatCo builds upon two novel components: (1) a cross-structure collaboration module that combines global tri-plane representations, which capture coarse scene</span>
                
                <span class="abstract-full" style="display: none;">We present SplatCo, a structure-view collaborative Gaussian splatting framework for high-fidelity rendering of complex outdoor environments. SplatCo builds upon two novel components: (1) a cross-structure collaboration module that combines global tri-plane representations, which capture coarse scene layouts, with local context grid features that represent fine surface details. This fusion is achieved through a novel hierarchical compensation strategy, ensuring both global consistency and local detail preservation; and (2) a cross-view assisted training strategy that enhances multi-view consistency by synchronizing gradient updates across viewpoints, applying visibility-aware densification, and pruning overfitted or inaccurate Gaussians based on structural consistency. Through joint optimization of structural representation and multi-view coherence, SplatCo effectively reconstructs fine-grained geometric structures and complex textures in large-scale scenes. Comprehensive evaluations on 13 diverse large-scale scenes, including Mill19, MatrixCity, Tanks & Temples, WHU, and custom aerial captures, demonstrate that SplatCo consistently achieves higher reconstruction quality than state-of-the-art methods, with PSNR improvements of 1-2 dB and SSIM gains of 0.1 to 0.2. These results establish a new benchmark for high-fidelity rendering of large-scale unbounded scenes. Code and additional information are available at https://github.com/SCUT-BIP-Lab/SplatCo.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.5%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.0%">
                            LLMs
                        </span>
                <!-- 3D: 3.3 -->
                    
                <!-- Federated Learning: 2.3 -->
                    
                <!-- GNN: 2.1 -->
                    
                <!-- Datasets: 1.8 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Computer Vision: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4312
                </span>
                <a href="https://arxiv.org/abs/2505.17208" target="_blank" rel="noopener noreferrer">RetroChat: Designing for the Preservation of Past Digital Experiences</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Suifang Zhou, Kexue Fu, Huanmin Yi, Ray Lc
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Rapid changes in social networks have transformed the way people express themselves, turning past neologisms, values, and mindsets embedded in these expressions into online heritage. How can we preserve these expressions as cultural heritage? Instead of traditional archiving methods for static mater</span>
                
                <span class="abstract-full" style="display: none;">Rapid changes in social networks have transformed the way people express themselves, turning past neologisms, values, and mindsets embedded in these expressions into online heritage. How can we preserve these expressions as cultural heritage? Instead of traditional archiving methods for static material, we designed an interactive and experiential form of archiving for Chinese social networks. Using dialogue data from 2000-2010 on early Chinese social media, we developed a GPT-driven agent within a retro chat interface, emulating the language and expression style of the period for interaction. Results from a qualitative study with 18 participants show that the design captures the past chatting experience and evokes memory flashbacks and nostalgia feeling through conversation. Participants, particularly those familiar with the era, adapted their language to match the agent's chatting style. This study explores how the design of preservation methods for digital experiences can be informed by experiential representations supported by generative tools.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.7%">
                            Medicine
                        </span>
                <!-- LLMs: 3.1 -->
                    
                <!-- Hardware: 2.4 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4328
                </span>
                <a href="https://arxiv.org/abs/2505.17582" target="_blank" rel="noopener noreferrer">Distance Estimation in Outdoor Driving Environments Using Phase-only Correlation Method with Event Cameras</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Masataka Kobayashi (School of Engineering, Nagoya University, Nagoya, Japan), Shintaro Shiba (Woven by Toyota, Inc., Tokyo, Japan), Quan Kong (Woven by Toyota, Inc., Tokyo, Japan), Norimasa Kobori (Woven by Toyota, Inc., Tokyo, Japan), Tsukasa Shimizu (Toyota Motor Corporation, Toyota, Japan), Shan Lu (School of Engineering, Nagoya University, Nagoya, Japan), Takaya Yamazato (School of Engineering, Nagoya University, Nagoya, Japan)
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">With the growing adoption of autonomous driving, the advancement of sensor technology is crucial for ensuring safety and reliable operation. Sensor fusion techniques that combine multiple sensors such as LiDAR, radar, and cameras have proven effective, but the integration of multiple devices increas</span>
                
                <span class="abstract-full" style="display: none;">With the growing adoption of autonomous driving, the advancement of sensor technology is crucial for ensuring safety and reliable operation. Sensor fusion techniques that combine multiple sensors such as LiDAR, radar, and cameras have proven effective, but the integration of multiple devices increases both hardware complexity and cost. Therefore, developing a single sensor capable of performing multiple roles is highly desirable for cost-efficient and scalable autonomous driving systems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.6%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.4%">
                            LLMs
                        </span>
                <!-- Blockchain: 3.3 -->
                    
                <!-- Hardware: 2.7 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 2.2 -->
                    
                <!-- Quantum Computing: 2.2 -->
                    
                <!-- Datasets: 2.0 -->
                    
                <!-- Bayesian Optimization: 1.6 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Computer Vision: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4338
                </span>
                <a href="https://arxiv.org/abs/2502.06661" target="_blank" rel="noopener noreferrer">iLOCO: Distribution-Free Inference for Feature Interactions</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Camille Little, Lili Zheng, Genevera Allen
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Feature importance measures are widely studied and are essential for understanding model behavior, guiding feature selection, and enhancing interpretability. However, many machine learning fitted models involve complex interactions between features. Existing feature importance metrics fail to captur</span>
                
                <span class="abstract-full" style="display: none;">Feature importance measures are widely studied and are essential for understanding model behavior, guiding feature selection, and enhancing interpretability. However, many machine learning fitted models involve complex interactions between features. Existing feature importance metrics fail to capture these pairwise or higher-order effects, while existing interaction metrics often suffer from limited applicability or excessive computation; no methods exist to conduct statistical inference for feature interactions. To bridge this gap, we first propose a new model-agnostic metric, interaction Leave-One-Covariate-Out (iLOCO), for measuring the importance of pairwise feature interactions, with extensions to higher-order interactions. Next, we leverage recent advances in LOCO inference to develop distribution-free and assumption-light confidence intervals for our iLOCO metric. To address computational challenges, we also introduce an ensemble learning method for calculating the iLOCO metric and confidence intervals that we show is both computationally and statistically efficient. We validate our iLOCO metric and our confidence intervals on both synthetic and real data sets, showing that our approach outperforms existing methods and provides the first inferential approach to detecting feature interactions.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.2%">
                            Medicine
                        </span>
                <!-- LLMs: 4.8 -->
                    
                <!-- Computer Vision: 3.4 -->
                    
                <!-- Decision Trees: 2.2 -->
                    
                <!-- GNN: 2.2 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- HPO and AutoML: 1.8 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- T2I: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4384
                </span>
                <a href="https://arxiv.org/abs/2505.14005" target="_blank" rel="noopener noreferrer">Towards Comprehensive and Prerequisite-Free Explainer for Graph Neural Networks</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Han Zhang, Yan Wang, Guanfeng Liu, Pengfei Ding, Huaxiong Wang, Kwok-Yan Lam
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">To enhance the reliability and credibility of graph neural networks (GNNs) and improve the transparency of their decision logic, a new field of explainability of GNNs (XGNN) has emerged. However, two major limitations severely degrade the performance and hinder the generalizability of existing XGNN </span>
                
                <span class="abstract-full" style="display: none;">To enhance the reliability and credibility of graph neural networks (GNNs) and improve the transparency of their decision logic, a new field of explainability of GNNs (XGNN) has emerged. However, two major limitations severely degrade the performance and hinder the generalizability of existing XGNN methods: they (a) fail to capture the complete decision logic of GNNs across diverse distributions in the entire dataset's sample space, and (b) impose strict prerequisites on edge properties and GNN internal accessibility. To address these limitations, we propose OPEN, a novel c\textbf{O}mprehensive and \textbf{P}rerequisite-free \textbf{E}xplainer for G\textbf{N}Ns. OPEN, as the first work in the literature, can infer and partition the entire dataset's sample space into multiple environments, each containing graphs that follow a distinct distribution. OPEN further learns the decision logic of GNNs across different distributions by sampling subgraphs from each environment and analyzing their predictions, thus eliminating the need for strict prerequisites. Experimental results demonstrate that OPEN captures nearly complete decision logic of GNNs, outperforms state-of-the-art methods in fidelity while maintaining similar efficiency, and enhances robustness in real-world scenarios.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.3%">
                            Medicine
                        </span>
                <!-- LLMs: 3.3 -->
                    
                <!-- GNN: 2.7 -->
                    
                <!-- Blockchain: 2.6 -->
                    
                <!-- Hardware: 2.2 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4521
                </span>
                <a href="https://arxiv.org/abs/2505.17439" target="_blank" rel="noopener noreferrer">Designing an efficient and equitable humanitarian supply chain dynamically via reinforcement learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Weijia Jin
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This study designs an efficient and equitable humanitarian supply chain dynamically by using reinforcement learning, PPO, and compared with heuristic algorithms. This study demonstrates the model of PPO always treats average satisfaction rate as the priority.</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.6%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.7%">
                            LLMs
                        </span>
                <!-- Blockchain: 3.1 -->
                    
                <!-- HPO and AutoML: 2.5 -->
                    
                <!-- Quantum Computing: 2.1 -->
                    
                <!-- Computer Vision: 1.9 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Federated Learning: 1.6 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- 3D: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4954
                </span>
                <a href="https://arxiv.org/abs/2505.13880" target="_blank" rel="noopener noreferrer">U-SAM: An audio language Model for Unified Speech, Audio, and Music Understanding</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ziqian Wang, Xianjun Xia, Xinfa Zhu, Lei Xie
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The text generation paradigm for audio tasks has opened new possibilities for unified audio understanding. However, existing models face significant challenges in achieving a comprehensive understanding across diverse audio types, such as speech, general audio events, and music. Furthermore, their e</span>
                
                <span class="abstract-full" style="display: none;">The text generation paradigm for audio tasks has opened new possibilities for unified audio understanding. However, existing models face significant challenges in achieving a comprehensive understanding across diverse audio types, such as speech, general audio events, and music. Furthermore, their exclusive reliance on cross-entropy loss for alignment often falls short, as it treats all tokens equally and fails to account for redundant audio features, leading to weaker cross-modal alignment. To deal with the above challenges, this paper introduces U-SAM, an advanced audio language model that integrates specialized encoders for speech, audio, and music with a pre-trained large language model (LLM). U-SAM employs a Mixture of Experts (MoE) projector for task-aware feature fusion, dynamically routing and integrating the domain-specific encoder outputs. Additionally, U-SAM incorporates a Semantic-Aware Contrastive Loss Module, which explicitly identifies redundant audio features under language supervision and rectifies their semantic and spectral representations to enhance cross-modal alignment. Extensive experiments demonstrate that U-SAM consistently outperforms both specialized models and existing audio language models across multiple benchmarks. Moreover, it exhibits emergent capabilities on unseen tasks, showcasing its generalization potential. Code is available (https://github.com/Honee-W/U-SAM/).</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 11.1%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.6%">
                            Medicine
                        </span>
                <!-- Computer Vision: 3.1 -->
                    
                <!-- Hardware: 2.4 -->
                    
                <!-- HPO and AutoML: 1.8 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- T2I: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4989
                </span>
                <a href="https://arxiv.org/abs/2505.17952" target="_blank" rel="noopener noreferrer">Beyond Distillation: Pushing the Limits of Medical LLM Reasoning with Minimalist Rule-Based RL</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Che Liu, Haozhe Wang, Jiazhen Pan, Zhongwei Wan, Yong Dai, Fangzhen Lin, Wenjia Bai, Daniel Rueckert, Rossella Arcucci
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Improving performance on complex tasks and enabling interpretable decision making in large language models (LLMs), especially for clinical applications, requires effective reasoning. Yet this remains challenging without supervised fine-tuning (SFT) on costly chain-of-thought (CoT) data distilled fro</span>
                
                <span class="abstract-full" style="display: none;">Improving performance on complex tasks and enabling interpretable decision making in large language models (LLMs), especially for clinical applications, requires effective reasoning. Yet this remains challenging without supervised fine-tuning (SFT) on costly chain-of-thought (CoT) data distilled from closed-source models (e.g., GPT-4o). In this work, we present AlphaMed, the first medical LLM to show that reasoning capability can emerge purely through reinforcement learning (RL), using minimalist rule-based rewards on public multiple-choice QA datasets, without relying on SFT or distilled CoT data. AlphaMed achieves state-of-the-art results on six medical QA benchmarks, outperforming models trained with conventional SFT+RL pipelines. On challenging benchmarks (e.g., MedXpert), AlphaMed even surpasses larger or closed-source models such as DeepSeek-V3-671B and Claude-3.5-Sonnet. To understand the factors behind this success, we conduct a comprehensive data-centric analysis guided by three questions: (i) Can minimalist rule-based RL incentivize reasoning without distilled CoT supervision? (ii) How do dataset quantity and diversity impact reasoning? (iii) How does question difficulty shape the emergence and generalization of reasoning? Our findings show that dataset informativeness is a key driver of reasoning performance, and that minimalist RL on informative, multiple-choice QA data is effective at inducing reasoning without CoT supervision. We also observe divergent trends across benchmarks, underscoring limitations in current evaluation and the need for more challenging, reasoning-oriented medical QA benchmarks.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 11.5%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.6%">
                            Medicine
                        </span>
                <!-- Computer Vision: 2.9 -->
                    
                <!-- Blockchain: 2.0 -->
                    
                <!-- Decision Trees: 1.8 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.5039
                </span>
                <a href="https://arxiv.org/abs/2505.07444" target="_blank" rel="noopener noreferrer">Lightweight Multispectral Crop-Weed Segmentation for Precision Agriculture</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zeynep Galymzhankyzy, Eric Martinson
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Efficient crop-weed segmentation is critical for site-specific weed control in precision agriculture. Conventional CNN-based methods struggle to generalize and rely on RGB imagery, limiting performance under complex field conditions. To address these challenges, we propose a lightweight transformer-</span>
                
                <span class="abstract-full" style="display: none;">Efficient crop-weed segmentation is critical for site-specific weed control in precision agriculture. Conventional CNN-based methods struggle to generalize and rely on RGB imagery, limiting performance under complex field conditions. To address these challenges, we propose a lightweight transformer-CNN hybrid. It processes RGB, Near-Infrared (NIR), and Red-Edge (RE) bands using specialized encoders and dynamic modality integration. Evaluated on the WeedsGalore dataset, the model achieves a segmentation accuracy (mean IoU) of 78.88%, outperforming RGB-only models by 15.8 percentage points. With only 8.7 million parameters, the model offers high accuracy, computational efficiency, and potential for real-time deployment on Unmanned Aerial Vehicles (UAVs) and edge devices, advancing precision weed management.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 8.2%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.1%">
                            Computer Vision
                        </span>
                <!-- LLMs: 3.0 -->
                    
                <!-- Hardware: 2.2 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Blockchain: 2.1 -->
                    
                <!-- HPO and AutoML: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- T2I: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.5211
                </span>
                <a href="https://arxiv.org/abs/2505.14311" target="_blank" rel="noopener noreferrer">HausaNLP: Current Status, Challenges and Future Directions for Hausa Natural Language Processing</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Shamsuddeen Hassan Muhammad, Ibrahim Said Ahmad, Idris Abdulmumin, Falalu Ibrahim Lawan, Babangida Sani, Sukairaj Hafiz Imam, Yusuf Aliyu, Sani Abdullahi Sani, Ali Usman Umar, Tajuddeen Gwadabe, Kenneth Church, Vukosi Marivate
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Hausa Natural Language Processing (NLP) has gained increasing attention in recent years, yet remains understudied as a low-resource language despite having over 120 million first-language (L1) and 80 million second-language (L2) speakers worldwide. While significant advances have been made in high-r</span>
                
                <span class="abstract-full" style="display: none;">Hausa Natural Language Processing (NLP) has gained increasing attention in recent years, yet remains understudied as a low-resource language despite having over 120 million first-language (L1) and 80 million second-language (L2) speakers worldwide. While significant advances have been made in high-resource languages, Hausa NLP faces persistent challenges, including limited open-source datasets and inadequate model representation. This paper presents an overview of the current state of Hausa NLP, systematically examining existing resources, research contributions, and gaps across fundamental NLP tasks: text classification, machine translation, named entity recognition, speech recognition, and question answering. We introduce HausaNLP (https://catalog.hausanlp.org), a curated catalog that aggregates datasets, tools, and research works to enhance accessibility and drive further development. Furthermore, we discuss challenges in integrating Hausa into large language models (LLMs), addressing issues of suboptimal tokenization and dialectal variation. Finally, we propose strategic research directions emphasizing dataset expansion, improved language modeling approaches, and strengthened community collaboration to advance Hausa NLP. Our work provides both a foundation for accelerating Hausa NLP progress and valuable insights for broader multilingual NLP research.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 18.9%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.0%">
                            Medicine
                        </span>
                <!-- Datasets: 2.5 -->
                    
                <!-- Hardware: 2.4 -->
                    
                <!-- Computer Vision: 1.9 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.523
                </span>
                <a href="https://arxiv.org/abs/2207.13560" target="_blank" rel="noopener noreferrer">D3C2-Net: Dual-Domain Deep Convolutional Coding Network for Compressive Sensing</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Weiqi Li, Bin Chen, Shuai Liu, Shijie Zhao, Bowen Du, Yongbing Zhang, Jian Zhang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">By mapping iterative optimization algorithms into neural networks (NNs), deep unfolding networks (DUNs) exhibit well-defined and interpretable structures and achieve remarkable success in the field of compressive sensing (CS). However, most existing DUNs solely rely on the image-domain unfolding, wh</span>
                
                <span class="abstract-full" style="display: none;">By mapping iterative optimization algorithms into neural networks (NNs), deep unfolding networks (DUNs) exhibit well-defined and interpretable structures and achieve remarkable success in the field of compressive sensing (CS). However, most existing DUNs solely rely on the image-domain unfolding, which restricts the information transmission capacity and reconstruction flexibility, leading to their loss of image details and unsatisfactory performance. To overcome these limitations, this paper develops a dual-domain optimization framework that combines the priors of (1) image- and (2) convolutional-coding-domains and offers generality to CS and other inverse imaging tasks. By converting this optimization framework into deep NN structures, we present a Dual-Domain Deep Convolutional Coding Network (D3C2-Net), which enjoys the ability to efficiently transmit high-capacity self-adaptive convolutional features across all its unfolded stages. Our theoretical analyses and experiments on simulated and real captured data, covering 2D and 3D natural, medical, and scientific signals, demonstrate the effectiveness, practicality, superior performance, and generalization ability of our method over other competing approaches and its significant potential in achieving a balance among accuracy, complexity, and interpretability. Code is available at https://github.com/lwq20020127/D3C2-Net.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.6%">
                            Medicine
                        </span>
                <!-- LLMs: 4.9 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- Blockchain: 2.0 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.5487
                </span>
                <a href="https://arxiv.org/abs/2504.13794" target="_blank" rel="noopener noreferrer">Active Learning of Symbolic NetKAT Automata</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Mark Moeller, Tiago Ferreira, Thomas Lu, Nate Foster, Alexandra Silva
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">NetKAT is a domain-specific programming language and logic that has been successfully used to specify and verify the behavior of packet-switched networks. This paper develops techniques for automatically learning NetKAT models of unknown networks using active learning. Prior work has explored active</span>
                
                <span class="abstract-full" style="display: none;">NetKAT is a domain-specific programming language and logic that has been successfully used to specify and verify the behavior of packet-switched networks. This paper develops techniques for automatically learning NetKAT models of unknown networks using active learning. Prior work has explored active learning for a wide range of automata (e.g., deterministic, register, B\"uchi, timed etc.) and also developed applications, such as validating implementations of network protocols. We present algorithms for learning different types of NetKAT automata, including symbolic automata proposed in recent work. We prove the soundness of these algorithms, build a prototype implementation, and evaluate it on a standard benchmark. Our results highlight the applicability of symbolic NetKAT learning for realistic network configurations and topologies.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.2%">
                            Medicine
                        </span>
                <!-- LLMs: 4.2 -->
                    
                <!-- Evolutionary Algorithms: 3.5 -->
                    
                <!-- Federated Learning: 3.3 -->
                    
                <!-- Hardware: 2.7 -->
                    
                <!-- Quantum Computing: 2.3 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Datasets: 1.8 -->
                    
                <!-- Bayesian Optimization: 1.6 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- GNN: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.5752
                </span>
                <a href="https://arxiv.org/abs/2505.18110" target="_blank" rel="noopener noreferrer">Watch and Listen: Understanding Audio-Visual-Speech Moments with Multimodal LLM</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zinuo Li, Xian Zhang, Yongxin Guo, Mohammed Bennamoun, Farid Boussaid, Girish Dwivedi, Luqi Gong, Qiuhong Ke
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Humans naturally understand moments in a video by integrating visual and auditory cues. For example, localizing a scene in the video like "A scientist passionately speaks on wildlife conservation as dramatic orchestral music plays, with the audience nodding and applauding" requires simultaneous proc</span>
                
                <span class="abstract-full" style="display: none;">Humans naturally understand moments in a video by integrating visual and auditory cues. For example, localizing a scene in the video like "A scientist passionately speaks on wildlife conservation as dramatic orchestral music plays, with the audience nodding and applauding" requires simultaneous processing of visual, audio, and speech signals. However, existing models often struggle to effectively fuse and interpret audio information, limiting their capacity for comprehensive video temporal understanding. To address this, we present TriSense, a triple-modality large language model designed for holistic video temporal understanding through the integration of visual, audio, and speech modalities. Central to TriSense is a Query-Based Connector that adaptively reweights modality contributions based on the input query, enabling robust performance under modality dropout and allowing flexible combinations of available inputs. To support TriSense's multimodal capabilities, we introduce TriSense-2M, a high-quality dataset of over 2 million curated samples generated via an automated pipeline powered by fine-tuned LLMs. TriSense-2M includes long-form videos and diverse modality combinations, facilitating broad generalization. Extensive experiments across multiple benchmarks demonstrate the effectiveness of TriSense and its potential to advance multimodal video analysis. Code and dataset will be publicly released.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.9%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.1%">
                            Medicine
                        </span>
                <!-- Federated Learning: 2.3 -->
                    
                <!-- Datasets: 2.1 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.5892
                </span>
                <a href="https://arxiv.org/abs/2407.02495" target="_blank" rel="noopener noreferrer">Minds, Brains, AI</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jay Seitz
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In the last year or so and going back many decades there has been extensive claims by major computational scientists, engineers, and others that AGI, artificial general intelligence, is five or ten years away, but without a scintilla of scientific evidence, for a broad body of these claims. Computer</span>
                
                <span class="abstract-full" style="display: none;">In the last year or so and going back many decades there has been extensive claims by major computational scientists, engineers, and others that AGI, artificial general intelligence, is five or ten years away, but without a scintilla of scientific evidence, for a broad body of these claims. Computers will become conscious, have a theory of mind, think and reason, will become more intelligent than humans, and so on. But the claims are science fiction, not science. This article reviews evidence for the following three propositions using extensive body of scientific research and related sources from the cognitive and neurosciences, evolutionary evidence, linguistics, data science, comparative psychology, self-driving cars, robotics. and the learning sciences. (1) Do computing machines think or reason? (2) Are computing machines sentient or conscious? (3) Do computing machines have a theory of mind?</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.4%">
                            Medicine
                        </span>
                <!-- LLMs: 4.3 -->
                    
                <!-- Blockchain: 2.9 -->
                    
                <!-- Hardware: 2.3 -->
                    
                <!-- Quantum Computing: 2.2 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                <!-- 3D: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.6047
                </span>
                <a href="https://arxiv.org/abs/2505.17490" target="_blank" rel="noopener noreferrer">DTRT: Enhancing Human Intent Estimation and Role Allocation for Physical Human-Robot Collaboration</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Haotian Liu, Yuchuang Tong, Zhengtao Zhang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In physical Human-Robot Collaboration (pHRC), accurate human intent estimation and rational human-robot role allocation are crucial for safe and efficient assistance. Existing methods that rely on short-term motion data for intention estimation lack multi-step prediction capabilities, hindering thei</span>
                
                <span class="abstract-full" style="display: none;">In physical Human-Robot Collaboration (pHRC), accurate human intent estimation and rational human-robot role allocation are crucial for safe and efficient assistance. Existing methods that rely on short-term motion data for intention estimation lack multi-step prediction capabilities, hindering their ability to sense intent changes and adjust human-robot assignments autonomously, resulting in potential discrepancies. To address these issues, we propose a Dual Transformer-based Robot Trajectron (DTRT) featuring a hierarchical architecture, which harnesses human-guided motion and force data to rapidly capture human intent changes, enabling accurate trajectory predictions and dynamic robot behavior adjustments for effective collaboration. Specifically, human intent estimation in DTRT uses two Transformer-based Conditional Variational Autoencoders (CVAEs), incorporating robot motion data in obstacle-free case with human-guided trajectory and force for obstacle avoidance. Additionally, Differential Cooperative Game Theory (DCGT) is employed to synthesize predictions based on human-applied forces, ensuring robot behavior align with human intention. Compared to state-of-the-art (SOTA) methods, DTRT incorporates human dynamics into long-term prediction, providing an accurate understanding of intention and enabling rational role allocation, achieving robot autonomy and maneuverability. Experiments demonstrate DTRT's accurate intent estimation and superior collaboration performance.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.8%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.8%">
                            LLMs
                        </span>
                <!-- Computer Vision: 2.4 -->
                    
                <!-- HPO and AutoML: 2.3 -->
                    
                <!-- Decision Trees: 2.2 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- T2I: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.6211
                </span>
                <a href="https://arxiv.org/abs/2502.14359" target="_blank" rel="noopener noreferrer">Triangulating LLM Progress through Benchmarks, Games, and Cognitive Tests</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Filippo Moment\`e, Alessandro Suglia, Mario Giulianelli, Ambra Ferrari, Alexander Koller, Oliver Lemon, David Schlangen, Raquel Fern\'andez, Raffaella Bernardi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We examine three evaluation paradigms: standard benchmarks (e.g., MMLU and BBH), interactive games (e.g., Signalling Games or Taboo), and cognitive tests (e.g., for working memory or theory of mind). First, we investigate which of the former two-benchmarks or games-is most effective at discriminatin</span>
                
                <span class="abstract-full" style="display: none;">We examine three evaluation paradigms: standard benchmarks (e.g., MMLU and BBH), interactive games (e.g., Signalling Games or Taboo), and cognitive tests (e.g., for working memory or theory of mind). First, we investigate which of the former two-benchmarks or games-is most effective at discriminating LLMs of varying quality. Then, inspired by human cognitive assessments, we compile a suite of targeted tests that measure cognitive abilities deemed essential for effective language use, and we investigate their correlation with model performance in benchmarks and games. Our analyses reveal that interactive games are superior to standard benchmarks in discriminating models. Causal and logical reasoning correlate with both static and interactive tests, while differences emerge regarding core executive functions and social/emotional skills, which correlate more with games. We advocate for the development of new interactive benchmarks and targeted cognitive tasks inspired by assessing human abilities but designed specifically for LLMs.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 16.0%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.5%">
                            Medicine
                        </span>
                <!-- Hardware: 2.3 -->
                    
                <!-- Datasets: 1.9 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- 3D: 1.0 -->
                    
                <!-- T2I: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.6689
                </span>
                <a href="https://arxiv.org/abs/2505.17104" target="_blank" rel="noopener noreferrer">P2P: Automated Paper-to-Poster Generation and Fine-Grained Benchmark</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Tao Sun, Enhao Pan, Zhengkai Yang, Kaixin Sui, Jiajun Shi, Xianfu Cheng, Tongliang Li, Wenhao Huang, Ge Zhang, Jian Yang, Zhoujun Li
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Academic posters are vital for scholarly communication, yet their manual creation is time-consuming. However, automated academic poster generation faces significant challenges in preserving intricate scientific details and achieving effective visual-textual integration. Existing approaches often str</span>
                
                <span class="abstract-full" style="display: none;">Academic posters are vital for scholarly communication, yet their manual creation is time-consuming. However, automated academic poster generation faces significant challenges in preserving intricate scientific details and achieving effective visual-textual integration. Existing approaches often struggle with semantic richness and structural nuances, and lack standardized benchmarks for evaluating generated academic posters comprehensively. To address these limitations, we introduce P2P, the first flexible, LLM-based multi-agent framework that generates high-quality, HTML-rendered academic posters directly from research papers, demonstrating strong potential for practical applications. P2P employs three specialized agents-for visual element processing, content generation, and final poster assembly-each integrated with dedicated checker modules to enable iterative refinement and ensure output quality. To foster advancements and rigorous evaluation in this domain, we construct and release P2PInstruct, the first large-scale instruction dataset comprising over 30,000 high-quality examples tailored for the academic paper-to-poster generation task. Furthermore, we establish P2PEval, a comprehensive benchmark featuring 121 paper-poster pairs and a dual evaluation methodology (Universal and Fine-Grained) that leverages LLM-as-a-Judge and detailed, human-annotated checklists. Our contributions aim to streamline research dissemination and provide the community with robust tools for developing and evaluating next-generation poster generation systems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.6%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.5%">
                            Medicine
                        </span>
                <!-- Computer Vision: 3.3 -->
                    
                <!-- Datasets: 2.4 -->
                    
                <!-- Blockchain: 2.1 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- 3D: 1.8 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- T2I: 1.6 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.676
                </span>
                <a href="https://arxiv.org/abs/2505.17763" target="_blank" rel="noopener noreferrer">Unsupervised Clustering for Fault Analysis in High-Voltage Power Systems Using Voltage and Current Signals</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Julian Oelhaf, Georg Kordowich, Andreas Maier, Johann Jager, Siming Bayer
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The widespread use of sensors in modern power grids has led to the accumulation of large amounts of voltage and current waveform data, especially during fault events. However, the lack of labeled datasets poses a significant challenge for fault classification and analysis. This paper explores the ap</span>
                
                <span class="abstract-full" style="display: none;">The widespread use of sensors in modern power grids has led to the accumulation of large amounts of voltage and current waveform data, especially during fault events. However, the lack of labeled datasets poses a significant challenge for fault classification and analysis. This paper explores the application of unsupervised clustering techniques for fault diagnosis in high-voltage power systems. A dataset provided by the Reseau de Transport d'Electricite (RTE) is analyzed, with frequency domain features extracted using the Fast Fourier Transform (FFT). The K-Means algorithm is then applied to identify underlying patterns in the data, enabling automated fault categorization without the need for labeled training samples. The resulting clusters are evaluated in collaboration with power system experts to assess their alignment with real-world fault characteristics. The results demonstrate the potential of unsupervised learning for scalable and data-driven fault analysis, providing a robust approach to detecting and classifying power system faults with minimal prior assumptions.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.3%">
                            Medicine
                        </span>
                <!-- LLMs: 2.3 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Blockchain: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                <!-- Networks: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Math: 1.1 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.7126
                </span>
                <a href="https://arxiv.org/abs/2505.18012" target="_blank" rel="noopener noreferrer">Classification of assembly tasks combining multiple primitive actions using Transformers and xLSTMs</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Miguel Neves, Pedro Neto
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The classification of human-performed assembly tasks is essential in collaborative robotics to ensure safety, anticipate robot actions, and facilitate robot learning. However, achieving reliable classification is challenging when segmenting tasks into smaller primitive actions is unfeasible, requiri</span>
                
                <span class="abstract-full" style="display: none;">The classification of human-performed assembly tasks is essential in collaborative robotics to ensure safety, anticipate robot actions, and facilitate robot learning. However, achieving reliable classification is challenging when segmenting tasks into smaller primitive actions is unfeasible, requiring us to classify long assembly tasks that encompass multiple primitive actions. In this study, we propose classifying long assembly sequential tasks based on hand landmark coordinates and compare the performance of two well-established classifiers, LSTM and Transformer, as well as a recent model, xLSTM. We used the HRC scenario proposed in the CT benchmark, which includes long assembly tasks that combine actions such as insertions, screw fastenings, and snap fittings. Testing was conducted using sequences gathered from both the human operator who performed the training sequences and three new operators. The testing results of real-padded sequences for the LSTM, Transformer, and xLSTM models was 72.9%, 95.0% and 93.2% for the training operator, and 43.5%, 54.3% and 60.8% for the new operators, respectively. The LSTM model clearly underperformed compared to the other two approaches. As expected, both the Transformer and xLSTM achieved satisfactory results for the operator they were trained on, though the xLSTM model demonstrated better generalization capabilities to new operators. The results clearly show that for this type of classification, the xLSTM model offers a slight edge over Transformers.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.9%">
                            Medicine
                        </span>
                <!-- LLMs: 2.4 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- Hardware: 2.3 -->
                    
                <!-- Federated Learning: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.7485
                </span>
                <a href="https://arxiv.org/abs/2505.17059" target="_blank" rel="noopener noreferrer">Medalyze: Lightweight Medical Report Summarization Application Using FLAN-T5-Large</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Van-Tinh Nguyen, Hoang-Duong Pham, Thanh-Hai To, Cong-Tuan Hung Do, Thi-Thu-Trang Dong, Vu-Trung Duong Le, Van-Phuc Hoang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Understanding medical texts presents significant challenges due to complex terminology and context-specific language. This paper introduces Medalyze, an AI-powered application designed to enhance the comprehension of medical texts using three specialized FLAN-T5-Large models. These models are fine-t</span>
                
                <span class="abstract-full" style="display: none;">Understanding medical texts presents significant challenges due to complex terminology and context-specific language. This paper introduces Medalyze, an AI-powered application designed to enhance the comprehension of medical texts using three specialized FLAN-T5-Large models. These models are fine-tuned for (1) summarizing medical reports, (2) extracting health issues from patient-doctor conversations, and (3) identifying the key question in a passage. Medalyze is deployed across a web and mobile platform with real-time inference, leveraging scalable API and YugabyteDB. Experimental evaluations demonstrate the system's superior summarization performance over GPT-4 in domain-specific tasks, based on metrics like BLEU, ROUGE-L, BERTScore, and SpaCy Similarity. Medalyze provides a practical, privacy-preserving, and lightweight solution for improving information accessibility in healthcare.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.4%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.0%">
                            LLMs
                        </span>
                <!-- Computer Vision: 2.6 -->
                    
                <!-- Blockchain: 2.0 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.7638
                </span>
                <a href="https://arxiv.org/abs/2505.17483" target="_blank" rel="noopener noreferrer">Hyperspectral in situ remote sensing of water surface nitrate in the Fitzroy River estuary, Queensland, Australia, using deep learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yiqing Guo, Nagur Cherukuru, Eric Lehmann, S. L. Kesav Unnithan, Gemma Kerrisk, Tim Malthus, Faisal Islam
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Nitrate ($\text{NO}_3^-$) is a form of dissolved inorganic nitrogen derived primarily from anthropogenic sources. The recent increase in river-discharged nitrate poses a major risk for coral bleaching in the Great Barrier Reef (GBR) lagoon. Although nitrate is an optically inactive (i.e., colourless</span>
                
                <span class="abstract-full" style="display: none;">Nitrate ($\text{NO}_3^-$) is a form of dissolved inorganic nitrogen derived primarily from anthropogenic sources. The recent increase in river-discharged nitrate poses a major risk for coral bleaching in the Great Barrier Reef (GBR) lagoon. Although nitrate is an optically inactive (i.e., colourless) constituent, previous studies have demonstrated there is an indirect, non-causal relationship between water surface nitrate and water-leaving reflectance that is mediated through optically active water quality parameters such as total suspended solids and coloured dissolved organic matter. This work aims to advance our understanding of this relationship with an effort to measure time-series nitrate and simultaneous hyperspectral reflectance at the Fitzroy River estuary, Queensland, Australia. Time-series observations revealed periodic cycles in nitrate loads due to the tidal influence in the estuarine study site. The water surface nitrate loads were predicted from hyperspectral reflectance and water salinity measurements, with hyperspectral reflectance indicating the concentrations of optically active variables and salinity indicating the mixing of river water and seawater proportions. The accuracy assessment of model-predicted nitrate against in-situ measured nitrate values showed that the predicted nitrate values correlated well with the ground-truth data, with an $R^2$ score of 0.86, and an RMSE of 0.03 mg/L. This work demonstrates the feasibility of predicting water surface nitrate from hyperspectral reflectance and salinity measurements.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.6%">
                            Medicine
                        </span>
                <!-- LLMs: 3.9 -->
                    
                <!-- Blockchain: 2.0 -->
                    
                <!-- Datasets: 1.9 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Federated Learning: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.7947
                </span>
                <a href="https://arxiv.org/abs/2505.17863" target="_blank" rel="noopener noreferrer">The emergence of sparse attention: impact of data distribution and benefits of repetition</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Nicolas Zucchet, Francesco d'Angelo, Andrew K. Lampinen, Stephanie C. Y. Chan
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Emergence is a fascinating property of large language models and neural networks more broadly: as models scale and train for longer, they sometimes develop new abilities in sudden ways. Despite initial studies, we still lack a comprehensive understanding of how and when these abilities emerge. To ad</span>
                
                <span class="abstract-full" style="display: none;">Emergence is a fascinating property of large language models and neural networks more broadly: as models scale and train for longer, they sometimes develop new abilities in sudden ways. Despite initial studies, we still lack a comprehensive understanding of how and when these abilities emerge. To address this gap, we study the emergence over training of sparse attention, a critical and frequently observed attention pattern in Transformers. By combining theoretical analysis of a toy model with empirical observations on small Transformers trained on a linear regression variant, we uncover the mechanics driving sparse attention emergence and reveal that emergence timing follows power laws based on task structure, architecture, and optimizer choice. We additionally find that repetition can greatly speed up emergence. Finally, we confirm these results on a well-studied in-context associative recall task. Our findings provide a simple, theoretically grounded framework for understanding how data distributions and model design influence the learning dynamics behind one form of emergence.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 9.5%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.9%">
                            Medicine
                        </span>
                <!-- Datasets: 2.3 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                <!-- 3D: 1.0 -->
                    
                <!-- Computer Vision: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.8125
                </span>
                <a href="https://arxiv.org/abs/2505.09473" target="_blank" rel="noopener noreferrer">Function-Correcting $b$-symbol Codes for Locally $(\lambda, \rho,b)$-Functions</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Gyanendra K. Verma, Anamika Singh, Abhay Kumar Singh
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The family of functions plays a central role in the design and effectiveness of function-correcting codes. By focusing on a well-defined family of functions, function-correcting codes can be constructed with minimal length while still ensuring full error detection or correction within that family. I</span>
                
                <span class="abstract-full" style="display: none;">The family of functions plays a central role in the design and effectiveness of function-correcting codes. By focusing on a well-defined family of functions, function-correcting codes can be constructed with minimal length while still ensuring full error detection or correction within that family. In this work, we explore the concept of locally $(\lambda,\rho)$-functions for $b$-symbol read channels and investigate the redundancy of the corresponding function-correcting $b$-symbol codes(FCBSC) by introducing the notions of locally $(\lambda,\rho,b)$-functions. First, we discuss the possible values of $\lambda$ and $\rho$ for which any function can be considered as locally $(\lambda,\rho)$-function in $b$-symbol metric. The findings improve some known results in the Hamming metric and present several new results in the $b$-symbol metric. Then we investigate the redundancy of $(f,t)$-FCBSC for locally $(\lambda,\rho,b)$-functions. We establish a recurrence relation between the optimal redundancy of $(f,t)$ -function-correcting codes for the $(b+1)$-read and $b$-read channels. We establish an upper bound on the redundancy of $(f,t)$-function-correcting $b$-symbol codes for general locally ($\lambda,\rho$, $b$)-functions by linking it to the minimum achievable length of $b$-symbol error-correcting codes and traditional Hamming-metric codes, given a fixed number of codewords and a specified minimum distance. We derive some explicit upper bounds on the redundancy of $(f,t)$-function-correcting $b$-symbol codes for $\rho=2t$. Moreover, for the case where $b=1$, we show that a locally ($3,2t,1$)-function achieves the optimal redundancy of $3t$. Additionally, we explicitly investigate locality and redundancy for the $b$-symbol weight distribution function for $b\geq1$.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.2%">
                            Medicine
                        </span>
                <!-- Federated Learning: 2.9 -->
                    
                <!-- Hardware: 2.7 -->
                    
                <!-- Bayesian Optimization: 2.4 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- Math: 1.9 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- LLMs: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.813
                </span>
                <a href="https://arxiv.org/abs/2505.17125" target="_blank" rel="noopener noreferrer">NEXT-EVAL: Next Evaluation of Traditional and LLM Web Data Record Extraction</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Soyeon Kim, Namhee Kim, Yeonwoo Jeong
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Effective evaluation of web data record extraction methods is crucial, yet hampered by static, domain-specific benchmarks and opaque scoring practices. This makes fair comparison between traditional algorithmic techniques, which rely on structural heuristics, and Large Language Model (LLM)-based app</span>
                
                <span class="abstract-full" style="display: none;">Effective evaluation of web data record extraction methods is crucial, yet hampered by static, domain-specific benchmarks and opaque scoring practices. This makes fair comparison between traditional algorithmic techniques, which rely on structural heuristics, and Large Language Model (LLM)-based approaches, offering zero-shot extraction across diverse layouts, particularly challenging. To overcome these limitations, we introduce a concrete evaluation framework. Our framework systematically generates evaluation datasets from arbitrary MHTML snapshots, annotates XPath-based supervision labels, and employs structure-aware metrics for consistent scoring, specifically preventing text hallucination and allowing only for the assessment of positional hallucination. It also incorporates preprocessing strategies to optimize input for LLMs while preserving DOM semantics: HTML slimming, Hierarchical JSON, and Flat JSON. Additionally, we created a publicly available synthetic dataset by transforming DOM structures and modifying content. We benchmark deterministic heuristic algorithms and off-the-shelf LLMs across these multiple input formats. Our benchmarking shows that Flat JSON input enables LLMs to achieve superior extraction accuracy (F1 score of 0.9567) and minimal hallucination compared to other input formats like Slimmed HTML and Hierarchical JSON. We establish a standardized foundation for rigorous benchmarking, paving the way for the next principled advancements in web data record extraction.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 11.7%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.5%">
                            Medicine
                        </span>
                <!-- Computer Vision: 2.2 -->
                    
                <!-- Datasets: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Federated Learning: 1.6 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- GNN: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.8207
                </span>
                <a href="https://arxiv.org/abs/2504.16559" target="_blank" rel="noopener noreferrer">Synergistic Benefits of Joint Molecule Generation and Property Prediction</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Adam Izdebski, Jan Olszewski, Pankhil Gawade, Krzysztof Koras, Serra Korkmaz, Valentin Rauscher, Jakub M. Tomczak, Ewa Szczurek
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Modeling the joint distribution of data samples and their properties allows to construct a single model for both data generation and property prediction, with synergistic benefits reaching beyond purely generative or predictive models. However, training joint models presents daunting architectural a</span>
                
                <span class="abstract-full" style="display: none;">Modeling the joint distribution of data samples and their properties allows to construct a single model for both data generation and property prediction, with synergistic benefits reaching beyond purely generative or predictive models. However, training joint models presents daunting architectural and optimization challenges. Here, we propose Hyformer, a transformer-based joint model that successfully blends the generative and predictive functionalities, using an alternating attention mechanism and a joint pre-training scheme. We show that Hyformer is simultaneously optimized for molecule generation and property prediction, while exhibiting synergistic benefits in conditional sampling, out-of-distribution property prediction and representation learning. Finally, we demonstrate the benefits of joint learning in a drug design use case of discovering novel antimicrobial~peptides.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 8.3%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.3%">
                            LLMs
                        </span>
                <!-- Hardware: 1.9 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- T2I: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.8279
                </span>
                <a href="https://arxiv.org/abs/2505.17660" target="_blank" rel="noopener noreferrer">DAM-GT: Dual Positional Encoding-Based Attention Masking Graph Transformer for Node Classification</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Chenyang Li, Jinsong Chen, John E. Hopcroft, Kun He
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Neighborhood-aware tokenized graph Transformers have recently shown great potential for node classification tasks. Despite their effectiveness, our in-depth analysis of neighborhood tokens reveals two critical limitations in the existing paradigm. First, current neighborhood token generation methods</span>
                
                <span class="abstract-full" style="display: none;">Neighborhood-aware tokenized graph Transformers have recently shown great potential for node classification tasks. Despite their effectiveness, our in-depth analysis of neighborhood tokens reveals two critical limitations in the existing paradigm. First, current neighborhood token generation methods fail to adequately capture attribute correlations within a neighborhood. Second, the conventional self-attention mechanism suffers from attention diversion when processing neighborhood tokens, where high-hop neighborhoods receive disproportionate focus, severely disrupting information interactions between the target node and its neighborhood tokens. To address these challenges, we propose DAM-GT, Dual positional encoding-based Attention Masking graph Transformer. DAM-GT introduces a novel dual positional encoding scheme that incorporates attribute-aware encoding via an attribute clustering strategy, effectively preserving node correlations in both topological and attribute spaces. In addition, DAM-GT formulates a new attention mechanism with a simple yet effective masking strategy to guide interactions between target nodes and their neighborhood tokens, overcoming the issue of attention diversion. Extensive experiments on various graphs with different homophily levels as well as different scales demonstrate that DAM-GT consistently outperforms state-of-the-art methods in node classification tasks.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #b243cd" title="Confidence: 5.8%">
                            GNN
                        </span>
                <!-- LLMs: 4.4 -->
                    
                <!-- Medicine: 2.5 -->
                    
                <!-- Quantum Computing: 2.4 -->
                    
                <!-- Computer Vision: 2.1 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- T2I: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.8408
                </span>
                <a href="https://arxiv.org/abs/2411.06232" target="_blank" rel="noopener noreferrer">RCR: Robust Crowd Reconstruction with Upright Space from a Single Large-scene Image</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jing Huang, Hao Wen, Tianyi Zhou, Haozhe Lin, Yu-kun Lai, Kun Li
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper focuses on spatially consistent hundreds of human pose and shape reconstruction from a single large-scene image with various human scales under arbitrary camera FoVs (Fields of View). Due to the small and highly varying 2D human scales, depth ambiguity, and perspective distortion, no exis</span>
                
                <span class="abstract-full" style="display: none;">This paper focuses on spatially consistent hundreds of human pose and shape reconstruction from a single large-scene image with various human scales under arbitrary camera FoVs (Fields of View). Due to the small and highly varying 2D human scales, depth ambiguity, and perspective distortion, no existing methods can achieve globally consistent reconstruction with correct reprojection. To address these challenges, we first propose a new concept, Human-scene Virtual Interaction Point (HVIP), to convert the complex 3D human localization into 2D-pixel localization. We then extend it to RCR (Robust Crowd Reconstruction), which achieves globally consistent reconstruction and stable generalization on different camera FoVs without test-time optimization. To perceive humans in varying pixel sizes, we propose an Iterative Ground-aware Cropping to automatically crop the image and then merge the results. To eliminate the influence of the camera and cropping process during the reconstruction, we introduce a canonical Upright 3D Space and the corresponding Upright 2D Space. To link the canonical space and the camera space, we propose the Upright Normalization, which transforms the local crop input into the Upright 2D Space, and transforms the output from the Upright 3D Space into the unified camera space. Besides, we contribute two benchmark datasets, LargeCrowd and SynCrowd, for evaluating crowd reconstruction in large scenes. Experimental results demonstrate the effectiveness of the proposed method. The source code and data will be publicly available for research purposes.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.1%">
                            Medicine
                        </span>
                <!-- Computer Vision: 2.9 -->
                    
                <!-- Federated Learning: 2.5 -->
                    
                <!-- Reinforcement Learning: 2.2 -->
                    
                <!-- 3D: 2.0 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- LLMs: 1.4 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.89
                </span>
                <a href="https://arxiv.org/abs/2505.18006" target="_blank" rel="noopener noreferrer">AI Literacy for Legal AI Systems: A practical approach</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Gizem Gultekin-Varkonyi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Legal AI systems are increasingly being adopted by judicial and legal system deployers and providers worldwide to support a range of applications. While they offer potential benefits such as reducing bias, increasing efficiency, and improving accountability, they also pose significant risks, requiri</span>
                
                <span class="abstract-full" style="display: none;">Legal AI systems are increasingly being adopted by judicial and legal system deployers and providers worldwide to support a range of applications. While they offer potential benefits such as reducing bias, increasing efficiency, and improving accountability, they also pose significant risks, requiring a careful balance between opportunities, and legal and ethical development and deployment. AI literacy, as a legal requirement under the EU AI Act and a critical enabler of ethical AI for deployers and providers, could be a tool to achieve this. The article introduces the term "legal AI systems" and then analyzes the concept of AI literacy and the benefits and risks associated with these systems. This analysis is linked to a broader AI-L concept for organizations that deal with legal AI systems. The outcome of the article, a roadmap questionnaire as a practical tool for developers and providers to assess risks, benefits, and stakeholder concerns, could be useful in meeting societal and regulatory expectations for legal AI.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.9%">
                            Medicine
                        </span>
                <!-- LLMs: 3.6 -->
                    
                <!-- Blockchain: 3.3 -->
                    
                <!-- Hardware: 3.2 -->
                    
                <!-- Datasets: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                <!-- Quantum Computing: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.9878
                </span>
                <a href="https://arxiv.org/abs/2505.17613" target="_blank" rel="noopener noreferrer">MMMG: a Comprehensive and Reliable Evaluation Suite for Multitask Multimodal Generation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jihan Yao, Yushi Hu, Yujie Yi, Bin Han, Shangbin Feng, Guang Yang, Bingbing Wen, Ranjay Krishna, Lucy Lu Wang, Yulia Tsvetkov, Noah A. Smith, Banghua Zhu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Automatically evaluating multimodal generation presents a significant challenge, as automated metrics often struggle to align reliably with human evaluation, especially for complex tasks that involve multiple modalities. To address this, we present MMMG, a comprehensive and human-aligned benchmark f</span>
                
                <span class="abstract-full" style="display: none;">Automatically evaluating multimodal generation presents a significant challenge, as automated metrics often struggle to align reliably with human evaluation, especially for complex tasks that involve multiple modalities. To address this, we present MMMG, a comprehensive and human-aligned benchmark for multimodal generation across 4 modality combinations (image, audio, interleaved text and image, interleaved text and audio), with a focus on tasks that present significant challenges for generation models, while still enabling reliable automatic evaluation through a combination of models and programs. MMMG encompasses 49 tasks (including 29 newly developed ones), each with a carefully designed evaluation pipeline, and 937 instructions to systematically assess reasoning, controllability, and other key capabilities of multimodal generation models. Extensive validation demonstrates that MMMG is highly aligned with human evaluation, achieving an average agreement of 94.3%. Benchmarking results on 24 multimodal generation models reveal that even though the state-of-the-art model, GPT Image, achieves 78.3% accuracy for image generation, it falls short on multimodal reasoning and interleaved generation. Furthermore, results suggest considerable headroom for improvement in audio generation, highlighting an important direction for future research.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 9.0%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.3%">
                            LLMs
                        </span>
                <!-- Datasets: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- 3D: 1.9 -->
                    
                <!-- T2I: 1.8 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.0369
                </span>
                <a href="https://arxiv.org/abs/2505.09755" target="_blank" rel="noopener noreferrer">Explainability Through Human-Centric Design for XAI in Lung Cancer Detection</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Amy Rafferty, Rishi Ramaesh, Ajitha Rajan
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Deep learning models have shown promise in lung pathology detection from chest X-rays, but widespread clinical adoption remains limited due to opaque model decision-making. In prior work, we introduced ClinicXAI, a human-centric, expert-guided concept bottleneck model (CBM) designed for interpretabl</span>
                
                <span class="abstract-full" style="display: none;">Deep learning models have shown promise in lung pathology detection from chest X-rays, but widespread clinical adoption remains limited due to opaque model decision-making. In prior work, we introduced ClinicXAI, a human-centric, expert-guided concept bottleneck model (CBM) designed for interpretable lung cancer diagnosis. We now extend that approach and present XpertXAI, a generalizable expert-driven model that preserves human-interpretable clinical concepts while scaling to detect multiple lung pathologies. Using a high-performing InceptionV3-based classifier and a public dataset of chest X-rays with radiology reports, we compare XpertXAI against leading post-hoc explainability methods and an unsupervised CBM, XCBs. We assess explanations through comparison with expert radiologist annotations and medical ground truth. Although XpertXAI is trained for multiple pathologies, our expert validation focuses on lung cancer. We find that existing techniques frequently fail to produce clinically meaningful explanations, omitting key diagnostic features and disagreeing with radiologist judgments. XpertXAI not only outperforms these baselines in predictive accuracy but also delivers concept-level explanations that better align with expert reasoning. While our focus remains on explainability in lung cancer detection, this work illustrates how human-centric model design can be effectively extended to broader diagnostic contexts - offering a scalable path toward clinically meaningful explainable AI in medical diagnostics.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 8.6%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.0%">
                            LLMs
                        </span>
                <!-- Computer Vision: 2.8 -->
                    
                <!-- GNN: 2.5 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Decision Trees: 1.8 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Federated Learning: 1.6 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.0631
                </span>
                <a href="https://arxiv.org/abs/2505.17702" target="_blank" rel="noopener noreferrer">Seek-CAD: A Self-refined Generative Modeling for 3D Parametric CAD Using Local Inference via DeepSeek</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Xueyang Li, Jiahao Li, Yu Song, Yunzhong Lou, Xiangdong Zhou
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The advent of Computer-Aided Design (CAD) generative modeling will significantly transform the design of industrial products. The recent research endeavor has extended into the realm of Large Language Models (LLMs). In contrast to fine-tuning methods, training-free approaches typically utilize the a</span>
                
                <span class="abstract-full" style="display: none;">The advent of Computer-Aided Design (CAD) generative modeling will significantly transform the design of industrial products. The recent research endeavor has extended into the realm of Large Language Models (LLMs). In contrast to fine-tuning methods, training-free approaches typically utilize the advanced closed-source LLMs, thereby offering enhanced flexibility and efficiency in the development of AI agents for generating CAD parametric models. However, the substantial cost and limitations of local deployment of the top-tier closed-source LLMs pose challenges in practical applications. The Seek-CAD is the pioneer exploration of locally deployed open-source inference LLM DeepSeek-R1 for CAD parametric model generation with a training-free methodology. This study is the first investigation to incorporate both visual and Chain-of-Thought (CoT) feedback within the self-refinement mechanism for generating CAD models. Specifically, the initial generated parametric CAD model is rendered into a sequence of step-wise perspective images, which are subsequently processed by a Vision Language Model (VLM) alongside the corresponding CoTs derived from DeepSeek-R1 to assess the CAD model generation. Then, the feedback is utilized by DeepSeek-R1 to refine the initial generated model for the next round of generation. Moreover, we present an innovative 3D CAD model dataset structured around the SSR (Sketch, Sketch-based feature, and Refinements) triple design paradigm. This dataset encompasses a wide range of CAD commands, thereby aligning effectively with industrial application requirements and proving suitable for the generation of LLMs. Extensive experiments validate the effectiveness of Seek-CAD under various metrics.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.6%">
                            Medicine
                        </span>
                <!-- LLMs: 3.7 -->
                    
                <!-- Federated Learning: 3.4 -->
                    
                <!-- Hardware: 2.5 -->
                    
                <!-- Bayesian Optimization: 2.3 -->
                    
                <!-- Evolutionary Algorithms: 2.2 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Computer Vision: 1.2 -->
                    
                <!-- Quantum Computing: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.0739
                </span>
                <a href="https://arxiv.org/abs/2505.17893" target="_blank" rel="noopener noreferrer">Pixels to Prognosis: Harmonized Multi-Region CT-Radiomics and Foundation-Model Signatures Across Multicentre NSCLC Data</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Shruti Atul Mali, Zohaib Salahuddin, Danial Khan, Yumeng Zhang, Henry C. Woodruff, Eduardo Ibor-Crespo, Ana Jimenez-Pastor, Luis Marti-Bonmati, Philippe Lambin
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Purpose: To evaluate the impact of harmonization and multi-region CT image feature integration on survival prediction in non-small cell lung cancer (NSCLC) patients, using handcrafted radiomics, pretrained foundation model (FM) features, and clinical data from a multicenter dataset.</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 8.8%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.4%">
                            LLMs
                        </span>
                <!-- Blockchain: 3.0 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Decision Trees: 1.9 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- 3D: 1.8 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Datasets: 1.4 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.0985
                </span>
                <a href="https://arxiv.org/abs/2505.17395" target="_blank" rel="noopener noreferrer">Wildfire Detection Using Vision Transformer with the Wildfire Dataset</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Gowtham Raj Vuppari, Navarun Gupta, Ahmed El-Sayed, Xingguo Xiong
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The critical need for sophisticated detection techniques has been highlighted by the rising frequency and intensity of wildfires in the US, especially in California. In 2023, wildfires caused 130 deaths nationwide, the highest since 1990. In January 2025, Los Angeles wildfires which included the Pal</span>
                
                <span class="abstract-full" style="display: none;">The critical need for sophisticated detection techniques has been highlighted by the rising frequency and intensity of wildfires in the US, especially in California. In 2023, wildfires caused 130 deaths nationwide, the highest since 1990. In January 2025, Los Angeles wildfires which included the Palisades and Eaton fires burnt approximately 40,000 acres and 12,000 buildings, and caused loss of human lives. The devastation underscores the urgent need for effective detection and prevention strategies. Deep learning models, such as Vision Transformers (ViTs), can enhance early detection by processing complex image data with high accuracy. However, wildfire detection faces challenges, including the availability of high-quality, real-time data. Wildfires often occur in remote areas with limited sensor coverage, and environmental factors like smoke and cloud cover can hinder detection. Additionally, training deep learning models is computationally expensive, and issues like false positives/negatives and scaling remain concerns. Integrating detection systems with real-time alert mechanisms also poses difficulties. In this work, we used the wildfire dataset consisting of 10.74 GB high-resolution images categorized into 'fire' and 'nofire' classes is used for training the ViT model. To prepare the data, images are resized to 224 x 224 pixels, converted into tensor format, and normalized using ImageNet statistics.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 9.1%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.9%">
                            Computer Vision
                        </span>
                <!-- LLMs: 3.3 -->
                    
                <!-- Hardware: 2.4 -->
                    
                <!-- Datasets: 2.2 -->
                    
                <!-- Blockchain: 2.0 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.1616
                </span>
                <a href="https://arxiv.org/abs/2505.17929" target="_blank" rel="noopener noreferrer">Predicting Length of Stay in Neurological ICU Patients Using Classical Machine Learning and Neural Network Models: A Benchmark Study on MIMIC-IV</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Alexander Gabitashvili, Philipp Kellmeyer
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Intensive care unit (ICU) is a crucial hospital department that handles life-threatening cases. Nowadays machine learning (ML) is being leveraged in healthcare ubiquitously. In recent years, management of ICU became one of the most significant parts of the hospital functionality (largely but not onl</span>
                
                <span class="abstract-full" style="display: none;">Intensive care unit (ICU) is a crucial hospital department that handles life-threatening cases. Nowadays machine learning (ML) is being leveraged in healthcare ubiquitously. In recent years, management of ICU became one of the most significant parts of the hospital functionality (largely but not only due to the worldwide COVID-19 pandemic). This study explores multiple ML approaches for predicting LOS in ICU specifically for the patients with neurological diseases based on the MIMIC-IV dataset. The evaluated models include classic ML algorithms (K-Nearest Neighbors, Random Forest, XGBoost and CatBoost) and Neural Networks (LSTM, BERT and Temporal Fusion Transformer). Given that LOS prediction is often framed as a classification task, this study categorizes LOS into three groups: less than two days, less than a week, and a week or more. As the first ML-based approach targeting LOS prediction for neurological disorder patients, this study does not aim to outperform existing methods but rather to assess their effectiveness in this specific context. The findings provide insights into the applicability of ML techniques for improving ICU resource management and patient care. According to the results, Random Forest model proved to outperform others on static, achieving an accuracy of 0.68, a precision of 0.68, a recall of 0.68, and F1-score of 0.67. While BERT model outperformed LSTM model on time-series data with an accuracy of 0.80, a precision of 0.80, a recall of 0.80 and F1-score 0.80.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.9%">
                            Medicine
                        </span>
                <!-- LLMs: 3.1 -->
                    
                <!-- Federated Learning: 3.1 -->
                    
                <!-- Evolutionary Algorithms: 2.4 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.2057
                </span>
                <a href="https://arxiv.org/abs/2502.11651" target="_blank" rel="noopener noreferrer">MMXU: A Multi-Modal and Multi-X-ray Understanding Dataset for Disease Progression</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Linjie Mu, Zhongzhen Huang, Shengqian Qin, Yakun Zhu, Shaoting Zhang, Xiaofan Zhang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Large vision-language models (LVLMs) have shown great promise in medical applications, particularly in visual question answering (MedVQA) and diagnosis from medical images. However, existing datasets and models often fail to consider critical aspects of medical diagnostics, such as the integration o</span>
                
                <span class="abstract-full" style="display: none;">Large vision-language models (LVLMs) have shown great promise in medical applications, particularly in visual question answering (MedVQA) and diagnosis from medical images. However, existing datasets and models often fail to consider critical aspects of medical diagnostics, such as the integration of historical records and the analysis of disease progression over time. In this paper, we introduce MMXU (Multimodal and MultiX-ray Understanding), a novel dataset for MedVQA that focuses on identifying changes in specific regions between two patient visits. Unlike previous datasets that primarily address single-image questions, MMXU enables multi-image questions, incorporating both current and historical patient data. We demonstrate the limitations of current LVLMs in identifying disease progression on MMXU-\textit{test}, even those that perform well on traditional benchmarks. To address this, we propose a MedRecord-Augmented Generation (MAG) approach, incorporating both global and regional historical records. Our experiments show that integrating historical records significantly enhances diagnostic accuracy by at least 20\%, bridging the gap between current LVLMs and human expert performance. Additionally, we fine-tune models with MAG on MMXU-\textit{dev}, which demonstrates notable improvements. We hope this work could illuminate the avenue of advancing the use of LVLMs in medical diagnostics by emphasizing the importance of historical context in interpreting medical images. Our dataset is released at github: https://github.com/linjiemu/MMXU.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.6%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.8%">
                            Medicine
                        </span>
                <!-- Blockchain: 2.3 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- Datasets: 2.2 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.2223
                </span>
                <a href="https://arxiv.org/abs/2501.05000" target="_blank" rel="noopener noreferrer">Load Forecasting for Households and Energy Communities: Are Deep Learning Models Worth the Effort?</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Lukas Moosbrugger, Valentin Seiler, Philipp Wohlgenannt, Sebastian Hegenbart, Sashko Ristov, Elias Eder, Peter Kepplinger
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Energy communities (ECs) play a key role in enabling local demand shifting and enhancing self-sufficiency, as energy systems transition toward decentralized structures with high shares of renewable generation. To optimally operate them, accurate short-term load forecasting is essential, particularly</span>
                
                <span class="abstract-full" style="display: none;">Energy communities (ECs) play a key role in enabling local demand shifting and enhancing self-sufficiency, as energy systems transition toward decentralized structures with high shares of renewable generation. To optimally operate them, accurate short-term load forecasting is essential, particularly for implementing demand-side management strategies. With the recent rise of deep learning methods, data-driven forecasting has gained significant attention, however, it remains insufficiently explored in many practical contexts. Therefore, this study evaluates the effectiveness of state-of-the-art deep learning models -- including LSTM, xLSTM, and Transformer architectures -- compared to traditional benchmarks such as K-Nearest Neighbors (KNN) and persistence forecasting, across varying community size, historical data availability, and model complexity. Additionally, we assess the benefits of transfer learning using publicly available synthetic load profiles. On average, transfer learning improves the normalized mean absolute error by 1.97%pt when only two months of training data are available. Interestingly, for less than six months of training data, simple persistence models outperform deep learning architectures in forecast accuracy. The practical value of improved forecasting is demonstrated using a mixed-integer linear programming optimization for ECs with a shared battery energy storage system. The most accurate deep learning model achieves an average reduction in financial energy costs of 8.06%. Notably, a simple KNN approach achieves average savings of 8.01%, making it a competitive and robust alternative. All implementations are publicly available to facilitate reproducibility. These findings offer actionable insights for ECs, and they highlight when the additional complexity of deep learning is warranted by performance gains.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 9.6%">
                            Medicine
                        </span>
                <!-- Federated Learning: 2.9 -->
                    
                <!-- LLMs: 2.6 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- Datasets: 2.1 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.4 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- GNN: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.232
                </span>
                <a href="https://arxiv.org/abs/2505.17666" target="_blank" rel="noopener noreferrer">Proto-FG3D: Prototype-based Interpretable Fine-Grained 3D Shape Classification</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Shuxian Ma, Zihao Dong, Runmin Cong, Sam Kwong, Xiuli Shao
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Deep learning-based multi-view coarse-grained 3D shape classification has achieved remarkable success over the past decade, leveraging the powerful feature learning capabilities of CNN-based and ViT-based backbones. However, as a challenging research area critical for detailed shape understanding, f</span>
                
                <span class="abstract-full" style="display: none;">Deep learning-based multi-view coarse-grained 3D shape classification has achieved remarkable success over the past decade, leveraging the powerful feature learning capabilities of CNN-based and ViT-based backbones. However, as a challenging research area critical for detailed shape understanding, fine-grained 3D classification remains understudied due to the limited discriminative information captured during multi-view feature aggregation, particularly for subtle inter-class variations, class imbalance, and inherent interpretability limitations of parametric model. To address these problems, we propose the first prototype-based framework named Proto-FG3D for fine-grained 3D shape classification, achieving a paradigm shift from parametric softmax to non-parametric prototype learning. Firstly, Proto-FG3D establishes joint multi-view and multi-category representation learning via Prototype Association. Secondly, prototypes are refined via Online Clustering, improving both the robustness of multi-view feature allocation and inter-subclass balance. Finally, prototype-guided supervised learning is established to enhance fine-grained discrimination via prototype-view correlation analysis and enables ad-hoc interpretability through transparent case-based reasoning. Experiments on FG3D and ModelNet40 show Proto-FG3D surpasses state-of-the-art methods in accuracy, transparent predictions, and ad-hoc interpretability with visualizations, challenging conventional fine-grained 3D recognition approaches.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 9.7%">
                            Medicine
                        </span>
                <!-- 3D: 4.5 -->
                    
                <!-- LLMs: 2.9 -->
                    
                <!-- Computer Vision: 2.7 -->
                    
                <!-- GNN: 2.2 -->
                    
                <!-- Hardware: 2.2 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Federated Learning: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.2348
                </span>
                <a href="https://arxiv.org/abs/2505.17818" target="_blank" rel="noopener noreferrer">PatientSim: A Persona-Driven Simulator for Realistic Doctor-Patient Interactions</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Daeun Kyung, Hyunseung Chung, Seongsu Bae, Jiho Kim, Jae Ho Sohn, Taerim Kim, Soo Kyung Kim, Edward Choi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Doctor-patient consultations require multi-turn, context-aware communication tailored to diverse patient personas. Training or evaluating doctor LLMs in such settings requires realistic patient interaction systems. However, existing simulators often fail to reflect the full range of personas seen in</span>
                
                <span class="abstract-full" style="display: none;">Doctor-patient consultations require multi-turn, context-aware communication tailored to diverse patient personas. Training or evaluating doctor LLMs in such settings requires realistic patient interaction systems. However, existing simulators often fail to reflect the full range of personas seen in clinical practice. To address this, we introduce PatientSim, a patient simulator that generates realistic and diverse patient personas for clinical scenarios, grounded in medical expertise. PatientSim operates using: 1) clinical profiles, including symptoms and medical history, derived from real-world data in the MIMIC-ED and MIMIC-IV datasets, and 2) personas defined by four axes: personality, language proficiency, medical history recall level, and cognitive confusion level, resulting in 37 unique combinations. We evaluated eight LLMs for factual accuracy and persona consistency. The top-performing open-source model, Llama 3.3, was validated by four clinicians to confirm the robustness of our framework. As an open-source, customizable platform, PatientSim provides a reproducible and scalable solution that can be customized for specific training needs. Offering a privacy-compliant environment, it serves as a robust testbed for evaluating medical dialogue systems across diverse patient presentations and shows promise as an educational tool for healthcare.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 10.1%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.8%">
                            LLMs
                        </span>
                <!-- Datasets: 2.1 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- GNN: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.2647
                </span>
                <a href="https://arxiv.org/abs/2505.17987" target="_blank" rel="noopener noreferrer">ADLGen: Synthesizing Symbolic, Event-Triggered Sensor Sequences for Human Activity Modeling</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Weihang You, Hanqi Jiang, Zishuai Liu, Zihang Xie, Tianming Liu, Jin Lu, Fei Dou
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Real world collection of Activities of Daily Living data is challenging due to privacy concerns, costly deployment and labeling, and the inherent sparsity and imbalance of human behavior. We present ADLGen, a generative framework specifically designed to synthesize realistic, event triggered, and sy</span>
                
                <span class="abstract-full" style="display: none;">Real world collection of Activities of Daily Living data is challenging due to privacy concerns, costly deployment and labeling, and the inherent sparsity and imbalance of human behavior. We present ADLGen, a generative framework specifically designed to synthesize realistic, event triggered, and symbolic sensor sequences for ambient assistive environments. ADLGen integrates a decoder only Transformer with sign based symbolic temporal encoding, and a context and layout aware sampling mechanism to guide generation toward semantically rich and physically plausible sensor event sequences. To enhance semantic fidelity and correct structural inconsistencies, we further incorporate a large language model into an automatic generate evaluate refine loop, which verifies logical, behavioral, and temporal coherence and generates correction rules without manual intervention or environment specific tuning. Through comprehensive experiments with novel evaluation metrics, ADLGen is shown to outperform baseline generators in statistical fidelity, semantic richness, and downstream activity recognition, offering a scalable and privacy-preserving solution for ADL data synthesis.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 10.3%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.7%">
                            LLMs
                        </span>
                <!-- Hardware: 2.0 -->
                    
                <!-- 3D: 2.0 -->
                    
                <!-- Datasets: 1.9 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- T2I: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.3272
                </span>
                <a href="https://arxiv.org/abs/2504.15928" target="_blank" rel="noopener noreferrer">A Clinician-Friendly Platform for Ophthalmic Image Analysis Without Technical Barriers</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Meng Wang, Tian Lin, Qingshan Hou, Aidi Lin, Jingcheng Wang, Qingsheng Peng, Truong X. Nguyen, Danqi Fang, Ke Zou, Ting Xu, Cancan Xue, Ten Cheer Quek, Qinkai Yu, Minxin Liu, Hui Zhou, Zixuan Xiao, Guiqin He, Huiyu Liang, Tingkun Shi, Man Chen, Linna Liu, Yuanyuan Peng, Lianyu Wang, Qiuming Hu, Junhong Chen, Zhenhua Zhang, Cheng Chen, Yitian Zhao, Dianbo Liu, Jianhua Wu, Xinjian Chen, Changqing Zhang, Triet Thanh Nguyen, Yanda Meng, Yalin Zheng, Yih Chung Tham, Carol Y. Cheung, Huazhu Fu, Haoyu Chen, Ching-Yu Cheng
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Artificial intelligence (AI) shows remarkable potential in medical imaging diagnostics, yet most current models require retraining when applied across different clinical settings, limiting their scalability. We introduce GlobeReady, a clinician-friendly AI platform that enables fundus disease diagno</span>
                
                <span class="abstract-full" style="display: none;">Artificial intelligence (AI) shows remarkable potential in medical imaging diagnostics, yet most current models require retraining when applied across different clinical settings, limiting their scalability. We introduce GlobeReady, a clinician-friendly AI platform that enables fundus disease diagnosis that operates without retraining, fine-tuning, or the needs for technical expertise. GlobeReady demonstrates high accuracy across imaging modalities: 93.9-98.5% for 11 fundus diseases using color fundus photographs (CPFs) and 87.2-92.7% for 15 fundus diseases using optic coherence tomography (OCT) scans. By leveraging training-free local feature augmentation, GlobeReady platform effectively mitigates domain shifts across centers and populations, achieving accuracies of 88.9-97.4% across five centers on average in China, 86.3-96.9% in Vietnam, and 73.4-91.0% in Singapore, and 90.2-98.9% in the UK. Incorporating a bulit-in confidence-quantifiable diagnostic mechanism further enhances the platform's accuracy to 94.9-99.4% with CFPs and 88.2-96.2% with OCT, while enabling identification of out-of-distribution cases with 86.3% accuracy across 49 common and rare fundus diseases using CFPs, and 90.6% accuracy across 13 diseases using OCT. Clinicians from countries rated GlobeReady highly for usability and clinical relevance (average score 4.6/5). These findings demonstrate GlobeReady's robustness, generalizability and potential to support global ophthalmic care without technical barriers.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 10.6%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.2%">
                            LLMs
                        </span>
                <!-- Computer Vision: 3.1 -->
                    
                <!-- Blockchain: 2.1 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- RAG: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.3422
                </span>
                <a href="https://arxiv.org/abs/2505.15180" target="_blank" rel="noopener noreferrer">NeuBM: Mitigating Model Bias in Graph Neural Networks through Neutral Input Calibration</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jiawei Gu, Ziyue Qiao, Xiao Luo
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Graph Neural Networks (GNNs) have shown remarkable performance across various domains, yet they often struggle with model bias, particularly in the presence of class imbalance. This bias can lead to suboptimal performance and unfair predictions, especially for underrepresented classes. We introduce </span>
                
                <span class="abstract-full" style="display: none;">Graph Neural Networks (GNNs) have shown remarkable performance across various domains, yet they often struggle with model bias, particularly in the presence of class imbalance. This bias can lead to suboptimal performance and unfair predictions, especially for underrepresented classes. We introduce NeuBM (Neutral Bias Mitigation), a novel approach to mitigate model bias in GNNs through neutral input calibration. NeuBM leverages a dynamically updated neutral graph to estimate and correct the inherent biases of the model. By subtracting the logits obtained from the neutral graph from those of the input graph, NeuBM effectively recalibrates the model's predictions, reducing bias across different classes. Our method integrates seamlessly into existing GNN architectures and training procedures, requiring minimal computational overhead. Extensive experiments on multiple benchmark datasets demonstrate that NeuBM significantly improves the balanced accuracy and recall of minority classes, while maintaining strong overall performance. The effectiveness of NeuBM is particularly pronounced in scenarios with severe class imbalance and limited labeled data, where traditional methods often struggle. We provide theoretical insights into how NeuBM achieves bias mitigation, relating it to the concept of representation balancing. Our analysis reveals that NeuBM not only adjusts the final predictions but also influences the learning of balanced feature representations throughout the network.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #b243cd" title="Confidence: 6.1%">
                            GNN
                        </span>
                <!-- Medicine: 3.5 -->
                    
                <!-- LLMs: 3.5 -->
                    
                <!-- Federated Learning: 2.7 -->
                    
                <!-- Computer Vision: 2.4 -->
                    
                <!-- Reinforcement Learning: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.3571
                </span>
                <a href="https://arxiv.org/abs/2505.17055" target="_blank" rel="noopener noreferrer">Enhancing Mathematics Learning for Hard-of-Hearing Students Through Real-Time Palestinian Sign Language Recognition: A New Dataset</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Fidaa khandaqji, Huthaifa I. Ashqar, Abdelrahem Atawnih
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The study aims to enhance mathematics education accessibility for hard-of-hearing students by developing an accurate Palestinian sign language PSL recognition system using advanced artificial intelligence techniques. Due to the scarcity of digital resources for PSL, a custom dataset comprising 41 ma</span>
                
                <span class="abstract-full" style="display: none;">The study aims to enhance mathematics education accessibility for hard-of-hearing students by developing an accurate Palestinian sign language PSL recognition system using advanced artificial intelligence techniques. Due to the scarcity of digital resources for PSL, a custom dataset comprising 41 mathematical gesture classes was created, and recorded by PSL experts to ensure linguistic accuracy and domain specificity. To leverage state-of-the-art-computer vision techniques, a Vision Transformer ViTModel was fine-tuned for gesture classification. The model achieved an accuracy of 97.59%, demonstrating its effectiveness in recognizing mathematical signs with high precision and reliability. This study highlights the role of deep learning in developing intelligent educational tools that bridge the learning gap for hard-of-hearing students by providing AI-driven interactive solutions to enhance mathematical comprehension. This work represents a significant step toward innovative and inclusive frosting digital integration in specialized learning environments. The dataset is hosted on Hugging Face at https://huggingface.co/datasets/fidaakh/STEM_data.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 10.2%">
                            Medicine
                        </span>
                <!-- LLMs: 4.0 -->
                    
                <!-- Evolutionary Algorithms: 2.2 -->
                    
                <!-- Datasets: 1.9 -->
                    
                <!-- Computer Vision: 1.9 -->
                    
                <!-- HPO and AutoML: 1.8 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- 3D: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.4259
                </span>
                <a href="https://arxiv.org/abs/2505.17457" target="_blank" rel="noopener noreferrer">Graph Mamba for Efficient Whole Slide Image Understanding</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jiaxuan Lu, Junyan Shi, Yuhui Lin, Fang Yan, Yue Gao, Shaoting Zhang, Xiaosong Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Whole Slide Images (WSIs) in histopathology present a significant challenge for large-scale medical image analysis due to their high resolution, large size, and complex tile relationships. Existing Multiple Instance Learning (MIL) methods, such as Graph Neural Networks (GNNs) and Transformer-based m</span>
                
                <span class="abstract-full" style="display: none;">Whole Slide Images (WSIs) in histopathology present a significant challenge for large-scale medical image analysis due to their high resolution, large size, and complex tile relationships. Existing Multiple Instance Learning (MIL) methods, such as Graph Neural Networks (GNNs) and Transformer-based models, face limitations in scalability and computational cost. To bridge this gap, we propose the WSI-GMamba framework, which synergistically combines the relational modeling strengths of GNNs with the efficiency of Mamba, the State Space Model designed for sequence learning. The proposed GMamba block integrates Message Passing, Graph Scanning & Flattening, and feature aggregation via a Bidirectional State Space Model (Bi-SSM), achieving Transformer-level performance with 7* fewer FLOPs. By leveraging the complementary strengths of lightweight GNNs and Mamba, the WSI-GMamba framework delivers a scalable solution for large-scale WSI analysis, offering both high accuracy and computational efficiency for slide-level classification.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 9.7%">
                            Medicine
                        </span>
                <!-- GNN: 3.6 -->
                    
                <!-- Hardware: 3.2 -->
                    
                <!-- LLMs: 2.6 -->
                    
                <!-- Computer Vision: 2.5 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Federated Learning: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- 3D: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.4377
                </span>
                <a href="https://arxiv.org/abs/2505.17915" target="_blank" rel="noopener noreferrer">Promptable cancer segmentation using minimal expert-curated data</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Lynn Karam, Yipei Wang, Veeru Kasivisvanathan, Mirabela Rusu, Yipeng Hu, Shaheer U. Saeed
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Automated segmentation of cancer on medical images can aid targeted diagnostic and therapeutic procedures. However, its adoption is limited by the high cost of expert annotations required for training and inter-observer variability in datasets. While weakly-supervised methods mitigate some challenge</span>
                
                <span class="abstract-full" style="display: none;">Automated segmentation of cancer on medical images can aid targeted diagnostic and therapeutic procedures. However, its adoption is limited by the high cost of expert annotations required for training and inter-observer variability in datasets. While weakly-supervised methods mitigate some challenges, using binary histology labels for training as opposed to requiring full segmentation, they require large paired datasets of histology and images, which are difficult to curate. Similarly, promptable segmentation aims to allow segmentation with no re-training for new tasks at inference, however, existing models perform poorly on pathological regions, again necessitating large datasets for training. In this work we propose a novel approach for promptable segmentation requiring only 24 fully-segmented images, supplemented by 8 weakly-labelled images, for training. Curating this minimal data to a high standard is relatively feasible and thus issues with the cost and variability of obtaining labels can be mitigated. By leveraging two classifiers, one weakly-supervised and one fully-supervised, our method refines segmentation through a guided search process initiated by a single-point prompt. Our approach outperforms existing promptable segmentation methods, and performs comparably with fully-supervised methods, for the task of prostate cancer segmentation, while using substantially less annotated data (up to 100X less). This enables promptable segmentation with very minimal labelled data, such that the labels can be curated to a very high standard.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 9.8%">
                            Medicine
                        </span>
                <!-- LLMs: 3.1 -->
                    
                <!-- Federated Learning: 2.9 -->
                    
                <!-- Computer Vision: 2.7 -->
                    
                <!-- Evolutionary Algorithms: 2.7 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.5033
                </span>
                <a href="https://arxiv.org/abs/2505.17344" target="_blank" rel="noopener noreferrer">A Multi-Head Attention Soft Random Forest for Interpretable Patient No-Show Prediction</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ninda Nurseha Amalina, Kwadwo Boateng Ofori-Amanfo, Heungjo An
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Unattended scheduled appointments, defined as patient no-shows, adversely affect both healthcare providers and patients' health, disrupting the continuity of care, operational efficiency, and the efficient allocation of medical resources. Accurate predictive modelling is needed to reduce the impact </span>
                
                <span class="abstract-full" style="display: none;">Unattended scheduled appointments, defined as patient no-shows, adversely affect both healthcare providers and patients' health, disrupting the continuity of care, operational efficiency, and the efficient allocation of medical resources. Accurate predictive modelling is needed to reduce the impact of no-shows. Although machine learning methods, such as logistic regression, random forest models, and decision trees, are widely used in predicting patient no-shows, they often rely on hard decision splits and static feature importance, limiting their adaptability to specific or complex patient behaviors. To address this limitation, we propose a new hybrid Multi-Head Attention Soft Random Forest (MHASRF) model that integrates attention mechanisms into a random forest model using probabilistic soft splitting instead of hard splitting. The MHASRF model assigns attention weights differently across the trees, enabling attention on specific patient behaviors. The model exhibited 93.56% accuracy, 93.67% precision, 93.56% recall, and a 93.59% F1 score, surpassing the performance of decision tree, logistic regression, random forest, and naive Bayes models. Furthermore, MHASRF was able to identify key predictors of patient no-shows using two levels of feature importance (tree level and attention mechanism level), offering deeper insights into patient no-show predictors. The proposed model is a robust, adaptable, and interpretable method for predicting patient no-shows that will help healthcare providers in optimizing resources.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 9.8%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.3%">
                            LLMs
                        </span>
                <!-- Federated Learning: 2.4 -->
                    
                <!-- Blockchain: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.5295
                </span>
                <a href="https://arxiv.org/abs/2505.17087" target="_blank" rel="noopener noreferrer">Informatics for Food Processing</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Gordana Ispirova, Michael Sebek, Giulia Menichetti
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This chapter explores the evolution, classification, and health implications of food processing, while emphasizing the transformative role of machine learning, artificial intelligence (AI), and data science in advancing food informatics. It begins with a historical overview and a critical review of </span>
                
                <span class="abstract-full" style="display: none;">This chapter explores the evolution, classification, and health implications of food processing, while emphasizing the transformative role of machine learning, artificial intelligence (AI), and data science in advancing food informatics. It begins with a historical overview and a critical review of traditional classification frameworks such as NOVA, Nutri-Score, and SIGA, highlighting their strengths and limitations, particularly the subjectivity and reproducibility challenges that hinder epidemiological research and public policy. To address these issues, the chapter presents novel computational approaches, including FoodProX, a random forest model trained on nutrient composition data to infer processing levels and generate a continuous FPro score. It also explores how large language models like BERT and BioBERT can semantically embed food descriptions and ingredient lists for predictive tasks, even in the presence of missing data. A key contribution of the chapter is a novel case study using the Open Food Facts database, showcasing how multimodal AI models can integrate structured and unstructured data to classify foods at scale, offering a new paradigm for food processing assessment in public health and research.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 8.2%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.4%">
                            LLMs
                        </span>
                <!-- Hardware: 2.3 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Datasets: 1.9 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.5436
                </span>
                <a href="https://arxiv.org/abs/2505.17293" target="_blank" rel="noopener noreferrer">Model-Free Graph Data Selection under Distribution Shift</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ting-Wei Li, Ruizhong Qiu, Hanghang Tong
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Graph domain adaptation (GDA) is a fundamental task in graph machine learning, with techniques like shift-robust graph neural networks (GNNs) and specialized training procedures to tackle the distribution shift problem. Although these model-centric approaches show promising results, they often strug</span>
                
                <span class="abstract-full" style="display: none;">Graph domain adaptation (GDA) is a fundamental task in graph machine learning, with techniques like shift-robust graph neural networks (GNNs) and specialized training procedures to tackle the distribution shift problem. Although these model-centric approaches show promising results, they often struggle with severe shifts and constrained computational resources. To address these challenges, we propose a novel model-free framework, GRADATE (GRAph DATa sElector), that selects the best training data from the source domain for the classification task on the target domain. GRADATE picks training samples without relying on any GNN model's predictions or training recipes, leveraging optimal transport theory to capture and adapt to distribution changes. GRADATE is data-efficient, scalable and meanwhile complements existing model-centric GDA approaches. Through comprehensive empirical studies on several real-world graph-level datasets and multiple covariate shift types, we demonstrate that GRADATE outperforms existing selection methods and enhances off-the-shelf GDA methods with much fewer training data.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #b243cd" title="Confidence: 6.6%">
                            GNN
                        </span>
                <!-- Medicine: 3.8 -->
                    
                <!-- Computer Vision: 3.6 -->
                    
                <!-- LLMs: 2.4 -->
                    
                <!-- HPO and AutoML: 2.3 -->
                    
                <!-- Federated Learning: 2.3 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.5685
                </span>
                <a href="https://arxiv.org/abs/2505.17338" target="_blank" rel="noopener noreferrer">Render-FM: A Foundation Model for Real-time Photorealistic Volumetric Rendering</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zhongpai Gao, Meng Zheng, Benjamin Planche, Anwesa Choudhuri, Terrence Chen, Ziyan Wu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Volumetric rendering of Computed Tomography (CT) scans is crucial for visualizing complex 3D anatomical structures in medical imaging. Current high-fidelity approaches, especially neural rendering techniques, require time-consuming per-scene optimization, limiting clinical applicability due to compu</span>
                
                <span class="abstract-full" style="display: none;">Volumetric rendering of Computed Tomography (CT) scans is crucial for visualizing complex 3D anatomical structures in medical imaging. Current high-fidelity approaches, especially neural rendering techniques, require time-consuming per-scene optimization, limiting clinical applicability due to computational demands and poor generalizability. We propose Render-FM, a novel foundation model for direct, real-time volumetric rendering of CT scans. Render-FM employs an encoder-decoder architecture that directly regresses 6D Gaussian Splatting (6DGS) parameters from CT volumes, eliminating per-scan optimization through large-scale pre-training on diverse medical data. By integrating robust feature extraction with the expressive power of 6DGS, our approach efficiently generates high-quality, real-time interactive 3D visualizations across diverse clinical CT data. Experiments demonstrate that Render-FM achieves visual fidelity comparable or superior to specialized per-scan methods while drastically reducing preparation time from nearly an hour to seconds for a single inference step. This advancement enables seamless integration into real-time surgical planning and diagnostic workflows. The project page is: https://gaozhongpai.github.io/renderfm/.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 12.8%">
                            Medicine
                        </span>
                <!-- LLMs: 3.9 -->
                    
                <!-- 3D: 3.3 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- HPO and AutoML: 2.0 -->
                    
                <!-- Quantum Computing: 2.0 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.6146
                </span>
                <a href="https://arxiv.org/abs/2505.17826" target="_blank" rel="noopener noreferrer">Trinity-RFT: A General-Purpose and Unified Framework for Reinforcement Fine-Tuning of Large Language Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Xuchen Pan, Yanxi Chen, Yushuo Chen, Yuchang Sun, Daoyuan Chen, Wenhao Zhang, Yuexiang Xie, Yilun Huang, Yilei Zhang, Dawei Gao, Yaliang Li, Bolin Ding, Jingren Zhou
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Trinity-RFT is a general-purpose, flexible and scalable framework designed for reinforcement fine-tuning (RFT) of large language models. It is built with a decoupled design, consisting of (1) an RFT-core that unifies and generalizes synchronous/asynchronous, on-policy/off-policy, and online/offline </span>
                
                <span class="abstract-full" style="display: none;">Trinity-RFT is a general-purpose, flexible and scalable framework designed for reinforcement fine-tuning (RFT) of large language models. It is built with a decoupled design, consisting of (1) an RFT-core that unifies and generalizes synchronous/asynchronous, on-policy/off-policy, and online/offline modes of RFT, (2) seamless integration for agent-environment interaction with high efficiency and robustness, and (3) systematic data pipelines optimized for RFT. Trinity-RFT can be easily adapted for diverse application scenarios, and serves as a unified platform for exploring advanced reinforcement learning paradigms. This technical report outlines the vision, features, design and implementations of Trinity-RFT, accompanied by extensive examples demonstrating the utility and user-friendliness of the proposed framework.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 10.2%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.4%">
                            LLMs
                        </span>
                <!-- Hardware: 3.3 -->
                    
                <!-- Datasets: 2.5 -->
                    
                <!-- Blockchain: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- 3D: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.6533
                </span>
                <a href="https://arxiv.org/abs/2505.17640" target="_blank" rel="noopener noreferrer">A Network Science Approach to Granular Time Series Segmentation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ivana Kesi\'c, Carolina Fortuna, Mihael Mohor\v{c}i\v{c}, Bla\v{z} Bertalani\v{c}
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Time series segmentation (TSS) is one of the time series (TS) analysis techniques, that has received considerably less attention compared to other TS related tasks. In recent years, deep learning architectures have been introduced for TSS, however their reliance on sliding windows limits segmentatio</span>
                
                <span class="abstract-full" style="display: none;">Time series segmentation (TSS) is one of the time series (TS) analysis techniques, that has received considerably less attention compared to other TS related tasks. In recent years, deep learning architectures have been introduced for TSS, however their reliance on sliding windows limits segmentation granularity due to fixed window sizes and strides. To overcome these challenges, we propose a new more granular TSS approach that utilizes the Weighted Dual Perspective Visbility Graph (WDPVG) TS into a graph and combines it with a Graph Attention Network (GAT). By transforming TS into graphs, we are able to capture different structural aspects of the data that would otherwise remain hidden. By utilizing the representation learning capabilities of Graph Neural Networks, our method is able to effectively identify meaningful segments within the TS. To better understand the potential of our approach, we also experimented with different TS-to-graph transformations and compared their performance. Our contributions include: a) formulating the TSS as a node classification problem on graphs; b) conducting an extensive analysis of various TS- to-graph transformations applied to TSS using benchmark datasets from the TSSB repository; c) providing the first detailed study on utilizing GNNs for analyzing graph representations of TS in the context of TSS; d) demonstrating the effectiveness of our method, which achieves an average F1 score of 0.97 across 59 diverse TSS benchmark datasets; e) outperforming the seq2point baseline method by 0.05 in terms of F1 score; and f) reducing the required training data compared to the baseline methods.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #b243cd" title="Confidence: 5.7%">
                            GNN
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #b3ebae" title="Confidence: 5.2%">
                            Federated Learning
                        </span>
                <!-- Medicine: 4.4 -->
                    
                <!-- Evolutionary Algorithms: 2.4 -->
                    
                <!-- LLMs: 1.9 -->
                    
                <!-- Reinforcement Learning: 1.8 -->
                    
                <!-- Bayesian Optimization: 1.7 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Hardware: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.6568
                </span>
                <a href="https://arxiv.org/abs/2505.17352" target="_blank" rel="noopener noreferrer">Alignment and Safety of Diffusion Models via Reinforcement Learning and Reward Modeling: A Survey</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Preeti Lamba, Kiran Ravish, Ankita Kushwaha, Pawan Kumar
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Diffusion models have emerged as leading generative models for images and other modalities, but aligning their outputs with human preferences and safety constraints remains a critical challenge. This thesis proposal investigates methods to align diffusion models using reinforcement learning (RL) and</span>
                
                <span class="abstract-full" style="display: none;">Diffusion models have emerged as leading generative models for images and other modalities, but aligning their outputs with human preferences and safety constraints remains a critical challenge. This thesis proposal investigates methods to align diffusion models using reinforcement learning (RL) and reward modeling. We survey recent advances in fine-tuning text-to-image diffusion models with human feedback, including reinforcement learning from human and AI feedback, direct preference optimization, and differentiable reward approaches. We classify these methods based on the type of feedback (human, automated, binary or ranked preferences), the fine-tuning technique (policy gradient, reward-weighted likelihood, direct backpropagation, etc.), and their efficiency and safety outcomes. We compare key algorithms and frameworks, highlighting how they improve alignment with user intent or safety standards, and discuss inter-relationships such as how newer methods build on or diverge from earlier ones. Based on the survey, we identify five promising research directions for the next two years: (1) multi-objective alignment with combined rewards, (2) efficient human feedback usage and active learning, (3) robust safety alignment against adversarial inputs, (4) continual and online alignment of diffusion models, and (5) interpretable and trustworthy reward modeling for generative images. Each direction is elaborated with its problem statement, challenges, related work, and a proposed research plan. The proposal is organized as a comprehensive document with literature review, comparative tables of methods, and detailed research plans, aiming to contribute new insights and techniques for safer and value-aligned diffusion-based generative AI.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 10.4%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.5%">
                            LLMs
                        </span>
                <!-- Computer Vision: 2.3 -->
                    
                <!-- Datasets: 2.3 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- HPO and AutoML: 1.8 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- 3D: 1.1 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.7882
                </span>
                <a href="https://arxiv.org/abs/2505.17065" target="_blank" rel="noopener noreferrer">Decoding Rarity: Large Language Models in the Diagnosis of Rare Diseases</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Valentina Carbonari, Pierangelo Veltri, Pietro Hiram Guzzi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Recent advances in artificial intelligence, particularly large language models LLMs, have shown promising capabilities in transforming rare disease research. This survey paper explores the integration of LLMs in the analysis of rare diseases, highlighting significant strides and pivotal studies that</span>
                
                <span class="abstract-full" style="display: none;">Recent advances in artificial intelligence, particularly large language models LLMs, have shown promising capabilities in transforming rare disease research. This survey paper explores the integration of LLMs in the analysis of rare diseases, highlighting significant strides and pivotal studies that leverage textual data to uncover insights and patterns critical for diagnosis, treatment, and patient care. While current research predominantly employs textual data, the potential for multimodal data integration combining genetic, imaging, and electronic health records stands as a promising frontier. We review foundational papers that demonstrate the application of LLMs in identifying and extracting relevant medical information, simulating intelligent conversational agents for patient interaction, and enabling the formulation of accurate and timely diagnoses. Furthermore, this paper discusses the challenges and ethical considerations inherent in deploying LLMs, including data privacy, model transparency, and the need for robust, inclusive data sets. As part of this exploration, we present a section on experimentation that utilizes multiple LLMs alongside structured questionnaires, specifically designed for diagnostic purposes in the context of different diseases. We conclude with future perspectives on the evolution of LLMs towards truly multimodal platforms, which would integrate diverse data types to provide a more comprehensive understanding of rare diseases, ultimately fostering better outcomes in clinical settings.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 21.1%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.7%">
                            Medicine
                        </span>
                <!-- Datasets: 2.3 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Blockchain: 2.0 -->
                    
                <!-- Federated Learning: 1.6 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.8146
                </span>
                <a href="https://arxiv.org/abs/2504.20118" target="_blank" rel="noopener noreferrer">OpenTCM: A GraphRAG-Empowered LLM-based System for Traditional Chinese Medicine Knowledge Retrieval and Diagnosis</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jinglin He, Yunqi Guo, Lai Kwan Lam, Waikei Leung, Lixing He, Yuanan Jiang, Chi Chiu Wang, Guoliang Xing, Hongkai Chen
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Traditional Chinese Medicine (TCM) represents a rich repository of ancient medical knowledge that continues to play an important role in modern healthcare. Due to the complexity and breadth of the TCM literature, the integration of AI technologies is critical for its modernization and broader access</span>
                
                <span class="abstract-full" style="display: none;">Traditional Chinese Medicine (TCM) represents a rich repository of ancient medical knowledge that continues to play an important role in modern healthcare. Due to the complexity and breadth of the TCM literature, the integration of AI technologies is critical for its modernization and broader accessibility. However, this integration poses considerable challenges, including the interpretation of obscure classical Chinese texts and the modeling of intricate semantic relationships among TCM concepts. In this paper, we develop OpenTCM, an LLM-based system that combines a domain-specific TCM knowledge graph and Graph-based Retrieval-Augmented Generation (GraphRAG). First, we extract more than 3.73 million classical Chinese characters from 68 gynecological books in the Chinese Medical Classics Database, with the help of TCM and gynecology experts. Second, we construct a comprehensive multi-relational knowledge graph comprising more than 48,000 entities and 152,000 interrelationships, using customized prompts and Chinese-oriented LLMs such as DeepSeek and Kimi to ensure high-fidelity semantic understanding. Last, we integrate OpenTCM with this knowledge graph, enabling high-fidelity ingredient knowledge retrieval and diagnostic question-answering without model fine-tuning. Experimental evaluations demonstrate that our prompt design and model selection significantly improve knowledge graph quality, achieving a precision of 98. 55% and an F1 score of 99. 55%. In addition, OpenTCM achieves mean expert scores of 4.5 in ingredient information retrieval and 3.8 in diagnostic question-answering tasks, outperforming state-of-the-art solutions in real-world TCM use cases.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 10.6%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 9.0%">
                            Medicine
                        </span>
                <!-- Blockchain: 1.9 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Datasets: 1.7 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.8294
                </span>
                <a href="https://arxiv.org/abs/2505.17367" target="_blank" rel="noopener noreferrer">EVM-Fusion: An Explainable Vision Mamba Architecture with Neural Algorithmic Fusion</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zichuan Yang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Medical image classification is critical for clinical decision-making, yet demands for accuracy, interpretability, and generalizability remain challenging. This paper introduces EVM-Fusion, an Explainable Vision Mamba architecture featuring a novel Neural Algorithmic Fusion (NAF) mechanism for multi</span>
                
                <span class="abstract-full" style="display: none;">Medical image classification is critical for clinical decision-making, yet demands for accuracy, interpretability, and generalizability remain challenging. This paper introduces EVM-Fusion, an Explainable Vision Mamba architecture featuring a novel Neural Algorithmic Fusion (NAF) mechanism for multi-organ medical image classification. EVM-Fusion leverages a multipath design, where DenseNet and U-Net based pathways, enhanced by Vision Mamba (Vim) modules, operate in parallel with a traditional feature pathway. These diverse features are dynamically integrated via a two-stage fusion process: cross-modal attention followed by the iterative NAF block, which learns an adaptive fusion algorithm. Intrinsic explainability is embedded through path-specific spatial attention, Vim {\Delta}-value maps, traditional feature SE-attention, and cross-modal attention weights. Experiments on a diverse 9-class multi-organ medical image dataset demonstrate EVM-Fusion's strong classification performance, achieving 99.75% test accuracy and provide multi-faceted insights into its decision-making process, highlighting its potential for trustworthy AI in medical diagnostics.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 13.2%">
                            Medicine
                        </span>
                <!-- LLMs: 3.5 -->
                    
                <!-- Computer Vision: 2.4 -->
                    
                <!-- 3D: 2.4 -->
                    
                <!-- HPO and AutoML: 2.1 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Datasets: 1.7 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- T2I: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.9262
                </span>
                <a href="https://arxiv.org/abs/2505.18106" target="_blank" rel="noopener noreferrer">F-ANcGAN: An Attention-Enhanced Cycle Consistent Generative Adversarial Architecture for Synthetic Image Generation of Nanoparticles</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Varun Ajith, Anindya Pal, Saumik Bhattacharya, Sayantari Ghosh
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Nanomaterial research is becoming a vital area for energy, medicine, and materials science, and accurate analysis of the nanoparticle topology is essential to determine their properties. Unfortunately, the lack of high-quality annotated datasets drastically hinders the creation of strong segmentatio</span>
                
                <span class="abstract-full" style="display: none;">Nanomaterial research is becoming a vital area for energy, medicine, and materials science, and accurate analysis of the nanoparticle topology is essential to determine their properties. Unfortunately, the lack of high-quality annotated datasets drastically hinders the creation of strong segmentation models for nanoscale imaging. To alleviate this problem, we introduce F-ANcGAN, an attention-enhanced cycle consistent generative adversarial system that can be trained using a limited number of data samples and generates realistic scanning electron microscopy (SEM) images directly from segmentation maps. Our model uses a Style U-Net generator and a U-Net segmentation network equipped with self-attention to capture structural relationships and applies augmentation methods to increase the variety of the dataset. The architecture reached a raw FID score of 17.65 for TiO$_2$ dataset generation, with a further reduction in FID score to nearly 10.39 by using efficient post-processing techniques. By facilitating scalable high-fidelity synthetic dataset generation, our approach can improve the effectiveness of downstream segmentation task training, overcoming severe data shortage issues in nanoparticle analysis, thus extending its applications to resource-limited fields.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 10.7%">
                            Medicine
                        </span>
                <!-- Federated Learning: 3.2 -->
                    
                <!-- LLMs: 2.9 -->
                    
                <!-- Evolutionary Algorithms: 2.9 -->
                    
                <!-- Bayesian Optimization: 2.1 -->
                    
                <!-- Datasets: 2.0 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.9432
                </span>
                <a href="https://arxiv.org/abs/2505.17075" target="_blank" rel="noopener noreferrer">Development and Validation of Engagement and Rapport Scales for Evaluating User Experience in Multimodal Dialogue Systems</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Fuma Kurata, Mao Saeki, Masaki Eguchi, Shungo Suzuki, Hiroaki Takatsu, Yoichi Matsuyama
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This study aimed to develop and validate two scales of engagement and rapport to evaluate the user experience quality with multimodal dialogue systems in the context of foreign language learning. The scales were designed based on theories of engagement in educational psychology, social psychology, a</span>
                
                <span class="abstract-full" style="display: none;">This study aimed to develop and validate two scales of engagement and rapport to evaluate the user experience quality with multimodal dialogue systems in the context of foreign language learning. The scales were designed based on theories of engagement in educational psychology, social psychology, and second language acquisition.Seventy-four Japanese learners of English completed roleplay and discussion tasks with trained human tutors and a dialog agent. After each dialogic task was completed, they responded to the scales of engagement and rapport. The validity and reliability of the scales were investigated through two analyses. We first conducted analysis of Cronbach's alpha coefficient and a series of confirmatory factor analyses to test the structural validity of the scales and the reliability of our designed items. We then compared the scores of engagement and rapport between the dialogue with human tutors and the one with a dialogue agent. The results revealed that our scales succeeded in capturing the difference in the dialogue experience quality between the human interlocutors and the dialogue agent from multiple perspectives.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 8.6%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.3%">
                            LLMs
                        </span>
                <!-- Blockchain: 2.1 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Datasets: 1.8 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Robotics: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.0801
                </span>
                <a href="https://arxiv.org/abs/2505.17116" target="_blank" rel="noopener noreferrer">Comparative Evaluation of Prompting and Fine-Tuning for Applying Large Language Models to Grid-Structured Geospatial Data</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Akash Dhruv, Yangxinyu Xie, Jordan Branham, Tanwi Mallick
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper presents a comparative study of large language models (LLMs) in interpreting grid-structured geospatial data. We evaluate the performance of a base model through structured prompting and contrast it with a fine-tuned variant trained on a dataset of user-assistant interactions. Our results</span>
                
                <span class="abstract-full" style="display: none;">This paper presents a comparative study of large language models (LLMs) in interpreting grid-structured geospatial data. We evaluate the performance of a base model through structured prompting and contrast it with a fine-tuned variant trained on a dataset of user-assistant interactions. Our results highlight the strengths and limitations of zero-shot prompting and demonstrate the benefits of fine-tuning for structured geospatial and temporal reasoning.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 19.4%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.6%">
                            Medicine
                        </span>
                <!-- Hardware: 2.7 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Datasets: 1.9 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.2189
                </span>
                <a href="https://arxiv.org/abs/2504.21464" target="_blank" rel="noopener noreferrer">VR-FuseNet: A Fusion of Heterogeneous Fundus Data and Explainable Deep Network for Diabetic Retinopathy Classification</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Shamim Rahim Refat, Ziyan Shirin Raha, Shuvashis Sarker, Faika Fairuj Preotee, MD. Musfikur Rahman, Tashreef Muhammad, Mohammad Shafiul Alam
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Diabetic retinopathy is a severe eye condition caused by diabetes where the retinal blood vessels get damaged and can lead to vision loss and blindness if not treated. Early and accurate detection is key to intervention and stopping the disease progressing. For addressing this disease properly, this</span>
                
                <span class="abstract-full" style="display: none;">Diabetic retinopathy is a severe eye condition caused by diabetes where the retinal blood vessels get damaged and can lead to vision loss and blindness if not treated. Early and accurate detection is key to intervention and stopping the disease progressing. For addressing this disease properly, this paper presents a comprehensive approach for automated diabetic retinopathy detection by proposing a new hybrid deep learning model called VR-FuseNet. Diabetic retinopathy is a major eye disease and leading cause of blindness especially among diabetic patients so accurate and efficient automated detection methods are required. To address the limitations of existing methods including dataset imbalance, diversity and generalization issues this paper presents a hybrid dataset created from five publicly available diabetic retinopathy datasets. Essential preprocessing techniques such as SMOTE for class balancing and CLAHE for image enhancement are applied systematically to the dataset to improve the robustness and generalizability of the dataset. The proposed VR-FuseNet model combines the strengths of two state-of-the-art convolutional neural networks, VGG19 which captures fine-grained spatial features and ResNet50V2 which is known for its deep hierarchical feature extraction. This fusion improves the diagnostic performance and achieves an accuracy of 91.824%. The model outperforms individual architectures on all performance metrics demonstrating the effectiveness of hybrid feature extraction in Diabetic Retinopathy classification tasks. To make the proposed model more clinically useful and interpretable this paper incorporates multiple XAI techniques. These techniques generate visual explanations that clearly indicate the retinal features affecting the model's prediction such as microaneurysms, hemorrhages and exudates so that clinicians can interpret and validate.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 10.7%">
                            Medicine
                        </span>
                <!-- Computer Vision: 3.4 -->
                    
                <!-- Datasets: 2.3 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- LLMs: 2.0 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.5453
                </span>
                <a href="https://arxiv.org/abs/2409.04491" target="_blank" rel="noopener noreferrer">Protein sequence classification using natural language processing techniques</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Huma Perveen (School of Mathematical and Physical Sciences, University of Sussex, Brighton, UK), Julie Weeds (School of Engineering and Informatics, University of Sussex, Brighton, UK)
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Purpose: This study aimed to enhance protein sequence classification using natural language processing (NLP) techniques while addressing the impact of sequence similarity on model performance. We compared various machine learning and deep learning models under two different data-splitting strategies</span>
                
                <span class="abstract-full" style="display: none;">Purpose: This study aimed to enhance protein sequence classification using natural language processing (NLP) techniques while addressing the impact of sequence similarity on model performance. We compared various machine learning and deep learning models under two different data-splitting strategies: random splitting and ECOD family-based splitting, which ensures evolutionary-related sequences are grouped together. Methods: The study evaluated models such as K-Nearest Neighbors (KNN), Multinomial Na\"ive Bayes, Logistic Regression, Multi-Layer Perceptron (MLP), Decision Tree, Random Forest, XGBoost, Voting and Stacking classifiers, Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM), and transformer models (BertForSequenceClassification, DistilBERT, and ProtBert). Performance was tested using different amino acid ranges and sequence lengths with a focus on generalization across unseen evolutionary families. Results: The Voting classifier achieved the highest performance with 74% accuracy, 74% weighted F1 score, and 65% macro F1 score under random splitting, while ProtBERT obtained 77% accuracy, 76% weighted F1 score, and 61% macro F1 score among transformer models. However, performance declined across all models when tested using ECOD-based splitting, revealing the impact of sequence similarity on classification performance. Conclusion: Advanced NLP techniques, particularly ensemble methods like Voting classifiers, and transformer models show significant potential in protein classification, with sufficient training data and sequence similarity management being crucial for optimal performance. However, the use of biologically meaningful splitting methods, such as ECOD family-based splitting, is crucial for realistic performance evaluation and generalization to unseen evolutionary families.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 14.0%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.4%">
                            LLMs
                        </span>
                <!-- Blockchain: 2.4 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- Hardware: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- HPO and AutoML: 1.9 -->
                    
                <!-- Datasets: 1.9 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.5795
                </span>
                <a href="https://arxiv.org/abs/2505.02279" target="_blank" rel="noopener noreferrer">A survey of agent interoperability protocols: Model Context Protocol (MCP), Agent Communication Protocol (ACP), Agent-to-Agent Protocol (A2A), and Agent Network Protocol (ANP)</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Abul Ehtesham, Aditi Singh, Gaurav Kumar Gupta, Saket Kumar
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Large language model powered autonomous agents demand robust, standardized protocols to integrate tools, share contextual data, and coordinate tasks across heterogeneous systems. Ad-hoc integrations are difficult to scale, secure, and generalize across domains. This survey examines four emerging age</span>
                
                <span class="abstract-full" style="display: none;">Large language model powered autonomous agents demand robust, standardized protocols to integrate tools, share contextual data, and coordinate tasks across heterogeneous systems. Ad-hoc integrations are difficult to scale, secure, and generalize across domains. This survey examines four emerging agent communication protocols: Model Context Protocol (MCP), Agent Communication Protocol (ACP), Agent-to-Agent Protocol (A2A), and Agent Network Protocol (ANP), each addressing interoperability in deployment contexts. MCP provides a JSON-RPC client-server interface for secure tool invocation and typed data exchange. ACP defines a general-purpose communication protocol over RESTful HTTP, supporting MIME-typed multipart messages and synchronous and asynchronous interactions. Its lightweight and runtime-independent design enables scalable agent invocation, while features like session management, message routing, and integration with role-based and decentralized identifiers (DIDs). A2A enables peer-to-peer task delegation using capability-based Agent Cards, supporting secure and scalable collaboration across enterprise agent workflows. ANP supports open network agent discovery and secure collaboration using W3C decentralized identifiers DIDs and JSON-LD graphs. The protocols are compared across multiple dimensions, including interaction modes, discovery mechanisms, communication patterns, and security models. Based on the comparative analysis, a phased adoption roadmap is proposed: beginning with MCP for tool access, followed by ACP for structured, multimodal messaging session-aware interaction and both online and offline agent discovery across scalable, HTTP-based deployments A2A for collaborative task execution, and extending to ANP for decentralized agent marketplaces. This work provides a comprehensive foundation for designing secure, interoperable, and scalable ecosystems of LLM-powered agents.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 12.9%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.7%">
                            LLMs
                        </span>
                <!-- Blockchain: 2.9 -->
                    
                <!-- Hardware: 2.8 -->
                    
                <!-- Computer Vision: 2.4 -->
                    
                <!-- Datasets: 2.4 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Federated Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.5896
                </span>
                <a href="https://arxiv.org/abs/2505.17214" target="_blank" rel="noopener noreferrer">MEDMKG: Benchmarking Medical Knowledge Exploitation with Multimodal Knowledge Graph</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Xiaochen Wang, Yuan Zhong, Lingwei Zhang, Lisong Dai, Ting Wang, Fenglong Ma
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Medical deep learning models depend heavily on domain-specific knowledge to perform well on knowledge-intensive clinical tasks. Prior work has primarily leveraged unimodal knowledge graphs, such as the Unified Medical Language System (UMLS), to enhance model performance. However, integrating multimo</span>
                
                <span class="abstract-full" style="display: none;">Medical deep learning models depend heavily on domain-specific knowledge to perform well on knowledge-intensive clinical tasks. Prior work has primarily leveraged unimodal knowledge graphs, such as the Unified Medical Language System (UMLS), to enhance model performance. However, integrating multimodal medical knowledge graphs remains largely underexplored, mainly due to the lack of resources linking imaging data with clinical concepts. To address this gap, we propose MEDMKG, a Medical Multimodal Knowledge Graph that unifies visual and textual medical information through a multi-stage construction pipeline. MEDMKG fuses the rich multimodal data from MIMIC-CXR with the structured clinical knowledge from UMLS, utilizing both rule-based tools and large language models for accurate concept extraction and relationship modeling. To ensure graph quality and compactness, we introduce Neighbor-aware Filtering (NaF), a novel filtering algorithm tailored for multimodal knowledge graphs. We evaluate MEDMKG across three tasks under two experimental settings, benchmarking twenty-four baseline methods and four state-of-the-art vision-language backbones on six datasets. Results show that MEDMKG not only improves performance in downstream medical tasks but also offers a strong foundation for developing adaptive and robust strategies for multimodal knowledge integration in medical artificial intelligence.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 15.4%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.4%">
                            LLMs
                        </span>
                <!-- GNN: 3.7 -->
                    
                <!-- Computer Vision: 2.9 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.7334
                </span>
                <a href="https://arxiv.org/abs/2505.17039" target="_blank" rel="noopener noreferrer">A new classification system of beer categories and styles based on large-scale data mining and self-organizing maps of beer recipes</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Diego Bonatto
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">A data-driven quantitative approach was used to develop a novel classification system for beer categories and styles. Sixty-two thousand one hundred twenty-one beer recipes were mined and analyzed, considering ingredient profiles, fermentation parameters, and recipe vital statistics. Statistical ana</span>
                
                <span class="abstract-full" style="display: none;">A data-driven quantitative approach was used to develop a novel classification system for beer categories and styles. Sixty-two thousand one hundred twenty-one beer recipes were mined and analyzed, considering ingredient profiles, fermentation parameters, and recipe vital statistics. Statistical analyses combined with self-organizing maps (SOMs) identified four major superclusters that showed distinctive malt and hop usage patterns, style characteristics, and historical brewing traditions. Cold fermented styles showed a conservative grain and hop composition, whereas hot fermented beers exhibited high heterogeneity, reflecting regional preferences and innovation. This new taxonomy offers a reproducible and objective framework beyond traditional sensory-based classifications, providing brewers, researchers, and educators with a scalable tool for recipe analysis and beer development. The findings in this work provide an understanding of beer diversity and open avenues for linking ingredient usage with fermentation profiles and flavor outcomes.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 15.9%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.7%">
                            LLMs
                        </span>
                <!-- Datasets: 2.8 -->
                    
                <!-- Blockchain: 2.3 -->
                    
                <!-- Hardware: 2.2 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- T2I: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.7422
                </span>
                <a href="https://arxiv.org/abs/2505.17363" target="_blank" rel="noopener noreferrer">Are GNNs Worth the Effort for IoT Botnet Detection? A Comparative Study of VAE-GNN vs. ViT-MLP and VAE-MLP Approaches</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Hassan Wasswa, Hussein Abbass, Timothy Lynar
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Due to the exponential rise in IoT-based botnet attacks, researchers have explored various advanced techniques for both dimensionality reduction and attack detection to enhance IoT security. Among these, Variational Autoencoders (VAE), Vision Transformers (ViT), and Graph Neural Networks (GNN), incl</span>
                
                <span class="abstract-full" style="display: none;">Due to the exponential rise in IoT-based botnet attacks, researchers have explored various advanced techniques for both dimensionality reduction and attack detection to enhance IoT security. Among these, Variational Autoencoders (VAE), Vision Transformers (ViT), and Graph Neural Networks (GNN), including Graph Convolutional Networks (GCN) and Graph Attention Networks (GAT), have garnered significant research attention in the domain of attack detection. This study evaluates the effectiveness of four state-of-the-art deep learning architectures for IoT botnet detection: a VAE encoder with a Multi-Layer Perceptron (MLP), a VAE encoder with a GCN, a VAE encoder with a GAT, and a ViT encoder with an MLP. The evaluation is conducted on a widely studied IoT benchmark dataset--the N-BaIoT dataset for both binary and multiclass tasks. For the binary classification task, all models achieved over 99.93% in accuracy, recall, precision, and F1-score, with no notable differences in performance. In contrast, for the multiclass classification task, GNN-based models showed significantly lower performance compared to VAE-MLP and ViT-MLP, with accuracies of 86.42%, 89.46%, 99.72%, and 98.38% for VAE-GCN, VAE-GAT, VAE-MLP, and ViT-MLP, respectively.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 13.7%">
                            Medicine
                        </span>
                <!-- LLMs: 2.6 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Datasets: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.7462
                </span>
                <a href="https://arxiv.org/abs/2505.17143" target="_blank" rel="noopener noreferrer">Evaluating the Performance of Nigerian Lecturers using Multilayer Perceptron</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: I. E. Ezeibe, S. O. Okide, D. C. Asogwa
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Evaluating the performance of a lecturer has been essential for enhancing teaching quality, improving student learning outcomes, and strengthening the institution's reputation. The absence of such a system brings about lecturer performance evaluation which was neither comprehensive nor holistic. Thi</span>
                
                <span class="abstract-full" style="display: none;">Evaluating the performance of a lecturer has been essential for enhancing teaching quality, improving student learning outcomes, and strengthening the institution's reputation. The absence of such a system brings about lecturer performance evaluation which was neither comprehensive nor holistic. This system was designed using a web-based platform, created a secure database, and by using a custom dataset, captured some performance metrics which included student evaluation scores, Research Publications, Years of Experience, and Administrative Duties. Multilayer Perceptron (MLP) algorithm was utilized due to its ability to process complex data patterns and generates accurate predictions in a lecturer's performance based on historical data. This research focused on designing multiple performance metrics beyond the standard ones, incorporating student participation, and integrating analytical tools to deliver a comprehensive and holistic evaluation of lecturers' performance and was developed using Object-Oriented Analysis and Design (OOAD) methodology. Lecturers' performance is evaluated by the model, and the evaluation accuracy is about 91% compared with actual performance. Finally, by evaluating the performance of the MLP model, it is concluded that MLP enhanced lecturer performance evaluation by providing accurate predictions, reducing bias, and supporting data-driven decisions, ultimately improving the fairness and efficiency of the evaluation process. The MLP model's performance was evaluated using Mean Squared Error (MSE) and Mean Absolute Error (MAE), achieved a test loss (MSE) of 256.99 and a MAE of 13.76, and reflected a high level of prediction accuracy. The model also demonstrated an estimated accuracy rate of approximately 96%, validated its effectiveness in predicting lecturer performance.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 10.0%">
                            Medicine
                        </span>
                <!-- Federated Learning: 3.2 -->
                    
                <!-- LLMs: 2.8 -->
                    
                <!-- Evolutionary Algorithms: 2.7 -->
                    
                <!-- Hardware: 2.2 -->
                    
                <!-- Datasets: 2.0 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.8079
                </span>
                <a href="https://arxiv.org/abs/2505.17357" target="_blank" rel="noopener noreferrer">Graph Attention Neural Network for Botnet Detection: Evaluating Autoencoder, VAE and PCA-Based Dimension Reduction</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Hassan Wasswa, Hussein Abbass, Timothy Lynar
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">With the rise of IoT-based botnet attacks, researchers have explored various learning models for detection, including traditional machine learning, deep learning, and hybrid approaches. A key advancement involves deploying attention mechanisms to capture long-term dependencies among features, signif</span>
                
                <span class="abstract-full" style="display: none;">With the rise of IoT-based botnet attacks, researchers have explored various learning models for detection, including traditional machine learning, deep learning, and hybrid approaches. A key advancement involves deploying attention mechanisms to capture long-term dependencies among features, significantly improving detection accuracy. However, most models treat attack instances independently, overlooking inter-instance relationships. Graph Neural Networks (GNNs) address this limitation by learning an embedding space via iterative message passing where similar instances are placed closer based on node features and relationships, enhancing classification performance. To further improve detection, attention mechanisms have been embedded within GNNs, leveraging both long-range dependencies and inter-instance connections. However, transforming the high dimensional IoT attack datasets into a graph structured dataset poses challenges, such as large graph structures leading computational overhead. To mitigate this, this paper proposes a framework that first reduces dimensionality of the NetFlow-based IoT attack dataset before transforming it into a graph dataset. We evaluate three dimension reduction techniques--Variational Autoencoder (VAE-encoder), classical autoencoder (AE-encoder), and Principal Component Analysis (PCA)--and compare their effects on a Graph Attention neural network (GAT) model for botnet attack detection</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #b243cd" title="Confidence: 6.2%">
                            GNN
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.1%">
                            Medicine
                        </span>
                <!-- LLMs: 3.3 -->
                    
                <!-- Computer Vision: 2.8 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Datasets: 1.8 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.8356
                </span>
                <a href="https://arxiv.org/abs/2505.17677" target="_blank" rel="noopener noreferrer">Towards Dynamic 3D Reconstruction of Hand-Instrument Interaction in Ophthalmic Surgery</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ming Hu, Zhendi Yu, Feilong Tang, Kaiwen Chen, Yulong Li, Imran Razzak, Junjun He, Tolga Birdal, Kaijing Zhou, Zongyuan Ge
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Accurate 3D reconstruction of hands and instruments is critical for vision-based analysis of ophthalmic microsurgery, yet progress has been hampered by the lack of realistic, large-scale datasets and reliable annotation tools. In this work, we introduce OphNet-3D, the first extensive RGB-D dynamic 3</span>
                
                <span class="abstract-full" style="display: none;">Accurate 3D reconstruction of hands and instruments is critical for vision-based analysis of ophthalmic microsurgery, yet progress has been hampered by the lack of realistic, large-scale datasets and reliable annotation tools. In this work, we introduce OphNet-3D, the first extensive RGB-D dynamic 3D reconstruction dataset for ophthalmic surgery, comprising 41 sequences from 40 surgeons and totaling 7.1 million frames, with fine-grained annotations of 12 surgical phases, 10 instrument categories, dense MANO hand meshes, and full 6-DoF instrument poses. To scalably produce high-fidelity labels, we design a multi-stage automatic annotation pipeline that integrates multi-view data observation, data-driven motion prior with cross-view geometric consistency and biomechanical constraints, along with a combination of collision-aware interaction constraints for instrument interactions. Building upon OphNet-3D, we establish two challenging benchmarks-bimanual hand pose estimation and hand-instrument interaction reconstruction-and propose two dedicated architectures: H-Net for dual-hand mesh recovery and OH-Net for joint reconstruction of two-hand-two-instrument interactions. These models leverage a novel spatial reasoning module with weak-perspective camera modeling and collision-aware center-based representation. Both architectures outperform existing methods by substantial margins, achieving improvements of over 2mm in Mean Per Joint Position Error (MPJPE) and up to 23% in ADD-S metrics for hand and instrument reconstruction, respectively.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 13.8%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.6%">
                            LLMs
                        </span>
                <!-- Datasets: 3.1 -->
                    
                <!-- Hardware: 2.3 -->
                    
                <!-- 3D: 2.2 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.9141
                </span>
                <a href="https://arxiv.org/abs/2505.17387" target="_blank" rel="noopener noreferrer">WiNGPT-3.0 Technical Report</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Boqin Zhuang, Chenxiao Song, Huitong Lu, Jiacheng Qiao, Mingqian Liu, Mingxing Yu, Ping Hong, Rui Li, Xiaoxia Song, Xiangjun Xu, Xu Chen, Yaoyao Ma, Yujie Gao
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Current Large Language Models (LLMs) exhibit significant limitations, notably in structured, interpretable, and verifiable medical reasoning, alongside practical deployment challenges related to computational resources and data privacy. This report focused on the development of WiNGPT-3.0, the 32-bi</span>
                
                <span class="abstract-full" style="display: none;">Current Large Language Models (LLMs) exhibit significant limitations, notably in structured, interpretable, and verifiable medical reasoning, alongside practical deployment challenges related to computational resources and data privacy. This report focused on the development of WiNGPT-3.0, the 32-billion parameter LLMs, engineered with the objective of enhancing its capacity for medical reasoning and exploring its potential for effective integration within healthcare IT infrastructures. The broader aim is to advance towards clinically applicable models. The approach involved a multi-stage training pipeline tailored for general, medical, and clinical reasoning. This pipeline incorporated supervised fine-tuning (SFT) and reinforcement learning (RL), leveraging curated Long Chain-of-Thought (CoT) datasets, auxiliary reward models, and an evidence-based diagnostic chain simulation. WiNGPT-3.0 demonstrated strong performance: specific model variants achieved scores of 66.6 on MedCalc and 87.1 on MedQA-USMLE. Furthermore, targeted training improved performance on a clinical reasoning task from a baseline score of 58.1 to 62.5. These findings suggest that reinforcement learning, even when applied with a limited dataset of only a few thousand examples, can enhance medical reasoning accuracy. Crucially, this demonstration of RL's efficacy with limited data and computation paves the way for more trustworthy and practically deployable LLMs within clinical workflows and health information infrastructures.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 15.4%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.6%">
                            LLMs
                        </span>
                <!-- Hardware: 2.3 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Datasets: 1.9 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- 3D: 1.1 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.2967
                </span>
                <a href="https://arxiv.org/abs/2504.15141" target="_blank" rel="noopener noreferrer">Breaking Down Quantum Compilation: Profiling and Identifying Costly Passes</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Felix Zilk, Alessandro Tundo, Vincenzo De Maio, Ivona Brandic
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">With the increasing capabilities of quantum systems, the efficient, practical execution of quantum programs is becoming more critical. Each execution includes compilation time, which accounts for substantial overhead of the overall program runtime. To address this challenge, proposals that leverage </span>
                
                <span class="abstract-full" style="display: none;">With the increasing capabilities of quantum systems, the efficient, practical execution of quantum programs is becoming more critical. Each execution includes compilation time, which accounts for substantial overhead of the overall program runtime. To address this challenge, proposals that leverage precompilation techniques have emerged, whereby entire circuits or select components are precompiled to mitigate the compilation time spent during execution. Considering the impact of compilation time on quantum program execution, identifying the contribution of each individual compilation task to the execution time is necessary in directing the community's research efforts towards the development of an efficient compilation and execution pipeline. In this work, we perform a preliminary analysis of the quantum circuit compilation process in Qiskit, examining the cumulative runtime of each individual compilation task and identifying the tasks that most strongly impact the overall compilation time. Our results indicate that, as the desired level of optimization increases, circuit optimization and gate synthesis passes become the dominant tasks in compiling a Quantum Fourier Transform, with individual passes consuming up to 87% of the total compilation time. Mapping passes require the most compilation time for a GHZ state preparation circuit, accounting for over 99% of total compilation time.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 7.0%">
                            Quantum Computing
                        </span>
                <!-- Federated Learning: 3.4 -->
                    
                <!-- Medicine: 2.4 -->
                    
                <!-- Evolutionary Algorithms: 2.2 -->
                    
                <!-- Bayesian Optimization: 2.2 -->
                    
                <!-- LLMs: 1.9 -->
                    
                <!-- Math: 1.8 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Cryptography: 1.2 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                <!-- GNN: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.3579
                </span>
                <a href="https://arxiv.org/abs/2311.06358" target="_blank" rel="noopener noreferrer">Compact Matrix Quantum Group Equivariant Neural Networks</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Edward Pearce-Crump
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Group equivariant neural networks have proven effective in modelling a wide range of tasks where the data lives in a classical geometric space and exhibits well-defined group symmetries. However, these networks are not suitable for learning from data that lives in a non-commutative geometry, describ</span>
                
                <span class="abstract-full" style="display: none;">Group equivariant neural networks have proven effective in modelling a wide range of tasks where the data lives in a classical geometric space and exhibits well-defined group symmetries. However, these networks are not suitable for learning from data that lives in a non-commutative geometry, described formally by non-commutative $C^{*}$-algebras, since the $C^{*}$-algebra of continuous functions on a compact matrix group is commutative. To address this limitation, we derive the existence of a new type of equivariant neural network, called compact matrix quantum group equivariant neural networks, which encode symmetries that are described by compact matrix quantum groups. We characterise the weight matrices that appear in these neural networks for the easy compact matrix quantum groups, which are defined by set partitions. As a result, we obtain new characterisations of equivariant weight matrices for some compact matrix groups that have not appeared previously in the machine learning literature.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 7.6%">
                            Quantum Computing
                        </span>
                <!-- GNN: 3.7 -->
                    
                <!-- Medicine: 2.1 -->
                    
                <!-- LLMs: 2.0 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Math: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Cryptography: 1.4 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Networks: 1.2 -->
                    
                <!-- Game Theory: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.4712
                </span>
                <a href="https://arxiv.org/abs/2505.17133" target="_blank" rel="noopener noreferrer">Learning Probabilities of Causation from Finite Population Data</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Shuai Wang, Song Jiang, Yizhou Sun, Judea Pearl, Ang Li
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Probabilities of causation play a crucial role in modern decision-making. This paper addresses the challenge of predicting probabilities of causation for subpopulations with \textbf{insufficient} data using machine learning models. Tian and Pearl first defined and derived tight bounds for three fund</span>
                
                <span class="abstract-full" style="display: none;">Probabilities of causation play a crucial role in modern decision-making. This paper addresses the challenge of predicting probabilities of causation for subpopulations with \textbf{insufficient} data using machine learning models. Tian and Pearl first defined and derived tight bounds for three fundamental probabilities of causation: the probability of necessity and sufficiency (PNS), the probability of sufficiency (PS), and the probability of necessity (PN). However, estimating these probabilities requires both experimental and observational distributions specific to each subpopulation, which are often unavailable or impractical to obtain with limited population-level data. Therefore, for most subgroups, the amount of data they have is not enough to guarantee the accuracy of their probabilities. Hence, to estimate these probabilities for subpopulations with \textbf{insufficient} data, we propose using machine learning models that draw insights from subpopulations with sufficient data. Our evaluation of multiple machine learning models indicates that, given the population-level data and an appropriate choice of machine learning model and activation function, PNS can be effectively predicted. Through simulation studies on multiple Structured Causal Models (SCMs), we show that our multilayer perceptron (MLP) model with the Mish activation function achieves a mean absolute error (MAE) of approximately $0.02$ in predicting PNS for $32,768$ subpopulations across most SCMs using data from only $2,000$ subpopulations with known PNS values.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 16.2%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #b3ebae" title="Confidence: 5.0%">
                            Federated Learning
                        </span>
                <!-- LLMs: 2.9 -->
                    
                <!-- Evolutionary Algorithms: 2.8 -->
                    
                <!-- Quantum Computing: 2.1 -->
                    
                <!-- Bayesian Optimization: 1.8 -->
                    
                <!-- Datasets: 1.7 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- GNN: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -5.2427
                </span>
                <a href="https://arxiv.org/abs/2505.17931" target="_blank" rel="noopener noreferrer">AutoMiSeg: Automatic Medical Image Segmentation via Test-Time Adaptation of Foundation Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Xingjian Li, Qifeng Wu, Colleen Que, Yiran Ding, Adithya S. Ubaradka, Jianhua Xing, Tianyang Wang, Min Xu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Medical image segmentation is vital for clinical diagnosis, yet current deep learning methods often demand extensive expert effort, i.e., either through annotating large training datasets or providing prompts at inference time for each new case. This paper introduces a zero-shot and automatic segmen</span>
                
                <span class="abstract-full" style="display: none;">Medical image segmentation is vital for clinical diagnosis, yet current deep learning methods often demand extensive expert effort, i.e., either through annotating large training datasets or providing prompts at inference time for each new case. This paper introduces a zero-shot and automatic segmentation pipeline that combines off-the-shelf vision-language and segmentation foundation models. Given a medical image and a task definition (e.g., "segment the optic disc in an eye fundus image"), our method uses a grounding model to generate an initial bounding box, followed by a visual prompt boosting module that enhance the prompts, which are then processed by a promptable segmentation model to produce the final mask. To address the challenges of domain gap and result verification, we introduce a test-time adaptation framework featuring a set of learnable adaptors that align the medical inputs with foundation model representations. Its hyperparameters are optimized via Bayesian Optimization, guided by a proxy validation model without requiring ground-truth labels. Our pipeline offers an annotation-efficient and scalable solution for zero-shot medical image segmentation across diverse tasks. Our pipeline is evaluated on seven diverse medical imaging datasets and shows promising results. By proper decomposition and test-time adaptation, our fully automatic pipeline performs competitively with weakly-prompted interactive foundation models.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 22.7%">
                            Medicine
                        </span>
                <!-- LLMs: 4.6 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- 3D: 2.1 -->
                    
                <!-- Computer Vision: 2.1 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                <!-- Datasets: 1.0 -->
                    
                <!-- Bayesian Optimization: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -5.2442
                </span>
                <a href="https://arxiv.org/abs/2505.17096" target="_blank" rel="noopener noreferrer">TAGS: 3D Tumor-Adaptive Guidance for SAM</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Sirui Li, Linkai Peng, Zheyuan Zhang, Gorkem Durak, Ulas Bagci
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Foundation models (FMs) such as CLIP and SAM have recently shown great promise in image segmentation tasks, yet their adaptation to 3D medical imaging-particularly for pathology detection and segmentation-remains underexplored. A critical challenge arises from the domain gap between natural images a</span>
                
                <span class="abstract-full" style="display: none;">Foundation models (FMs) such as CLIP and SAM have recently shown great promise in image segmentation tasks, yet their adaptation to 3D medical imaging-particularly for pathology detection and segmentation-remains underexplored. A critical challenge arises from the domain gap between natural images and medical volumes: existing FMs, pre-trained on 2D data, struggle to capture 3D anatomical context, limiting their utility in clinical applications like tumor segmentation. To address this, we propose an adaptation framework called TAGS: Tumor Adaptive Guidance for SAM, which unlocks 2D FMs for 3D medical tasks through multi-prompt fusion. By preserving most of the pre-trained weights, our approach enhances SAM's spatial feature extraction using CLIP's semantic insights and anatomy-specific prompts. Extensive experiments on three open-source tumor segmentation datasets prove that our model surpasses the state-of-the-art medical image segmentation models (+46.88% over nnUNet), interactive segmentation frameworks, and other established medical FMs, including SAM-Med2D, SAM-Med3D, SegVol, Universal, 3D-Adapter, and SAM-B (at least +13% over them). This highlights the robustness and adaptability of our proposed framework across diverse medical segmentation tasks.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 23.8%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.5%">
                            Computer Vision
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.1%">
                            LLMs
                        </span>
                <!-- 3D: 3.6 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -5.9754
                </span>
                <a href="https://arxiv.org/abs/2505.17971" target="_blank" rel="noopener noreferrer">Explainable Anatomy-Guided AI for Prostate MRI: Foundation Models and In Silico Clinical Trials for Virtual Biopsy-based Risk Assessment</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Danial Khan, Zohaib Salahuddin, Yumeng Zhang, Sheng Kuang, Shruti Atul Mali, Henry C. Woodruff, Sina Amirrajab, Rachel Cavill, Eduardo Ibor-Crespo, Ana Jimenez-Pastor, Adrian Galiana-Bordera, Paula Jimenez Gomez, Luis Marti-Bonmati, Philippe Lambin
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We present a fully automated, anatomically guided deep learning pipeline for prostate cancer (PCa) risk stratification using routine MRI. The pipeline integrates three key components: an nnU-Net module for segmenting the prostate gland and its zones on axial T2-weighted MRI; a classification module </span>
                
                <span class="abstract-full" style="display: none;">We present a fully automated, anatomically guided deep learning pipeline for prostate cancer (PCa) risk stratification using routine MRI. The pipeline integrates three key components: an nnU-Net module for segmenting the prostate gland and its zones on axial T2-weighted MRI; a classification module based on the UMedPT Swin Transformer foundation model, fine-tuned on 3D patches with optional anatomical priors and clinical data; and a VAE-GAN framework for generating counterfactual heatmaps that localize decision-driving image regions. The system was developed using 1,500 PI-CAI cases for segmentation and 617 biparametric MRIs with metadata from the CHAIMELEON challenge for classification (split into 70% training, 10% validation, and 20% testing). Segmentation achieved mean Dice scores of 0.95 (gland), 0.94 (peripheral zone), and 0.92 (transition zone). Incorporating gland priors improved AUC from 0.69 to 0.72, with a three-scale ensemble achieving top performance (AUC = 0.79, composite score = 0.76), outperforming the 2024 CHAIMELEON challenge winners. Counterfactual heatmaps reliably highlighted lesions within segmented regions, enhancing model interpretability. In a prospective multi-center in-silico trial with 20 clinicians, AI assistance increased diagnostic accuracy from 0.72 to 0.77 and Cohen's kappa from 0.43 to 0.53, while reducing review time per case by 40%. These results demonstrate that anatomy-aware foundation models with counterfactual explainability can enable accurate, interpretable, and efficient PCa risk assessment, supporting their potential use as virtual biopsies in clinical practice.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 23.9%">
                            Medicine
                        </span>
                <!-- LLMs: 3.1 -->
                    
                <!-- Computer Vision: 2.6 -->
                    
                <!-- 3D: 2.0 -->
                    
                <!-- HPO and AutoML: 1.8 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -6.0311
                </span>
                <a href="https://arxiv.org/abs/2405.20237" target="_blank" rel="noopener noreferrer">Training-efficient density quantum machine learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Brian Coyle, Snehal Raj, Natansh Mathur, El Amine Cherrat, Nishant Jain, Skander Kazdaghli, Iordanis Kerenidis
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Quantum machine learning (QML) requires powerful, flexible and efficiently trainable models to be successful in solving challenging problems. We introduce density quantum neural networks, a model family that prepares mixtures of trainable unitaries, with a distributional constraint over coefficients</span>
                
                <span class="abstract-full" style="display: none;">Quantum machine learning (QML) requires powerful, flexible and efficiently trainable models to be successful in solving challenging problems. We introduce density quantum neural networks, a model family that prepares mixtures of trainable unitaries, with a distributional constraint over coefficients. This framework balances expressivity and efficient trainability, especially on quantum hardware. For expressivity, the Hastings-Campbell Mixing lemma converts benefits from linear combination of unitaries into density models with similar performance guarantees but shallower circuits. For trainability, commuting-generator circuits enable density model construction with efficiently extractable gradients. The framework connects to various facets of QML including post-variational and measurement-based learning. In classical settings, density models naturally integrate the mixture of experts formalism, and offer natural overfitting mitigation. The framework is versatile - we uplift several quantum models into density versions to improve model performance, or trainability, or both. These include Hamming weight-preserving and equivariant models, among others. Extensive numerical experiments validate our findings.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 8.0%">
                            Quantum Computing
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.7%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.3%">
                            LLMs
                        </span>
                <!-- Federated Learning: 2.4 -->
                    
                <!-- Decision Trees: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -6.4511
                </span>
                <a href="https://arxiv.org/abs/2505.17034" target="_blank" rel="noopener noreferrer">Preparing for the Post Quantum Era: Quantum Ready Architecture for Security and Risk Management (QUASAR) -- A Strategic Framework for Cybersecurity</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Abraham Itzhak Weinberg
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">As quantum computing progresses, traditional cryptographic systems face the threat of obsolescence due to the capabilities of quantum algorithms. This paper introduces the Quantum-Ready Architecture for Security and Risk Management (QUASAR), a novel framework designed to help organizations prepare f</span>
                
                <span class="abstract-full" style="display: none;">As quantum computing progresses, traditional cryptographic systems face the threat of obsolescence due to the capabilities of quantum algorithms. This paper introduces the Quantum-Ready Architecture for Security and Risk Management (QUASAR), a novel framework designed to help organizations prepare for the post-quantum era. QUASAR provides a structured approach to transition from current cryptographic systems to quantum-resistant alternatives, emphasizing technical, security, and operational readiness. The framework integrates a set of actionable components, a timeline for phased implementation, and continuous optimization strategies to ensure ongoing preparedness. Through performance indicators, readiness scores, and optimization functions, QUASAR enables organizations to assess their current state, identify gaps, and execute targeted actions to mitigate risks posed by quantum computing. By offering a comprehensive, adaptable, and quantifiable strategy, QUASAR equips organizations with the tools necessary to future-proof their operations and secure sensitive data against the impending rise of quantum technologies.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 6.1%">
                            Quantum Computing
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.2%">
                            Medicine
                        </span>
                <!-- Evolutionary Algorithms: 2.7 -->
                    
                <!-- LLMs: 2.2 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -6.5202
                </span>
                <a href="https://arxiv.org/abs/2411.11369" target="_blank" rel="noopener noreferrer">Exact Quantum Algorithm for Unit Commitment Optimization based on Partially Connected Quantum Neural Networks</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jian Liu, Xu Zhou, Zhuojun Zhou, Le Luo
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The quantum hybrid algorithm has become a very promising and speedily method today for solving the larger-scale optimization in the noisy intermediate-scale quantum (NISQ) era. The unit commitment (UC) problem is a fundamental problem in the power system which aims to satisfy a balance load with min</span>
                
                <span class="abstract-full" style="display: none;">The quantum hybrid algorithm has become a very promising and speedily method today for solving the larger-scale optimization in the noisy intermediate-scale quantum (NISQ) era. The unit commitment (UC) problem is a fundamental problem in the power system which aims to satisfy a balance load with minimal cost. In this paper, we focus on the implement of the UC-solving by exact quantum algorithms based on the quantum neural network (QNN). This method is tested with up to 10-unit system with the balance load constraint. In order to improve the computing precision and reduce the network complexity, we suggest the knowledge-based partially connected quantum neural network (PCQNN). The results show that the exact solutions can be obtained by the improved algorithm and the depth of the quantum circuit can be reduced simultaneously.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 10.6%">
                            Quantum Computing
                        </span>
                <!-- Evolutionary Algorithms: 3.7 -->
                    
                <!-- Federated Learning: 3.5 -->
                    
                <!-- Cryptography: 2.5 -->
                    
                <!-- Math: 2.4 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- Bayesian Optimization: 1.6 -->
                    
                <!-- Medicine: 1.5 -->
                    
                <!-- Finance: 1.3 -->
                    
                <!-- Networks: 1.2 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- GNN: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -6.9094
                </span>
                <a href="https://arxiv.org/abs/2504.08456" target="_blank" rel="noopener noreferrer">Generalization Bounds in Hybrid Quantum-Classical Machine Learning Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Tongyan Wu, Amine Bentellis, Alona Sakhnenko, Jeanette Miriam Lorenz
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Hybrid classical-quantum models aim to harness the strengths of both quantum computing and classical machine learning, but their practical potential remains poorly understood. In this work, we develop a unified mathematical framework for analyzing generalization in hybrid models, offering insight in</span>
                
                <span class="abstract-full" style="display: none;">Hybrid classical-quantum models aim to harness the strengths of both quantum computing and classical machine learning, but their practical potential remains poorly understood. In this work, we develop a unified mathematical framework for analyzing generalization in hybrid models, offering insight into how these systems learn from data. We establish a novel generalization bound of the form $O\big( \sqrt{\frac{T\log{T}}{N}} + \frac{\alpha}{\sqrt{N}}\big)$ for $N$ training data points, $T$ trainable quantum gates, and bounded fully-connected layers $||F|| \leq \alpha$. This bound decomposes cleanly into quantum and classical contributions, extending prior work on both components and clarifying their interaction. We apply our results to the quantum-classical convolutional neural network (QCCNN), an architecture that integrates quantum convolutional layers with classical processing. Alongside the bound, we highlight conceptual limitations of applying classical statistical learning theory in the hybrid setting and suggest promising directions for future theoretical work.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 11.2%">
                            Quantum Computing
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.3%">
                            LLMs
                        </span>
                <!-- Medicine: 4.0 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Datasets: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -7.4602
                </span>
                <a href="https://arxiv.org/abs/2505.18133" target="_blank" rel="noopener noreferrer">Joint Encryption and Error Correction for Secure Quantum Communication</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Nitin Jha, Abhishek Parakh, Mahadevan Subramaniam
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Secure quantum networks are a bedrock requirement for developing a future quantum internet. However, quantum channels are susceptible to channel noise that introduce errors in the transmitted data. The traditional approach to providing error correction typically encapsulates the message in an error </span>
                
                <span class="abstract-full" style="display: none;">Secure quantum networks are a bedrock requirement for developing a future quantum internet. However, quantum channels are susceptible to channel noise that introduce errors in the transmitted data. The traditional approach to providing error correction typically encapsulates the message in an error correction code after encryption. Such separate processes incur overhead that must be avoided when possible. We, consequently, provide a single integrated process that allows for encryption as well as error correction. This is a first attempt to do so for secure quantum communication and combines the Calderbank-Shor-Steane (CSS) code with the three-stage secure quantum communication protocol. Lastly, it allows for arbitrary qubits to be transmitted from sender to receiver making the proposed protocol general purpose.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 14.9%">
                            Quantum Computing
                        </span>
                <!-- Networks: 2.2 -->
                    
                <!-- Cryptography: 1.8 -->
                    
                <!-- Medicine: 1.7 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- LLMs: 1.4 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                <!-- Hardware: 1.1 -->
                    
                <!-- Game Theory: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Math: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -8.2955
                </span>
                <a href="https://arxiv.org/abs/2401.10579" target="_blank" rel="noopener noreferrer">Trade-offs between classical and quantum space using spooky pebbling</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Arend-Jan Quist, Alfons Laarman
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Pebble games are used to study space/time trade-offs. Recently, spooky pebble games were introduced to study classical space / quantum space / time trade-offs for simulation of classical circuits on quantum computers. In this paper, the spooky pebble game framework is applied for the first time to g</span>
                
                <span class="abstract-full" style="display: none;">Pebble games are used to study space/time trade-offs. Recently, spooky pebble games were introduced to study classical space / quantum space / time trade-offs for simulation of classical circuits on quantum computers. In this paper, the spooky pebble game framework is applied for the first time to general circuits. Using this framework we prove an upper bound for quantum space in the spooky pebble game. We also prove that solving the spooky pebble game is PSPACE-complete. Moreover, we present a solver for the spooky pebble game based on satisfiability solvers combined with heuristic optimizers. This spooky pebble game solver was empirically evaluated by calculating optimal classical space / quantum space / time trade-offs. Within limited runtime, the solver could find a strategy reducing quantum space when classical space is taken into account, showing that the spooky pebble model is useful to reduce quantum space.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 16.6%">
                            Quantum Computing
                        </span>
                <!-- Computer Vision: 2.0 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Cryptography: 1.9 -->
                    
                <!-- Math: 1.9 -->
                    
                <!-- Networks: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- Medicine: 1.7 -->
                    
                <!-- Game Theory: 1.5 -->
                    
                <!-- LLMs: 1.4 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Finance: 1.3 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -8.5713
                </span>
                <a href="https://arxiv.org/abs/2505.17756" target="_blank" rel="noopener noreferrer">Qiskit Machine Learning: an open-source library for quantum machine learning tasks at scale on quantum hardware and classical simulators</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: M. Emre Sahin, Edoardo Altamura, Oscar Wallis, Stephen P. Wood, Anton Dekusar, Declan A. Millar, Takashi Imamichi, Atsushi Matsuo, Stefano Mensa
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We present Qiskit Machine Learning (ML), a high-level Python library that combines elements of quantum computing with traditional machine learning. The API abstracts Qiskit's primitives to facilitate interactions with classical simulators and quantum hardware. Qiskit ML started as a proof-of-concept</span>
                
                <span class="abstract-full" style="display: none;">We present Qiskit Machine Learning (ML), a high-level Python library that combines elements of quantum computing with traditional machine learning. The API abstracts Qiskit's primitives to facilitate interactions with classical simulators and quantum hardware. Qiskit ML started as a proof-of-concept code in 2019 and has since been developed to be a modular, intuitive tool for non-specialist users while allowing extensibility and fine-tuning controls for quantum computational scientists and developers. The library is available as a public, open-source tool and is distributed under the Apache version 2.0 license.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 13.9%">
                            Quantum Computing
                        </span>
                <!-- Medicine: 4.7 -->
                    
                <!-- HPO and AutoML: 2.4 -->
                    
                <!-- LLMs: 2.3 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- 3D: 1.8 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                <!-- GNN: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -9.1107
                </span>
                <a href="https://arxiv.org/abs/2501.04600" target="_blank" rel="noopener noreferrer">Do Automated Fixes Truly Mitigate Smart Contract Exploits?</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Sofia Bobadilla, Monica Jin, Martin Monperrus
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Automated Program Repair (APR) for smart contract security promises to automatically mitigate smart contract vulnerabilities responsible for billions in financial losses. However, the true effectiveness of this research in addressing smart contract exploits remains uncharted territory. This paper br</span>
                
                <span class="abstract-full" style="display: none;">Automated Program Repair (APR) for smart contract security promises to automatically mitigate smart contract vulnerabilities responsible for billions in financial losses. However, the true effectiveness of this research in addressing smart contract exploits remains uncharted territory. This paper bridges this critical gap by introducing a novel and systematic experimental framework for evaluating exploit mitigation of program repair tools for smart contracts. We qualitatively and quantitatively analyze 20 state-of-the-art APR tools using a dataset of 143 vulnerable smart contracts, for which we manually craft 91 executable exploits. We are the very first to define and measure the essential "exploit mitigation rate" , giving researchers and practitioners a real sense of effectiveness of cutting edge techniques. Our findings reveal substantial disparities in the state of the art, with an exploit mitigation rate ranging from a low of 29% to a high of 74%. Our study identifies systemic limitations, such as inconsistent functionality preservation, that must be addressed in future research on program repair for smart contracts.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #3cc377" title="Confidence: 6.1%">
                            Blockchain
                        </span>
                <!-- LLMs: 3.5 -->
                    
                <!-- Medicine: 3.3 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Datasets: 1.9 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -12.3548
                </span>
                <a href="https://arxiv.org/abs/2505.17416" target="_blank" rel="noopener noreferrer">LLM-BSCVM: An LLM-Based Blockchain Smart Contract Vulnerability Management Framework</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yanli Jin, Chunpei Li, Peng Fan, Peng Liu, Xianxian Li, Chen Liu, Wangjie Qiu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Smart contracts are a key component of the Web 3.0 ecosystem, widely applied in blockchain services and decentralized applications. However, the automated execution feature of smart contracts makes them vulnerable to potential attacks due to inherent flaws, which can lead to severe security risks an</span>
                
                <span class="abstract-full" style="display: none;">Smart contracts are a key component of the Web 3.0 ecosystem, widely applied in blockchain services and decentralized applications. However, the automated execution feature of smart contracts makes them vulnerable to potential attacks due to inherent flaws, which can lead to severe security risks and financial losses, even threatening the integrity of the entire decentralized finance system. Currently, research on smart contract vulnerabilities has evolved from traditional program analysis methods to deep learning techniques, with the gradual introduction of Large Language Models. However, existing studies mainly focus on vulnerability detection, lacking systematic cause analysis and Vulnerability Repair. To address this gap, we propose LLM-BSCVM, a Large Language Model-based smart contract vulnerability management framework, designed to provide end-to-end vulnerability detection, analysis, repair, and evaluation capabilities for Web 3.0 ecosystem. LLM-BSCVM combines retrieval-augmented generation technology and multi-agent collaboration, introducing a three-stage method of Decompose-Retrieve-Generate. This approach enables smart contract vulnerability management through the collaborative efforts of six intelligent agents, specifically: vulnerability detection, cause analysis, repair suggestion generation, risk assessment, vulnerability repair, and patch evaluation. Experimental results demonstrate that LLM-BSCVM achieves a vulnerability detection accuracy and F1 score exceeding 91\% on benchmark datasets, comparable to the performance of state-of-the-art (SOTA) methods, while reducing the false positive rate from 7.2\% in SOTA methods to 5.1\%, thus enhancing the reliability of vulnerability management. Furthermore, LLM-BSCVM supports continuous security monitoring and governance of smart contracts through a knowledge base hot-swapping dynamic update mechanism.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #3cc377" title="Confidence: 9.0%">
                            Blockchain
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.1%">
                            LLMs
                        </span>
                <!-- Medicine: 3.3 -->
                    
                <!-- Federated Learning: 3.2 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -67.7087
                </span>
                <a href="https://arxiv.org/abs/2412.18208" target="_blank" rel="noopener noreferrer">Quantum framework for Reinforcement Learning: integrating Markov Decision Process, quantum arithmetic, and trajectory search</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Thet Htar Su, Shaswot Shresthamali, Masaaki Kondo
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper introduces a quantum framework for addressing reinforcement learning (RL) tasks, grounded in the quantum principles and leveraging a fully quantum model of the classical Markov Decision Process (MDP). By employing quantum concepts and a quantum search algorithm, this work presents the imp</span>
                
                <span class="abstract-full" style="display: none;">This paper introduces a quantum framework for addressing reinforcement learning (RL) tasks, grounded in the quantum principles and leveraging a fully quantum model of the classical Markov Decision Process (MDP). By employing quantum concepts and a quantum search algorithm, this work presents the implementation and optimization of the agent-environment interactions entirely within the quantum domain, eliminating reliance on classical computations. Key contributions include the quantum-based state transitions, return calculation, and trajectory search mechanism that utilize quantum principles to demonstrate the realization of RL processes through quantum phenomena. The implementation emphasizes the fundamental role of quantum superposition in enhancing computational efficiency for RL tasks. Results demonstrate the capacity of a quantum model to achieve quantum enhancement in RL, highlighting the potential of fully quantum implementations in decision-making tasks. This work not only underscores the applicability of quantum computing in machine learning but also contributes the field of quantum reinforcement learning (QRL) by offering a robust framework for understanding and exploiting quantum computing in RL systems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge high-confidence" style="background-color: #d37d97" title="Confidence: 76.2%">
                            Quantum Computing
                        </span>
                <!-- Medicine: 2.7 -->
                    
                <!-- Evolutionary Algorithms: 2.5 -->
                    
                <!-- Reinforcement Learning: 2.0 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                <!-- LLMs: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
    </div>
    
    
    <div id="jsonPopup" class="json-popup">
        <pre id="jsonContent"></pre>
        <button onclick="copyJson()">Copy to Clipboard</button>
        <button onclick="closePopup()">Close</button>
    </div>

    <script>
        function extractPaperData(paperElement) {
            const titleElement = paperElement.querySelector('.paper-title a');
            const metaElement = paperElement.querySelector('.paper-meta');
            const abstractElement = paperElement.querySelector('.paper-abstract');
            const tagsElement = paperElement.querySelector('.paper-tags');
            
            // Get the date from the parent date-section header
            const dateSection = paperElement.closest('.date-section');
            const dateText = dateSection.querySelector('.date-header').textContent.trim();
            
            const authorsText = metaElement.textContent.replace('Authors:', '').trim();
            
            const paperData = {
                title: titleElement.textContent,
                url: titleElement.href,
                authors: authorsText.split(',').map(author => author.trim()),
                created: dateText,
                abstract: abstractElement.querySelector('.abstract-full').textContent
            };
            
            return paperData;
        }

        function showJson(paperElement) {
            const popup = document.getElementById('jsonPopup');
            const content = document.getElementById('jsonContent');
            const paperData = extractPaperData(paperElement);
            content.textContent = JSON.stringify(paperData, null, null);
            popup.style.display = 'block';
            document.addEventListener('click', function closePopupOnClick(event) {
                if (!popup.contains(event.target)) {
                    popup.style.display = 'none';
                    document.removeEventListener('click', closePopupOnClick);
                }
            });
        }
        function toggleAbstract(element) {
            const abstract = element.parentElement;
            const short = abstract.querySelector('.abstract-short');
            const full = abstract.querySelector('.abstract-full');
            const lowConfidenceTags = abstract.parentElement.querySelectorAll('.tag-badge.low-confidence');
            
            if (element.textContent === '... more') {
                short.style.display = 'none';
                full.style.display = 'inline';
                element.textContent = ' less';
                lowConfidenceTags.forEach(tag => tag.style.display = 'inline-block');
            } else {
                short.style.display = 'inline';
                full.style.display = 'none';
                element.textContent = '... more';
                lowConfidenceTags.forEach(tag => tag.style.display = 'none');
            }
        }

        function closePopup() {
            document.getElementById('jsonPopup').style.display = 'none';
        }

        function copyJson() {
            const content = document.getElementById('jsonContent').textContent;
            navigator.clipboard.writeText(content).catch(() => {
                // If clipboard API is not available, just show the popup
                alert('Could not copy to clipboard. JSON is displayed in the popup.');
            });
        }

        // Close popup when clicking outside
        window.onclick = function(event) {
            const popup = document.getElementById('jsonPopup');
            if (event.target === popup) {
                popup.style.display = 'none';
            }
        }
    </script>
</body>
</html> 