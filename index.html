<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv Frontpage</title>
    <style>
        body {
            font-family: sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
        }
        .paper {
            margin-bottom: 30px;
            margin-top: 30px;
            padding: 20px;
            border: 1px solid #ddd;
            border-radius: 5px;
        }
        .paper-title {
            font-size: 1.2em;
            font-weight: bold;
            margin-bottom: 10px;
        }
        .paper-meta {
            color: #666;
            font-size: 0.9em;
            margin-bottom: 10px;
        }
        .paper-abstract {
            margin-bottom: 10px;
        }
        .abstract-short {
            display: inline;
        }
        .abstract-full {
            display: none;
        }
        .more-link {
            color: blue;
            cursor: pointer;
            text-decoration: underline;
        }
        .tag-badge {
            display: inline-block;
            padding: 3px 8px;
            margin-right: 5px;
            margin-bottom: 5px;
            border-radius: 3px;
            font-size: 0.8em;
            color: white;
        }
        .tag-badge.high-confidence {
            opacity: 1;
        }
        .tag-badge.low-confidence {
            opacity: 0.6;
            display: none;
        }
        .interestingness-score {
            display: inline-block;
            padding: 3px 8px;
            margin-right: 10px;
            color: white;
            border-radius: 3px;
            font-weight: bold;
        }
        .interestingness-positive {
            background-color: #4CAF50;
        }
        .interestingness-negative {
            background-color: #f44336;
        }
        .interestingness-neutral {
            background-color: #9e9e9e;
        }
        .last-updated {
            text-align: right;
            color: #666;
            font-size: 0.9em;
            margin-top: 20px;
            margin-bottom: 20px;
        }
        .intro {
            text-align: center;
            max-width: 60em;
            margin: 0 auto;
            color: #888;
        }
        .copy-icon {
            display: inline-block;
            width: 16px;
            height: 16px;
            cursor: pointer;
            margin-left: 5px;
            opacity: 0.5;
        }
        .copy-icon:hover {
            opacity: 1;
        }
        .json-popup {
            display: none;
            position: fixed;
            top: 20px;
            right: 20px;
            background: white;
            padding: 20px;
            border: 1px solid #ddd;
            border-radius: 5px;
            max-width: 500px;
            max-height: 300px;
            overflow: auto;
            box-shadow: 0 0 10px rgba(0,0,0,0.1);
        }
        a {
            color: inherit;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        h1 {
            text-align: center;
        }
        h1 a {
            text-decoration: underline;
        }
        .date-section {
            margin-bottom: 40px;
        }
        .date-header {
            color: #666;
            font-size: 1.5em;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 2px solid #eee;
        }
    </style>
</head>
<body>
    <h1>
        <a href="https://github.com/DataWraith/arxiv-frontpage">DataWraith's</a> ArXiv Frontpage
    </h1>

    <div class="last-updated">
        Last updated: 2025-04-18
    </div>

    <p class="intro">
        This frontpage is made by scraping ArXiv's computer science RSS feed and tagging papers with a classifier.
    </p>

    <p class="intro">
        Each tag is weighted according to my preferences to compute a paper's <i>interestingness</i> score.
    </p>
    
    
    <div class="date-section">
        <h2 class="date-header">2025-04-18</h2>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.134
                </span>
                <a href="https://arxiv.org/abs/2504.12691" target="_blank" rel="noopener noreferrer">Why and How LLMs Hallucinate: Connecting the Dots with Subsequence Associations</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yiyou Sun, Yu Gai, Lijie Chen, Abhilasha Ravichander, Yejin Choi, Dawn Song
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Large language models (LLMs) frequently generate hallucinations-content that deviates from factual accuracy or provided context-posing challenges for diagnosis due to the complex interplay of underlying causes. This paper introduces a subsequence association framework to systematically trace and und</span>
                
                <span class="abstract-full" style="display: none;">Large language models (LLMs) frequently generate hallucinations-content that deviates from factual accuracy or provided context-posing challenges for diagnosis due to the complex interplay of underlying causes. This paper introduces a subsequence association framework to systematically trace and understand hallucinations. Our key insight is that hallucinations arise when dominant hallucinatory associations outweigh faithful ones. Through theoretical and empirical analyses, we demonstrate that decoder-only transformers effectively function as subsequence embedding models, with linear layers encoding input-output associations. We propose a tracing algorithm that identifies causal subsequences by analyzing hallucination probabilities across randomized input contexts. Experiments show our method outperforms standard attribution techniques in identifying hallucination causes and aligns with evidence from the model's training corpus. This work provides a unified perspective on hallucinations and a robust framework for their tracing and analysis.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 14.7 -->
                    
                <!-- Medicine: 6.8 -->
                    
                <!-- Quantum Computing: 3.8 -->
                    
                <!-- 3D: 2.3 -->
                    
                <!-- Networks: 1.8 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- RAG: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- T2I: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.1397
                </span>
                <a href="https://arxiv.org/abs/2412.01113" target="_blank" rel="noopener noreferrer">Think-to-Talk or Talk-to-Think? When LLMs Come Up with an Answer in Multi-Step Arithmetic Reasoning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Keito Kudo, Yoichi Aoki, Tatsuki Kuribayashi, Shusaku Sone, Masaya Taniguchi, Ana Brassard, Keisuke Sakaguchi, Kentaro Inui
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This study investigates the internal reasoning process of language models during arithmetic multi-step reasoning, motivated by the question of when they internally form their answers during reasoning. Particularly, we inspect whether the answer is determined before or after chain-of-thought (CoT) be</span>
                
                <span class="abstract-full" style="display: none;">This study investigates the internal reasoning process of language models during arithmetic multi-step reasoning, motivated by the question of when they internally form their answers during reasoning. Particularly, we inspect whether the answer is determined before or after chain-of-thought (CoT) begins to determine whether models follow a post-hoc Think-to-Talk mode or a step-by-step Talk-to-Think mode of explanation. Through causal probing experiments in controlled arithmetic reasoning tasks, we found systematic internal reasoning patterns across models in our case study; for example, single-step subproblems are solved before CoT begins, and more complicated multi-step calculations are performed during CoT.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 19.6 -->
                    
                <!-- Medicine: 4.9 -->
                    
                <!-- Quantum Computing: 3.5 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Networks: 1.7 -->
                    
                <!-- RAG: 1.7 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Math: 1.4 -->
                    
                <!-- T2I: 1.2 -->
                    
                <!-- 3D: 1.1 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                <!-- Evolutionary Algorithms: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.1481
                </span>
                <a href="https://arxiv.org/abs/2504.12461" target="_blank" rel="noopener noreferrer">Rethinking Trust in AI Assistants for Software Development: A Critical Review</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Sebastian Baltes, Timo Speith, Brenda Chiteri, Seyedmoein Mohsenimofidi, Shalini Chakraborty, Daniel Buschek
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Trust is a fundamental concept in human decision-making and collaboration that has long been studied in philosophy and psychology. However, software engineering (SE) articles often use the term 'trust' informally - providing an explicit definition or embedding results in established trust models is </span>
                
                <span class="abstract-full" style="display: none;">Trust is a fundamental concept in human decision-making and collaboration that has long been studied in philosophy and psychology. However, software engineering (SE) articles often use the term 'trust' informally - providing an explicit definition or embedding results in established trust models is rare. In SE research on AI assistants, this practice culminates in equating trust with the likelihood of accepting generated content, which does not capture the full complexity of the trust concept. Without a common definition, true secondary research on trust is impossible. The objectives of our research were: (1) to present the psychological and philosophical foundations of human trust, (2) to systematically study how trust is conceptualized in SE and the related disciplines human-computer interaction and information systems, and (3) to discuss limitations of equating trust with content acceptance, outlining how SE research can adopt existing trust models to overcome the widespread informal use of the term 'trust'. We conducted a literature review across disciplines and a critical review of recent SE articles focusing on conceptualizations of trust. We found that trust is rarely defined or conceptualized in SE articles. Related disciplines commonly embed their methodology and results in established trust models, clearly distinguishing, for example, between initial trust and trust formation and discussing whether and when trust can be applied to AI assistants. Our study reveals a significant maturity gap of trust research in SE compared to related disciplines. We provide concrete recommendations on how SE researchers can adopt established trust models and instruments to study trust in AI assistants beyond the acceptance of generated software artifacts.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 10.4 -->
                    
                <!-- Medicine: 5.1 -->
                    
                <!-- Robotics: 2.5 -->
                    
                <!-- Quantum Computing: 2.3 -->
                    
                <!-- Networks: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Math: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.183
                </span>
                <a href="https://arxiv.org/abs/2504.12337" target="_blank" rel="noopener noreferrer">"It Listens Better Than My Therapist": Exploring Social Media Discourse on LLMs as Mental Health Tool</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Anna-Carolina Haensch
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The emergence of generative AI chatbots such as ChatGPT has prompted growing public and academic interest in their role as informal mental health support tools. While early rule-based systems have been around for several years, large language models (LLMs) offer new capabilities in conversational fl</span>
                
                <span class="abstract-full" style="display: none;">The emergence of generative AI chatbots such as ChatGPT has prompted growing public and academic interest in their role as informal mental health support tools. While early rule-based systems have been around for several years, large language models (LLMs) offer new capabilities in conversational fluency, empathy simulation, and availability. This study explores how users engage with LLMs as mental health tools by analyzing over 10,000 TikTok comments from videos referencing LLMs as mental health tools. Using a self-developed tiered coding schema and supervised classification models, we identify user experiences, attitudes, and recurring themes. Results show that nearly 20% of comments reflect personal use, with these users expressing overwhelmingly positive attitudes. Commonly cited benefits include accessibility, emotional support, and perceived therapeutic value. However, concerns around privacy, generic responses, and the lack of professional oversight remain prominent. It is important to note that the user feedback does not indicate which therapeutic framework, if any, the LLM-generated output aligns with. While the findings underscore the growing relevance of AI in everyday practices, they also highlight the urgent need for clinical and ethical scrutiny in the use of AI for mental health support.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 16.5 -->
                    
                <!-- Medicine: 7.2 -->
                    
                <!-- Quantum Computing: 3.5 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- Networks: 1.5 -->
                    
                <!-- Math: 1.3 -->
                    
                <!-- RAG: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.2603
                </span>
                <a href="https://arxiv.org/abs/2504.13038" target="_blank" rel="noopener noreferrer">How Large Language Models Are Changing MOOC Essay Answers: A Comparison of Pre- and Post-LLM Responses</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Leo Lepp\"anen, Lili Aunimo, Arto Hellas, Jukka K. Nurminen, Linda Mannila
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The release of ChatGPT in late 2022 caused a flurry of activity and concern in the academic and educational communities. Some see the tool's ability to generate human-like text that passes at least cursory inspections for factual accuracy ``often enough'' a golden age of information retrieval and co</span>
                
                <span class="abstract-full" style="display: none;">The release of ChatGPT in late 2022 caused a flurry of activity and concern in the academic and educational communities. Some see the tool's ability to generate human-like text that passes at least cursory inspections for factual accuracy ``often enough'' a golden age of information retrieval and computer-assisted learning. Some, on the other hand, worry the tool may lead to unprecedented levels of academic dishonesty and cheating. In this work, we quantify some of the effects of the emergence of Large Language Models (LLMs) on online education by analyzing a multi-year dataset of student essay responses from a free university-level MOOC on AI ethics. Our dataset includes essays submitted both before and after ChatGPT's release. We find that the launch of ChatGPT coincided with significant changes in both the length and style of student essays, mirroring observations in other contexts such as academic publishing. We also observe -- as expected based on related public discourse -- changes in prevalence of key content words related to AI and LLMs, but not necessarily the general themes or topics discussed in the student essays as identified through (dynamic) topic modeling.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 20.8 -->
                    
                <!-- Medicine: 4.7 -->
                    
                <!-- Quantum Computing: 2.5 -->
                    
                <!-- Reinforcement Learning: 2.3 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- Math: 1.4 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Pathfinding: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.3794
                </span>
                <a href="https://arxiv.org/abs/2504.12809" target="_blank" rel="noopener noreferrer">Saliency-Aware Diffusion Reconstruction for Effective Invisible Watermark Removal</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Inzamamul Alam, Md Tanvir Islam, Simon S. Woo
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">As digital content becomes increasingly ubiquitous, the need for robust watermark removal techniques has grown due to the inadequacy of existing embedding techniques, which lack robustness. This paper introduces a novel Saliency-Aware Diffusion Reconstruction (SADRE) framework for watermark eliminat</span>
                
                <span class="abstract-full" style="display: none;">As digital content becomes increasingly ubiquitous, the need for robust watermark removal techniques has grown due to the inadequacy of existing embedding techniques, which lack robustness. This paper introduces a novel Saliency-Aware Diffusion Reconstruction (SADRE) framework for watermark elimination on the web, combining adaptive noise injection, region-specific perturbations, and advanced diffusion-based reconstruction. SADRE disrupts embedded watermarks by injecting targeted noise into latent representations guided by saliency masks although preserving essential image features. A reverse diffusion process ensures high-fidelity image restoration, leveraging adaptive noise levels determined by watermark strength. Our framework is theoretically grounded with stability guarantees and achieves robust watermark removal across diverse scenarios. Empirical evaluations on state-of-the-art (SOTA) watermarking techniques demonstrate SADRE's superiority in balancing watermark disruption and image quality. SADRE sets a new benchmark for watermark elimination, offering a flexible and reliable solution for real-world web content. Code is available on~\href{https://github.com/inzamamulDU/SADRE}{\textbf{https://github.com/inzamamulDU/SADRE}}.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 10.3 -->
                    
                <!-- LLMs: 5.1 -->
                    
                <!-- Quantum Computing: 3.4 -->
                    
                <!-- Networks: 2.6 -->
                    
                <!-- 3D: 2.1 -->
                    
                <!-- RAG: 1.7 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- T2I: 1.5 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Math: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.4813
                </span>
                <a href="https://arxiv.org/abs/2411.07863" target="_blank" rel="noopener noreferrer">CDXLSTM: Boosting Remote Sensing Change Detection with Extended Long Short-Term Memory</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zhenkai Wu, Xiaowen Ma, Rongrong Lian, Kai Zheng, Wei Zhang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In complex scenes and varied conditions, effectively integrating spatial-temporal context is crucial for accurately identifying changes. However, current RS-CD methods lack a balanced consideration of performance and efficiency. CNNs lack global context, Transformers are computationally expensive, a</span>
                
                <span class="abstract-full" style="display: none;">In complex scenes and varied conditions, effectively integrating spatial-temporal context is crucial for accurately identifying changes. However, current RS-CD methods lack a balanced consideration of performance and efficiency. CNNs lack global context, Transformers are computationally expensive, and Mambas face CUDA dependence and local correlation loss. In this paper, we propose CDXLSTM, with a core component that is a powerful XLSTM-based feature enhancement layer, integrating the advantages of linear computational complexity, global context perception, and strong interpret-ability. Specifically, we introduce a scale-specific Feature Enhancer layer, incorporating a Cross-Temporal Global Perceptron customized for semantic-accurate deep features, and a Cross-Temporal Spatial Refiner customized for detail-rich shallow features. Additionally, we propose a Cross-Scale Interactive Fusion module to progressively interact global change representations with spatial responses. Extensive experimental results demonstrate that CDXLSTM achieves state-of-the-art performance across three benchmark datasets, offering a compelling balance between efficiency and accuracy. Code is available at https://github.com/xwmaxwma/rschange.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 10.8 -->
                    
                <!-- LLMs: 6.4 -->
                    
                <!-- 3D: 2.5 -->
                    
                <!-- Networks: 2.2 -->
                    
                <!-- Quantum Computing: 2.2 -->
                    
                <!-- GNN: 2.2 -->
                    
                <!-- T2I: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- RAG: 1.3 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Attention: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.6259
                </span>
                <a href="https://arxiv.org/abs/2504.12869" target="_blank" rel="noopener noreferrer">SC3EF: A Joint Self-Correlation and Cross-Correspondence Estimation Framework for Visible and Thermal Image Registration</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Xi Tong, Xing Luo, Jiangxin Yang, Yanpeng Cao
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Multispectral imaging plays a critical role in a range of intelligent transportation applications, including advanced driver assistance systems (ADAS), traffic monitoring, and night vision. However, accurate visible and thermal (RGB-T) image registration poses a significant challenge due to the cons</span>
                
                <span class="abstract-full" style="display: none;">Multispectral imaging plays a critical role in a range of intelligent transportation applications, including advanced driver assistance systems (ADAS), traffic monitoring, and night vision. However, accurate visible and thermal (RGB-T) image registration poses a significant challenge due to the considerable modality differences. In this paper, we present a novel joint Self-Correlation and Cross-Correspondence Estimation Framework (SC3EF), leveraging both local representative features and global contextual cues to effectively generate RGB-T correspondences. For this purpose, we design a convolution-transformer-based pipeline to extract local representative features and encode global correlations of intra-modality for inter-modality correspondence estimation between unaligned visible and thermal images. After merging the local and global correspondence estimation results, we further employ a hierarchical optical flow estimation decoder to progressively refine the estimated dense correspondence maps. Extensive experiments demonstrate the effectiveness of our proposed method, outperforming the current state-of-the-art (SOTA) methods on representative RGB-T datasets. Furthermore, it also shows competitive generalization capabilities across challenging scenarios, including large parallax, severe occlusions, adverse weather, and other cross-modal datasets (e.g., RGB-N and RGB-D).</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 10.5 -->
                    
                <!-- LLMs: 5.5 -->
                    
                <!-- 3D: 2.0 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- Networks: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- RAG: 1.3 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- T2I: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.6922
                </span>
                <a href="https://arxiv.org/abs/2504.12735" target="_blank" rel="noopener noreferrer">The Athenian Academy: A Seven-Layer Architecture Model for Multi-Agent Systems</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Lidong Zhai, Zhijie Qiu, Xizhong Guo, Jiaqi Li
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper proposes the "Academy of Athens" multi-agent seven-layer framework, aimed at systematically addressing challenges in multi-agent systems (MAS) within artificial intelligence (AI) art creation, such as collaboration efficiency, role allocation, environmental adaptation, and task parallelis</span>
                
                <span class="abstract-full" style="display: none;">This paper proposes the "Academy of Athens" multi-agent seven-layer framework, aimed at systematically addressing challenges in multi-agent systems (MAS) within artificial intelligence (AI) art creation, such as collaboration efficiency, role allocation, environmental adaptation, and task parallelism. The framework divides MAS into seven layers: multi-agent collaboration, single-agent multi-role playing, single-agent multi-scene traversal, single-agent multi-capability incarnation, different single agents using the same large model to achieve the same target agent, single-agent using different large models to achieve the same target agent, and multi-agent synthesis of the same target agent. Through experimental validation in art creation, the framework demonstrates its unique advantages in task collaboration, cross-scene adaptation, and model fusion. This paper further discusses current challenges such as collaboration mechanism optimization, model stability, and system security, proposing future exploration through technologies like meta-learning and federated learning. The framework provides a structured methodology for multi-agent collaboration in AI art creation and promotes innovative applications in the art field.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 10.4 -->
                    
                <!-- LLMs: 10.2 -->
                    
                <!-- Quantum Computing: 2.8 -->
                    
                <!-- Networks: 2.2 -->
                    
                <!-- Robotics: 2.2 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- RAG: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                <!-- T2I: 1.1 -->
                    
                <!-- Pathfinding: 1.1 -->
                    
                <!-- 3D: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.7742
                </span>
                <a href="https://arxiv.org/abs/2504.13078" target="_blank" rel="noopener noreferrer">Enhancing Person-to-Person Virtual Try-On with Multi-Garment Virtual Try-Off</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Riza Velioglu, Petra Bevandic, Robin Chan, Barbara Hammer
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Computer vision is transforming fashion through Virtual Try-On (VTON) and Virtual Try-Off (VTOFF). VTON generates images of a person in a specified garment using a target photo and a standardized garment image, while a more challenging variant, Person-to-Person Virtual Try-On (p2p-VTON), uses a phot</span>
                
                <span class="abstract-full" style="display: none;">Computer vision is transforming fashion through Virtual Try-On (VTON) and Virtual Try-Off (VTOFF). VTON generates images of a person in a specified garment using a target photo and a standardized garment image, while a more challenging variant, Person-to-Person Virtual Try-On (p2p-VTON), uses a photo of another person wearing the garment. VTOFF, on the other hand, extracts standardized garment images from clothed individuals. We introduce TryOffDiff, a diffusion-based VTOFF model. Built on a latent diffusion framework with SigLIP image conditioning, it effectively captures garment properties like texture, shape, and patterns. TryOffDiff achieves state-of-the-art results on VITON-HD and strong performance on DressCode dataset, covering upper-body, lower-body, and dresses. Enhanced with class-specific embeddings, it pioneers multi-garment VTOFF, the first of its kind. When paired with VTON models, it improves p2p-VTON by minimizing unwanted attribute transfer, such as skin color. Code is available at: https://rizavelioglu.github.io/tryoffdiff/</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 10.2 -->
                    
                <!-- LLMs: 4.2 -->
                    
                <!-- Networks: 2.7 -->
                    
                <!-- Quantum Computing: 2.6 -->
                    
                <!-- 3D: 2.2 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Reinforcement Learning: 1.8 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- T2I: 1.2 -->
                    
                <!-- Math: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.8035
                </span>
                <a href="https://arxiv.org/abs/2504.13069" target="_blank" rel="noopener noreferrer">Early Accessibility: Automating Alt-Text Generation for UI Icons During App Development</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Sabrina Haque, Christoph Csallner
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Alt-text is essential for mobile app accessibility, yet UI icons often lack meaningful descriptions, limiting accessibility for screen reader users. Existing approaches either require extensive labeled datasets, struggle with partial UI contexts, or operate post-development, increasing technical deb</span>
                
                <span class="abstract-full" style="display: none;">Alt-text is essential for mobile app accessibility, yet UI icons often lack meaningful descriptions, limiting accessibility for screen reader users. Existing approaches either require extensive labeled datasets, struggle with partial UI contexts, or operate post-development, increasing technical debt. We first conduct a formative study to determine when and how developers prefer to generate icon alt-text. We then explore the ALTICON approach for generating alt-text for UI icons during development using two fine-tuned models: a text-only large language model that processes extracted UI metadata and a multi-modal model that jointly analyzes icon images and textual context. To improve accuracy, the method extracts relevant UI information from the DOM tree, retrieves in-icon text via OCR, and applies structured prompts for alt-text generation. Our empirical evaluation with the most closely related deep-learning and vision-language models shows that ALTICON generates alt-text that is of higher quality while not requiring a full-screen input.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 11.2 -->
                    
                <!-- LLMs: 7.7 -->
                    
                <!-- Quantum Computing: 3.2 -->
                    
                <!-- Networks: 2.1 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- RAG: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- T2I: 1.1 -->
                    
                <!-- Math: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.8301
                </span>
                <a href="https://arxiv.org/abs/2504.12670" target="_blank" rel="noopener noreferrer">Temporal Attention Pooling for Frequency Dynamic Convolution in Sound Event Detection</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Hyeonuk Nam, Yong-Hwa Park
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Recent advances in deep learning, particularly frequency dynamic convolution (FDY conv), have significantly improved sound event detection (SED) by enabling frequency-adaptive feature extraction. However, FDY conv relies on temporal average pooling, which treats all temporal frames equally, limiting</span>
                
                <span class="abstract-full" style="display: none;">Recent advances in deep learning, particularly frequency dynamic convolution (FDY conv), have significantly improved sound event detection (SED) by enabling frequency-adaptive feature extraction. However, FDY conv relies on temporal average pooling, which treats all temporal frames equally, limiting its ability to capture transient sound events such as alarm bells, door knocks, and speech plosives. To address this limitation, we propose temporal attention pooling frequency dynamic convolution (TFD conv) to replace temporal average pooling with temporal attention pooling (TAP). TAP adaptively weights temporal features through three complementary mechanisms: time attention pooling (TA) for emphasizing salient features, velocity attention pooling (VA) for capturing transient changes, and conventional average pooling for robustness to stationary signals. Ablation studies show that TFD conv improves average PSDS1 by 3.02% over FDY conv with only a 14.8% increase in parameter count. Classwise ANOVA and Tukey HSD analysis further demonstrate that TFD conv significantly enhances detection performance for transient-heavy events, outperforming existing FDY conv models. Notably, TFD conv achieves a maximum PSDS1 score of 0.456, surpassing previous state-of-the-art SED systems. We also explore the compatibility of TAP with other FDY conv variants, including dilated FDY conv (DFD conv), partial FDY conv (PFD conv), and multi-dilated FDY conv (MDFD conv). Among these, the integration of TAP with MDFD conv achieves the best result with a PSDS1 score of 0.459, validating the complementary strengths of temporal attention and multi-scale frequency adaptation. These findings establish TFD conv as a powerful and generalizable framework for enhancing both transient sensitivity and overall feature robustness in SED.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 12.3 -->
                    
                <!-- LLMs: 7.0 -->
                    
                <!-- Quantum Computing: 3.3 -->
                    
                <!-- Networks: 1.8 -->
                    
                <!-- T2I: 1.5 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- RAG: 1.4 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Attention: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- Evolutionary Algorithms: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.8676
                </span>
                <a href="https://arxiv.org/abs/2408.11054" target="_blank" rel="noopener noreferrer">Near, far: Patch-ordering enhances vision foundation models' scene understanding</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Valentinos Pariza, Mohammadreza Salehi, Gertjan Burghouts, Francesco Locatello, Yuki M. Asano
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We introduce NeCo: Patch Neighbor Consistency, a novel self-supervised training loss that enforces patch-level nearest neighbor consistency across a student and teacher model. Compared to contrastive approaches that only yield binary learning signals, i.e., 'attract' and 'repel', this approach benef</span>
                
                <span class="abstract-full" style="display: none;">We introduce NeCo: Patch Neighbor Consistency, a novel self-supervised training loss that enforces patch-level nearest neighbor consistency across a student and teacher model. Compared to contrastive approaches that only yield binary learning signals, i.e., 'attract' and 'repel', this approach benefits from the more fine-grained learning signal of sorting spatially dense features relative to reference patches. Our method leverages differentiable sorting applied on top of pretrained representations, such as DINOv2-registers to bootstrap the learning signal and further improve upon them. This dense post-pretraining leads to superior performance across various models and datasets, despite requiring only 19 hours on a single GPU. This method generates high-quality dense feature encoders and establishes several new state-of-the-art results such as +5.5% and +6% for non-parametric in-context semantic segmentation on ADE20k and Pascal VOC, +7.2% and +5.7% for linear segmentation evaluations on COCO-Things and -Stuff and improvements in the 3D understanding of multi-view consistency on SPair-71k, by more than 1.5%.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 10.5 -->
                    
                <!-- LLMs: 6.6 -->
                    
                <!-- Quantum Computing: 2.7 -->
                    
                <!-- 3D: 2.7 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Networks: 1.5 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- RAG: 1.4 -->
                    
                <!-- T2I: 1.1 -->
                    
                <!-- GNN: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.8783
                </span>
                <a href="https://arxiv.org/abs/2504.13161" target="_blank" rel="noopener noreferrer">CLIMB: CLustering-based Iterative Data Mixture Bootstrapping for Language Model Pre-training</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Shizhe Diao (Celine), Yu Yang (Celine), Yonggan Fu (Celine), Xin Dong (Celine), Dan Su (Celine), Markus Kliegl (Celine), Zijia Chen (Celine), Peter Belcak (Celine), Yoshi Suhara (Celine), Hongxu Yin (Celine), Mostofa Patwary (Celine), Yingyan (Celine), Lin, Jan Kautz, Pavlo Molchanov
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Pre-training datasets are typically collected from web content and lack inherent domain divisions. For instance, widely used datasets like Common Crawl do not include explicit domain labels, while manually curating labeled datasets such as The Pile is labor-intensive. Consequently, identifying an op</span>
                
                <span class="abstract-full" style="display: none;">Pre-training datasets are typically collected from web content and lack inherent domain divisions. For instance, widely used datasets like Common Crawl do not include explicit domain labels, while manually curating labeled datasets such as The Pile is labor-intensive. Consequently, identifying an optimal pre-training data mixture remains a challenging problem, despite its significant benefits for pre-training performance. To address these challenges, we propose CLustering-based Iterative Data Mixture Bootstrapping (CLIMB), an automated framework that discovers, evaluates, and refines data mixtures in a pre-training setting. Specifically, CLIMB embeds and clusters large-scale datasets in a semantic space and then iteratively searches for optimal mixtures using a smaller proxy model and a predictor. When continuously trained on 400B tokens with this mixture, our 1B model exceeds the state-of-the-art Llama-3.2-1B by 2.0%. Moreover, we observe that optimizing for a specific domain (e.g., Social Sciences) yields a 5% improvement over random sampling. Finally, we introduce ClimbLab, a filtered 1.2-trillion-token corpus with 20 clusters as a research playground, and ClimbMix, a compact yet powerful 400-billion-token dataset designed for efficient pre-training that delivers superior performance under an equal token budget. We analyze the final data mixture, elucidating the characteristics of an optimal data mixture. Our data is available at: https://research.nvidia.com/labs/lpr/climb/</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 11.5 -->
                    
                <!-- LLMs: 4.1 -->
                    
                <!-- Quantum Computing: 2.9 -->
                    
                <!-- Networks: 2.3 -->
                    
                <!-- 3D: 2.1 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- T2I: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- RAG: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.0363
                </span>
                <a href="https://arxiv.org/abs/2504.12619" target="_blank" rel="noopener noreferrer">SAM-Based Building Change Detection with Distribution-Aware Fourier Adaptation and Edge-Constrained Warping</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yun-Cheng Li, Sen Lei, Yi-Tao Zhao, Heng-Chao Li, Jun Li, Antonio Plaza
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Building change detection remains challenging for urban development, disaster assessment, and military reconnaissance. While foundation models like Segment Anything Model (SAM) show strong segmentation capabilities, SAM is limited in the task of building change detection due to domain gap issues. Ex</span>
                
                <span class="abstract-full" style="display: none;">Building change detection remains challenging for urban development, disaster assessment, and military reconnaissance. While foundation models like Segment Anything Model (SAM) show strong segmentation capabilities, SAM is limited in the task of building change detection due to domain gap issues. Existing adapter-based fine-tuning approaches face challenges with imbalanced building distribution, resulting in poor detection of subtle changes and inaccurate edge extraction. Additionally, bi-temporal misalignment in change detection, typically addressed by optical flow, remains vulnerable to background noises. This affects the detection of building changes and compromises both detection accuracy and edge recognition. To tackle these challenges, we propose a new SAM-Based Network with Distribution-Aware Fourier Adaptation and Edge-Constrained Warping (FAEWNet) for building change detection. FAEWNet utilizes the SAM encoder to extract rich visual features from remote sensing images. To guide SAM in focusing on specific ground objects in remote sensing scenes, we propose a Distribution-Aware Fourier Aggregated Adapter to aggregate task-oriented changed information. This adapter not only effectively addresses the domain gap issue, but also pays attention to the distribution of changed buildings. Furthermore, to mitigate noise interference and misalignment in height offset estimation, we design a novel flow module that refines building edge extraction and enhances the perception of changed buildings. Our state-of-the-art results on the LEVIR-CD, S2Looking and WHU-CD datasets highlight the effectiveness of FAEWNet. The code is available at https://github.com/SUPERMAN123000/FAEWNet.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 11.1 -->
                    
                <!-- LLMs: 7.3 -->
                    
                <!-- Quantum Computing: 2.3 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Networks: 1.5 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- T2I: 1.1 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                <!-- RAG: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.0934
                </span>
                <a href="https://arxiv.org/abs/2504.13026" target="_blank" rel="noopener noreferrer">TTRD3: Texture Transfer Residual Denoising Dual Diffusion Model for Remote Sensing Image Super-Resolution</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yide Liu, Haijiang Sun, Xiaowen Zhang, Qiaoyuan Liu, Zhouchang Chen, Chongzhuo Xiao
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Remote Sensing Image Super-Resolution (RSISR) reconstructs high-resolution (HR) remote sensing images from low-resolution inputs to support fine-grained ground object interpretation. Existing methods face three key challenges: (1) Difficulty in extracting multi-scale features from spatially heteroge</span>
                
                <span class="abstract-full" style="display: none;">Remote Sensing Image Super-Resolution (RSISR) reconstructs high-resolution (HR) remote sensing images from low-resolution inputs to support fine-grained ground object interpretation. Existing methods face three key challenges: (1) Difficulty in extracting multi-scale features from spatially heterogeneous RS scenes, (2) Limited prior information causing semantic inconsistency in reconstructions, and (3) Trade-off imbalance between geometric accuracy and visual quality. To address these issues, we propose the Texture Transfer Residual Denoising Dual Diffusion Model (TTRD3) with three innovations: First, a Multi-scale Feature Aggregation Block (MFAB) employing parallel heterogeneous convolutional kernels for multi-scale feature extraction. Second, a Sparse Texture Transfer Guidance (STTG) module that transfers HR texture priors from reference images of similar scenes. Third, a Residual Denoising Dual Diffusion Model (RDDM) framework combining residual diffusion for deterministic reconstruction and noise diffusion for diverse generation. Experiments on multi-source RS datasets demonstrate TTRD3's superiority over state-of-the-art methods, achieving 1.43% LPIPS improvement and 3.67% FID enhancement compared to best-performing baselines. Code/model: https://github.com/LED-666/TTRD3.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 12.4 -->
                    
                <!-- LLMs: 6.7 -->
                    
                <!-- Quantum Computing: 3.5 -->
                    
                <!-- 3D: 3.3 -->
                    
                <!-- RAG: 2.4 -->
                    
                <!-- Networks: 2.3 -->
                    
                <!-- T2I: 2.1 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.1244
                </span>
                <a href="https://arxiv.org/abs/2412.05486" target="_blank" rel="noopener noreferrer">Listen to Your Map: An Online Representation for Spatial Sonification</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Lan Wu, Craig Jin, Monisha Mushtary Uttsha, Teresa Vidal-Calleja
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Robotic perception is becoming a key technology for navigation aids, especially helping individuals with visual impairments through spatial sonification. This paper introduces a mapping representation that accurately captures scene geometry for sonification, turning physical spaces into auditory exp</span>
                
                <span class="abstract-full" style="display: none;">Robotic perception is becoming a key technology for navigation aids, especially helping individuals with visual impairments through spatial sonification. This paper introduces a mapping representation that accurately captures scene geometry for sonification, turning physical spaces into auditory experiences. Using depth sensors, we encode an incrementally built 3D scene into a compact 360-degree representation with angular and distance information, aligning this way with human auditory spatial perception. The proposed framework performs localisation and mapping via VDB-Gaussian Process Distance Fields for efficient online scene reconstruction. The key aspect is a sensor-centric structure that maintains either a 2D-circular or 3D-cylindrical raster-based projection. This spatial representation is then converted into binaural auditory signals using simple pre-recorded responses from a representative room. Quantitative and qualitative evaluations show improvements in accuracy, coverage, timing and suitability for sonification compared to other approaches, with effective handling of dynamic objects as well. An accompanying video demonstrates spatial sonification in room-like environments. https://tinyurl.com/ListenToYourMap</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 12.5 -->
                    
                <!-- LLMs: 4.8 -->
                    
                <!-- Quantum Computing: 3.7 -->
                    
                <!-- Networks: 3.3 -->
                    
                <!-- 3D: 3.2 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- Robotics: 1.7 -->
                    
                <!-- T2I: 1.5 -->
                    
                <!-- RAG: 1.5 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.1502
                </span>
                <a href="https://arxiv.org/abs/2504.12452" target="_blank" rel="noopener noreferrer">PlanGlow: Personalized Study Planning with an Explainable and Controllable LLM-Driven System</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jiwon Chun, Yankun Zhao, Hanlin Chen, Meng Xia
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Personal development through self-directed learning is essential in today's fast-changing world, but many learners struggle to manage it effectively. While AI tools like large language models (LLMs) have the potential for personalized learning planning, they face issues such as transparency and hall</span>
                
                <span class="abstract-full" style="display: none;">Personal development through self-directed learning is essential in today's fast-changing world, but many learners struggle to manage it effectively. While AI tools like large language models (LLMs) have the potential for personalized learning planning, they face issues such as transparency and hallucinated information. To address this, we propose PlanGlow, an LLM-based system that generates personalized, well-structured study plans with clear explanations and controllability through user-centered interactions. Through mixed methods, we surveyed 28 participants and interviewed 10 before development, followed by a within-subject experiment with 24 participants to evaluate PlanGlow's performance, usability, controllability, and explainability against two baseline systems: a GPT-4o-based system and Khan Academy's Khanmigo. Results demonstrate that PlanGlow significantly improves usability, explainability, and controllability. Additionally, two educational experts assessed and confirmed the quality of the generated study plans. These findings highlight PlanGlow's potential to enhance personalized learning and address key challenges in self-directed learning.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 13.0 -->
                    
                <!-- Medicine: 12.2 -->
                    
                <!-- Quantum Computing: 2.4 -->
                    
                <!-- RAG: 2.0 -->
                    
                <!-- 3D: 1.8 -->
                    
                <!-- Networks: 1.6 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- T2I: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.1592
                </span>
                <a href="https://arxiv.org/abs/2504.12492" target="_blank" rel="noopener noreferrer">MobilePoser: Real-Time Full-Body Pose Estimation and 3D Human Translation from IMUs in Mobile Consumer Devices</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Vasco Xu, Chenfeng Gao, Henry Hoffmann, Karan Ahuja
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">There has been a continued trend towards minimizing instrumentation for full-body motion capture, going from specialized rooms and equipment, to arrays of worn sensors and recently sparse inertial pose capture methods. However, as these techniques migrate towards lower-fidelity IMUs on ubiquitous co</span>
                
                <span class="abstract-full" style="display: none;">There has been a continued trend towards minimizing instrumentation for full-body motion capture, going from specialized rooms and equipment, to arrays of worn sensors and recently sparse inertial pose capture methods. However, as these techniques migrate towards lower-fidelity IMUs on ubiquitous commodity devices, like phones, watches, and earbuds, challenges arise including compromised online performance, temporal consistency, and loss of global translation due to sensor noise and drift. Addressing these challenges, we introduce MobilePoser, a real-time system for full-body pose and global translation estimation using any available subset of IMUs already present in these consumer devices. MobilePoser employs a multi-stage deep neural network for kinematic pose estimation followed by a physics-based motion optimizer, achieving state-of-the-art accuracy while remaining lightweight. We conclude with a series of demonstrative applications to illustrate the unique potential of MobilePoser across a variety of fields, such as health and wellness, gaming, and indoor navigation to name a few.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 10.5 -->
                    
                <!-- LLMs: 5.6 -->
                    
                <!-- Quantum Computing: 3.1 -->
                    
                <!-- 3D: 2.4 -->
                    
                <!-- Robotics: 2.1 -->
                    
                <!-- Networks: 1.9 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- RAG: 1.2 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.226
                </span>
                <a href="https://arxiv.org/abs/2504.12717" target="_blank" rel="noopener noreferrer">Post-pre-training for Modality Alignment in Vision-Language Foundation Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Shin'ya Yamaguchi, Dewei Feng, Sekitoshi Kanai, Kazuki Adachi, Daiki Chijiwa
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Contrastive language image pre-training (CLIP) is an essential component of building modern vision-language foundation models. While CLIP demonstrates remarkable zero-shot performance on downstream tasks, the multi-modal feature spaces still suffer from a modality gap, which is a gap between image a</span>
                
                <span class="abstract-full" style="display: none;">Contrastive language image pre-training (CLIP) is an essential component of building modern vision-language foundation models. While CLIP demonstrates remarkable zero-shot performance on downstream tasks, the multi-modal feature spaces still suffer from a modality gap, which is a gap between image and text feature clusters and limits downstream task performance. Although existing works attempt to address the modality gap by modifying pre-training or fine-tuning, they struggle with heavy training costs with large datasets or degradations of zero-shot performance. This paper presents CLIP-Refine, a post-pre-training method for CLIP models at a phase between pre-training and fine-tuning. CLIP-Refine aims to align the feature space with 1 epoch training on small image-text datasets without zero-shot performance degradations. To this end, we introduce two techniques: random feature alignment (RaFA) and hybrid contrastive-distillation (HyCD). RaFA aligns the image and text features to follow a shared prior distribution by minimizing the distance to random reference vectors sampled from the prior. HyCD updates the model with hybrid soft labels generated by combining ground-truth image-text pair labels and outputs from the pre-trained CLIP model. This contributes to achieving both maintaining the past knowledge and learning new knowledge to align features. Our extensive experiments with multiple classification and retrieval tasks show that CLIP-Refine succeeds in mitigating the modality gap and improving the zero-shot performance.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 10.8 -->
                    
                <!-- LLMs: 4.6 -->
                    
                <!-- Reinforcement Learning: 2.1 -->
                    
                <!-- Networks: 1.9 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- RAG: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.3161
                </span>
                <a href="https://arxiv.org/abs/2502.04991" target="_blank" rel="noopener noreferrer">C2GM: Cascading conditional generative cartography framework for multi-scale tile map generation with geographic feature constraints</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Chenxing Sun, Yongyang Xu, Xuwei Xu, Xixi Fan, Jing Bai, Xiechun Lu, Zhanlong Chen
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Multi-scale maps are essential representations of surveying and cartographic results, serving as fundamental components of geographic services. Current image generation networks can quickly produce map tiles from remote-sensing images. However, generative models designed for natural images often foc</span>
                
                <span class="abstract-full" style="display: none;">Multi-scale maps are essential representations of surveying and cartographic results, serving as fundamental components of geographic services. Current image generation networks can quickly produce map tiles from remote-sensing images. However, generative models designed for natural images often focus on texture features, neglecting the unique characteristics of remote-sensing features and the scale attributes of tile maps. This limitation in generative models impairs the accurate representation of geographic information, and the quality of tile map generation still needs improvement. Diffusion models have demonstrated remarkable success in various image generation tasks, highlighting their potential to address this challenge. This paper presents C2GM, a novel framework for generating multi-scale tile maps through conditional guided diffusion and multi-scale cascade generation. Specifically, we implement a conditional feature fusion encoder to extract object priors from remote sensing images and cascade reference double branch input, ensuring an accurate representation of complex features. Low-level generated tiles act as constraints for high-level map generation, enhancing visual continuity. Moreover, we incorporate map scale modality information using CLIP to simulate the relationship between map scale and cartographic generalization in tile maps. Extensive experimental evaluations demonstrate that C2GM consistently achieves the state-of-the-art (SOTA) performance on all metrics, facilitating the rapid and effective generation of multi-scale large-format maps for emergency response and remote mapping applications.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 12.2 -->
                    
                <!-- LLMs: 8.9 -->
                    
                <!-- Quantum Computing: 2.8 -->
                    
                <!-- T2I: 1.7 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- Networks: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- RAG: 1.2 -->
                    
                <!-- Math: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.3168
                </span>
                <a href="https://arxiv.org/abs/2504.06755" target="_blank" rel="noopener noreferrer">FANeRV: Frequency Separation and Augmentation based Neural Representation for Video</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Li Yu, Zhihui Li, Jimin Xiao, Moncef Gabbouj
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Neural representations for video (NeRV) have gained considerable attention for their strong performance across various video tasks. However, existing NeRV methods often struggle to capture fine spatial details, resulting in vague reconstructions. In this paper, we present a Frequency Separation and </span>
                
                <span class="abstract-full" style="display: none;">Neural representations for video (NeRV) have gained considerable attention for their strong performance across various video tasks. However, existing NeRV methods often struggle to capture fine spatial details, resulting in vague reconstructions. In this paper, we present a Frequency Separation and Augmentation based Neural Representation for video (FANeRV), which addresses these limitations with its core Wavelet Frequency Upgrade Block. This block explicitly separates input frames into high and low-frequency components using discrete wavelet transform, followed by targeted enhancement using specialized modules. Finally, a specially designed gated network effectively fuses these frequency components for optimal reconstruction. Additionally, convolutional residual enhancement blocks are integrated into the later stages of the network to balance parameter distribution and improve the restoration of high-frequency details. Experimental results demonstrate that FANeRV significantly improves reconstruction performance and excels in multiple tasks, including video compression, inpainting, and interpolation, outperforming existing NeRV methods.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 13.3 -->
                    
                <!-- LLMs: 6.9 -->
                    
                <!-- Quantum Computing: 3.5 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Networks: 1.7 -->
                    
                <!-- RAG: 1.6 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- T2I: 1.3 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.4621
                </span>
                <a href="https://arxiv.org/abs/2504.12749" target="_blank" rel="noopener noreferrer">LAD-Reasoner: Tiny Multimodal Models are Good Reasoners for Logical Anomaly Detection</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Weijia Li, Guanglei Chu, Jiong Chen, Guo-Sen Xie, Caifeng Shan, Fang Zhao
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Recent advances in industrial anomaly detection have highlighted the need for deeper logical anomaly analysis, where unexpected relationships among objects, counts, and spatial configurations must be identified and explained. Existing approaches often rely on large-scale external reasoning modules o</span>
                
                <span class="abstract-full" style="display: none;">Recent advances in industrial anomaly detection have highlighted the need for deeper logical anomaly analysis, where unexpected relationships among objects, counts, and spatial configurations must be identified and explained. Existing approaches often rely on large-scale external reasoning modules or elaborate pipeline designs, hindering practical deployment and interpretability. To address these limitations, we introduce a new task, Reasoning Logical Anomaly Detection (RLAD), which extends traditional anomaly detection by incorporating logical reasoning. We propose a new framework, LAD-Reasoner, a customized tiny multimodal language model built on Qwen2.5-VL 3B. Our approach leverages a two-stage training paradigm that first employs Supervised Fine-Tuning (SFT) for fine-grained visual understanding, followed by Group Relative Policy Optimization (GRPO) to refine logical anomaly detection and enforce coherent, human-readable reasoning. Crucially, reward signals are derived from both the detection accuracy and the structural quality of the outputs, obviating the need for building chain of thought (CoT) reasoning data. Experiments on the MVTec LOCO AD dataset show that LAD-Reasoner, though significantly smaller, matches the performance of Qwen2.5-VL-72B in accuracy and F1 score, and further excels in producing concise and interpretable rationales. This unified design reduces reliance on large models and complex pipelines, while offering transparent and interpretable insights into logical anomaly detection. Code and data will be released.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 12.7 -->
                    
                <!-- LLMs: 7.6 -->
                    
                <!-- Quantum Computing: 2.2 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- RAG: 1.2 -->
                    
                <!-- Networks: 1.2 -->
                    
                <!-- T2I: 1.1 -->
                    
                <!-- Math: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.4868
                </span>
                <a href="https://arxiv.org/abs/2504.12309" target="_blank" rel="noopener noreferrer">Large Language Model-Based Knowledge Graph System Construction for Sustainable Development Goals: An AI-Based Speculative Design Perspective</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yi-De Lin, Guan-Ze Liao
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">From 2000 to 2015, the UN's Millennium Development Goals guided global priorities. The subsequent Sustainable Development Goals (SDGs) adopted a more dynamic approach, with annual indicator updates. As 2030 nears and progress lags, innovative acceleration strategies are critical. This study develops</span>
                
                <span class="abstract-full" style="display: none;">From 2000 to 2015, the UN's Millennium Development Goals guided global priorities. The subsequent Sustainable Development Goals (SDGs) adopted a more dynamic approach, with annual indicator updates. As 2030 nears and progress lags, innovative acceleration strategies are critical. This study develops an AI-powered knowledge graph system to analyze SDG interconnections, discover potential new goals, and visualize them online. Using official SDG texts, Elsevier's keyword dataset, and 1,127 TED Talk transcripts (2020-2023), a pilot on 269 talks from 2023 applies AI-speculative design, large language models, and retrieval-augmented generation. Key findings include: (1) Heatmap analysis reveals strong associations between Goal 10 and Goal 16, and minimal coverage of Goal 6. (2) In the knowledge graph, simulated dialogue over time reveals new central nodes, showing how richer data supports divergent thinking and goal clarity. (3) Six potential new goals are proposed, centered on equity, resilience, and technology-driven inclusion. This speculative-AI framework offers fresh insights for policymakers and lays groundwork for future multimodal and cross-system SDG applications.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 14.7 -->
                    
                <!-- LLMs: 11.7 -->
                    
                <!-- Quantum Computing: 2.7 -->
                    
                <!-- RAG: 2.0 -->
                    
                <!-- 3D: 2.0 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Networks: 1.6 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- T2I: 1.4 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- Datasets: 1.0 -->
                    
                <!-- Evolutionary Algorithms: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.8211
                </span>
                <a href="https://arxiv.org/abs/2504.12891" target="_blank" rel="noopener noreferrer">Are AI agents the new machine translation frontier? Challenges and opportunities of single- and multi-agent systems for multilingual digital communication</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Vicent Briva-Iglesias
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The rapid evolution of artificial intelligence (AI) has introduced AI agents as a disruptive paradigm across various industries, yet their application in machine translation (MT) remains underexplored. This paper describes and analyses the potential of single- and multi-agent systems for MT, reflect</span>
                
                <span class="abstract-full" style="display: none;">The rapid evolution of artificial intelligence (AI) has introduced AI agents as a disruptive paradigm across various industries, yet their application in machine translation (MT) remains underexplored. This paper describes and analyses the potential of single- and multi-agent systems for MT, reflecting on how they could enhance multilingual digital communication. While single-agent systems are well-suited for simpler translation tasks, multi-agent systems, which involve multiple specialized AI agents collaborating in a structured manner, may offer a promising solution for complex scenarios requiring high accuracy, domain-specific knowledge, and contextual awareness. To demonstrate the feasibility of multi-agent workflows in MT, we are conducting a pilot study in legal MT. The study employs a multi-agent system involving four specialized AI agents for (i) translation, (ii) adequacy review, (iii) fluency review, and (iv) final editing. Our findings suggest that multi-agent systems may have the potential to significantly improve domain-adaptability and contextual awareness, with superior translation quality to traditional MT or single-agent systems. This paper also sets the stage for future research into multi-agent applications in MT, integration into professional translation workflows, and shares a demo of the system analyzed in the paper.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 11.5 -->
                    
                <!-- LLMs: 4.9 -->
                    
                <!-- Quantum Computing: 3.0 -->
                    
                <!-- Networks: 2.2 -->
                    
                <!-- Robotics: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- RAG: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.8698
                </span>
                <a href="https://arxiv.org/abs/2504.06998" target="_blank" rel="noopener noreferrer">A Krylov projection algorithm for large symmetric matrices with dense spectra</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Vladimir Druskin, J\"orn Zimmerling
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We consider the approximation of $B^T (A+sI)^{-1} B$ for large s.p.d. $A\in\mathbb{R}^{n\times n}$ with dense spectrum and $B\in\mathbb{R}^{n\times p}$, $p\ll n$. We target the computations of Multiple-Input Multiple-Output (MIMO) transfer functions for large-scale discretizations of problems with c</span>
                
                <span class="abstract-full" style="display: none;">We consider the approximation of $B^T (A+sI)^{-1} B$ for large s.p.d. $A\in\mathbb{R}^{n\times n}$ with dense spectrum and $B\in\mathbb{R}^{n\times p}$, $p\ll n$. We target the computations of Multiple-Input Multiple-Output (MIMO) transfer functions for large-scale discretizations of problems with continuous spectral measures, such as linear time-invariant (LTI) PDEs on unbounded domains. Traditional Krylov methods, such as the Lanczos or CG algorithm, are known to be optimal for the computation of $(A+sI)^{-1}B$ with real positive $s$, resulting in an adaptation to the distinctively discrete and nonuniform spectra. However, the adaptation is damped for matrices with dense spectra. It was demonstrated in [Zimmerling, Druskin, Simoncini, Journal of Scientific Computing 103(1), 5 (2025)] that averaging Gau{\ss} and Gau\ss -Radau quadratures computed using the block-Lanczos method significantly reduces approximation errors for such problems. Here, we introduce an adaptive Kre\u{i}n-Nudelman extension to the (block) Lanczos recursions, allowing further acceleration at negligible $o(n)$ cost. Similar to the Gau\ss -Radau quadrature, a low-rank modification is applied to the (block) Lanczos matrix. However, unlike the Gau\ss -Radau quadrature, this modification depends on $\sqrt{s}$ and can be considered in the framework of the Hermite-Pad\'e approximants, which are known to be efficient for problems with branch-cuts, that can be good approximations to dense spectral intervals. Numerical results for large-scale discretizations of heat-diffusion and quasi-magnetostatic Maxwell's operators in unbounded domains confirm the efficiency of the proposed approach.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge high-confidence" style="background-color: #a49950" title="Confidence: 77.4%">
                            Math
                        </span>
                <!-- Medicine: 5.1 -->
                    
                <!-- LLMs: 3.3 -->
                    
                <!-- Quantum Computing: 3.1 -->
                    
                <!-- Reinforcement Learning: 2.5 -->
                    
                <!-- Networks: 1.7 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- Pathfinding: 1.1 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.9726
                </span>
                <a href="https://arxiv.org/abs/2504.13088" target="_blank" rel="noopener noreferrer">Imperative MPC: An End-to-End Self-Supervised Learning with Differentiable MPC for UAV Attitude Control</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Haonan He, Yuheng Qiu, Junyi Geng
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Modeling and control of nonlinear dynamics are critical in robotics, especially in scenarios with unpredictable external influences and complex dynamics. Traditional cascaded modular control pipelines often yield suboptimal performance due to conservative assumptions and tedious parameter tuning. Pu</span>
                
                <span class="abstract-full" style="display: none;">Modeling and control of nonlinear dynamics are critical in robotics, especially in scenarios with unpredictable external influences and complex dynamics. Traditional cascaded modular control pipelines often yield suboptimal performance due to conservative assumptions and tedious parameter tuning. Pure data-driven approaches promise robust performance but suffer from low sample efficiency, sim-to-real gaps, and reliance on extensive datasets. Hybrid methods combining learning-based and traditional model-based control in an end-to-end manner offer a promising alternative. This work presents a self-supervised learning framework combining learning-based inertial odometry (IO) module and differentiable model predictive control (d-MPC) for Unmanned Aerial Vehicle (UAV) attitude control. The IO denoises raw IMU measurements and predicts UAV attitudes, which are then optimized by MPC for control actions in a bi-level optimization (BLO) setup, where the inner MPC optimizes control actions and the upper level minimizes discrepancy between real-world and predicted performance. The framework is thus end-to-end and can be trained in a self-supervised manner. This approach combines the strength of learning-based perception with the interpretable model-based control. Results show the effectiveness even under strong wind. It can simultaneously enhance both the MPC parameter learning and IMU prediction performance.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 14.6 -->
                    
                <!-- LLMs: 4.1 -->
                    
                <!-- Quantum Computing: 2.2 -->
                    
                <!-- Robotics: 2.1 -->
                    
                <!-- Reinforcement Learning: 1.9 -->
                    
                <!-- Networks: 1.8 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- T2I: 1.4 -->
                    
                <!-- RAG: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.9975
                </span>
                <a href="https://arxiv.org/abs/2504.12350" target="_blank" rel="noopener noreferrer">A Large-Language Model Framework for Relative Timeline Extraction from PubMed Case Reports</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jing Wang, Jeremy C Weiss
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Timing of clinical events is central to characterization of patient trajectories, enabling analyses such as process tracing, forecasting, and causal reasoning. However, structured electronic health records capture few data elements critical to these tasks, while clinical reports lack temporal locali</span>
                
                <span class="abstract-full" style="display: none;">Timing of clinical events is central to characterization of patient trajectories, enabling analyses such as process tracing, forecasting, and causal reasoning. However, structured electronic health records capture few data elements critical to these tasks, while clinical reports lack temporal localization of events in structured form. We present a system that transforms case reports into textual time series-structured pairs of textual events and timestamps. We contrast manual and large language model (LLM) annotations (n=320 and n=390 respectively) of ten randomly-sampled PubMed open-access (PMOA) case reports (N=152,974) and assess inter-LLM agreement (n=3,103; N=93). We find that the LLM models have moderate event recall(O1-preview: 0.80) but high temporal concordance among identified events (O1-preview: 0.95). By establishing the task, annotation, and assessment systems, and by demonstrating high concordance, this work may serve as a benchmark for leveraging the PMOA corpus for temporal analytics.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 14.1 -->
                    
                <!-- Medicine: 11.5 -->
                    
                <!-- Quantum Computing: 3.8 -->
                    
                <!-- Networks: 1.6 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- RAG: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- 3D: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.0113
                </span>
                <a href="https://arxiv.org/abs/2504.13059" target="_blank" rel="noopener noreferrer">RoboTwin: Dual-Arm Robot Benchmark with Generative Digital Twins</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yao Mu, Tianxing Chen, Zanxin Chen, Shijia Peng, Zhiqian Lan, Zeyu Gao, Zhixuan Liang, Qiaojun Yu, Yude Zou, Mingkun Xu, Lunkai Lin, Zhiqiang Xie, Mingyu Ding, Ping Luo
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In the rapidly advancing field of robotics, dual-arm coordination and complex object manipulation are essential capabilities for developing advanced autonomous systems. However, the scarcity of diverse, high-quality demonstration data and real-world-aligned evaluation benchmarks severely limits such</span>
                
                <span class="abstract-full" style="display: none;">In the rapidly advancing field of robotics, dual-arm coordination and complex object manipulation are essential capabilities for developing advanced autonomous systems. However, the scarcity of diverse, high-quality demonstration data and real-world-aligned evaluation benchmarks severely limits such development. To address this, we introduce RoboTwin, a generative digital twin framework that uses 3D generative foundation models and large language models to produce diverse expert datasets and provide a real-world-aligned evaluation platform for dual-arm robotic tasks. Specifically, RoboTwin creates varied digital twins of objects from single 2D images, generating realistic and interactive scenarios. It also introduces a spatial relation-aware code generation framework that combines object annotations with large language models to break down tasks, determine spatial constraints, and generate precise robotic movement code. Our framework offers a comprehensive benchmark with both simulated and real-world data, enabling standardized evaluation and better alignment between simulated training and real-world performance. We validated our approach using the open-source COBOT Magic Robot platform. Policies pre-trained on RoboTwin-generated data and fine-tuned with limited real-world samples demonstrate significant potential for enhancing dual-arm robotic manipulation systems by improving success rates by over 70% for single-arm tasks and over 40% for dual-arm tasks compared to models trained solely on real-world data.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 15.7 -->
                    
                <!-- LLMs: 10.8 -->
                    
                <!-- 3D: 2.5 -->
                    
                <!-- Quantum Computing: 2.4 -->
                    
                <!-- RAG: 1.9 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- T2I: 1.4 -->
                    
                <!-- Networks: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- Evolutionary Algorithms: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.0304
                </span>
                <a href="https://arxiv.org/abs/2504.12545" target="_blank" rel="noopener noreferrer">Knowledge Acquisition on Mass-shooting Events via LLMs for AI-Driven Justice</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Benign John Ihugba, Afsana Nasrin, Ling Wu, Lin Li, Lijun Qian, Xishuang Dong
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Mass-shooting events pose a significant challenge to public safety, generating large volumes of unstructured textual data that hinder effective investigations and the formulation of public policy. Despite the urgency, few prior studies have effectively automated the extraction of key information fro</span>
                
                <span class="abstract-full" style="display: none;">Mass-shooting events pose a significant challenge to public safety, generating large volumes of unstructured textual data that hinder effective investigations and the formulation of public policy. Despite the urgency, few prior studies have effectively automated the extraction of key information from these events to support legal and investigative efforts. This paper presented the first dataset designed for knowledge acquisition on mass-shooting events through the application of named entity recognition (NER) techniques. It focuses on identifying key entities such as offenders, victims, locations, and criminal instruments, that are vital for legal and investigative purposes. The NER process is powered by Large Language Models (LLMs) using few-shot prompting, facilitating the efficient extraction and organization of critical information from diverse sources, including news articles, police reports, and social media. Experimental results on real-world mass-shooting corpora demonstrate that GPT-4o is the most effective model for mass-shooting NER, achieving the highest Micro Precision, Micro Recall, and Micro F1-scores. Meanwhile, o1-mini delivers competitive performance, making it a resource-efficient alternative for less complex NER tasks. It is also observed that increasing the shot count enhances the performance of all models, but the gains are more substantial for GPT-4o and o1-mini, highlighting their superior adaptability to few-shot learning scenarios.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 10.7 -->
                    
                <!-- LLMs: 8.3 -->
                    
                <!-- Quantum Computing: 2.9 -->
                    
                <!-- Reinforcement Learning: 2.0 -->
                    
                <!-- Networks: 1.4 -->
                    
                <!-- Math: 1.3 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Robotics: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.049
                </span>
                <a href="https://arxiv.org/abs/2504.12683" target="_blank" rel="noopener noreferrer">Cluster weighted models with multivariate skewed distributions for functional data</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Cristina Anton, Roy Shivam Ram Shreshtth
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We propose a clustering method, funWeightClustSkew, based on mixtures of functional linear regression models and three skewed multivariate distributions: the variance-gamma distribution, the skew-t distribution, and the normal-inverse Gaussian distribution. Our approach follows the framework of the </span>
                
                <span class="abstract-full" style="display: none;">We propose a clustering method, funWeightClustSkew, based on mixtures of functional linear regression models and three skewed multivariate distributions: the variance-gamma distribution, the skew-t distribution, and the normal-inverse Gaussian distribution. Our approach follows the framework of the functional high dimensional data clustering (funHDDC) method, and we extend to functional data the cluster weighted models based on skewed distributions used for finite dimensional multivariate data. We consider several parsimonious models, and to estimate the parameters we construct an expectation maximization (EM) algorithm. We illustrate the performance of funWeightClustSkew for simulated data and for the Air Quality dataset.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 12.1 -->
                    
                <!-- LLMs: 4.7 -->
                    
                <!-- Reinforcement Learning: 3.0 -->
                    
                <!-- Quantum Computing: 2.6 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Math: 1.7 -->
                    
                <!-- Networks: 1.3 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.1073
                </span>
                <a href="https://arxiv.org/abs/2504.09597" target="_blank" rel="noopener noreferrer">Understanding LLM Behaviors via Compression: Data Generation, Knowledge Acquisition and Scaling Laws</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zhixuan Pan, Shaowen Wang, Jian Li
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Large Language Models (LLMs) have demonstrated remarkable capabilities across numerous tasks, yet principled explanations for their underlying mechanisms and several phenomena, such as scaling laws, hallucinations, and related behaviors, remain elusive. In this work, we revisit the classical relatio</span>
                
                <span class="abstract-full" style="display: none;">Large Language Models (LLMs) have demonstrated remarkable capabilities across numerous tasks, yet principled explanations for their underlying mechanisms and several phenomena, such as scaling laws, hallucinations, and related behaviors, remain elusive. In this work, we revisit the classical relationship between compression and prediction, grounded in Kolmogorov complexity and Shannon information theory, to provide deeper insights into LLM behaviors. By leveraging the Kolmogorov Structure Function and interpreting LLM compression as a two-part coding process, we offer a detailed view of how LLMs acquire and store information across increasing model and data scales -- from pervasive syntactic patterns to progressively rarer knowledge elements. Motivated by this theoretical perspective and natural assumptions inspired by Heap's and Zipf's laws, we introduce a simplified yet representative hierarchical data-generation framework called the Syntax-Knowledge model. Under the Bayesian setting, we show that prediction and compression within this model naturally lead to diverse learning and scaling behaviors of LLMs. In particular, our theoretical analysis offers intuitive and principled explanations for both data and model scaling laws, the dynamics of knowledge acquisition during training and fine-tuning, factual knowledge hallucinations in LLMs. The experimental results validate our theoretical predictions.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 31.3 -->
                    
                <!-- Medicine: 11.3 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- RAG: 1.6 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- T2I: 1.4 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.3255
                </span>
                <a href="https://arxiv.org/abs/2504.12610" target="_blank" rel="noopener noreferrer">Machine Learning Methods for Gene Regulatory Network Inference</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Akshata Hegde, Tom Nguyen, Jianlin Cheng
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Gene Regulatory Networks (GRNs) are intricate biological systems that control gene expression and regulation in response to environmental and developmental cues. Advances in computational biology, coupled with high throughput sequencing technologies, have significantly improved the accuracy of GRN i</span>
                
                <span class="abstract-full" style="display: none;">Gene Regulatory Networks (GRNs) are intricate biological systems that control gene expression and regulation in response to environmental and developmental cues. Advances in computational biology, coupled with high throughput sequencing technologies, have significantly improved the accuracy of GRN inference and modeling. Modern approaches increasingly leverage artificial intelligence (AI), particularly machine learning techniques including supervised, unsupervised, semi-supervised, and contrastive learning to analyze large scale omics data and uncover regulatory gene interactions. To support both the application of GRN inference in studying gene regulation and the development of novel machine learning methods, we present a comprehensive review of machine learning based GRN inference methodologies, along with the datasets and evaluation metrics commonly used. Special emphasis is placed on the emerging role of cutting edge deep learning techniques in enhancing inference performance. The potential future directions for improving GRN inference are also discussed.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 13.0 -->
                    
                <!-- LLMs: 6.4 -->
                    
                <!-- Quantum Computing: 3.5 -->
                    
                <!-- Reinforcement Learning: 2.0 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- Networks: 1.3 -->
                    
                <!-- RAG: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Math: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.3518
                </span>
                <a href="https://arxiv.org/abs/2504.13177" target="_blank" rel="noopener noreferrer">Single-Shot Shape and Reflectance with Spatial Polarization Multiplexing</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Tomoki Ichikawa, Ryo Kawahara, Ko Nishino
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We propose spatial polarization multiplexing (SPM) for reconstructing object shape and reflectance from a single polarimetric image and demonstrate its application to dynamic surface recovery. Although single-pattern structured light enables single-shot shape reconstruction, the reflectance is chall</span>
                
                <span class="abstract-full" style="display: none;">We propose spatial polarization multiplexing (SPM) for reconstructing object shape and reflectance from a single polarimetric image and demonstrate its application to dynamic surface recovery. Although single-pattern structured light enables single-shot shape reconstruction, the reflectance is challenging to recover due to the lack of angular sampling of incident light and the entanglement of the projected pattern and the surface color texture. We design a spatially multiplexed pattern of polarization that can be robustly and uniquely decoded for shape reconstruction by quantizing the AoLP values. At the same time, our spatial-multiplexing enables single-shot ellipsometry of linear polarization by projecting differently polarized light within a local region, which separates the specular and diffuse reflections for BRDF estimation. We achieve this spatial polarization multiplexing with a constrained de Bruijn sequence. Unlike single-pattern structured light with intensity and color, our polarization pattern is invisible to the naked eye and retains the natural surface appearance which is essential for accurate appearance modeling and also interaction with people. We experimentally validate our method on real data. The results show that our method can recover the shape, the Mueller matrix, and the BRDF from a single-shot polarimetric image. We also demonstrate the application of our method to dynamic surfaces.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 11.6 -->
                    
                <!-- LLMs: 3.2 -->
                    
                <!-- Reinforcement Learning: 2.7 -->
                    
                <!-- Quantum Computing: 2.2 -->
                    
                <!-- Networks: 1.7 -->
                    
                <!-- Math: 1.5 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- Robotics: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.353
                </span>
                <a href="https://arxiv.org/abs/2504.12326" target="_blank" rel="noopener noreferrer">Reconstructing Sepsis Trajectories from Clinical Case Reports using LLMs: the Textual Time Series Corpus for Sepsis</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Shahriar Noroozizadeh, Jeremy C. Weiss
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Clinical case reports and discharge summaries may be the most complete and accurate summarization of patient encounters, yet they are finalized, i.e., timestamped after the encounter. Complementary data structured streams become available sooner but suffer from incompleteness. To train models and al</span>
                
                <span class="abstract-full" style="display: none;">Clinical case reports and discharge summaries may be the most complete and accurate summarization of patient encounters, yet they are finalized, i.e., timestamped after the encounter. Complementary data structured streams become available sooner but suffer from incompleteness. To train models and algorithms on more complete and temporally fine-grained data, we construct a pipeline to phenotype, extract, and annotate time-localized findings within case reports using large language models. We apply our pipeline to generate an open-access textual time series corpus for Sepsis-3 comprising 2,139 case reports from the Pubmed-Open Access (PMOA) Subset. To validate our system, we apply it on PMOA and timeline annotations from I2B2/MIMIC-IV and compare the results to physician-expert annotations. We show high recovery rates of clinical findings (event match rates: O1-preview--0.755, Llama 3.3 70B Instruct--0.753) and strong temporal ordering (concordance: O1-preview--0.932, Llama 3.3 70B Instruct--0.932). Our work characterizes the ability of LLMs to time-localize clinical findings in text, illustrating the limitations of LLM use for temporal reconstruction and providing several potential avenues of improvement via multimodal integration.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 14.1 -->
                    
                <!-- LLMs: 11.3 -->
                    
                <!-- Quantum Computing: 2.8 -->
                    
                <!-- Reinforcement Learning: 2.0 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Networks: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- RAG: 1.1 -->
                    
                <!-- Math: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.3557
                </span>
                <a href="https://arxiv.org/abs/2504.13015" target="_blank" rel="noopener noreferrer">Hierarchical Feature Learning for Medical Point Clouds via State Space Model</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Guoqing Zhang, Jingyun Yang, Yang Li
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Deep learning-based point cloud modeling has been widely investigated as an indispensable component of general shape analysis. Recently, transformer and state space model (SSM) have shown promising capacities in point cloud learning. However, limited research has been conducted on medical point clou</span>
                
                <span class="abstract-full" style="display: none;">Deep learning-based point cloud modeling has been widely investigated as an indispensable component of general shape analysis. Recently, transformer and state space model (SSM) have shown promising capacities in point cloud learning. However, limited research has been conducted on medical point clouds, which have great potential in disease diagnosis and treatment. This paper presents an SSM-based hierarchical feature learning framework for medical point cloud understanding. Specifically, we down-sample input into multiple levels through the farthest point sampling. At each level, we perform a series of k-nearest neighbor (KNN) queries to aggregate multi-scale structural information. To assist SSM in processing point clouds, we introduce coordinate-order and inside-out scanning strategies for efficient serialization of irregular points. Point features are calculated progressively from short neighbor sequences and long point sequences through vanilla and group Point SSM blocks, to capture both local patterns and long-range dependencies. To evaluate the proposed method, we build a large-scale medical point cloud dataset named MedPointS for anatomy classification, completion, and segmentation. Extensive experiments conducted on MedPointS demonstrate that our method achieves superior performance across all tasks. The dataset is available at https://flemme-docs.readthedocs.io/en/latest/medpoints.html. Code is merged to a public medical imaging platform: https://github.com/wlsdzyzl/flemme.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 16.0 -->
                    
                <!-- LLMs: 7.1 -->
                    
                <!-- Quantum Computing: 2.8 -->
                    
                <!-- 3D: 2.8 -->
                    
                <!-- Networks: 1.6 -->
                    
                <!-- RAG: 1.5 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- T2I: 1.5 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.4354
                </span>
                <a href="https://arxiv.org/abs/2504.12737" target="_blank" rel="noopener noreferrer">Chinese-Vicuna: A Chinese Instruction-following Llama-based Model</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Chenghao Fan, Zhenyi Lu, Jie Tian
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Chinese-Vicuna is an open-source, resource-efficient language model designed to bridge the gap in Chinese instruction-following capabilities by fine-tuning Meta's LLaMA architecture using Low-Rank Adaptation (LoRA). Targeting low-resource environments, it enables cost-effective deployment on consume</span>
                
                <span class="abstract-full" style="display: none;">Chinese-Vicuna is an open-source, resource-efficient language model designed to bridge the gap in Chinese instruction-following capabilities by fine-tuning Meta's LLaMA architecture using Low-Rank Adaptation (LoRA). Targeting low-resource environments, it enables cost-effective deployment on consumer GPUs (e.g., RTX-2080Ti for 7B models) and supports domain-specific adaptation in fields like healthcare and law. By integrating hybrid datasets (BELLE and Guanaco) and 4-bit quantization (QLoRA), the model achieves competitive performance in tasks such as translation, code generation, and domain-specific Q\&amp;A. The project provides a comprehensive toolkit for model conversion, CPU inference, and multi-turn dialogue interfaces, emphasizing accessibility for researchers and developers. Evaluations indicate competitive performance across medical tasks, multi-turn dialogue coherence, and real-time legal updates. Chinese-Vicuna's modular design, open-source ecosystem, and community-driven enhancements position it as a versatile foundation for Chinese LLM applications.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 17.7 -->
                    
                <!-- LLMs: 9.2 -->
                    
                <!-- Quantum Computing: 2.4 -->
                    
                <!-- RAG: 2.1 -->
                    
                <!-- 3D: 1.8 -->
                    
                <!-- Robotics: 1.8 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Networks: 1.6 -->
                    
                <!-- T2I: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- Attention: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.6056
                </span>
                <a href="https://arxiv.org/abs/2504.13167" target="_blank" rel="noopener noreferrer">ODHSR: Online Dense 3D Reconstruction of Humans and Scenes from Monocular Videos</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zetong Zhang, Manuel kaufmann, Lixin Xue, Jie Song, Martin R. Oswald
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Creating a photorealistic scene and human reconstruction from a single monocular in-the-wild video figures prominently in the perception of a human-centric 3D world. Recent neural rendering advances have enabled holistic human-scene reconstruction but require pre-calibrated camera and human poses, a</span>
                
                <span class="abstract-full" style="display: none;">Creating a photorealistic scene and human reconstruction from a single monocular in-the-wild video figures prominently in the perception of a human-centric 3D world. Recent neural rendering advances have enabled holistic human-scene reconstruction but require pre-calibrated camera and human poses, and days of training time. In this work, we introduce a novel unified framework that simultaneously performs camera tracking, human pose estimation and human-scene reconstruction in an online fashion. 3D Gaussian Splatting is utilized to learn Gaussian primitives for humans and scenes efficiently, and reconstruction-based camera tracking and human pose estimation modules are designed to enable holistic understanding and effective disentanglement of pose and appearance. Specifically, we design a human deformation module to reconstruct the details and enhance generalizability to out-of-distribution poses faithfully. Aiming to learn the spatial correlation between human and scene accurately, we introduce occlusion-aware human silhouette rendering and monocular geometric priors, which further improve reconstruction quality. Experiments on the EMDB and NeuMan datasets demonstrate superior or on-par performance with existing methods in camera tracking, human pose estimation, novel view synthesis and runtime. Our project page is at https://eth-ait.github.io/ODHSR.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 13.8 -->
                    
                <!-- LLMs: 7.4 -->
                    
                <!-- 3D: 5.5 -->
                    
                <!-- Robotics: 1.8 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- T2I: 1.1 -->
                    
                <!-- RAG: 1.1 -->
                    
                <!-- Networks: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.7181
                </span>
                <a href="https://arxiv.org/abs/2501.16371" target="_blank" rel="noopener noreferrer">Which Optimizer Works Best for Physics-Informed Neural Networks and Kolmogorov-Arnold Networks?</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Elham Kiyani, Khemraj Shukla, Jorge F. Urb\'an, J\'er\^ome Darbon, George Em Karniadakis
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Physics-Informed Neural Networks (PINNs) have revolutionized the computation of PDE solutions by integrating partial differential equations (PDEs) into the neural network's training process as soft constraints, becoming an important component of the scientific machine learning (SciML) ecosystem. Mor</span>
                
                <span class="abstract-full" style="display: none;">Physics-Informed Neural Networks (PINNs) have revolutionized the computation of PDE solutions by integrating partial differential equations (PDEs) into the neural network's training process as soft constraints, becoming an important component of the scientific machine learning (SciML) ecosystem. More recently, physics-informed Kolmogorv-Arnold networks (PIKANs) have also shown to be effective and comparable in accuracy with PINNs. In their current implementation, both PINNs and PIKANs are mainly optimized using first-order methods like Adam, as well as quasi-Newton methods such as BFGS and its low-memory variant, L-BFGS. However, these optimizers often struggle with highly non-linear and non-convex loss landscapes, leading to challenges such as slow convergence, local minima entrapment, and (non)degenerate saddle points. In this study, we investigate the performance of Self-Scaled BFGS (SSBFGS), Self-Scaled Broyden (SSBroyden) methods and other advanced quasi-Newton schemes, including BFGS and L-BFGS with different line search strategies approaches. These methods dynamically rescale updates based on historical gradient information, thus enhancing training efficiency and accuracy. We systematically compare these optimizers -- using both PINNs and PIKANs -- on key challenging linear, stiff, multi-scale and non-linear PDEs, including the Burgers, Allen-Cahn, Kuramoto-Sivashinsky, and Ginzburg-Landau equations. Our findings provide state-of-the-art results with orders-of-magnitude accuracy improvements without the use of adaptive weights or any other enhancements typically employed in PINNs. More broadly, our results reveal insights into the effectiveness of second-order optimization strategies in significantly improving the convergence and accurate generalization of PINNs and PIKANs.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 12.6 -->
                    
                <!-- LLMs: 8.6 -->
                    
                <!-- Quantum Computing: 3.0 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- T2I: 1.1 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.7527
                </span>
                <a href="https://arxiv.org/abs/2504.12938" target="_blank" rel="noopener noreferrer">Optimal analysis of penalized lowest-order mixed FEMs for the Stokes-Darcy model</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Luling Cao, Weiwei Sun
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper is concerned with non-uniform fully-mixed FEMs for dynamic coupled Stokes-Darcy model with the well-known Beavers-Joseph-Saffman (BJS) interface condition. In particular, a decoupled algorithm with the lowest-order mixed non-uniform FE approximations (MINI for the Stokes equation and RT0-</span>
                
                <span class="abstract-full" style="display: none;">This paper is concerned with non-uniform fully-mixed FEMs for dynamic coupled Stokes-Darcy model with the well-known Beavers-Joseph-Saffman (BJS) interface condition. In particular, a decoupled algorithm with the lowest-order mixed non-uniform FE approximations (MINI for the Stokes equation and RT0-DG0 for the Darcy equation) and the classical Nitsche-type penalty is studied. The method with the combined approximation of different orders is commonly used in practical simulations. However, the optimal error analysis of methods with non-uniform approximations for the coupled Stokes-Darcy flow model has remained challenging, although the analysis for uniform approximations has been well done. The key question is how the lower-order approximation to the Darcy flow influences the accuracy of the Stokes solution through the interface condition. In this paper, we prove that the decoupled algorithm provides a truly optimal convergence rate in L^2-norm in spatial direction: O(h^2) for Stokes velocity and O(h) for Darcy flow in the coupled Stokes-Darcy model. This implies that the lower-order approximation to the Darcy flow does not pollute the accuracy of numerical velocity for Stokes flow. The analysis presented in this paper is based on a well-designed Stokes-Darcy Ritz projection and given for a dynamic coupled model. The optimal error estimate holds for more general combined approximations and more general coupled models, including the corresponding model of steady-state Stokes-Darcy flows and the model of coupled dynamic Stokes and steady-state Darcy flows. Numerical results confirm our theoretical analysis and show that the decoupled algorithm is efficient.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 14.3 -->
                    
                <!-- Math: 3.5 -->
                    
                <!-- Reinforcement Learning: 2.8 -->
                    
                <!-- LLMs: 2.1 -->
                    
                <!-- Pathfinding: 2.0 -->
                    
                <!-- Networks: 1.7 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- Robotics: 1.5 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.9595
                </span>
                <a href="https://arxiv.org/abs/2412.17152" target="_blank" rel="noopener noreferrer">Unifying Feature-Based Explanations with Functional ANOVA and Cooperative Game Theory</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Fabian Fumagalli, Maximilian Muschalik, Eyke H\"ullermeier, Barbara Hammer, Julia Herbinger
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Feature-based explanations, using perturbations or gradients, are a prevalent tool to understand decisions of black box machine learning models. Yet, differences between these methods still remain mostly unknown, which limits their applicability for practitioners. In this work, we introduce a unifie</span>
                
                <span class="abstract-full" style="display: none;">Feature-based explanations, using perturbations or gradients, are a prevalent tool to understand decisions of black box machine learning models. Yet, differences between these methods still remain mostly unknown, which limits their applicability for practitioners. In this work, we introduce a unified framework for local and global feature-based explanations using two well-established concepts: functional ANOVA (fANOVA) from statistics, and the notion of value and interaction from cooperative game theory. We introduce three fANOVA decompositions that determine the influence of feature distributions, and use game-theoretic measures, such as the Shapley value and interactions, to specify the influence of higher-order interactions. Our framework combines these two dimensions to uncover similarities and differences between a wide range of explanation techniques for features and groups of features. We then empirically showcase the usefulness of our framework on synthetic and real-world datasets.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 11.6 -->
                    
                <!-- LLMs: 8.7 -->
                    
                <!-- Quantum Computing: 3.8 -->
                    
                <!-- Reinforcement Learning: 1.8 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.966
                </span>
                <a href="https://arxiv.org/abs/2504.12368" target="_blank" rel="noopener noreferrer">Geographical Context Matters: Bridging Fine and Coarse Spatial Information to Enhance Continental Land Cover Mapping</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Babak Ghassemi, Cassio Fraga-Dantas, Raffaele Gaetano, Dino Ienco, Omid Ghorbanzadeh, Emma Izquierdo-Verdiguier, Francesco Vuolo
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Land use and land cover mapping from Earth Observation (EO) data is a critical tool for sustainable land and resource management. While advanced machine learning and deep learning algorithms excel at analyzing EO imagery data, they often overlook crucial geospatial metadata information that could en</span>
                
                <span class="abstract-full" style="display: none;">Land use and land cover mapping from Earth Observation (EO) data is a critical tool for sustainable land and resource management. While advanced machine learning and deep learning algorithms excel at analyzing EO imagery data, they often overlook crucial geospatial metadata information that could enhance scalability and accuracy across regional, continental, and global scales. To address this limitation, we propose BRIDGE-LC (Bi-level Representation Integration for Disentangled GEospatial Land Cover), a novel deep learning framework that integrates multi-scale geospatial information into the land cover classification process. By simultaneously leveraging fine-grained (latitude/longitude) and coarse-grained (biogeographical region) spatial information, our lightweight multi-layer perceptron architecture learns from both during training but only requires fine-grained information for inference, allowing it to disentangle region-specific from region-agnostic land cover features while maintaining computational efficiency. To assess the quality of our framework, we use an open-access in-situ dataset and adopt several competing classification approaches commonly considered for large-scale land cover mapping. We evaluated all approaches through two scenarios: an extrapolation scenario in which training data encompasses samples from all biogeographical regions, and a leave-one-region-out scenario where one region is excluded from training. We also explore the spatial representation learned by our model, highlighting a connection between its internal manifold and the geographical information used during training. Our results demonstrate that integrating geospatial information improves land cover mapping performance, with the most substantial gains achieved by jointly leveraging both fine- and coarse-grained spatial information.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 18.2 -->
                    
                <!-- LLMs: 4.6 -->
                    
                <!-- Quantum Computing: 3.3 -->
                    
                <!-- 3D: 2.3 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Networks: 1.4 -->
                    
                <!-- RAG: 1.4 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- T2I: 1.1 -->
                    
                <!-- Federated Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -5.051
                </span>
                <a href="https://arxiv.org/abs/2504.12476" target="_blank" rel="noopener noreferrer">What do people expect from Artificial Intelligence? Public opinion on alignment in AI moderation from Germany and the United States</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Andreas Jungherr, Adrian Rauchfleisch
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Recent advances in generative Artificial Intelligence have raised public awareness, shaping expectations and concerns about their societal implications. Central to these debates is the question of AI alignment -- how well AI systems meet public expectations regarding safety, fairness, and social val</span>
                
                <span class="abstract-full" style="display: none;">Recent advances in generative Artificial Intelligence have raised public awareness, shaping expectations and concerns about their societal implications. Central to these debates is the question of AI alignment -- how well AI systems meet public expectations regarding safety, fairness, and social values. However, little is known about what people expect from AI-enabled systems and how these expectations differ across national contexts. We present evidence from two surveys of public preferences for key functional features of AI-enabled systems in Germany (n = 1800) and the United States (n = 1756). We examine support for four types of alignment in AI moderation: accuracy and reliability, safety, bias mitigation, and the promotion of aspirational imaginaries. U.S. respondents report significantly higher AI use and consistently greater support for all alignment features, reflecting broader technological openness and higher societal involvement with AI. In both countries, accuracy and safety enjoy the strongest support, while more normatively charged goals -- like fairness and aspirational imaginaries -- receive more cautious backing, particularly in Germany. We also explore how individual experience with AI, attitudes toward free speech, political ideology, partisan affiliation, and gender shape these preferences. AI use and free speech support explain more variation in Germany. In contrast, U.S. responses show greater attitudinal uniformity, suggesting that higher exposure to AI may consolidate public expectations. These findings contribute to debates on AI governance and cross-national variation in public preferences. More broadly, our study demonstrates the value of empirically grounding AI alignment debates in public attitudes and of explicitly developing normatively grounded expectations into theoretical and policy discussions on the governance of AI-generated content.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 14.1 -->
                    
                <!-- Medicine: 13.0 -->
                    
                <!-- Quantum Computing: 3.1 -->
                    
                <!-- Robotics: 1.9 -->
                    
                <!-- RAG: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Math: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -5.5967
                </span>
                <a href="https://arxiv.org/abs/2504.12300" target="_blank" rel="noopener noreferrer">Implementing Effective Changes in Software Projects to Optimize Runtimes and Minimize Defects</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Kartik Gupta
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The continuous evolution of software projects necessitates the implementation of changes to enhance performance and reduce defects. This research explores effective strategies for learning and implementing useful changes in software projects, focusing on optimizing runtimes and minimizing software d</span>
                
                <span class="abstract-full" style="display: none;">The continuous evolution of software projects necessitates the implementation of changes to enhance performance and reduce defects. This research explores effective strategies for learning and implementing useful changes in software projects, focusing on optimizing runtimes and minimizing software defects. A comprehensive review of existing literature sets the foundation for understanding the current landscape of software optimization and defect reduction. The study employs a mixed-methods approach, incorporating both qualitative and quantitative data from software projects before and after changes were made. Key methodologies include detailed data collection on runtimes and defect rates, root cause analysis of common issues, and the application of best practices from successful case studies. The research highlights critical techniques for learning from past projects, identifying actionable changes, and ensuring their effective implementation. In-depth case study analysis provides insights into the practical challenges and success factors associated with these changes. Statistical analysis of the results demonstrates significant improvements in runtimes and defect rates, underscoring the value of a structured approach to software project optimization. The findings offer actionable recommendations for software development teams aiming to enhance project performance and reliability. This study contributes to the broader understanding of software engineering practices, providing a framework for continuous improvement in software projects. Future research directions are suggested to refine these strategies further and explore their application in diverse software development environments.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 14.9 -->
                    
                <!-- LLMs: 8.4 -->
                    
                <!-- Robotics: 2.5 -->
                    
                <!-- Quantum Computing: 2.2 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- Networks: 1.4 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- RAG: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -5.7703
                </span>
                <a href="https://arxiv.org/abs/2412.01506" target="_blank" rel="noopener noreferrer">Structured 3D Latents for Scalable and Versatile 3D Generation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jianfeng Xiang, Zelong Lv, Sicheng Xu, Yu Deng, Ruicheng Wang, Bowen Zhang, Dong Chen, Xin Tong, Jiaolong Yang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We introduce a novel 3D generation method for versatile and high-quality 3D asset creation. The cornerstone is a unified Structured LATent (SLAT) representation which allows decoding to different output formats, such as Radiance Fields, 3D Gaussians, and meshes. This is achieved by integrating a spa</span>
                
                <span class="abstract-full" style="display: none;">We introduce a novel 3D generation method for versatile and high-quality 3D asset creation. The cornerstone is a unified Structured LATent (SLAT) representation which allows decoding to different output formats, such as Radiance Fields, 3D Gaussians, and meshes. This is achieved by integrating a sparsely-populated 3D grid with dense multiview visual features extracted from a powerful vision foundation model, comprehensively capturing both structural (geometry) and textural (appearance) information while maintaining flexibility during decoding. We employ rectified flow transformers tailored for SLAT as our 3D generation models and train models with up to 2 billion parameters on a large 3D asset dataset of 500K diverse objects. Our model generates high-quality results with text or image conditions, significantly surpassing existing methods, including recent ones at similar scales. We showcase flexible output format selection and local 3D editing capabilities which were not offered by previous models. Code, model, and data will be released.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 14.9 -->
                    
                <!-- 3D: 10.8 -->
                    
                <!-- LLMs: 5.4 -->
                    
                <!-- Quantum Computing: 2.4 -->
                    
                <!-- Networks: 2.0 -->
                    
                <!-- T2I: 2.0 -->
                    
                <!-- RAG: 1.7 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- GNN: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -6.3007
                </span>
                <a href="https://arxiv.org/abs/2504.12992" target="_blank" rel="noopener noreferrer">Enhancing Cocoa Pod Disease Classification via Transfer Learning and Ensemble Methods: Toward Robust Predictive Modeling</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Devina Anduyan, Nyza Cabillo, Navy Gultiano, Mark Phil Pacot
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This study presents an ensemble-based approach for cocoa pod disease classification by integrating transfer learning with three ensemble learning strategies: Bagging, Boosting, and Stacking. Pre-trained convolutional neural networks, including VGG16, VGG19, ResNet50, ResNet101, InceptionV3, and Xcep</span>
                
                <span class="abstract-full" style="display: none;">This study presents an ensemble-based approach for cocoa pod disease classification by integrating transfer learning with three ensemble learning strategies: Bagging, Boosting, and Stacking. Pre-trained convolutional neural networks, including VGG16, VGG19, ResNet50, ResNet101, InceptionV3, and Xception, were fine-tuned and employed as base learners to detect three disease categories: Black Pod Rot, Pod Borer, and Healthy. A balanced dataset of 6,000 cocoa pod images was curated and augmented to ensure robustness against variations in lighting, orientation, and disease severity. The performance of each ensemble method was evaluated using accuracy, precision, recall, and F1-score. Experimental results show that Bagging consistently achieved superior classification performance with a test accuracy of 100%, outperforming Boosting (97%) and Stacking (92%). The findings confirm that combining transfer learning with ensemble techniques improves model generalization and reliability, making it a promising direction for precision agriculture and automated crop disease management.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 25.2 -->
                    
                <!-- LLMs: 9.0 -->
                    
                <!-- Quantum Computing: 2.9 -->
                    
                <!-- 3D: 2.6 -->
                    
                <!-- RAG: 1.8 -->
                    
                <!-- Networks: 1.8 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- T2I: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -6.4352
                </span>
                <a href="https://arxiv.org/abs/2502.08255" target="_blank" rel="noopener noreferrer">Principles and Framework for the Operationalisation of Meaningful Human Control over Autonomous Systems</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Simeon C. Calvert
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper proposes an alignment for the operationalisation of Meaningful Human Control (MHC) for autonomous systems by proposing operational principles for MHC and introducing a generic framework for its application. With a plethora of different seemingly diverging expansions for use of MHC in prac</span>
                
                <span class="abstract-full" style="display: none;">This paper proposes an alignment for the operationalisation of Meaningful Human Control (MHC) for autonomous systems by proposing operational principles for MHC and introducing a generic framework for its application. With a plethora of different seemingly diverging expansions for use of MHC in practice, this work aims to bring alignment and convergence use in practice. The increasing integration of autonomous systems in various domains emphasises a critical need to maintain human control to ensure responsible safety, accountability, and ethical operation of these systems. The concept of MHC offers an ideal concept for the design and evaluation of human control over autonomous systems, while considering human and technology capabilities. Through analysis of existing literature and investigation across various domains and related concepts, principles for the operationalisation of MHC are set out to provide tangible guidelines for researchers and practitioners aiming to implement MHC in their systems. The proposed framework dissects generic components of systems and their subsystems aligned with different agents, stakeholders and processes at different levels of proximity to an autonomous technology. The framework is domain-agnostic, emphasizing the universal applicability of the MHC principles irrespective of the technological context, paving the way for safer and more responsible autonomous systems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 12.9 -->
                    
                <!-- LLMs: 7.0 -->
                    
                <!-- Quantum Computing: 2.4 -->
                    
                <!-- Robotics: 2.1 -->
                    
                <!-- Reinforcement Learning: 1.9 -->
                    
                <!-- Networks: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -7.1001
                </span>
                <a href="https://arxiv.org/abs/2405.11008" target="_blank" rel="noopener noreferrer">A Systematic Review on Sleep Stage Classification and Sleep Disorder Detection Using Artificial Intelligence</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Tayab Uddin Wara, Ababil Hossain Fahad, Adri Shankar Das, Md. Mehedi Hasan Shawon
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Sleep is vital for people's physical and mental health, and sound sleep can help them focus on daily activities. Therefore, a sleep study that includes sleep patterns and sleep disorders is crucial to enhancing our knowledge about individuals' health status. This study aims to provide a comprehensiv</span>
                
                <span class="abstract-full" style="display: none;">Sleep is vital for people's physical and mental health, and sound sleep can help them focus on daily activities. Therefore, a sleep study that includes sleep patterns and sleep disorders is crucial to enhancing our knowledge about individuals' health status. This study aims to provide a comprehensive, systematic review of the recent literature to analyze the different approaches and their outcomes in sleep studies, which includes works on "sleep stages classification" and "sleep disorder detection" using AI. In this review, 183 articles were initially selected from different journals, among which 80 records were enlisted for explicit review, ranging from 2016 to 2023. Brain waves were the most commonly employed body parameters for sleep staging and disorder studies (almost 29% of the research used brain activity signals exclusively, and 77% combined with the other signals). The convolutional neural network (CNN), the most widely used of the 34 distinct artificial intelligence models, comprised 27%. The other models included the long short-term memory (LSTM), support vector machine (SVM), random forest (RF), and recurrent neural network (RNN), which consisted of 11%, 6%, 6%, and 5% sequentially. For performance metrics, accuracy was widely used for a maximum of 83.75% of the cases, the F1 score of 45%, Kappa of 36.25%, Sensitivity of 31.25%, and Specificity of 30% of cases, along with the other metrics. This article would help physicians and researchers get the gist of AI's contribution to sleep studies and the feasibility of their intended work.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 18.9 -->
                    
                <!-- LLMs: 5.6 -->
                    
                <!-- Quantum Computing: 2.6 -->
                    
                <!-- Reinforcement Learning: 2.3 -->
                    
                <!-- Robotics: 1.8 -->
                    
                <!-- Math: 1.4 -->
                    
                <!-- Networks: 1.2 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -8.0957
                </span>
                <a href="https://arxiv.org/abs/2504.12574" target="_blank" rel="noopener noreferrer">Prompt-Driven and Training-Free Forgetting Approach and Dataset for Large Language Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zhenyu Yu, Mohd Yamani Inda Idris, Pei Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The widespread adoption of diffusion models in image generation has increased the demand for privacy-compliant unlearning. However, due to the high-dimensional nature and complex feature representations of diffusion models, achieving selective unlearning remains challenging, as existing methods stru</span>
                
                <span class="abstract-full" style="display: none;">The widespread adoption of diffusion models in image generation has increased the demand for privacy-compliant unlearning. However, due to the high-dimensional nature and complex feature representations of diffusion models, achieving selective unlearning remains challenging, as existing methods struggle to remove sensitive information while preserving the consistency of non-sensitive regions. To address this, we propose an Automatic Dataset Creation Framework based on prompt-based layered editing and training-free local feature removal, constructing the ForgetMe dataset and introducing the Entangled evaluation metric. The Entangled metric quantifies unlearning effectiveness by assessing the similarity and consistency between the target and background regions and supports both paired (Entangled-D) and unpaired (Entangled-S) image data, enabling unsupervised evaluation. The ForgetMe dataset encompasses a diverse set of real and synthetic scenarios, including CUB-200-2011 (Birds), Stanford-Dogs, ImageNet, and a synthetic cat dataset. We apply LoRA fine-tuning on Stable Diffusion to achieve selective unlearning on this dataset and validate the effectiveness of both the ForgetMe dataset and the Entangled metric, establishing them as benchmarks for selective unlearning. Our work provides a scalable and adaptable solution for advancing privacy-preserving generative AI.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 18.9 -->
                    
                <!-- LLMs: 6.5 -->
                    
                <!-- Reinforcement Learning: 1.9 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -9.3838
                </span>
                <a href="https://arxiv.org/abs/2504.13113" target="_blank" rel="noopener noreferrer">Quorum: Zero-Training Unsupervised Anomaly Detection using Quantum Autoencoders</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jason Zev Ludmir, Sophia Rebello, Jacob Ruiz, Tirthak Patel
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Detecting mission-critical anomalous events and data is a crucial challenge across various industries, including finance, healthcare, and energy. Quantum computing has recently emerged as a powerful tool for tackling several machine learning tasks, but training quantum machine learning models remain</span>
                
                <span class="abstract-full" style="display: none;">Detecting mission-critical anomalous events and data is a crucial challenge across various industries, including finance, healthcare, and energy. Quantum computing has recently emerged as a powerful tool for tackling several machine learning tasks, but training quantum machine learning models remains challenging, particularly due to the difficulty of gradient calculation. The challenge is even greater for anomaly detection, where unsupervised learning methods are essential to ensure practical applicability. To address these issues, we propose Quorum, the first quantum anomaly detection framework designed for unsupervised learning that operates without requiring any training.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Quantum Computing: 11.4 -->
                    
                <!-- Medicine: 10.3 -->
                    
                <!-- LLMs: 4.0 -->
                    
                <!-- Networks: 2.3 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Reinforcement Learning: 1.8 -->
                    
                <!-- RAG: 1.7 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- T2I: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -10.5201
                </span>
                <a href="https://arxiv.org/abs/2504.12586" target="_blank" rel="noopener noreferrer">Quantum Search on Bipartite Multigraphs</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Gustavo Alves Bezerra, Andris Ambainis, Renato Portugal
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Quantum walks provide a powerful framework for achieving algorithmic speedup in quantum computing. This paper presents a quantum search algorithm for 2-tessellable graphs, a generalization of bipartite graphs, achieving a quadratic speedup over classical Markov chain-based search methods. Our approa</span>
                
                <span class="abstract-full" style="display: none;">Quantum walks provide a powerful framework for achieving algorithmic speedup in quantum computing. This paper presents a quantum search algorithm for 2-tessellable graphs, a generalization of bipartite graphs, achieving a quadratic speedup over classical Markov chain-based search methods. Our approach employs an adapted version of the Szegedy quantum walk model (adapted SzQW), which takes place on bipartite graphs, and an adapted version of Staggered Quantum Walks (Adapted StQW), which takes place on 2-tessellable graphs, with the goal of efficiently finding a marked vertex by querying an oracle. The Ambainis, Gily\'en, Jeffery, and Kokainis' algorithm (AGJK), which provides a quadratic speedup on balanced bipartite graphs, is used as a subroutine in our algorithm. Our approach generalizes existing quantum walk techniques and offers a quadratic speedup in the number of queries needed, demonstrating the utility of our adapted quantum walk models in a broader class of graphs.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Quantum Computing: 15.8 -->
                    
                <!-- Medicine: 4.1 -->
                    
                <!-- LLMs: 3.7 -->
                    
                <!-- Networks: 1.9 -->
                    
                <!-- Reinforcement Learning: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Math: 1.3 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Pathfinding: 1.2 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -14.7643
                </span>
                <a href="https://arxiv.org/abs/2401.07912" target="_blank" rel="noopener noreferrer">Lower Bounds for Unitary Property Testing with Proofs and Advice</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jordi Weggemans
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In unitary property testing a quantum algorithm, also known as a tester, is given query access to a black-box unitary and has to decide whether it satisfies some property. We propose a new technique for proving lower bounds on the quantum query complexity of unitary property testing and related prob</span>
                
                <span class="abstract-full" style="display: none;">In unitary property testing a quantum algorithm, also known as a tester, is given query access to a black-box unitary and has to decide whether it satisfies some property. We propose a new technique for proving lower bounds on the quantum query complexity of unitary property testing and related problems, which utilises its connection to unitary channel discrimination. The main advantage of this technique is that all obtained lower bounds hold for any $\mathsf{C}$-tester with $\mathsf{C} \subseteq \mathsf{QMA}(2)/\mathsf{qpoly}$, showing that even having access to both (unentangled) quantum proofs and advice does not help for many unitary property testing problems. We apply our technique to prove lower bounds for problems like quantum phase estimation, the entanglement entropy problem, quantum Gibbs sampling and more, removing all logarithmic factors in the lower bounds obtained by the sample-to-query lifting theorem of Wang and Zhang (2023). As a direct corollary, we show that there exist quantum oracles relative to which $\mathsf{QMA}(2) \not\supset \mathsf{SBQP}$ and $\mathsf{QMA}/\mathsf{qpoly} \not\supset \mathsf{SBQP}$. The former shows that, at least in a black-box way, having unentangled quantum proofs does not help in solving problems that require high precision.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Quantum Computing: 20.3 -->
                    
                <!-- LLMs: 3.6 -->
                    
                <!-- Medicine: 3.4 -->
                    
                <!-- Networks: 2.4 -->
                    
                <!-- Math: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- RAG: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -14.9744
                </span>
                <a href="https://arxiv.org/abs/2412.14639" target="_blank" rel="noopener noreferrer">A Shapley Value Estimation Speedup for Efficient Explainable Quantum AI</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Iain Burge, Michel Barbeau, Joaquin Garcia-Alfaro
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This work focuses on developing efficient post-hoc explanations for quantum AI algorithms. In classical contexts, the cooperative game theory concept of the Shapley value adapts naturally to post-hoc explanations, where it can be used to identify which factors are important in an AI's decision-makin</span>
                
                <span class="abstract-full" style="display: none;">This work focuses on developing efficient post-hoc explanations for quantum AI algorithms. In classical contexts, the cooperative game theory concept of the Shapley value adapts naturally to post-hoc explanations, where it can be used to identify which factors are important in an AI's decision-making process. An interesting question is how to translate Shapley values to the quantum setting and whether quantum effects could be used to accelerate their calculation. We propose quantum algorithms that can extract Shapley values within some confidence interval. Our method is capable of quadratically outperforming classical Monte Carlo approaches to approximating Shapley values up to polylogarithmic factors in various circumstances. We demonstrate the validity of our approach empirically with specific voting games and provide rigorous proofs of performance for general cooperative games.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Quantum Computing: 18.7 -->
                    
                <!-- LLMs: 7.0 -->
                    
                <!-- Medicine: 3.7 -->
                    
                <!-- Networks: 2.1 -->
                    
                <!-- Reinforcement Learning: 1.8 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- Math: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- RAG: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -16.6627
                </span>
                <a href="https://arxiv.org/abs/2504.12729" target="_blank" rel="noopener noreferrer">Dead Gate Elimination</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yanbin Chen, Christian B. Mendl, Helmut Seidl
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Hybrid quantum algorithms combine the strengths of quantum and classical computing. Many quantum algorithms, such as the variational quantum eigensolver (VQE), leverage this synergy. However, quantum circuits are executed in full, even when only subsets of measurement outcomes contribute to subseque</span>
                
                <span class="abstract-full" style="display: none;">Hybrid quantum algorithms combine the strengths of quantum and classical computing. Many quantum algorithms, such as the variational quantum eigensolver (VQE), leverage this synergy. However, quantum circuits are executed in full, even when only subsets of measurement outcomes contribute to subsequent classical computations. In this manuscript, we propose a novel circuit optimization technique that identifies and removes dead gates. We prove that the removal of dead gates has no influence on the probability distribution of the measurement outcomes that contribute to the subsequent calculation result. We implemented and evaluated our optimization on a VQE instance, a quantum phase estimation (QPE) instance, and hybrid programs embedded with random circuits of varying circuit width, confirming its capability to remove a non-trivial number of dead gates in real-world algorithms. The effect of our optimization scales up as more measurement outcomes are identified as non-contributory, resulting in a proportionally greater reduction of dead gates.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Quantum Computing: 18.7 -->
                    
                <!-- LLMs: 6.1 -->
                    
                <!-- Reinforcement Learning: 2.5 -->
                    
                <!-- Medicine: 2.1 -->
                    
                <!-- Math: 1.6 -->
                    
                <!-- Networks: 1.5 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -17.5185
                </span>
                <a href="https://arxiv.org/abs/2504.06932" target="_blank" rel="noopener noreferrer">Maximizing Battery Storage Profits via High-Frequency Intraday Trading</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: David Schaurecker, David Wozabal, Nils L\"ohndorf, Thorsten Staake
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Maximizing revenue for grid-scale battery energy storage systems in continuous intraday electricity markets requires strategies that are able to seize trading opportunities as soon as new information arrives. This paper introduces and evaluates an automated high-frequency trading strategy for batter</span>
                
                <span class="abstract-full" style="display: none;">Maximizing revenue for grid-scale battery energy storage systems in continuous intraday electricity markets requires strategies that are able to seize trading opportunities as soon as new information arrives. This paper introduces and evaluates an automated high-frequency trading strategy for battery energy storage systems trading on the intraday market for power while explicitly considering the dynamics of the limit order book, market rules, and technical parameters. The standard rolling intrinsic strategy is adapted for continuous intraday electricity markets and solved using a dynamic programming approximation that is two to three orders of magnitude faster than an exact mixed-integer linear programming solution. A detailed backtest over a full year of German order book data demonstrates that the proposed dynamic programming formulation does not reduce trading profits and enables the policy to react to every relevant order book update, enabling realistic rapid backtesting. Our results show the significant revenue potential of high-frequency trading: our policy earns 58% more than when re-optimizing only once every hour and 14% more than when re-optimizing once per minute, highlighting that profits critically depend on trading speed. Furthermore, we leverage the speed of our algorithm to train a parametric extension of the rolling intrinsic, increasing yearly revenue by 8.4% out of sample.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #c48298" title="Confidence: 70.1%">
                            Finance
                        </span>
                <!-- SpikingNN: 4.2 -->
                    
                <!-- Hardware: 3.1 -->
                    
                <!-- HPO and AutoML: 2.7 -->
                    
                <!-- Multi-armed Bandit: 2.5 -->
                    
                <!-- Bayesian Optimization: 2.3 -->
                    
                <!-- Fuzzy Logic: 2.2 -->
                    
                <!-- Quality Diversity: 2.1 -->
                    
                <!-- Cool: 2.0 -->
                    
                <!-- Game Theory: 1.8 -->
                    
                <!-- Computer Vision: 1.2 -->
                    
                <!-- Distributed Systems: 1.2 -->
                    
                <!-- LLMs: 1.2 -->
                    
                <!-- Optimizers: 1.2 -->
                    
                <!-- Cryptography: 1.2 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Expert Iteration: 1.1 -->
                    
                <!-- Astronomy: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -19.4028
                </span>
                <a href="https://arxiv.org/abs/2504.12575" target="_blank" rel="noopener noreferrer">Featuremetric benchmarking: Quantum computer benchmarks based on circuit features</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Timothy Proctor, Anh Tran, Xingxin Liu, Aditya Dhumuntarao, Stefan Seritan, Alaina Green, Norbert M Linke
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Benchmarks that concisely summarize the performance of many-qubit quantum computers are essential for measuring progress towards the goal of useful quantum computation. In this work, we present a benchmarking framework that is based on quantifying how a quantum computer's performance on quantum circ</span>
                
                <span class="abstract-full" style="display: none;">Benchmarks that concisely summarize the performance of many-qubit quantum computers are essential for measuring progress towards the goal of useful quantum computation. In this work, we present a benchmarking framework that is based on quantifying how a quantum computer's performance on quantum circuits varies as a function of features of those circuits, such as circuit depth, width, two-qubit gate density, problem input size, or algorithmic depth. Our featuremetric benchmarking framework generalizes volumetric benchmarking -- a widely-used methodology that quantifies performance versus circuit width and depth -- and we show that it enables richer and more faithful models of quantum computer performance. We demonstrate featuremetric benchmarking with example benchmarks run on IBM Q and IonQ systems of up to 27 qubits, and we show how to produce performance summaries from the data using Gaussian process regression. Our data analysis methods are also of interest in the special case of volumetric benchmarking, as they enable the creation of intuitive two-dimensional capability regions using data from few circuits.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Quantum Computing: 17.0 -->
                    
                <!-- LLMs: 7.1 -->
                    
                <!-- Medicine: 4.3 -->
                    
                <!-- Reinforcement Learning: 2.0 -->
                    
                <!-- Math: 1.6 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- GNN: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -28.097
                </span>
                <a href="https://arxiv.org/abs/2504.08141" target="_blank" rel="noopener noreferrer">Variational quantum and neural quantum states algorithms for the linear complementarity problem</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Saibal De, Oliver Knitter, Rohan Kodati, Paramsothy Jayakumar, James Stokes, Shravan Veerapaneni
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Variational quantum algorithms (VQAs) are promising hybrid quantum-classical methods designed to leverage the computational advantages of quantum computing while mitigating the limitations of current noisy intermediate-scale quantum (NISQ) hardware. Although VQAs have been demonstrated as proofs of </span>
                
                <span class="abstract-full" style="display: none;">Variational quantum algorithms (VQAs) are promising hybrid quantum-classical methods designed to leverage the computational advantages of quantum computing while mitigating the limitations of current noisy intermediate-scale quantum (NISQ) hardware. Although VQAs have been demonstrated as proofs of concept, their practical utility in solving real-world problems -- and whether quantum-inspired classical algorithms can match their performance -- remains an open question. We present a novel application of the variational quantum linear solver (VQLS) and its classical neural quantum states-based counterpart, the variational neural linear solver (VNLS), as key components within a minimum map Newton solver for a complementarity-based rigid body contact model. We demonstrate using the VNLS that our solver accurately simulates the dynamics of rigid spherical bodies during collision events. These results suggest that quantum and quantum-inspired linear algebra algorithms can serve as viable alternatives to standard linear algebra solvers for modeling certain physical systems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Quantum Computing: 35.1 -->
                    
                <!-- LLMs: 3.9 -->
                    
                <!-- Medicine: 3.2 -->
                    
                <!-- Reinforcement Learning: 2.2 -->
                    
                <!-- Math: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- Networks: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -39.6478
                </span>
                <a href="https://arxiv.org/abs/2503.06341" target="_blank" rel="noopener noreferrer">Digital Zero-Noise Extrapolation with Quantum Circuit Unoptimization</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Elijah Pelofske, Vincent Russo
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Quantum circuit unoptimization is an algorithm that transforms a quantum circuit into a different circuit that uses more gate operations while maintaining the same unitary transformation. We demonstrate that this method can implement digital zero-noise extrapolation (ZNE), a quantum error mitigation</span>
                
                <span class="abstract-full" style="display: none;">Quantum circuit unoptimization is an algorithm that transforms a quantum circuit into a different circuit that uses more gate operations while maintaining the same unitary transformation. We demonstrate that this method can implement digital zero-noise extrapolation (ZNE), a quantum error mitigation technique. By employing quantum circuit unoptimization as a form of circuit folding, noise can be systematically amplified. The key advantages of this approach are twofold. First, its ability to generate an exponentially increasing number of distinct circuit variants as the noise level is amplified, which allows noise averaging over many circuit instances with slightly different circuit structure which mitigates the effect of biased error propagation because of the significantly altered circuit structure from quantum circuit unoptimization, or highly biased local noise on a quantum processor. Second, quantum circuit unoptimization by design resists circuit simplification back to the original unmodified circuit, making it plausible to use ZNE in contexts where circuit compiler optimization is applied server-side. We evaluate the effectiveness of quantum circuit unoptimization as a noise-scaling method for ZNE in two test cases using depolarizing noise numerical simulations: random quantum volume circuits, where the observable is the heavy output probability, and QAOA circuits for the (unweighted) maximum cut problem on random 3-regular graphs, where the observable is the cut value. We show that using quantum circuit unoptimization to perform ZNE can approximately recover signal from noisy quantum simulations.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Quantum Computing: 49.6 -->
                    
                <!-- Math: 2.8 -->
                    
                <!-- Networks: 2.6 -->
                    
                <!-- Reinforcement Learning: 2.5 -->
                    
                <!-- LLMs: 2.3 -->
                    
                <!-- Evolutionary Algorithms: 2.2 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Medicine: 1.5 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- Pathfinding: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -40.2521
                </span>
                <a href="https://arxiv.org/abs/2504.08876" target="_blank" rel="noopener noreferrer">Is Productivity in Quantum Programming Equivalent to Expressiveness?</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Francini Corrales-Garro, Danny Valerio-Ram\'irez, Santiago N\'u\~nez-Corrales
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The expressiveness of quantum programming languages plays a crucial role in the efficient and comprehensible representation of quantum algorithms. Unlike classical programming languages, which offer mature and well-defined abstraction mechanisms, quantum languages must integrate cognitively challeng</span>
                
                <span class="abstract-full" style="display: none;">The expressiveness of quantum programming languages plays a crucial role in the efficient and comprehensible representation of quantum algorithms. Unlike classical programming languages, which offer mature and well-defined abstraction mechanisms, quantum languages must integrate cognitively challenging concepts such as superposition, interference and entanglement while maintaining clarity and usability. However, identifying and characterizing differences in expressiveness between quantum programming paradigms remains an open area of study. Our work investigates the landscape of expressiveness through a comparative analysis of hosted quantum programming languages such as Qiskit, Cirq, Qrisp, and quAPL, and standalone languages including Q# and Qmod. We focused on evaluating how different quantum programming languages support the implementation of core quantum algorithms -- Deutsch-Jozsa, Simon, Bernstein-Vazirani, and Grover -- using expressiveness metrics: Lines of Code (LOC), Cyclomatic Complexity (CC), and Halstead Complexity (HC) metrics as proxies for developer productivity. Our findings suggest that different quantum programming paradigms offer distinct trade-offs between expressiveness and productivity, highlighting the importance of language design in quantum software development.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Quantum Computing: 30.2 -->
                    
                <!-- LLMs: 8.6 -->
                    
                <!-- Medicine: 5.9 -->
                    
                <!-- Blockchain: 2.4 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -53.7994
                </span>
                <a href="https://arxiv.org/abs/2504.07048" target="_blank" rel="noopener noreferrer">Context Switching for Secure Multi-programming of Near-Term Quantum Computers</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Avinash Kumar, Meng Wang, Chenxu Liu, Ang Li, Prashant J. Nair, Poulami Das
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Multi-programming quantum computers improve device utilization and throughput. However, crosstalk from concurrent two-qubit CNOT gates poses security risks, compromising the fidelity and output of co-running victim programs. We design Zero Knowledge Tampering Attacks (ZKTAs), using which attackers c</span>
                
                <span class="abstract-full" style="display: none;">Multi-programming quantum computers improve device utilization and throughput. However, crosstalk from concurrent two-qubit CNOT gates poses security risks, compromising the fidelity and output of co-running victim programs. We design Zero Knowledge Tampering Attacks (ZKTAs), using which attackers can exploit crosstalk without knowledge of the hardware error profile. ZKTAs can alter victim program outputs in 40% of cases on commercial systems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge high-confidence" style="background-color: #d37d97" title="Confidence: 80.7%">
                            Quantum Computing
                        </span>
                <!-- LLMs: 8.1 -->
                    
                <!-- Medicine: 6.5 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- RAG: 1.8 -->
                    
                <!-- Math: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Networks: 1.6 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- T2I: 1.0 -->
                    
                
            </div>
        </div>
        
    </div>
    
    <div class="date-section">
        <h2 class="date-header">2025-04-17</h2>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.9594
                </span>
                <a href="https://arxiv.org/abs/2312.06923" target="_blank" rel="noopener noreferrer">Nonlinear Expectation Inference for Efficient Uncertainty Quantification and History Matching of Transient Darcy Flows in Porous Media with Random Parameters Under Distribution Uncertainty</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zhao Zhang, Xinpeng Li, Menghan Li, Jiayu Zhai, Piyang Liu, Xia Yan, Kai Zhang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The uncertainty quantification of Darcy flows using history matching is important for the evaluation and prediction of subsurface reservoir performance. Conventional methods aim to obtain the maximum a posterior or maximum likelihood estimate (MLE) using gradient-based, heuristic or ensemble-based m</span>
                
                <span class="abstract-full" style="display: none;">The uncertainty quantification of Darcy flows using history matching is important for the evaluation and prediction of subsurface reservoir performance. Conventional methods aim to obtain the maximum a posterior or maximum likelihood estimate (MLE) using gradient-based, heuristic or ensemble-based methods. These methods can be computationally expensive for high-dimensional problems since forward simulation needs to be run iteratively as physical parameters are updated. In the current study, we propose a nonlinear expectation inference (NEI) method for efficient history matching and uncertainty quantification accounting for distribution or Knightian uncertainty. Forward simulation runs are conducted on prior realisations once, and then a range of expectations are computed in the data space based on subsets of prior realisations with no repetitive forward runs required. In NEI, no prior probability distribution for data is assumed. Instead, the probability distribution is assumed to be uncertain with prior and posterior uncertainty quantified by nonlinear expectations. The inferred result of NEI is the posterior subsets on which the expected flow rates are consistent with observation. The accuracy and efficiency of the new method are validated using single- and two-phase Darcy flows in 2D and 3D heterogeneous reservoirs.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 11.9 -->
                    
                <!-- LLMs: 3.8 -->
                    
                <!-- Quantum Computing: 2.5 -->
                    
                <!-- Robotics: 1.8 -->
                    
                <!-- Math: 1.8 -->
                    
                <!-- Networks: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -7.4669
                </span>
                <a href="https://arxiv.org/abs/2504.09438" target="_blank" rel="noopener noreferrer">Cartographers in Cubicles: How Training and Preferences of Mapmakers Interplay with Structures and Norms in Not-for-Profit Organizations</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Arpit Narechania, Alex Endert, Clio Andris
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Choropleth maps are a common and effective way to visualize geographic thematic data. Although cartographers have established many principles about map design, data binning and color usage, less is known about how mapmakers make individual decisions in practice. We interview 16 cartographers and geo</span>
                
                <span class="abstract-full" style="display: none;">Choropleth maps are a common and effective way to visualize geographic thematic data. Although cartographers have established many principles about map design, data binning and color usage, less is known about how mapmakers make individual decisions in practice. We interview 16 cartographers and geographic information systems (GIS) experts from 13 government organizations, NGOs, and federal agencies about their choropleth mapmaking decisions and workflows. We categorize our findings and report on how mapmakers follow cartographic guidelines and personal rules of thumb, collaborate with other stakeholders within and outside their organization, and how organizational structures and norms are tied to decision-making during data preparation, data analysis, data binning, map styling, and map post-processing. We find several points of variation as well as regularity across mapmakers and organizations and present takeaways to inform cartographic education and practice, including broader implications and opportunities for CSCW, HCI, and information visualization researchers and practitioners.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 22.0 -->
                    
                <!-- LLMs: 10.8 -->
                    
                <!-- Quantum Computing: 2.6 -->
                    
                <!-- Robotics: 2.4 -->
                    
                <!-- RAG: 2.2 -->
                    
                <!-- 3D: 1.9 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- T2I: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -9.1223
                </span>
                <a href="https://arxiv.org/abs/2504.10001" target="_blank" rel="noopener noreferrer">GaussVideoDreamer: 3D Scene Generation with Video Diffusion and Inconsistency-Aware Gaussian Splatting</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Junlin Hao, Peiheng Wang, Haoyang Wang, Xinggong Zhang, Zongming Guo
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Single-image 3D scene reconstruction presents significant challenges due to its inherently ill-posed nature and limited input constraints. Recent advances have explored two promising directions: multiview generative models that train on 3D consistent datasets but struggle with out-of-distribution ge</span>
                
                <span class="abstract-full" style="display: none;">Single-image 3D scene reconstruction presents significant challenges due to its inherently ill-posed nature and limited input constraints. Recent advances have explored two promising directions: multiview generative models that train on 3D consistent datasets but struggle with out-of-distribution generalization, and 3D scene inpainting and completion frameworks that suffer from cross-view inconsistency and suboptimal error handling, as they depend exclusively on depth data or 3D smoothness, which ultimately degrades output quality and computational performance. Building upon these approaches, we present GaussVideoDreamer, which advances generative multimedia approaches by bridging the gap between image, video, and 3D generation, integrating their strengths through two key innovations: (1) A progressive video inpainting strategy that harnesses temporal coherence for improved multiview consistency and faster convergence. (2) A 3D Gaussian Splatting consistency mask to guide the video diffusion with 3D consistent multiview evidence. Our pipeline combines three core components: a geometry-aware initialization protocol, Inconsistency-Aware Gaussian Splatting, and a progressive video inpainting strategy. Experimental results demonstrate that our approach achieves 32% higher LLaVA-IQA scores and at least 2x speedup compared to existing methods while maintaining robust performance across diverse scenes.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge high-confidence" style="background-color: #76aa96" title="Confidence: 83.6%">
                            3D
                        </span>
                <!-- Medicine: 9.7 -->
                    
                <!-- LLMs: 6.3 -->
                    
                <!-- Quantum Computing: 2.9 -->
                    
                <!-- RAG: 2.0 -->
                    
                <!-- T2I: 1.7 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Networks: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                
            </div>
        </div>
        
    </div>
    
    <div class="date-section">
        <h2 class="date-header">2025-04-16</h2>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    23.7161
                </span>
                <a href="https://arxiv.org/abs/2504.10959" target="_blank" rel="noopener noreferrer">Learning-Based User Association for MmWave Vehicular Networks With Kernelized Contextual Bandits</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Xiaoyang He, Xiaoxia Huang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Vehicles require timely channel conditions to determine the base station (BS) to communicate with, but it is costly to estimate the fast-fading mmWave channels frequently. Without additional channel estimations, the proposed Distributed Kernelized Upper Confidence Bound (DK-UCB) algorithm estimates </span>
                
                <span class="abstract-full" style="display: none;">Vehicles require timely channel conditions to determine the base station (BS) to communicate with, but it is costly to estimate the fast-fading mmWave channels frequently. Without additional channel estimations, the proposed Distributed Kernelized Upper Confidence Bound (DK-UCB) algorithm estimates the current instantaneous transmission rates utilizing past contexts, such as the vehicle's location and velocity, along with past instantaneous transmission rates. To capture the nonlinear mapping from a context to the instantaneous transmission rate, DK-UCB maps a context into the reproducing kernel Hilbert space (RKHS) where a linear mapping becomes observable. To improve estimation accuracy, we propose a novel kernel function in RKHS which incorporates the propagation characteristics of the mmWave signals. Moreover, DK-UCB encourages a vehicle to share necessary information when it has conducted significant explorations, which speeds up the learning process while maintaining affordable communication costs.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge high-confidence" style="background-color: #9139ec" title="Confidence: 79.1%">
                            Networks
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #21a5fc" title="Confidence: 72.7%">
                            Multi-armed Bandit
                        </span>
                <!-- Reinforcement Learning: 4.6 -->
                    
                <!-- SpikingNN: 4.6 -->
                    
                <!-- Hardware: 3.3 -->
                    
                <!-- Medicine: 3.0 -->
                    
                <!-- Quantum Computing: 2.6 -->
                    
                <!-- LLMs: 2.5 -->
                    
                <!-- HPO and AutoML: 2.2 -->
                    
                <!-- Finance: 2.0 -->
                    
                <!-- Fuzzy Logic: 2.0 -->
                    
                <!-- Game Theory: 2.0 -->
                    
                <!-- Bayesian Optimization: 2.0 -->
                    
                <!-- Quality Diversity: 1.9 -->
                    
                <!-- Cool: 1.8 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Math: 1.7 -->
                    
                <!-- Federated Learning: 1.6 -->
                    
                <!-- Cryptography: 1.5 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- Pathfinding: 1.3 -->
                    
                <!-- Expert Iteration: 1.2 -->
                    
                <!-- Astronomy: 1.2 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Distributed Systems: 1.2 -->
                    
                <!-- Optimizers: 1.1 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    14.7549
                </span>
                <a href="https://arxiv.org/abs/2504.10865" target="_blank" rel="noopener noreferrer">Understanding the theoretical properties of projected Bellman equation, linear Q-learning, and approximate value iteration</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Han-Dong Lim, Donghwan Lee
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In this paper, we study the theoretical properties of the projected Bellman equation (PBE) and two algorithms to solve this equation: linear Q-learning and approximate value iteration (AVI). We consider two sufficient conditions for the existence of a solution to PBE : strictly negatively row domina</span>
                
                <span class="abstract-full" style="display: none;">In this paper, we study the theoretical properties of the projected Bellman equation (PBE) and two algorithms to solve this equation: linear Q-learning and approximate value iteration (AVI). We consider two sufficient conditions for the existence of a solution to PBE : strictly negatively row dominating diagonal (SNRDD) assumption and a condition motivated by the convergence of AVI. The SNRDD assumption also ensures the convergence of linear Q-learning, and its relationship with the convergence of AVI is examined. Lastly, several interesting observations on the solution of PBE are provided when using $\epsilon$-greedy policy.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge high-confidence" style="background-color: #44f899" title="Confidence: 78.7%">
                            Reinforcement Learning
                        </span>
                <!-- LLMs: 6.2 -->
                    
                <!-- Medicine: 5.8 -->
                    
                <!-- Quantum Computing: 2.7 -->
                    
                <!-- Math: 2.0 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Networks: 1.1 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    12.931
                </span>
                <a href="https://arxiv.org/abs/2504.03784" target="_blank" rel="noopener noreferrer">Robust Reinforcement Learning from Human Feedback for Large Language Models Fine-Tuning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Kai Ye, Hongyi Zhou, Jin Zhu, Francesco Quinzan, Chengchung Shi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Reinforcement learning from human feedback (RLHF) has emerged as a key technique for aligning the output of large language models (LLMs) with human preferences. To learn the reward function, most existing RLHF algorithms use the Bradley-Terry model, which relies on assumptions about human preference</span>
                
                <span class="abstract-full" style="display: none;">Reinforcement learning from human feedback (RLHF) has emerged as a key technique for aligning the output of large language models (LLMs) with human preferences. To learn the reward function, most existing RLHF algorithms use the Bradley-Terry model, which relies on assumptions about human preferences that may not reflect the complexity and variability of real-world judgments. In this paper, we propose a robust algorithm to enhance the performance of existing approaches under such reward model misspecifications. Theoretically, our algorithm reduces the variance of reward and policy estimators, leading to improved regret bounds. Empirical evaluations on LLM benchmark datasets demonstrate that the proposed algorithm consistently outperforms existing methods, with 77-81% of responses being favored over baselines on the Anthropic Helpful and Harmless dataset.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge high-confidence" style="background-color: #44f899" title="Confidence: 78.4%">
                            Reinforcement Learning
                        </span>
                <!-- LLMs: 12.3 -->
                    
                <!-- Medicine: 4.4 -->
                    
                <!-- Quantum Computing: 2.4 -->
                    
                <!-- Math: 1.6 -->
                    
                <!-- Federated Learning: 1.6 -->
                    
                <!-- Networks: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    7.1362
                </span>
                <a href="https://arxiv.org/abs/2504.10699" target="_blank" rel="noopener noreferrer">HyRRT-Connect: Bidirectional Motion Planning for Hybrid Dynamical Systems</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Nan Wang, Ricardo G. Sanfelice
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper proposes a bidirectional rapidly-exploring random trees (RRT) algorithm to solve the motion planning problem for hybrid systems. The proposed algorithm, called HyRRT-Connect, propagates in both forward and backward directions in hybrid time until an overlap between the forward and backwar</span>
                
                <span class="abstract-full" style="display: none;">This paper proposes a bidirectional rapidly-exploring random trees (RRT) algorithm to solve the motion planning problem for hybrid systems. The proposed algorithm, called HyRRT-Connect, propagates in both forward and backward directions in hybrid time until an overlap between the forward and backward propagation results is detected. Then, HyRRT-Connect constructs a motion plan through the reversal and concatenation of functions defined on hybrid time domains, ensuring that the motion plan satisfies the given hybrid dynamics. To address the potential discontinuity along the flow caused by tolerating some distance between the forward and backward partial motion plans, we reconstruct the backward partial motion plan by a forward-in-hybrid-time simulation from the final state of the forward partial motion plan. effectively eliminating the discontinuity. The proposed algorithm is applied to an actuated bouncing ball system and a walking robot example to highlight its computational improvement.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge high-confidence" style="background-color: #5caaa5" title="Confidence: 78.5%">
                            Pathfinding
                        </span>
                <!-- Medicine: 4.9 -->
                    
                <!-- Reinforcement Learning: 3.0 -->
                    
                <!-- Robotics: 2.2 -->
                    
                <!-- LLMs: 2.2 -->
                    
                <!-- Networks: 2.2 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Math: 1.5 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- 3D: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    2.755
                </span>
                <a href="https://arxiv.org/abs/2504.10810" target="_blank" rel="noopener noreferrer">PatrolVision: Automated License Plate Recognition in the wild</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Anmol Singhal Navya Singhal
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Adoption of AI driven techniques in public services remains low due to challenges related to accuracy and speed of information at population scale. Computer vision techniques for traffic monitoring have not gained much popularity despite their relative strength in areas such as autonomous driving. D</span>
                
                <span class="abstract-full" style="display: none;">Adoption of AI driven techniques in public services remains low due to challenges related to accuracy and speed of information at population scale. Computer vision techniques for traffic monitoring have not gained much popularity despite their relative strength in areas such as autonomous driving. Despite large number of academic methods for Automatic License Plate Recognition (ALPR) systems, very few provide an end to end solution for patrolling in the city. This paper presents a novel prototype for a low power GPU based patrolling system to be deployed in an urban environment on surveillance vehicles for automated vehicle detection, recognition and tracking. In this work, we propose a complete ALPR system for Singapore license plates having both single and double line creating our own YOLO based network. We focus on unconstrained capture scenarios as would be the case in real world application, where the license plate (LP) might be considerably distorted due to oblique views. In this work, we first detect the license plate from the full image using RFB-Net and rectify multiple distorted license plates in a single image. After that, the detected license plate image is fed to our network for character recognition. We evaluate the performance of our proposed system on a newly built dataset covering more than 16,000 images. The system was able to correctly detect license plates with 86\% precision and recognize characters of a license plate in 67\% of the test set, and 89\% accuracy with one incorrect character (partial match). We also test latency of our system and achieve 64FPS on Tesla P4 GPU</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 66.9%">
                            Computer Vision
                        </span>
                <!-- SpikingNN: 3.5 -->
                    
                <!-- Hardware: 2.8 -->
                    
                <!-- Multi-armed Bandit: 2.6 -->
                    
                <!-- Game Theory: 2.1 -->
                    
                <!-- HPO and AutoML: 2.0 -->
                    
                <!-- Fuzzy Logic: 1.9 -->
                    
                <!-- Bayesian Optimization: 1.8 -->
                    
                <!-- Quality Diversity: 1.8 -->
                    
                <!-- Cool: 1.7 -->
                    
                <!-- Finance: 1.5 -->
                    
                <!-- Medicine: 1.5 -->
                    
                <!-- Astronomy: 1.1 -->
                    
                <!-- LLMs: 1.1 -->
                    
                <!-- Distributed Systems: 1.1 -->
                    
                <!-- Expert Iteration: 1.0 -->
                    
                <!-- Cryptography: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10500" target="_blank" rel="noopener noreferrer">Leveraging Auto-Distillation and Generative Self-Supervised Learning in Residual Graph Transformers for Enhanced Recommender Systems</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Eya Mhedhbi, Youssef Mourchid, Alice Othmani
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper introduces a cutting-edge method for enhancing recommender systems through the integration of generative self-supervised learning (SSL) with a Residual Graph Transformer. Our approach emphasizes the importance of superior data enhancement through the use of pertinent pretext tasks, automa</span>
                
                <span class="abstract-full" style="display: none;">This paper introduces a cutting-edge method for enhancing recommender systems through the integration of generative self-supervised learning (SSL) with a Residual Graph Transformer. Our approach emphasizes the importance of superior data enhancement through the use of pertinent pretext tasks, automated through rationale-aware SSL to distill clear ways of how users and items interact. The Residual Graph Transformer incorporates a topology-aware transformer for global context and employs residual connections to improve graph representation learning. Additionally, an auto-distillation process refines self-supervised signals to uncover consistent collaborative rationales. Experimental evaluations on multiple datasets demonstrate that our approach consistently outperforms baseline methods.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 9.3 -->
                    
                <!-- LLMs: 7.4 -->
                    
                <!-- Quantum Computing: 3.5 -->
                    
                <!-- Networks: 2.2 -->
                    
                <!-- Reinforcement Learning: 2.1 -->
                    
                <!-- 3D: 1.8 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- RAG: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10507" target="_blank" rel="noopener noreferrer">PinRec: Outcome-Conditioned, Multi-Token Generative Retrieval for Industry-Scale Recommendation Systems</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Anirudhan Badrinath, Prabhat Agarwal, Laksh Bhasin, Jaewon Yang, Jiajing Xu, Charles Rosenberg
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Generative retrieval methods utilize generative sequential modeling techniques, such as transformers, to generate candidate items for recommender systems. These methods have demonstrated promising results in academic benchmarks, surpassing traditional retrieval models like two-tower architectures. H</span>
                
                <span class="abstract-full" style="display: none;">Generative retrieval methods utilize generative sequential modeling techniques, such as transformers, to generate candidate items for recommender systems. These methods have demonstrated promising results in academic benchmarks, surpassing traditional retrieval models like two-tower architectures. However, current generative retrieval methods lack the scalability required for industrial recommender systems, and they are insufficiently flexible to satisfy the multiple metric requirements of modern systems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 8.7 -->
                    
                <!-- Medicine: 7.4 -->
                    
                <!-- Quantum Computing: 4.6 -->
                    
                <!-- RAG: 2.5 -->
                    
                <!-- Networks: 2.1 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- T2I: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Math: 1.2 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- Attention: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10512" target="_blank" rel="noopener noreferrer">JEPA4Rec: Learning Effective Language Representations for Sequential Recommendation via Joint Embedding Predictive Architecture</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Minh-Anh Nguyen, Dung D. Le
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Language representation learning has emerged as a promising approach for sequential recommendation, thanks to its ability to learn generalizable representations. However, despite its advantages, this approach still struggles with data sparsity and a limited understanding of common-sense user prefere</span>
                
                <span class="abstract-full" style="display: none;">Language representation learning has emerged as a promising approach for sequential recommendation, thanks to its ability to learn generalizable representations. However, despite its advantages, this approach still struggles with data sparsity and a limited understanding of common-sense user preferences. To address these limitations, we propose $\textbf{JEPA4Rec}$, a framework that combines $\textbf{J}$oint $\textbf{E}$mbedding $\textbf{P}$redictive $\textbf{A}$rchitecture with language modeling of item textual descriptions. JEPA4Rec captures semantically rich and transferable representations, improving recommendation performance and reducing reliance on large-scale pre-training data. Specifically, JEPA4Rec represents items as text sentences by flattening descriptive information such as $\textit{title, category}$, and other attributes. To encode these sentences, we employ a bidirectional Transformer encoder with modified embedding layers tailored for capturing item information in recommendation datasets. We apply masking to text sentences and use them to predict the representations of the unmasked sentences, helping the model learn generalizable item embeddings. To further improve recommendation performance and language understanding, we employ a two-stage training strategy incorporating self-supervised learning losses. Experiments on six real-world datasets demonstrate that JEPA4Rec consistently outperforms state-of-the-art methods, particularly in cross-domain, cross-platform, and low-resource scenarios.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 7.6 -->
                    
                <!-- Medicine: 7.3 -->
                    
                <!-- Quantum Computing: 3.3 -->
                    
                <!-- 3D: 2.1 -->
                    
                <!-- Reinforcement Learning: 2.1 -->
                    
                <!-- Networks: 1.9 -->
                    
                <!-- RAG: 1.6 -->
                    
                <!-- T2I: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Federated Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10519" target="_blank" rel="noopener noreferrer">Toward Super Agent System with Hybrid AI Routers</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yuhang Yao, Haixin Wang, Yibo Chen, Jiawen Wang, Min Chang Jordan Ren, Bosheng Ding, Salman Avestimehr, Chaoyang He
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">AI Agents powered by Large Language Models are transforming the world through enormous applications. A super agent has the potential to fulfill diverse user needs, such as summarization, coding, and research, by accurately understanding user intent and leveraging the appropriate tools to solve tasks</span>
                
                <span class="abstract-full" style="display: none;">AI Agents powered by Large Language Models are transforming the world through enormous applications. A super agent has the potential to fulfill diverse user needs, such as summarization, coding, and research, by accurately understanding user intent and leveraging the appropriate tools to solve tasks. However, to make such an agent viable for real-world deployment and accessible at scale, significant optimizations are required to ensure high efficiency and low cost. This paper presents a design of the Super Agent System. Upon receiving a user prompt, the system first detects the intent of the user, then routes the request to specialized task agents with the necessary tools or automatically generates agentic workflows. In practice, most applications directly serve as AI assistants on edge devices such as phones and robots. As different language models vary in capability and cloud-based models often entail high computational costs, latency, and privacy concerns, we then explore the hybrid mode where the router dynamically selects between local and cloud models based on task complexity. Finally, we introduce the blueprint of an on-device super agent enhanced with cloud. With advances in multi-modality models and edge hardware, we envision that most computations can be handled locally, with cloud collaboration only as needed. Such architecture paves the way for super agents to be seamlessly integrated into everyday life in the near future.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 8.8 -->
                    
                <!-- Medicine: 6.0 -->
                    
                <!-- Reinforcement Learning: 1.9 -->
                    
                <!-- Networks: 1.8 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Robotics: 1.8 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                <!-- Math: 1.3 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10521" target="_blank" rel="noopener noreferrer">Integrating Emotion Distribution Networks and Textual Message Analysis for X User Emotional State Classification</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Pardis Moradbeiki, Mohammad Ali Zare Chahooki
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">As the popularity and reach of social networks continue to surge, a vast reservoir of opinions and sentiments across various subjects inundates these platforms. Among these, X social network (formerly Twitter) stands as a juggernaut, boasting approximately 420 million active users. Extracting users'</span>
                
                <span class="abstract-full" style="display: none;">As the popularity and reach of social networks continue to surge, a vast reservoir of opinions and sentiments across various subjects inundates these platforms. Among these, X social network (formerly Twitter) stands as a juggernaut, boasting approximately 420 million active users. Extracting users' emotional and mental states from their expressed opinions on social media has become a common pursuit. While past methodologies predominantly focused on the textual content of messages to analyze user sentiment, the interactive nature of these platforms suggests a deeper complexity. This study employs hybrid methodologies, integrating textual analysis, profile examination, follower analysis, and emotion dissemination patterns. Initially, user interactions are leveraged to refine emotion classification within messages, encompassing exchanges where users respond to each other. Introducing the concept of a communication tree, a model is extracted to map these interactions. Subsequently, users' bios and interests from this tree are juxtaposed with message text to enrich analysis. Finally, influential figures are identified among users' followers in the communication tree, categorized into different topics to gauge interests. The study highlights that traditional sentiment analysis methodologies, focusing solely on textual content, are inadequate in discerning sentiment towards significant events, notably the presidential election. Comparative analysis with conventional methods reveals a substantial improvement in accuracy with the incorporation of emotion distribution patterns and user profiles. The proposed approach yields a 12% increase in accuracy with emotion distribution patterns and a 15% increase when considering user profiles, underscoring its efficacy in capturing nuanced sentiment dynamics.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 5.0 -->
                    
                <!-- LLMs: 4.7 -->
                    
                <!-- Networks: 3.3 -->
                    
                <!-- Quantum Computing: 2.3 -->
                    
                <!-- Robotics: 2.1 -->
                    
                <!-- Reinforcement Learning: 2.0 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- RAG: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10535" target="_blank" rel="noopener noreferrer">Where Should I Deploy My Contracts? A Practical Experience Report</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: C\u{a}t\u{a}lina Laz\u{a}r, Gabriela Secrieru, Emanuel Onica
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Blockchain networks provide a reliable trust anchor to decentralized applications (DApps) backed by smart contracts. The Ethereum ecosystem now encompasses most blockchain networks that provide compatible support for smart contracts code. Recently, many Ethereum Layer 2 (L2) rollup solutions emerged</span>
                
                <span class="abstract-full" style="display: none;">Blockchain networks provide a reliable trust anchor to decentralized applications (DApps) backed by smart contracts. The Ethereum ecosystem now encompasses most blockchain networks that provide compatible support for smart contracts code. Recently, many Ethereum Layer 2 (L2) rollup solutions emerged, meant to scale the base Layer 1 (L1) network, consequently decreasing transaction fees and diversifying the usage scenarios. Furthermore, the number of blockchain providers that offer access to the network infrastructure for both L1 and L2 continuously increases. A developer is faced with a multitude of deployment options and must weigh between the gains in costs and the losses in trust that are still an issue with L2. A decisive factor in this trade-off can be the use case itself, depending on its security requirements. Still, the evaluation of costs and performance cannot be ignored and should rely on a set of measurable metrics, although choosing the right metrics can be complicated. In this practical experience report, we explore the relevance of several such metrics in choosing between different providers and rollups. For this purpose, we perform evaluations for two use cases of DApps: a voting DApp with high security demands, suited for L1 deployment, and a cost-sensitive supply chain DApp, where L2 can be an option. We analyze a set of basic metrics by comparing these between two highly used access providers, Alchemy and Infura, for the L1 deployment case, and between two of the most popular rollups, Arbitrum One and OP Mainnet (Optimism), for the L2 deployment scenario.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 6.9 -->
                    
                <!-- LLMs: 4.0 -->
                    
                <!-- Quantum Computing: 2.8 -->
                    
                <!-- Reinforcement Learning: 2.1 -->
                    
                <!-- Math: 1.8 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- Networks: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10545" target="_blank" rel="noopener noreferrer">Integrating Textual Embeddings from Contrastive Learning with Generative Recommender for Enhanced Personalization</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yijun Liu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Recent advances in recommender systems have highlighted the complementary strengths of generative modeling and pretrained language models. We propose a hybrid framework that augments the Hierarchical Sequential Transduction Unit (HSTU) generative recommender with BLaIR -- a contrastive text embeddin</span>
                
                <span class="abstract-full" style="display: none;">Recent advances in recommender systems have highlighted the complementary strengths of generative modeling and pretrained language models. We propose a hybrid framework that augments the Hierarchical Sequential Transduction Unit (HSTU) generative recommender with BLaIR -- a contrastive text embedding model. This integration enriches item representations with semantic signals from textual metadata while preserving HSTU's powerful sequence modeling capabilities.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 9.4 -->
                    
                <!-- LLMs: 8.6 -->
                    
                <!-- Quantum Computing: 4.5 -->
                    
                <!-- Networks: 2.7 -->
                    
                <!-- 3D: 2.0 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- RAG: 1.6 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- T2I: 1.3 -->
                    
                <!-- Math: 1.3 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                <!-- Evolutionary Algorithms: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10551" target="_blank" rel="noopener noreferrer">MiMu: Mitigating Multiple Shortcut Learning Behavior of Transformers</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Lili Zhao, Qi Liu, Wei Chen, Liyi Chen, Ruijun Sun, Min Hou, Yang Wang, Shijin Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Empirical Risk Minimization (ERM) models often rely on spurious correlations between features and labels during the learning process, leading to shortcut learning behavior that undermines robustness generalization performance. Current research mainly targets identifying or mitigating a single shortc</span>
                
                <span class="abstract-full" style="display: none;">Empirical Risk Minimization (ERM) models often rely on spurious correlations between features and labels during the learning process, leading to shortcut learning behavior that undermines robustness generalization performance. Current research mainly targets identifying or mitigating a single shortcut; however, in real-world scenarios, cues within the data are diverse and unknown. In empirical studies, we reveal that the models rely to varying extents on different shortcuts. Compared to weak shortcuts, models depend more heavily on strong shortcuts, resulting in their poor generalization ability. To address these challenges, we propose MiMu, a novel method integrated with Transformer-based ERMs designed to Mitigate Multiple shortcut learning behavior, which incorporates self-calibration strategy and self-improvement strategy. In the source model, we preliminarily propose the self-calibration strategy to prevent the model from relying on shortcuts and make overconfident predictions. Then, we further design self-improvement strategy in target model to reduce the reliance on multiple shortcuts. The random mask strategy involves randomly masking partial attention positions to diversify the focus of target model other than concentrating on a fixed region. Meanwhile, the adaptive attention alignment module facilitates the alignment of attention weights to the calibrated source model, without the need for post-hoc attention maps or supervision. Finally, extensive experiments conducted on Natural Language Processing (NLP) and Computer Vision (CV) demonstrate the effectiveness of MiMu in improving robustness generalization abilities.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 5.1 -->
                    
                <!-- Medicine: 4.7 -->
                    
                <!-- Reinforcement Learning: 3.9 -->
                    
                <!-- Federated Learning: 2.6 -->
                    
                <!-- Quantum Computing: 2.0 -->
                    
                <!-- Networks: 1.8 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Math: 1.2 -->
                    
                <!-- 3D: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10555" target="_blank" rel="noopener noreferrer">Beyond the Generative Learning Trilemma: Generative Model Assessment in Data Scarcity Domains</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Marco Salm\`e, Lorenzo Tronchin, Rosa Sicilia, Paolo Soda, Valerio Guarrasi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Data scarcity remains a critical bottleneck impeding technological advancements across various domains, including but not limited to medicine and precision agriculture. To address this challenge, we explore the potential of Deep Generative Models (DGMs) in producing synthetic data that satisfies the</span>
                
                <span class="abstract-full" style="display: none;">Data scarcity remains a critical bottleneck impeding technological advancements across various domains, including but not limited to medicine and precision agriculture. To address this challenge, we explore the potential of Deep Generative Models (DGMs) in producing synthetic data that satisfies the Generative Learning Trilemma: fidelity, diversity, and sampling efficiency. However, recognizing that these criteria alone are insufficient for practical applications, we extend the trilemma to include utility, robustness, and privacy, factors crucial for ensuring the applicability of DGMs in real-world scenarios. Evaluating these metrics becomes particularly challenging in data-scarce environments, as DGMs traditionally rely on large datasets to perform optimally. This limitation is especially pronounced in domains like medicine and precision agriculture, where ensuring acceptable model performance under data constraints is vital. To address these challenges, we assess the Generative Learning Trilemma in data-scarcity settings using state-of-the-art evaluation metrics, comparing three prominent DGMs: Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), and Diffusion Models (DMs). Furthermore, we propose a comprehensive framework to assess utility, robustness, and privacy in synthetic data generated by DGMs. Our findings demonstrate varying strengths among DGMs, with each model exhibiting unique advantages based on the application context. This study broadens the scope of the Generative Learning Trilemma, aligning it with real-world demands and providing actionable guidance for selecting DGMs tailored to specific applications.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 8.0 -->
                    
                <!-- Medicine: 6.2 -->
                    
                <!-- Quantum Computing: 2.8 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- Networks: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- RAG: 1.4 -->
                    
                <!-- T2I: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10558" target="_blank" rel="noopener noreferrer">Enhancing Image Restoration through Learning Context-Rich and Detail-Accurate Features</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Hu Gao, Depeng Dang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Image restoration involves recovering high-quality images from their corrupted versions, requiring a nuanced balance between spatial details and contextual information. While certain methods address this balance, they predominantly emphasize spatial aspects, neglecting frequency variation comprehens</span>
                
                <span class="abstract-full" style="display: none;">Image restoration involves recovering high-quality images from their corrupted versions, requiring a nuanced balance between spatial details and contextual information. While certain methods address this balance, they predominantly emphasize spatial aspects, neglecting frequency variation comprehension. In this paper, we present a multi-scale design that optimally balances these competing objectives, seamlessly integrating spatial and frequency domain knowledge to selectively recover the most informative information. Specifically, we develop a hybrid scale frequency selection block (HSFSBlock), which not only captures multi-scale information from the spatial domain, but also selects the most informative components for image restoration in the frequency domain. Furthermore, to mitigate the inherent noise introduced by skip connections employing only addition or concatenation, we introduce a skip connection attention mechanism (SCAM) to selectively determines the information that should propagate through skip connections. The resulting tightly interlinked architecture, named as LCDNet. Extensive experiments conducted across diverse image restoration tasks showcase that our model attains performance levels that are either superior or comparable to those of state-of-the-art algorithms.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 8.3 -->
                    
                <!-- Medicine: 4.8 -->
                    
                <!-- Quantum Computing: 3.9 -->
                    
                <!-- Reinforcement Learning: 2.3 -->
                    
                <!-- GNN: 2.2 -->
                    
                <!-- Networks: 1.9 -->
                    
                <!-- 3D: 1.8 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- RAG: 1.2 -->
                    
                <!-- T2I: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Math: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10559" target="_blank" rel="noopener noreferrer">Efficient Process Reward Model Training via Active Learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Keyu Duan, Zichen Liu, Xin Mao, Tianyu Pang, Changyu Chen, Qiguang Chen, Michael Qizhe Shieh, Longxu Dou
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Process Reward Models (PRMs) provide step-level supervision to large language models (LLMs), but scaling up training data annotation remains challenging for both humans and LLMs. To address this limitation, we propose an active learning approach, ActPRM, which proactively selects the most uncertain </span>
                
                <span class="abstract-full" style="display: none;">Process Reward Models (PRMs) provide step-level supervision to large language models (LLMs), but scaling up training data annotation remains challenging for both humans and LLMs. To address this limitation, we propose an active learning approach, ActPRM, which proactively selects the most uncertain samples for training, substantially reducing labeling costs. During training, we use the PRM to estimate uncertainty after the forward pass, retaining only highly uncertain data. A capable yet costly reasoning model then labels this data. Then we compute the loss with respect to the labels and update the PRM's weights. We compare ActPRM vs. vanilla fine-tuning, on a pool-based active learning setting, demonstrating that ActPRM reduces 50% annotation, but achieving the comparable or even better performance. Beyond annotation efficiency, we further advance the actively trained PRM by filtering over 1M+ math reasoning trajectories with ActPRM, retaining 60% of the data. A subsequent training on this selected dataset yields a new state-of-the-art (SOTA) PRM on ProcessBench (75.0%) and PRMBench (65.5%) compared with same sized models.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 8.6 -->
                    
                <!-- LLMs: 6.5 -->
                    
                <!-- Reinforcement Learning: 3.6 -->
                    
                <!-- Quantum Computing: 2.4 -->
                    
                <!-- Federated Learning: 2.3 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Networks: 1.5 -->
                    
                <!-- Math: 1.4 -->
                    
                <!-- RAG: 1.3 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- T2I: 1.1 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10561" target="_blank" rel="noopener noreferrer">Self-Controlled Dynamic Expansion Model for Continual Learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Runqing Wu, Fei Ye, Rongyao Hu, Guoxi Huang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Continual Learning (CL) epitomizes an advanced training paradigm wherein prior data samples remain inaccessible during the acquisition of new tasks. Numerous investigations have delved into leveraging a pre-trained Vision Transformer (ViT) to enhance model efficacy in continual learning. Nonetheless</span>
                
                <span class="abstract-full" style="display: none;">Continual Learning (CL) epitomizes an advanced training paradigm wherein prior data samples remain inaccessible during the acquisition of new tasks. Numerous investigations have delved into leveraging a pre-trained Vision Transformer (ViT) to enhance model efficacy in continual learning. Nonetheless, these approaches typically utilize a singular, static backbone, which inadequately adapts to novel tasks, particularly when engaging with diverse data domains, due to a substantial number of inactive parameters. This paper addresses this limitation by introducing an innovative Self-Controlled Dynamic Expansion Model (SCDEM), which orchestrates multiple distinct trainable pre-trained ViT backbones to furnish diverse and semantically enriched representations. Specifically, by employing the multi-backbone architecture as a shared module, the proposed SCDEM dynamically generates a new expert with minimal parameters to accommodate a new task. A novel Collaborative Optimization Mechanism (COM) is introduced to synergistically optimize multiple backbones by harnessing prediction signals from historical experts, thereby facilitating new task learning without erasing previously acquired knowledge. Additionally, a novel Feature Distribution Consistency (FDC) approach is proposed to align semantic similarity between previously and currently learned representations through an optimal transport distance-based mechanism, effectively mitigating negative knowledge transfer effects. Furthermore, to alleviate over-regularization challenges, this paper presents a novel Dynamic Layer-Wise Feature Attention Mechanism (DLWFAM) to autonomously determine the penalization intensity on each trainable representation layer. An extensive series of experiments have been conducted to evaluate the proposed methodology's efficacy, with empirical results corroborating that the approach attains state-of-the-art performance.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Networks: 4.8 -->
                    
                <!-- LLMs: 4.8 -->
                    
                <!-- Medicine: 3.4 -->
                    
                <!-- Reinforcement Learning: 3.2 -->
                    
                <!-- Quantum Computing: 2.5 -->
                    
                <!-- GNN: 2.3 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- Federated Learning: 1.6 -->
                    
                <!-- RAG: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10567" target="_blank" rel="noopener noreferrer">H3AE: High Compression, High Speed, and High Quality AutoEncoder for Video Diffusion Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yushu Wu, Yanyu Li, Ivan Skorokhodov, Anil Kag, Willi Menapace, Sharath Girish, Aliaksandr Siarohin, Yanzhi Wang, Sergey Tulyakov
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Autoencoder (AE) is the key to the success of latent diffusion models for image and video generation, reducing the denoising resolution and improving efficiency. However, the power of AE has long been underexplored in terms of network design, compression ratio, and training strategy. In this work, w</span>
                
                <span class="abstract-full" style="display: none;">Autoencoder (AE) is the key to the success of latent diffusion models for image and video generation, reducing the denoising resolution and improving efficiency. However, the power of AE has long been underexplored in terms of network design, compression ratio, and training strategy. In this work, we systematically examine the architecture design choices and optimize the computation distribution to obtain a series of efficient and high-compression video AEs that can decode in real time on mobile devices. We also unify the design of plain Autoencoder and image-conditioned I2V VAE, achieving multifunctionality in a single network. In addition, we find that the widely adopted discriminative losses, i.e., GAN, LPIPS, and DWT losses, provide no significant improvements when training AEs at scale. We propose a novel latent consistency loss that does not require complicated discriminator design or hyperparameter tuning, but provides stable improvements in reconstruction quality. Our AE achieves an ultra-high compression ratio and real-time decoding speed on mobile while outperforming prior art in terms of reconstruction metrics by a large margin. We finally validate our AE by training a DiT on its latent space and demonstrate fast, high-quality text-to-video generation capability.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 9.0 -->
                    
                <!-- Medicine: 5.4 -->
                    
                <!-- Quantum Computing: 2.7 -->
                    
                <!-- Reinforcement Learning: 1.9 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- Networks: 1.2 -->
                    
                <!-- T2I: 1.2 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Math: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Attention: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10568" target="_blank" rel="noopener noreferrer">AgMMU: A Comprehensive Agricultural Multimodal Understanding and Reasoning Benchmark</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Aruna Gauba, Irene Pi, Yunze Man, Ziqi Pang, Vikram S. Adve, Yu-Xiong Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We curate a dataset AgMMU for evaluating and developing vision-language models (VLMs) to produce factually accurate answers for knowledge-intensive expert domains. Our AgMMU concentrates on one of the most socially beneficial domains, agriculture, which requires connecting detailed visual observatio</span>
                
                <span class="abstract-full" style="display: none;">We curate a dataset AgMMU for evaluating and developing vision-language models (VLMs) to produce factually accurate answers for knowledge-intensive expert domains. Our AgMMU concentrates on one of the most socially beneficial domains, agriculture, which requires connecting detailed visual observation with precise knowledge to diagnose, e.g., pest identification, management instructions, etc. As a core uniqueness of our dataset, all facts, questions, and answers are extracted from 116,231 conversations between real-world users and authorized agricultural experts. After a three-step dataset curation pipeline with GPT-4o, LLaMA models, and human verification, AgMMU features an evaluation set of 5,460 multiple-choice questions (MCQs) and open-ended questions (OEQs). We also provide a development set that contains 205,399 pieces of agricultural knowledge information, including disease identification, symptoms descriptions, management instructions, insect and pest identification, and species identification. As a multimodal factual dataset, it reveals that existing VLMs face significant challenges with questions requiring both detailed perception and factual knowledge. Moreover, open-source VLMs still demonstrate a substantial performance gap compared to proprietary ones. To advance knowledge-intensive VLMs, we conduct fine-tuning experiments using our development set, which improves LLaVA-1.5 evaluation accuracy by up to 3.1%. We hope that AgMMU can serve both as an evaluation benchmark dedicated to agriculture and a development suite for incorporating knowledge-intensive expertise into general-purpose VLMs.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 9.4 -->
                    
                <!-- LLMs: 7.9 -->
                    
                <!-- Quantum Computing: 3.1 -->
                    
                <!-- 3D: 2.5 -->
                    
                <!-- Networks: 2.0 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- RAG: 1.5 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- T2I: 1.2 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10609" target="_blank" rel="noopener noreferrer">Finding Pathways in Reaction Networks guided by Energy Barriers using Integer Linear Programming</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Adittya Pal, Rolf Fagerberg, Jakob Lykke Andersen, Peter Dittrich, Daniel Merkle
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Analyzing synthesis pathways for target molecules in a chemical reaction network annotated with information on the kinetics of individual reactions is an area of active study. This work presents a computational methodology for searching for pathways in reaction networks which is based on integer lin</span>
                
                <span class="abstract-full" style="display: none;">Analyzing synthesis pathways for target molecules in a chemical reaction network annotated with information on the kinetics of individual reactions is an area of active study. This work presents a computational methodology for searching for pathways in reaction networks which is based on integer linear programming and the modeling of reaction networks by directed hypergraphs. Often multiple pathways fit the given search criteria. To rank them, we develop an objective function based on physical arguments maximizing the probability of the pathway. We furthermore develop an automated pipeline to estimate the energy barriers of individual reactions in reaction networks. Combined, the methodology facilitates flexible and kinetically informed pathway investigations on large reaction networks by computational means, even for networks coming without kinetic annotation, such as those created via generative approaches for expanding molecular spaces.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 6.7 -->
                    
                <!-- LLMs: 4.6 -->
                    
                <!-- Quantum Computing: 3.4 -->
                    
                <!-- Math: 2.2 -->
                    
                <!-- Reinforcement Learning: 1.8 -->
                    
                <!-- Networks: 1.8 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Pathfinding: 1.1 -->
                    
                <!-- Federated Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10612" target="_blank" rel="noopener noreferrer">Energy Matching: Unifying Flow Matching and Energy-Based Models for Generative Modeling</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Michal Balcerak, Tamaz Amiranashvili, Suprosanna Shit, Antonio Terpin, Sebastian Kaltenbach, Petros Koumoutsakos, Bjoern Menze
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Generative models often map noise to data by matching flows or scores, but these approaches become cumbersome for incorporating partial observations or additional priors. Inspired by recent advances in Wasserstein gradient flows, we propose Energy Matching, a framework that unifies flow-based approa</span>
                
                <span class="abstract-full" style="display: none;">Generative models often map noise to data by matching flows or scores, but these approaches become cumbersome for incorporating partial observations or additional priors. Inspired by recent advances in Wasserstein gradient flows, we propose Energy Matching, a framework that unifies flow-based approaches with the flexibility of energy-based models (EBMs). Far from the data manifold, samples move along curl-free, optimal transport paths from noise to data. As they approach the data manifold, an entropic energy term guides the system into a Boltzmann equilibrium distribution, explicitly capturing the underlying likelihood structure of the data. We parameterize this dynamic with a single time-independent scalar field, which serves as both a powerful generator and a flexible prior for effective regularization of inverse problems. Our method substantially outperforms existing EBMs on CIFAR-10 generation (FID 3.97 compared to 8.61), while retaining the simulation-free training of transport-based approaches away from the data manifold. Additionally, we exploit the flexibility of our method and introduce an interaction energy for diverse mode exploration. Our approach focuses on learning a static scalar potential energy -- without time conditioning, auxiliary generators, or additional networks -- marking a significant departure from recent EBM methods. We believe this simplified framework significantly advances EBM capabilities and paves the way for their broader adoption in generative modeling across diverse domains.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 7.5 -->
                    
                <!-- LLMs: 5.3 -->
                    
                <!-- Reinforcement Learning: 3.0 -->
                    
                <!-- Quantum Computing: 2.9 -->
                    
                <!-- Networks: 1.7 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Math: 1.1 -->
                    
                <!-- 3D: 1.1 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10620" target="_blank" rel="noopener noreferrer">SPreV</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Srivathsan Amruth
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">SPREV, short for hyperSphere Reduced to two-dimensional Regular Polygon for Visualisation, is a novel dimensionality reduction technique developed to address the challenges of reducing dimensions and visualizing labeled datasets that exhibit a unique combination of three characteristics: small class</span>
                
                <span class="abstract-full" style="display: none;">SPREV, short for hyperSphere Reduced to two-dimensional Regular Polygon for Visualisation, is a novel dimensionality reduction technique developed to address the challenges of reducing dimensions and visualizing labeled datasets that exhibit a unique combination of three characteristics: small class size, high dimensionality, and low sample size. SPREV is designed not only to uncover but also to visually represent hidden patterns within such datasets. Its distinctive integration of geometric principles, adapted for discrete computational environments, makes it an indispensable tool in the modern data science toolkit, enabling users to identify trends, extract insights, and navigate complex data efficiently and effectively.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 8.5 -->
                    
                <!-- LLMs: 8.3 -->
                    
                <!-- Quantum Computing: 3.4 -->
                    
                <!-- Networks: 2.2 -->
                    
                <!-- RAG: 1.8 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10622" target="_blank" rel="noopener noreferrer">Improving Upon the generalized c-mu rule: a Whittle approach</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zhouzi Li, Keerthana Gurushankar, Mor Harchol-Balter, Alan Scheller-Wolf
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Scheduling a stream of jobs whose holding cost changes over time is a classic and practical problem. Specifically, each job is associated with a holding cost (penalty), where a job's instantaneous holding cost is some increasing function of its class and current age (the time it has spent in the sys</span>
                
                <span class="abstract-full" style="display: none;">Scheduling a stream of jobs whose holding cost changes over time is a classic and practical problem. Specifically, each job is associated with a holding cost (penalty), where a job's instantaneous holding cost is some increasing function of its class and current age (the time it has spent in the system since its arrival). The goal is to schedule the jobs to minimize the time-average total holding cost across all jobs.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Networks: 5.1 -->
                    
                <!-- LLMs: 4.5 -->
                    
                <!-- Medicine: 4.4 -->
                    
                <!-- Quantum Computing: 3.1 -->
                    
                <!-- Reinforcement Learning: 1.9 -->
                    
                <!-- Robotics: 1.8 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- Math: 1.3 -->
                    
                <!-- Pathfinding: 1.2 -->
                    
                <!-- RAG: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10639" target="_blank" rel="noopener noreferrer">Secure Estimation of Battery Voltage Under Sensor Attacks: A Self-Learning Koopman Approach</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Sanchita Ghosh, Tanushree Roy
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Cloud-based battery management system (BMS) requires accurate terminal voltage measurement data to ensure optimal and safe charging of Lithium-ion batteries. Unfortunately, an adversary can corrupt the battery terminal voltage data as it passes from the local-BMS to the cloud-BMS through the communi</span>
                
                <span class="abstract-full" style="display: none;">Cloud-based battery management system (BMS) requires accurate terminal voltage measurement data to ensure optimal and safe charging of Lithium-ion batteries. Unfortunately, an adversary can corrupt the battery terminal voltage data as it passes from the local-BMS to the cloud-BMS through the communication network, with the objective of under- or over-charging the battery. To ensure accurate terminal voltage data under such malicious sensor attacks, this paper investigates a Koopman-based secure terminal voltage estimation scheme using a two-stage error-compensated self-learning feedback. During the first stage of error correction, the potential Koopman prediction error is estimated to compensate for the error accumulation due to the linear approximation of Koopman operator. The second stage of error compensation aims to recover the error amassing from the higher-order dynamics of the Lithium-ion batteries missed by the self-learning strategy. Specifically, we have proposed two different methods for this second stage error compensation. First, an interpretable empirical correction strategy has been obtained using the open circuit voltage to state-of-charge mapping for the battery. Second, a Gaussian process regression-based data-driven method has been explored. Finally, we demonstrate the efficacy of the proposed secure estimator using both empirical and data-driven corrections.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 6.0 -->
                    
                <!-- Reinforcement Learning: 5.1 -->
                    
                <!-- Quantum Computing: 3.3 -->
                    
                <!-- LLMs: 2.6 -->
                    
                <!-- Math: 2.6 -->
                    
                <!-- Networks: 2.3 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- Pathfinding: 1.4 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10649" target="_blank" rel="noopener noreferrer">Ride-pool Assignment Algorithms: Modern Implementation and Swapping Heuristics</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Matthew Zalesak, Hins Hu, Samitha Samaranayake
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">On-demand ride-pooling has emerged as a popular urban transportation solution, addressing the efficiency limitations of traditional ride-hailing services by grouping multiple riding requests with spatiotemporal proximity into a single vehicle. Although numerous algorithms have been developed for the</span>
                
                <span class="abstract-full" style="display: none;">On-demand ride-pooling has emerged as a popular urban transportation solution, addressing the efficiency limitations of traditional ride-hailing services by grouping multiple riding requests with spatiotemporal proximity into a single vehicle. Although numerous algorithms have been developed for the Ride-pool Assignment Problem (RAP) -- a core component of ride-pooling systems, there is a lack of open-source implementations, making it difficult to benchmark these algorithms on a common dataset and objective. In this paper, we present the implementation details of a ride-pool simulator that encompasses several key ride-pool assignment algorithms, along with associated components such as vehicle routing and rebalancing. We also open-source a highly optimized and modular C++ codebase, designed to facilitate the extension of new algorithms and features. Additionally, we introduce a family of swapping-based local-search heuristics to enhance existing ride-pool assignment algorithms, achieving a better balance between performance and computational efficiency. Extensive experiments on a large-scale, real-world dataset from Manhattan, NYC reveal that while all selected algorithms perform comparably, the newly proposed Multi-Round Linear Assignment with Cyclic Exchange (LA-MR-CE) algorithm achieves a state-of-the-art service rate with significantly reduced computational time. Furthermore, an in-depth analysis suggests that a performance barrier exists for all myopic ride-pool assignment algorithms due to the system's capacity bottleneck, and incorporating future information could be key to overcoming this limitation.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.2 -->
                    
                <!-- LLMs: 4.2 -->
                    
                <!-- Quantum Computing: 2.8 -->
                    
                <!-- Reinforcement Learning: 2.6 -->
                    
                <!-- Networks: 2.4 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10650" target="_blank" rel="noopener noreferrer">Will AI shape the way we speak? The emerging sociolinguistic influence of synthetic voices</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: \'Eva Sz\'ekely (Michaela), J\=ura Miniota (Michaela), M\'i\v{s}a (Michaela), Hejn\'a
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The growing prevalence of conversational voice interfaces, powered by developments in both speech and language technologies, raises important questions about their influence on human communication. While written communication can signal identity through lexical and stylistic choices, voice-based int</span>
                
                <span class="abstract-full" style="display: none;">The growing prevalence of conversational voice interfaces, powered by developments in both speech and language technologies, raises important questions about their influence on human communication. While written communication can signal identity through lexical and stylistic choices, voice-based interactions inherently amplify socioindexical elements - such as accent, intonation, and speech style - which more prominently convey social identity and group affiliation. There is evidence that even passive media such as television is likely to influence the audience's linguistic patterns. Unlike passive media, conversational AI is interactive, creating a more immersive and reciprocal dynamic that holds a greater potential to impact how individuals speak in everyday interactions. Such heightened influence can be expected to arise from phenomena such as acoustic-prosodic entrainment and linguistic accommodation, which occur naturally during interaction and enable users to adapt their speech patterns in response to the system. While this phenomenon is still emerging, its potential societal impact could provide organisations, movements, and brands with a subtle yet powerful avenue for shaping and controlling public perception and social identity. We argue that the socioindexical influence of AI-generated speech warrants attention and should become a focus of interdisciplinary research, leveraging new and existing methodologies and technologies to better understand its implications.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 9.6 -->
                    
                <!-- Medicine: 5.3 -->
                    
                <!-- Quantum Computing: 2.9 -->
                    
                <!-- Networks: 1.9 -->
                    
                <!-- Robotics: 1.9 -->
                    
                <!-- RAG: 1.5 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- GNN: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10657" target="_blank" rel="noopener noreferrer">Balanced TSP partitioning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Benjamin Aram Berendsohn, Hwi Kim, L\'aszl\'o Kozma
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The traveling salesman problem (TSP) famously asks for a shortest tour that a salesperson can take to visit a given set of cities in any order. In this paper, we ask how much faster $k \ge 2$ salespeople can visit the cities if they divide the task among themselves. We show that, in the two-dimensio</span>
                
                <span class="abstract-full" style="display: none;">The traveling salesman problem (TSP) famously asks for a shortest tour that a salesperson can take to visit a given set of cities in any order. In this paper, we ask how much faster $k \ge 2$ salespeople can visit the cities if they divide the task among themselves. We show that, in the two-dimensional Euclidean setting, two salespeople can always achieve a speedup of at least $\frac12 + \frac1\pi \approx 0.818$, for any given input, and there are inputs where they cannot do better. We also give (non-matching) upper and lower bounds for $k \geq 3$.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 7.3 -->
                    
                <!-- Quantum Computing: 4.6 -->
                    
                <!-- Medicine: 4.3 -->
                    
                <!-- Networks: 2.0 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- Math: 1.4 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- RAG: 1.1 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- Pathfinding: 1.1 -->
                    
                <!-- T2I: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10662" target="_blank" rel="noopener noreferrer">Emotion Alignment: Discovering the Gap Between Social Media and Real-World Sentiments in Persian Tweets and Images</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Sina Elahimanesh, Mohammadali Mohammadkhani, Shohreh Kasaei
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In contemporary society, widespread social media usage is evident in people's daily lives. Nevertheless, disparities in emotional expressions between the real world and online platforms can manifest. We comprehensively analyzed Persian community on X to explore this phenomenon. An innovative pipelin</span>
                
                <span class="abstract-full" style="display: none;">In contemporary society, widespread social media usage is evident in people's daily lives. Nevertheless, disparities in emotional expressions between the real world and online platforms can manifest. We comprehensively analyzed Persian community on X to explore this phenomenon. An innovative pipeline was designed to measure the similarity between emotions in the real world compared to social media. Accordingly, recent tweets and images of participants were gathered and analyzed using Transformers-based text and image sentiment analysis modules. Each participant's friends also provided insights into the their real-world emotions. A distance criterion was used to compare real-world feelings with virtual experiences. Our study encompassed N=105 participants, 393 friends who contributed their perspectives, over 8,300 collected tweets, and 2,000 media images. Results indicated a 28.67% similarity between images and real-world emotions, while tweets exhibited a 75.88% alignment with real-world feelings. Additionally, the statistical significance confirmed that the observed disparities in sentiment proportions.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 7.7 -->
                    
                <!-- LLMs: 7.6 -->
                    
                <!-- Quantum Computing: 2.4 -->
                    
                <!-- Robotics: 2.1 -->
                    
                <!-- Networks: 1.8 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- RAG: 1.4 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- T2I: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10663" target="_blank" rel="noopener noreferrer">Characterizing Knowledge Manipulation in a Russian Wikipedia Fork</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Mykola Trokhymovych, Oleksandr Kosovan, Nathan Forrester, Pablo Arag\'on, Diego Saez-Trumper, Ricardo Baeza-Yates
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Wikipedia is powered by MediaWiki, a free and open-source software that is also the infrastructure for many other wiki-based online encyclopedias. These include the recently launched website Ruwiki, which has copied and modified the original Russian Wikipedia content to conform to Russian law. To id</span>
                
                <span class="abstract-full" style="display: none;">Wikipedia is powered by MediaWiki, a free and open-source software that is also the infrastructure for many other wiki-based online encyclopedias. These include the recently launched website Ruwiki, which has copied and modified the original Russian Wikipedia content to conform to Russian law. To identify practices and narratives that could be associated with different forms of knowledge manipulation, this article presents an in-depth analysis of this Russian Wikipedia fork. We propose a methodology to characterize the main changes with respect to the original version. The foundation of this study is a comprehensive comparative analysis of more than 1.9M articles from Russian Wikipedia and its fork. Using meta-information and geographical, temporal, categorical, and textual features, we explore the changes made by Ruwiki editors. Furthermore, we present a classification of the main topics of knowledge manipulation in this fork, including a numerical estimation of their scope. This research not only sheds light on significant changes within Ruwiki, but also provides a methodology that could be applied to analyze other Wikipedia forks and similar collaborative projects.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 6.6 -->
                    
                <!-- Medicine: 4.8 -->
                    
                <!-- Quantum Computing: 2.7 -->
                    
                <!-- Reinforcement Learning: 2.1 -->
                    
                <!-- Networks: 2.0 -->
                    
                <!-- Robotics: 1.7 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Math: 1.2 -->
                    
                <!-- 3D: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10669" target="_blank" rel="noopener noreferrer">Perturbed State Space Feature Encoders for Optical Flow with Event Cameras</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Gokul Raju Govinda Raju, Nikola Zubi\'c, Marco Cannici, Davide Scaramuzza
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">With their motion-responsive nature, event-based cameras offer significant advantages over traditional cameras for optical flow estimation. While deep learning has improved upon traditional methods, current neural networks adopted for event-based optical flow still face temporal and spatial reasonin</span>
                
                <span class="abstract-full" style="display: none;">With their motion-responsive nature, event-based cameras offer significant advantages over traditional cameras for optical flow estimation. While deep learning has improved upon traditional methods, current neural networks adopted for event-based optical flow still face temporal and spatial reasoning limitations. We propose Perturbed State Space Feature Encoders (P-SSE) for multi-frame optical flow with event cameras to address these challenges. P-SSE adaptively processes spatiotemporal features with a large receptive field akin to Transformer-based methods, while maintaining the linear computational complexity characteristic of SSMs. However, the key innovation that enables the state-of-the-art performance of our model lies in our perturbation technique applied to the state dynamics matrix governing the SSM system. This approach significantly improves the stability and performance of our model. We integrate P-SSE into a framework that leverages bi-directional flows and recurrent connections, expanding the temporal context of flow prediction. Evaluations on DSEC-Flow and MVSEC datasets showcase P-SSE's superiority, with 8.48% and 11.86% improvements in EPE performance, respectively.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 9.4 -->
                    
                <!-- LLMs: 5.9 -->
                    
                <!-- Quantum Computing: 3.5 -->
                    
                <!-- Reinforcement Learning: 2.1 -->
                    
                <!-- Networks: 1.7 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Math: 1.3 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- RAG: 1.1 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10671" target="_blank" rel="noopener noreferrer">Token Sliding Reconfiguration on DAGs</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jona Dirks, Alexandre Vigny
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Given a graph $G$ and two independent sets of same size, the Independent Set Reconfiguration Problem under token sliding ask whether one can, in a step by step manner, transform the first independent set into the second one. In each step we must preserve the condition of independence. Further, refer</span>
                
                <span class="abstract-full" style="display: none;">Given a graph $G$ and two independent sets of same size, the Independent Set Reconfiguration Problem under token sliding ask whether one can, in a step by step manner, transform the first independent set into the second one. In each step we must preserve the condition of independence. Further, referring to solution vertices as tokens, we are only permitted to slide a token along an edge. Until the recent work of Ito et al. [Ito et al. MFCS 2022] this problem was only considered on undirected graphs. In this work, we study reconfiguration under token sliding focusing on DAGs.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 7.5 -->
                    
                <!-- Medicine: 3.9 -->
                    
                <!-- Quantum Computing: 3.6 -->
                    
                <!-- Reinforcement Learning: 2.6 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- Math: 1.6 -->
                    
                <!-- Networks: 1.5 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- T2I: 1.0 -->
                    
                <!-- RAG: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10685" target="_blank" rel="noopener noreferrer">NTIRE 2025 Challenge on Cross-Domain Few-Shot Object Detection: Methods and Results</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yuqian Fu, Xingyu Qiu, Bin Ren, Yanwei Fu, Radu Timofte, Nicu Sebe, Ming-Hsuan Yang, Luc Van Gool, Kaijin Zhang, Qingpeng Nong, Xiugang Dong, Hong Gao, Xiangsheng Zhou, Jiancheng Pan, Yanxing Liu, Xiao He, Jiahao Li, Yuze Sun, Xiaomeng Huang, Zhenyu Zhang, Ran Ma, Yuhan Liu, Zijian Zhuang, Shuai Yi, Yixiong Zou, Lingyi Hong, Mingxi Chen, Runze Li, Xingdong Sheng, Wenqiang Zhang, Weisen Chen, Yongxin Yan, Xinguo Chen, Yuanjie Shao, Zhengrong Zuo, Nong Sang, Hao Wu, Haoran Sun, Shuming Hu, Yan Zhang, Zhiguang Shi, Yu Zhang, Chao Chen, Tao Wang, Da Feng, Linhai Zhuo, Ziming Lin, Yali Huang, Jie Me, Yiming Yang, Mi Guo, Mingyuan Jiu, Mingliang Xu, Maomao Xiong, Qunshu Zhang, Xinyu Cao, Yuqing Yang, Dianmo Sheng, Xuanpu Zhao, Zhiyu Li, Xuyang Ding, Wenqian Li
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Cross-Domain Few-Shot Object Detection (CD-FSOD) poses significant challenges to existing object detection and few-shot detection models when applied across domains. In conjunction with NTIRE 2025, we organized the 1st CD-FSOD Challenge, aiming to advance the performance of current object detectors </span>
                
                <span class="abstract-full" style="display: none;">Cross-Domain Few-Shot Object Detection (CD-FSOD) poses significant challenges to existing object detection and few-shot detection models when applied across domains. In conjunction with NTIRE 2025, we organized the 1st CD-FSOD Challenge, aiming to advance the performance of current object detectors on entirely novel target domains with only limited labeled data. The challenge attracted 152 registered participants, received submissions from 42 teams, and concluded with 13 teams making valid final submissions. Participants approached the task from diverse perspectives, proposing novel models that achieved new state-of-the-art (SOTA) results under both open-source and closed-source settings. In this report, we present an overview of the 1st NTIRE 2025 CD-FSOD Challenge, highlighting the proposed solutions and summarizing the results submitted by the participants.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 8.8 -->
                    
                <!-- LLMs: 8.7 -->
                    
                <!-- Quantum Computing: 3.0 -->
                    
                <!-- Reinforcement Learning: 2.1 -->
                    
                <!-- RAG: 2.1 -->
                    
                <!-- 3D: 1.8 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Networks: 1.6 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- T2I: 1.4 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- Math: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10686" target="_blank" rel="noopener noreferrer">The Tenth NTIRE 2025 Efficient Super-Resolution Challenge Report</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Bin Ren, Hang Guo, Lei Sun, Zongwei Wu, Radu Timofte, Yawei Li, Yao Zhang, Xinning Chai, Zhengxue Cheng, Yingsheng Qin, Yucai Yang, Li Song, Hongyuan Yu, Pufan Xu, Cheng Wan, Zhijuan Huang, Peng Guo, Shuyuan Cui, Chenjun Li, Xuehai Hu, Pan Pan, Xin Zhang, Heng Zhang, Qing Luo, Linyan Jiang, Haibo Lei, Qifang Gao, Yaqing Li, Weihua Luo, Tsing Li, Qing Wang, Yi Liu, Yang Wang, Hongyu An, Liou Zhang, Shijie Zhao, Lianhong Song, Long Sun, Jinshan Pan, Jiangxin Dong, Jinhui Tang, Jing Wei, Mengyang Wang, Ruilong Guo, Qian Wang, Qingliang Liu, Yang Cheng, Davinci, Enxuan Gu, Pinxin Liu, Yongsheng Yu, Hang Hua, Yunlong Tang, Shihao Wang, Yukun Yang, Zhiyu Zhang, Yukun Yang, Jiyu Wu, Jiancheng Huang, Yifan Liu, Yi Huang, Shifeng Chen, Rui Chen, Yi Feng, Mingxi Li, Cailu Wan, Xiangji Wu, Zibin Liu, Jinyang Zhong, Kihwan Yoon, Ganzorig Gankhuyag, Shengyun Zhong, Mingyang Wu, Renjie Li, Yushen Zuo, Zhengzhong Tu, Zongang Gao, Guannan Chen, Yuan Tian, Wenhui Chen, Weijun Yuan, Zhan Li, Yihang Chen, Yifan Deng, Ruting Deng, Yilin Zhang, Huan Zheng, Yanyan Wei, Wenxuan Zhao, Suiyi Zhao, Fei Wang, Kun Li, Yinggan Tang, Mengjie Su, Jae-hyeon Lee, Dong-Hyeop Son, Ui-Jin Choi, Tiancheng Shao, Yuqing Zhang, Mengcheng Ma, Donggeun Ko, Youngsang Kwak, Jiun Lee, Jaehwa Kwak, Yuxuan Jiang, Qiang Zhu, Siyue Teng, Fan Zhang, Shuyuan Zhu, Bing Zeng, David Bull, Jing Hu, Hui Deng, Xuan Zhang, Lin Zhu, Qinrui Fan, Weijian Deng, Junnan Wu, Wenqin Deng, Yuquan Liu, Zhaohong Xu, Jameer Babu Pinjari, Kuldeep Purohit, Zeyu Xiao, Zhuoyuan Li, Surya Vashisth, Akshay Dudhane, Praful Hambarde, Sachin Chaudhary, Satya Naryan Tazi, Prashant Patil, Santosh Kumar Vipparthi, Subrahmanyam Murala, Wei-Chen Shen, I-Hsiang Chen, Yunzhe Xu, Chen Zhao, Zhizhou Chen, Akram Khatami-Rizi, Ahmad Mahmoudi-Aznaveh, Alejandro Merino, Bruno Longarela, Javier Abad, Marcos V. Conde, Simone Bianco, Luca Cogo, Gianmarco Corti
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper presents a comprehensive review of the NTIRE 2025 Challenge on Single-Image Efficient Super-Resolution (ESR). The challenge aimed to advance the development of deep models that optimize key computational metrics, i.e., runtime, parameters, and FLOPs, while achieving a PSNR of at least 26.</span>
                
                <span class="abstract-full" style="display: none;">This paper presents a comprehensive review of the NTIRE 2025 Challenge on Single-Image Efficient Super-Resolution (ESR). The challenge aimed to advance the development of deep models that optimize key computational metrics, i.e., runtime, parameters, and FLOPs, while achieving a PSNR of at least 26.90 dB on the $\operatorname{DIV2K\_LSDIR\_valid}$ dataset and 26.99 dB on the $\operatorname{DIV2K\_LSDIR\_test}$ dataset. A robust participation saw \textbf{244} registered entrants, with \textbf{43} teams submitting valid entries. This report meticulously analyzes these methods and results, emphasizing groundbreaking advancements in state-of-the-art single-image ESR techniques. The analysis highlights innovative approaches and establishes benchmarks for future research in the field.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 9.4 -->
                    
                <!-- Medicine: 6.1 -->
                    
                <!-- Quantum Computing: 3.6 -->
                    
                <!-- RAG: 3.5 -->
                    
                <!-- Blockchain: 2.6 -->
                    
                <!-- Networks: 2.3 -->
                    
                <!-- 3D: 2.1 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- T2I: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- Math: 1.2 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                <!-- Datasets: 1.0 -->
                    
                <!-- Attention: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10691" target="_blank" rel="noopener noreferrer">Spectrum Sharing in STAR-RIS-assisted UAV with NOMA for Cognitive Radio Networks</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ali Nazari, Ali Olfat
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">As an emerging technology, the simultaneous transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) can improve the spectrum efficiency (SE) of primary users (PUs) and secondary users (SUs) in cognitive radio (CR) networks by mitigating the interference of the incident signals. The</span>
                
                <span class="abstract-full" style="display: none;">As an emerging technology, the simultaneous transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) can improve the spectrum efficiency (SE) of primary users (PUs) and secondary users (SUs) in cognitive radio (CR) networks by mitigating the interference of the incident signals. The STAR-RIS-assisted unmanned aerial vehicle (UAV) can fully cover the dynamic environment through high mobility and fast deployment. According to the dynamic air-to-ground channels, the STAR-RIS-assisted UAV may face a challenge configuring their elements' coefficients (i.e., reflecting and transmitting the amplitude and phases). Hence, to meet the requirements of dynamic channel determination with the SE approach, this paper proposes the sum rate maximization of both PUs and SUs through non-orthogonal multiple access in CR network to jointly optimize the trajectory and transmission-reflection beamforming design of the STAR-RIS-assisted UAV, and power allocation. Since the non-convex joint optimization problem includes coupled optimization variables, we develop an alternative optimization algorithm. Simulation results study the impact of: 1) the significant parameters, 2) the performance of different intelligence surface modes and STAR-RIS operating protocols, 3) the joint trajectory and beamforming design with fixed and mobile users, and 4) STAR-RIS capabilities such as mitigating the interference, and how variations in the roles of elements dynamically.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 9.7 -->
                    
                <!-- LLMs: 4.3 -->
                    
                <!-- Reinforcement Learning: 2.7 -->
                    
                <!-- Math: 1.9 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Networks: 1.6 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- Pathfinding: 1.4 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10693" target="_blank" rel="noopener noreferrer">Load Balancing with Network Latencies via Distributed Gradient Descent</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Santiago R. Balseiro, Vahab S. Mirrokni, Bartek Wydrowski
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Motivated by the growing demand for serving large language model inference requests, we study distributed load balancing for global serving systems with network latencies. We consider a fluid model in which continuous flows of requests arrive at different frontends and need to be routed to distant b</span>
                
                <span class="abstract-full" style="display: none;">Motivated by the growing demand for serving large language model inference requests, we study distributed load balancing for global serving systems with network latencies. We consider a fluid model in which continuous flows of requests arrive at different frontends and need to be routed to distant backends for processing whose processing rates are workload dependent. Network latencies can lead to long travel times for requests and delayed feedback from backends. The objective is to minimize the average latency of requests, composed of the network latency and the serving latency at the backends.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 9.0 -->
                    
                <!-- LLMs: 5.7 -->
                    
                <!-- Quantum Computing: 2.9 -->
                    
                <!-- Networks: 2.2 -->
                    
                <!-- Reinforcement Learning: 1.8 -->
                    
                <!-- Robotics: 1.8 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                <!-- Math: 1.3 -->
                    
                <!-- RAG: 1.1 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10700" target="_blank" rel="noopener noreferrer">Optimizing Data Distribution and Kernel Performance for Efficient Training of Chemistry Foundation Models: A Case Study with MACE</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jesun Firoz, Franco Pellegrini, Mario Geiger, Darren Hsu, Jenna A. Bilbrey, Han-Yi Chou, Maximilian Stadler, Markus Hoehnerbach, Tingyu Wang, Dejun Lin, Emine Kucukbenli, Henry W. Sprueill, Ilyes Batatia, Sotiris S. Xantheas, MalSoon Lee, Chris Mundy, Gabor Csanyi, Justin S. Smith, Ponnuswamy Sadayappan, Sutanay Choudhury
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Chemistry Foundation Models (CFMs) that leverage Graph Neural Networks (GNNs) operating on 3D molecular graph structures are becoming indispensable tools for computational chemists and materials scientists. These models facilitate the understanding of matter and the discovery of new molecules and ma</span>
                
                <span class="abstract-full" style="display: none;">Chemistry Foundation Models (CFMs) that leverage Graph Neural Networks (GNNs) operating on 3D molecular graph structures are becoming indispensable tools for computational chemists and materials scientists. These models facilitate the understanding of matter and the discovery of new molecules and materials. In contrast to GNNs operating on a large homogeneous graphs, GNNs used by CFMs process a large number of geometric graphs of varying sizes, requiring different optimization strategies than those developed for large homogeneous GNNs. This paper presents optimizations for two critical phases of CFM training: data distribution and model training, targeting MACE - a state-of-the-art CFM. We address the challenge of load balancing in data distribution by formulating it as a multi-objective bin packing problem. We propose an iterative algorithm that provides a highly effective, fast, and practical solution, ensuring efficient data distribution. For the training phase, we identify symmetric tensor contraction as the key computational kernel in MACE and optimize this kernel to improve the overall performance. Our combined approach of balanced data distribution and kernel optimization significantly enhances the training process of MACE. Experimental results demonstrate a substantial speedup, reducing per-epoch execution time for training from 12 to 2 minutes on 740 GPUs with a 2.6M sample dataset.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 8.7 -->
                    
                <!-- LLMs: 6.9 -->
                    
                <!-- Quantum Computing: 3.0 -->
                    
                <!-- Reinforcement Learning: 2.0 -->
                    
                <!-- Networks: 1.7 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                <!-- Math: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10702" target="_blank" rel="noopener noreferrer">Container-level Energy Observability in Kubernetes Clusters</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Bjorn Pijnacker, Brian Setz, Vasilios Andrikopoulos
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Kubernetes has been for a number of years the default cloud orchestrator solution across multiple application and research domains. As such, optimizing the energy efficiency of Kubernetes-deployed workloads is of primary interest towards controlling operational expenses by reducing energy consumptio</span>
                
                <span class="abstract-full" style="display: none;">Kubernetes has been for a number of years the default cloud orchestrator solution across multiple application and research domains. As such, optimizing the energy efficiency of Kubernetes-deployed workloads is of primary interest towards controlling operational expenses by reducing energy consumption at data center level and allocated resources at application level. A lot of research in this direction aims on reducing the total energy usage of Kubernetes clusters without establishing an understanding of their workloads, i.e. the applications deployed on the cluster. This means that there are untapped potential improvements in energy efficiency that can be achieved through, for example, application refactoring or deployment optimization. For all these cases a prerequisite is establishing fine-grained observability down to the level of individual containers and their power draw over time. A state-of-the-art tool approved by the Cloud-Native Computing Foundation, Kepler, aims to provide this functionality, but has not been assessed for its accuracy and therefore fitness for purpose. In this work we start by developing an experimental procedure to this goal, and we conclude that the reported energy usage metrics provided by Kepler are not at a satisfactory level. As a reaction to this, we develop KubeWatt as an alternative to Kepler for specific use case scenarios, and demonstrate its higher accuracy through the same experimental procedure as we used for Kepler.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 7.7 -->
                    
                <!-- Medicine: 4.9 -->
                    
                <!-- Quantum Computing: 3.2 -->
                    
                <!-- Reinforcement Learning: 1.8 -->
                    
                <!-- Math: 1.5 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- Networks: 1.2 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- Federated Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10703" target="_blank" rel="noopener noreferrer">The Trie Measure, Revisited</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jarno N. Alanko, Ruben Becker, Davide Cenzato, Travis Gagie, Sung-Hwan Kim, Bojana Kodric, Nicola Prezza
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In this paper, we study the following problem: given $n$ subsets $S_1, \dots, S_n$ of an integer universe $U = \{0,\dots, u-1\}$, having total cardinality $N = \sum_{i=1}^n |S_i|$, find a prefix-free encoding $enc : U \rightarrow \{0,1\}^+$ minimizing the so-called trie measure, i.e., the total numb</span>
                
                <span class="abstract-full" style="display: none;">In this paper, we study the following problem: given $n$ subsets $S_1, \dots, S_n$ of an integer universe $U = \{0,\dots, u-1\}$, having total cardinality $N = \sum_{i=1}^n |S_i|$, find a prefix-free encoding $enc : U \rightarrow \{0,1\}^+$ minimizing the so-called trie measure, i.e., the total number of edges in the $n$ binary tries $\mathcal T_1, \dots, \mathcal T_n$, where $\mathcal T_i$ is the trie packing the encoded integers $\{enc(x):x\in S_i\}$. We first observe that this problem is equivalent to that of merging $u$ sets with the cheapest sequence of binary unions, a problem which in [Ghosh et al., ICDCS 2015] is shown to be NP-hard. Motivated by the hardness of the general problem, we focus on particular families of prefix-free encodings. We start by studying the fixed-length shifted encoding of [Gupta et al., Theoretical Computer Science 2007]. Given a parameter $0\le a < u$, this encoding sends each $x \in U$ to $(x + a) \mod u$, interpreted as a bit-string of $\log u$ bits. We develop the first efficient algorithms that find the value of $a$ minimizing the trie measure when this encoding is used. Our two algorithms run in $O(u + N\log u)$ and $O(N\log^2 u)$ time, respectively. We proceed by studying ordered encodings (a.k.a. monotone or alphabetic), and describe an algorithm finding the optimal such encoding in $O(N+u^3)$ time. Within the same running time, we show how to compute the best shifted ordered encoding, provably no worse than both the optimal shifted and optimal ordered encodings. We provide implementations of our algorithms and discuss how these encodings perform in practice.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 5.5 -->
                    
                <!-- Reinforcement Learning: 3.8 -->
                    
                <!-- Quantum Computing: 3.7 -->
                    
                <!-- Math: 3.3 -->
                    
                <!-- Medicine: 1.9 -->
                    
                <!-- Pathfinding: 1.7 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- Networks: 1.6 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- GNN: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10704" target="_blank" rel="noopener noreferrer">PDSP-Bench: A Benchmarking System for Parallel and Distributed Stream Processing</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Pratyush Agnihotri, Boris Koldehofe, Roman Heinrich, Carsten Binnig, Manisha Luthra
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The paper introduces PDSP-Bench, a novel benchmarking system designed for a systematic understanding of performance of parallel stream processing in a distributed environment. Such an understanding is essential for determining how Stream Processing Systems (SPS) use operator parallelism and the avai</span>
                
                <span class="abstract-full" style="display: none;">The paper introduces PDSP-Bench, a novel benchmarking system designed for a systematic understanding of performance of parallel stream processing in a distributed environment. Such an understanding is essential for determining how Stream Processing Systems (SPS) use operator parallelism and the available resources to process massive workloads of modern applications. Existing benchmarking systems focus on analyzing SPS using queries with sequential operator pipelines within a homogeneous centralized environment. Quite differently, PDSP-Bench emphasizes the aspects of parallel stream processing in a distributed heterogeneous environment and simultaneously allows the integration of machine learning models for SPS workloads. In our results, we benchmark a well-known SPS, Apache Flink, using parallel query structures derived from real-world applications and synthetic queries to show the capabilities of PDSP-Bench towards parallel stream processing. Moreover, we compare different learned cost models using generated SPS workloads on PDSP-Bench by showcasing their evaluations on model and training efficiency. We present key observations from our experiments using PDSP-Bench that highlight interesting trends given different query workloads, such as non-linearity and paradoxical effects of parallelism on the performance.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 9.8 -->
                    
                <!-- LLMs: 6.7 -->
                    
                <!-- Quantum Computing: 2.7 -->
                    
                <!-- Reinforcement Learning: 2.2 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- Networks: 1.5 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- GNN: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10706" target="_blank" rel="noopener noreferrer">GestureCoach: Rehearsing for Engaging Talks with LLM-Driven Gesture Recommendations</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ashwin Ram, Varsha Suresh, Artin Saberpour Abadian, Vera Demberg, J\"urgen Steimle
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper introduces GestureCoach, a system designed to help speakers deliver more engaging talks by guiding them to gesture effectively during rehearsal. GestureCoach combines an LLM-driven gesture recommendation model with a rehearsal interface that proactively cues speakers to gesture appropriat</span>
                
                <span class="abstract-full" style="display: none;">This paper introduces GestureCoach, a system designed to help speakers deliver more engaging talks by guiding them to gesture effectively during rehearsal. GestureCoach combines an LLM-driven gesture recommendation model with a rehearsal interface that proactively cues speakers to gesture appropriately. Trained on experts' gesturing patterns from TED talks, the model consists of two modules: an emphasis proposal module, which predicts when to gesture by identifying gesture-worthy text segments in the presenter notes, and a gesture identification module, which determines what gesture to use by retrieving semantically appropriate gestures from a curated gesture database. Results of a model performance evaluation and user study (N=30) show that the emphasis proposal module outperforms off-the-shelf LLMs in identifying suitable gesture regions, and that participants rated the majority of these predicted regions and their corresponding gestures as highly appropriate. A subsequent user study (N=10) showed that rehearsing with GestureCoach encouraged speakers to gesture and significantly increased gesture diversity, resulting in more engaging talks. We conclude with design implications for future AI-driven rehearsal systems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 8.7 -->
                    
                <!-- Medicine: 5.7 -->
                    
                <!-- Quantum Computing: 3.5 -->
                    
                <!-- Networks: 2.5 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- RAG: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10708" target="_blank" rel="noopener noreferrer">Legally-Informed Explainable AI</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Gennie Mansi, Naveena Karusala, Mark Riedl
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Explanations for artificial intelligence (AI) systems are intended to support the people who are impacted by AI systems in high-stakes decision-making environments, such as doctors, patients, teachers, students, housing applicants, and many others. To protect people and support the responsible devel</span>
                
                <span class="abstract-full" style="display: none;">Explanations for artificial intelligence (AI) systems are intended to support the people who are impacted by AI systems in high-stakes decision-making environments, such as doctors, patients, teachers, students, housing applicants, and many others. To protect people and support the responsible development of AI, explanations need to be actionable--helping people take pragmatic action in response to an AI system--and contestable--enabling people to push back against an AI system and its determinations. For many high-stakes domains, such as healthcare, education, and finance, the sociotechnical environment includes significant legal implications that impact how people use AI explanations. For example, physicians who use AI decision support systems may need information on how accepting or rejecting an AI determination will protect them from lawsuits or help them advocate for their patients. In this paper, we make the case for Legally-Informed Explainable AI, responding to the need to integrate and design for legal considerations when creating AI explanations. We describe three stakeholder groups with different informational and actionability needs, and provide practical recommendations to tackle design challenges around the design of explainable AI systems that incorporate legal considerations.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 7.5 -->
                    
                <!-- Medicine: 6.4 -->
                    
                <!-- Quantum Computing: 3.4 -->
                    
                <!-- Robotics: 1.8 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- RAG: 1.5 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Networks: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10709" target="_blank" rel="noopener noreferrer">Vehicle Dynamics Control for Simultaneous Optimization of Tire Emissions and Performance in EVs</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Chi-Bach Pham, Homayoun Hamedmoghadam Rafati, Robert Noel Shorten
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In recent years, Electric Vehicles (EVs) have seen widespread public adoption. While EVs produce zero tailpipe emissions, they contribute to an increase in another type of vehicular emission: tire emissions. Battery-operated EVs are generally heavier than their combustion-engine counterparts and req</span>
                
                <span class="abstract-full" style="display: none;">In recent years, Electric Vehicles (EVs) have seen widespread public adoption. While EVs produce zero tailpipe emissions, they contribute to an increase in another type of vehicular emission: tire emissions. Battery-operated EVs are generally heavier than their combustion-engine counterparts and require greater acceleration forces, which their high-torque electric motors provide. This combination of increased weight and traction forces leads to higher tire emissions, which possess various adverse health and environmental effects. Here, we propose a control solution with promising results in mitigating tire wear in all-wheel-drive EVs. The idea is to utilize different tire profiles on each drive axis: a low-wear, low-traction axis and a high-wear, high-traction axis. Derived from detailed mathematical analyses, we propose a simple control scheme to counteract the performance difference from using the low-traction tires. The proposed control mechanism then distributes torque optimally between the two axes, maximizing usage from the low-wear axis and simultaneously maintaining stability and performance by leveraging high-traction tires. Through detailed numerical simulations, we demonstrate that the developed model significantly reduces tire emissions and maintains vehicle drivability and performance.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 8.5 -->
                    
                <!-- LLMs: 6.9 -->
                    
                <!-- Quantum Computing: 2.2 -->
                    
                <!-- Reinforcement Learning: 2.1 -->
                    
                <!-- Networks: 1.9 -->
                    
                <!-- Robotics: 1.7 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- RAG: 1.3 -->
                    
                <!-- T2I: 1.3 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10710" target="_blank" rel="noopener noreferrer">On an efficient line smoother for the p-multigrid {\gamma}-cycle</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jos\'e Pablo Lucero Lorca, Duane Rosenberg, Isidora Jankov, Conor McCoid, Martin Jakob Gander
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">As part of the development of a Poisson solver for the spectral element discretization used in the GeoFluid Object Workbench (GeoFLOW) code, we propose a solver for the linear system arising from a Gauss-Legendre-Lobatto global spectral method. We precondition using a p-multigrid {\gamma}-cycle with</span>
                
                <span class="abstract-full" style="display: none;">As part of the development of a Poisson solver for the spectral element discretization used in the GeoFluid Object Workbench (GeoFLOW) code, we propose a solver for the linear system arising from a Gauss-Legendre-Lobatto global spectral method. We precondition using a p-multigrid {\gamma}-cycle with highly-vectorizable smoothers, that we refer to as line smoothers. Our smoothers are restrictions of spectral and finite element discretizations to low-order one-dimensional problems along lines, that are solved by a reformulation of cyclic reduction as a direct multigrid method. We illustrate our method with numerical experiments showing the apparent boundedness of the iteration count for a fixed residual reduction over a range of moderately deformed domains, right hand sides and Dirichlet boundary conditions.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 5.0 -->
                    
                <!-- LLMs: 3.7 -->
                    
                <!-- Quantum Computing: 3.3 -->
                    
                <!-- Reinforcement Learning: 3.1 -->
                    
                <!-- Networks: 2.8 -->
                    
                <!-- Math: 1.9 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- Pathfinding: 1.1 -->
                    
                <!-- 3D: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10717" target="_blank" rel="noopener noreferrer">FuzzSense: Towards A Modular Fuzzing Framework for Autonomous Driving Software</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Andrew Roberts, Lorenz Teply, Mert D. Pese, Olaf Maennel, Mohammad Hamad, Sebastian Steinhorst
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Fuzz testing to find semantic control vulnerabilities is an essential activity to evaluate the robustness of autonomous driving (AD) software. Whilst there is a preponderance of disparate fuzzing tools that target different parts of the test environment, such as the scenario, sensors, and vehicle dy</span>
                
                <span class="abstract-full" style="display: none;">Fuzz testing to find semantic control vulnerabilities is an essential activity to evaluate the robustness of autonomous driving (AD) software. Whilst there is a preponderance of disparate fuzzing tools that target different parts of the test environment, such as the scenario, sensors, and vehicle dynamics, there is a lack of fuzzing strategies that ensemble these fuzzers to enable concurrent fuzzing, utilizing diverse techniques and targets. This research proposes FuzzSense, a modular, black-box, mutation-based fuzzing framework that is architected to ensemble diverse AD fuzzing tools. To validate the utility of FuzzSense, a LiDAR sensor fuzzer was developed as a plug-in, and the fuzzer was implemented in the new AD simulation platform AWSIM and Autoware.Universe AD software platform. The results demonstrated that FuzzSense was able to find vulnerabilities in the new Autoware.Universe software. We contribute to FuzzSense open-source with the aim of initiating a conversation in the community on the design of AD-specific fuzzers and the establishment of a community fuzzing framework to better target the diverse technology base of autonomous vehicles.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 5.2 -->
                    
                <!-- Medicine: 3.2 -->
                    
                <!-- Reinforcement Learning: 3.1 -->
                    
                <!-- Quantum Computing: 2.6 -->
                    
                <!-- Networks: 2.6 -->
                    
                <!-- Robotics: 2.2 -->
                    
                <!-- Math: 1.8 -->
                    
                <!-- Pathfinding: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10720" target="_blank" rel="noopener noreferrer">Leveraging Deep Operator Networks (DeepONet) for Acoustic Full Waveform Inversion (FWI)</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Kamaljyoti Nath, Khemraj Shukla, Victor C. Tsai, Umair bin Waheed, Christian Huber, Omer Alpak, Chuen-Song Chen, Ligang Lu, Amik St-Cyr
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Full Waveform Inversion (FWI) is an important geophysical technique considered in subsurface property prediction. It solves the inverse problem of predicting high-resolution Earth interior models from seismic data. Traditional FWI methods are computationally demanding. Inverse problems in geophysics</span>
                
                <span class="abstract-full" style="display: none;">Full Waveform Inversion (FWI) is an important geophysical technique considered in subsurface property prediction. It solves the inverse problem of predicting high-resolution Earth interior models from seismic data. Traditional FWI methods are computationally demanding. Inverse problems in geophysics often face challenges of non-uniqueness due to limited data, as data are often collected only on the surface. In this study, we introduce a novel methodology that leverages Deep Operator Networks (DeepONet) to attempt to improve both the efficiency and accuracy of FWI. The proposed DeepONet methodology inverts seismic waveforms for the subsurface velocity field. This approach is able to capture some key features of the subsurface velocity field. We have shown that the architecture can be applied to noisy seismic data with an accuracy that is better than some other machine learning methods. We also test our proposed method with out-of-distribution prediction for different velocity models. The proposed DeepONet shows comparable and better accuracy in some velocity models than some other machine learning methods. To improve the FWI workflow, we propose using the DeepONet output as a starting model for conventional FWI and that it may improve FWI performance. While we have only shown that DeepONet facilitates faster convergence than starting with a homogeneous velocity field, it may have some benefits compared to other approaches to constructing starting models. This integration of DeepONet into FWI may accelerate the inversion process and may also enhance its robustness and reliability.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 7.6 -->
                    
                <!-- LLMs: 5.4 -->
                    
                <!-- Quantum Computing: 3.6 -->
                    
                <!-- Reinforcement Learning: 2.3 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- Networks: 1.9 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- Math: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10726" target="_blank" rel="noopener noreferrer">Beyond the Classroom: Bridging the Gap Between Academia and Industry with a Hands-on Learning Approach</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Mingyang Xu, Ryan Zheng He Liu, Mark Stoodley, Ladan Tahvildari
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Modern software systems require various capabilities to meet architectural and operational demands, such as the ability to scale automatically and recover from sudden failures. Self-adaptive software systems have emerged as a critical focus in software design and operation due to their capacity to a</span>
                
                <span class="abstract-full" style="display: none;">Modern software systems require various capabilities to meet architectural and operational demands, such as the ability to scale automatically and recover from sudden failures. Self-adaptive software systems have emerged as a critical focus in software design and operation due to their capacity to autonomously adapt to changing environments. However, educating students on this topic is scarce in academia, and a survey among practitioners identified that the lack of knowledgeable individuals has hindered its adoption in the industry. In this paper, we present our experience teaching a course on self-adaptive software systems that integrates theoretical knowledge and hands-on learning with industry-relevant technologies. To close the gap between academic education and industry practices, we incorporated guest lectures from experts and showcases featuring industry professionals as judges, improving technical and communication skills for our students. Feedback based on surveys from 21 students indicates significant improvements in their understanding of self-adaptive systems. The empirical analysis of the developed course demonstrates the effectiveness of the proposed course syllabus and teaching methodology. In addition, we provide a summary of the educational challenges of running this unique course, including balancing theory and practice, addressing the diverse backgrounds and motivations of students, and integrating the industry-relevant technologies. We believe these insights can provide valuable guidance for educating students in other emerging topics within software engineering.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 6.0 -->
                    
                <!-- LLMs: 5.8 -->
                    
                <!-- Reinforcement Learning: 2.6 -->
                    
                <!-- Robotics: 2.2 -->
                    
                <!-- Quantum Computing: 2.2 -->
                    
                <!-- Networks: 1.1 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10728" target="_blank" rel="noopener noreferrer">Iterative Recommendations based on Monte Carlo Sampling and Trust Estimation in Multi-Stage Vehicular Traffic Routing Games</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Doris E. M. Brown, Venkata Sriram Siddhardh Nadendla, Sajal K. Das
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The shortest-time route recommendations offered by modern navigation systems fuel selfish routing in urban vehicular traffic networks and are therefore one of the main reasons for the growth of congestion. In contrast, intelligent transportation systems (ITS) prefer to steer driver-vehicle systems (</span>
                
                <span class="abstract-full" style="display: none;">The shortest-time route recommendations offered by modern navigation systems fuel selfish routing in urban vehicular traffic networks and are therefore one of the main reasons for the growth of congestion. In contrast, intelligent transportation systems (ITS) prefer to steer driver-vehicle systems (DVS) toward system-optimal route recommendations, which are primarily designed to mitigate network congestion. However, due to the misalignment in motives, drivers exhibit a lack of trust in the ITS. This paper models the interaction between a DVS and an ITS as a novel, multi-stage routing game where the DVS exhibits dynamics in its trust towards the recommendations of ITS based on counterfactual and observed game outcomes. Specifically, DVS and ITS are respectively modeled as a travel-time minimizer and network congestion minimizer, each having nonidentical prior beliefs about the network state. A novel approximate algorithm to compute the Bayesian Nash equilibrium, called ROSTER(Recommendation Outcome Sampling with Trust Estimation and Re-evaluation), is proposed based on Monte Carlo sampling with trust belief updating to determine the best response route recommendations of the ITS at each stage of the game. Simulation results demonstrate that the trust prediction error in the proposed algorithm converges to zero with a growing number of multi-stage DVS-ITS interactions and is effectively able to both mitigate congestion and reduce driver travel times when compared to alternative route recommendation strategies.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 3.9 -->
                    
                <!-- LLMs: 3.7 -->
                    
                <!-- Reinforcement Learning: 3.3 -->
                    
                <!-- Networks: 2.5 -->
                    
                <!-- Robotics: 2.1 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Math: 1.7 -->
                    
                <!-- Pathfinding: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10730" target="_blank" rel="noopener noreferrer">PQ-CAN: A Framework for Simulating Post-Quantum Cryptography in Embedded Systems</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Mauro Conti, Francesco Marchiori, Sebastiano Matarazzo, Marco Rubin
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The rapid development of quantum computers threatens traditional cryptographic schemes, prompting the need for Post-Quantum Cryptography (PQC). Although the NIST standardization process has accelerated the development of such algorithms, their application in resource-constrained environments such as</span>
                
                <span class="abstract-full" style="display: none;">The rapid development of quantum computers threatens traditional cryptographic schemes, prompting the need for Post-Quantum Cryptography (PQC). Although the NIST standardization process has accelerated the development of such algorithms, their application in resource-constrained environments such as embedded systems remains a challenge. Automotive systems relying on the Controller Area Network (CAN) bus for communication are particularly vulnerable due to their limited computational capabilities, high traffic, and need for real-time response. These constraints raise concerns about the feasibility of implementing PQC in automotive environments, where legacy hardware and bit rate limitations must also be considered.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 7.8 -->
                    
                <!-- LLMs: 6.0 -->
                    
                <!-- Quantum Computing: 5.5 -->
                    
                <!-- Blockchain: 2.1 -->
                    
                <!-- Networks: 1.8 -->
                    
                <!-- Math: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- RAG: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- Pathfinding: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10743" target="_blank" rel="noopener noreferrer">Robust Gittins for Stochastic Scheduling</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Benjamin Moseley, Heather Newman, Kirk Pruhs, Rudy Zhou
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">A common theme in stochastic optimization problems is that, theoretically, stochastic algorithms need to "know" relatively rich information about the underlying distributions. This is at odds with most applications, where distributions are rough predictions based on historical data. Thus, commonly, </span>
                
                <span class="abstract-full" style="display: none;">A common theme in stochastic optimization problems is that, theoretically, stochastic algorithms need to "know" relatively rich information about the underlying distributions. This is at odds with most applications, where distributions are rough predictions based on historical data. Thus, commonly, stochastic algorithms are making decisions using imperfect predicted distributions, while trying to optimize over some unknown true distributions. We consider the fundamental problem of scheduling stochastic jobs preemptively on a single machine to minimize expected mean completion time in the setting where the scheduler is only given imperfect predicted job size distributions. If the predicted distributions are perfect, then it is known that this problem can be solved optimally by the Gittins index policy. The goal of our work is to design a scheduling policy that is robust in the sense that it produces nearly optimal schedules even if there are modest discrepancies between the predicted distributions and the underlying real distributions. Our main contributions are:</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Quantum Computing: 3.8 -->
                    
                <!-- LLMs: 3.6 -->
                    
                <!-- Math: 2.9 -->
                    
                <!-- Reinforcement Learning: 2.8 -->
                    
                <!-- Networks: 2.7 -->
                    
                <!-- GNN: 2.7 -->
                    
                <!-- Medicine: 2.6 -->
                    
                <!-- Robotics: 2.0 -->
                    
                <!-- Pathfinding: 1.3 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- Multi-armed Bandit: 1.2 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10746" target="_blank" rel="noopener noreferrer">Hearing Anywhere in Any Environment</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Xiulong Liu, Anurag Kumar, Paul Calamia, Sebastia V. Amengual, Calvin Murdock, Ishwarya Ananthabhotla, Philip Robinson, Eli Shlizerman, Vamsi Krishna Ithapu, Ruohan Gao
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In mixed reality applications, a realistic acoustic experience in spatial environments is as crucial as the visual experience for achieving true immersion. Despite recent advances in neural approaches for Room Impulse Response (RIR) estimation, most existing methods are limited to the single environ</span>
                
                <span class="abstract-full" style="display: none;">In mixed reality applications, a realistic acoustic experience in spatial environments is as crucial as the visual experience for achieving true immersion. Despite recent advances in neural approaches for Room Impulse Response (RIR) estimation, most existing methods are limited to the single environment on which they are trained, lacking the ability to generalize to new rooms with different geometries and surface materials. We aim to develop a unified model capable of reconstructing the spatial acoustic experience of any environment with minimum additional measurements. To this end, we present xRIR, a framework for cross-room RIR prediction. The core of our generalizable approach lies in combining a geometric feature extractor, which captures spatial context from panorama depth images, with a RIR encoder that extracts detailed acoustic features from only a few reference RIR samples. To evaluate our method, we introduce ACOUSTICROOMS, a new dataset featuring high-fidelity simulation of over 300,000 RIRs from 260 rooms. Experiments show that our method strongly outperforms a series of baselines. Furthermore, we successfully perform sim-to-real transfer by evaluating our model on four real-world environments, demonstrating the generalizability of our approach and the realism of our dataset.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 5.7 -->
                    
                <!-- Medicine: 5.0 -->
                    
                <!-- Quantum Computing: 3.4 -->
                    
                <!-- Reinforcement Learning: 2.9 -->
                    
                <!-- Networks: 2.1 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- Math: 1.1 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                <!-- T2I: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10751" target="_blank" rel="noopener noreferrer">Communication-aware Hierarchical Map Compression of Time-Varying Environments for Mobile Robots</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Daniel T. Larsson, Dipankar Maity
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In this paper, we develop a systematic framework for the time-sequential compression of dynamic probabilistic occupancy grids. Our approach leverages ideas from signal compression theory to formulate an optimization problem that searches for a multi-resolution hierarchical encoder that balances the </span>
                
                <span class="abstract-full" style="display: none;">In this paper, we develop a systematic framework for the time-sequential compression of dynamic probabilistic occupancy grids. Our approach leverages ideas from signal compression theory to formulate an optimization problem that searches for a multi-resolution hierarchical encoder that balances the quality of the compressed map (distortion) with its description size, the latter of which relates to the bandwidth required to reliably transmit the map to other agents or to store map estimates in on-board memory. The resulting optimization problem allows for multi-resolution map compressions to be obtained that satisfy available communication or memory resources, and does not require knowledge of the occupancy map dynamics. We develop an algorithm to solve our problem, and demonstrate the utility of the proposed framework in simulation on both static (i.e., non-time varying) and dynamic (time-varying) occupancy maps.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 8.4 -->
                    
                <!-- Reinforcement Learning: 4.2 -->
                    
                <!-- Medicine: 3.4 -->
                    
                <!-- Quantum Computing: 3.4 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- Networks: 1.6 -->
                    
                <!-- Math: 1.5 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10753" target="_blank" rel="noopener noreferrer">Epistemic Uncertainty-aware Recommendation Systems via Bayesian Deep Ensemble Learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Radin Cheraghi, Amir Mohammad Mahfoozi, Sepehr Zolfaghari, Mohammadshayan Shabani, Maryam Ramezani, Hamid R. Rabiee
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Recommending items to users has long been a fundamental task, and studies have tried to improve it ever since. Most well-known models commonly employ representation learning to map users and items into a unified embedding space for matching assessment. These approaches have primary limitations, espe</span>
                
                <span class="abstract-full" style="display: none;">Recommending items to users has long been a fundamental task, and studies have tried to improve it ever since. Most well-known models commonly employ representation learning to map users and items into a unified embedding space for matching assessment. These approaches have primary limitations, especially when dealing with explicit feedback and sparse data contexts. Two primary limitations are their proneness to overfitting and failure to incorporate epistemic uncertainty in predictions. To address these problems, we propose a novel Bayesian Deep Ensemble Collaborative Filtering method named BDECF. To improve model generalization and quality, we utilize Bayesian Neural Networks, which incorporate uncertainty within their weight parameters. In addition, we introduce a new interpretable non-linear matching approach for the user and item embeddings, leveraging the advantages of the attention mechanism. Furthermore, we endorse the implementation of an ensemble-based supermodel to generate more robust and reliable predictions, resulting in a more complete model. Empirical evaluation through extensive experiments and ablation studies across a range of publicly accessible real-world datasets with differing sparsity characteristics confirms our proposed method's effectiveness and the importance of its components.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 8.8 -->
                    
                <!-- Medicine: 6.8 -->
                    
                <!-- Networks: 2.2 -->
                    
                <!-- Quantum Computing: 2.0 -->
                    
                <!-- Reinforcement Learning: 2.0 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- RAG: 1.3 -->
                    
                <!-- T2I: 1.2 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- Federated Learning: 1.0 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10754" target="_blank" rel="noopener noreferrer">auto-fpt: Automating Free Probability Theory Calculations for Machine Learning Theory</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Arjun Subramonian, Elvis Dohmatob
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">A large part of modern machine learning theory often involves computing the high-dimensional expected trace of a rational expression of large rectangular random matrices. To symbolically compute such quantities using free probability theory, we introduce auto-fpt, a lightweight Python and SymPy-base</span>
                
                <span class="abstract-full" style="display: none;">A large part of modern machine learning theory often involves computing the high-dimensional expected trace of a rational expression of large rectangular random matrices. To symbolically compute such quantities using free probability theory, we introduce auto-fpt, a lightweight Python and SymPy-based tool that can automatically produce a reduced system of fixed-point equations which can be solved for the quantities of interest, and effectively constitutes a theory. We overview the algorithmic ideas underlying auto-fpt and its applications to various interesting problems, such as the high-dimensional error of linearized feed-forward neural networks, recovering well-known results. We hope that auto-fpt streamlines the majority of calculations involved in high-dimensional analysis, while helping the machine learning community reproduce known and uncover new phenomena.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 6.6 -->
                    
                <!-- Medicine: 5.6 -->
                    
                <!-- Quantum Computing: 5.0 -->
                    
                <!-- Reinforcement Learning: 2.7 -->
                    
                <!-- Math: 2.1 -->
                    
                <!-- Networks: 1.8 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10762" target="_blank" rel="noopener noreferrer">Auto-Test: Learning Semantic-Domain Constraints for Unsupervised Error Detection in Tables</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Qixu Chen, Yeye He, Raymond Chi-Wing Wong, Weiwei Cui, Song Ge, Haidong Zhang, Dongmei Zhang, Surajit Chaudhuri
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Data cleaning is a long-standing challenge in data management. While powerful logic and statistical algorithms have been developed to detect and repair data errors in tables, existing algorithms predominantly rely on domain-experts to first manually specify data-quality constraints specific to a giv</span>
                
                <span class="abstract-full" style="display: none;">Data cleaning is a long-standing challenge in data management. While powerful logic and statistical algorithms have been developed to detect and repair data errors in tables, existing algorithms predominantly rely on domain-experts to first manually specify data-quality constraints specific to a given table, before data cleaning algorithms can be applied.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 8.5 -->
                    
                <!-- Medicine: 6.1 -->
                    
                <!-- Quantum Computing: 4.3 -->
                    
                <!-- RAG: 3.0 -->
                    
                <!-- Networks: 2.5 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- Robotics: 1.9 -->
                    
                <!-- 3D: 1.9 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- T2I: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Attention: 1.1 -->
                    
                <!-- Federated Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10764" target="_blank" rel="noopener noreferrer">SeeTree -- A modular, open-source system for tree detection and orchard localization</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jostan Brown, Cindy Grimm, Joseph R. Davidson
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Accurate localization is an important functional requirement for precision orchard management. However, there are few off-the-shelf commercial solutions available to growers. In this paper, we present SeeTree, a modular, open source embedded system for tree trunk detection and orchard localization t</span>
                
                <span class="abstract-full" style="display: none;">Accurate localization is an important functional requirement for precision orchard management. However, there are few off-the-shelf commercial solutions available to growers. In this paper, we present SeeTree, a modular, open source embedded system for tree trunk detection and orchard localization that is deployable on any vehicle. Building on our prior work on vision-based in-row localization using particle filters, SeeTree includes several new capabilities. First, it provides capacity for full orchard localization including out-of-row headland turning. Second, it includes the flexibility to integrate either visual, GNSS, or wheel odometry in the motion model. During field experiments in a commercial orchard, the system converged to the correct location 99% of the time over 800 trials, even when starting with large uncertainty in the initial particle locations. When turning out of row, the system correctly tracked 99% of the turns (860 trials representing 43 unique row changes). To help support adoption and future research and development, we make our dataset, design files, and source code freely available to the community.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 9.9 -->
                    
                <!-- LLMs: 4.6 -->
                    
                <!-- Quantum Computing: 2.7 -->
                    
                <!-- Reinforcement Learning: 2.2 -->
                    
                <!-- Networks: 1.9 -->
                    
                <!-- Robotics: 1.7 -->
                    
                <!-- Math: 1.4 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Pathfinding: 1.2 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                <!-- Evolutionary Algorithms: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10765" target="_blank" rel="noopener noreferrer">Minimal Sensing for Orienting a Solar Panel</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jeremy Klotz, Shree K. Nayar
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">A solar panel harvests the most energy when pointing in the direction that maximizes the total illumination (irradiance) falling on it. Given an arbitrary orientation of a panel and an arbitrary environmental illumination, we address the problem of finding the direction of maximum total irradiance. </span>
                
                <span class="abstract-full" style="display: none;">A solar panel harvests the most energy when pointing in the direction that maximizes the total illumination (irradiance) falling on it. Given an arbitrary orientation of a panel and an arbitrary environmental illumination, we address the problem of finding the direction of maximum total irradiance. We develop a minimal sensing approach where measurements from just four photodetectors are used to iteratively vary the tilt of the panel to maximize the irradiance. Many environments produce irradiance functions with multiple local maxima. As a result, simply measuring the gradient of the irradiance function and applying gradient ascent will not work. We show that a larger, optimized tilt between the detectors and the panel is equivalent to blurring the irradiance function. This has the effect of eliminating local maxima and turning the irradiance function into a unimodal one, whose maximum can be found using gradient ascent. We show that there is a close relationship between our approach and scale space theory. We have collected a large dataset of high-dynamic range lighting environments in New York City, called \textit{UrbanSky}. We used this dataset to conduct simulations to verify the robustness of our approach. Finally, we have built a portable solar panel with four compact detectors and an actuator to conduct experiments in various real-world settings: direct sunlight, cloudy sky, urban settings with occlusions and shadows, and complex indoor lighting. In all cases, we show significant improvements in harvested energy compared to standard approaches for controlling the orientation of a solar panel.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.1 -->
                    
                <!-- Reinforcement Learning: 3.7 -->
                    
                <!-- Medicine: 3.5 -->
                    
                <!-- Math: 2.0 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Networks: 1.9 -->
                    
                <!-- Robotics: 1.8 -->
                    
                <!-- Pathfinding: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10770" target="_blank" rel="noopener noreferrer">Collaborative Bayesian Optimization via Wasserstein Barycenters</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Donglin Zhan, Haoting Zhang, Rhonda Righter, Zeyu Zheng, James Anderson
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Motivated by the growing need for black-box optimization and data privacy, we introduce a collaborative Bayesian optimization (BO) framework that addresses both of these challenges. In this framework agents work collaboratively to optimize a function they only have oracle access to. In order to miti</span>
                
                <span class="abstract-full" style="display: none;">Motivated by the growing need for black-box optimization and data privacy, we introduce a collaborative Bayesian optimization (BO) framework that addresses both of these challenges. In this framework agents work collaboratively to optimize a function they only have oracle access to. In order to mitigate against communication and privacy constraints, agents are not allowed to share their data but can share their Gaussian process (GP) surrogate models. To enable collaboration under these constraints, we construct a central model to approximate the objective function by leveraging the concept of Wasserstein barycenters of GPs. This central model integrates the shared models without accessing the underlying data. A key aspect of our approach is a collaborative acquisition function that balances exploration and exploitation, allowing for the optimization of decision variables collaboratively in each iteration. We prove that our proposed algorithm is asymptotically consistent and that its implementation via Monte Carlo methods is numerically accurate. Through numerical experiments, we demonstrate that our approach outperforms other baseline collaborative frameworks and is competitive with centralized approaches that do not consider data privacy.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 10.0 -->
                    
                <!-- Medicine: 4.4 -->
                    
                <!-- Quantum Computing: 3.9 -->
                    
                <!-- Reinforcement Learning: 2.1 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- Networks: 1.8 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- Math: 1.4 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10777" target="_blank" rel="noopener noreferrer">AtlasD: Automatic Local Symmetry Discovery</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Manu Bhat, Jonghyun Park, Jianke Yang, Nima Dehmamy, Robin Walters, Rose Yu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Existing symmetry discovery methods predominantly focus on global transformations across the entire system or space, but they fail to consider the symmetries in local neighborhoods. This may result in the reported symmetry group being a misrepresentation of the true symmetry. In this paper, we forma</span>
                
                <span class="abstract-full" style="display: none;">Existing symmetry discovery methods predominantly focus on global transformations across the entire system or space, but they fail to consider the symmetries in local neighborhoods. This may result in the reported symmetry group being a misrepresentation of the true symmetry. In this paper, we formalize the notion of local symmetry as atlas equivariance. Our proposed pipeline, automatic local symmetry discovery (AtlasD), recovers the local symmetries of a function by training local predictor networks and then learning a Lie group basis to which the predictors are equivariant. We demonstrate AtlasD is capable of discovering local symmetry groups with multiple connected components in top-quark tagging and partial differential equation experiments. The discovered local symmetry is shown to be a useful inductive bias that improves the performance of downstream tasks in climate segmentation and vision tasks.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 6.5 -->
                    
                <!-- Medicine: 3.8 -->
                    
                <!-- Quantum Computing: 2.7 -->
                    
                <!-- Reinforcement Learning: 2.7 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Networks: 1.9 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- Math: 1.5 -->
                    
                <!-- Pathfinding: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10782" target="_blank" rel="noopener noreferrer">Deep Audio Watermarks are Shallow: Limitations of Post-Hoc Watermarking Techniques for Speech</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Patrick O'Reilly, Zeyu Jin, Jiaqi Su, Bryan Pardo
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In the audio modality, state-of-the-art watermarking methods leverage deep neural networks to allow the embedding of human-imperceptible signatures in generated audio. The ideal is to embed signatures that can be detected with high accuracy when the watermarked audio is altered via compression, filt</span>
                
                <span class="abstract-full" style="display: none;">In the audio modality, state-of-the-art watermarking methods leverage deep neural networks to allow the embedding of human-imperceptible signatures in generated audio. The ideal is to embed signatures that can be detected with high accuracy when the watermarked audio is altered via compression, filtering, or other transformations. Existing audio watermarking techniques operate in a post-hoc manner, manipulating "low-level" features of audio recordings after generation (e.g. through the addition of a low-magnitude watermark signal). We show that this post-hoc formulation makes existing audio watermarks vulnerable to transformation-based removal attacks. Focusing on speech audio, we (1) unify and extend existing evaluations of the effect of audio transformations on watermark detectability, and (2) demonstrate that state-of-the-art post-hoc audio watermarks can be removed with no knowledge of the watermarking scheme and minimal degradation in audio quality.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 9.6 -->
                    
                <!-- Medicine: 5.1 -->
                    
                <!-- Quantum Computing: 3.8 -->
                    
                <!-- Reinforcement Learning: 2.5 -->
                    
                <!-- Math: 2.3 -->
                    
                <!-- Networks: 1.6 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10783" target="_blank" rel="noopener noreferrer">Superfast Configuration-Space Convex Set Computation on GPUs for Online Motion Planning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Peter Werner, Richard Cheng, Tom Stewart, Russ Tedrake, Daniela Rus
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In this work, we leverage GPUs to construct probabilistically collision-free convex sets in robot configuration space on the fly. This extends the use of modern motion planning algorithms that leverage such representations to changing environments. These planners rapidly and reliably optimize high-q</span>
                
                <span class="abstract-full" style="display: none;">In this work, we leverage GPUs to construct probabilistically collision-free convex sets in robot configuration space on the fly. This extends the use of modern motion planning algorithms that leverage such representations to changing environments. These planners rapidly and reliably optimize high-quality trajectories, without the burden of challenging nonconvex collision-avoidance constraints. We present an algorithm that inflates collision-free piecewise linear paths into sequences of convex sets (SCS) that are probabilistically collision-free using massive parallelism. We then integrate this algorithm into a motion planning pipeline, which leverages dynamic roadmaps to rapidly find one or multiple collision-free paths, and inflates them. We then optimize the trajectory through the probabilistically collision-free sets, simultaneously using the candidate trajectory to detect and remove collisions from the sets. We demonstrate the efficacy of our approach on a simulation benchmark and a KUKA iiwa 7 robot manipulator with perception in the loop. On our benchmark, our approach runs 17.1 times faster and yields a 27.9% increase in reliability over the nonlinear trajectory optimization baseline, while still producing high-quality motion plans.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 5.5 -->
                    
                <!-- Medicine: 4.4 -->
                    
                <!-- Quantum Computing: 3.3 -->
                    
                <!-- Reinforcement Learning: 3.3 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- Networks: 1.5 -->
                    
                <!-- Math: 1.5 -->
                    
                <!-- Pathfinding: 1.2 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- 3D: 1.1 -->
                    
                <!-- Federated Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10784" target="_blank" rel="noopener noreferrer">ATLASv2: LLM-Guided Adaptive Landmark Acquisition and Navigation on the Edge</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Mikolaj Walczak, Uttej Kallakuri, Tinoosh Mohsenin
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Autonomous systems deployed on edge devices face significant challenges, including resource constraints, real-time processing demands, and adapting to dynamic environments. This work introduces ATLASv2, a novel system that integrates a fine-tuned TinyLLM, real-time object detection, and efficient pa</span>
                
                <span class="abstract-full" style="display: none;">Autonomous systems deployed on edge devices face significant challenges, including resource constraints, real-time processing demands, and adapting to dynamic environments. This work introduces ATLASv2, a novel system that integrates a fine-tuned TinyLLM, real-time object detection, and efficient path planning to enable hierarchical, multi-task navigation and manipulation all on the edge device, Jetson Nano. ATLASv2 dynamically expands its navigable landmarks by detecting and localizing objects in the environment which are saved to its internal knowledge base to be used for future task execution. We evaluate ATLASv2 in real-world environments, including a handcrafted home and office setting constructed with diverse objects and landmarks. Results show that ATLASv2 effectively interprets natural language instructions, decomposes them into low-level actions, and executes tasks with high success rates. By leveraging generative AI in a fully on-board framework, ATLASv2 achieves optimized resource utilization with minimal prompting latency and power consumption, bridging the gap between simulated environments and real-world applications.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 7.8 -->
                    
                <!-- LLMs: 6.1 -->
                    
                <!-- 3D: 2.6 -->
                    
                <!-- Quantum Computing: 2.5 -->
                    
                <!-- Robotics: 2.1 -->
                    
                <!-- Networks: 1.7 -->
                    
                <!-- RAG: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- T2I: 1.2 -->
                    
                <!-- Attention: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10792" target="_blank" rel="noopener noreferrer">GUM-SAGE: A Novel Dataset and Approach for Graded Entity Salience Prediction</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jessica Lin, Amir Zeldes
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Determining and ranking the most salient entities in a text is critical for user-facing systems, especially as users increasingly rely on models to interpret long documents they only partially read. Graded entity salience addresses this need by assigning entities scores that reflect their relative i</span>
                
                <span class="abstract-full" style="display: none;">Determining and ranking the most salient entities in a text is critical for user-facing systems, especially as users increasingly rely on models to interpret long documents they only partially read. Graded entity salience addresses this need by assigning entities scores that reflect their relative importance in a text. Existing approaches fall into two main categories: subjective judgments of salience, which allow for gradient scoring but lack consistency, and summarization-based methods, which define salience as mention-worthiness in a summary, promoting explainability but limiting outputs to binary labels (entities are either summary-worthy or not). In this paper, we introduce a novel approach for graded entity salience that combines the strengths of both approaches. Using an English dataset spanning 12 spoken and written genres, we collect 5 summaries per document and calculate each entity's salience score based on its presence across these summaries. Our approach shows stronger correlation with scores based on human summaries and alignments, and outperforms existing techniques, including LLMs. We release our data and code at https://github.com/jl908069/gum_sum_salience to support further research on graded salient entity extraction.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 8.3 -->
                    
                <!-- Medicine: 7.1 -->
                    
                <!-- Quantum Computing: 3.3 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- RAG: 1.5 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- T2I: 1.3 -->
                    
                <!-- Networks: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10793" target="_blank" rel="noopener noreferrer">SonicSieve: Bringing Directional Speech Extraction to Smartphones Using Acoustic Microstructures</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Kuang Yuan, Yifeng Wang, Xiyuxing Zhang, Chengyi Shen, Swarun Kumar, Justin Chan
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Imagine placing your smartphone on a table in a noisy restaurant and clearly capturing the voices of friends seated around you, or recording a lecturer's voice with clarity in a reverberant auditorium. We introduce SonicSieve, the first intelligent directional speech extraction system for smartphone</span>
                
                <span class="abstract-full" style="display: none;">Imagine placing your smartphone on a table in a noisy restaurant and clearly capturing the voices of friends seated around you, or recording a lecturer's voice with clarity in a reverberant auditorium. We introduce SonicSieve, the first intelligent directional speech extraction system for smartphones using a bio-inspired acoustic microstructure. Our passive design embeds directional cues onto incoming speech without any additional electronics. It attaches to the in-line mic of low-cost wired earphones which can be attached to smartphones. We present an end-to-end neural network that processes the raw audio mixtures in real-time on mobile devices. Our results show that SonicSieve achieves a signal quality improvement of 5.0 dB when focusing on a 30{\deg} angular region. Additionally, the performance of our system based on only two microphones exceeds that of conventional 5-microphone arrays.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 5.2 -->
                    
                <!-- Quantum Computing: 4.6 -->
                    
                <!-- Medicine: 3.3 -->
                    
                <!-- Reinforcement Learning: 2.8 -->
                    
                <!-- Networks: 2.3 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- Math: 1.7 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10798" target="_blank" rel="noopener noreferrer">AdapCsiNet: Environment-Adaptive CSI Feedback via Scene Graph-Aided Deep Learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jiayi Liu, Jiajia Guo, Yiming Cui, Chao-Kai Wen, Shi Jin
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Accurate channel state information (CSI) is critical for realizing the full potential of multiple-antenna wireless communication systems. While deep learning (DL)-based CSI feedback methods have shown promise in reducing feedback overhead, their generalization capability across varying propagation e</span>
                
                <span class="abstract-full" style="display: none;">Accurate channel state information (CSI) is critical for realizing the full potential of multiple-antenna wireless communication systems. While deep learning (DL)-based CSI feedback methods have shown promise in reducing feedback overhead, their generalization capability across varying propagation environments remains limited due to their data-driven nature. Existing solutions based on online training improve adaptability but impose significant overhead in terms of data collection and computational resources. In this work, we propose AdapCsiNet, an environment-adaptive DL-based CSI feedback framework that eliminates the need for online training. By integrating environmental information -- represented as a scene graph -- into a hypernetwork-guided CSI reconstruction process, AdapCsiNet dynamically adapts to diverse channel conditions. A two-step training strategy is introduced to ensure baseline reconstruction performance and effective environment-aware adaptation. Simulation results demonstrate that AdapCsiNet achieves up to 46.4% improvement in CSI reconstruction accuracy and matches the performance of online learning methods without incurring additional runtime overhead.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 8.8 -->
                    
                <!-- Medicine: 6.1 -->
                    
                <!-- Quantum Computing: 3.8 -->
                    
                <!-- Networks: 2.5 -->
                    
                <!-- GNN: 2.3 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- RAG: 1.7 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- T2I: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10800" target="_blank" rel="noopener noreferrer">Products of Recursive Programs for Hypersafety Verification</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ruotong Cheng, Azadeh Farzan
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We study the problem of automated hypersafety verification of infinite-state recursive programs. We propose an infinite class of product programs, specifically designed with recursion in mind, that reduce the hypersafety verification of a recursive program to standard safety verification. For this, </span>
                
                <span class="abstract-full" style="display: none;">We study the problem of automated hypersafety verification of infinite-state recursive programs. We propose an infinite class of product programs, specifically designed with recursion in mind, that reduce the hypersafety verification of a recursive program to standard safety verification. For this, we combine insights from language theory and concurrency theory to propose an algorithmic solution for constructing an infinite class of recursive product programs. One key insight is that, using the simple theory of visibly pushdown languages, one can maintain the recursive structure of syntactic program alignments which is vital to constructing a new product program that can be viewed as a classic recursive program -- that is, one that can be executed on a single stack. Another key insight is that techniques from concurrency theory can be generalized to help define product programs based on the view that the parallel composition of individual recursive programs includes all possible alignments from which a sound set of alignments that faithfully preserve the satisfaction of the hypersafety property can be selected. On the practical side, we formulate a family of parametric canonical product constructions that are intuitive to programmers and can be used as building blocks to specify recursive product programs for the purpose of relational and hypersafety verification, with the idea that the right product program can be verified automatically using existing techniques. We demonstrate the effectiveness of these techniques through an implementation and highly promising experimental results.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 6.2 -->
                    
                <!-- Quantum Computing: 5.9 -->
                    
                <!-- Math: 5.6 -->
                    
                <!-- Reinforcement Learning: 3.8 -->
                    
                <!-- Medicine: 2.3 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- Networks: 1.4 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10807" target="_blank" rel="noopener noreferrer">Power-scaled Bayesian Inference with Score-based Generative mModels</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Huseyin Tuna Erdinc, Yunlin Zeng, Abhinav Prakash Gahlot, Felix J. Herrmann
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We propose a score-based generative algorithm for sampling from power-scaled priors and likelihoods within the Bayesian inference framework. Our algorithm enables flexible control over prior-likelihood influence without requiring retraining for different power-scaling configurations. Specifically, w</span>
                
                <span class="abstract-full" style="display: none;">We propose a score-based generative algorithm for sampling from power-scaled priors and likelihoods within the Bayesian inference framework. Our algorithm enables flexible control over prior-likelihood influence without requiring retraining for different power-scaling configurations. Specifically, we focus on synthesizing seismic velocity models conditioned on imaged seismic. Our method enables sensitivity analysis by sampling from intermediate power posteriors, allowing us to assess the relative influence of the prior and likelihood on samples of the posterior distribution. Through a comprehensive set of experiments, we evaluate the effects of varying the power parameter in different settings: applying it solely to the prior, to the likelihood of a Bayesian formulation, and to both simultaneously. The results show that increasing the power of the likelihood up to a certain threshold improves the fidelity of posterior samples to the conditioning data (e.g., seismic images), while decreasing the prior power promotes greater structural diversity among samples. Moreover, we find that moderate scaling of the likelihood leads to a reduced shot data residual, confirming its utility in posterior refinement.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Reinforcement Learning: 5.4 -->
                    
                <!-- LLMs: 4.6 -->
                    
                <!-- Medicine: 3.1 -->
                    
                <!-- Quantum Computing: 2.7 -->
                    
                <!-- Networks: 2.3 -->
                    
                <!-- Math: 1.9 -->
                    
                <!-- Federated Learning: 1.6 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- Pathfinding: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10808" target="_blank" rel="noopener noreferrer">Tabular foundation model to detect empathy from visual cues</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Md Rakibul Hasan, Shafin Rahman, Md Zakir Hossain, Aneesh Krishna, Tom Gedeon
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Detecting empathy from video interactions is an emerging area of research. Video datasets, however, are often released as extracted features (i.e., tabular data) rather than raw footage due to privacy and ethical concerns. Prior research on such tabular datasets established tree-based classical mach</span>
                
                <span class="abstract-full" style="display: none;">Detecting empathy from video interactions is an emerging area of research. Video datasets, however, are often released as extracted features (i.e., tabular data) rather than raw footage due to privacy and ethical concerns. Prior research on such tabular datasets established tree-based classical machine learning approaches as the best-performing models. Motivated by the recent success of textual foundation models (i.e., large language models), we explore the use of tabular foundation models in empathy detection from tabular visual features. We experiment with two recent tabular foundation models $-$ TabPFN v2 and TabICL $-$ through in-context learning and fine-tuning setups. Our experiments on a public human-robot interaction benchmark demonstrate a significant boost in cross-subject empathy detection accuracy over several strong baselines (accuracy: $0.590 \rightarrow 0.730$; AUC: $0.564 \rightarrow 0.669$). In addition to performance improvement, we contribute novel insights and an evaluation setup to ensure generalisation on unseen subjects in this public benchmark. As the practice of releasing video features as tabular datasets is likely to persist due to privacy constraints, our findings will be widely applicable to future empathy detection video datasets as well.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 8.4 -->
                    
                <!-- Medicine: 7.1 -->
                    
                <!-- Quantum Computing: 3.1 -->
                    
                <!-- Reinforcement Learning: 1.9 -->
                    
                <!-- Robotics: 1.7 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Networks: 1.7 -->
                    
                <!-- RAG: 1.5 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Federated Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10809" target="_blank" rel="noopener noreferrer">GaSLight: Gaussian Splats for Spatially-Varying Lighting in HDR</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Christophe Bolduc, Yannick Hold-Geoffroy, Zhixin Shu, Jean-Fran\c{c}ois Lalonde
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We present GaSLight, a method that generates spatially-varying lighting from regular images. Our method proposes using HDR Gaussian Splats as light source representation, marking the first time regular images can serve as light sources in a 3D renderer. Our two-stage process first enhances the dynam</span>
                
                <span class="abstract-full" style="display: none;">We present GaSLight, a method that generates spatially-varying lighting from regular images. Our method proposes using HDR Gaussian Splats as light source representation, marking the first time regular images can serve as light sources in a 3D renderer. Our two-stage process first enhances the dynamic range of images plausibly and accurately by leveraging the priors embedded in diffusion models. Next, we employ Gaussian Splats to model 3D lighting, achieving spatially variant lighting. Our approach yields state-of-the-art results on HDR estimations and their applications in illuminating virtual objects and scenes. To facilitate the benchmarking of images as light sources, we introduce a novel dataset of calibrated and unsaturated HDR to evaluate images as light sources. We assess our method using a combination of this novel dataset and an existing dataset from the literature. The code to reproduce our method will be available upon acceptance.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 8.3 -->
                    
                <!-- Medicine: 5.6 -->
                    
                <!-- Quantum Computing: 3.0 -->
                    
                <!-- 3D: 2.3 -->
                    
                <!-- Reinforcement Learning: 2.0 -->
                    
                <!-- Robotics: 1.8 -->
                    
                <!-- Networks: 1.3 -->
                    
                <!-- T2I: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Attention: 1.1 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10817" target="_blank" rel="noopener noreferrer">FHBench: Towards Efficient and Personalized Federated Learning for Multimodal Healthcare</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Penghao Wang, Qian Chen, Teng Zhang, Yingwei Zhang, Wang Lu, Yiqiang Chen
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Federated Learning (FL) has emerged as an effective solution for multi-institutional collaborations without sharing patient data, offering a range of methods tailored for diverse applications. However, real-world medical datasets are often multimodal, and computational resources are limited, posing </span>
                
                <span class="abstract-full" style="display: none;">Federated Learning (FL) has emerged as an effective solution for multi-institutional collaborations without sharing patient data, offering a range of methods tailored for diverse applications. However, real-world medical datasets are often multimodal, and computational resources are limited, posing significant challenges for existing FL approaches. Recognizing these limitations, we developed the Federated Healthcare Benchmark(FHBench), a benchmark specifically designed from datasets derived from real-world healthcare applications. FHBench encompasses critical diagnostic tasks across domains such as the nervous, cardiovascular, and respiratory systems and general pathology, providing comprehensive support for multimodal healthcare evaluations and filling a significant gap in existing benchmarks. Building on FHBench, we introduced Efficient Personalized Federated Learning with Adaptive LoRA(EPFL), a personalized FL framework that demonstrates superior efficiency and effectiveness across various healthcare modalities. Our results highlight the robustness of FHBench as a benchmarking tool and the potential of EPFL as an innovative approach to advancing healthcare-focused FL, addressing key limitations of existing methods.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 8.4 -->
                    
                <!-- LLMs: 4.8 -->
                    
                <!-- Quantum Computing: 3.2 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- 3D: 1.8 -->
                    
                <!-- Networks: 1.7 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                <!-- RAG: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- T2I: 1.2 -->
                    
                <!-- GNN: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10819" target="_blank" rel="noopener noreferrer">Generalized Audio Deepfake Detection Using Frame-level Latent Information Entropy</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Botao Zhao, Zuheng Kang, Yayun He, Xiaoyang Qu, Junqing Peng, Jing Xiao, Jianzong Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Generalizability, the capacity of a robust model to perform effectively on unseen data, is crucial for audio deepfake detection due to the rapid evolution of text-to-speech (TTS) and voice conversion (VC) technologies. A promising approach to differentiate between bonafide and spoof samples lies in </span>
                
                <span class="abstract-full" style="display: none;">Generalizability, the capacity of a robust model to perform effectively on unseen data, is crucial for audio deepfake detection due to the rapid evolution of text-to-speech (TTS) and voice conversion (VC) technologies. A promising approach to differentiate between bonafide and spoof samples lies in identifying intrinsic disparities to enhance model generalizability. From an information-theoretic perspective, we hypothesize the information content is one of the intrinsic differences: bonafide sample represents a dense, information-rich sampling of the real world, whereas spoof sample is typically derived from lower-dimensional, less informative representations. To implement this, we introduce frame-level latent information entropy detector(f-InfoED), a framework that extracts distinctive information entropy from latent representations at the frame level to identify audio deepfakes. Furthermore, we present AdaLAM, which extends large pre-trained audio models with trainable adapters for enhanced feature extraction. To facilitate comprehensive evaluation, the audio deepfake forensics 2024 (ADFF 2024) dataset was built by the latest TTS and VC methods. Extensive experiments demonstrate that our proposed approach achieves state-of-the-art performance and exhibits remarkable generalization capabilities. Further analytical studies confirms the efficacy of AdaLAM in extracting discriminative audio features and f-InfoED in leveraging latent entropy information for more generalized deepfake detection.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 7.3 -->
                    
                <!-- LLMs: 5.8 -->
                    
                <!-- Quantum Computing: 2.6 -->
                    
                <!-- Reinforcement Learning: 2.5 -->
                    
                <!-- Networks: 2.1 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Math: 1.4 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- 3D: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10822" target="_blank" rel="noopener noreferrer">IlluSign: Illustrating Sign Language Videos by Leveraging the Attention Mechanism</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Janna Bruner, Amit Moryossef, Lior Wolf
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Sign languages are dynamic visual languages that involve hand gestures, in combination with non manual elements such as facial expressions. While video recordings of sign language are commonly used for education and documentation, the dynamic nature of signs can make it challenging to study them in </span>
                
                <span class="abstract-full" style="display: none;">Sign languages are dynamic visual languages that involve hand gestures, in combination with non manual elements such as facial expressions. While video recordings of sign language are commonly used for education and documentation, the dynamic nature of signs can make it challenging to study them in detail, especially for new learners and educators. This work aims to convert sign language video footage into static illustrations, which serve as an additional educational resource to complement video content. This process is usually done by an artist, and is therefore quite costly. We propose a method that illustrates sign language videos by leveraging generative models' ability to understand both the semantic and geometric aspects of images. Our approach focuses on transferring a sketch like illustration style to video footage of sign language, combining the start and end frames of a sign into a single illustration, and using arrows to highlight the hand's direction and motion. While many style transfer methods address domain adaptation at varying levels of abstraction, applying a sketch like style to sign languages, especially for hand gestures and facial expressions, poses a significant challenge. To tackle this, we intervene in the denoising process of a diffusion model, injecting style as keys and values into high resolution attention layers, and fusing geometric information from the image and edges as queries. For the final illustration, we use the attention mechanism to combine the attention weights from both the start and end illustrations, resulting in a soft combination. Our method offers a cost effective solution for generating sign language illustrations at inference time, addressing the lack of such resources in educational materials.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 6.3 -->
                    
                <!-- Medicine: 4.4 -->
                    
                <!-- Quantum Computing: 2.2 -->
                    
                <!-- Robotics: 2.2 -->
                    
                <!-- Reinforcement Learning: 1.9 -->
                    
                <!-- Networks: 1.9 -->
                    
                <!-- 3D: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10825" target="_blank" rel="noopener noreferrer">OmniVDiff: Omni Controllable Video Diffusion for Generation and Understanding</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Dianbing Xi, Jiepeng Wang, Yuanzhi Liang, Xi Qiu, Yuchi Huo, Rui Wang, Chi Zhang, Xuelong Li
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In this paper, we propose a novel framework for controllable video diffusion, OmniVDiff, aiming to synthesize and comprehend multiple video visual content in a single diffusion model. To achieve this, OmniVDiff treats all video visual modalities in the color space to learn a joint distribution, whil</span>
                
                <span class="abstract-full" style="display: none;">In this paper, we propose a novel framework for controllable video diffusion, OmniVDiff, aiming to synthesize and comprehend multiple video visual content in a single diffusion model. To achieve this, OmniVDiff treats all video visual modalities in the color space to learn a joint distribution, while employing an adaptive control strategy that dynamically adjusts the role of each visual modality during the diffusion process, either as a generation modality or a conditioning modality. This allows flexible manipulation of each modality's role, enabling support for a wide range of tasks. Consequently, our model supports three key functionalities: (1) Text-conditioned video generation: multi-modal visual video sequences (i.e., rgb, depth, canny, segmentaion) are generated based on the text conditions in one diffusion process; (2) Video understanding: OmniVDiff can estimate the depth, canny map, and semantic segmentation across the input rgb frames while ensuring coherence with the rgb input; and (3) X-conditioned video generation: OmniVDiff generates videos conditioned on fine-grained attributes (e.g., depth maps or segmentation maps). By integrating these diverse tasks into a unified video diffusion framework, OmniVDiff enhances the flexibility and scalability for controllable video diffusion, making it an effective tool for a variety of downstream applications, such as video-to-video translation. Extensive experiments demonstrate the effectiveness of our approach, highlighting its potential for various video-related applications.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 6.3 -->
                    
                <!-- LLMs: 4.7 -->
                    
                <!-- Quantum Computing: 2.5 -->
                    
                <!-- Reinforcement Learning: 2.5 -->
                    
                <!-- Networks: 1.9 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- T2I: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Math: 1.1 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- GNN: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10826" target="_blank" rel="noopener noreferrer">SteerMusic: Enhanced Musical Consistency for Zero-shot Text-Guided and Personalized Music Editing</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Xinlei Niu, Kin Wai Cheuk, Jing Zhang, Naoki Murata, Chieh-Hsin Lai, Michele Mancusi, Woosung Choi, Giorgio Fabbro, Wei-Hsiang Liao, Charles Patrick Martin, Yuki Mitsufuji
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Music editing is an important step in music production, which has broad applications, including game development and film production. Most existing zero-shot text-guided methods rely on pretrained diffusion models by involving forward-backward diffusion processes for editing. However, these methods </span>
                
                <span class="abstract-full" style="display: none;">Music editing is an important step in music production, which has broad applications, including game development and film production. Most existing zero-shot text-guided methods rely on pretrained diffusion models by involving forward-backward diffusion processes for editing. However, these methods often struggle to maintain the music content consistency. Additionally, text instructions alone usually fail to accurately describe the desired music. In this paper, we propose two music editing methods that enhance the consistency between the original and edited music by leveraging score distillation. The first method, SteerMusic, is a coarse-grained zero-shot editing approach using delta denoising score. The second method, SteerMusic+, enables fine-grained personalized music editing by manipulating a concept token that represents a user-defined musical style. SteerMusic+ allows for the editing of music into any user-defined musical styles that cannot be achieved by the text instructions alone. Experimental results show that our methods outperform existing approaches in preserving both music content consistency and editing fidelity. User studies further validate that our methods achieve superior music editing quality. Audio examples are available on https://steermusic.pages.dev/.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 8.0 -->
                    
                <!-- Medicine: 5.2 -->
                    
                <!-- Quantum Computing: 4.0 -->
                    
                <!-- GNN: 2.3 -->
                    
                <!-- 3D: 1.9 -->
                    
                <!-- Networks: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- RAG: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Math: 1.1 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- T2I: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10828" target="_blank" rel="noopener noreferrer">Following Is All You Need: Robot Crowd Navigation Using People As Planners</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yuwen Liao, Xinhang Xu, Ruofei Bai, Yizhuo Yang, Muqing Cao, Shenghai Yuan, Lihua Xie
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Navigating in crowded environments requires the robot to be equipped with high-level reasoning and planning techniques. Existing works focus on developing complex and heavyweight planners while ignoring the role of human intelligence. Since humans are highly capable agents who are also widely availa</span>
                
                <span class="abstract-full" style="display: none;">Navigating in crowded environments requires the robot to be equipped with high-level reasoning and planning techniques. Existing works focus on developing complex and heavyweight planners while ignoring the role of human intelligence. Since humans are highly capable agents who are also widely available in a crowd navigation setting, we propose an alternative scheme where the robot utilises people as planners to benefit from their effective planning decisions and social behaviours. Through a set of rule-based evaluations, we identify suitable human leaders who exhibit the potential to guide the robot towards its goal. Using a simple base planner, the robot follows the selected leader through shorthorizon subgoals that are designed to be straightforward to achieve. We demonstrate through both simulated and real-world experiments that our novel framework generates safe and efficient robot plans compared to existing planners, even without predictive or data-driven modules. Our method also brings human-like robot behaviours without explicitly defining traffic rules and social norms. Code will be available at https://github.com/centiLinda/PeopleAsPlanner.git.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 8.2 -->
                    
                <!-- Medicine: 4.3 -->
                    
                <!-- Quantum Computing: 2.7 -->
                    
                <!-- Reinforcement Learning: 2.7 -->
                    
                <!-- Robotics: 2.5 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- Networks: 1.8 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- RAG: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Math: 1.1 -->
                    
                <!-- Federated Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2504.10830" target="_blank" rel="noopener noreferrer">Radiation Footprint Control in Cell-Free Cooperative ISAC: Optimal Joint BS Activation and Beamforming Coordination</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jie Chen, Xianbin Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Coordinated beamforming across distributed base stations (BSs) in cell-free architectures can efficiently support integrated sensing and communication (ISAC) users by improving resource sharing and reducing conflicts in the spatial domain. However, coordinating numerous BSs within the ISAC network p</span>
                
                <span class="abstract-full" style="display: none;">Coordinated beamforming across distributed base stations (BSs) in cell-free architectures can efficiently support integrated sensing and communication (ISAC) users by improving resource sharing and reducing conflicts in the spatial domain. However, coordinating numerous BSs within the ISAC network poses risks of generating substantial interference for other networks sharing the spectrum, while also increasing operational costs from power consumption and signaling overhead. Therefore, in this paper, we propose an interference-suppressed and cost-optimized cell-free ISAC network by opportunistically and cooperatively orchestrating distributed radio resources to address competing sensing and communication (S\&amp;C) demands. Specifically, we conceive a radiation footprint control mechanism that autonomously suppresses interference across the entire signal propagation space to safeguard other networks without exchanging signaling. Then, we propose joint BS activation and beamforming coordination to dynamically activate appropriate BSs and orchestrate their spatial beams for service provisioning. Building upon this framework, we formulate a cost-efficient utility maximization problem that considers individual S\&amp;C demands and location-dependent radiation footprint constraints. Since this results in a non-convex optimization problem, we develop a monotonic optimization embedded branch-and-bound (MO-BRB) algorithm to find the optimal solution. Additionally, we apply a low-complexity iterative method to obtain near-optimal solutions. Finally, simulation results validate the effectiveness of the proposed algorithms.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 8.1 -->
                    
                <!-- Medicine: 5.2 -->
                    
                <!-- Quantum Computing: 2.0 -->
                    
                <!-- Reinforcement Learning: 1.9 -->
                    
                <!-- Networks: 1.8 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- RAG: 1.4 -->
                    
                <!-- T2I: 1.3 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- Attention: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.0937
                </span>
                <a href="https://arxiv.org/abs/2406.09983" target="_blank" rel="noopener noreferrer">Epidemic-induced local awareness behavior inferred from surveys and genetic sequence data</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Gergely \'Odor, M\'arton Karsai
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Behavior-disease models suggest that pandemics can be contained cost-effectively if individuals take preventive actions when disease prevalence rises among their close contacts. However, assessing local awareness behavior in real-world datasets remains a challenge. Through the analysis of mutation p</span>
                
                <span class="abstract-full" style="display: none;">Behavior-disease models suggest that pandemics can be contained cost-effectively if individuals take preventive actions when disease prevalence rises among their close contacts. However, assessing local awareness behavior in real-world datasets remains a challenge. Through the analysis of mutation patterns in clinical genetic sequence data, we propose an efficient approach to quantify the impact of local awareness by identifying superspreading events and assigning containment scores to them.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 13.1 -->
                    
                <!-- Medicine: 6.1 -->
                    
                <!-- Quantum Computing: 4.7 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- RAG: 1.8 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- Networks: 1.5 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- Math: 1.1 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- T2I: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.2717
                </span>
                <a href="https://arxiv.org/abs/2412.07355" target="_blank" rel="noopener noreferrer">Towards Predictive Communication with Brain-Computer Interfaces integrating Large Language Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Andrea Caria
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This perspective article aims at providing an outline of the state of the art and future developments towards the integration of cutting-edge predictive language models with BCI. A synthetic overview of early and more recent linguistic models, from natural language processing (NLP) models to recent </span>
                
                <span class="abstract-full" style="display: none;">This perspective article aims at providing an outline of the state of the art and future developments towards the integration of cutting-edge predictive language models with BCI. A synthetic overview of early and more recent linguistic models, from natural language processing (NLP) models to recent LLM, that to a varying extent improved predictive writing systems, is first provided. Second, a summary of previous BCI implementations integrating language models is presented. The few preliminary studies investigating the possible combination of LLM with BCI spellers to efficiently support fast communication and control are then described. Finally, current challenges and limitations towards the full integration of LLM with BCI systems are discussed. Recent investigations suggest that the combination of LLM with BCI might drastically improve human-computer interaction in patients with motor or language disorders as well as in healthy individuals. In particular, the pretrained autoregressive transformer models, such as GPT, that capitalize from parallelization, learning through pre-training and fine-tuning, promise a substantial improvement of BCI for communication with respect to previous systems incorporating simpler language models. Indeed, among various models, the GPT-2 was shown to represent an excellent candidate for its integration into BCI although testing was only perfomed on simulated conversations and not on real BCI scenarios. Prospectively, the full integration of LLM with advanced BCI systems might lead to a big leap forward towards fast, efficient and user-adaptive neurotechnology.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 19.0 -->
                    
                <!-- Medicine: 7.5 -->
                    
                <!-- Quantum Computing: 2.4 -->
                    
                <!-- Reinforcement Learning: 2.4 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- Networks: 1.5 -->
                    
                <!-- Math: 1.5 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.05
                </span>
                <a href="https://arxiv.org/abs/2409.06857" target="_blank" rel="noopener noreferrer">What is the Role of Small Models in the LLM Era: A Survey</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Lihu Chen, Ga\"el Varoquaux
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Large Language Models (LLMs) have made significant progress in advancing artificial general intelligence (AGI), leading to the development of increasingly large models such as GPT-4 and LLaMA-405B. However, scaling up model sizes results in exponentially higher computational costs and energy consump</span>
                
                <span class="abstract-full" style="display: none;">Large Language Models (LLMs) have made significant progress in advancing artificial general intelligence (AGI), leading to the development of increasingly large models such as GPT-4 and LLaMA-405B. However, scaling up model sizes results in exponentially higher computational costs and energy consumption, making these models impractical for academic researchers and businesses with limited resources. At the same time, Small Models (SMs) are frequently used in practical settings, although their significance is currently underestimated. This raises important questions about the role of small models in the era of LLMs, a topic that has received limited attention in prior research. In this work, we systematically examine the relationship between LLMs and SMs from two key perspectives: Collaboration and Competition. We hope this survey provides valuable insights for practitioners, fostering a deeper understanding of the contribution of small models and promoting more efficient use of computational resources. The code is available at https://github.com/tigerchen52/role_of_small_models</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge high-confidence" style="background-color: #5f6936" title="Confidence: 84.0%">
                            LLMs
                        </span>
                <!-- Medicine: 5.3 -->
                    
                <!-- Quantum Computing: 2.2 -->
                    
                <!-- Math: 1.4 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Pathfinding: 1.1 -->
                    
                <!-- Networks: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.8776
                </span>
                <a href="https://arxiv.org/abs/2504.10747" target="_blank" rel="noopener noreferrer">Encryption scheme based on Automorphism Group of Hermitian Function Field with Homomorphic Encryption</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Gennady Khalimov, Yevgen Kotukh
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This article proposes a comprehensive approach to implementing encryption schemes based on the automorphism group of the Hermitian function field. We utilize a three-parameter group with logarithmic representations outside the group's center. In this work, we enhance the Hermitian function field-bas</span>
                
                <span class="abstract-full" style="display: none;">This article proposes a comprehensive approach to implementing encryption schemes based on the automorphism group of the Hermitian function field. We utilize a three-parameter group with logarithmic representations outside the group's center. In this work, we enhance the Hermitian function field-based encryption scheme with homomorphic encryption capabilities, which constitutes a significant advantage of our implementation. Both the attack complexity and the encrypted message size are directly correlated with the order of the group.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #64ef07" title="Confidence: 70.4%">
                            Cryptography
                        </span>
                <!-- SpikingNN: 4.7 -->
                    
                <!-- Multi-armed Bandit: 3.8 -->
                    
                <!-- Hardware: 3.0 -->
                    
                <!-- HPO and AutoML: 2.4 -->
                    
                <!-- Quality Diversity: 2.0 -->
                    
                <!-- Cool: 2.0 -->
                    
                <!-- Bayesian Optimization: 2.0 -->
                    
                <!-- Finance: 1.9 -->
                    
                <!-- Fuzzy Logic: 1.8 -->
                    
                <!-- Game Theory: 1.7 -->
                    
                <!-- Astronomy: 1.2 -->
                    
                <!-- Computer Vision: 1.2 -->
                    
                <!-- Optimizers: 1.2 -->
                    
                <!-- Distributed Systems: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.2186
                </span>
                <a href="https://arxiv.org/abs/2504.11154" target="_blank" rel="noopener noreferrer">SAR-to-RGB Translation with Latent Diffusion for Earth Observation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Kaan Aydin, Joelle Hanna, Damian Borth
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Earth observation satellites like Sentinel-1 (S1) and Sentinel-2 (S2) provide complementary remote sensing (RS) data, but S2 images are often unavailable due to cloud cover or data gaps. To address this, we propose a diffusion model (DM)-based approach for SAR-to-RGB translation, generating syntheti</span>
                
                <span class="abstract-full" style="display: none;">Earth observation satellites like Sentinel-1 (S1) and Sentinel-2 (S2) provide complementary remote sensing (RS) data, but S2 images are often unavailable due to cloud cover or data gaps. To address this, we propose a diffusion model (DM)-based approach for SAR-to-RGB translation, generating synthetic optical images from SAR inputs. We explore three different setups: two using Standard Diffusion, which reconstruct S2 images by adding and removing noise (one without and one with class conditioning), and one using Cold Diffusion, which blends S2 with S1 before removing the SAR signal. We evaluate the generated images in downstream tasks, including land cover classification and cloud removal. While generated images may not perfectly replicate real S2 data, they still provide valuable information. Our results show that class conditioning improves classification accuracy, while cloud removal performance remains competitive despite our approach not being optimized for it. Interestingly, despite exhibiting lower perceptual quality, the Cold Diffusion setup performs well in land cover classification, suggesting that traditional quantitative evaluation metrics may not fully reflect the practical utility of generated images. Our findings highlight the potential of DMs for SAR-to-RGB translation in RS applications where RGB images are missing.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 10.4 -->
                    
                <!-- LLMs: 7.4 -->
                    
                <!-- Quantum Computing: 3.9 -->
                    
                <!-- 3D: 1.8 -->
                    
                <!-- Networks: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- T2I: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- RAG: 1.3 -->
                    
                <!-- Math: 1.2 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Evolutionary Algorithms: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.3225
                </span>
                <a href="https://arxiv.org/abs/2504.10698" target="_blank" rel="noopener noreferrer">Optimising Intrusion Detection Systems in Cloud-Edge Continuum with Knowledge Distillation for Privacy-Preserving and Efficient Communication</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Soad Almabdy, Amjad Ullah
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The growth of the Internet of Things has amplified the need for secure data interactions in cloud-edge ecosystems, where sensitive information is constantly processed across various system layers. Intrusion detection systems are commonly used to protect such environments from malicious attacks. Rece</span>
                
                <span class="abstract-full" style="display: none;">The growth of the Internet of Things has amplified the need for secure data interactions in cloud-edge ecosystems, where sensitive information is constantly processed across various system layers. Intrusion detection systems are commonly used to protect such environments from malicious attacks. Recently, Federated Learning has emerged as an effective solution for implementing intrusion detection systems, owing to its decentralised architecture that avoids sharing raw data with a central server, thereby enhancing data privacy. Despite its benefits, Federated Learning faces criticism for high communication overhead from frequent model updates, especially in large-scale Cloud-Edge infrastructures. This paper explores Knowledge Distillation to reduce communication overhead in Cloud-Edge intrusion detection while preserving accuracy and data privacy. Experiments show significant improvements over state-of-the-art methods.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 10.1 -->
                    
                <!-- LLMs: 8.2 -->
                    
                <!-- Quantum Computing: 4.2 -->
                    
                <!-- Networks: 2.9 -->
                    
                <!-- RAG: 1.9 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- T2I: 1.2 -->
                    
                <!-- 3D: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.541
                </span>
                <a href="https://arxiv.org/abs/2504.11171" target="_blank" rel="noopener noreferrer">TerraMind: Large-Scale Generative Multimodality for Earth Observation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Johannes Jakubik, Felix Yang, Benedikt Blumenstiel, Erik Scheurer, Rocco Sedona, Stefano Maurogiovanni, Jente Bosmans, Nikolaos Dionelis, Valerio Marsocci, Niklas Kopp, Rahul Ramachandran, Paolo Fraccaro, Thomas Brunschwiler, Gabriele Cavallaro, Juan Bernabe-Moreno, Nicolas Long\'ep\'e
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We present TerraMind, the first any-to-any generative, multimodal foundation model for Earth observation (EO). Unlike other multimodal models, TerraMind is pretrained on dual-scale representations combining both token-level and pixel-level data across modalities. On a token level, TerraMind encodes </span>
                
                <span class="abstract-full" style="display: none;">We present TerraMind, the first any-to-any generative, multimodal foundation model for Earth observation (EO). Unlike other multimodal models, TerraMind is pretrained on dual-scale representations combining both token-level and pixel-level data across modalities. On a token level, TerraMind encodes high-level contextual information to learn cross-modal relationships, while on a pixel level, TerraMind leverages fine-grained representations to capture critical spatial nuances. We pretrained TerraMind on nine geospatial modalities of a global, large-scale dataset. In this paper, we demonstrate that (i) TerraMind's dual-scale early fusion approach unlocks a range of zero-shot and few-shot applications for Earth observation, (ii) TerraMind introduces "Thinking-in-Modalities" (TiM) -- the capability of generating additional artificial data during finetuning and inference to improve the model output -- and (iii) TerraMind achieves beyond state-of-the-art performance in community-standard benchmarks for EO like PANGAEA. The pretraining dataset, the model weights, and our code is open-sourced under a permissive license.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 11.0 -->
                    
                <!-- LLMs: 6.0 -->
                    
                <!-- Quantum Computing: 2.7 -->
                    
                <!-- Networks: 2.1 -->
                    
                <!-- Reinforcement Learning: 1.9 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- T2I: 1.1 -->
                    
                <!-- RAG: 1.1 -->
                    
                <!-- Math: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.5759
                </span>
                <a href="https://arxiv.org/abs/2503.16188" target="_blank" rel="noopener noreferrer">Think or Not Think: A Study of Explicit Thinking in Rule-Based Visual Reinforcement Fine-Tuning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ming Li, Jike Zhong, Shitian Zhao, Yuxiang Lai, Kaipeng Zhang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper investigates the thinking process in rule-based reinforcement learning fine-tuning (RFT) for multi-modal large language models (MLLMs). We first propose CLS-RL for classification, using verifiable rewards to encourage MLLM thinking. Experiments show CLS-RL significantly outperforms SFT an</span>
                
                <span class="abstract-full" style="display: none;">This paper investigates the thinking process in rule-based reinforcement learning fine-tuning (RFT) for multi-modal large language models (MLLMs). We first propose CLS-RL for classification, using verifiable rewards to encourage MLLM thinking. Experiments show CLS-RL significantly outperforms SFT and yields a 'free-lunch' generalization effect (improving performance on unseen datasets after training on one dataset). We then question if this explicit thinking is always necessary for RFT. Challenging convention that explicit thinking is crucial for RFT, we introduce No-Thinking-RL, minimizing thinking via a simple equality accuracy reward. Experiments show No-Thinking-RL surpasses CLS-RL in in-domain and generalization abilities, with significantly less fine-tuning time. This suggests reducing thinking can improve MLLM fine-tuning efficiency and effectiveness for certain visual tasks. We hypothesize explicit thinking negatively impacts reward convergence during RFT. To test this, we propose the Think-After-Answerwer method to let models first output the answer and then generate thinking process to alliviate the negative impact of thinking. We further test No-Thinking-RL on diverse tasks (including math, spatial, puzzles) with 2B and 7B models. For 2B models, No-Thinking-RL outperforms thinking-based RFT for all tasks, even on math, with Think-After-Answerwer performing intermediately. For 7B models, performance is comparable on simple visual tasks, but RFT with thinking excels on complex reasoning (math). This implies when dealing with complex math problems, smaller models struggle with generating effective reasoning, hurting performance on complex tasks. Conversely, for simple visual tasks, thinking is not indispensable, and its removal can boost performance and reduce training time. We hope our findings offer insights for better understanding the effect of the thinking process in RFT.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 11.2 -->
                    
                <!-- LLMs: 7.3 -->
                    
                <!-- Quantum Computing: 2.6 -->
                    
                <!-- Networks: 1.5 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- T2I: 1.4 -->
                    
                <!-- RAG: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- 3D: 1.1 -->
                    
                <!-- Math: 1.1 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.5904
                </span>
                <a href="https://arxiv.org/abs/2411.19000" target="_blank" rel="noopener noreferrer">An AI-driven multimodal smart home platform for continuous monitoring and intelligent assistance in post-stroke patients</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Chenyu Tang, Ruizhi Zhang, Shuo Gao, Zihe Zhao, Zibo Zhang, Jiaqi Wang, Cong Li, Junliang Chen, Yanning Dai, Shengbo Wang, Ruoyu Juan, Qiaoying Li, Ruimou Xie, Xuhang Chen, Xinkai Zhou, Yunjia Xia, Jianan Chen, Fanghao Lu, Xin Li, Ninglli Wang, Peter Smielewski, Yu Pan, Hubin Zhao, Luigi G. Occhipinti
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">At-home rehabilitation for post-stroke patients presents significant challenges, as continuous, personalized care is often limited outside clinical settings. Additionally, the absence of comprehensive solutions addressing diverse monitoring and assistance needs in home environments complicates recov</span>
                
                <span class="abstract-full" style="display: none;">At-home rehabilitation for post-stroke patients presents significant challenges, as continuous, personalized care is often limited outside clinical settings. Additionally, the absence of comprehensive solutions addressing diverse monitoring and assistance needs in home environments complicates recovery efforts. Here, we present a multimodal smart home platform designed for continuous, at-home rehabilitation of post-stroke patients, integrating wearable sensing, ambient monitoring, and adaptive automation. A plantar pressure insole equipped with a machine learning pipeline classifies users into motor recovery stages with up to 94% accuracy, enabling quantitative tracking of walking patterns. A head-mounted eye-tracking module supports cognitive assessments and hands-free control of household devices, while ambient sensors ensure sub-second response times for interaction. These data streams are fused locally via a hierarchical Internet of Things (IoT) architecture, protecting privacy and minimizing latency. An embedded large language model (LLM) agent, Auto-Care, continuously interprets multimodal data to provide real-time interventions-issuing personalized reminders, adjusting environmental conditions, and notifying caregivers. Implemented in a post-stroke context, this integrated smart home platform increases overall user satisfaction by an average of 115% (p<0.01) compared to traditional home environment. Beyond stroke, the system offers a scalable framework for patient-centered, long-term care in broader neurorehabilitation and aging-in-place applications.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 11.2 -->
                    
                <!-- LLMs: 8.7 -->
                    
                <!-- Quantum Computing: 3.0 -->
                    
                <!-- Networks: 2.2 -->
                    
                <!-- RAG: 2.1 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- T2I: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- Attention: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.615
                </span>
                <a href="https://arxiv.org/abs/2504.10834" target="_blank" rel="noopener noreferrer">LightFormer: A lightweight and efficient decoder for remote sensing image segmentation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Sihang Chen, Lijun Yun, Ze Liu, JianFeng Zhu, Jie Chen, Hui Wang, Yueping Nie
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Deep learning techniques have achieved remarkable success in the semantic segmentation of remote sensing images and in land-use change detection. Nevertheless, their real-time deployment on edge platforms remains constrained by decoder complexity. Herein, we introduce LightFormer, a lightweight deco</span>
                
                <span class="abstract-full" style="display: none;">Deep learning techniques have achieved remarkable success in the semantic segmentation of remote sensing images and in land-use change detection. Nevertheless, their real-time deployment on edge platforms remains constrained by decoder complexity. Herein, we introduce LightFormer, a lightweight decoder for time-critical tasks that involve unstructured targets, such as disaster assessment, unmanned aerial vehicle search-and-rescue, and cultural heritage monitoring. LightFormer employs a feature-fusion and refinement module built on channel processing and a learnable gating mechanism to aggregate multi-scale, multi-range information efficiently, which drastically curtails model complexity. Furthermore, we propose a spatial information selection module (SISM) that integrates long-range attention with a detail preservation branch to capture spatial dependencies across multiple scales, thereby substantially improving the recognition of unstructured targets in complex scenes. On the ISPRS Vaihingen benchmark, LightFormer attains 99.9% of GLFFNet's mIoU (83.9% vs. 84.0%) while requiring only 14.7% of its FLOPs and 15.9% of its parameters, thus achieving an excellent accuracy-efficiency trade-off. Consistent results on LoveDA, ISPRS Potsdam, RescueNet, and FloodNet further demonstrate its robustness and superior perception of unstructured objects. These findings highlight LightFormer as a practical solution for remote sensing applications where both computational economy and high-precision segmentation are imperative.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 10.5 -->
                    
                <!-- LLMs: 7.5 -->
                    
                <!-- Quantum Computing: 2.7 -->
                    
                <!-- Networks: 1.9 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- RAG: 1.3 -->
                    
                <!-- T2I: 1.3 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- Attention: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.6858
                </span>
                <a href="https://arxiv.org/abs/2502.10436" target="_blank" rel="noopener noreferrer">MERGE$^3$: Efficient Evolutionary Merging on Consumer-grade GPUs</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Tommaso Mencattini, Adrian Robert Minut, Donato Crisostomi, Andrea Santilli, Emanuele Rodol\`a
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Evolutionary model merging enables the creation of high-performing multi-task models but remains computationally prohibitive for consumer hardware. We introduce MERGE$^3$, an efficient framework that makes evolutionary merging feasible on a single GPU by reducing fitness computation costs 50$\times$</span>
                
                <span class="abstract-full" style="display: none;">Evolutionary model merging enables the creation of high-performing multi-task models but remains computationally prohibitive for consumer hardware. We introduce MERGE$^3$, an efficient framework that makes evolutionary merging feasible on a single GPU by reducing fitness computation costs 50$\times$ while preserving performance. MERGE$^3$ achieves this by Extracting a reduced dataset for evaluation, Estimating model abilities using Item Response Theory (IRT), and Evolving optimal merges via IRT-based performance estimators. Our method enables state-of-the-art multilingual and cross-lingual merging, transferring knowledge across languages with significantly lower computational overhead. We provide theoretical guarantees and an open-source library, democratizing high-quality model merging.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 12.2 -->
                    
                <!-- LLMs: 10.1 -->
                    
                <!-- Quantum Computing: 4.0 -->
                    
                <!-- 3D: 1.9 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- RAG: 1.6 -->
                    
                <!-- T2I: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Networks: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Attention: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.751
                </span>
                <a href="https://arxiv.org/abs/2504.11202" target="_blank" rel="noopener noreferrer">Focal Split: Untethered Snapshot Depth from Differential Defocus</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Junjie Luo, John Mamish, Alan Fu, Thomas Concannon, Josiah Hester, Emma Alexander, Qi Guo
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We introduce Focal Split, a handheld, snapshot depth camera with fully onboard power and computing based on depth-from-differential-defocus (DfDD). Focal Split is passive, avoiding power consumption of light sources. Its achromatic optical system simultaneously forms two differentially defocused ima</span>
                
                <span class="abstract-full" style="display: none;">We introduce Focal Split, a handheld, snapshot depth camera with fully onboard power and computing based on depth-from-differential-defocus (DfDD). Focal Split is passive, avoiding power consumption of light sources. Its achromatic optical system simultaneously forms two differentially defocused images of the scene, which can be independently captured using two photosensors in a snapshot. The data processing is based on the DfDD theory, which efficiently computes a depth and a confidence value for each pixel with only 500 floating point operations (FLOPs) per pixel from the camera measurements. We demonstrate a Focal Split prototype, which comprises a handheld custom camera system connected to a Raspberry Pi 5 for real-time data processing. The system consumes 4.9 W and is powered on a 5 V, 10,000 mAh battery. The prototype can measure objects with distances from 0.4 m to 1.2 m, outputting 480$\times$360 sparse depth maps at 2.1 frames per second (FPS) using unoptimized Python scripts. Focal Split is DIY friendly. A comprehensive guide to building your own Focal Split depth camera, code, and additional data can be found at https://focal-split.qiguo.org.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 10.1 -->
                    
                <!-- Networks: 3.5 -->
                    
                <!-- Quantum Computing: 3.4 -->
                    
                <!-- LLMs: 2.9 -->
                    
                <!-- Reinforcement Learning: 2.3 -->
                    
                <!-- 3D: 2.0 -->
                    
                <!-- Robotics: 1.8 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Math: 1.3 -->
                    
                <!-- RAG: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.868
                </span>
                <a href="https://arxiv.org/abs/2504.10735" target="_blank" rel="noopener noreferrer">Frozen Layers: Memory-efficient Many-fidelity Hyperparameter Optimization</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Timur Carstensen, Neeratyoy Mallik, Frank Hutter, Martin Rapp
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">As model sizes grow, finding efficient and cost-effective hyperparameter optimization (HPO) methods becomes increasingly crucial for deep learning pipelines. While multi-fidelity HPO (MF-HPO) trades off computational resources required for DL training with lower fidelity estimations, existing fideli</span>
                
                <span class="abstract-full" style="display: none;">As model sizes grow, finding efficient and cost-effective hyperparameter optimization (HPO) methods becomes increasingly crucial for deep learning pipelines. While multi-fidelity HPO (MF-HPO) trades off computational resources required for DL training with lower fidelity estimations, existing fidelity sources often fail under lower compute and memory constraints. We propose a novel fidelity source: the number of layers that are trained or frozen during training. For deep networks, this approach offers significant compute and memory savings while preserving rank correlations between hyperparameters at low fidelities compared to full model training. We demonstrate this in our empirical evaluation across ResNets and Transformers and additionally analyze the utility of frozen layers as a fidelity in using GPU resources as a fidelity in HPO, and for a combined MF-HPO with other fidelity sources. This contribution opens new applications for MF-HPO with hardware resources as a fidelity and creates opportunities for improved algorithms navigating joint fidelity spaces.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 12.4 -->
                    
                <!-- LLMs: 6.4 -->
                    
                <!-- Quantum Computing: 3.1 -->
                    
                <!-- Networks: 2.1 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- T2I: 1.5 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- RAG: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Attention: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.9142
                </span>
                <a href="https://arxiv.org/abs/2504.10916" target="_blank" rel="noopener noreferrer">Embedding Radiomics into Vision Transformers for Multimodal Medical Image Classification</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zhenyu Yang, Haiming Zhu, Rihui Zhang, Haipeng Zhang, Jianliang Wang, Chunhao Wang, Minbin Chen, Fang-Fang Yin
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Background: Deep learning has significantly advanced medical image analysis, with Vision Transformers (ViTs) offering a powerful alternative to convolutional models by modeling long-range dependencies through self-attention. However, ViTs are inherently data-intensive and lack domain-specific induct</span>
                
                <span class="abstract-full" style="display: none;">Background: Deep learning has significantly advanced medical image analysis, with Vision Transformers (ViTs) offering a powerful alternative to convolutional models by modeling long-range dependencies through self-attention. However, ViTs are inherently data-intensive and lack domain-specific inductive biases, limiting their applicability in medical imaging. In contrast, radiomics provides interpretable, handcrafted descriptors of tissue heterogeneity but suffers from limited scalability and integration into end-to-end learning frameworks. In this work, we propose the Radiomics-Embedded Vision Transformer (RE-ViT) that combines radiomic features with data-driven visual embeddings within a ViT backbone.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 13.2 -->
                    
                <!-- LLMs: 10.7 -->
                    
                <!-- Quantum Computing: 3.6 -->
                    
                <!-- RAG: 2.3 -->
                    
                <!-- GNN: 2.2 -->
                    
                <!-- Networks: 1.9 -->
                    
                <!-- 3D: 1.9 -->
                    
                <!-- T2I: 1.7 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- Attention: 1.2 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                <!-- Evolutionary Algorithms: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.951
                </span>
                <a href="https://arxiv.org/abs/2504.11368" target="_blank" rel="noopener noreferrer">From Gaze to Insight: Bridging Human Visual Attention and Vision Language Model Explanation for Weakly-Supervised Medical Image Segmentation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jingkun Chen, Haoran Duan, Xiao Zhang, Boyan Gao, Tao Tan, Vicente Grau, Jungong Han
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Medical image segmentation remains challenging due to the high cost of pixel-level annotations for training. In the context of weak supervision, clinician gaze data captures regions of diagnostic interest; however, its sparsity limits its use for segmentation. In contrast, vision-language models (VL</span>
                
                <span class="abstract-full" style="display: none;">Medical image segmentation remains challenging due to the high cost of pixel-level annotations for training. In the context of weak supervision, clinician gaze data captures regions of diagnostic interest; however, its sparsity limits its use for segmentation. In contrast, vision-language models (VLMs) provide semantic context through textual descriptions but lack the explanation precision required. Recognizing that neither source alone suffices, we propose a teacher-student framework that integrates both gaze and language supervision, leveraging their complementary strengths. Our key insight is that gaze data indicates where clinicians focus during diagnosis, while VLMs explain why those regions are significant. To implement this, the teacher model first learns from gaze points enhanced by VLM-generated descriptions of lesion morphology, establishing a foundation for guiding the student model. The teacher then directs the student through three strategies: (1) Multi-scale feature alignment to fuse visual cues with textual semantics; (2) Confidence-weighted consistency constraints to focus on reliable predictions; (3) Adaptive masking to limit error propagation in uncertain areas. Experiments on the Kvasir-SEG, NCI-ISBI, and ISIC datasets show that our method achieves Dice scores of 80.78%, 80.53%, and 84.22%, respectively-improving 3-5% over gaze baselines without increasing the annotation burden. By preserving correlations among predictions, gaze data, and lesion descriptions, our framework also maintains clinical interpretability. This work illustrates how integrating human visual attention with AI-generated semantic context can effectively overcome the limitations of individual weak supervision signals, thereby advancing the development of deployable, annotation-efficient medical AI systems. Code is available at: https://github.com/jingkunchen/FGI.git.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 10.8 -->
                    
                <!-- LLMs: 9.0 -->
                    
                <!-- Quantum Computing: 3.6 -->
                    
                <!-- Reinforcement Learning: 2.3 -->
                    
                <!-- Networks: 1.7 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Math: 1.3 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- 3D: 1.0 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.0165
                </span>
                <a href="https://arxiv.org/abs/2312.08558" target="_blank" rel="noopener noreferrer">Leveraging Driver Field-of-View for Multimodal Ego-Trajectory Prediction</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: M. Eren Akbiyik, Nedko Savov, Danda Pani Paudel, Nikola Popovic, Christian Vater, Otmar Hilliges, Luc Van Gool, Xi Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Understanding drivers' decision-making is crucial for road safety. Although predicting the ego-vehicle's path is valuable for driver-assistance systems, existing methods mainly focus on external factors like other vehicles' motions, often neglecting the driver's attention and intent. To address this</span>
                
                <span class="abstract-full" style="display: none;">Understanding drivers' decision-making is crucial for road safety. Although predicting the ego-vehicle's path is valuable for driver-assistance systems, existing methods mainly focus on external factors like other vehicles' motions, often neglecting the driver's attention and intent. To address this gap, we infer the ego-trajectory by integrating the driver's gaze and the surrounding scene. We introduce RouteFormer, a novel multimodal ego-trajectory prediction network combining GPS data, environmental context, and the driver's field-of-view, comprising first-person video and gaze fixations. We also present the Path Complexity Index (PCI), a new metric for trajectory complexity that enables a more nuanced evaluation of challenging scenarios. To tackle data scarcity and enhance diversity, we introduce GEM, a comprehensive dataset of urban driving scenarios enriched with synchronized driver field-of-view and gaze data. Extensive evaluations on GEM and DR(eye)VE demonstrate that RouteFormer significantly outperforms state-of-the-art methods, achieving notable improvements in prediction accuracy across diverse conditions. Ablation studies reveal that incorporating driver field-of-view data yields significantly better average displacement error, especially in challenging scenarios with high PCI scores, underscoring the importance of modeling driver attention. All data and code are available at https://meakbiyik.github.io/routeformer.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 13.1 -->
                    
                <!-- LLMs: 4.5 -->
                    
                <!-- Quantum Computing: 2.3 -->
                    
                <!-- Reinforcement Learning: 1.9 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- Networks: 1.4 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Math: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                <!-- RAG: 1.1 -->
                    
                <!-- T2I: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.0996
                </span>
                <a href="https://arxiv.org/abs/2504.10556" target="_blank" rel="noopener noreferrer">VAE-based Feature Disentanglement for Data Augmentation and Compression in Generalized GNSS Interference Classification</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Lucas Heublein, Simon Kocher, Tobias Feigl, Alexander R\"ugamer, Christopher Mutschler, Felix Ott
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Distributed learning and Edge AI necessitate efficient data processing, low-latency communication, decentralized model training, and stringent data privacy to facilitate real-time intelligence on edge devices while reducing dependency on centralized infrastructure and ensuring high model performance</span>
                
                <span class="abstract-full" style="display: none;">Distributed learning and Edge AI necessitate efficient data processing, low-latency communication, decentralized model training, and stringent data privacy to facilitate real-time intelligence on edge devices while reducing dependency on centralized infrastructure and ensuring high model performance. In the context of global navigation satellite system (GNSS) applications, the primary objective is to accurately monitor and classify interferences that degrade system performance in distributed environments, thereby enhancing situational awareness. To achieve this, machine learning (ML) models can be deployed on low-resource devices, ensuring minimal communication latency and preserving data privacy. The key challenge is to compress ML models while maintaining high classification accuracy. In this paper, we propose variational autoencoders (VAEs) for disentanglement to extract essential latent features that enable accurate classification of interferences. We demonstrate that the disentanglement approach can be leveraged for both data compression and data augmentation by interpolating the lower-dimensional latent representations of signal power. To validate our approach, we evaluate three VAE variants - vanilla, factorized, and conditional generative - on four distinct datasets, including two collected in controlled indoor environments and two real-world highway datasets. Additionally, we conduct extensive hyperparameter searches to optimize performance. Our proposed VAE achieves a data compression rate ranging from 512 to 8,192 and achieves an accuracy up to 99.92%.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 12.4 -->
                    
                <!-- LLMs: 9.1 -->
                    
                <!-- Quantum Computing: 2.9 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- RAG: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- Networks: 1.2 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- T2I: 1.1 -->
                    
                <!-- Evolutionary Algorithms: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.1131
                </span>
                <a href="https://arxiv.org/abs/2504.11000" target="_blank" rel="noopener noreferrer">Why am I seeing this? Towards recognizing social media recommender systems with missing recommendations</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Sabrina Guidotti, Sabrina Patania, Giuseppe Vizzari, Dimitri Ognibene, Gregor Donabauer, Udo Kruschwitz, Davide Taibi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Social media plays a crucial role in shaping society, often amplifying polarization and spreading misinformation. These effects stem from complex dynamics involving user interactions, individual traits, and recommender algorithms driving content selection. Recommender systems, which significantly sh</span>
                
                <span class="abstract-full" style="display: none;">Social media plays a crucial role in shaping society, often amplifying polarization and spreading misinformation. These effects stem from complex dynamics involving user interactions, individual traits, and recommender algorithms driving content selection. Recommender systems, which significantly shape the content users see and decisions they make, offer an opportunity for intervention and regulation. However, assessing their impact is challenging due to algorithmic opacity and limited data availability. To effectively model user decision-making, it is crucial to recognize the recommender system adopted by the platform.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 12.5 -->
                    
                <!-- LLMs: 6.3 -->
                    
                <!-- Quantum Computing: 3.3 -->
                    
                <!-- Networks: 2.5 -->
                    
                <!-- RAG: 2.2 -->
                    
                <!-- 3D: 1.9 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- Robotics: 1.7 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- T2I: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.2236
                </span>
                <a href="https://arxiv.org/abs/2504.11305" target="_blank" rel="noopener noreferrer">CFIS-YOLO: A Lightweight Multi-Scale Fusion Network for Edge-Deployable Wood Defect Detection</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jincheng Kang, Yi Cen, Yigang Cen, Ke Wang, Yuhan Liu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Wood defect detection is critical for ensuring quality control in the wood processing industry. However, current industrial applications face two major challenges: traditional methods are costly, subjective, and labor-intensive, while mainstream deep learning models often struggle to balance detecti</span>
                
                <span class="abstract-full" style="display: none;">Wood defect detection is critical for ensuring quality control in the wood processing industry. However, current industrial applications face two major challenges: traditional methods are costly, subjective, and labor-intensive, while mainstream deep learning models often struggle to balance detection accuracy and computational efficiency for edge deployment. To address these issues, this study proposes CFIS-YOLO, a lightweight object detection model optimized for edge devices. The model introduces an enhanced C2f structure, a dynamic feature recombination module, and a novel loss function that incorporates auxiliary bounding boxes and angular constraints. These innovations improve multi-scale feature fusion and small object localization while significantly reducing computational overhead. Evaluated on a public wood defect dataset, CFIS-YOLO achieves a mean Average Precision (mAP@0.5) of 77.5\%, outperforming the baseline YOLOv10s by 4 percentage points. On SOPHON BM1684X edge devices, CFIS-YOLO delivers 135 FPS, reduces power consumption to 17.3\% of the original implementation, and incurs only a 0.5 percentage point drop in mAP. These results demonstrate that CFIS-YOLO is a practical and effective solution for real-world wood defect detection in resource-constrained environments.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 12.9 -->
                    
                <!-- LLMs: 4.9 -->
                    
                <!-- Quantum Computing: 2.6 -->
                    
                <!-- Networks: 2.5 -->
                    
                <!-- 3D: 2.1 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- RAG: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- T2I: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.3377
                </span>
                <a href="https://arxiv.org/abs/2504.10873" target="_blank" rel="noopener noreferrer">Can Vision-Language Models Understand and Interpret Dynamic Gestures from Pedestrians? Pilot Datasets and Exploration Towards Instructive Nonverbal Commands for Cooperative Autonomous Vehicles</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Tonko E. W. Bossen, Andreas M{\o}gelmose, Ross Greer
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In autonomous driving, it is crucial to correctly interpret traffic gestures (TGs), such as those of an authority figure providing orders or instructions, or a pedestrian signaling the driver, to ensure a safe and pleasant traffic environment for all road users. This study investigates the capabilit</span>
                
                <span class="abstract-full" style="display: none;">In autonomous driving, it is crucial to correctly interpret traffic gestures (TGs), such as those of an authority figure providing orders or instructions, or a pedestrian signaling the driver, to ensure a safe and pleasant traffic environment for all road users. This study investigates the capabilities of state-of-the-art vision-language models (VLMs) in zero-shot interpretation, focusing on their ability to caption and classify human gestures in traffic contexts. We create and publicly share two custom datasets with varying formal and informal TGs, such as 'Stop', 'Reverse', 'Hail', etc. The datasets are "Acted TG (ATG)" and "Instructive TG In-The-Wild (ITGI)". They are annotated with natural language, describing the pedestrian's body position and gesture. We evaluate models using three methods utilizing expert-generated captions as baseline and control: (1) caption similarity, (2) gesture classification, and (3) pose sequence reconstruction similarity. Results show that current VLMs struggle with gesture understanding: sentence similarity averages below 0.59, and classification F1 scores reach only 0.14-0.39, well below the expert baseline of 0.70. While pose reconstruction shows potential, it requires more data and refined metrics to be reliable. Our findings reveal that although some SOTA VLMs can interpret zero-shot human traffic gestures, none are accurate and robust enough to be trustworthy, emphasizing the need for further research in this domain.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 11.1 -->
                    
                <!-- LLMs: 8.0 -->
                    
                <!-- Quantum Computing: 3.0 -->
                    
                <!-- Robotics: 2.0 -->
                    
                <!-- RAG: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Networks: 1.3 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.3458
                </span>
                <a href="https://arxiv.org/abs/2504.11416" target="_blank" rel="noopener noreferrer">Deep Learning-based Bathymetry Retrieval without In-situ Depths using Remote Sensing Imagery and SfM-MVS DSMs with Data Gaps</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Panagiotis Agrafiotis, Beg\"um Demir
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Accurate, detailed, and high-frequent bathymetry is crucial for shallow seabed areas facing intense climatological and anthropogenic pressures. Current methods utilizing airborne or satellite optical imagery to derive bathymetry primarily rely on either SfM-MVS with refraction correction or Spectral</span>
                
                <span class="abstract-full" style="display: none;">Accurate, detailed, and high-frequent bathymetry is crucial for shallow seabed areas facing intense climatological and anthropogenic pressures. Current methods utilizing airborne or satellite optical imagery to derive bathymetry primarily rely on either SfM-MVS with refraction correction or Spectrally Derived Bathymetry (SDB). However, SDB methods often require extensive manual fieldwork or costly reference data, while SfM-MVS approaches face challenges even after refraction correction. These include depth data gaps and noise in environments with homogeneous visual textures, which hinder the creation of accurate and complete Digital Surface Models (DSMs) of the seabed. To address these challenges, this work introduces a methodology that combines the high-fidelity 3D reconstruction capabilities of the SfM-MVS methods with state-of-the-art refraction correction techniques, along with the spectral analysis capabilities of a new deep learning-based method for bathymetry prediction. This integration enables a synergistic approach where SfM-MVS derived DSMs with data gaps are used as training data to generate complete bathymetric maps. In this context, we propose Swin-BathyUNet that combines U-Net with Swin Transformer self-attention layers and a cross-attention mechanism, specifically tailored for SDB. Swin-BathyUNet is designed to improve bathymetric accuracy by capturing long-range spatial relationships and can also function as a standalone solution for standard SDB with various training depth data, independent of the SfM-MVS output. Experimental results in two completely different test sites in the Mediterranean and Baltic Seas demonstrate the effectiveness of the proposed approach through extensive experiments that demonstrate improvements in bathymetric accuracy, detail, coverage, and noise reduction in the predicted DSM. The code is available at https://github.com/pagraf/Swin-BathyUNet.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 11.2 -->
                    
                <!-- LLMs: 5.6 -->
                    
                <!-- Quantum Computing: 2.4 -->
                    
                <!-- Reinforcement Learning: 1.8 -->
                    
                <!-- Networks: 1.7 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- Math: 1.1 -->
                    
                <!-- 3D: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.3495
                </span>
                <a href="https://arxiv.org/abs/2504.10506" target="_blank" rel="noopener noreferrer">WorldMove, a global open data for human mobility</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yuan Yuan, Yuheng Zhang, Jingtao Ding, Yong Li
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">High-quality human mobility data is crucial for applications such as urban planning, transportation management, and public health, yet its collection is often hindered by privacy concerns and data scarcity-particularly in less-developed regions. To address this challenge, we introduce WorldMove, a l</span>
                
                <span class="abstract-full" style="display: none;">High-quality human mobility data is crucial for applications such as urban planning, transportation management, and public health, yet its collection is often hindered by privacy concerns and data scarcity-particularly in less-developed regions. To address this challenge, we introduce WorldMove, a large-scale synthetic mobility dataset covering over 1,600 cities across 179 countries and 6 continents. Our method leverages publicly available multi-source data, including gridded population distribution, point-of-interest (POI) maps, and commuting origin-destination (OD) flows-to generate realistic city-scale mobility trajectories using a diffusion-based generative model. The generation process involves defining city boundaries, collecting multi-source input features, and simulating individual-level movements that reflect plausible daily mobility behavior. Comprehensive validation demonstrates that the generated data closely aligns with real-world observations, both in terms of fine-grained individual mobility behavior and city-scale population flows. Alongside the pre-generated datasets, we release the trained model and a complete open-source pipeline, enabling researchers and practitioners to generate custom synthetic mobility data for any city worldwide. This work not only fills critical data gaps, but also lays a global foundation for scalable, privacy-preserving, and inclusive mobility research-empowering data-scarce regions and enabling universal access to human mobility insights.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 14.5 -->
                    
                <!-- LLMs: 6.6 -->
                    
                <!-- Quantum Computing: 2.4 -->
                    
                <!-- Networks: 1.9 -->
                    
                <!-- 3D: 1.9 -->
                    
                <!-- RAG: 1.6 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- T2I: 1.5 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                <!-- Evolutionary Algorithms: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.3924
                </span>
                <a href="https://arxiv.org/abs/2504.11333" target="_blank" rel="noopener noreferrer">Implicit dual time-stepping positivity-preserving entropy-stable schemes for the compressible Navier-Stokes equations</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Mohammed Sayyari, Nail K. Yamaleev
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We generalize the explicit high-order positivity-preserving entropy-stable spectral collocation schemes developed in [30, 34] for the three-dimensional (3D) compressible Navier Stokes equations to a time implicit formulation. The time derivative terms are discretized by using the first- and second-o</span>
                
                <span class="abstract-full" style="display: none;">We generalize the explicit high-order positivity-preserving entropy-stable spectral collocation schemes developed in [30, 34] for the three-dimensional (3D) compressible Navier Stokes equations to a time implicit formulation. The time derivative terms are discretized by using the first- and second-order implicit backward difference formulas (BDF1 and BDF2) that are well suited for solving steady-state and time-dependent viscous flows at high Reynolds numbers, respectively. The nonlinear system of discrete equations at each physical timestep is solved by using a dual time-stepping technique. The proposed scheme is provably entropy-stable and positivity-preserving and provides unconditional stability properties in the physical time. Numerical results demonstrating accuracy and positivity-preserving properties of the new dual time-stepping scheme are presented for supersonic viscous flows with strong shock waves and contact discontinuities.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 12.4 -->
                    
                <!-- LLMs: 4.2 -->
                    
                <!-- Quantum Computing: 2.8 -->
                    
                <!-- Networks: 2.0 -->
                    
                <!-- Robotics: 1.8 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Math: 1.5 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- GNN: 1.0 -->
                    
                <!-- Pathfinding: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.4616
                </span>
                <a href="https://arxiv.org/abs/2411.15124" target="_blank" rel="noopener noreferrer">Tulu 3: Pushing Frontiers in Open Language Model Post-Training</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Nathan Lambert, Jacob Morrison, Valentina Pyatkin, Shengyi Huang, Hamish Ivison, Faeze Brahman, Lester James V. Miranda, Alisa Liu, Nouha Dziri, Shane Lyu, Yuling Gu, Saumya Malik, Victoria Graf, Jena D. Hwang, Jiangjiang Yang, Ronan Le Bras, Oyvind Tafjord, Chris Wilhelm, Luca Soldaini, Noah A. Smith, Yizhong Wang, Pradeep Dasigi, Hannaneh Hajishirzi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Language model post-training is applied to refine behaviors and unlock new skills across a wide range of recent language models, but open recipes for applying these techniques lag behind proprietary ones. The underlying training data and recipes for post-training are simultaneously the most importan</span>
                
                <span class="abstract-full" style="display: none;">Language model post-training is applied to refine behaviors and unlock new skills across a wide range of recent language models, but open recipes for applying these techniques lag behind proprietary ones. The underlying training data and recipes for post-training are simultaneously the most important pieces of the puzzle and the portion with the least transparency. To bridge this gap, we introduce Tulu 3, a family of fully-open state-of-the-art post-trained models, alongside its data, code, and training recipes, serving as a comprehensive guide for modern post-training techniques. Tulu 3, which builds on Llama 3.1 base models, achieves results surpassing the instruct versions of Llama 3.1, Qwen 2.5, Mistral, and even closed models such as GPT-4o-mini and Claude 3.5-Haiku. The training algorithms for our models include supervised finetuning (SFT), Direct Preference Optimization (DPO), and a novel method we call Reinforcement Learning with Verifiable Rewards (RLVR). With Tulu 3, we introduce a multi-task evaluation scheme for post-training recipes with development and unseen evaluations, standard benchmark implementations, and substantial decontamination of existing open datasets on said benchmarks. We conclude with analysis and discussion of training methods that did not reliably improve performance.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 11.5 -->
                    
                <!-- LLMs: 7.6 -->
                    
                <!-- Quantum Computing: 2.3 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- T2I: 1.4 -->
                    
                <!-- Networks: 1.4 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- RAG: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.5769
                </span>
                <a href="https://arxiv.org/abs/2504.10502" target="_blank" rel="noopener noreferrer">Human-Oriented Image Retrieval System (HORSE): A Neuro-Symbolic Approach to Optimizing Retrieval of Previewed Images</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Abraham Itzhak Weinberg
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Image retrieval remains a challenging task due to the complex interaction between human visual perception, memory, and computational processes. Current image search engines often struggle to efficiently retrieve images based on natural language descriptions, as they rely on time-consuming preprocess</span>
                
                <span class="abstract-full" style="display: none;">Image retrieval remains a challenging task due to the complex interaction between human visual perception, memory, and computational processes. Current image search engines often struggle to efficiently retrieve images based on natural language descriptions, as they rely on time-consuming preprocessing, tagging, and machine learning pipelines. This paper introduces the Human-Oriented Retrieval Search Engine for Images (HORSE), a novel approach that leverages neuro-symbolic indexing to improve image retrieval by focusing on human-oriented indexing. By integrating cognitive science insights with advanced computational techniques, HORSE enhances the retrieval process, making it more aligned with how humans perceive, store, and recall visual information. The neuro-symbolic framework combines the strengths of neural networks and symbolic reasoning, mitigating their individual limitations. The proposed system optimizes image retrieval, offering a more intuitive and efficient solution for users. We discuss the design and implementation of HORSE, highlight its potential applications in fields such as design error detection and knowledge management, and suggest future directions for research to further refine the system's metrics and capabilities.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 10.7 -->
                    
                <!-- LLMs: 5.6 -->
                    
                <!-- Quantum Computing: 2.8 -->
                    
                <!-- Networks: 2.0 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- RAG: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.5882
                </span>
                <a href="https://arxiv.org/abs/2504.10878" target="_blank" rel="noopener noreferrer">Large Language Model-Informed Feature Discovery Improves Prediction and Interpretation of Credibility Perceptions of Visual Content</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yilang Peng, Sijia Qian, Yingdan Lu, Cuihua Shen
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In today's visually dominated social media landscape, predicting the perceived credibility of visual content and understanding what drives human judgment are crucial for countering misinformation. However, these tasks are challenging due to the diversity and richness of visual features. We introduce</span>
                
                <span class="abstract-full" style="display: none;">In today's visually dominated social media landscape, predicting the perceived credibility of visual content and understanding what drives human judgment are crucial for countering misinformation. However, these tasks are challenging due to the diversity and richness of visual features. We introduce a Large Language Model (LLM)-informed feature discovery framework that leverages multimodal LLMs, such as GPT-4o, to evaluate content credibility and explain its reasoning. We extract and quantify interpretable features using targeted prompts and integrate them into machine learning models to improve credibility predictions. We tested this approach on 4,191 visual social media posts across eight topics in science, health, and politics, using credibility ratings from 5,355 crowdsourced workers. Our method outperformed zero-shot GPT-based predictions by 13 percent in R2, and revealed key features like information concreteness and image format. We discuss the implications for misinformation mitigation, visual credibility, and the role of LLMs in social science.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 20.1 -->
                    
                <!-- Medicine: 10.1 -->
                    
                <!-- Quantum Computing: 2.9 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- RAG: 1.3 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Networks: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.6269
                </span>
                <a href="https://arxiv.org/abs/2504.10738" target="_blank" rel="noopener noreferrer">CleanMAP: Distilling Multimodal LLMs for Confidence-Driven Crowdsourced HD Map Updates</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ankit Kumar Shaw (Tsinghua University), Kun Jiang (Tsinghua University), Tuopu Wen (Tsinghua University), Chandan Kumar Sah (Beihang University), Yining Shi (Tsinghua University), Mengmeng Yang (Tsinghua University), Diange Yang (Tsinghua University), Xiaoli Lian (Beihang University)
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The rapid growth of intelligent connected vehicles (ICVs) and integrated vehicle-road-cloud systems has increased the demand for accurate, real-time HD map updates. However, ensuring map reliability remains challenging due to inconsistencies in crowdsourced data, which suffer from motion blur, light</span>
                
                <span class="abstract-full" style="display: none;">The rapid growth of intelligent connected vehicles (ICVs) and integrated vehicle-road-cloud systems has increased the demand for accurate, real-time HD map updates. However, ensuring map reliability remains challenging due to inconsistencies in crowdsourced data, which suffer from motion blur, lighting variations, adverse weather, and lane marking degradation. This paper introduces CleanMAP, a Multimodal Large Language Model (MLLM)-based distillation framework designed to filter and refine crowdsourced data for high-confidence HD map updates. CleanMAP leverages an MLLM-driven lane visibility scoring model that systematically quantifies key visual parameters, assigning confidence scores (0-10) based on their impact on lane detection. A novel dynamic piecewise confidence-scoring function adapts scores based on lane visibility, ensuring strong alignment with human evaluations while effectively filtering unreliable data. To further optimize map accuracy, a confidence-driven local map fusion strategy ranks and selects the top-k highest-scoring local maps within an optimal confidence range (best score minus 10%), striking a balance between data quality and quantity. Experimental evaluations on a real-world autonomous vehicle dataset validate CleanMAP's effectiveness, demonstrating that fusing the top three local maps achieves the lowest mean map update error of 0.28m, outperforming the baseline (0.37m) and meeting stringent accuracy thresholds (<= 0.32m). Further validation with real-vehicle data confirms 84.88% alignment with human evaluators, reinforcing the model's robustness and reliability. This work establishes CleanMAP as a scalable and deployable solution for crowdsourced HD map updates, ensuring more precise and reliable autonomous navigation. The code will be available at https://Ankit-Zefan.github.io/CleanMap/</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 14.5 -->
                    
                <!-- LLMs: 5.5 -->
                    
                <!-- Quantum Computing: 2.7 -->
                    
                <!-- 3D: 2.0 -->
                    
                <!-- Networks: 1.9 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- RAG: 1.4 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                <!-- T2I: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.6908
                </span>
                <a href="https://arxiv.org/abs/2504.11026" target="_blank" rel="noopener noreferrer">A PyTorch-Compatible Spike Encoding Framework for Energy-Efficient Neuromorphic Applications</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Alexandru Vasilache, Jona Scholz, Vincent Schilling, Sven Nitzsche, Florian Kaelber, Johannes Korsch, Juergen Becker
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Spiking Neural Networks (SNNs) offer promising energy efficiency advantages, particularly when processing sparse spike trains. However, their incompatibility with traditional datasets, which consist of batches of input vectors rather than spike trains, necessitates the development of efficient encod</span>
                
                <span class="abstract-full" style="display: none;">Spiking Neural Networks (SNNs) offer promising energy efficiency advantages, particularly when processing sparse spike trains. However, their incompatibility with traditional datasets, which consist of batches of input vectors rather than spike trains, necessitates the development of efficient encoding methods. This paper introduces a novel, open-source PyTorch-compatible Python framework for spike encoding, designed for neuromorphic applications in machine learning and reinforcement learning. The framework supports a range of encoding algorithms, including Leaky Integrate-and-Fire (LIF), Step Forward (SF), Pulse Width Modulation (PWM), and Ben's Spiker Algorithm (BSA), as well as specialized encoding strategies covering population coding and reinforcement learning scenarios. Furthermore, we investigate the performance trade-offs of each method on embedded hardware using C/C++ implementations, considering energy consumption, computation time, spike sparsity, and reconstruction accuracy. Our findings indicate that SF typically achieves the lowest reconstruction error and offers the highest energy efficiency and fastest encoding speed, achieving the second-best spike sparsity. At the same time, other methods demonstrate particular strengths depending on the signal characteristics. This framework and the accompanying empirical analysis provide valuable resources for selecting optimal encoding strategies for energy-efficient SNN applications.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 12.3 -->
                    
                <!-- LLMs: 5.3 -->
                    
                <!-- Quantum Computing: 4.2 -->
                    
                <!-- Reinforcement Learning: 1.9 -->
                    
                <!-- Networks: 1.5 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Math: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.7868
                </span>
                <a href="https://arxiv.org/abs/2503.08580" target="_blank" rel="noopener noreferrer">Comparing Next-Day Wildfire Predictability of MODIS and VIIRS Satellite Data</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Justus Karlsson, Yonghao Xu, Amanda Berg, Leif Haglund
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Multiple studies have performed next-day fire prediction using satellite imagery. Two main satellites are used to detect wildfires: MODIS and VIIRS. Both satellites provide fire mask products, called MOD14 and VNP14, respectively. Studies have used one or the other, but there has been no comparison </span>
                
                <span class="abstract-full" style="display: none;">Multiple studies have performed next-day fire prediction using satellite imagery. Two main satellites are used to detect wildfires: MODIS and VIIRS. Both satellites provide fire mask products, called MOD14 and VNP14, respectively. Studies have used one or the other, but there has been no comparison between them to determine which might be more suitable for next-day fire prediction. In this paper, we first evaluate how well VIIRS and MODIS data can be used to forecast wildfire spread one day ahead. We find that the model using VIIRS as input and VNP14 as target achieves the best results. Interestingly, the model using MODIS as input and VNP14 as target performs significantly better than using VNP14 as input and MOD14 as target. Next, we discuss why MOD14 might be harder to use for predicting next-day fires. We find that the MOD14 fire mask is highly stochastic and does not correlate with reasonable fire spread patterns. This is detrimental for machine learning tasks, as the model learns irrational patterns. Therefore, we conclude that MOD14 is unsuitable for next-day fire prediction and that VNP14 is a much better option. However, using MODIS input and VNP14 as target, we achieve a significant improvement in predictability. This indicates that an improved fire detection model is possible for MODIS. The full code and dataset is available online: https://github.com/justuskarlsson/wildfire-mod14-vnp14</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 12.6 -->
                    
                <!-- LLMs: 5.4 -->
                    
                <!-- Quantum Computing: 3.5 -->
                    
                <!-- Robotics: 1.8 -->
                    
                <!-- Networks: 1.7 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- 3D: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- T2I: 1.0 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.7953
                </span>
                <a href="https://arxiv.org/abs/2504.11380" target="_blank" rel="noopener noreferrer">Speak with Confidence: Designing an Augmented Reality Training Tool for Public Speaking</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Mark Edison Jim, Jan Benjamin Yap, Gian Chill Laolao, Andrei Zachary Lim, Jordan Aiko Deja
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Public speaking anxiety affects many individuals, yet opportunities for real-world practice remain limited. This study explores how augmented reality (AR) can provide an accessible training environment for public speaking. Drawing from literature on public speaking, VR-based training, self-efficacy,</span>
                
                <span class="abstract-full" style="display: none;">Public speaking anxiety affects many individuals, yet opportunities for real-world practice remain limited. This study explores how augmented reality (AR) can provide an accessible training environment for public speaking. Drawing from literature on public speaking, VR-based training, self-efficacy, and behavioral feedback mechanisms, we designed SpeakAR, an AR-based tool that simulates audience interaction through virtual models. SpeakAR was evaluated with five participants of varying anxiety levels, each completing six speaking tasks. Results indicate that AR exposure can enhance confidence, with participants finding the system useful for practice. Feedback highlighted the importance of dynamic facial expressions and idle animations in virtual models to improve realism and engagement. Our findings contribute to the design of AR-based training tools for public speaking, offering insights into how immersive environments can support skill development and anxiety reduction.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 16.4 -->
                    
                <!-- LLMs: 9.9 -->
                    
                <!-- Quantum Computing: 4.8 -->
                    
                <!-- RAG: 1.6 -->
                    
                <!-- Networks: 1.4 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- T2I: 1.3 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Math: 1.2 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.8026
                </span>
                <a href="https://arxiv.org/abs/2504.11002" target="_blank" rel="noopener noreferrer">Dopamine Audiobook: A Training-free MLLM Agent for Emotional and Human-like Audiobook Generation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yan Rong, Shan Yang, Guangzhi Lei, Li Liu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Audiobook generation, which creates vivid and emotion-rich audio works, faces challenges in conveying complex emotions, achieving human-like qualities, and aligning evaluations with human preferences. Existing text-to-speech (TTS) methods are often limited to specific scenarios, struggle with emotio</span>
                
                <span class="abstract-full" style="display: none;">Audiobook generation, which creates vivid and emotion-rich audio works, faces challenges in conveying complex emotions, achieving human-like qualities, and aligning evaluations with human preferences. Existing text-to-speech (TTS) methods are often limited to specific scenarios, struggle with emotional transitions, and lack automatic human-aligned evaluation benchmarks, instead relying on either misaligned automated metrics or costly human assessments. To address these issues, we propose Dopamine Audiobook, a new unified training-free system leveraging a multimodal large language model (MLLM) as an AI agent for emotional and human-like audiobook generation and evaluation. Specifically, we first design a flow-based emotion-enhanced framework that decomposes complex emotional speech synthesis into controllable sub-tasks. Then, we propose an adaptive model selection module that dynamically selects the most suitable TTS methods from a set of existing state-of-the-art (SOTA) TTS methods for diverse scenarios. We further enhance emotional expressiveness through paralinguistic augmentation and prosody retrieval at word and utterance levels. For evaluation, we propose a novel GPT-based evaluation framework incorporating self-critique, perspective-taking, and psychological MagicEmo prompts to ensure human-aligned and self-aligned assessments. Experiments show that our method generates long speech with superior emotional expression to SOTA TTS models in various metrics. Importantly, our evaluation framework demonstrates better alignment with human preferences and transferability across audio tasks. Project website with audio samples can be found at https://dopamine-audiobook.github.io.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 12.3 -->
                    
                <!-- LLMs: 11.3 -->
                    
                <!-- 3D: 3.1 -->
                    
                <!-- Quantum Computing: 2.4 -->
                    
                <!-- T2I: 2.3 -->
                    
                <!-- RAG: 1.9 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Networks: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.8774
                </span>
                <a href="https://arxiv.org/abs/2504.11112" target="_blank" rel="noopener noreferrer">Flyweight FLIM Networks for Salient Object Detection in Biomedical Images</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Leonardo M. Joao, Jancarlo F. Gomes, Silvio J. F. Guimaraes, Ewa Kijak, Alexandre X. Falcao
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Salient Object Detection (SOD) with deep learning often requires substantial computational resources and large annotated datasets, making it impractical for resource-constrained applications. Lightweight models address computational demands but typically strive in complex and scarce labeled-data sce</span>
                
                <span class="abstract-full" style="display: none;">Salient Object Detection (SOD) with deep learning often requires substantial computational resources and large annotated datasets, making it impractical for resource-constrained applications. Lightweight models address computational demands but typically strive in complex and scarce labeled-data scenarios. Feature Learning from Image Markers (FLIM) learns an encoder's convolutional kernels among image patches extracted from discriminative regions marked on a few representative images, dismissing large annotated datasets, pretraining, and backpropagation. Such a methodology exploits information redundancy commonly found in biomedical image applications. This study presents methods to learn dilated-separable convolutional kernels and multi-dilation layers without backpropagation for FLIM networks. It also proposes a novel network simplification method to reduce kernel redundancy and encoder size. By combining a FLIM encoder with an adaptive decoder, a concept recently introduced to estimate a pointwise convolution per image, this study presents very efficient (named flyweight) SOD models for biomedical images. Experimental results in challenging datasets demonstrate superior efficiency and effectiveness to lightweight models. By requiring significantly fewer parameters and floating-point operations, the results show competitive effectiveness to heavyweight models. These advances highlight the potential of FLIM networks for data-limited and resource-constrained applications with information redundancy.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 15.5 -->
                    
                <!-- LLMs: 6.0 -->
                    
                <!-- Quantum Computing: 2.9 -->
                    
                <!-- Networks: 2.4 -->
                    
                <!-- 3D: 2.2 -->
                    
                <!-- RAG: 1.7 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- T2I: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Attention: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.9185
                </span>
                <a href="https://arxiv.org/abs/1908.08652" target="_blank" rel="noopener noreferrer">MTCNET: Multi-task Learning Paradigm for Crowd Count Estimation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Abhay Kumar, Nishant Jain, Suraj Tripathi, Chirag Singh, Kamal Krishna
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We propose a Multi-Task Learning (MTL) paradigm based deep neural network architecture, called MTCNet (Multi-Task Crowd Network) for crowd density and count estimation. Crowd count estimation is challenging due to the non-uniform scale variations and the arbitrary perspective of an individual image.</span>
                
                <span class="abstract-full" style="display: none;">We propose a Multi-Task Learning (MTL) paradigm based deep neural network architecture, called MTCNet (Multi-Task Crowd Network) for crowd density and count estimation. Crowd count estimation is challenging due to the non-uniform scale variations and the arbitrary perspective of an individual image. The proposed model has two related tasks, with Crowd Density Estimation as the main task and Crowd-Count Group Classification as the auxiliary task. The auxiliary task helps in capturing the relevant scale-related information to improve the performance of the main task. The main task model comprises two blocks: VGG-16 front-end for feature extraction and a dilated Convolutional Neural Network for density map generation. The auxiliary task model shares the same front-end as the main task, followed by a CNN classifier. Our proposed network achieves 5.8% and 14.9% lower Mean Absolute Error (MAE) than the state-of-the-art methods on ShanghaiTech dataset without using any data augmentation. Our model also outperforms with 10.5% lower MAE on UCF_CC_50 dataset.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 14.4 -->
                    
                <!-- Quantum Computing: 2.6 -->
                    
                <!-- LLMs: 2.6 -->
                    
                <!-- Networks: 2.6 -->
                    
                <!-- Reinforcement Learning: 2.1 -->
                    
                <!-- Robotics: 1.8 -->
                    
                <!-- Federated Learning: 1.6 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Math: 1.1 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.0005
                </span>
                <a href="https://arxiv.org/abs/2504.11433" target="_blank" rel="noopener noreferrer">Predicting Wave Dynamics using Deep Learning with Multistep Integration Inspired Attention and Physics-Based Loss Decomposition</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Indu Kant Deo, Rajeev K. Jaiman
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In this paper, we present a physics-based deep learning framework for data-driven prediction of wave propagation in fluid media. The proposed approach, termed Multistep Integration-Inspired Attention (MI2A), combines a denoising-based convolutional autoencoder for reduced latent representation with </span>
                
                <span class="abstract-full" style="display: none;">In this paper, we present a physics-based deep learning framework for data-driven prediction of wave propagation in fluid media. The proposed approach, termed Multistep Integration-Inspired Attention (MI2A), combines a denoising-based convolutional autoencoder for reduced latent representation with an attention-based recurrent neural network with long-short-term memory cells for time evolution of reduced coordinates. This proposed architecture draws inspiration from classical linear multistep methods to enhance stability and long-horizon accuracy in latent-time integration. Despite the efficiency of hybrid neural architectures in modeling wave dynamics, autoregressive predictions are often prone to accumulating phase and amplitude errors over time. To mitigate this issue within the MI2A framework, we introduce a novel loss decomposition strategy that explicitly separates the training loss function into distinct phase and amplitude components. We assess the performance of MI2A against two baseline reduced-order models trained with standard mean-squared error loss: a sequence-to-sequence recurrent neural network and a variant using Luong-style attention. To demonstrate the effectiveness of the MI2A model, we consider three benchmark wave propagation problems of increasing complexity, namely one-dimensional linear convection, the nonlinear viscous Burgers equation, and the two-dimensional Saint-Venant shallow water system. Our results demonstrate that the MI2A framework significantly improves the accuracy and stability of long-term predictions, accurately preserving wave amplitude and phase characteristics. Compared to the standard long-short term memory and attention-based models, MI2A-based deep learning exhibits superior generalization and temporal accuracy, making it a promising tool for real-time wave modeling.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 13.3 -->
                    
                <!-- LLMs: 4.1 -->
                    
                <!-- Reinforcement Learning: 3.1 -->
                    
                <!-- Quantum Computing: 2.3 -->
                    
                <!-- Networks: 1.4 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                <!-- Math: 1.1 -->
                    
                <!-- 3D: 1.1 -->
                    
                <!-- GNN: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.0064
                </span>
                <a href="https://arxiv.org/abs/2308.09013" target="_blank" rel="noopener noreferrer">Deep-seeded Clustering for Emotion Recognition from Wearable Physiological Sensors</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Marta A. Concei\c{c}\~ao, Antoine Dubois, Sonja Haustein, Bruno Miranda, Carlos Lima Azevedo
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">According to the circumplex model of affect, an emotional response could characterized by a level of pleasure (valence) and intensity (arousal). As it reflects on the autonomic nervous system (ANS) activity, modern wearable wristbands can record non-invasively and during our everyday lives periphera</span>
                
                <span class="abstract-full" style="display: none;">According to the circumplex model of affect, an emotional response could characterized by a level of pleasure (valence) and intensity (arousal). As it reflects on the autonomic nervous system (ANS) activity, modern wearable wristbands can record non-invasively and during our everyday lives peripheral end-points of this response. While emotion recognition from physiological signals is usually achieved using supervised machine learning algorithms that require ground truth labels for training, collecting it is cumbersome and particularly unfeasible in naturalistic settings, and extracting meaningful insights from these signals requires domain knowledge and might be prone to bias. Here, we propose and test a deep-seeded clustering algorithm that automatically extracts and classifies features from those physiological signals with minimal supervision - combining an autoencoder (AE) for unsupervised feature representation and c-means clustering for fine-grained classification. We also show that the model obtains good performance results across three different datasets frequently used in affective computing studies (accuracies of 80.7% on WESAD, 64.2% on Stress-Predict and 61.0% on CEAP360-VR).</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 14.7 -->
                    
                <!-- LLMs: 7.2 -->
                    
                <!-- Quantum Computing: 4.0 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- RAG: 1.2 -->
                    
                <!-- Networks: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Math: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.2536
                </span>
                <a href="https://arxiv.org/abs/2504.04982" target="_blank" rel="noopener noreferrer">Transforming Future Data Center Operations and Management via Physical AI</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zhiwei Cao, Minghao Li, Feng Lin, Jimin Jia, Yonggang Wen, Jianxiong Yin, Simon See
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Data centers (DCs) as mission-critical infrastructures are pivotal in powering the growth of artificial intelligence (AI) and the digital economy. The evolution from Internet DC to AI DC has introduced new challenges in operating and managing data centers for improved business resilience and reduced</span>
                
                <span class="abstract-full" style="display: none;">Data centers (DCs) as mission-critical infrastructures are pivotal in powering the growth of artificial intelligence (AI) and the digital economy. The evolution from Internet DC to AI DC has introduced new challenges in operating and managing data centers for improved business resilience and reduced total cost of ownership. As a result, new paradigms, beyond the traditional approaches based on best practices, must be in order for future data centers. In this research, we propose and develop a novel Physical AI (PhyAI) framework for advancing DC operations and management. Our system leverages the emerging capabilities of state-of-the-art industrial products and our in-house research and development. Specifically, it presents three core modules, namely: 1) an industry-grade in-house simulation engine to simulate DC operations in a highly accurate manner, 2) an AI engine built upon NVIDIA PhysicsNemo for the training and evaluation of physics-informed machine learning (PIML) models, and 3) a digital twin platform built upon NVIDIA Omniverse for our proposed 5-tier digital twin framework. This system presents a scalable and adaptable solution to digitalize, optimize, and automate future data center operations and management, by enabling real-time digital twins for future data centers. To illustrate its effectiveness, we present a compelling case study on building a surrogate model for predicting the thermal and airflow profiles of a large-scale DC in a real-time manner. Our results demonstrate its superior performance over traditional time-consuming Computational Fluid Dynamics/Heat Transfer (CFD/HT) simulation, with a median absolute temperature prediction error of 0.18 {\deg}C. This emerging approach would open doors to several potential research directions for advancing Physical AI in future DC operations.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 14.2 -->
                    
                <!-- LLMs: 4.8 -->
                    
                <!-- Networks: 2.1 -->
                    
                <!-- Quantum Computing: 2.0 -->
                    
                <!-- Robotics: 1.8 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- T2I: 1.1 -->
                    
                <!-- RAG: 1.1 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.3698
                </span>
                <a href="https://arxiv.org/abs/2403.09850" target="_blank" rel="noopener noreferrer">MARVIS: Motion & Geometry Aware Real and Virtual Image Segmentation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jiayi Wu, Xiaomin Lin, Shahriar Negahdaripour, Cornelia Ferm\"uller, Yiannis Aloimonos
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Tasks such as autonomous navigation, 3D reconstruction, and object recognition near the water surfaces are crucial in marine robotics applications. However, challenges arise due to dynamic disturbances, e.g., light reflections and refraction from the random air-water interface, irregular liquid flow</span>
                
                <span class="abstract-full" style="display: none;">Tasks such as autonomous navigation, 3D reconstruction, and object recognition near the water surfaces are crucial in marine robotics applications. However, challenges arise due to dynamic disturbances, e.g., light reflections and refraction from the random air-water interface, irregular liquid flow, and similar factors, which can lead to potential failures in perception and navigation systems. Traditional computer vision algorithms struggle to differentiate between real and virtual image regions, significantly complicating tasks. A virtual image region is an apparent representation formed by the redirection of light rays, typically through reflection or refraction, creating the illusion of an object's presence without its actual physical location. This work proposes a novel approach for segmentation on real and virtual image regions, exploiting synthetic images combined with domain-invariant information, a Motion Entropy Kernel, and Epipolar Geometric Consistency. Our segmentation network does not need to be re-trained if the domain changes. We show this by deploying the same segmentation network in two different domains: simulation and the real world. By creating realistic synthetic images that mimic the complexities of the water surface, we provide fine-grained training data for our network (MARVIS) to discern between real and virtual images effectively. By motion & geometry-aware design choices and through comprehensive experimental analysis, we achieve state-of-the-art real-virtual image segmentation performance in unseen real world domain, achieving an IoU over 78% and a F1-Score over 86% while ensuring a small computational footprint. MARVIS offers over 43 FPS (8 FPS) inference rates on a single GPU (CPU core). Our code and dataset are available here https://github.com/jiayi-wu-umd/MARVIS.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 11.7 -->
                    
                <!-- LLMs: 4.7 -->
                    
                <!-- Quantum Computing: 2.1 -->
                    
                <!-- Robotics: 1.9 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Networks: 1.3 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.6376
                </span>
                <a href="https://arxiv.org/abs/2410.20502" target="_blank" rel="noopener noreferrer">ARLON: Boosting Diffusion Transformers with Autoregressive Models for Long Video Generation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zongyi Li, Shujie Hu, Shujie Liu, Long Zhou, Jeongsoo Choi, Lingwei Meng, Xun Guo, Jinyu Li, Hefei Ling, Furu Wei
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Text-to-video models have recently undergone rapid and substantial advancements. Nevertheless, due to limitations in data and computational resources, achieving efficient generation of long videos with rich motion dynamics remains a significant challenge. To generate high-quality, dynamic, and tempo</span>
                
                <span class="abstract-full" style="display: none;">Text-to-video models have recently undergone rapid and substantial advancements. Nevertheless, due to limitations in data and computational resources, achieving efficient generation of long videos with rich motion dynamics remains a significant challenge. To generate high-quality, dynamic, and temporally consistent long videos, this paper presents ARLON, a novel framework that boosts diffusion Transformers with autoregressive models for long video generation, by integrating the coarse spatial and long-range temporal information provided by the AR model to guide the DiT model. Specifically, ARLON incorporates several key innovations: 1) A latent Vector Quantized Variational Autoencoder (VQ-VAE) compresses the input latent space of the DiT model into compact visual tokens, bridging the AR and DiT models and balancing the learning complexity and information density; 2) An adaptive norm-based semantic injection module integrates the coarse discrete visual units from the AR model into the DiT model, ensuring effective guidance during video generation; 3) To enhance the tolerance capability of noise introduced from the AR inference, the DiT model is trained with coarser visual latent tokens incorporated with an uncertainty sampling module. Experimental results demonstrate that ARLON significantly outperforms the baseline OpenSora-V1.2 on eight out of eleven metrics selected from VBench, with notable improvements in dynamic degree and aesthetic quality, while delivering competitive results on the remaining three and simultaneously accelerating the generation process. In addition, ARLON achieves state-of-the-art performance in long video generation. Detailed analyses of the improvements in inference efficiency are presented, alongside a practical application that demonstrates the generation of long videos using progressive text prompts. See demos of ARLON at http://aka.ms/arlon.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 13.9 -->
                    
                <!-- LLMs: 4.7 -->
                    
                <!-- Reinforcement Learning: 2.9 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Math: 1.7 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- Networks: 1.3 -->
                    
                <!-- Pathfinding: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.6563
                </span>
                <a href="https://arxiv.org/abs/2410.19115" target="_blank" rel="noopener noreferrer">MoGe: Unlocking Accurate Monocular Geometry Estimation for Open-Domain Images with Optimal Training Supervision</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ruicheng Wang, Sicheng Xu, Cassie Dai, Jianfeng Xiang, Yu Deng, Xin Tong, Jiaolong Yang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We present MoGe, a powerful model for recovering 3D geometry from monocular open-domain images. Given a single image, our model directly predicts a 3D point map of the captured scene with an affine-invariant representation, which is agnostic to true global scale and shift. This new representation pr</span>
                
                <span class="abstract-full" style="display: none;">We present MoGe, a powerful model for recovering 3D geometry from monocular open-domain images. Given a single image, our model directly predicts a 3D point map of the captured scene with an affine-invariant representation, which is agnostic to true global scale and shift. This new representation precludes ambiguous supervision in training and facilitate effective geometry learning. Furthermore, we propose a set of novel global and local geometry supervisions that empower the model to learn high-quality geometry. These include a robust, optimal, and efficient point cloud alignment solver for accurate global shape learning, and a multi-scale local geometry loss promoting precise local geometry supervision. We train our model on a large, mixed dataset and demonstrate its strong generalizability and high accuracy. In our comprehensive evaluation on diverse unseen datasets, our model significantly outperforms state-of-the-art methods across all tasks, including monocular estimation of 3D point map, depth map, and camera field of view. Code and models can be found on our project page.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 15.5 -->
                    
                <!-- LLMs: 5.7 -->
                    
                <!-- 3D: 4.1 -->
                    
                <!-- Quantum Computing: 2.2 -->
                    
                <!-- T2I: 1.6 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- Networks: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.8053
                </span>
                <a href="https://arxiv.org/abs/2504.08670" target="_blank" rel="noopener noreferrer">Designing Child-Friendly AI Interfaces: Six Developmentally-Appropriate Design Insights from Analysing Disney Animation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Nomisha Kurian
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">To build AI interfaces that children can intuitively understand and use, designers need a design grammar that truly serves children's developmental needs. This paper bridges Artificial Intelligence design for children -- an emerging field still defining its best practices -- and children's animation</span>
                
                <span class="abstract-full" style="display: none;">To build AI interfaces that children can intuitively understand and use, designers need a design grammar that truly serves children's developmental needs. This paper bridges Artificial Intelligence design for children -- an emerging field still defining its best practices -- and children's animation, a well-established field with decades of experience in engaging young viewers through emotionally resonant, cognitively accessible storytelling. Pairing Piagetian developmental theory with design pattern extraction from 52 works of Disney animation, the paper presents six design insights transferable to child-centred AI interface design: (1) emotional expressiveness and visual clarity, (2) musical and auditory scaffolding, (3) audiovisual synchrony for emotional comfort, (4) sidekick-style personas, (5) support for symbolic play and imaginative exploration, and (6) predictable and scaffolded interaction structures. These strategies -- long refined in Disney animation -- function as multimodal scaffolds for attention, understanding, and emotional attunement, thereby forming a structured design grammar familiar to children and transferable to AI interface design. By reframing cinematic storytelling as design logic for AI, the paper offers heuristics for crafting intuitive AI interfaces that align with children's cognitive stages and emotional needs. The work contributes to design theory by showing how sensory, affective and narrative techniques can inform developmentally attuned AI design for children. Future directions include empirical testing, cultural adaptation, and participatory co-design.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 14.4 -->
                    
                <!-- LLMs: 8.1 -->
                    
                <!-- Quantum Computing: 3.3 -->
                    
                <!-- 3D: 1.9 -->
                    
                <!-- Networks: 1.8 -->
                    
                <!-- Robotics: 1.8 -->
                    
                <!-- RAG: 1.6 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- T2I: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -5.2232
                </span>
                <a href="https://arxiv.org/abs/2504.11008" target="_blank" rel="noopener noreferrer">MediSee: Reasoning-based Pixel-level Perception in Medical Images</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Qinyue Tong, Ziqian Lu, Jun Liu, Yangming Zheng, Zheming Lu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Despite remarkable advancements in pixel-level medical image perception, existing methods are either limited to specific tasks or heavily rely on accurate bounding boxes or text labels as input prompts. However, the medical knowledge required for input is a huge obstacle for general public, which gr</span>
                
                <span class="abstract-full" style="display: none;">Despite remarkable advancements in pixel-level medical image perception, existing methods are either limited to specific tasks or heavily rely on accurate bounding boxes or text labels as input prompts. However, the medical knowledge required for input is a huge obstacle for general public, which greatly reduces the universality of these methods. Compared with these domain-specialized auxiliary information, general users tend to rely on oral queries that require logical reasoning. In this paper, we introduce a novel medical vision task: Medical Reasoning Segmentation and Detection (MedSD), which aims to comprehend implicit queries about medical images and generate the corresponding segmentation mask and bounding box for the target object. To accomplish this task, we first introduce a Multi-perspective, Logic-driven Medical Reasoning Segmentation and Detection (MLMR-SD) dataset, which encompasses a substantial collection of medical entity targets along with their corresponding reasoning. Furthermore, we propose MediSee, an effective baseline model designed for medical reasoning segmentation and detection. The experimental results indicate that the proposed method can effectively address MedSD with implicit colloquial queries and outperform traditional medical referring segmentation methods.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 20.9 -->
                    
                <!-- LLMs: 5.8 -->
                    
                <!-- Quantum Computing: 2.4 -->
                    
                <!-- Reinforcement Learning: 1.9 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Networks: 1.5 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- T2I: 1.3 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- RAG: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -5.2235
                </span>
                <a href="https://arxiv.org/abs/2412.11045" target="_blank" rel="noopener noreferrer">Facial Surgery Preview Based on the Orthognathic Treatment Prediction</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Huijun Han, Congyi Zhang, Lifeng Zhu, Pradeep Singh, Richard Tai Chiu Hsung, Yiu Yan Leung, Taku Komura, Wenping Wang, Min Gu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Orthognathic surgery consultation is essential to help patients understand the changes to their facial appearance after surgery. However, current visualization methods are often inefficient and inaccurate due to limited pre- and post-treatment data and the complexity of the treatment. To overcome th</span>
                
                <span class="abstract-full" style="display: none;">Orthognathic surgery consultation is essential to help patients understand the changes to their facial appearance after surgery. However, current visualization methods are often inefficient and inaccurate due to limited pre- and post-treatment data and the complexity of the treatment. To overcome these challenges, this study aims to develop a fully automated pipeline that generates accurate and efficient 3D previews of postsurgical facial appearances for patients with orthognathic treatment without requiring additional medical images. The study introduces novel aesthetic losses, such as mouth-convexity and asymmetry losses, to improve the accuracy of facial surgery prediction. Additionally, it proposes a specialized parametric model for 3D reconstruction of the patient, medical-related losses to guide latent code prediction network optimization, and a data augmentation scheme to address insufficient data. The study additionally employs FLAME, a parametric model, to enhance the quality of facial appearance previews by extracting facial latent codes and establishing dense correspondences between pre- and post-surgery geometries. Quantitative comparisons showed the algorithm's effectiveness, and qualitative results highlighted accurate facial contour and detail predictions. A user study confirmed that doctors and the public could not distinguish between machine learning predictions and actual postoperative results. This study aims to offer a practical, effective solution for orthognathic surgery consultations, benefiting doctors and patients.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 13.9 -->
                    
                <!-- LLMs: 4.9 -->
                    
                <!-- Networks: 2.1 -->
                    
                <!-- Quantum Computing: 2.0 -->
                    
                <!-- Reinforcement Learning: 1.8 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -5.3715
                </span>
                <a href="https://arxiv.org/abs/2504.11379" target="_blank" rel="noopener noreferrer">Omni$^2$: Unifying Omnidirectional Image Generation and Editing in an Omni Model</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Liu Yang, Huiyu Duan, Yucheng Zhu, Xiaohong Liu, Lu Liu, Zitong Xu, Guangji Ma, Xiongkuo Min, Guangtao Zhai, Patrick Le Callet
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">$360^{\circ}$ omnidirectional images (ODIs) have gained considerable attention recently, and are widely used in various virtual reality (VR) and augmented reality (AR) applications. However, capturing such images is expensive and requires specialized equipment, making ODI synthesis increasingly impo</span>
                
                <span class="abstract-full" style="display: none;">$360^{\circ}$ omnidirectional images (ODIs) have gained considerable attention recently, and are widely used in various virtual reality (VR) and augmented reality (AR) applications. However, capturing such images is expensive and requires specialized equipment, making ODI synthesis increasingly important. While common 2D image generation and editing methods are rapidly advancing, these models struggle to deliver satisfactory results when generating or editing ODIs due to the unique format and broad 360$^{\circ}$ Field-of-View (FoV) of ODIs. To bridge this gap, we construct \textbf{\textit{Any2Omni}}, the first comprehensive ODI generation-editing dataset comprises 60,000+ training data covering diverse input conditions and up to 9 ODI generation and editing tasks. Built upon Any2Omni, we propose an \textbf{\underline{Omni}} model for \textbf{\underline{Omni}}-directional image generation and editing (\textbf{\textit{Omni$^2$}}), with the capability of handling various ODI generation and editing tasks under diverse input conditions using one model. Extensive experiments demonstrate the superiority and effectiveness of the proposed Omni$^2$ model for both the ODI generation and editing tasks.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 15.7 -->
                    
                <!-- LLMs: 11.1 -->
                    
                <!-- T2I: 2.2 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- RAG: 1.9 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -5.4759
                </span>
                <a href="https://arxiv.org/abs/2504.10750" target="_blank" rel="noopener noreferrer">Real-time Seafloor Segmentation and Mapping</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Michele Grimaldi, Nouf Alkaabi, Francesco Ruscio, Sebastian Realpe Rua, Rafael Garcia, Nuno Gracias
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Posidonia oceanica meadows are a species of seagrass highly dependent on rocks for their survival and conservation. In recent years, there has been a concerning global decline in this species, emphasizing the critical need for efficient monitoring and assessment tools. While deep learning-based sema</span>
                
                <span class="abstract-full" style="display: none;">Posidonia oceanica meadows are a species of seagrass highly dependent on rocks for their survival and conservation. In recent years, there has been a concerning global decline in this species, emphasizing the critical need for efficient monitoring and assessment tools. While deep learning-based semantic segmentation and visual automated monitoring systems have shown promise in a variety of applications, their performance in underwater environments remains challenging due to complex water conditions and limited datasets. This paper introduces a framework that combines machine learning and computer vision techniques to enable an autonomous underwater vehicle (AUV) to inspect the boundaries of Posidonia oceanica meadows autonomously. The framework incorporates an image segmentation module using an existing Mask R-CNN model and a strategy for Posidonia oceanica meadow boundary tracking. Furthermore, a new class dedicated to rocks is introduced to enhance the existing model, aiming to contribute to a comprehensive monitoring approach and provide a deeper understanding of the intricate interactions between the meadow and its surrounding environment. The image segmentation model is validated using real underwater images, while the overall inspection framework is evaluated in a realistic simulation environment, replicating actual monitoring scenarios with real underwater images. The results demonstrate that the proposed framework enables the AUV to autonomously accomplish the main tasks of underwater inspection and segmentation of rocks. Consequently, this work holds significant potential for the conservation and protection of marine environments, providing valuable insights into the status of Posidonia oceanica meadows and supporting targeted preservation efforts</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 11.0 -->
                    
                <!-- LLMs: 4.0 -->
                    
                <!-- Reinforcement Learning: 2.4 -->
                    
                <!-- Robotics: 2.4 -->
                    
                <!-- Networks: 1.9 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -5.8666
                </span>
                <a href="https://arxiv.org/abs/2504.11262" target="_blank" rel="noopener noreferrer">Enhanced Small Target Detection via Multi-Modal Fusion and Attention Mechanisms: A YOLOv5 Approach</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Xiaoxiao Ma, Junxiong Tong
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">With the rapid development of information technology, modern warfare increasingly relies on intelligence, making small target detection critical in military applications. The growing demand for efficient, real-time detection has created challenges in identifying small targets in complex environments</span>
                
                <span class="abstract-full" style="display: none;">With the rapid development of information technology, modern warfare increasingly relies on intelligence, making small target detection critical in military applications. The growing demand for efficient, real-time detection has created challenges in identifying small targets in complex environments due to interference. To address this, we propose a small target detection method based on multi-modal image fusion and attention mechanisms. This method leverages YOLOv5, integrating infrared and visible light data along with a convolutional attention module to enhance detection performance. The process begins with multi-modal dataset registration using feature point matching, ensuring accurate network training. By combining infrared and visible light features with attention mechanisms, the model improves detection accuracy and robustness. Experimental results on anti-UAV and Visdrone datasets demonstrate the effectiveness and practicality of our approach, achieving superior detection results for small and dim targets.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 23.5 -->
                    
                <!-- LLMs: 6.7 -->
                    
                <!-- 3D: 2.4 -->
                    
                <!-- Quantum Computing: 2.2 -->
                    
                <!-- T2I: 1.6 -->
                    
                <!-- Networks: 1.6 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- RAG: 1.5 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Attention: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -5.9074
                </span>
                <a href="https://arxiv.org/abs/2504.05408" target="_blank" rel="noopener noreferrer">Frontier AI's Impact on the Cybersecurity Landscape</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Wenbo Guo, Yujin Potter, Tianneng Shi, Zhun Wang, Andy Zhang, Dawn Song
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">As frontier AI advances rapidly, understanding its impact on cybersecurity and inherent risks is essential to ensuring safe AI evolution (e.g., guiding risk mitigation and informing policymakers). While some studies review AI applications in cybersecurity, none of them comprehensively discuss AI's f</span>
                
                <span class="abstract-full" style="display: none;">As frontier AI advances rapidly, understanding its impact on cybersecurity and inherent risks is essential to ensuring safe AI evolution (e.g., guiding risk mitigation and informing policymakers). While some studies review AI applications in cybersecurity, none of them comprehensively discuss AI's future impacts or provide concrete recommendations for navigating its safe and secure usage. This paper presents an in-depth analysis of frontier AI's impact on cybersecurity and establishes a systematic framework for risk assessment and mitigation. To this end, we first define and categorize the marginal risks of frontier AI in cybersecurity and then systemically analyze the current and future impacts of frontier AI in cybersecurity, qualitatively and quantitatively. We also discuss why frontier AI likely benefits attackers more than defenders in the short term from equivalence classes, asymmetry, and economic impact. Next, we explore frontier AI's impact on future software system development, including enabling complex hybrid systems while introducing new risks. Based on our findings, we provide security recommendations, including constructing fine-grained benchmarks for risk assessment, designing AI agents for defenses, building security mechanisms and provable defenses for hybrid systems, enhancing pre-deployment security testing and transparency, and strengthening defenses for users. Finally, we present long-term research questions essential for understanding AI's future impacts and unleashing its defensive capabilities.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 17.7 -->
                    
                <!-- LLMs: 8.5 -->
                    
                <!-- Quantum Computing: 2.5 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- RAG: 1.7 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- T2I: 1.5 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -6.2778
                </span>
                <a href="https://arxiv.org/abs/2504.10901" target="_blank" rel="noopener noreferrer">Design and Verification of a Synchronus First In First Out (FIFO)</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yatheeswar Penta, Riadul Islam
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This project focuses on designing and verifying a synchronous FIFO First In First Out (FIFO) memory, a critical component in digital systems for temporary data storage and seamless data transfer. The FIFO operates under a single clock domain, ensuring synchronized read and write operations, making i</span>
                
                <span class="abstract-full" style="display: none;">This project focuses on designing and verifying a synchronous FIFO First In First Out (FIFO) memory, a critical component in digital systems for temporary data storage and seamless data transfer. The FIFO operates under a single clock domain, ensuring synchronized read and write operations, making it suitable for systems requiring high-speed, reliable data buffering. This design includes FIFO's key features, such as read and write operations, full and empty flag generation, and pointer management for memory control. The FIFO was implemented using Verilog to define the Register Transfer Level (RTL) design, ensuring functionality and timing requirements were met. For verification, three approaches were employed: (1) UVM-based Verification: A Universal Verification Methodology (UVM) testbench was developed to test the FIFO design rigorously. The testbench includes components like interface, sequence item, driver, monitor, scoreboard, agent, and environment. Directed and random tests were performed to verify corner cases, such as simultaneous reads and writes, full and empty conditions, and overflow and underflow scenarios; (2) Traditional Verilog Testbench: A standalone Verilog testbench was also used to validate the functionality of the FIFO through directed test scenarios and waveform analysis; (3) FPGA implementation: Additionally, the design was implemented on an FPGA for real-time testing to verify its functionality and timing behavior in hardware. FPGA-based verification ensured the design performed as expected under practical conditions. The results confirmed the correct operation of the FIFO, including accurate data transfer, flag behavior, and timing synchronization. The project successfully demonstrated the robustness and reliability of the synchronous FIFO design, highlighting its importance in modern digital systems for efficient data handling and buffering.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 18.8 -->
                    
                <!-- LLMs: 4.1 -->
                    
                <!-- Robotics: 2.1 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Networks: 1.6 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- 3D: 1.1 -->
                    
                <!-- RAG: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -6.5987
                </span>
                <a href="https://arxiv.org/abs/2504.11318" target="_blank" rel="noopener noreferrer">Mildly-Interacting Fermionic Unitaries are Efficiently Learnable</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Vishnu Iyer
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Recent work has shown that one can efficiently learn fermionic Gaussian unitaries, also commonly known as nearest-neighbor matchcircuits or non-interacting fermionic unitaries. However, one could ask a similar question about unitaries that are near Gaussian: for example, unitaries prepared with a sm</span>
                
                <span class="abstract-full" style="display: none;">Recent work has shown that one can efficiently learn fermionic Gaussian unitaries, also commonly known as nearest-neighbor matchcircuits or non-interacting fermionic unitaries. However, one could ask a similar question about unitaries that are near Gaussian: for example, unitaries prepared with a small number of non-Gaussian circuit elements. These operators find significance in quantum chemistry and many-body physics, yet no algorithm exists to learn them.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Quantum Computing: 11.5 -->
                    
                <!-- LLMs: 9.0 -->
                    
                <!-- Medicine: 4.5 -->
                    
                <!-- GNN: 2.5 -->
                    
                <!-- Networks: 2.3 -->
                    
                <!-- 3D: 2.0 -->
                    
                <!-- RAG: 1.9 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Math: 1.5 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- T2I: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- Attention: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -6.9548
                </span>
                <a href="https://arxiv.org/abs/2504.10776" target="_blank" rel="noopener noreferrer">Rainy: Unlocking Satellite Calibration for Deep Learning in Precipitation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zhenyu Yu, Hanqing Chen, Mohd Yamani Idna Idris, Pei Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Precipitation plays a critical role in the Earth's hydrological cycle, directly affecting ecosystems, agriculture, and water resource management. Accurate precipitation estimation and prediction are crucial for understanding climate dynamics, disaster preparedness, and environmental monitoring. In r</span>
                
                <span class="abstract-full" style="display: none;">Precipitation plays a critical role in the Earth's hydrological cycle, directly affecting ecosystems, agriculture, and water resource management. Accurate precipitation estimation and prediction are crucial for understanding climate dynamics, disaster preparedness, and environmental monitoring. In recent years, artificial intelligence (AI) has gained increasing attention in quantitative remote sensing (QRS), enabling more advanced data analysis and improving precipitation estimation accuracy. Although traditional methods have been widely used for precipitation estimation, they face limitations due to the difficulty of data acquisition and the challenge of capturing complex feature relationships. Furthermore, the lack of standardized multi-source satellite datasets, and in most cases, the exclusive reliance on station data, significantly hinders the effective application of advanced AI models. To address these challenges, we propose the Rainy dataset, a multi-source spatio-temporal dataset that integrates pure satellite data with station data, and propose Taper Loss, designed to fill the gap in tasks where only in-situ data is available without area-wide support. The Rainy dataset supports five main tasks: (1) satellite calibration, (2) precipitation event prediction, (3) precipitation level prediction, (4) spatiotemporal prediction, and (5) precipitation downscaling. For each task, we selected benchmark models and evaluation metrics to provide valuable references for researchers. Using precipitation as an example, the Rainy dataset and Taper Loss demonstrate the seamless collaboration between QRS and computer vision, offering data support for AI for Science in the field of QRS and providing valuable insights for interdisciplinary collaboration and integration.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 18.5 -->
                    
                <!-- LLMs: 6.1 -->
                    
                <!-- Quantum Computing: 2.2 -->
                    
                <!-- Robotics: 1.8 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                <!-- Networks: 1.1 -->
                    
                <!-- RAG: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -8.3508
                </span>
                <a href="https://arxiv.org/abs/2504.10679" target="_blank" rel="noopener noreferrer">Keyword Extraction, and Aspect Classification in Sinhala, English, and Code-Mixed Content</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: F. A. Rizvi, T. Navojith, A. M. N. H. Adhikari, W. P. U. Senevirathna, Dharshana Kasthurirathna, Lakmini Abeywardhana
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Brand reputation in the banking sector is maintained through insightful analysis of customer opinion on code-mixed and multilingual content. Conventional NLP models misclassify or ignore code-mixed text, when mix with low resource languages such as Sinhala-English and fail to capture domain-specific</span>
                
                <span class="abstract-full" style="display: none;">Brand reputation in the banking sector is maintained through insightful analysis of customer opinion on code-mixed and multilingual content. Conventional NLP models misclassify or ignore code-mixed text, when mix with low resource languages such as Sinhala-English and fail to capture domain-specific knowledge. This study introduces a hybrid NLP method to improve keyword extraction, content filtering, and aspect-based classification of banking content. Keyword extraction in English is performed with a hybrid approach comprising a fine-tuned SpaCy NER model, FinBERT-based KeyBERT embeddings, YAKE, and EmbedRank, which results in a combined accuracy of 91.2%. Code-mixed and Sinhala keywords are extracted using a fine-tuned XLM-RoBERTa model integrated with a domain-specific Sinhala financial vocabulary, and it results in an accuracy of 87.4%. To ensure data quality, irrelevant comment filtering was performed using several models, with the BERT-base-uncased model achieving 85.2% for English and XLM-RoBERTa 88.1% for Sinhala, which was better than GPT-4o, SVM, and keyword-based filtering. Aspect classification followed the same pattern, with the BERT-base-uncased model achieving 87.4% for English and XLM-RoBERTa 85.9% for Sinhala, both exceeding GPT-4 and keyword-based approaches. These findings confirm that fine-tuned transformer models outperform traditional methods in multilingual financial text analysis. The present framework offers an accurate and scalable solution for brand reputation monitoring in code-mixed and low-resource banking environments.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 25.1 -->
                    
                <!-- LLMs: 6.2 -->
                    
                <!-- Robotics: 1.8 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Networks: 1.7 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- T2I: 1.3 -->
                    
                <!-- RAG: 1.1 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -8.4799
                </span>
                <a href="https://arxiv.org/abs/2504.11444" target="_blank" rel="noopener noreferrer">Fault Tolerant Quantum Simulation via Symplectic Transvections</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zhuangzhuang Chen, Jack Owen Weinberg, Narayanan Rengaswamy
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Conventional approaches to fault-tolerant quantum computing realize logical circuits gate-by-gate, synthesizing each gate independently on one or more code blocks. This incurs excess overhead and doesn't leverage common structures in quantum algorithms. In contrast, we propose a framework that enabl</span>
                
                <span class="abstract-full" style="display: none;">Conventional approaches to fault-tolerant quantum computing realize logical circuits gate-by-gate, synthesizing each gate independently on one or more code blocks. This incurs excess overhead and doesn't leverage common structures in quantum algorithms. In contrast, we propose a framework that enables the execution of entire logical circuit blocks at once, preserving their global structure. This whole-block approach allows for the direct implementation of logical Trotter circuits - of arbitrary rotation angles - on any stabilizer code, providing a powerful new method for fault tolerant Hamiltonian simulation within a single code block. At the heart of our approach lies a deep structural correspondence between symplectic transvections and Trotter circuits. This connection enables both logical and physical circuits to share the Trotter structure while preserving stabilizer centralization and circuit symmetry even in the presence of non-Clifford rotations. We discuss potential approaches to fault tolerance via biased noise and code concatenation. While we illustrate the key principles using a $[[8,3,3]]$ code, our simulations show that the framework applies to Hamiltonian simulation on even good quantum LDPC codes. These results open the door to new algorithm-tailored, block-level strategies for fault tolerant circuit design, especially in quantum simulation.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Quantum Computing: 11.7 -->
                    
                <!-- LLMs: 6.2 -->
                    
                <!-- Medicine: 3.3 -->
                    
                <!-- Reinforcement Learning: 2.5 -->
                    
                <!-- Networks: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- 3D: 1.1 -->
                    
                <!-- Math: 1.1 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -9.2555
                </span>
                <a href="https://arxiv.org/abs/2406.19120" target="_blank" rel="noopener noreferrer">QOS: A Quantum Operating System</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Emmanouil Giortamis, Francisco Rom\~ao, Nathaniel Tornow, Pramod Bhatotia
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Quantum computers face challenges due to hardware constraints, noise errors, and heterogeneity, and face fundamental design tradeoffs between key performance metrics such as \textit{quantum fidelity} and system utilization. This substantially complicates managing quantum resources to scale the size </span>
                
                <span class="abstract-full" style="display: none;">Quantum computers face challenges due to hardware constraints, noise errors, and heterogeneity, and face fundamental design tradeoffs between key performance metrics such as \textit{quantum fidelity} and system utilization. This substantially complicates managing quantum resources to scale the size and number of quantum algorithms that can be executed reliably in a given time.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Quantum Computing: 13.9 -->
                    
                <!-- LLMs: 7.2 -->
                    
                <!-- Medicine: 5.6 -->
                    
                <!-- RAG: 2.1 -->
                    
                <!-- Networks: 1.9 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- 3D: 1.9 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- T2I: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -10.2746
                </span>
                <a href="https://arxiv.org/abs/2504.11213" target="_blank" rel="noopener noreferrer">Characterizing High Schmidt Number Witnesses in Arbitrary Dimensions System</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Liang Xiong, Nung-sing Sze
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">A profound comprehension of quantum entanglement is crucial for the progression of quantum technologies. The degree of entanglement can be assessed by enumerating the entangled degrees of freedom, leading to the determination of a parameter known as the Schmidt number. In this paper, we develop an e</span>
                
                <span class="abstract-full" style="display: none;">A profound comprehension of quantum entanglement is crucial for the progression of quantum technologies. The degree of entanglement can be assessed by enumerating the entangled degrees of freedom, leading to the determination of a parameter known as the Schmidt number. In this paper, we develop an efficient analytical tool for characterizing high Schmidt number witnesses for bipartite quantum states in arbitrary dimensions. Our methods not only offer viable mathematical methods for constructing high-dimensional Schmidt number witnesses in theory but also simplify the quantification of entanglement and dimensionality. Most notably, we develop high-dimensional Schmidt number witnesses within arbitrary-dimensional systems, with our Schmidt witness coefficients relying solely on the operator Schmidt coefficient. Subsequently, we demonstrate our theoretical advancements and computational superiority by constructing Schmidt number witnesses in arbitrary dimensional bipartite quantum systems with Schmidt numbers four and five.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Quantum Computing: 15.4 -->
                    
                <!-- LLMs: 6.5 -->
                    
                <!-- Medicine: 6.4 -->
                    
                <!-- Math: 1.8 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- Networks: 1.1 -->
                    
                <!-- Pathfinding: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -11.4424
                </span>
                <a href="https://arxiv.org/abs/2410.17908" target="_blank" rel="noopener noreferrer">Fully smooth one shot multipartite soft covering of quantum states without pairwise independence</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Pranab Sen
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We provide a powerful machinery to prove fully smooth one shot multipartite covering, aka convex split, type results for quantum states. In the important case of smooth multipartite convex split for classical quantum states, aka smooth multipartite soft covering, our machinery works even when certai</span>
                
                <span class="abstract-full" style="display: none;">We provide a powerful machinery to prove fully smooth one shot multipartite covering, aka convex split, type results for quantum states. In the important case of smooth multipartite convex split for classical quantum states, aka smooth multipartite soft covering, our machinery works even when certain marginals of these states do not satisfy pairwise independence. The recent paper (arXiv:2410.17893) gave the first proof of fully smooth multipartite convex split by simplifying and extending a technique called telescoping, developed originally for convex split by (arXiv:2304.12056). However, that work as well as all earlier works on convex split assumed pairwise or even more independence amongst suitable marginals of the quantum states.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Quantum Computing: 18.6 -->
                    
                <!-- LLMs: 6.5 -->
                    
                <!-- Medicine: 4.1 -->
                    
                <!-- Networks: 1.9 -->
                    
                <!-- Reinforcement Learning: 1.8 -->
                    
                <!-- Math: 1.7 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- 3D: 1.1 -->
                    
                <!-- RAG: 1.1 -->
                    
                <!-- Federated Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -12.2574
                </span>
                <a href="https://arxiv.org/abs/2406.09211" target="_blank" rel="noopener noreferrer">WildlifeReID-10k: Wildlife re-identification dataset with 10k individual animals</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Luk\'a\v{s} Adam, Vojt\v{e}ch \v{C}erm\'ak, Kostas Papafitsoros, Lukas Picek
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper introduces WildlifeReID-10k, a new large-scale re-identification benchmark with more than 10k animal identities of around 33 species across more than 140k images, re-sampled from 37 existing datasets. WildlifeReID-10k covers diverse animal species and poses significant challenges for SoTA</span>
                
                <span class="abstract-full" style="display: none;">This paper introduces WildlifeReID-10k, a new large-scale re-identification benchmark with more than 10k animal identities of around 33 species across more than 140k images, re-sampled from 37 existing datasets. WildlifeReID-10k covers diverse animal species and poses significant challenges for SoTA methods, ensuring fair and robust evaluation through its time-aware and similarity-aware split protocol. The latter is designed to address the common issue of training-to-test data leakage caused by visually similar images appearing in both training and test sets. The WildlifeReID-10k dataset and benchmark are publicly available on Kaggle, along with strong baselines for both closed-set and open-set evaluation, enabling fair, transparent, and standardized evaluation of not just multi-species animal re-identification models.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge high-confidence" style="background-color: #f1cb45" title="Confidence: 77.0%">
                            Datasets
                        </span>
                <!-- Medicine: 10.5 -->
                    
                <!-- LLMs: 8.3 -->
                    
                <!-- Quantum Computing: 2.4 -->
                    
                <!-- RAG: 1.9 -->
                    
                <!-- Networks: 1.7 -->
                    
                <!-- Robotics: 1.7 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- T2I: 1.6 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -15.3908
                </span>
                <a href="https://arxiv.org/abs/2504.11109" target="_blank" rel="noopener noreferrer">Fine-Tuning Large Language Models on Quantum Optimization Problems for Circuit Generation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Linus Jern, Valter Uotila, Cong Yu, Bo Zhao
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Large language models (LLM) have achieved remarkable outcomes in addressing complex problems, including math, coding, and analyzing large amounts of scientific reports. Yet few works have explored the potential of LLM in quantum computing. The most challenging problem is how to leverage LLMs to auto</span>
                
                <span class="abstract-full" style="display: none;">Large language models (LLM) have achieved remarkable outcomes in addressing complex problems, including math, coding, and analyzing large amounts of scientific reports. Yet few works have explored the potential of LLM in quantum computing. The most challenging problem is how to leverage LLMs to automatically generate quantum circuits at a large scale. In this paper, we address such a challenge by fine-tuning LLMs and injecting the domain-specific knowledge of quantum computing. In particular, we investigate the mechanisms to generate training data sets and construct the end-to-end pipeline to fine-tune pre-trained LLMs that produce parameterized quantum circuits for optimization problems. We have prepared 14,000 quantum circuits covering a substantial part of the quantum optimization landscape: 12 optimization problem instances and their optimized QAOA, VQE, and adaptive VQE circuits. The fine-tuned LLMs can construct syntactically correct parametrized quantum circuits in the most recent OpenQASM 3.0. We have evaluated the quality of the parameters by comparing them to the optimized expectation values and distributions. Our evaluation shows that the fine-tuned LLM outperforms state-of-the-art models and that the parameters are better than random. The LLM-generated parametrized circuits and initial parameters can be used as a starting point for further optimization, \emph{e.g.,} templates in quantum machine learning and the benchmark for compilers and hardware.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Quantum Computing: 15.2 -->
                    
                <!-- LLMs: 13.2 -->
                    
                <!-- Medicine: 3.2 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Math: 1.1 -->
                    
                <!-- Networks: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -17.1367
                </span>
                <a href="https://arxiv.org/abs/2504.10972" target="_blank" rel="noopener noreferrer">AFiRe: Anatomy-Driven Self-Supervised Learning for Fine-Grained Representation in Radiographic Images</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yihang Liu, Lianghua He, Ying Wen, Longzhen Yang, Hongzhou Chen
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Current self-supervised methods, such as contrastive learning, predominantly focus on global discrimination, neglecting the critical fine-grained anatomical details required for accurate radiographic analysis. To address this challenge, we propose an Anatomy-driven self-supervised framework for enha</span>
                
                <span class="abstract-full" style="display: none;">Current self-supervised methods, such as contrastive learning, predominantly focus on global discrimination, neglecting the critical fine-grained anatomical details required for accurate radiographic analysis. To address this challenge, we propose an Anatomy-driven self-supervised framework for enhancing Fine-grained Representation in radiographic image analysis (AFiRe). The core idea of AFiRe is to align the anatomical consistency with the unique token-processing characteristics of Vision Transformer. Specifically, AFiRe synergistically performs two self-supervised schemes: (i) Token-wise anatomy-guided contrastive learning, which aligns image tokens based on structural and categorical consistency, thereby enhancing fine-grained spatial-anatomical discrimination; (ii) Pixel-level anomaly-removal restoration, which particularly focuses on local anomalies, thereby refining the learned discrimination with detailed geometrical information. Additionally, we propose Synthetic Lesion Mask to enhance anatomical diversity while preserving intra-consistency, which is typically corrupted by traditional data augmentations, such as Cropping and Affine transformations. Experimental results show that AFiRe: (i) provides robust anatomical discrimination, achieving more cohesive feature clusters compared to state-of-the-art contrastive learning methods; (ii) demonstrates superior generalization, surpassing 7 radiography-specific self-supervised methods in multi-label classification tasks with limited labeling; and (iii) integrates fine-grained information, enabling precise anomaly detection using only image-level annotations.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge high-confidence" style="background-color: #4ff278" title="Confidence: 80.0%">
                            Medicine
                        </span>
                <!-- LLMs: 5.4 -->
                    
                <!-- Quantum Computing: 3.0 -->
                    
                <!-- Networks: 2.1 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- RAG: 1.6 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- T2I: 1.5 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- Math: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -24.4643
                </span>
                <a href="https://arxiv.org/abs/2504.03699" target="_blank" rel="noopener noreferrer">Reinforcing Clinical Decision Support through Multi-Agent Systems and Ethical AI Governance</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ying-Jung Chen, Ahmad Albarqawi, Chi-Sheng Chen
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Recent advances in the data-driven medicine approach, which integrates ethically managed and explainable artificial intelligence into clinical decision support systems (CDSS), are critical to ensure reliable and effective patient care. This paper focuses on comparing novel agent system designs that </span>
                
                <span class="abstract-full" style="display: none;">Recent advances in the data-driven medicine approach, which integrates ethically managed and explainable artificial intelligence into clinical decision support systems (CDSS), are critical to ensure reliable and effective patient care. This paper focuses on comparing novel agent system designs that use modular agents to analyze laboratory results, vital signs, and clinical context, and to predict and validate results. We implement our agent system with the eICU database, including running lab analysis, vitals-only interpreters, and contextual reasoners agents first, then sharing the memory into the integration agent, prediction agent, transparency agent, and a validation agent. Our results suggest that the multi-agent system (MAS) performed better than the single-agent system (SAS) with mortality prediction accuracy (59%, 56%) and the mean error for length of stay (LOS)(4.37 days, 5.82 days), respectively. However, the transparency score for the SAS (86.21) is slightly better than the transparency score for MAS (85.5). Finally, this study suggests that our agent-based framework not only improves process transparency and prediction accuracy but also strengthens trustworthy AI-assisted decision support in an intensive care setting.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge high-confidence" style="background-color: #4ff278" title="Confidence: 81.5%">
                            Medicine
                        </span>
                <!-- LLMs: 4.6 -->
                    
                <!-- Quantum Computing: 2.6 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Networks: 1.5 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Math: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -25.731
                </span>
                <a href="https://arxiv.org/abs/2410.08010" target="_blank" rel="noopener noreferrer">Securing HHL Quantum Algorithm against Quantum Computer Attacks</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yizhuo Tan, Hrvoje Kukina, Jakub Szefer
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">As the quantum research community expands and new quantum algorithms are created and implemented, it is essential to consider the security implications and potential threats that could lead to the compromise the information processed by them. This work focuses on securing the HHL quantum algorithm a</span>
                
                <span class="abstract-full" style="display: none;">As the quantum research community expands and new quantum algorithms are created and implemented, it is essential to consider the security implications and potential threats that could lead to the compromise the information processed by them. This work focuses on securing the HHL quantum algorithm against attacks while it executes on a quantum computer. Specifically, two types of potential attacks could be deployed on a cloud-based quantum computer by an attacker circuit attempting to interfere with the victim HHL circuit: the Improper Initialization Attack (IIA) and the Higher Energy Attack (HEA). To protect the HHL algorithm from IIA and HEA, this work proposes first-of-a-kind defense strategies against these attacks on the HHL quantum algorithm. Next, this work demonstrates an implementation of a new quantum circuit for the HHL quantum algorithm that incorporates these defenses. The redesigned quantum circuit is necessary to successfully apply and realize all proposed defense strategies. Finally, this work illustrates how these defense strategies function in practice in the redesigned circuit, specifically how they can protect the HHL quantum algorithm from both IIA and HEA across multiple qubits involving all three types of qubits used in the HHL algorithms: ancilla, clock, and b. The defense requires minimal modification to the circuit, and has only a very small effect on the fidelity of the circuits. The circuits have been tested and validated in both simulation, and also on real IBM quantum computer hardware. The work further analyzes how the modified HHL circuit with the defenses is affected by noise during quantum computation. This work in the end demonstrates that it is practical to add protections to quantum circuits so that they not only perform correct computation, but also self-detect if an attack has occured during the execution.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Quantum Computing: 32.2 -->
                    
                <!-- Medicine: 2.7 -->
                    
                <!-- Reinforcement Learning: 2.4 -->
                    
                <!-- Math: 2.0 -->
                    
                <!-- LLMs: 1.8 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- Pathfinding: 1.1 -->
                    
                <!-- Networks: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -54.9822
                </span>
                <a href="https://arxiv.org/abs/2504.10542" target="_blank" rel="noopener noreferrer">An Efficient Quantum Classifier Based on Hamiltonian Representations</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Federico Tiblias, Anna Schroeder, Yue Zhang, Mariami Gachechiladze, Iryna Gurevych
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Quantum machine learning (QML) is a discipline that seeks to transfer the advantages of quantum computing to data-driven tasks. However, many studies rely on toy datasets or heavy feature reduction, raising concerns about their scalability. Progress is further hindered by hardware limitations and th</span>
                
                <span class="abstract-full" style="display: none;">Quantum machine learning (QML) is a discipline that seeks to transfer the advantages of quantum computing to data-driven tasks. However, many studies rely on toy datasets or heavy feature reduction, raising concerns about their scalability. Progress is further hindered by hardware limitations and the significant costs of encoding dense vector representations on quantum devices. To address these challenges, we propose an efficient approach called Hamiltonian classifier that circumvents the costs associated with data encoding by mapping inputs to a finite set of Pauli strings and computing predictions as their expectation values. In addition, we introduce two classifier variants with different scaling in terms of parameters and sample complexity. We evaluate our approach on text and image classification tasks, against well-established classical and quantum models. The Hamiltonian classifier delivers performance comparable to or better than these methods. Notably, our method achieves logarithmic complexity in both qubits and quantum gates, making it well-suited for large-scale, real-world applications. We make our implementation available on GitHub.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge high-confidence" style="background-color: #d37d97" title="Confidence: 82.5%">
                            Quantum Computing
                        </span>
                <!-- LLMs: 5.1 -->
                    
                <!-- Medicine: 4.0 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Networks: 1.2 -->
                    
                <!-- RAG: 1.2 -->
                    
                <!-- T2I: 1.1 -->
                    
                <!-- Evolutionary Algorithms: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -58.9835
                </span>
                <a href="https://arxiv.org/abs/2410.13163" target="_blank" rel="noopener noreferrer">Revocable Encryption, Programs, and More: The Case of Multi-Copy Security</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Prabhanjan Ananth, Saachi Mutreja, Alexander Poremba
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Fundamental principles of quantum mechanics have inspired many new research directions, particularly in quantum cryptography. One such principle is quantum no-cloning which has led to the emerging field of revocable cryptography. Roughly speaking, in a revocable cryptographic primitive, a cryptograp</span>
                
                <span class="abstract-full" style="display: none;">Fundamental principles of quantum mechanics have inspired many new research directions, particularly in quantum cryptography. One such principle is quantum no-cloning which has led to the emerging field of revocable cryptography. Roughly speaking, in a revocable cryptographic primitive, a cryptographic object (such as a ciphertext or program) is represented as a quantum state in such a way that surrendering it effectively translates into losing the capability to use this cryptographic object. All of the revocable cryptographic systems studied so far have a major drawback: the recipient only receives one copy of the quantum state. Worse yet, the schemes become completely insecure if the recipient receives many identical copies of the same quantum state -- a property that is clearly much more desirable in practice. While multi-copy security has been extensively studied for a number of other quantum cryptographic primitives, it has so far received only little treatment in context of unclonable primitives. Our work, for the first time, shows the feasibility of revocable primitives, such as revocable encryption and revocable programs, which satisfy multi-copy security in oracle models. This suggest that the stronger notion of multi-copy security is within reach in unclonable cryptography more generally, and therefore could lead to a new research direction in the field.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge high-confidence" style="background-color: #d37d97" title="Confidence: 81.1%">
                            Quantum Computing
                        </span>
                <!-- LLMs: 3.2 -->
                    
                <!-- Networks: 2.7 -->
                    
                <!-- Reinforcement Learning: 2.1 -->
                    
                <!-- Math: 1.9 -->
                    
                <!-- Robotics: 1.7 -->
                    
                <!-- Medicine: 1.5 -->
                    
                <!-- Pathfinding: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -104.7666
                </span>
                <a href="https://arxiv.org/abs/2504.10811" target="_blank" rel="noopener noreferrer">FlexiContracts: A Novel and Efficient Scheme for Upgrading Smart Contracts in Ethereum Blockchain</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Tahrim Hossain, Sakib Hassan, Faisal Haque Bappy, Muhammad Nur Yanhaona, Sarker Ahmed Rumee, Moinul Zaber, Tariqul Islam
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Blockchain technology has revolutionized contractual processes, enhancing efficiency and trust through smart contracts. Ethereum, as a pioneer in this domain, offers a platform for decentralized applications but is challenged by the immutability of smart contracts, which makes upgrades cumbersome. E</span>
                
                <span class="abstract-full" style="display: none;">Blockchain technology has revolutionized contractual processes, enhancing efficiency and trust through smart contracts. Ethereum, as a pioneer in this domain, offers a platform for decentralized applications but is challenged by the immutability of smart contracts, which makes upgrades cumbersome. Existing design patterns, while addressing upgradability, introduce complexity, increased development effort, and higher gas costs, thus limiting their effectiveness. In response, we introduce FlexiContracts, an innovative scheme that reimagines the evolution of smart contracts on Ethereum. By enabling secure, in-place upgrades without losing historical data, FlexiContracts surpasses existing approaches, introducing a previously unexplored path in smart contract evolution. Its streamlined design transcends the limitations of current design patterns by simplifying smart contract development, eliminating the need for extensive upfront planning, and significantly reducing the complexity of the design process. This advancement fosters an environment for continuous improvement and adaptation to new requirements, redefining the possibilities for dynamic, upgradable smart contracts.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge high-confidence" style="background-color: #3cc377" title="Confidence: 76.8%">
                            Blockchain
                        </span>
                <!-- Medicine: 6.2 -->
                    
                <!-- LLMs: 4.9 -->
                    
                <!-- Quantum Computing: 2.9 -->
                    
                <!-- Networks: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Math: 1.4 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Pathfinding: 1.1 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
    </div>
    
    
    <div id="jsonPopup" class="json-popup">
        <pre id="jsonContent"></pre>
        <button onclick="copyJson()">Copy to Clipboard</button>
        <button onclick="closePopup()">Close</button>
    </div>

    <script>
        function extractPaperData(paperElement) {
            const titleElement = paperElement.querySelector('.paper-title a');
            const metaElement = paperElement.querySelector('.paper-meta');
            const abstractElement = paperElement.querySelector('.paper-abstract');
            const tagsElement = paperElement.querySelector('.paper-tags');
            
            // Get the date from the parent date-section header
            const dateSection = paperElement.closest('.date-section');
            const dateText = dateSection.querySelector('.date-header').textContent.trim();
            
            const authorsText = metaElement.textContent.replace('Authors:', '').trim();
            
            const paperData = {
                title: titleElement.textContent,
                url: titleElement.href,
                authors: authorsText.split(',').map(author => author.trim()),
                created: dateText,
                abstract: abstractElement.querySelector('.abstract-full').textContent
            };
            
            return paperData;
        }

        function showJson(paperElement) {
            const popup = document.getElementById('jsonPopup');
            const content = document.getElementById('jsonContent');
            const paperData = extractPaperData(paperElement);
            content.textContent = JSON.stringify(paperData, null, null);
            popup.style.display = 'block';
            document.addEventListener('click', function closePopupOnClick(event) {
                if (!popup.contains(event.target)) {
                    popup.style.display = 'none';
                    document.removeEventListener('click', closePopupOnClick);
                }
            });
        }
        function toggleAbstract(element) {
            const abstract = element.parentElement;
            const short = abstract.querySelector('.abstract-short');
            const full = abstract.querySelector('.abstract-full');
            const lowConfidenceTags = abstract.parentElement.querySelectorAll('.tag-badge.low-confidence');
            
            if (element.textContent === '... more') {
                short.style.display = 'none';
                full.style.display = 'inline';
                element.textContent = ' less';
                lowConfidenceTags.forEach(tag => tag.style.display = 'inline-block');
            } else {
                short.style.display = 'inline';
                full.style.display = 'none';
                element.textContent = '... more';
                lowConfidenceTags.forEach(tag => tag.style.display = 'none');
            }
        }

        function closePopup() {
            document.getElementById('jsonPopup').style.display = 'none';
        }

        function copyJson() {
            const content = document.getElementById('jsonContent').textContent;
            navigator.clipboard.writeText(content).catch(() => {
                // If clipboard API is not available, just show the popup
                alert('Could not copy to clipboard. JSON is displayed in the popup.');
            });
        }

        // Close popup when clicking outside
        window.onclick = function(event) {
            const popup = document.getElementById('jsonPopup');
            if (event.target === popup) {
                popup.style.display = 'none';
            }
        }
    </script>
</body>
</html> 