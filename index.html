<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv Frontpage</title>
    <style>
        body {
            font-family: sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
        }
        .paper {
            margin-bottom: 30px;
            margin-top: 30px;
            padding: 20px;
            border: 1px solid #ddd;
            border-radius: 5px;
        }
        .paper-title {
            font-size: 1.2em;
            font-weight: bold;
            margin-bottom: 10px;
        }
        .paper-meta {
            color: #666;
            font-size: 0.9em;
            margin-bottom: 10px;
        }
        .paper-abstract {
            margin-bottom: 10px;
        }
        .abstract-short {
            display: inline;
        }
        .abstract-full {
            display: none;
        }
        .more-link {
            color: blue;
            cursor: pointer;
            text-decoration: underline;
        }
        .tag-badge {
            display: inline-block;
            padding: 3px 8px;
            margin-right: 5px;
            margin-bottom: 5px;
            border-radius: 3px;
            font-size: 0.8em;
            color: white;
        }
        .tag-badge.high-confidence {
            opacity: 1;
        }
        .tag-badge.low-confidence {
            opacity: 0.6;
            display: none;
        }
        .interestingness-score {
            display: inline-block;
            padding: 3px 8px;
            margin-right: 10px;
            color: white;
            border-radius: 3px;
            font-weight: bold;
        }
        .interestingness-positive {
            background-color: #4CAF50;
        }
        .interestingness-negative {
            background-color: #f44336;
        }
        .interestingness-neutral {
            background-color: #9e9e9e;
        }
        .last-updated {
            text-align: right;
            color: #666;
            font-size: 0.9em;
            margin-top: 20px;
            margin-bottom: 20px;
        }
        .intro {
            text-align: center;
            max-width: 60em;
            margin: 0 auto;
            color: #888;
        }
        .copy-icon {
            display: inline-block;
            width: 16px;
            height: 16px;
            cursor: pointer;
            margin-left: 5px;
            opacity: 0.5;
        }
        .copy-icon:hover {
            opacity: 1;
        }
        .json-popup {
            display: none;
            position: fixed;
            top: 20px;
            right: 20px;
            background: white;
            padding: 20px;
            border: 1px solid #ddd;
            border-radius: 5px;
            max-width: 500px;
            max-height: 300px;
            overflow: auto;
            box-shadow: 0 0 10px rgba(0,0,0,0.1);
        }
        a {
            color: inherit;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        h1 {
            text-align: center;
        }
        h1 a {
            text-decoration: underline;
        }
        .date-section {
            margin-bottom: 40px;
        }
        .date-header {
            color: #666;
            font-size: 1.5em;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 2px solid #eee;
        }
    </style>
</head>
<body>
    <h1>
        <a href="https://github.com/DataWraith/arxiv-frontpage">DataWraith's</a> ArXiv Frontpage
    </h1>

    <div class="last-updated">
        Last updated: 2025-06-02
    </div>

    <p class="intro">
        This frontpage is made by scraping ArXiv's computer science RSS feed and tagging papers with a classifier.
    </p>

    <p class="intro">
        Each tag is weighted according to my preferences to compute a paper's <i>interestingness</i> score.
    </p>
    
    
    <div class="date-section">
        <h2 class="date-header">2025-06-02</h2>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.6969
                </span>
                <a href="https://arxiv.org/abs/2505.24113" target="_blank" rel="noopener noreferrer">Distributed Neural Policy Gradient Algorithm for Global Convergence of Networked Multi-Agent Reinforcement Learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Pengcheng Dai, Yuanqiu Mo, Wenwu Yu, Wei Ren
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper studies the networked multi-agent reinforcement learning (NMARL) problem, where the objective of agents is to collaboratively maximize the discounted average cumulative rewards. Different from the existing methods that suffer from poor expression due to linear function approximation, we p</span>
                
                <span class="abstract-full" style="display: none;">This paper studies the networked multi-agent reinforcement learning (NMARL) problem, where the objective of agents is to collaboratively maximize the discounted average cumulative rewards. Different from the existing methods that suffer from poor expression due to linear function approximation, we propose a distributed neural policy gradient algorithm that features two innovatively designed neural networks, specifically for the approximate Q-functions and policy functions of agents. This distributed neural policy gradient algorithm consists of two key components: the distributed critic step and the decentralized actor step. In the distributed critic step, agents receive the approximate Q-function parameters from their neighboring agents via a time-varying communication networks to collaboratively evaluate the joint policy. In contrast, in the decentralized actor step, each agent updates its local policy parameter solely based on its own approximate Q-function. In the convergence analysis, we first establish the global convergence of agents for the joint policy evaluation in the distributed critic step. Subsequently, we rigorously demonstrate the global convergence of the overall distributed neural policy gradient algorithm with respect to the objective function. Finally, the effectiveness of the proposed algorithm is demonstrated by comparing it with a centralized algorithm through simulation in the robot path planning environment.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #44f899" title="Confidence: 7.0%">
                            Reinforcement Learning
                        </span>
                <!-- Federated Learning: 4.3 -->
                    
                <!-- Math: 3.4 -->
                    
                <!-- GNN: 2.3 -->
                    
                <!-- Bayesian Optimization: 2.1 -->
                    
                <!-- Cryptography: 1.9 -->
                    
                <!-- Networks: 1.8 -->
                    
                <!-- Finance: 1.8 -->
                    
                <!-- Pathfinding: 1.5 -->
                    
                <!-- Game Theory: 1.5 -->
                    
                <!-- Medicine: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Computer Vision: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.5451
                </span>
                <a href="https://arxiv.org/abs/2505.23927" target="_blank" rel="noopener noreferrer">Thompson Sampling in Online RLHF with General Function Approximation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Songtao Feng, Jie Fu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Reinforcement learning from human feedback (RLHF) has achieved great empirical success in aligning large language models (LLMs) with human preference, and it is of great importance to study the statistical efficiency of RLHF algorithms from a theoretical perspective. In this work, we consider the on</span>
                
                <span class="abstract-full" style="display: none;">Reinforcement learning from human feedback (RLHF) has achieved great empirical success in aligning large language models (LLMs) with human preference, and it is of great importance to study the statistical efficiency of RLHF algorithms from a theoretical perspective. In this work, we consider the online RLHF setting where the preference data is revealed during the learning process and study action value function approximation. We design a model-free posterior sampling algorithm for online RLHF inspired by Thompson sampling and provide its theoretical guarantee. Specifically, we adopt Bellman eluder (BE) dimension as the complexity measure of the function class and establish $O(\sqrt{T})$ regret bound for the proposed algorithm with other multiplicative factor depending on the horizon, BE dimension and the $log$-bracketing number of the function class. Further, in the analysis, we first establish the concentration-type inequality of the squared Bellman error bound based on the maximum likelihood estimator (MLE) generalization bound, which plays the crucial rules in obtaining the eluder-type regret bound and may be of independent interest.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #44f899" title="Confidence: 5.1%">
                            Reinforcement Learning
                        </span>
                <!-- Medicine: 2.6 -->
                    
                <!-- Federated Learning: 2.5 -->
                    
                <!-- LLMs: 2.2 -->
                    
                <!-- Bayesian Optimization: 2.2 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Math: 1.9 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- Cryptography: 1.5 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Networks: 1.0 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.3979
                </span>
                <a href="https://arxiv.org/abs/2502.13859" target="_blank" rel="noopener noreferrer">MSVCOD:A Large-Scale Multi-Scene Dataset for Video Camouflage Object Detection</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Shuyong Gao, Yu'ang Feng, Qishan Wang, Lingyi Hong, Xinyu Zhou, Liu Fei, Yan Wang, Wenqiang Zhang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Video Camouflaged Object Detection (VCOD) is a challenging task which aims to identify objects that seamlessly concealed within the background in videos. The dynamic properties of video enable detection of camouflaged objects through motion cues or varied perspectives. Previous VCOD datasets primari</span>
                
                <span class="abstract-full" style="display: none;">Video Camouflaged Object Detection (VCOD) is a challenging task which aims to identify objects that seamlessly concealed within the background in videos. The dynamic properties of video enable detection of camouflaged objects through motion cues or varied perspectives. Previous VCOD datasets primarily contain animal objects, limiting the scope of research to wildlife scenarios. However, the applications of VCOD extend beyond wildlife and have significant implications in security, art, and medical fields. Addressing this problem, we construct a new large-scale multi-domain VCOD dataset MSVCOD. To achieve high-quality annotations, we design a semi-automatic iterative annotation pipeline that reduces costs while maintaining annotation accuracy. Our MSVCOD is the largest VCOD dataset to date, introducing multiple object categories including human, animal, medical, and vehicle objects for the first time, while also expanding background diversity across various environments. This expanded scope increases the practical applicability of the VCOD task in camouflaged object detection. Alongside this dataset, we introduce a one-steam video camouflage object detection model that performs both feature extraction and information fusion without additional motion feature fusion modules. Our framework achieves state-of-the-art results on the existing VCOD animal dataset and the proposed MSVCOD. The dataset and code will be made publicly available.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 6.8%">
                            Computer Vision
                        </span>
                <!-- Medicine: 3.9 -->
                    
                <!-- LLMs: 3.6 -->
                    
                <!-- Datasets: 2.5 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.3831
                </span>
                <a href="https://arxiv.org/abs/2409.07541" target="_blank" rel="noopener noreferrer">ENACT: Entropy-based Clustering of Attention Input for Reducing the Computational Needs of Object Detection Transformers</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Giorgos Savathrakis, Antonis Argyros
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Transformers demonstrate competitive performance in terms of precision on the problem of vision-based object detection. However, they require considerable computational resources due to the quadratic size of the attention weights. In this work, we propose to cluster the transformer input on the basi</span>
                
                <span class="abstract-full" style="display: none;">Transformers demonstrate competitive performance in terms of precision on the problem of vision-based object detection. However, they require considerable computational resources due to the quadratic size of the attention weights. In this work, we propose to cluster the transformer input on the basis of its entropy, due to its similarity between same object pixels. This is expected to reduce GPU usage during training, while maintaining reasonable accuracy. This idea is realized with an implemented module that is called ENtropy-based Attention Clustering for detection Transformers (ENACT), which serves as a plug-in to any multi-head self-attention based transformer network. Experiments on the COCO object detection dataset and three detection transformers demonstrate that the requirements on memory are reduced, while the detection accuracy is degraded only slightly. The code of the ENACT module is available at https://github.com/GSavathrakis/ENACT.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 7.1%">
                            Computer Vision
                        </span>
                <!-- Federated Learning: 4.7 -->
                    
                <!-- Evolutionary Algorithms: 2.6 -->
                    
                <!-- Bayesian Optimization: 2.6 -->
                    
                <!-- Medicine: 2.1 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- LLMs: 1.2 -->
                    
                <!-- Robotics: 1.0 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.353
                </span>
                <a href="https://arxiv.org/abs/2403.05852" target="_blank" rel="noopener noreferrer">SSF-Net: Spatial-Spectral Fusion Network with Spectral Angle Awareness for Hyperspectral Object Tracking</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Hanzheng Wang, Wei Li, Xiang-Gen Xia, Qian Du, Jing Tian
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Hyperspectral video (HSV) offers valuable spatial, spectral, and temporal information simultaneously, making it highly suitable for handling challenges such as background clutter and visual similarity in object tracking. However, existing methods primarily focus on band regrouping and rely on RGB tr</span>
                
                <span class="abstract-full" style="display: none;">Hyperspectral video (HSV) offers valuable spatial, spectral, and temporal information simultaneously, making it highly suitable for handling challenges such as background clutter and visual similarity in object tracking. However, existing methods primarily focus on band regrouping and rely on RGB trackers for feature extraction, resulting in limited exploration of spectral information and difficulties in achieving complementary representations of object features. In this paper, a spatial-spectral fusion network with spectral angle awareness (SST-Net) is proposed for hyperspectral (HS) object tracking. Firstly, to address the issue of insufficient spectral feature extraction in existing networks, a spatial-spectral feature backbone ($S^2$FB) is designed. With the spatial and spectral extraction branch, a joint representation of texture and spectrum is obtained. Secondly, a spectral attention fusion module (SAFM) is presented to capture the intra- and inter-modality correlation to obtain the fused features from the HS and RGB modalities. It can incorporate the visual information into the HS spectral context to form a robust representation. Thirdly, to ensure a more accurate response of the tracker to the object position, a spectral angle awareness module (SAAM) investigates the region-level spectral similarity between the template and search images during the prediction stage. Furthermore, we develop a novel spectral angle awareness loss (SAAL) to offer guidance for the SAAM based on similar regions. Finally, to obtain the robust tracking results, a weighted prediction method is considered to combine the HS and RGB predicted motions of objects to leverage the strengths of each modality. Extensive experiments on the HOTC dataset demonstrate the effectiveness of the proposed SSF-Net, compared with state-of-the-art trackers.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.0%">
                            Computer Vision
                        </span>
                <!-- Medicine: 2.9 -->
                    
                <!-- Federated Learning: 2.8 -->
                    
                <!-- Evolutionary Algorithms: 2.4 -->
                    
                <!-- Reinforcement Learning: 2.0 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Networks: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.3158
                </span>
                <a href="https://arxiv.org/abs/2505.24461" target="_blank" rel="noopener noreferrer">Logits-Based Finetuning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jingyao Li, Senqiao Yang, Sitong Wu, Han Shi, Chuanyang Zheng, Hong Xu, Jiaya Jia
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The core of out-of-distribution (OOD) detection is to learn the in-distribution (ID) representation, which is distinguishable from OOD samples. Previous work applied recognition-based methods to learn the ID features, which tend to learn shortcuts instead of comprehensive representations. In this wo</span>
                
                <span class="abstract-full" style="display: none;">The core of out-of-distribution (OOD) detection is to learn the in-distribution (ID) representation, which is distinguishable from OOD samples. Previous work applied recognition-based methods to learn the ID features, which tend to learn shortcuts instead of comprehensive representations. In this work, we find surprisingly that simply using reconstruction-based methods could boost the performance of OOD detection significantly. We deeply explore the main contributors of OOD detection and find that reconstruction-based pretext tasks have the potential to provide a generally applicable and efficacious prior, which benefits the model in learning intrinsic data distributions of the ID dataset. Specifically, we take Masked Image Modeling as a pretext task for our OOD detection framework (MOOD). Without bells and whistles, MOOD outperforms previous SOTA of one-class OOD detection by 5.7%, multi-class OOD detection by 3.0%, and near-distribution OOD detection by 2.1%. It even defeats the 10-shot-per-class outlier exposure OOD detection, although we do not include any OOD samples for our detection. Codes are available at https://github.com/JulietLJY/MOOD.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 6.3%">
                            Computer Vision
                        </span>
                <!-- Federated Learning: 3.6 -->
                    
                <!-- LLMs: 3.0 -->
                    
                <!-- Medicine: 2.7 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2817
                </span>
                <a href="https://arxiv.org/abs/2505.20685" target="_blank" rel="noopener noreferrer">GIT-BO: High-Dimensional Bayesian Optimization with Tabular Foundation Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Rosen Ting-Ying Yu, Cyril Picard, Faez Ahmed
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Bayesian optimization (BO) effectively optimizes expensive black-box functions but faces significant challenges in high-dimensional spaces (dimensions exceeding 100) due to the curse of dimensionality. Existing high-dimensional BO methods typically leverage low-dimensional embeddings or structural a</span>
                
                <span class="abstract-full" style="display: none;">Bayesian optimization (BO) effectively optimizes expensive black-box functions but faces significant challenges in high-dimensional spaces (dimensions exceeding 100) due to the curse of dimensionality. Existing high-dimensional BO methods typically leverage low-dimensional embeddings or structural assumptions to mitigate this challenge, yet these approaches frequently incur considerable computational overhead and rigidity due to iterative surrogate retraining and fixed assumptions. To address these limitations, we propose Gradient-Informed Bayesian Optimization using Tabular Foundation Models (GIT-BO), an approach that utilizes a pre-trained tabular foundation model (TFM) as a surrogate, leveraging its gradient information to adaptively identify low-dimensional subspaces for optimization. We propose a way to exploit internal gradient computations from the TFM's forward pass by creating a gradient-informed diagnostic matrix that reveals the most sensitive directions of the TFM's predictions, enabling optimization in a continuously re-estimated active subspace without the need for repeated model retraining. Extensive empirical evaluation across 23 synthetic and real-world benchmarks demonstrates that GIT-BO consistently outperforms four state-of-the-art Gaussian process-based high-dimensional BO methods, showing superior scalability and optimization performances, especially as dimensionality increases up to 500 dimensions. This work establishes foundation models, augmented with gradient-informed adaptive subspace identification, as highly competitive alternatives to traditional Gaussian process-based approaches for high-dimensional Bayesian optimization tasks.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #31bb31" title="Confidence: 7.3%">
                            Bayesian Optimization
                        </span>
                <!-- LLMs: 3.8 -->
                    
                <!-- GNN: 2.5 -->
                    
                <!-- Medicine: 2.2 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- HPO and AutoML: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2793
                </span>
                <a href="https://arxiv.org/abs/2505.24310" target="_blank" rel="noopener noreferrer">Progressive Class-level Distillation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jiayan Li, Jun Li, Zhourui Zhang, Jianhua Xu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In knowledge distillation (KD), logit distillation (LD) aims to transfer class-level knowledge from a more powerful teacher network to a small student model via accurate teacher-student alignment at the logits level. Since high-confidence object classes usually dominate the distillation process, low</span>
                
                <span class="abstract-full" style="display: none;">In knowledge distillation (KD), logit distillation (LD) aims to transfer class-level knowledge from a more powerful teacher network to a small student model via accurate teacher-student alignment at the logits level. Since high-confidence object classes usually dominate the distillation process, low-probability classes which also contain discriminating information are downplayed in conventional methods, leading to insufficient knowledge transfer. To address this issue, we propose a simple yet effective LD method termed Progressive Class-level Distillation (PCD). In contrast to existing methods which perform all-class ensemble distillation, our PCD approach performs stage-wise distillation for step-by-step knowledge transfer. More specifically, we perform ranking on teacher-student logits difference for identifying distillation priority from scratch, and subsequently divide the entire LD process into multiple stages. Next, bidirectional stage-wise distillation incorporating fine-to-coarse progressive learning and reverse coarse-to-fine refinement is conducted, allowing comprehensive knowledge transfer via sufficient logits alignment within separate class groups in different distillation stages. Extension experiments on public benchmarking datasets demonstrate the superiority of our method compared to state-of-the-arts for both classification and detection tasks.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.6%">
                            Computer Vision
                        </span>
                <!-- LLMs: 3.5 -->
                    
                <!-- Federated Learning: 3.1 -->
                    
                <!-- Medicine: 2.9 -->
                    
                <!-- GNN: 2.6 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Hardware: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2698
                </span>
                <a href="https://arxiv.org/abs/2505.22604" target="_blank" rel="noopener noreferrer">Adversarially Robust AI-Generated Image Detection for Free: An Information Theoretic Perspective</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ruixuan Zhang, He Wang, Zhengyu Zhao, Zhiqing Guo, Xun Yang, Yunfeng Diao, Meng Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Rapid advances in Artificial Intelligence Generated Images (AIGI) have facilitated malicious use, such as forgery and misinformation. Therefore, numerous methods have been proposed to detect fake images. Although such detectors have been proven to be universally vulnerable to adversarial attacks, de</span>
                
                <span class="abstract-full" style="display: none;">Rapid advances in Artificial Intelligence Generated Images (AIGI) have facilitated malicious use, such as forgery and misinformation. Therefore, numerous methods have been proposed to detect fake images. Although such detectors have been proven to be universally vulnerable to adversarial attacks, defenses in this field are scarce. In this paper, we first identify that adversarial training (AT), widely regarded as the most effective defense, suffers from performance collapse in AIGI detection. Through an information-theoretic lens, we further attribute the cause of collapse to feature entanglement, which disrupts the preservation of feature-label mutual information. Instead, standard detectors show clear feature separation. Motivated by this difference, we propose Training-free Robust Detection via Information-theoretic Measures (TRIM), the first training-free adversarial defense for AIGI detection. TRIM builds on standard detectors and quantifies feature shifts using prediction entropy and KL divergence. Extensive experiments across multiple datasets and attacks validate the superiority of our TRIM, e.g., outperforming the state-of-the-art defense by 33.88% (28.91%) on ProGAN (GenImage), while well maintaining original accuracy.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.0%">
                            Computer Vision
                        </span>
                <!-- LLMs: 4.8 -->
                    
                <!-- GNN: 2.9 -->
                    
                <!-- Federated Learning: 2.5 -->
                    
                <!-- Blockchain: 2.2 -->
                    
                <!-- Medicine: 2.1 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2586
                </span>
                <a href="https://arxiv.org/abs/2505.04594" target="_blank" rel="noopener noreferrer">MonoCoP: Chain-of-Prediction for Monocular 3D Object Detection</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zhihao Zhang, Abhinav Kumar, Girish Chandar Ganesan, Xiaoming Liu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Accurately predicting 3D attributes is crucial for monocular 3D object detection (Mono3D), with depth estimation posing the greatest challenge due to the inherent ambiguity in mapping 2D images to 3D space. While existing methods leverage multiple depth cues (e.g., estimating depth uncertainty, mode</span>
                
                <span class="abstract-full" style="display: none;">Accurately predicting 3D attributes is crucial for monocular 3D object detection (Mono3D), with depth estimation posing the greatest challenge due to the inherent ambiguity in mapping 2D images to 3D space. While existing methods leverage multiple depth cues (e.g., estimating depth uncertainty, modeling depth error) to improve depth accuracy, they overlook that accurate depth prediction requires conditioning on other 3D attributes, as these attributes are intrinsically inter-correlated through the 3D to 2D projection, which ultimately limits overall accuracy and stability. Inspired by Chain-of-Thought (CoT) in large language models (LLMs), this paper proposes MonoCoP, which leverages a Chain-of-Prediction (CoP) to predict attributes sequentially and conditionally via three key designs. First, it employs a lightweight AttributeNet (AN) for each 3D attribute to learn attribute-specific features. Next, MonoCoP constructs an explicit chain to propagate these learned features from one attribute to the next. Finally, MonoCoP uses a residual connection to aggregate features for each attribute along the chain, ensuring that later attribute predictions are conditioned on all previously processed attributes without forgetting the features of earlier ones. Experimental results show that our MonoCoP achieves state-of-the-art (SoTA) performance on the KITTI leaderboard without requiring additional data and further surpasses existing methods on the Waymo and nuScenes frontal datasets.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.2%">
                            Computer Vision
                        </span>
                <!-- 3D: 3.8 -->
                    
                <!-- Medicine: 3.0 -->
                    
                <!-- Federated Learning: 2.3 -->
                    
                <!-- GNN: 2.3 -->
                    
                <!-- LLMs: 2.3 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Hardware: 1.0 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2378
                </span>
                <a href="https://arxiv.org/abs/2505.21649" target="_blank" rel="noopener noreferrer">Right Side Up? Disentangling Orientation Understanding in MLLMs with Fine-grained Multi-axis Perception Tasks</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Keanu Nichols, Nazia Tasnim, Yuting Yan, Nicholas Ikechukwu, Elva Zou, Deepti Ghadiyaram, Bryan A. Plummer
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Object orientation understanding represents a fundamental challenge in visual perception critical for applications like robotic manipulation and augmented reality. Current vision-language benchmarks fail to isolate this capability, often conflating it with positional relationships and general scene </span>
                
                <span class="abstract-full" style="display: none;">Object orientation understanding represents a fundamental challenge in visual perception critical for applications like robotic manipulation and augmented reality. Current vision-language benchmarks fail to isolate this capability, often conflating it with positional relationships and general scene understanding. We introduce DORI (Discriminative Orientation Reasoning Intelligence), a comprehensive benchmark establishing object orientation perception as a primary evaluation target. DORI assesses four dimensions of orientation comprehension: frontal alignment, rotational transformations, relative directional relationships, and canonical orientation understanding. Through carefully curated tasks from 11 datasets spanning 67 object categories across synthetic and real-world scenarios, DORI provides insights on how multi-modal systems understand object orientations. Our evaluation of 15 state-of-the-art vision-language models reveals critical limitations: even the best models achieve only 54.2% accuracy on coarse tasks and 33.0% on granular orientation judgments, with performance deteriorating for tasks requiring reference frame shifts or compound rotations. These findings demonstrate the need for dedicated orientation representation mechanisms, as models show systematic inability to perform precise angular estimations, track orientation changes across viewpoints, and understand compound rotations - suggesting limitations in their internal 3D spatial representations. As the first diagnostic framework specifically designed for orientation awareness in multimodal systems, DORI offers implications for improving robotic control, 3D scene reconstruction, and human-AI interaction in physical environments. DORI data: https://huggingface.co/datasets/appledora/DORI-Benchmark</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.9%">
                            Computer Vision
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.9%">
                            LLMs
                        </span>
                <!-- Medicine: 4.0 -->
                    
                <!-- Hardware: 2.3 -->
                    
                <!-- Datasets: 1.9 -->
                    
                <!-- 3D: 1.8 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- T2I: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.1534
                </span>
                <a href="https://arxiv.org/abs/2505.23913" target="_blank" rel="noopener noreferrer">Simplifying Bayesian Optimization Via In-Context Direct Optimum Sampling</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Gustavo Sutter Pessurno de Carvalho, Mohammed Abdulrahman, Hao Wang, Sriram Ganapathi Subramanian, Marc St-Aubin, Sharon O'Sullivan, Lawrence Wan, Luis Ricardez-Sandoval, Pascal Poupart, Agustinus Kristiadi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The optimization of expensive black-box functions is ubiquitous in science and engineering. A common solution to this problem is Bayesian optimization (BO), which is generally comprised of two components: (i) a surrogate model and (ii) an acquisition function, which generally require expensive re-tr</span>
                
                <span class="abstract-full" style="display: none;">The optimization of expensive black-box functions is ubiquitous in science and engineering. A common solution to this problem is Bayesian optimization (BO), which is generally comprised of two components: (i) a surrogate model and (ii) an acquisition function, which generally require expensive re-training and optimization steps at each iteration, respectively. Although recent work enabled in-context surrogate models that do not require re-training, virtually all existing BO methods still require acquisition function maximization to select the next observation, which introduces many knobs to tune, such as Monte Carlo samplers and multi-start optimizers. In this work, we propose a completely in-context, zero-shot solution for BO that does not require surrogate fitting or acquisition function optimization. This is done by using a pre-trained deep generative model to directly sample from the posterior over the optimum point. We show that this process is equivalent to Thompson sampling and demonstrate the capabilities and cost-effectiveness of our foundation model on a suite of real-world benchmarks. We achieve an efficiency gain of more than 35x in terms of wall-clock time when compared with Gaussian process-based BO, enabling efficient parallel and distributed BO, e.g., for high-throughput optimization.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.7%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #31bb31" title="Confidence: 5.1%">
                            Bayesian Optimization
                        </span>
                <!-- Medicine: 2.9 -->
                    
                <!-- Federated Learning: 2.6 -->
                    
                <!-- Evolutionary Algorithms: 2.2 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Hardware: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.23771" target="_blank" rel="noopener noreferrer">AESHA3: Efficient and Secure Sub-Key Generation for AES Using SHA-3</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ankush Soni, Sanjay K. Sahay, Parit Mehta
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Advanced Encryption Standard (AES) is one of the most widely used symmetric cipher for the confidentiality of data. Also it is used for other security services, viz. integrity, authentication and key establishment. However, recently, authors have shown some weakness in the generation of sub-keys in </span>
                
                <span class="abstract-full" style="display: none;">Advanced Encryption Standard (AES) is one of the most widely used symmetric cipher for the confidentiality of data. Also it is used for other security services, viz. integrity, authentication and key establishment. However, recently, authors have shown some weakness in the generation of sub-keys in AES, e.g. bit leakage attack, etc. Also, AES sub-keys are generated sequentially, which is an overhead, especially for resource-constrained devices. Therefore, we propose and investigate a novel encryption AESHA3, which uses sub-keys generated by Secure Hash Algorithm-3 (SHA3). The output of SHA3 is one-way and highly non-linear, and random. The experimental analysis shows that the average time taken for generating the sub-keys to be used for encrypting the data using our approach i.e. AESHA3 is ~1300 times faster than the sub-key generated by the standard AES. Accordingly, we find that AESHA3 will be very relevant not only in terms of security but also it will save the resources in IoT devices. We investigated AESHA3 in Intel Core i7, 6th Generation processor and Raspberry Pi 4B and found that up to two MB data encryption is very significant, and lesser the data size, more the resource saving compared to AES.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.7 -->
                    
                <!-- LLMs: 2.6 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.23772" target="_blank" rel="noopener noreferrer">Anamorphic Cryptography with Elliptic Curve Methods</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: William J Buchanan
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In 2022, Persianom, Phan and Yung outlined the creation of Anamorphic Cryptography. With this, we can create a public key to encrypt data, and then have two secret keys. These secret keys are used to decrypt the cipher into different messages. So, one secret key is given to the Dictator (who must be</span>
                
                <span class="abstract-full" style="display: none;">In 2022, Persianom, Phan and Yung outlined the creation of Anamorphic Cryptography. With this, we can create a public key to encrypt data, and then have two secret keys. These secret keys are used to decrypt the cipher into different messages. So, one secret key is given to the Dictator (who must be able to decrypt all the messages), and the other is given to Alice. Alice can then decrypt the ciphertext to a secret message that the Dictator cannot see. This paper outlines the implementation of Anamorphic Cryptography using ECC (Elliptic Curve Cryptography), such as with the secp256k1 curve. This gives considerable performance improvements over discrete logarithm-based methods. Overall, it outlines how the secret message sent to Alice is hidden within the random nonce value, which is used within the encryption process, and which is cancelled out when the Dictator decrypts the ciphertext.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 2.5 -->
                    
                <!-- Networks: 2.3 -->
                    
                <!-- Cryptography: 2.3 -->
                    
                <!-- Computer Vision: 2.1 -->
                    
                <!-- Math: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Finance: 1.4 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Medicine: 1.3 -->
                    
                <!-- Game Theory: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.23782" target="_blank" rel="noopener noreferrer">4,500 Seconds: Small Data Training Approaches for Deep UAV Audio Classification</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Andrew P. Berg, Qian Zhang, Mia Y. Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Unmanned aerial vehicle (UAV) usage is expected to surge in the coming decade, raising the need for heightened security measures to prevent airspace violations and security threats. This study investigates deep learning approaches to UAV classification focusing on the key issue of data scarcity. To </span>
                
                <span class="abstract-full" style="display: none;">Unmanned aerial vehicle (UAV) usage is expected to surge in the coming decade, raising the need for heightened security measures to prevent airspace violations and security threats. This study investigates deep learning approaches to UAV classification focusing on the key issue of data scarcity. To investigate this we opted to train the models using a total of 4,500 seconds of audio samples, evenly distributed across a 9-class dataset. We leveraged parameter efficient fine-tuning (PEFT) and data augmentations to mitigate the data scarcity. This paper implements and compares the use of convolutional neural networks (CNNs) and attention-based transformers. Our results show that, CNNs outperform transformers by 1-2\% accuracy, while still being more computationally efficient. These early findings, however, point to potential in using transformers models; suggesting that with more data and further optimizations they could outperform CNNs. Future works aims to upscale the dataset to better understand the trade-offs between these approaches.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 3.9 -->
                    
                <!-- Federated Learning: 3.2 -->
                    
                <!-- LLMs: 2.7 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- Evolutionary Algorithms: 2.2 -->
                    
                <!-- Decision Trees: 1.8 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.23784" target="_blank" rel="noopener noreferrer">Learning Normal Patterns in Musical Loops</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Shayan Dadman, Bernt Arild Bremdal, B{\o}rre Bang, Rune Dalmo
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper introduces an unsupervised framework for detecting audio patterns in musical samples (loops) through anomaly detection techniques, addressing challenges in music information retrieval (MIR). Existing methods are often constrained by reliance on handcrafted features, domain-specific limita</span>
                
                <span class="abstract-full" style="display: none;">This paper introduces an unsupervised framework for detecting audio patterns in musical samples (loops) through anomaly detection techniques, addressing challenges in music information retrieval (MIR). Existing methods are often constrained by reliance on handcrafted features, domain-specific limitations, or dependence on iterative user interaction. We address these limitations through an architecture combining deep feature extraction with unsupervised anomaly detection. Our approach leverages a pre-trained Hierarchical Token-semantic Audio Transformer (HTS-AT), paired with a Feature Fusion Mechanism (FFM), to generate representations from variable-length audio loops. These embeddings are processed using one-class Deep Support Vector Data Description (Deep SVDD), which learns normative audio patterns by mapping them to a compact latent hypersphere. Evaluations on curated bass and guitar datasets compare standard and residual autoencoder variants against baselines like Isolation Forest (IF) and and principle component analysis (PCA) methods. Results show our Deep SVDD models, especially the residual autoencoder variant, deliver improved anomaly separation, particularly for larger variations. This research contributes a flexible, fully unsupervised solution for processing diverse audio samples, overcoming previous structural and input limitations while enabling effective pattern identification through distance-based latent space scoring.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.8 -->
                    
                <!-- Medicine: 4.4 -->
                    
                <!-- Computer Vision: 2.9 -->
                    
                <!-- GNN: 2.2 -->
                    
                <!-- Blockchain: 2.2 -->
                    
                <!-- 3D: 2.1 -->
                    
                <!-- HPO and AutoML: 2.1 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Federated Learning: 1.6 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Robotics: 1.0 -->
                    
                <!-- T2I: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.23786" target="_blank" rel="noopener noreferrer">Mind the Gap: A Practical Attack on GGUF Quantization</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Kazuki Egashira, Robin Staab, Mark Vero, Jingxuan He, Martin Vechev
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">With the increasing size of frontier LLMs, post-training quantization has become the standard for memory-efficient deployment. Recent work has shown that basic rounding-based quantization schemes pose security risks, as they can be exploited to inject malicious behaviors into quantized models that r</span>
                
                <span class="abstract-full" style="display: none;">With the increasing size of frontier LLMs, post-training quantization has become the standard for memory-efficient deployment. Recent work has shown that basic rounding-based quantization schemes pose security risks, as they can be exploited to inject malicious behaviors into quantized models that remain hidden in full precision. However, existing attacks cannot be applied to more complex quantization methods, such as the GGUF family used in the popular ollama and llama.cpp frameworks. In this work, we address this gap by introducing the first attack on GGUF. Our key insight is that the quantization error -- the difference between the full-precision weights and their (de-)quantized version -- provides sufficient flexibility to construct malicious quantized models that appear benign in full precision. Leveraging this, we develop an attack that trains the target malicious LLM while constraining its weights based on quantization errors. We demonstrate the effectiveness of our attack on three popular LLMs across nine GGUF quantization data types on three diverse attack scenarios: insecure code generation ($\Delta$=$88.7\%$), targeted content injection ($\Delta$=$85.0\%$), and benign instruction refusal ($\Delta$=$30.1\%$). Our attack highlights that (1) the most widely used post-training quantization method is susceptible to adversarial interferences, and (2) the complexity of quantization schemes alone is insufficient as a defense.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.8 -->
                    
                <!-- Federated Learning: 3.0 -->
                    
                <!-- Computer Vision: 2.6 -->
                    
                <!-- Quantum Computing: 2.3 -->
                    
                <!-- Blockchain: 2.0 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Bayesian Optimization: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Cryptography: 1.1 -->
                    
                <!-- Medicine: 1.1 -->
                    
                <!-- Math: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.23791" target="_blank" rel="noopener noreferrer">Evaluating Query Efficiency and Accuracy of Transfer Learning-based Model Extraction Attack in Federated Learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Sayyed Farid Ahamed, Sandip Roy, Soumya Banerjee, Marc Vucovich, Kevin Choi, Abdul Rahman, Alison Hu, Edward Bowen, Sachin Shetty
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Federated Learning (FL) is a collaborative learning framework designed to protect client data, yet it remains highly vulnerable to Intellectual Property (IP) threats. Model extraction (ME) attacks pose a significant risk to Machine Learning as a Service (MLaaS) platforms, enabling attackers to repli</span>
                
                <span class="abstract-full" style="display: none;">Federated Learning (FL) is a collaborative learning framework designed to protect client data, yet it remains highly vulnerable to Intellectual Property (IP) threats. Model extraction (ME) attacks pose a significant risk to Machine Learning as a Service (MLaaS) platforms, enabling attackers to replicate confidential models by querying black-box (without internal insight) APIs. Despite FL's privacy-preserving goals, its distributed nature makes it particularly susceptible to such attacks. This paper examines the vulnerability of FL-based victim models to two types of model extraction attacks. For various federated clients built under the NVFlare platform, we implemented ME attacks across two deep learning architectures and three image datasets. We evaluate the proposed ME attack performance using various metrics, including accuracy, fidelity, and KL divergence. The experiments show that for different FL clients, the accuracy and fidelity of the extracted model are closely related to the size of the attack query set. Additionally, we explore a transfer learning based approach where pretrained models serve as the starting point for the extraction process. The results indicate that the accuracy and fidelity of the fine-tuned pretrained extraction models are notably higher, particularly with smaller query sets, highlighting potential advantages for attackers.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 4.4 -->
                    
                <!-- Medicine: 3.1 -->
                    
                <!-- LLMs: 2.4 -->
                    
                <!-- Computer Vision: 2.1 -->
                    
                <!-- Reinforcement Learning: 1.8 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Bayesian Optimization: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Robotics: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.23800" target="_blank" rel="noopener noreferrer">Strengthening Cybersecurity Resilience in Agriculture Through Educational Interventions: A Case Study of the Ponca Tribe of Nebraska</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: George Grispos, Logan Mears, Larry Loucks
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The increasing digitization of agricultural operations has introduced new cybersecurity challenges for the farming community. This paper introduces an educational intervention called Cybersecurity Improvement Initiative for Agriculture (CIIA), which aims to strengthen cybersecurity awareness and res</span>
                
                <span class="abstract-full" style="display: none;">The increasing digitization of agricultural operations has introduced new cybersecurity challenges for the farming community. This paper introduces an educational intervention called Cybersecurity Improvement Initiative for Agriculture (CIIA), which aims to strengthen cybersecurity awareness and resilience among farmers and food producers. Using a case study that focuses on farmers from the Ponca Tribe of Nebraska, the research evaluates pre- and post- intervention survey data to assess participants' cybersecurity knowledge and awareness before and after exposure to the CIIA. The findings reveal a substantial baseline deficiency in cybersecurity education among participants, however, post-intervention assessments demonstrate improvements in the comprehension of cybersecurity concepts, such as password hygiene, multi-factor authentication, and the necessity of routine data backups. These initial findings highlight the need for a continued and sustained, community-specific cybersecurity education effort to help mitigate emerging cyber threats in the agricultural sector.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.1 -->
                    
                <!-- LLMs: 4.0 -->
                    
                <!-- Hardware: 2.7 -->
                    
                <!-- Blockchain: 2.3 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.23801" target="_blank" rel="noopener noreferrer">SEMFED: Semantic-Aware Resource-Efficient Federated Learning for Heterogeneous NLP Tasks</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Sajid Hussain, Muhammad Sohail, Nauman Ali Khan
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Background: Federated Learning (FL) has emerged as a promising paradigm for training machine learning models while preserving data privacy. However, applying FL to Natural Language Processing (NLP) tasks presents unique challenges due to semantic heterogeneity across clients, vocabulary mismatches, </span>
                
                <span class="abstract-full" style="display: none;">Background: Federated Learning (FL) has emerged as a promising paradigm for training machine learning models while preserving data privacy. However, applying FL to Natural Language Processing (NLP) tasks presents unique challenges due to semantic heterogeneity across clients, vocabulary mismatches, and varying resource constraints on edge devices. Objectives: This paper introduces SEMFED, a novel semantic-aware resource-efficient federated learning framework specifically designed for heterogeneous NLP tasks. Methods: SEMFED incorporates three key innovations: (1) a semantic-aware client selection mechanism that balances semantic diversity with resource constraints, (2) adaptive NLP-specific model architectures tailored to device capabilities while preserving semantic information, and (3) a communication-efficient semantic feature compression technique that significantly reduces bandwidth requirements. Results: Experimental results on various NLP classification tasks demonstrate that SEMFED achieves an 80.5% reduction in communication costs while maintaining model accuracy above 98%, outperforming state-of-the-art FL approaches. Conclusion: SEMFED effectively manages heterogeneous client environments with varying computational resources, network reliability, and semantic data distributions, making it particularly suitable for real-world federated NLP deployments.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.9 -->
                    
                <!-- LLMs: 4.6 -->
                    
                <!-- Federated Learning: 4.4 -->
                    
                <!-- GNN: 2.8 -->
                    
                <!-- Computer Vision: 2.7 -->
                    
                <!-- Quantum Computing: 2.5 -->
                    
                <!-- HPO and AutoML: 2.5 -->
                    
                <!-- 3D: 2.3 -->
                    
                <!-- Decision Trees: 2.1 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- T2I: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.23805" target="_blank" rel="noopener noreferrer">ADA: Automated Moving Target Defense for AI Workloads via Ephemeral Infrastructure-Native Rotation in Kubernetes</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Akram Sheriff, Ken Huang, Zsolt Nemeth, Madjid Nakhjiri
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper introduces the Adaptive Defense Agent (ADA), an innovative Automated Moving Target Defense (AMTD) system designed to fundamentally enhance the security posture of AI workloads. ADA operates by continuously and automatically rotating these workloads at the infrastructure level, leveraging </span>
                
                <span class="abstract-full" style="display: none;">This paper introduces the Adaptive Defense Agent (ADA), an innovative Automated Moving Target Defense (AMTD) system designed to fundamentally enhance the security posture of AI workloads. ADA operates by continuously and automatically rotating these workloads at the infrastructure level, leveraging the inherent ephemerality of Kubernetes pods. This constant managed churn systematically invalidates attacker assumptions and disrupts potential kill chains by regularly destroying and respawning AI service instances. This methodology, applying principles of chaos engineering as a continuous, proactive defense, offers a paradigm shift from traditional static defenses that rely on complex and expensive confidential or trusted computing solutions to secure the underlying compute platforms, while at the same time agnostically supporting the latest advancements in agentic and nonagentic AI ecosystems and solutions such as agent-to-agent (A2A) communication frameworks or model context protocols (MCP). This AI-native infrastructure design, relying on the widely proliferated cloud-native Kubernetes technologies, facilitates easier deployment, simplifies maintenance through an inherent zero trust posture achieved by rotation, and promotes faster adoption. We posit that ADA's novel approach to AMTD provides a more robust, agile, and operationally efficient zero-trust model for AI services, achieving security through proactive environmental manipulation rather than reactive patching.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.3 -->
                    
                <!-- Medicine: 3.3 -->
                    
                <!-- Blockchain: 2.8 -->
                    
                <!-- Hardware: 2.4 -->
                    
                <!-- Computer Vision: 2.2 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.23812" target="_blank" rel="noopener noreferrer">Emotion-aware Dual Cross-Attentive Neural Network with Label Fusion for Stance Detection in Misinformative Social Media Content</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Lata Pangtey, Mohammad Zia Ur Rehman, Prasad Chaudhari, Shubhi Bansal, Nagendra Kumar
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The rapid evolution of social media has generated an overwhelming volume of user-generated content, conveying implicit opinions and contributing to the spread of misinformation. The method aims to enhance the detection of stance where misinformation can polarize user opinions. Stance detection has e</span>
                
                <span class="abstract-full" style="display: none;">The rapid evolution of social media has generated an overwhelming volume of user-generated content, conveying implicit opinions and contributing to the spread of misinformation. The method aims to enhance the detection of stance where misinformation can polarize user opinions. Stance detection has emerged as a crucial approach to effectively analyze underlying biases in shared information and combating misinformation. This paper proposes a novel method for \textbf{S}tance \textbf{P}rediction through a \textbf{L}abel-fused dual cross-\textbf{A}ttentive \textbf{E}motion-aware neural \textbf{Net}work (SPLAENet) in misinformative social media user-generated content. The proposed method employs a dual cross-attention mechanism and a hierarchical attention network to capture inter and intra-relationships by focusing on the relevant parts of source text in the context of reply text and vice versa. We incorporate emotions to effectively distinguish between different stance categories by leveraging the emotional alignment or divergence between the texts. We also employ label fusion that uses distance-metric learning to align extracted features with stance labels, improving the method's ability to accurately distinguish between stances. Extensive experiments demonstrate the significant improvements achieved by SPLAENet over existing state-of-the-art methods. SPLAENet demonstrates an average gain of 8.92\% in accuracy and 17.36\% in F1-score on the RumourEval dataset. On the SemEval dataset, it achieves average gains of 7.02\% in accuracy and 10.92\% in F1-score. On the P-stance dataset, it demonstrates average gains of 10.03\% in accuracy and 11.18\% in F1-score. These results validate the effectiveness of the proposed method for stance detection in the context of misinformative social media content.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 3.6 -->
                    
                <!-- Medicine: 2.2 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.23813" target="_blank" rel="noopener noreferrer">DP-RTFL: Differentially Private Resilient Temporal Federated Learning for Trustworthy AI in Regulated Industries</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Abhijit Talluri
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Federated Learning (FL) has emerged as a critical paradigm for enabling privacy-preserving machine learning, particularly in regulated sectors such as finance and healthcare. However, standard FL strategies often encounter significant operational challenges related to fault tolerance, system resilie</span>
                
                <span class="abstract-full" style="display: none;">Federated Learning (FL) has emerged as a critical paradigm for enabling privacy-preserving machine learning, particularly in regulated sectors such as finance and healthcare. However, standard FL strategies often encounter significant operational challenges related to fault tolerance, system resilience against concurrent client and server failures, and the provision of robust, verifiable privacy guarantees essential for handling sensitive data. These deficiencies can lead to training disruptions, data loss, compromised model integrity, and non-compliance with data protection regulations (e.g., GDPR, CCPA). This paper introduces Differentially Private Resilient Temporal Federated Learning (DP-RTFL), an advanced FL framework designed to ensure training continuity, precise state recovery, and strong data privacy. DP-RTFL integrates local Differential Privacy (LDP) at the client level with resilient temporal state management and integrity verification mechanisms, such as hash-based commitments (referred to as Zero-Knowledge Integrity Proofs or ZKIPs in this context). The framework is particularly suited for critical applications like credit risk assessment using sensitive financial data, aiming to be operationally robust, auditable, and scalable for enterprise AI deployments. The implementation of the DP-RTFL framework is available as open-source.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.7 -->
                    
                <!-- LLMs: 3.2 -->
                    
                <!-- Hardware: 3.1 -->
                    
                <!-- HPO and AutoML: 2.8 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- Blockchain: 2.0 -->
                    
                <!-- Decision Trees: 1.9 -->
                    
                <!-- Datasets: 1.8 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.23821" target="_blank" rel="noopener noreferrer">SpeechVerifier: Robust Acoustic Fingerprint against Tampering Attacks via Watermarking</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Lingfeng Yao (University of Houston), Chenpei Huang (University of Houston), Shengyao Wang (Waseda University), Junpei Xue (Waseda University), Hanqing Guo (University of Hawaii at M\=anoa), Jiang Liu (Waseda University), Xun Chen (Independent Researcher), Miao Pan (University of Houston)
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">With the surge of social media, maliciously tampered public speeches, especially those from influential figures, have seriously affected social stability and public trust. Existing speech tampering detection methods remain insufficient: they either rely on external reference data or fail to be both </span>
                
                <span class="abstract-full" style="display: none;">With the surge of social media, maliciously tampered public speeches, especially those from influential figures, have seriously affected social stability and public trust. Existing speech tampering detection methods remain insufficient: they either rely on external reference data or fail to be both sensitive to attacks and robust to benign operations, such as compression and resampling. To tackle these challenges, we introduce SpeechVerifer to proactively verify speech integrity using only the published speech itself, i.e., without requiring any external references. Inspired by audio fingerprinting and watermarking, SpeechVerifier can (i) effectively detect tampering attacks, (ii) be robust to benign operations and (iii) verify the integrity only based on published speeches. Briefly, SpeechVerifier utilizes multiscale feature extraction to capture speech features across different temporal resolutions. Then, it employs contrastive learning to generate fingerprints that can detect modifications at varying granularities. These fingerprints are designed to be robust to benign operations, but exhibit significant changes when malicious tampering occurs. To enable speech verification in a self-contained manner, the generated fingerprints are then embedded into the speech signal by segment-wise watermarking. Without external references, SpeechVerifier can retrieve the fingerprint from the published audio and check it with the embedded watermark to verify the integrity of the speech. Extensive experimental results demonstrate that the proposed SpeechVerifier is effective in detecting tampering attacks and robust to benign operations.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 3.2 -->
                    
                <!-- Computer Vision: 3.1 -->
                    
                <!-- LLMs: 2.8 -->
                    
                <!-- GNN: 2.6 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- Medicine: 1.5 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.23822" target="_blank" rel="noopener noreferrer">Speech as a Multimodal Digital Phenotype for Multi-Task LLM-based Mental Health Prediction</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Mai Ali, Christopher Lucasius, Tanmay P. Patel, Madison Aitken, Jacob Vorstman, Peter Szatmari, Marco Battaglia, Deepa Kundur
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Speech is a noninvasive digital phenotype that can offer valuable insights into mental health conditions, but it is often treated as a single modality. In contrast, we propose the treatment of patient speech data as a trimodal multimedia data source for depression detection. This study explores the </span>
                
                <span class="abstract-full" style="display: none;">Speech is a noninvasive digital phenotype that can offer valuable insights into mental health conditions, but it is often treated as a single modality. In contrast, we propose the treatment of patient speech data as a trimodal multimedia data source for depression detection. This study explores the potential of large language model-based architectures for speech-based depression prediction in a multimodal regime that integrates speech-derived text, acoustic landmarks, and vocal biomarkers. Adolescent depression presents a significant challenge and is often comorbid with multiple disorders, such as suicidal ideation and sleep disturbances. This presents an additional opportunity to integrate multi-task learning (MTL) into our study by simultaneously predicting depression, suicidal ideation, and sleep disturbances using the multimodal formulation. We also propose a longitudinal analysis strategy that models temporal changes across multiple clinical interactions, allowing for a comprehensive understanding of the conditions' progression. Our proposed approach, featuring trimodal, longitudinal MTL is evaluated on the Depression Early Warning dataset. It achieves a balanced accuracy of 70.8%, which is higher than each of the unimodal, single-task, and non-longitudinal methods.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.7 -->
                    
                <!-- LLMs: 3.5 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- Networks: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- 3D: 1.1 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.23825" target="_blank" rel="noopener noreferrer">Privacy-Preserving Inconsistency Measurement</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Carl Corea, Timotheus Kampik, Nico Potyka
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We investigate a new form of (privacy-preserving) inconsistency measurement for multi-party communication. Intuitively, for two knowledge bases K_A, K_B (of two agents A, B), our results allow to quantitatively assess the degree of inconsistency for K_A U K_B without having to reveal the actual cont</span>
                
                <span class="abstract-full" style="display: none;">We investigate a new form of (privacy-preserving) inconsistency measurement for multi-party communication. Intuitively, for two knowledge bases K_A, K_B (of two agents A, B), our results allow to quantitatively assess the degree of inconsistency for K_A U K_B without having to reveal the actual contents of the knowledge bases. Using secure multi-party computation (SMPC) and cryptographic protocols, we develop two concrete methods for this use-case and show that they satisfy important properties of SMPC protocols -- notably, input privacy, i.e., jointly computing the inconsistency degree without revealing the inputs.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.2 -->
                    
                <!-- LLMs: 3.4 -->
                    
                <!-- Federated Learning: 2.5 -->
                    
                <!-- Quantum Computing: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Bayesian Optimization: 1.8 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Math: 1.1 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.23845" target="_blank" rel="noopener noreferrer">Read Your Own Mind: Reasoning Helps Surface Self-Confidence Signals in LLMs</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jakub Podolak, Rajeev Verma
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We study the source of uncertainty in DeepSeek R1-32B by analyzing its self-reported verbal confidence on question answering (QA) tasks. In the default answer-then-confidence setting, the model is regularly over-confident, whereas semantic entropy - obtained by sampling many responses - remains reli</span>
                
                <span class="abstract-full" style="display: none;">We study the source of uncertainty in DeepSeek R1-32B by analyzing its self-reported verbal confidence on question answering (QA) tasks. In the default answer-then-confidence setting, the model is regularly over-confident, whereas semantic entropy - obtained by sampling many responses - remains reliable. We hypothesize that this is because of semantic entropy's larger test-time compute, which lets us explore the model's predictive distribution. We show that granting DeepSeek the budget to explore its distribution by forcing a long chain-of-thought before the final answer greatly improves its verbal score effectiveness, even on simple fact-retrieval questions that normally require no reasoning. Furthermore, a separate reader model that sees only the chain can reconstruct very similar confidences, indicating the verbal score might be merely a statistic of the alternatives surfaced during reasoning. Our analysis concludes that reliable uncertainty estimation requires explicit exploration of the generative space, and self-reported confidence is trustworthy only after such exploration.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.3 -->
                    
                <!-- Math: 2.8 -->
                    
                <!-- Cryptography: 2.4 -->
                    
                <!-- Bayesian Optimization: 2.1 -->
                    
                <!-- Quantum Computing: 2.1 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Networks: 1.9 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Finance: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Game Theory: 1.4 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Medicine: 1.3 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.23846" target="_blank" rel="noopener noreferrer">Scalable, Symbiotic, AI and Non-AI Agent Based Parallel Discrete Event Simulations</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Atanu Barai, Stephan Eidenbenz, Nandakishore Santhi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">To fully leverage the potential of artificial intelligence (AI) systems in a trustworthy manner, it is desirable to couple multiple AI and non-AI systems together seamlessly for constraining and ensuring correctness of the output. This paper introduces a novel parallel discrete event simulation (PDE</span>
                
                <span class="abstract-full" style="display: none;">To fully leverage the potential of artificial intelligence (AI) systems in a trustworthy manner, it is desirable to couple multiple AI and non-AI systems together seamlessly for constraining and ensuring correctness of the output. This paper introduces a novel parallel discrete event simulation (PDES) based methodology to combine multiple AI and non-AI agents in a causal, rule-based way. Our approach tightly integrates the concept of passage of time, with each agent considered as an entity in the PDES framework and responding to prior requests from other agents. Such coupling mechanism enables the agents to work in a co-operative environment towards a common goal while many tasks run in parallel throughout the simulation. It further enables setting up boundaries to the outputs of the AI agents by applying necessary dynamic constraints using non-AI agents while allowing for scalability through deployment of hundreds of such agents in a larger compute cluster. Distributing smaller AI agents can enable extremely scalable simulations in the future, addressing local memory bottlenecks for model parameter storage. Within a PDES involving both AI and non-AI agents, we break down the problem at hand into structured steps, when necessary, providing a set of multiple choices to the AI agents, and then progressively solve these steps towards a final goal. At each step, the non-AI agents act as unbiased auditors, verifying each action by the AI agents so that certain rules of engagement are followed. We evaluate our approach by solving four problems from four different domains and comparing the results with those from AI models alone. Our results show greater accuracy in solving problems from various domains where the AI models struggle to solve the problems solely by themselves. Results show that overall accuracy of our approach is 68% where as the accuracy of vanilla models is less than 23%.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 3.9 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- Reinforcement Learning: 2.0 -->
                    
                <!-- Medicine: 1.8 -->
                    
                <!-- Networks: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Robotics: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.4 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Hardware: 1.1 -->
                    
                <!-- Math: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.23861" target="_blank" rel="noopener noreferrer">BiBLDR: Bidirectional Behavior Learning for Drug Repositioning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Renye Zhang, Mengyun Yang, Qichang Zhao, Jianxin Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Drug repositioning aims to identify potential new indications for existing drugs to reduce the time and financial costs associated with developing new drugs. Most existing deep learning-based drug repositioning methods predominantly utilize graph-based representations. However, graph-based drug repo</span>
                
                <span class="abstract-full" style="display: none;">Drug repositioning aims to identify potential new indications for existing drugs to reduce the time and financial costs associated with developing new drugs. Most existing deep learning-based drug repositioning methods predominantly utilize graph-based representations. However, graph-based drug repositioning methods struggle to perform effective inference in cold-start scenarios involving novel drugs because of the lack of association information with the diseases. Unlike traditional graph-based approaches, we propose a bidirectional behavior learning strategy for drug repositioning, known as BiBLDR. This innovative framework redefines drug repositioning as a behavior sequential learning task to capture drug-disease interaction patterns. First, we construct bidirectional behavioral sequences based on drug and disease sides. The consideration of bidirectional information ensures a more meticulous and rigorous characterization of the behavioral sequences. Subsequently, we propose a two-stage strategy for drug repositioning. In the first stage, we construct prototype spaces to characterize the representational attributes of drugs and diseases. In the second stage, these refined prototypes and bidirectional behavior sequence data are leveraged to predict potential drug-disease associations. Based on this learning approach, the model can more robustly and precisely capture the interactive relationships between drug and disease features from bidirectional behavioral sequences. Extensive experiments demonstrate that our method achieves state-of-the-art performance on benchmark datasets. Meanwhile, BiBLDR demonstrates significantly superior performance compared to previous methods in cold-start scenarios. Our code is published in https://github.com/Renyeeah/BiBLDR.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 3.6 -->
                    
                <!-- Computer Vision: 3.3 -->
                    
                <!-- Federated Learning: 2.8 -->
                    
                <!-- LLMs: 2.7 -->
                    
                <!-- GNN: 2.4 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                <!-- 3D: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.23868" target="_blank" rel="noopener noreferrer">Noise-Robustness Through Noise: Asymmetric LoRA Adaption with Poisoning Expert</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zhaokun Wang, Jinyu Guo, Jingwen Pu, Lingfeng Chen, Hongli Pu, Jie Ou. Libo Qin, Wenhong Tian
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Current parameter-efficient fine-tuning methods for adapting pre-trained language models to downstream tasks are susceptible to interference from noisy data. Conventional noise-handling approaches either rely on laborious data pre-processing or employ model architecture modifications prone to error </span>
                
                <span class="abstract-full" style="display: none;">Current parameter-efficient fine-tuning methods for adapting pre-trained language models to downstream tasks are susceptible to interference from noisy data. Conventional noise-handling approaches either rely on laborious data pre-processing or employ model architecture modifications prone to error accumulation. In contrast to existing noise-process paradigms, we propose a noise-robust adaptation method via asymmetric LoRA poisoning experts (LoPE), a novel framework that enhances model robustness to noise only with generated noisy data. Drawing inspiration from the mixture-of-experts architecture, LoPE strategically integrates a dedicated poisoning expert in an asymmetric LoRA configuration. Through a two-stage paradigm, LoPE performs noise injection on the poisoning expert during fine-tuning to enhance its noise discrimination and processing ability. During inference, we selectively mask the dedicated poisoning expert to leverage purified knowledge acquired by normal experts for noise-robust output. Extensive experiments demonstrate that LoPE achieves strong performance and robustness purely through the low-cost noise injection, which completely eliminates the requirement of data cleaning.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.4 -->
                    
                <!-- Computer Vision: 3.5 -->
                    
                <!-- Medicine: 3.2 -->
                    
                <!-- Federated Learning: 3.0 -->
                    
                <!-- GNN: 3.0 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Hardware: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.23871" target="_blank" rel="noopener noreferrer">ADG: Ambient Diffusion-Guided Dataset Recovery for Corruption-Robust Offline Reinforcement Learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zeyuan Liu, Zhihe Yang, Jiawei Xu, Rui Yang, Jiafei Lyu, Baoxiang Wang, Yunjian Xu, Xiu Li
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Real-world datasets collected from sensors or human inputs are prone to noise and errors, posing significant challenges for applying offline reinforcement learning (RL). While existing methods have made progress in addressing corrupted actions and rewards, they remain insufficient for handling corru</span>
                
                <span class="abstract-full" style="display: none;">Real-world datasets collected from sensors or human inputs are prone to noise and errors, posing significant challenges for applying offline reinforcement learning (RL). While existing methods have made progress in addressing corrupted actions and rewards, they remain insufficient for handling corruption in high-dimensional state spaces and for cases where multiple elements in the dataset are corrupted simultaneously. Diffusion models, known for their strong denoising capabilities, offer a promising direction for this problem-but their tendency to overfit noisy samples limits their direct applicability. To overcome this, we propose Ambient Diffusion-Guided Dataset Recovery (ADG), a novel approach that pioneers the use of diffusion models to tackle data corruption in offline RL. First, we introduce Ambient Denoising Diffusion Probabilistic Models (DDPM) from approximated distributions, which enable learning on partially corrupted datasets with theoretical guarantees. Second, we use the noise-prediction property of Ambient DDPM to distinguish between clean and corrupted data, and then use the clean subset to train a standard DDPM. Third, we employ the trained standard DDPM to refine the previously identified corrupted data, enhancing data quality for subsequent offline RL training. A notable strength of ADG is its versatility-it can be seamlessly integrated with any offline RL algorithm. Experiments on a range of benchmarks, including MuJoCo, Kitchen, and Adroit, demonstrate that ADG effectively mitigates the impact of corrupted data and improves the robustness of offline RL under various noise settings, achieving state-of-the-art results.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.4 -->
                    
                <!-- LLMs: 3.0 -->
                    
                <!-- Federated Learning: 2.3 -->
                    
                <!-- Reinforcement Learning: 1.9 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.23873" target="_blank" rel="noopener noreferrer">KGMark: A Diffusion Watermark for Knowledge Graphs</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Hongrui Peng, Haolang Lu, Yuanlong Yu, Weiye Fu, Kun Wang, Guoshun Nan
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Knowledge graphs (KGs) are ubiquitous in numerous real-world applications, and watermarking facilitates protecting intellectual property and preventing potential harm from AI-generated content. Existing watermarking methods mainly focus on static plain text or image data, while they can hardly be ap</span>
                
                <span class="abstract-full" style="display: none;">Knowledge graphs (KGs) are ubiquitous in numerous real-world applications, and watermarking facilitates protecting intellectual property and preventing potential harm from AI-generated content. Existing watermarking methods mainly focus on static plain text or image data, while they can hardly be applied to dynamic graphs due to spatial and temporal variations of structured data. This motivates us to propose KGMARK, the first graph watermarking framework that aims to generate robust, detectable, and transparent diffusion fingerprints for dynamic KG data. Specifically, we propose a novel clustering-based alignment method to adapt the watermark to spatial variations. Meanwhile, we present a redundant embedding strategy to harden the diffusion watermark against various attacks, facilitating the robustness of the watermark to the temporal variations. Additionally, we introduce a novel learnable mask matrix to improve the transparency of diffusion fingerprints. By doing so, our KGMARK properly tackles the variation challenges of structured data. Experiments on various public benchmarks show the effectiveness of our proposed KGMARK.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 4.1 -->
                    
                <!-- GNN: 3.4 -->
                    
                <!-- LLMs: 3.1 -->
                    
                <!-- Computer Vision: 2.9 -->
                    
                <!-- Evolutionary Algorithms: 2.3 -->
                    
                <!-- Medicine: 1.9 -->
                    
                <!-- Bayesian Optimization: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Hardware: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.23875" target="_blank" rel="noopener noreferrer">A Benchmark Dataset for Graph Regression with Homogeneous and Multi-Relational Variants</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Peter Samoaa, Marcus Vukojevic, Morteza Haghir Chehreghani, Antonio Longa
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Graph-level regression underpins many real-world applications, yet public benchmarks remain heavily skewed toward molecular graphs and citation networks. This limited diversity hinders progress on models that must generalize across both homogeneous and heterogeneous graph structures. We introduce Re</span>
                
                <span class="abstract-full" style="display: none;">Graph-level regression underpins many real-world applications, yet public benchmarks remain heavily skewed toward molecular graphs and citation networks. This limited diversity hinders progress on models that must generalize across both homogeneous and heterogeneous graph structures. We introduce RelSC, a new graph-regression dataset built from program graphs that combine syntactic and semantic information extracted from source code. Each graph is labelled with the execution-time cost of the corresponding program, providing a continuous target variable that differs markedly from those found in existing benchmarks. RelSC is released in two complementary variants. RelSC-H supplies rich node features under a single (homogeneous) edge type, while RelSC-M preserves the original multi-relational structure, connecting nodes through multiple edge types that encode distinct semantic relationships. Together, these variants let researchers probe how representation choice influences model behaviour. We evaluate a diverse set of graph neural network architectures on both variants of RelSC. The results reveal consistent performance differences between the homogeneous and multi-relational settings, emphasising the importance of structural representation. These findings demonstrate RelSC's value as a challenging and versatile benchmark for advancing graph regression methods.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.6 -->
                    
                <!-- LLMs: 4.5 -->
                    
                <!-- GNN: 3.7 -->
                    
                <!-- Datasets: 1.9 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.23939" target="_blank" rel="noopener noreferrer">Searching Neural Architectures for Sensor Nodes on IoT Gateways</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Andrea Mattia Garavagno, Edoardo Ragusa, Antonio Frisoli, Paolo Gastaldo
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper presents an automatic method for the design of Neural Networks (NNs) at the edge, enabling Machine Learning (ML) access even in privacy-sensitive Internet of Things (IoT) applications. The proposed method runs on IoT gateways and designs NNs for connected sensor nodes without sharing the </span>
                
                <span class="abstract-full" style="display: none;">This paper presents an automatic method for the design of Neural Networks (NNs) at the edge, enabling Machine Learning (ML) access even in privacy-sensitive Internet of Things (IoT) applications. The proposed method runs on IoT gateways and designs NNs for connected sensor nodes without sharing the collected data outside the local network, keeping the data in the site of collection. This approach has the potential to enable ML for Healthcare Internet of Things (HIoT) and Industrial Internet of Things (IIoT), designing hardware-friendly and custom NNs at the edge for personalized healthcare and advanced industrial services such as quality control, predictive maintenance, or fault diagnosis. By preventing data from being disclosed to cloud services, this method safeguards sensitive information, including industrial secrets and personal data. The outcomes of a thorough experimental session confirm that -- on the Visual Wake Words dataset -- the proposed approach can achieve state-of-the-art results by exploiting a search procedure that runs in less than 10 hours on the Raspberry Pi Zero 2.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.5 -->
                    
                <!-- Hardware: 3.5 -->
                    
                <!-- Federated Learning: 2.3 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- LLMs: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Finance: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.23947" target="_blank" rel="noopener noreferrer">Position: The Future of Bayesian Prediction Is Prior-Fitted</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Samuel M\"uller, Arik Reuter, Noah Hollmann, David R\"ugamer, Frank Hutter
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Training neural networks on randomly generated artificial datasets yields Bayesian models that capture the prior defined by the dataset-generating distribution. Prior-data Fitted Networks (PFNs) are a class of methods designed to leverage this insight. In an era of rapidly increasing computational r</span>
                
                <span class="abstract-full" style="display: none;">Training neural networks on randomly generated artificial datasets yields Bayesian models that capture the prior defined by the dataset-generating distribution. Prior-data Fitted Networks (PFNs) are a class of methods designed to leverage this insight. In an era of rapidly increasing computational resources for pre-training and a near stagnation in the generation of new real-world data in many applications, PFNs are poised to play a more important role across a wide range of applications. They enable the efficient allocation of pre-training compute to low-data scenarios. Originally applied to small Bayesian modeling tasks, the field of PFNs has significantly expanded to address more complex domains and larger datasets. This position paper argues that PFNs and other amortized inference approaches represent the future of Bayesian inference, leveraging amortized learning to tackle data-scarce problems. We thus believe they are a fruitful area of research. In this position paper, we explore their potential and directions to address their current limitations.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.7 -->
                    
                <!-- Federated Learning: 4.3 -->
                    
                <!-- Evolutionary Algorithms: 2.9 -->
                    
                <!-- Bayesian Optimization: 2.6 -->
                    
                <!-- GNN: 2.1 -->
                    
                <!-- Medicine: 2.1 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.23952" target="_blank" rel="noopener noreferrer">Leveraging Auxiliary Information in Text-to-Video Retrieval: A Review</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Adriano Fragomeni, Dima Damen, Michael Wray
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Text-to-Video (T2V) retrieval aims to identify the most relevant item from a gallery of videos based on a user's text query. Traditional methods rely solely on aligning video and text modalities to compute the similarity and retrieve relevant items. However, recent advancements emphasise incorporati</span>
                
                <span class="abstract-full" style="display: none;">Text-to-Video (T2V) retrieval aims to identify the most relevant item from a gallery of videos based on a user's text query. Traditional methods rely solely on aligning video and text modalities to compute the similarity and retrieve relevant items. However, recent advancements emphasise incorporating auxiliary information extracted from video and text modalities to improve retrieval performance and bridge the semantic gap between these modalities. Auxiliary information can include visual attributes, such as objects; temporal and spatial context; and textual descriptions, such as speech and rephrased captions. This survey comprehensively reviews 81 research papers on Text-to-Video retrieval that utilise such auxiliary information. It provides a detailed analysis of their methodologies; highlights state-of-the-art results on benchmark datasets; and discusses available datasets and their auxiliary information. Additionally, it proposes promising directions for future research, focusing on different ways to further enhance retrieval performance using this information.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 3.9 -->
                    
                <!-- Computer Vision: 3.0 -->
                    
                <!-- Medicine: 2.8 -->
                    
                <!-- Blockchain: 2.5 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Decision Trees: 1.8 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.23961" target="_blank" rel="noopener noreferrer">MangoLeafViT: Leveraging Lightweight Vision Transformer with Runtime Augmentation for Efficient Mango Leaf Disease Classification</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Rafi Hassan Chowdhury, Sabbir Ahmed
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Ensuring food safety is critical due to its profound impact on public health, economic stability, and global supply chains. Cultivation of Mango, a major agricultural product in several South Asian countries, faces high financial losses due to different diseases, affecting various aspects of the ent</span>
                
                <span class="abstract-full" style="display: none;">Ensuring food safety is critical due to its profound impact on public health, economic stability, and global supply chains. Cultivation of Mango, a major agricultural product in several South Asian countries, faces high financial losses due to different diseases, affecting various aspects of the entire supply chain. While deep learning-based methods have been explored for mango leaf disease classification, there remains a gap in designing solutions that are computationally efficient and compatible with low-end devices. In this work, we propose a lightweight Vision Transformer-based pipeline with a self-attention mechanism to classify mango leaf diseases, achieving state-of-the-art performance with minimal computational overhead. Our approach leverages global attention to capture intricate patterns among disease types and incorporates runtime augmentation for enhanced performance. Evaluation on the MangoLeafBD dataset demonstrates a 99.43% accuracy, outperforming existing methods in terms of model size, parameter count, and FLOPs count.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 5.0 -->
                    
                <!-- LLMs: 4.5 -->
                    
                <!-- Federated Learning: 3.3 -->
                    
                <!-- GNN: 2.4 -->
                    
                <!-- Computer Vision: 2.4 -->
                    
                <!-- Evolutionary Algorithms: 2.3 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.23967" target="_blank" rel="noopener noreferrer">Improved Approximations for Hard Graph Problems using Predictions</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Anders Aamand, Justin Y. Chen, Siddharth Gollapudi, Sandeep Silwal, Hao Wu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We design improved approximation algorithms for NP-hard graph problems by incorporating predictions (e.g., learned from past data). Our prediction model builds upon and extends the $\varepsilon$-prediction framework by Cohen-Addad, d'Orsi, Gupta, Lee, and Panigrahi (NeurIPS 2024). We consider an edg</span>
                
                <span class="abstract-full" style="display: none;">We design improved approximation algorithms for NP-hard graph problems by incorporating predictions (e.g., learned from past data). Our prediction model builds upon and extends the $\varepsilon$-prediction framework by Cohen-Addad, d'Orsi, Gupta, Lee, and Panigrahi (NeurIPS 2024). We consider an edge-based version of this model, where each edge provides two bits of information, corresponding to predictions about whether each of its endpoints belong to an optimal solution. Even with weak predictions where each bit is only $\varepsilon$-correlated with the true solution, this information allows us to break approximation barriers in the standard setting. We develop algorithms with improved approximation ratios for MaxCut, Vertex Cover, Set Cover, and Maximum Independent Set problems (among others). Across these problems, our algorithms share a unifying theme, where we separately satisfy constraints related to high degree vertices (using predictions) and low-degree vertices (without using predictions) and carefully combine the answers.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.6 -->
                    
                <!-- LLMs: 4.3 -->
                    
                <!-- Federated Learning: 2.7 -->
                    
                <!-- Evolutionary Algorithms: 2.2 -->
                    
                <!-- Computer Vision: 1.9 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Datasets: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.23968" target="_blank" rel="noopener noreferrer">Confidential Guardian: Cryptographically Prohibiting the Abuse of Model Abstention</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Stephan Rabanser, Ali Shahin Shamsabadi, Olive Franzese, Xiao Wang, Adrian Weller, Nicolas Papernot
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Cautious predictions -- where a machine learning model abstains when uncertain -- are crucial for limiting harmful errors in safety-critical applications. In this work, we identify a novel threat: a dishonest institution can exploit these mechanisms to discriminate or unjustly deny services under th</span>
                
                <span class="abstract-full" style="display: none;">Cautious predictions -- where a machine learning model abstains when uncertain -- are crucial for limiting harmful errors in safety-critical applications. In this work, we identify a novel threat: a dishonest institution can exploit these mechanisms to discriminate or unjustly deny services under the guise of uncertainty. We demonstrate the practicality of this threat by introducing an uncertainty-inducing attack called Mirage, which deliberately reduces confidence in targeted input regions, thereby covertly disadvantaging specific individuals. At the same time, Mirage maintains high predictive performance across all data points. To counter this threat, we propose Confidential Guardian, a framework that analyzes calibration metrics on a reference dataset to detect artificially suppressed confidence. Additionally, it employs zero-knowledge proofs of verified inference to ensure that reported confidence scores genuinely originate from the deployed model. This prevents the provider from fabricating arbitrary model confidence values while protecting the model's proprietary details. Our results confirm that Confidential Guardian effectively prevents the misuse of cautious predictions, providing verifiable assurances that abstention reflects genuine model uncertainty rather than malicious intent.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 4.1 -->
                    
                <!-- LLMs: 4.1 -->
                    
                <!-- GNN: 3.1 -->
                    
                <!-- Medicine: 2.8 -->
                    
                <!-- Bayesian Optimization: 2.2 -->
                    
                <!-- Quantum Computing: 2.1 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Reinforcement Learning: 1.8 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Cryptography: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.23969" target="_blank" rel="noopener noreferrer">Force-Dual Modes: Subspace Design from Stochastic Forces</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Otman Benchekroun, Eitan Grinspun, Maurizio Chiaramonte, Philip Allen Etter
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Designing subspaces for Reduced Order Modeling (ROM) is crucial for accelerating finite element simulations in graphics and engineering. Unfortunately, it's not always clear which subspace is optimal for arbitrary dynamic simulation. We propose to construct simulation subspaces from force distributi</span>
                
                <span class="abstract-full" style="display: none;">Designing subspaces for Reduced Order Modeling (ROM) is crucial for accelerating finite element simulations in graphics and engineering. Unfortunately, it's not always clear which subspace is optimal for arbitrary dynamic simulation. We propose to construct simulation subspaces from force distributions, allowing us to tailor such subspaces to common scene interactions involving constraint penalties, handles-based control, contact and musculoskeletal actuation. To achieve this we adopt a statistical perspective on Reduced Order Modelling, which allows us to push such user-designed force distributions through a linearized simulation to obtain a dual distribution on displacements. To construct our subspace, we then fit a low-rank Gaussian model to this displacement distribution, which we show generalizes Linear Modal Analysis subspaces for uncorrelated unit variance force distributions, as well as Green's Function subspaces for low rank force distributions. We show our framework allows for the construction of subspaces that are optimal both with respect to physical material properties, as well as arbitrary force distributions as observed in handle-based, contact, and musculoskeletal scene interactions.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 2.8 -->
                    
                <!-- Computer Vision: 2.6 -->
                    
                <!-- Medicine: 2.2 -->
                    
                <!-- Quantum Computing: 2.1 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- 3D: 1.8 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Networks: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.23980" target="_blank" rel="noopener noreferrer">DeepTopoNet: A Framework for Subglacial Topography Estimation on the Greenland Ice Sheets</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Bayu Adhi Tama, Mansa Krishna, Homayra Alam, Mostafa Cham, Omar Faruque, Gong Cheng, Jianwu Wang, Mathieu Morlighem, Vandana Janeja
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Understanding Greenland's subglacial topography is critical for projecting the future mass loss of the ice sheet and its contribution to global sea-level rise. However, the complex and sparse nature of observational data, particularly information about the bed topography under the ice sheet, signifi</span>
                
                <span class="abstract-full" style="display: none;">Understanding Greenland's subglacial topography is critical for projecting the future mass loss of the ice sheet and its contribution to global sea-level rise. However, the complex and sparse nature of observational data, particularly information about the bed topography under the ice sheet, significantly increases the uncertainty in model projections. Bed topography is traditionally measured by airborne ice-penetrating radar that measures the ice thickness directly underneath the aircraft, leaving data gap of tens of kilometers in between flight lines. This study introduces a deep learning framework, which we call as DeepTopoNet, that integrates radar-derived ice thickness observations and BedMachine Greenland data through a novel dynamic loss-balancing mechanism. Among all efforts to reconstruct bed topography, BedMachine has emerged as one of the most widely used datasets, combining mass conservation principles and ice thickness measurements to generate high-resolution bed elevation estimates. The proposed loss function adaptively adjusts the weighting between radar and BedMachine data, ensuring robustness in areas with limited radar coverage while leveraging the high spatial resolution of BedMachine predictions i.e. bed estimates. Our approach incorporates gradient-based and trend surface features to enhance model performance and utilizes a CNN architecture designed for subgrid-scale predictions. By systematically testing on the Upernavik Isstr{\o}m) region, the model achieves high accuracy, outperforming baseline methods in reconstructing subglacial terrain. This work demonstrates the potential of deep learning in bridging observational gaps, providing a scalable and efficient solution to inferring subglacial topography.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.5 -->
                    
                <!-- Computer Vision: 2.5 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- LLMs: 2.0 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Networks: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24005" target="_blank" rel="noopener noreferrer">How far away are truly hyperparameter-free learning algorithms?</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Priya Kasimbeg, Vincent Roulet, Naman Agarwal, Sourabh Medapati, Fabian Pedregosa, Atish Agarwala, George E. Dahl
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Despite major advances in methodology, hyperparameter tuning remains a crucial (and expensive) part of the development of machine learning systems. Even ignoring architectural choices, deep neural networks have a large number of optimization and regularization hyperparameters that need to be tuned c</span>
                
                <span class="abstract-full" style="display: none;">Despite major advances in methodology, hyperparameter tuning remains a crucial (and expensive) part of the development of machine learning systems. Even ignoring architectural choices, deep neural networks have a large number of optimization and regularization hyperparameters that need to be tuned carefully per workload in order to obtain the best results. In a perfect world, training algorithms would not require workload-specific hyperparameter tuning, but would instead have default settings that performed well across many workloads. Recently, there has been a growing literature on optimization methods which attempt to reduce the number of hyperparameters -- particularly the learning rate and its accompanying schedule. Given these developments, how far away is the dream of neural network training algorithms that completely obviate the need for painful tuning?</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Bayesian Optimization: 3.2 -->
                    
                <!-- Federated Learning: 3.1 -->
                    
                <!-- GNN: 3.0 -->
                    
                <!-- Evolutionary Algorithms: 2.5 -->
                    
                <!-- LLMs: 2.5 -->
                    
                <!-- Medicine: 2.2 -->
                    
                <!-- Quantum Computing: 2.2 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Networks: 1.1 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                <!-- Math: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24008" target="_blank" rel="noopener noreferrer">HoneySat: A Network-based Satellite Honeypot Framework</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Efr\'en L\'opez-Morales (Texas A&M University-Corpus Christi), Ulysse Planta (CISPA Helmholtz Center for Information Security), Gabriele Marra (CISPA Helmholtz Center for Information Security), Carlos Gonz\'alez (German Aerospace Center), Jacob Hopkins (Texas A&M University-Corpus Christi), Majid Garoosi (CISPA Helmholtz Center for Information Security), El\'ias Obreque (Universidad de Chile), Carlos Rubio-Medrano (Texas A&M University-Corpus Christi), Ali Abbasi (CISPA Helmholtz Center for Information Security)
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Satellites are the backbone of several mission-critical services, such as GPS that enable our modern society to function. For many years, satellites were assumed to be secure because of their indecipherable architectures and the reliance on security by obscurity. However, technological advancements </span>
                
                <span class="abstract-full" style="display: none;">Satellites are the backbone of several mission-critical services, such as GPS that enable our modern society to function. For many years, satellites were assumed to be secure because of their indecipherable architectures and the reliance on security by obscurity. However, technological advancements have made these assumptions obsolete, paving the way for potential attacks, and sparking a renewed interest in satellite security. Unfortunately, to this day, there is no efficient way to collect data on adversarial techniques for satellites, which severely hurts the generation of security intelligence. In this paper, we present HoneySat, the first high-interaction satellite honeypot framework, which is fully capable of convincingly simulating a real-world CubeSat, a type of Small Satellite (SmallSat) widely used in practice. To provide evidence of the effectiveness of HoneySat, we surveyed experienced SmallSat operators currently in charge of active in-orbit satellite missions. Results revealed that the majority of satellite operators (71.4%) agreed that HoneySat provides realistic and engaging simulations of CubeSat missions. Further experimental evaluations also showed that HoneySat provides adversaries with extensive interaction opportunities by supporting the majority of adversarial techniques (86.8%) and tactics (100%) that target satellites. Additionally, we also obtained a series of real interactions from actual adversaries by deploying HoneySat on the internet over several months, confirming that HoneySat can operate covertly and efficiently while collecting highly valuable interaction data.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.5 -->
                    
                <!-- Federated Learning: 3.8 -->
                    
                <!-- Medicine: 3.1 -->
                    
                <!-- Evolutionary Algorithms: 2.5 -->
                    
                <!-- Bayesian Optimization: 2.3 -->
                    
                <!-- Quantum Computing: 2.3 -->
                    
                <!-- Blockchain: 2.0 -->
                    
                <!-- Datasets: 1.7 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24009" target="_blank" rel="noopener noreferrer">Diversity of Transformer Layers: One Aspect of Parameter Scaling Laws</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Hidetaka Kamigaito, Ying Zhang, Jingun Kwon, Katsuhiko Hayashi, Manabu Okumura, Taro Watanabe
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Transformers deliver outstanding performance across a wide range of tasks and are now a dominant backbone architecture for large language models (LLMs). Their task-solving performance is improved by increasing parameter size, as shown in the recent studies on parameter scaling laws. Although recent </span>
                
                <span class="abstract-full" style="display: none;">Transformers deliver outstanding performance across a wide range of tasks and are now a dominant backbone architecture for large language models (LLMs). Their task-solving performance is improved by increasing parameter size, as shown in the recent studies on parameter scaling laws. Although recent mechanistic-interpretability studies have deepened our understanding of the internal behavior of Transformers by analyzing their residual stream, the relationship between these internal mechanisms and the parameter scaling laws remains unclear. To bridge this gap, we focus on layers and their size, which mainly decide the parameter size of Transformers. For this purpose, we first theoretically investigate the layers within the residual stream through a bias-diversity decomposition. The decomposition separates (i) bias, the error of each layer's output from the ground truth, and (ii) diversity, which indicates how much the outputs of each layer differ from each other. Analyzing Transformers under this theory reveals that performance improves when individual layers make predictions close to the correct answer and remain mutually diverse. We show that diversity becomes especially critical when individual layers' outputs are far from the ground truth. Finally, we introduce an information-theoretic diversity and show our main findings that adding layers enhances performance only when those layers behave differently, i.e., are diverse. We also reveal the performance gains from increasing the number of layers exhibit submodularity: marginal improvements diminish as additional layers increase, mirroring the logarithmic convergence predicted by the parameter scaling laws. Experiments on multiple semantic-understanding tasks with various LLMs empirically confirm the theoretical properties derived in this study.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 3.8 -->
                    
                <!-- Federated Learning: 3.2 -->
                    
                <!-- Medicine: 2.4 -->
                    
                <!-- Reinforcement Learning: 2.3 -->
                    
                <!-- Blockchain: 2.0 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Bayesian Optimization: 1.7 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Math: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24022" target="_blank" rel="noopener noreferrer">The Rich and the Simple: On the Implicit Bias of Adam and SGD</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Bhavya Vasudeva, Jung Whan Lee, Vatsal Sharan, Mahdi Soltanolkotabi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Adam is the de facto optimization algorithm for several deep learning applications, but an understanding of its implicit bias and how it differs from other algorithms, particularly standard first-order methods such as (stochastic) gradient descent (GD), remains limited. In practice, neural networks </span>
                
                <span class="abstract-full" style="display: none;">Adam is the de facto optimization algorithm for several deep learning applications, but an understanding of its implicit bias and how it differs from other algorithms, particularly standard first-order methods such as (stochastic) gradient descent (GD), remains limited. In practice, neural networks trained with SGD are known to exhibit simplicity bias -- a tendency to find simple solutions. In contrast, we show that Adam is more resistant to such simplicity bias. To demystify this phenomenon, in this paper, we investigate the differences in the implicit biases of Adam and GD when training two-layer ReLU neural networks on a binary classification task involving synthetic data with Gaussian clusters. We find that GD exhibits a simplicity bias, resulting in a linear decision boundary with a suboptimal margin, whereas Adam leads to much richer and more diverse features, producing a nonlinear boundary that is closer to the Bayes' optimal predictor. This richer decision boundary also allows Adam to achieve higher test accuracy both in-distribution and under certain distribution shifts. We theoretically prove these results by analyzing the population gradients. To corroborate our theoretical findings, we present empirical results showing that this property of Adam leads to superior generalization across datasets with spurious correlations where neural networks trained with SGD are known to show simplicity bias and don't generalize well under certain distributional shifts.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 3.5 -->
                    
                <!-- GNN: 2.8 -->
                    
                <!-- Federated Learning: 2.6 -->
                    
                <!-- Medicine: 2.3 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Computer Vision: 1.2 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.0 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24024" target="_blank" rel="noopener noreferrer">Exploiting Euclidean Distance Field Properties for Fast and Safe 3D planning with a modified Lazy Theta*</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jose A. Cobano, L. Merino, F. Caballero
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Graph search planners have been widely used for 3D path planning in the literature, and Euclidean Distance Fields (EDFs) are increasingly being used as a representation of the environment. However, to the best of our knowledge, the integration of EDFs into heuristic planning has been carried out in </span>
                
                <span class="abstract-full" style="display: none;">Graph search planners have been widely used for 3D path planning in the literature, and Euclidean Distance Fields (EDFs) are increasingly being used as a representation of the environment. However, to the best of our knowledge, the integration of EDFs into heuristic planning has been carried out in a loosely coupled fashion, dismissing EDF properties that can be used to accelerate/improve the planning process and enhance the safety margins of the resultant trajectories. This paper presents a fast graph search planner based on a modified Lazy Theta* planning algorithm for aerial robots in challenging 3D environments that exploits the EDF properties. The proposed planner outperforms classic graph search planners in terms of path smoothness and safety. It integrates EDFs as environment representation and directly generates fast and smooth paths avoiding the use of post-processing methods; it also considers the analytical properties of EDFs to obtain an approximation of the EDF cost along the line-of-sight segments and to reduce the number of visibility neighbours, which directly impacts the computation time. Moreover, we demonstrate that the proposed EDF-based cost function satisfies the triangle inequality, which reduces calculations during exploration and, hence, computation time. Many experiments and comparatives are carried out in 3D challenging indoor and outdoor simulation environments to evaluate and validate the proposed planner. The results show an efficient and safe planner in these environments.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 3.0 -->
                    
                <!-- Federated Learning: 2.3 -->
                    
                <!-- Reinforcement Learning: 2.3 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- LLMs: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24028" target="_blank" rel="noopener noreferrer">Hidden Persuasion: Detecting Manipulative Narratives on Social Media During the 2022 Russian Invasion of Ukraine</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Kateryna Akhynko, Oleksandr Kosovan, Mykola Trokhymovych
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper presents one of the top-performing solutions to the UNLP 2025 Shared Task on Detecting Manipulation in Social Media. The task focuses on detecting and classifying rhetorical and stylistic manipulation techniques used to influence Ukrainian Telegram users. For the classification subtask, w</span>
                
                <span class="abstract-full" style="display: none;">This paper presents one of the top-performing solutions to the UNLP 2025 Shared Task on Detecting Manipulation in Social Media. The task focuses on detecting and classifying rhetorical and stylistic manipulation techniques used to influence Ukrainian Telegram users. For the classification subtask, we fine-tuned the Gemma 2 language model with LoRA adapters and applied a second-level classifier leveraging meta-features and threshold optimization. For span detection, we employed an XLM-RoBERTa model trained for multi-target, including token binary classification. Our approach achieved 2nd place in classification and 3rd place in span detection.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.4 -->
                    
                <!-- LLMs: 4.3 -->
                    
                <!-- Computer Vision: 3.4 -->
                    
                <!-- Blockchain: 2.3 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24029" target="_blank" rel="noopener noreferrer">Nonlinear Oscillatory Response of Automated Vehicle Car-following: Theoretical Analysis with Traffic State and Control Input Limits</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Sixu Li, Yang Zhou
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper presents a framework grounded in the theory of describing function (DF) and incremental-input DF to theoretically analyze the nonlinear oscillatory response of automated vehicles (AVs) car-following (CF) amidst traffic oscillations, considering the limits of traffic state and control inpu</span>
                
                <span class="abstract-full" style="display: none;">This paper presents a framework grounded in the theory of describing function (DF) and incremental-input DF to theoretically analyze the nonlinear oscillatory response of automated vehicles (AVs) car-following (CF) amidst traffic oscillations, considering the limits of traffic state and control input. While prevailing approaches largely ignore these limits (i.e., saturation of acceleration/deceleration and speed) and focus on linear string stability analysis, this framework establishes a basis for theoretically analyzing the frequency response of AV systems with nonlinearities imposed by these limits. To this end, trajectories of CF pairs are decomposed into nominal and oscillatory trajectories, subsequently, the controlled AV system is repositioned within the oscillatory trajectory coordinates. Built on this base, DFs are employed to approximate the frequency responses of nonlinear saturation components by using their first harmonic output, thereby capturing the associated amplification ratio and phase shift. Considering the closed-loop nature of AV control systems, where system states and control input mutually influence each other, amplification ratios and phase shifts are balanced within the loop to ensure consistency. This balancing process may render multiple solutions, hence the incremental-input DF is further applied to identify the reasonable ones. The proposed method is validated by estimations from Simulink, and further comparisons with prevailing methods are conducted. Results confirm the alignment of our framework with Simulink results and exhibit its superior accuracy in analysis compared to the prevailing methods. Furthermore, the framework proves valuable in string stability analysis, especially when conventional linear methods offer misleading insights.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 3.8 -->
                    
                <!-- Federated Learning: 3.7 -->
                    
                <!-- LLMs: 2.6 -->
                    
                <!-- Blockchain: 2.3 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Math: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24036" target="_blank" rel="noopener noreferrer">GenIC: An LLM-Based Framework for Instance Completion in Knowledge Graphs</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Amel Gader, Alsayed Algergawy
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Knowledge graph completion aims to address the gaps of knowledge bases by adding new triples that represent facts. The complexity of this task depends on how many parts of a triple are already known. Instance completion involves predicting the relation-tail pair when only the head is given (h, ?, ?)</span>
                
                <span class="abstract-full" style="display: none;">Knowledge graph completion aims to address the gaps of knowledge bases by adding new triples that represent facts. The complexity of this task depends on how many parts of a triple are already known. Instance completion involves predicting the relation-tail pair when only the head is given (h, ?, ?). Notably, modern knowledge bases often contain entity descriptions and types, which can provide valuable context for inferring missing facts. By leveraging these textual descriptions and the ability of large language models to extract facts from them and recognize patterns within the knowledge graph schema, we propose an LLM-powered, end-to-end instance completion approach. Specifically, we introduce GenIC: a two-step Generative Instance Completion framework. The first step focuses on property prediction, treated as a multi-label classification task. The second step is link prediction, framed as a generative sequence-to-sequence task. Experimental results on three datasets show that our method outperforms existing baselines. Our code is available at https://github.com/amal-gader/genic.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.5 -->
                    
                <!-- GNN: 2.9 -->
                    
                <!-- Medicine: 2.8 -->
                    
                <!-- Federated Learning: 2.7 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24046" target="_blank" rel="noopener noreferrer">A Conceptual Introduction to Hetero-functional Graph Theory for Systems-of-Systems</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Amro M. Farid, Amirreza Hosseini, John C. Little
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">A defining feature of twenty first century engineering challenges is their inherent complexity, demanding the convergence of knowledge across diverse disciplines. Establishing consistent methodological foundations for engineering systems remains a challenge -- one that both systems engineering and n</span>
                
                <span class="abstract-full" style="display: none;">A defining feature of twenty first century engineering challenges is their inherent complexity, demanding the convergence of knowledge across diverse disciplines. Establishing consistent methodological foundations for engineering systems remains a challenge -- one that both systems engineering and network science have sought to address. Model-based systems engineering (MBSE) has recently emerged as a practical, interdisciplinary approach for developing complex systems from concept through implementation. In contrast, network science focuses on the quantitative analysis of networks present within engineering systems. This paper introduces hetero-functional graph theory (HFGT) as a conceptual bridge between these two fields, serving as a tutorial for both communities. For systems engineers, HFGT preserves the heterogeneity of conceptual and ontological constructs in MBSE, including system form, function, and concept. For network scientists, it provides multiple graph-based data structures enabling matrix-based quantitative analysis. The modeling process begins with ontological foundations, defining an engineering system as an abstraction and representing it with a model. Model fidelity is assessed using four linguistic properties: soundness, completeness, lucidity, and laconicity. A meta-architecture is introduced to manage the convergence challenges between domain-specific reference architectures and case-specific instantiations. Unlike other meta-architectures, HFGT is rooted in linguistic structures, modeling resources as subjects, system processes as predicates, and operands-such as matter, energy, organisms, information, and money-as objects. These elements are integrated within a system meta-architecture expressed in the Systems Modeling Language (SysML). The paper concludes by offering guidance for further reading.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.0 -->
                    
                <!-- LLMs: 2.6 -->
                    
                <!-- Hardware: 2.3 -->
                    
                <!-- Datasets: 2.1 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24055" target="_blank" rel="noopener noreferrer">Bridging Source and Target Domains via Link Prediction for Unsupervised Domain Adaptation on Graphs</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yilong Wang, Tianxiang Zhao, Zongyu Wu, Suhang Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Graph neural networks (GNNs) have shown great ability for node classification on graphs. However, the success of GNNs relies on abundant labeled data, while obtaining high-quality labels is costly and challenging, especially for newly emerging domains. Hence, unsupervised domain adaptation (UDA), wh</span>
                
                <span class="abstract-full" style="display: none;">Graph neural networks (GNNs) have shown great ability for node classification on graphs. However, the success of GNNs relies on abundant labeled data, while obtaining high-quality labels is costly and challenging, especially for newly emerging domains. Hence, unsupervised domain adaptation (UDA), which trains a classifier on the labeled source graph and adapts it to the unlabeled target graph, is attracting increasing attention. Various approaches have been proposed to alleviate the distribution shift between the source and target graphs to facilitate the classifier adaptation. However, most of them simply adopt existing UDA techniques developed for independent and identically distributed data to gain domain-invariant node embeddings for graphs, which do not fully consider the graph structure and message-passing mechanism of GNNs during the adaptation and will fail when label distribution shift exists among domains. In this paper, we proposed a novel framework that adopts link prediction to connect nodes between source and target graphs, which can facilitate message-passing between the source and target graphs and augment the target nodes to have ``in-distribution'' neighborhoods with the source domain. This strategy modified the target graph on the input level to reduce its deviation from the source domain in the embedding space and is insensitive to disproportional label distributions across domains. To prevent the loss of discriminative information in the target graph, we further design a novel identity-preserving learning objective, which guides the learning of the edge insertion module together with reconstruction and adaptation losses. Experimental results on real-world datasets demonstrate the effectiveness of our framework.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- GNN: 4.4 -->
                    
                <!-- Medicine: 4.3 -->
                    
                <!-- Computer Vision: 4.3 -->
                    
                <!-- Federated Learning: 3.3 -->
                    
                <!-- Reinforcement Learning: 2.8 -->
                    
                <!-- Evolutionary Algorithms: 2.2 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24056" target="_blank" rel="noopener noreferrer">Hybrid CG-Tikhonov as a filtration of the CG Lanczos vectors</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Daniel Gerth, Kirk M. Soodhalter
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We consider iterative methods for solving linear ill-posed problems with compact operator and right-hand side only available via noise-polluted measurements. Conjugate gradients (CG) applied to the normal equations with an appropriate stopping rule and CG applied to the system solving for a Tikhonov</span>
                
                <span class="abstract-full" style="display: none;">We consider iterative methods for solving linear ill-posed problems with compact operator and right-hand side only available via noise-polluted measurements. Conjugate gradients (CG) applied to the normal equations with an appropriate stopping rule and CG applied to the system solving for a Tikhonov-regularized solution (CGT) $(A^\ast A + c I_{\mathcal{X}}) x^{(\delta,c)} = A^\ast y^\delta$ are closely related methods as build iterates from the same family of Krylov subspaces.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 3.5 -->
                    
                <!-- LLMs: 2.4 -->
                    
                <!-- Quantum Computing: 2.3 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Networks: 1.5 -->
                    
                <!-- Math: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Cryptography: 1.1 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24058" target="_blank" rel="noopener noreferrer">A positivity-preserving hybrid DDG method for Poisson--Nernst--Planck systems</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Hailiang Liu, Zhongming Wang, Peimeng Yin
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In earlier work [H. Liu and Z. Wang, J. Comput. Phys., 328(2017)], an arbitrary high-order conservative and energy-dissipative direct discontinuous Galerkin (DDG) scheme was developed. Although this scheme enforced solution positivity using cell averages as reference values, it lacked a theoretical </span>
                
                <span class="abstract-full" style="display: none;">In earlier work [H. Liu and Z. Wang, J. Comput. Phys., 328(2017)], an arbitrary high-order conservative and energy-dissipative direct discontinuous Galerkin (DDG) scheme was developed. Although this scheme enforced solution positivity using cell averages as reference values, it lacked a theoretical guarantee for the positivity of those cell averages. In this study, we develop a novel arbitrary high-order DDG method with rigorously proven positivity-preserving properties. Specifically, the positivity of the cell averages is ensured through a modified numerical flux in combination with forward Euler time discretization. To achieve point-wise positivity of ion concentrations, we introduce a hybrid algorithm that integrates a positivity-preserving limiter. The proposed method is further extended to higher-dimensional problems with rectangular meshes. Numerical results confirm the scheme's high-order accuracy, guaranteed positivity preservation, and consistent discrete energy dissipation.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.5 -->
                    
                <!-- LLMs: 4.1 -->
                    
                <!-- Federated Learning: 3.3 -->
                    
                <!-- Evolutionary Algorithms: 2.5 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Networks: 1.2 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Hardware: 1.1 -->
                    
                <!-- Datasets: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24060" target="_blank" rel="noopener noreferrer">Characterising the Inductive Biases of Neural Networks on Boolean Data</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Chris Mingard, Lukas Seier, Niclas G\"oring, Andrei-Vlad Badelita, Charles London, Ard Louis
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Deep neural networks are renowned for their ability to generalise well across diverse tasks, even when heavily overparameterized. Existing works offer only partial explanations (for example, the NTK-based task-model alignment explanation neglects feature learning). Here, we provide an end-to-end, an</span>
                
                <span class="abstract-full" style="display: none;">Deep neural networks are renowned for their ability to generalise well across diverse tasks, even when heavily overparameterized. Existing works offer only partial explanations (for example, the NTK-based task-model alignment explanation neglects feature learning). Here, we provide an end-to-end, analytically tractable case study that links a network's inductive prior, its training dynamics including feature learning, and its eventual generalisation. Specifically, we exploit the one-to-one correspondence between depth-2 discrete fully connected networks and disjunctive normal form (DNF) formulas by training on Boolean functions. Under a Monte Carlo learning algorithm, our model exhibits predictable training dynamics and the emergence of interpretable features. This framework allows us to trace, in detail, how inductive bias and feature formation drive generalisation.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.4 -->
                    
                <!-- GNN: 3.6 -->
                    
                <!-- Medicine: 3.2 -->
                    
                <!-- Computer Vision: 2.4 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- Blockchain: 2.3 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Datasets: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24068" target="_blank" rel="noopener noreferrer">DiffCoTune: Differentiable Co-Tuning for Cross-domain Robot Control</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Lokesh Krishna, Sheng Cheng, Junheng Li, Naira Hovakimyan, Quan Nguyen
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The deployment of robot controllers is hindered by modeling discrepancies due to necessary simplifications for computational tractability or inaccuracies in data-generating simulators. Such discrepancies typically require ad-hoc tuning to meet the desired performance, thereby ensuring successful tra</span>
                
                <span class="abstract-full" style="display: none;">The deployment of robot controllers is hindered by modeling discrepancies due to necessary simplifications for computational tractability or inaccuracies in data-generating simulators. Such discrepancies typically require ad-hoc tuning to meet the desired performance, thereby ensuring successful transfer to a target domain. We propose a framework for automated, gradient-based tuning to enhance performance in the deployment domain by leveraging differentiable simulators. Our method collects rollouts in an iterative manner to co-tune the simulator and controller parameters, enabling systematic transfer within a few trials in the deployment domain. Specifically, we formulate multi-step objectives for tuning and employ alternating optimization to effectively adapt the controller to the deployment domain. The scalability of our framework is demonstrated by co-tuning model-based and learning-based controllers of arbitrary complexity for tasks ranging from low-dimensional cart-pole stabilization to high-dimensional quadruped and biped tracking, showing performance improvements across different deployment domains.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 3.0 -->
                    
                <!-- Federated Learning: 2.5 -->
                    
                <!-- Medicine: 2.4 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- Networks: 1.7 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24079" target="_blank" rel="noopener noreferrer">Principal Context-aware Diffusion Guided Data Augmentation for Fault Localization</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Shihao Fu, Yan Lei
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Test cases are indispensable for conducting effective fault localization (FL). However, test cases in practice are severely class imbalanced, i.e. the number of failing test cases (i.e. minority class) is much less than that of passing ones (i.e. majority class). The severe class imbalance between f</span>
                
                <span class="abstract-full" style="display: none;">Test cases are indispensable for conducting effective fault localization (FL). However, test cases in practice are severely class imbalanced, i.e. the number of failing test cases (i.e. minority class) is much less than that of passing ones (i.e. majority class). The severe class imbalance between failing and passing test cases have hindered the FL effectiveness.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.1 -->
                    
                <!-- Medicine: 3.4 -->
                    
                <!-- Blockchain: 3.0 -->
                    
                <!-- Hardware: 2.7 -->
                    
                <!-- Quantum Computing: 2.3 -->
                    
                <!-- GNN: 2.2 -->
                    
                <!-- Bayesian Optimization: 2.1 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Computer Vision: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- HPO and AutoML: 1.9 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- 3D: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24081" target="_blank" rel="noopener noreferrer">A Benchmark Reference for ESP32-CAM Module</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Sayed T. Nowroz, Nermeen M. Saleh, Siam Shakur, Sean Banerjee, Fathi Amsaad
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The ESP32-CAM is one of the most widely adopted open-source modules for prototyping embedded vision applications. Since its release in 2019, it has gained popularity among both hobbyists and professional developers due to its affordability, versatility, and integrated wireless capabilities. Despite </span>
                
                <span class="abstract-full" style="display: none;">The ESP32-CAM is one of the most widely adopted open-source modules for prototyping embedded vision applications. Since its release in 2019, it has gained popularity among both hobbyists and professional developers due to its affordability, versatility, and integrated wireless capabilities. Despite its widespread use, comprehensive documentation of the performance metrics remains limited. This study addresses this gap by collecting and analyzing over six hours of real-time video streaming logs across all supported resolutions of the OV2640 image sensor, tested under five distinct voltage conditions via an HTTP-based WiFi connection. A long standing bug in the official Arduino ESP32 driver, responsible for inaccurate frame rate logging, was fixed. The resulting analysis includes key performance metrics such as instantaneous and average frame rate, total streamed data, transmission count, and internal chip temperature. The influence of varying power levels was evaluated to assess the reliability of the module.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.3 -->
                    
                <!-- Hardware: 4.0 -->
                    
                <!-- LLMs: 3.7 -->
                    
                <!-- Blockchain: 2.7 -->
                    
                <!-- Computer Vision: 2.2 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Datasets: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- Bayesian Optimization: 1.6 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24089" target="_blank" rel="noopener noreferrer">Practical Bayes-Optimal Membership Inference Attacks</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Marcus Lassila, Johan \"Ostman, Khac-Hoang Ngo, Alexandre Graell i Amat
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We develop practical and theoretically grounded membership inference attacks (MIAs) against both independent and identically distributed (i.i.d.) data and graph-structured data. Building on the Bayesian decision-theoretic framework of Sablayrolles et al., we derive the Bayes-optimal membership infer</span>
                
                <span class="abstract-full" style="display: none;">We develop practical and theoretically grounded membership inference attacks (MIAs) against both independent and identically distributed (i.i.d.) data and graph-structured data. Building on the Bayesian decision-theoretic framework of Sablayrolles et al., we derive the Bayes-optimal membership inference rule for node-level MIAs against graph neural networks, addressing key open questions about optimal query strategies in the graph setting. We introduce BASE and G-BASE, computationally efficient approximations of the Bayes-optimal attack. G-BASE achieves superior performance compared to previously proposed classifier-based node-level MIA attacks. BASE, which is also applicable to non-graph data, matches or exceeds the performance of prior state-of-the-art MIAs, such as LiRA and RMIA, at a significantly lower computational cost. Finally, we show that BASE and RMIA are equivalent under a specific hyperparameter setting, providing a principled, Bayes-optimal justification for the RMIA attack.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 3.1 -->
                    
                <!-- Medicine: 3.1 -->
                    
                <!-- Hardware: 2.4 -->
                    
                <!-- Computer Vision: 2.0 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.4 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- Datasets: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24091" target="_blank" rel="noopener noreferrer">Temporally Extending Existing Web Archive Collections for Longitudinal Analysis</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Lesley Frew, Michael L. Nelson, Michele C. Weigle
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The Environmental Governance and Data Initiative (EDGI) regularly crawled US federal environmental websites between 2016 and 2020 to capture changes between two presidential administrations. However, because it does not include the previous administration ending in 2008, the collection is unsuitable</span>
                
                <span class="abstract-full" style="display: none;">The Environmental Governance and Data Initiative (EDGI) regularly crawled US federal environmental websites between 2016 and 2020 to capture changes between two presidential administrations. However, because it does not include the previous administration ending in 2008, the collection is unsuitable for answering our research question, Were the website terms deleted by the Trump administration (2017--2021) added by the Obama administration (2009--2017)? Thus, like many researchers using the Wayback Machine's holdings for historical analysis, we do not have access to a complete collection suiting our needs. To answer our research question, we must extend the EDGI collection back to January, 2008. This includes discovering relevant pages that were not included in the EDGI collection that persisted through 2020, not just going further back in time with the existing pages. We pieced together artifacts collected by various organizations for their purposes through many means (Save Page Now, Archive-It, and more) in order to curate a dataset sufficient for our intentions. In this paper, we contribute a methodology to extend existing web archive collections temporally to enable longitudinal analysis, including a dataset extended with this methodology. We use our new dataset to analyze our question, Were the website terms deleted by the Trump administration added by the Obama administration? We find that 81 percent of the pages in the dataset changed between 2008 and 2020, and that 87 percent of the pages with terms deleted by the Trump administration were terms added during the Obama administration.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 2.6 -->
                    
                <!-- Computer Vision: 2.6 -->
                    
                <!-- LLMs: 2.5 -->
                    
                <!-- Medicine: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Networks: 1.4 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Cryptography: 1.2 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Math: 1.1 -->
                    
                <!-- Finance: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24096" target="_blank" rel="noopener noreferrer">Towards Tangible Immersion for Cobot Programming-by-Demonstration: Visual, Tactile and Haptic Interfaces for Mixed-Reality Cobot Automation in Semiconductor Manufacturing</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: David I. Gonzalez-Aguirre, Javier Felip Leon, Javier Felix-Rendon, Roderico Garcia-Leal, Julio C. Zamora Esquivel
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Sensor-based reactive and hybrid approaches have proven a promising line of study to address imperfect knowledge in grasping and manipulation. However the reactive approaches are usually tightly coupled to a particular embodiment making transfer of knowledge difficult. This paper proposes a paradigm</span>
                
                <span class="abstract-full" style="display: none;">Sensor-based reactive and hybrid approaches have proven a promising line of study to address imperfect knowledge in grasping and manipulation. However the reactive approaches are usually tightly coupled to a particular embodiment making transfer of knowledge difficult. This paper proposes a paradigm for modeling and execution of reactive manipulation actions, which makes knowledge transfer to different embodiments possible while retaining the reactive capabilities of the embodiments. The proposed approach extends the idea of control primitives coordinated by a state machine by introducing an embodiment independent layer of abstraction. Abstract manipulation primitives constitute a vocabulary of atomic, embodiment independent actions, which can be coordinated using state machines to describe complex actions. To obtain embodiment specific models, the abstract state machines are automatically translated to embodiment specific models, such that full capabilities of each platform can be utilized. The strength of the manipulation primitives paradigm is demonstrated by developing a set of corresponding embodiment specific primitives for object transport, including a complex reactive grasping primitive. The robustness of the approach is experimentally studied in emptying of a box filled with several unknown objects. The embodiment independence is studied by performing a manipulation task on two different platforms using the same abstract description.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 3.1 -->
                    
                <!-- Evolutionary Algorithms: 2.9 -->
                    
                <!-- Networks: 2.5 -->
                    
                <!-- Medicine: 2.2 -->
                    
                <!-- LLMs: 1.9 -->
                    
                <!-- Bayesian Optimization: 1.8 -->
                    
                <!-- Math: 1.5 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Game Theory: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Cryptography: 1.4 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Finance: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24103" target="_blank" rel="noopener noreferrer">Weakly-Supervised Affordance Grounding Guided by Part-Level Semantic Priors</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Peiran Xu, Yadong Mu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In this work, we focus on the task of weakly supervised affordance grounding, where a model is trained to identify affordance regions on objects using human-object interaction images and egocentric object images without dense labels. Previous works are mostly built upon class activation maps, which </span>
                
                <span class="abstract-full" style="display: none;">In this work, we focus on the task of weakly supervised affordance grounding, where a model is trained to identify affordance regions on objects using human-object interaction images and egocentric object images without dense labels. Previous works are mostly built upon class activation maps, which are effective for semantic segmentation but may not be suitable for locating actions and functions. Leveraging recent advanced foundation models, we develop a supervised training pipeline based on pseudo labels. The pseudo labels are generated from an off-the-shelf part segmentation model, guided by a mapping from affordance to part names. Furthermore, we introduce three key enhancements to the baseline model: a label refining stage, a fine-grained feature alignment process, and a lightweight reasoning module. These techniques harness the semantic knowledge of static objects embedded in off-the-shelf foundation models to improve affordance learning, effectively bridging the gap between objects and actions. Extensive experiments demonstrate that the performance of the proposed model has achieved a breakthrough improvement over existing methods. Our codes are available at https://github.com/woyut/WSAG-PLSP .</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Computer Vision: 3.5 -->
                    
                <!-- Medicine: 3.3 -->
                    
                <!-- Federated Learning: 2.8 -->
                    
                <!-- LLMs: 2.8 -->
                    
                <!-- GNN: 2.5 -->
                    
                <!-- Reinforcement Learning: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Bayesian Optimization: 1.4 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24106" target="_blank" rel="noopener noreferrer">Controller Design for Bilinear Neural Feedback Loops</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Dhruv Shah, Jorge Cort\'es
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper considers a class of bilinear systems with a neural network in the loop. These arise naturally when employing machine learning techniques to approximate general, non-affine in the input, control systems. We propose a controller design framework that combines linear fractional representati</span>
                
                <span class="abstract-full" style="display: none;">This paper considers a class of bilinear systems with a neural network in the loop. These arise naturally when employing machine learning techniques to approximate general, non-affine in the input, control systems. We propose a controller design framework that combines linear fractional representations and tools from linear parameter varying control to guarantee local exponential stability of a desired equilibrium. The controller is obtained from the solution of linear matrix inequalities, which can be solved offline, making the approach suitable for online applications. The proposed methodology offers tools for stability and robustness analysis of deep neural networks interconnected with dynamical systems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 3.7 -->
                    
                <!-- Networks: 2.3 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- LLMs: 1.7 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Math: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Game Theory: 1.4 -->
                    
                <!-- Cryptography: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Finance: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24116" target="_blank" rel="noopener noreferrer">Humanoid Loco-Manipulations Pattern Generation and Stabilization Control</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Masaki Murooka, Kevin Chappellet, Arnaud Tanguy, Mehdi Benallegue, Iori Kumagai, Mitsuharu Morisawa, Fumio Kanehiro, Abderrahmane Kheddar
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In order for a humanoid robot to perform loco-manipulation such as moving an object while walking, it is necessary to account for sustained or alternating external forces other than ground-feet reaction, resulting from humanoid-object contact interactions. In this letter, we propose a bipedal contro</span>
                
                <span class="abstract-full" style="display: none;">In order for a humanoid robot to perform loco-manipulation such as moving an object while walking, it is necessary to account for sustained or alternating external forces other than ground-feet reaction, resulting from humanoid-object contact interactions. In this letter, we propose a bipedal control strategy for humanoid loco-manipulation that can cope with such external forces. First, the basic formulas of the bipedal dynamics, i.e., linear inverted pendulum mode and divergent component of motion, are derived, taking into account the effects of external manipulation forces. Then, we propose a pattern generator to plan center of mass trajectories consistent with the reference trajectory of the manipulation forces, and a stabilizer to compensate for the error between desired and actual manipulation forces. The effectiveness of our controller is assessed both in simulation and loco-manipulation experiments with real humanoid robots.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.3 -->
                    
                <!-- LLMs: 3.3 -->
                    
                <!-- Federated Learning: 2.6 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Robotics: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24117" target="_blank" rel="noopener noreferrer">Bounds on the Excess Minimum Risk via Generalized Information Divergence Measures</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ananya Omanwar, Fady Alajaji, Tam\'as Linder
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Given finite-dimensional random vectors $Y$, $X$, and $Z$ that form a Markov chain in that order (i.e., $Y \to X \to Z$), we derive upper bounds on the excess minimum risk using generalized information divergence measures. Here, $Y$ is a target vector to be estimated from an observed feature vector </span>
                
                <span class="abstract-full" style="display: none;">Given finite-dimensional random vectors $Y$, $X$, and $Z$ that form a Markov chain in that order (i.e., $Y \to X \to Z$), we derive upper bounds on the excess minimum risk using generalized information divergence measures. Here, $Y$ is a target vector to be estimated from an observed feature vector $X$ or its stochastically degraded version $Z$. The excess minimum risk is defined as the difference between the minimum expected loss in estimating $Y$ from $X$ and from $Z$. We present a family of bounds that generalize the mutual information based bound of Gy\"orfi et al. (2023), using the R\'enyi and $\alpha$-Jensen-Shannon divergences, as well as Sibson's mutual information. Our bounds are similar to those developed by Modak et al. (2021) and Aminian et al. (2024) for the generalization error of learning algorithms. However, unlike these works, our bounds do not require the sub-Gaussian parameter to be constant and therefore apply to a broader class of joint distributions over $Y$, $X$, and $Z$. We also provide numerical examples under both constant and non-constant sub-Gaussianity assumptions, illustrating that our generalized divergence based bounds can be tighter than the one based on mutual information for certain regimes of the parameter $\alpha$.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Quantum Computing: 2.1 -->
                    
                <!-- Medicine: 2.0 -->
                    
                <!-- Reinforcement Learning: 1.8 -->
                    
                <!-- Math: 1.7 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- LLMs: 1.7 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Bayesian Optimization: 1.4 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Networks: 1.3 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Cryptography: 1.2 -->
                    
                <!-- Finance: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Game Theory: 1.0 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24137" target="_blank" rel="noopener noreferrer">Energy-Oriented Computing Architecture Simulator for SNN Training</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yunhao Ma (Pengcheng Laboratory, Southern University of Science and Technology), Wanyi Jia (Pengcheng Laboratory, Southern University of Science and Technology), Yanyu Lin (Pengcheng Laboratory), Wenjie Lin (Pengcheng Laboratory), Xueke Zhu (Pengcheng Laboratory), Huihui Zhou (Pengcheng Laboratory), Fengwei An (Southern University of Science and Technology)
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">With the growing demand for intelligent computing, neuromorphic computing, a paradigm that mimics the structure and functionality of the human brain, offers a promising approach to developing new high-efficiency intelligent computing systems. Spiking Neural Networks (SNNs), the foundation of neuromo</span>
                
                <span class="abstract-full" style="display: none;">With the growing demand for intelligent computing, neuromorphic computing, a paradigm that mimics the structure and functionality of the human brain, offers a promising approach to developing new high-efficiency intelligent computing systems. Spiking Neural Networks (SNNs), the foundation of neuromorphic computing, have garnered significant attention due to their unique potential in energy efficiency and biomimetic neural processing. However, current hardware development for efficient SNN training lags significantly. No systematic energy evaluation methods exist for SNN training tasks. Therefore, this paper proposes an Energy-Oriented Computing Architecture Simulator (EOCAS) for SNN training to identify the optimal architecture. EOCAS investigates the high sparsity of spike signals, unique hardware design representations, energy assessment, and computation patterns to support energy optimization in various architectures. Under the guidance of EOCAS, we implement the power-aimed optimal hardware architecture through Verilog HDL and achieve low energy consumption using Synopsys Design Compiler with TSMC-28nm technology library under typical parameters. Compared with several State-Of-The-Art (SOTA) DNN and SNN works, our hardware architecture outstands others in various criteria.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.8 -->
                    
                <!-- Hardware: 4.4 -->
                    
                <!-- LLMs: 4.4 -->
                    
                <!-- Federated Learning: 2.9 -->
                    
                <!-- Evolutionary Algorithms: 2.9 -->
                    
                <!-- Datasets: 1.7 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24140" target="_blank" rel="noopener noreferrer">B2LoRa: Boosting LoRa Transmission for Satellite-IoT Systems with Blind Coherent Combining</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yimin Zhao, Weibo Wang, Xiong Wang, Linghe Kong, Jiadi Yu, Yifei Zhu, Shiyuan Li, Chong He, Guihai Chen
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">With the rapid growth of Low Earth Orbit (LEO) satellite networks, satellite-IoT systems using the LoRa technique have been increasingly deployed to provide widespread Internet services to low-power and low-cost ground devices. However, the long transmission distance and adverse environments from Io</span>
                
                <span class="abstract-full" style="display: none;">With the rapid growth of Low Earth Orbit (LEO) satellite networks, satellite-IoT systems using the LoRa technique have been increasingly deployed to provide widespread Internet services to low-power and low-cost ground devices. However, the long transmission distance and adverse environments from IoT satellites to ground devices pose a huge challenge to link reliability, as evidenced by the measurement results based on our real-world setup. In this paper, we propose a blind coherent combining design named B2LoRa to boost LoRa transmission performance. The intuition behind B2LoRa is to leverage the repeated broadcasting mechanism inherent in satellite-IoT systems to achieve coherent combining under the low-power and low-cost constraints, where each re-transmission at different times is regarded as the same packet transmitted from different antenna elements within an antenna array. Then, the problem is translated into aligning these packets at a fine granularity despite the time, frequency, and phase offsets between packets in the case of frequent packet loss. To overcome this challenge, we present three designs - joint packet sniffing, frequency shift alignment, and phase drift mitigation to deal with ultra-low SNRs and Doppler shifts featured in satellite-IoT systems, respectively. Finally, experiment results based on our real-world deployments demonstrate the high efficiency of B2LoRa.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 3.7 -->
                    
                <!-- LLMs: 2.5 -->
                    
                <!-- GNN: 2.5 -->
                    
                <!-- Computer Vision: 2.4 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- Medicine: 1.6 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Networks: 1.1 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24143" target="_blank" rel="noopener noreferrer">CrossICL: Cross-Task In-Context Learning via Unsupervised Demonstration Transfer</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jinglong Gao, Xiao Ding, Lingxiao Zou, Bing Qin, Ting Liu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In-Context Learning (ICL) enhances the performance of large language models (LLMs) with demonstrations. However, obtaining these demonstrations primarily relies on manual effort. In most real-world scenarios, users are often unwilling or unable to provide such demonstrations. Inspired by the human a</span>
                
                <span class="abstract-full" style="display: none;">In-Context Learning (ICL) enhances the performance of large language models (LLMs) with demonstrations. However, obtaining these demonstrations primarily relies on manual effort. In most real-world scenarios, users are often unwilling or unable to provide such demonstrations. Inspired by the human analogy, we explore a new ICL paradigm CrossICL to study how to utilize existing source task demonstrations in the ICL for target tasks, thereby obtaining reliable guidance without any additional manual effort. To explore this, we first design a two-stage alignment strategy to mitigate the interference caused by gaps across tasks, as the foundation for our experimental exploration. Based on it, we conduct comprehensive exploration of CrossICL, with 875 NLP tasks from the Super-NI benchmark and six types of LLMs, including GPT-4o. Experimental results demonstrate the effectiveness of CrossICL and provide valuable insights on questions like the criteria for selecting cross-task demonstrations, as well as the types of task-gap-induced interference in CrossICL.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.7 -->
                    
                <!-- Federated Learning: 4.0 -->
                    
                <!-- Computer Vision: 2.5 -->
                    
                <!-- Evolutionary Algorithms: 2.3 -->
                    
                <!-- Medicine: 2.2 -->
                    
                <!-- GNN: 2.1 -->
                    
                <!-- Reinforcement Learning: 2.0 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Bayesian Optimization: 1.6 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24159" target="_blank" rel="noopener noreferrer">A Causation-Based Framework for Pricing and Cost Allocation of Energy, Reserves, and Transmission in Modern Power Systems</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Luiza Ribeiro, Alexandre Street, Jose Manuel Arroyo, Rodrigo Moreno
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The increasing vulnerability of power systems has heightened the need for operating reserves to manage contingencies such as generator outages, line failures, and sudden load variations. Unlike energy costs, driven by consumer demand, operating reserve costs arise from addressing the most critical c</span>
                
                <span class="abstract-full" style="display: none;">The increasing vulnerability of power systems has heightened the need for operating reserves to manage contingencies such as generator outages, line failures, and sudden load variations. Unlike energy costs, driven by consumer demand, operating reserve costs arise from addressing the most critical credible contingencies - prompting the question: how should these costs be allocated through efficient pricing mechanisms? As an alternative to previously reported schemes, this paper presents a new causation-based pricing framework for electricity markets based on contingency-constrained energy and reserve scheduling models. Major salient features include a novel security charge mechanism along with the explicit definition of prices for up-spinning reserves, down-spinning reserves, and transmission services. These features ensure more comprehensive and efficient cost-reflective market operations. Moreover, the proposed nodal pricing scheme yields revenue adequacy and neutrality while promoting reliability incentives for generators based on the cost-causation principle. An additional salient aspect of the proposed framework is the economic incentive for transmission assets, which are remunerated based on their use to deliver energy and reserves across all contingency states. Numerical results from two case studies illustrate the performance of the proposed pricing scheme.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 3.8 -->
                    
                <!-- Hardware: 3.5 -->
                    
                <!-- Computer Vision: 2.9 -->
                    
                <!-- Federated Learning: 2.7 -->
                    
                <!-- Evolutionary Algorithms: 2.5 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- LLMs: 1.9 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24161" target="_blank" rel="noopener noreferrer">Proxy Target: Bridging the Gap Between Discrete Spiking Neural Networks and Continuous Control</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zijie Xu, Tong Bu, Zecheng Hao, Jianhao Ding, Zhaofei Yu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Spiking Neural Networks (SNNs) offer low-latency and energy-efficient decision making through neuromorphic hardware, making them compelling for Reinforcement Learning (RL) in resource-constrained edge devices. Recent studies in this field directly replace Artificial Neural Networks (ANNs) by SNNs in</span>
                
                <span class="abstract-full" style="display: none;">Spiking Neural Networks (SNNs) offer low-latency and energy-efficient decision making through neuromorphic hardware, making them compelling for Reinforcement Learning (RL) in resource-constrained edge devices. Recent studies in this field directly replace Artificial Neural Networks (ANNs) by SNNs in existing RL frameworks, overlooking whether the RL algorithm is suitable for SNNs. However, most RL algorithms in continuous control are designed tailored to ANNs, including the target network soft updates mechanism, which conflict with the discrete, non-differentiable dynamics of SNN spikes. We identify that this mismatch destabilizes SNN training in continuous control tasks. To bridge this gap between discrete SNN and continuous control, we propose a novel proxy target framework. The continuous and differentiable dynamics of the proxy target enable smooth updates, bypassing the incompatibility of SNN spikes, stabilizing the RL algorithms. Since the proxy network operates only during training, the SNN retains its energy efficiency during deployment without inference overhead. Extensive experiments on continuous control benchmarks demonstrate that compared to vanilla SNNs, the proxy target framework enables SNNs to achieve up to 32% higher performance across different spiking neurons. Notably, we are the first to surpass ANN performance in continuous control with simple Leaky-Integrate-and-Fire (LIF) neurons. This work motivates a new class of SNN-friendly RL algorithms tailored to SNN's characteristics, paving the way for neuromorphic agents that combine high performance with low power consumption.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- GNN: 2.6 -->
                    
                <!-- LLMs: 2.5 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- Reinforcement Learning: 2.2 -->
                    
                <!-- Computer Vision: 2.1 -->
                    
                <!-- Medicine: 1.7 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Networks: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Game Theory: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24168" target="_blank" rel="noopener noreferrer">Rydberg Atomic Receivers for Multi-Band Communications and Sensing</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Mingyao Cui, Qunsong Zeng, Zhanwei Wang, Kaibin Huang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Harnessing multi-level electron transitions, Rydberg Atomic Receivers (RAREs) can detect wireless signals across a wide range of frequency bands, from Megahertz to Terahertz, enabling multi-band communications and sensing (C&amp;S). Current research on multi-band RAREs primarily focuses on experimen</span>
                
                <span class="abstract-full" style="display: none;">Harnessing multi-level electron transitions, Rydberg Atomic Receivers (RAREs) can detect wireless signals across a wide range of frequency bands, from Megahertz to Terahertz, enabling multi-band communications and sensing (C&amp;S). Current research on multi-band RAREs primarily focuses on experimental demonstrations, lacking an interpretable model to mathematically characterize their mechanisms. This issue leaves the multi-band RARE as a black box, posing challenges in its practical C&amp;S applications. To fill in this gap, this paper investigates the underlying mechanism of multi-band RAREs and explores their optimal performance. For the first time, the closed-form expression of the transfer function of a multi-band RARE is derived by solving the quantum response of Rydberg atoms excited by multi-band signals. The function reveals that a multiband RARE simultaneously serves as both a multi-band atomic mixer for down-converting multi-band signals and a multi-band atomic amplifier that reflects its sensitivity to each band. Further analysis of the atomic amplifier unveils that the gain factor at each frequency band can be decoupled into a global gain term and a Rabi attention term. The former determines the overall sensitivity of a RARE to all frequency bands of wireless signals. The latter influences the allocation of the overall sensitivity to each frequency band, representing a unique attention mechanism of multi-band RAREs. The optimal design of the global gain is provided to maximize the overall sensitivity of multi-band RAREs. Subsequently, the optimal Rabi attentions are also derived to maximize the practical multi-band C&amp;S performance. Numerical results confirm the effectiveness of the derived transfer function and the superiority of multi-band RAREs.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 3.2 -->
                    
                <!-- Networks: 3.0 -->
                    
                <!-- Math: 2.2 -->
                    
                <!-- Bayesian Optimization: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Cryptography: 1.8 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- Finance: 1.6 -->
                    
                <!-- Medicine: 1.4 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- LLMs: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Game Theory: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24176" target="_blank" rel="noopener noreferrer">ISMAF: Intrinsic-Social Modality Alignment and Fusion for Multimodal Rumor Detection</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zihao Yu, Xiang Li, Jing Zhang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The rapid dissemination of rumors on social media highlights the urgent need for automatic detection methods to safeguard societal trust and stability. While existing multimodal rumor detection models primarily emphasize capturing consistency between intrinsic modalities (e.g., news text and images)</span>
                
                <span class="abstract-full" style="display: none;">The rapid dissemination of rumors on social media highlights the urgent need for automatic detection methods to safeguard societal trust and stability. While existing multimodal rumor detection models primarily emphasize capturing consistency between intrinsic modalities (e.g., news text and images), they often overlook the intricate interplay between intrinsic and social modalities. This limitation hampers the ability to fully capture nuanced relationships that are crucial for a comprehensive understanding. Additionally, current methods struggle with effectively fusing social context with textual and visual information, resulting in fragmented interpretations. To address these challenges, this paper proposes a novel Intrinsic-Social Modality Alignment and Fusion (ISMAF) framework for multimodal rumor detection. ISMAF first employs a cross-modal consistency alignment strategy to align complex interactions between intrinsic and social modalities. It then leverages a mutual learning approach to facilitate collaborative refinement and integration of complementary information across modalities. Finally, an adaptive fusion mechanism is incorporated to dynamically adjust the contribution of each modality, tackling the complexities of three-modality fusion. Extensive experiments on both English and Chinese real-world multimedia datasets demonstrate that ISMAF consistently outperforms state-of-the-art models.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.9 -->
                    
                <!-- LLMs: 4.3 -->
                    
                <!-- Computer Vision: 3.2 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- GNN: 2.3 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24178" target="_blank" rel="noopener noreferrer">Invariant Link Selector for Spatial-Temporal Out-of-Distribution Problem</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Katherine Tieu, Dongqi Fu, Jun Wu, Jingrui He
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In the era of foundation models, Out-of- Distribution (OOD) problems, i.e., the data discrepancy between the training environments and testing environments, hinder AI generalization. Further, relational data like graphs disobeying the Independent and Identically Distributed (IID) condition makes the</span>
                
                <span class="abstract-full" style="display: none;">In the era of foundation models, Out-of- Distribution (OOD) problems, i.e., the data discrepancy between the training environments and testing environments, hinder AI generalization. Further, relational data like graphs disobeying the Independent and Identically Distributed (IID) condition makes the problem more challenging, especially much harder when it is associated with time. Motivated by this, to realize the robust invariant learning over temporal graphs, we want to investigate what components in temporal graphs are most invariant and representative with respect to labels. With the Information Bottleneck (IB) method, we propose an error-bounded Invariant Link Selector that can distinguish invariant components and variant components during the training process to make the deep learning model generalizable for different testing scenarios. Besides deriving a series of rigorous generalizable optimization functions, we also equip the training with task-specific loss functions, e.g., temporal link prediction, to make pretrained models solve real-world application tasks like citation recommendation and merchandise recommendation, as demonstrated in our experiments with state-of-the-art (SOTA) methods. Our code is available at https://github.com/kthrn22/OOD-Linker.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Computer Vision: 3.3 -->
                    
                <!-- Federated Learning: 3.2 -->
                    
                <!-- Medicine: 3.2 -->
                    
                <!-- LLMs: 2.8 -->
                    
                <!-- GNN: 2.5 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24193" target="_blank" rel="noopener noreferrer">Improved Best-of-Both-Worlds Regret for Bandits with Delayed Feedback</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ofir Schlisselberg, Tal Lancewicki, Peter Auer, Yishay Mansour
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We study the multi-armed bandit problem with adversarially chosen delays in the Best-of-Both-Worlds (BoBW) framework, which aims to achieve near-optimal performance in both stochastic and adversarial environments. While prior work has made progress toward this goal, existing algorithms suffer from s</span>
                
                <span class="abstract-full" style="display: none;">We study the multi-armed bandit problem with adversarially chosen delays in the Best-of-Both-Worlds (BoBW) framework, which aims to achieve near-optimal performance in both stochastic and adversarial environments. While prior work has made progress toward this goal, existing algorithms suffer from significant gaps to the known lower bounds, especially in the stochastic settings. Our main contribution is a new algorithm that, up to logarithmic factors, matches the known lower bounds in each setting individually.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 3.6 -->
                    
                <!-- Game Theory: 2.7 -->
                    
                <!-- Networks: 2.3 -->
                    
                <!-- Quantum Computing: 2.2 -->
                    
                <!-- Cryptography: 2.0 -->
                    
                <!-- Math: 2.0 -->
                    
                <!-- Computer Vision: 1.9 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- RAG: 1.3 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Medicine: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- Hardware: 1.1 -->
                    
                <!-- Finance: 1.1 -->
                    
                <!-- Pathfinding: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24196" target="_blank" rel="noopener noreferrer">CLaSp: In-Context Layer Skip for Self-Speculative Decoding</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Longze Chen, Renke Shan, Huiming Wang, Lu Wang, Ziqiang Liu, Run Luo, Jiawei Wang, Hamid Alinejad-Rokny, Min Yang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Speculative decoding (SD) is a promising method for accelerating the decoding process of Large Language Models (LLMs). The efficiency of SD primarily hinges on the consistency between the draft model and the verify model. However, existing drafting approaches typically require additional modules to </span>
                
                <span class="abstract-full" style="display: none;">Speculative decoding (SD) is a promising method for accelerating the decoding process of Large Language Models (LLMs). The efficiency of SD primarily hinges on the consistency between the draft model and the verify model. However, existing drafting approaches typically require additional modules to be trained, which can be challenging to implement and ensure compatibility across various LLMs. In this paper, we propose CLaSp, an in-context layer-skipping strategy for self-speculative decoding. Unlike prior methods, CLaSp does not require additional drafting modules or extra training. Instead, it employs a plug-and-play mechanism by skipping intermediate layers of the verify model to construct a compressed draft model. Specifically, we develop a dynamic programming algorithm that optimizes the layer-skipping process by leveraging the complete hidden states from the last verification stage as an objective. This enables CLaSp to dynamically adjust its layer-skipping strategy after each verification stage, without relying on pre-optimized sets of skipped layers. Experimental results across diverse downstream tasks demonstrate that CLaSp achieves a speedup of 1.3x ~ 1.7x on LLaMA3 series models without altering the original distribution of the generated text.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.6 -->
                    
                <!-- Federated Learning: 4.6 -->
                    
                <!-- Evolutionary Algorithms: 2.3 -->
                    
                <!-- Medicine: 2.1 -->
                    
                <!-- Computer Vision: 1.9 -->
                    
                <!-- Bayesian Optimization: 1.9 -->
                    
                <!-- Reinforcement Learning: 1.8 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Cryptography: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.24204" target="_blank" rel="noopener noreferrer">Damping LFOs: Grid Following with Power Oscillation Damping vs. Grid Forming vs. PSS</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Tamojit Chakraborty, Anamitra Pal, Sam Maleki
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Low-frequency oscillations (LFOs) present a significant challenge to the stability and reliability of power systems, especially in grids with a high penetration of renewable energy sources. Traditional grid-following (GFL) inverters have proven less effective in damping such oscillations. This paper</span>
                
                <span class="abstract-full" style="display: none;">Low-frequency oscillations (LFOs) present a significant challenge to the stability and reliability of power systems, especially in grids with a high penetration of renewable energy sources. Traditional grid-following (GFL) inverters have proven less effective in damping such oscillations. This paper presents a GFL-power plant controller with an auxiliary power oscillation damping control for damping LFOs. This approach is compared with a traditional power system stabilizer (PSS) for a two-area power system. Next, the research is extended by deploying grid forming (GFM) controls, which by actively controlling the voltage and frequency dynamics emulate the behavior of traditional synchronous generators. The paper analyzes two GFM control strategies: virtual synchronous machine (VSM) and droop control, and demonstrates their effectiveness in damping LFOs in the test system. The simulation results reveal that the performance of the proposed GFM-VSM rivals that of the PSS and is better than the GFL-power oscillation damper.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 3.4 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- LLMs: 2.1 -->
                    
                <!-- Networks: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Math: 1.3 -->
                    
                <!-- Cryptography: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.0406
                </span>
                <a href="https://arxiv.org/abs/2504.10545" target="_blank" rel="noopener noreferrer">HSTU-BLaIR: Lightweight Contrastive Text Embedding for Generative Recommender</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yijun Liu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Recent advances in recommender systems have underscored the complementary strengths of generative modeling and pretrained language models. We propose HSTU-BLaIR, a hybrid framework that augments the Hierarchical Sequential Transduction Unit (HSTU)-based generative recommender with BLaIR, a lightweig</span>
                
                <span class="abstract-full" style="display: none;">Recent advances in recommender systems have underscored the complementary strengths of generative modeling and pretrained language models. We propose HSTU-BLaIR, a hybrid framework that augments the Hierarchical Sequential Transduction Unit (HSTU)-based generative recommender with BLaIR, a lightweight contrastive text embedding model. This integration enriches item representations with semantic signals from textual metadata while preserving HSTU's powerful sequence modeling capabilities.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.3%">
                            LLMs
                        </span>
                <!-- Medicine: 4.7 -->
                    
                <!-- Quantum Computing: 2.5 -->
                    
                <!-- GNN: 2.1 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Cryptography: 1.6 -->
                    
                <!-- Networks: 1.5 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                <!-- Game Theory: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.0542
                </span>
                <a href="https://arxiv.org/abs/2505.24097" target="_blank" rel="noopener noreferrer">Performative Risk Control: Calibrating Models for Reliable Deployment under Performativity</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Victor Li, Baiting Chen, Yuzhen Mao, Qi Lei, Zhun Deng
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Calibrating blackbox machine learning models to achieve risk control is crucial to ensure reliable decision-making. A rich line of literature has been studying how to calibrate a model so that its predictions satisfy explicit finite-sample statistical guarantees under a fixed, static, and unknown da</span>
                
                <span class="abstract-full" style="display: none;">Calibrating blackbox machine learning models to achieve risk control is crucial to ensure reliable decision-making. A rich line of literature has been studying how to calibrate a model so that its predictions satisfy explicit finite-sample statistical guarantees under a fixed, static, and unknown data-generating distribution. However, prediction-supported decisions may influence the outcome they aim to predict, a phenomenon named performativity of predictions, which is commonly seen in social science and economics. In this paper, we introduce Performative Risk Control, a framework to calibrate models to achieve risk control under performativity with provable theoretical guarantees. Specifically, we provide an iteratively refined calibration process, where we ensure the predictions are improved and risk-controlled throughout the process. We also study different types of risk measures and choices of tail bounds. Lastly, we demonstrate the effectiveness of our framework by numerical experiments on the task of predicting credit default risk. To the best of our knowledge, this work is the first one to study statistically rigorous risk control under performativity, which will serve as an important safeguard against a wide range of strategic manipulation in decision-making processes.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #b3ebae" title="Confidence: 5.4%">
                            Federated Learning
                        </span>
                <!-- LLMs: 4.9 -->
                    
                <!-- Medicine: 2.8 -->
                    
                <!-- Evolutionary Algorithms: 2.7 -->
                    
                <!-- GNN: 2.6 -->
                    
                <!-- Reinforcement Learning: 1.9 -->
                    
                <!-- Bayesian Optimization: 1.7 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.0559
                </span>
                <a href="https://arxiv.org/abs/2505.24203" target="_blank" rel="noopener noreferrer">Aligning Protein Conformation Ensemble Generation with Physical Feedback</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jiarui Lu, Xiaoyin Chen, Stephen Zhewen Lu, Aur\'elie Lozano, Vijil Chenthamarakshan, Payel Das, Jian Tang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Protein dynamics play a crucial role in protein biological functions and properties, and their traditional study typically relies on time-consuming molecular dynamics (MD) simulations conducted in silico. Recent advances in generative modeling, particularly denoising diffusion models, have enabled e</span>
                
                <span class="abstract-full" style="display: none;">Protein dynamics play a crucial role in protein biological functions and properties, and their traditional study typically relies on time-consuming molecular dynamics (MD) simulations conducted in silico. Recent advances in generative modeling, particularly denoising diffusion models, have enabled efficient accurate protein structure prediction and conformation sampling by learning distributions over crystallographic structures. However, effectively integrating physical supervision into these data-driven approaches remains challenging, as standard energy-based objectives often lead to intractable optimization. In this paper, we introduce Energy-based Alignment (EBA), a method that aligns generative models with feedback from physical models, efficiently calibrating them to appropriately balance conformational states based on their energy differences. Experimental results on the MD ensemble benchmark demonstrate that EBA achieves state-of-the-art performance in generating high-quality protein ensembles. By improving the physical plausibility of generated structures, our approach enhances model predictions and holds promise for applications in structural biology and drug discovery.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.4%">
                            LLMs
                        </span>
                <!-- Medicine: 3.1 -->
                    
                <!-- Computer Vision: 2.8 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- GNN: 2.3 -->
                    
                <!-- HPO and AutoML: 2.1 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- T2I: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.0587
                </span>
                <a href="https://arxiv.org/abs/2504.21578" target="_blank" rel="noopener noreferrer">Glucagon and insulin production in pancreatic cells modeled using Petri nets and Boolean networks</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Kamila Barylska, Franck Delaplace, Anna Gogoli\'nska, Ewa Pa\'nkowska
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Diabetes is a civilization chronic disease characterized by a constant elevated concentration of glucose in the blood. Many processes are involved in the glucose regulation, and their interactions are very complex. To better understand those processes we set ourselves a goal to create a Petri net mo</span>
                
                <span class="abstract-full" style="display: none;">Diabetes is a civilization chronic disease characterized by a constant elevated concentration of glucose in the blood. Many processes are involved in the glucose regulation, and their interactions are very complex. To better understand those processes we set ourselves a goal to create a Petri net model of the glucose regulation in the whole body. So far we have managed to create a model of glycolysis and synthesis of glucose in the liver, and the general overview models of the glucose regulation in a healthy and diabetic person. In this paper we introduce Petri nets models of insulin secretion in beta cell of the pancreas, and glucagon in the pancreas alpha cells. Those two hormones have mutually opposite effects: insulin preventing hyperglycemia, and glucagon preventing hypoglycemia. Understanding the mechanisms of insulin and glucagon secretion constitutes the basis for understanding diabetes. We also present a model in which both processes occur together, depending on the blood glucose level. The dynamics of each model is analysed. Additionally, we transform the overall insulin and glucagon secretion system to a Boolean network, following standard transformation rules.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.3%">
                            LLMs
                        </span>
                <!-- Medicine: 4.0 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Robotics: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Computer Vision: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.0697
                </span>
                <a href="https://arxiv.org/abs/2503.05771" target="_blank" rel="noopener noreferrer">A Materials Foundation Model via Hybrid Invariant-Equivariant Architectures</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Keqiang Yan, Montgomery Bohde, Andrii Kryvenko, Ziyu Xiang, Kaiji Zhao, Siya Zhu, Saagar Kolachina, Do\u{g}uhan Sar{\i}t\"urk, Jianwen Xie, Raymundo Arroyave, Xiaoning Qian, Xiaofeng Qian, Shuiwang Ji
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Machine learning interatomic potentials (MLIPs) can predict energy, force, and stress of materials and enable a wide range of downstream discovery tasks. A key design choice in MLIPs involves the trade-off between invariant and equivariant architectures. Invariant models offer computational efficien</span>
                
                <span class="abstract-full" style="display: none;">Machine learning interatomic potentials (MLIPs) can predict energy, force, and stress of materials and enable a wide range of downstream discovery tasks. A key design choice in MLIPs involves the trade-off between invariant and equivariant architectures. Invariant models offer computational efficiency but may not perform as well, especially when predicting high-order outputs. In contrast, equivariant models can capture high-order symmetries, but are computationally expensive. In this work, we propose HIENet, a hybrid invariant-equivariant materials interatomic potential model that integrates both invariant and equivariant message passing layers, while provably satisfying key physical constraints. HIENet achieves state-of-the-art performance with considerable computational speedups over prior models. Experimental results on both common benchmarks and downstream materials discovery tasks demonstrate the efficiency and effectiveness of HIENet.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 9.8%">
                            LLMs
                        </span>
                <!-- Medicine: 4.6 -->
                    
                <!-- Federated Learning: 2.5 -->
                    
                <!-- GNN: 2.4 -->
                    
                <!-- Blockchain: 2.2 -->
                    
                <!-- Computer Vision: 2.1 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Decision Trees: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.0831
                </span>
                <a href="https://arxiv.org/abs/2505.24346" target="_blank" rel="noopener noreferrer">VUDG: A Dataset for Video Understanding Domain Generalization</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ziyi Wang, Zhi Gao, Boxuan Yu, Zirui Dai, Yuxiang Song, Qingyuan Lu, Jin Chen, Xinxiao Wu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Video understanding has made remarkable progress in recent years, largely driven by advances in deep models and the availability of large-scale annotated datasets. However, existing works typically ignore the inherent domain shifts encountered in real-world video applications, leaving domain general</span>
                
                <span class="abstract-full" style="display: none;">Video understanding has made remarkable progress in recent years, largely driven by advances in deep models and the availability of large-scale annotated datasets. However, existing works typically ignore the inherent domain shifts encountered in real-world video applications, leaving domain generalization (DG) in video understanding underexplored. Hence, we propose Video Understanding Domain Generalization (VUDG), a novel dataset designed specifically for evaluating the DG performance in video understanding. VUDG contains videos from 11 distinct domains that cover three types of domain shifts, and maintains semantic similarity across different domains to ensure fair and meaningful evaluation. We propose a multi-expert progressive annotation framework to annotate each video with both multiple-choice and open-ended question-answer pairs. Extensive experiments on 9 representative large video-language models (LVLMs) and several traditional video question answering methods show that most models (including state-of-the-art LVLMs) suffer performance degradation under domain shifts. These results highlight the challenges posed by VUDG and the difference in the robustness of current models to data distribution shifts. We believe VUDG provides a valuable resource for prompting future research in domain generalization video understanding.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 10.8%">
                            LLMs
                        </span>
                <!-- Medicine: 3.4 -->
                    
                <!-- Computer Vision: 2.9 -->
                    
                <!-- Datasets: 1.8 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.0835
                </span>
                <a href="https://arxiv.org/abs/2505.24731" target="_blank" rel="noopener noreferrer">Circuit Stability Characterizes Language Model Generalization</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Alan Sun
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Extensively evaluating the capabilities of (large) language models is difficult. Rapid development of state-of-the-art models induce benchmark saturation, while creating more challenging datasets is labor-intensive. Inspired by the recent developments in mechanistic interpretability, we introduce ci</span>
                
                <span class="abstract-full" style="display: none;">Extensively evaluating the capabilities of (large) language models is difficult. Rapid development of state-of-the-art models induce benchmark saturation, while creating more challenging datasets is labor-intensive. Inspired by the recent developments in mechanistic interpretability, we introduce circuit stability as a new way to assess model performance. Circuit stability refers to a model's ability to apply a consistent reasoning process-its circuit-across various inputs. We mathematically formalize circuit stability and circuit equivalence. Then, through three case studies, we empirically show that circuit stability and the lack thereof can characterize and predict different aspects of generalization. Our proposed methods offer a step towards rigorously relating the generality of models to their interpretability.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 11.7%">
                            LLMs
                        </span>
                <!-- Federated Learning: 2.8 -->
                    
                <!-- Evolutionary Algorithms: 2.3 -->
                    
                <!-- Medicine: 2.2 -->
                    
                <!-- GNN: 2.1 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Bayesian Optimization: 1.6 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- Hardware: 1.0 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.0927
                </span>
                <a href="https://arxiv.org/abs/2505.24138" target="_blank" rel="noopener noreferrer">AMSbench: A Comprehensive Benchmark for Evaluating MLLM Capabilities in AMS Circuits</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yichen Shi, Ze Zhang, Hongyang Wang, Zhuofu Tao, Zhongyi Li, Bingyu Chen, Yaxin Wang, Zhiping Yu, Ting-Jung Lin, Lei He
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Analog/Mixed-Signal (AMS) circuits play a critical role in the integrated circuit (IC) industry. However, automating Analog/Mixed-Signal (AMS) circuit design has remained a longstanding challenge due to its difficulty and complexity. Recent advances in Multi-modal Large Language Models (MLLMs) offer</span>
                
                <span class="abstract-full" style="display: none;">Analog/Mixed-Signal (AMS) circuits play a critical role in the integrated circuit (IC) industry. However, automating Analog/Mixed-Signal (AMS) circuit design has remained a longstanding challenge due to its difficulty and complexity. Recent advances in Multi-modal Large Language Models (MLLMs) offer promising potential for supporting AMS circuit analysis and design. However, current research typically evaluates MLLMs on isolated tasks within the domain, lacking a comprehensive benchmark that systematically assesses model capabilities across diverse AMS-related challenges. To address this gap, we introduce AMSbench, a benchmark suite designed to evaluate MLLM performance across critical tasks including circuit schematic perception, circuit analysis, and circuit design. AMSbench comprises approximately 8000 test questions spanning multiple difficulty levels and assesses eight prominent models, encompassing both open-source and proprietary solutions such as Qwen 2.5-VL and Gemini 2.5 Pro. Our evaluation highlights significant limitations in current MLLMs, particularly in complex multi-modal reasoning and sophisticated circuit design tasks. These results underscore the necessity of advancing MLLMs' understanding and effective application of circuit-specific knowledge, thereby narrowing the existing performance gap relative to human expertise and moving toward fully automated AMS circuit design workflows. Our data is released at https://huggingface.co/datasets/wwhhyy/AMSBench</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 13.0%">
                            LLMs
                        </span>
                <!-- Medicine: 2.9 -->
                    
                <!-- Hardware: 2.8 -->
                    
                <!-- Computer Vision: 2.4 -->
                    
                <!-- Blockchain: 2.2 -->
                    
                <!-- Datasets: 2.1 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- T2I: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.0944
                </span>
                <a href="https://arxiv.org/abs/2501.03191" target="_blank" rel="noopener noreferrer">CLIX: Cross-Lingual Explanations of Idiomatic Expressions</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Aaron Gluck, Katharina von der Wense, Maria Leonor Pacheco
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Automated definition generation systems have been proposed to support vocabulary expansion for language learners. The main barrier to the success of these systems is that learners often struggle to understand definitions due to the presence of potentially unfamiliar words and grammar, particularly w</span>
                
                <span class="abstract-full" style="display: none;">Automated definition generation systems have been proposed to support vocabulary expansion for language learners. The main barrier to the success of these systems is that learners often struggle to understand definitions due to the presence of potentially unfamiliar words and grammar, particularly when non-standard language is involved. To address these challenges, we propose CLIX, the task of Cross-Lingual explanations of Idiomatic eXpressions. We explore the capabilities of current NLP models for this task, and observe that while it remains challenging, large language models show promise. Finally, we perform a detailed error analysis to highlight the key challenges that need to be addressed before we can reliably incorporate these systems into educational tools.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 10.4%">
                            LLMs
                        </span>
                <!-- Federated Learning: 3.8 -->
                    
                <!-- Bayesian Optimization: 3.3 -->
                    
                <!-- GNN: 2.4 -->
                    
                <!-- Medicine: 2.3 -->
                    
                <!-- Quantum Computing: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Computer Vision: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.1014
                </span>
                <a href="https://arxiv.org/abs/2505.24499" target="_blank" rel="noopener noreferrer">Reason-SVG: Hybrid Reward RL for Aha-Moments in Vector Graphics Generation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ximing Xing, Yandong Guan, Jing Zhang, Dong Xu, Qian Yu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Generating high-quality Scalable Vector Graphics (SVGs) is challenging for Large Language Models (LLMs), as it requires advanced reasoning for structural validity, semantic faithfulness, and visual coherence -- capabilities in which current LLMs often fall short. In this work, we introduce Reason-SV</span>
                
                <span class="abstract-full" style="display: none;">Generating high-quality Scalable Vector Graphics (SVGs) is challenging for Large Language Models (LLMs), as it requires advanced reasoning for structural validity, semantic faithfulness, and visual coherence -- capabilities in which current LLMs often fall short. In this work, we introduce Reason-SVG, a novel framework designed to enhance LLM reasoning for SVG generation. Reason-SVG pioneers the "Drawing-with-Thought" (DwT) paradigm, in which models generate both SVG code and explicit design rationales, mimicking the human creative process. Reason-SVG adopts a two-stage training strategy: First, Supervised Fine-Tuning (SFT) trains the LLM on the DwT paradigm to activate foundational reasoning abilities. Second, Reinforcement Learning (RL), utilizing Group Relative Policy Optimization (GRPO), empowers the model to generate both DwT and SVGs rationales through refined, reward-driven reasoning. To facilitate reasoning-driven SVG generation, we design a Hybrid Reward function that evaluates the presence and utility of DwT reasoning, along with structural validity, semantic alignment, and visual quality. We also introduce the SVGX-DwT-10k dataset, a high-quality corpus of 10,000 SVG-DwT pairs, where each SVG code is generated based on explicit DwT reasoning. By integrating DwT, SFT, and Hybrid Reward-guided RL, Reason-SVG significantly improves LLM performance in generating accurate and visually compelling SVGs, potentially fostering "Aha moments" in design.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 13.2%">
                            LLMs
                        </span>
                <!-- Computer Vision: 3.0 -->
                    
                <!-- Medicine: 2.8 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Quantum Computing: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.1034
                </span>
                <a href="https://arxiv.org/abs/2502.15197" target="_blank" rel="noopener noreferrer">TETRIS: Optimal Draft Token Selection for Batch Speculative Decoding</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zhaoxuan Wu, Zijian Zhou, Arun Verma, Alok Prakash, Daniela Rus, Bryan Kian Hsiang Low
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We propose TETRIS, a novel method that optimizes the total throughput of batch speculative decoding in multi-request settings. Unlike existing methods that optimize for a single request or a group of requests as a whole, TETRIS actively selects the most promising draft tokens (for every request in a</span>
                
                <span class="abstract-full" style="display: none;">We propose TETRIS, a novel method that optimizes the total throughput of batch speculative decoding in multi-request settings. Unlike existing methods that optimize for a single request or a group of requests as a whole, TETRIS actively selects the most promising draft tokens (for every request in a batch) to be accepted when verified in parallel, resulting in fewer rejected tokens and hence less wasted computing resources. Such an effective resource utilization to achieve fast inference in large language models (LLMs) is especially important to service providers with limited inference capacity. Compared to baseline speculative decoding, TETRIS yields a consistently higher acceptance rate and more effective utilization of the limited inference capacity. We show theoretically and empirically that TETRIS outperforms baseline speculative decoding and existing methods that dynamically select draft tokens, leading to a more efficient batch inference in LLMs.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 17.6%">
                            LLMs
                        </span>
                <!-- Quantum Computing: 2.0 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Networks: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Medicine: 1.1 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                <!-- Game Theory: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.1138
                </span>
                <a href="https://arxiv.org/abs/2505.24238" target="_blank" rel="noopener noreferrer">MIRAGE: Assessing Hallucination in Multimodal Reasoning Chains of MLLM</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Bowen Dong, Minheng Ni, Zitong Huang, Guanglei Yang, Wangmeng Zuo, Lei Zhang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Multimodal hallucination in multimodal large language models (MLLMs) restricts the correctness of MLLMs. However, multimodal hallucinations are multi-sourced and arise from diverse causes. Existing benchmarks fail to adequately distinguish between perception-induced hallucinations and reasoning-indu</span>
                
                <span class="abstract-full" style="display: none;">Multimodal hallucination in multimodal large language models (MLLMs) restricts the correctness of MLLMs. However, multimodal hallucinations are multi-sourced and arise from diverse causes. Existing benchmarks fail to adequately distinguish between perception-induced hallucinations and reasoning-induced hallucinations. This failure constitutes a significant issue and hinders the diagnosis of multimodal reasoning failures within MLLMs. To address this, we propose the {\dataset} benchmark, which isolates reasoning hallucinations by constructing questions where input images are correctly perceived by MLLMs yet reasoning errors persist. {\dataset} introduces multi-granular evaluation metrics: accuracy, factuality, and LLMs hallucination score for hallucination quantification. Our analysis reveals that (1) the model scale, data scale, and training stages significantly affect the degree of logical, fabrication, and factual hallucinations; (2) current MLLMs show no effective improvement on spatial hallucinations caused by misinterpreted spatial relationships, indicating their limited visual reasoning capabilities; and (3) question types correlate with distinct hallucination patterns, highlighting targeted challenges and potential mitigation strategies. To address these challenges, we propose {\method}, a method that combines curriculum reinforcement fine-tuning to encourage models to generate logic-consistent reasoning chains by stepwise reducing learning difficulty, and collaborative hint inference to reduce reasoning complexity. {\method} establishes a baseline on {\dataset}, and reduces the logical hallucinations in original base models.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 13.7%">
                            LLMs
                        </span>
                <!-- Medicine: 3.8 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- Blockchain: 2.2 -->
                    
                <!-- Computer Vision: 1.9 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- 3D: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.1139
                </span>
                <a href="https://arxiv.org/abs/2505.23912" target="_blank" rel="noopener noreferrer">Reinforcement Learning for Better Verbalized Confidence in Long-Form Generation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Caiqi Zhang, Xiaochen Zhu, Chengzu Li, Nigel Collier, Andreas Vlachos
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Hallucination remains a major challenge for the safe and trustworthy deployment of large language models (LLMs) in factual content generation. Prior work has explored confidence estimation as an effective approach to hallucination detection, but often relies on post-hoc self-consistency methods that</span>
                
                <span class="abstract-full" style="display: none;">Hallucination remains a major challenge for the safe and trustworthy deployment of large language models (LLMs) in factual content generation. Prior work has explored confidence estimation as an effective approach to hallucination detection, but often relies on post-hoc self-consistency methods that require computationally expensive sampling. Verbalized confidence offers a more efficient alternative, but existing approaches are largely limited to short-form question answering (QA) tasks and do not generalize well to open-ended generation. In this paper, we propose LoVeC (Long-form Verbalized Confidence), an on-the-fly verbalized confidence estimation method for long-form generation. Specifically, we use reinforcement learning (RL) to train LLMs to append numerical confidence scores to each generated statement, serving as a direct and interpretable signal of the factuality of generation. Our experiments consider both on-policy and off-policy RL methods, including DPO, ORPO, and GRPO, to enhance the model calibration. We introduce two novel evaluation settings, free-form tagging and iterative tagging, to assess different verbalized confidence estimation methods. Experiments on three long-form QA datasets show that our RL-trained models achieve better calibration and generalize robustly across domains. Also, our method is highly efficient, as it only requires adding a few tokens to the output being decoded.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 14.8%">
                            LLMs
                        </span>
                <!-- Computer Vision: 2.3 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- Reinforcement Learning: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- Medicine: 1.6 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Hardware: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.1384
                </span>
                <a href="https://arxiv.org/abs/2505.23830" target="_blank" rel="noopener noreferrer">EvoMoE: Expert Evolution in Mixture of Experts for Multimodal Large Language Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Linglin Jing, Yuting Gao, Zhigang Wang, Wang Lan, Yiwen Tang, Wenhai Wang, Kaipeng Zhang, Qingpei Guo
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Recent advancements have shown that the Mixture of Experts (MoE) approach significantly enhances the capacity of large language models (LLMs) and improves performance on downstream tasks. Building on these promising results, multi-modal large language models (MLLMs) have increasingly adopted MoE tec</span>
                
                <span class="abstract-full" style="display: none;">Recent advancements have shown that the Mixture of Experts (MoE) approach significantly enhances the capacity of large language models (LLMs) and improves performance on downstream tasks. Building on these promising results, multi-modal large language models (MLLMs) have increasingly adopted MoE techniques. However, existing multi-modal MoE tuning methods typically face two key challenges: expert uniformity and router rigidity. Expert uniformity occurs because MoE experts are often initialized by simply replicating the FFN parameters from LLMs, leading to homogenized expert functions and weakening the intended diversification of the MoE architecture. Meanwhile, router rigidity stems from the prevalent use of static linear routers for expert selection, which fail to distinguish between visual and textual tokens, resulting in similar expert distributions for image and text. To address these limitations, we propose EvoMoE, an innovative MoE tuning framework. EvoMoE introduces a meticulously designed expert initialization strategy that progressively evolves multiple robust experts from a single trainable expert, a process termed expert evolution that specifically targets severe expert homogenization. Furthermore, we introduce the Dynamic Token-aware Router (DTR), a novel routing mechanism that allocates input tokens to appropriate experts based on their modality and intrinsic token values. This dynamic routing is facilitated by hypernetworks, which dynamically generate routing weights tailored for each individual token. Extensive experiments demonstrate that EvoMoE significantly outperforms other sparse MLLMs across a variety of multi-modal benchmarks, including MME, MMBench, TextVQA, and POPE. Our results highlight the effectiveness of EvoMoE in enhancing the performance of MLLMs by addressing the critical issues of expert uniformity and router rigidity.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 16.6%">
                            LLMs
                        </span>
                <!-- Medicine: 3.5 -->
                    
                <!-- Federated Learning: 2.6 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Datasets: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.159
                </span>
                <a href="https://arxiv.org/abs/2505.24716" target="_blank" rel="noopener noreferrer">Towards Scalable Schema Mapping using Large Language Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Christopher Buss, Mahdis Safari, Arash Termehchy, Stefan Lee, David Maier
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The growing need to integrate information from a large number of diverse sources poses significant scalability challenges for data integration systems. These systems often rely on manually written schema mappings, which are complex, source-specific, and costly to maintain as sources evolve. While re</span>
                
                <span class="abstract-full" style="display: none;">The growing need to integrate information from a large number of diverse sources poses significant scalability challenges for data integration systems. These systems often rely on manually written schema mappings, which are complex, source-specific, and costly to maintain as sources evolve. While recent advances suggest that large language models (LLMs) can assist in automating schema matching by leveraging both structural and natural language cues, key challenges remain. In this paper, we identify three core issues with using LLMs for schema mapping: (1) inconsistent outputs due to sensitivity to input phrasing and structure, which we propose methods to address through sampling and aggregation techniques; (2) the need for more expressive mappings (e.g., GLaV), which strain the limited context windows of LLMs; and (3) the computational cost of repeated LLM calls, which we propose to mitigate through strategies like data type prefiltering.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 22.3%">
                            LLMs
                        </span>
                <!-- Medicine: 3.1 -->
                    
                <!-- Hardware: 2.2 -->
                    
                <!-- Computer Vision: 2.2 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- 3D: 1.1 -->
                    
                <!-- Datasets: 1.0 -->
                    
                <!-- Bayesian Optimization: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.2044
                </span>
                <a href="https://arxiv.org/abs/2505.23944" target="_blank" rel="noopener noreferrer">Retrieval Augmented Generation based Large Language Models for Causality Mining</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Thushara Manjari Naduvilakandy, Hyeju Jang, Mohammad Al Hasan
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Causality detection and mining are important tasks in information retrieval due to their enormous use in information extraction, and knowledge graph construction. To solve these tasks, in existing literature there exist several solutions -- both unsupervised and supervised. However, the unsupervised</span>
                
                <span class="abstract-full" style="display: none;">Causality detection and mining are important tasks in information retrieval due to their enormous use in information extraction, and knowledge graph construction. To solve these tasks, in existing literature there exist several solutions -- both unsupervised and supervised. However, the unsupervised methods suffer from poor performance and they often require significant human intervention for causal rule selection, leading to poor generalization across different domains. On the other hand, supervised methods suffer from the lack of large training datasets. Recently, large language models (LLMs) with effective prompt engineering are found to be effective to overcome the issue of unavailability of large training dataset. Yet, in existing literature, there does not exist comprehensive works on causality detection and mining using LLM prompting. In this paper, we present several retrieval-augmented generation (RAG) based dynamic prompting schemes to enhance LLM performance in causality detection and extraction tasks. Extensive experiments over three datasets and five LLMs validate the superiority of our proposed RAG-based dynamic prompting over other static prompting schemes.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 24.5%">
                            LLMs
                        </span>
                <!-- Computer Vision: 4.6 -->
                    
                <!-- GNN: 2.2 -->
                    
                <!-- Medicine: 2.1 -->
                    
                <!-- Federated Learning: 1.6 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Quantum Computing: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.2446
                </span>
                <a href="https://arxiv.org/abs/2505.24012" target="_blank" rel="noopener noreferrer">Large Language Model Meets Constraint Propagation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Alexandre Bonlarron, Florian R\'egin, Elisabetta De Maria, Jean-Charles R\'egin
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Large Language Models (LLMs) excel at generating fluent text but struggle to enforce external constraints because they generate tokens sequentially without explicit control mechanisms. GenCP addresses this limitation by combining LLM predictions with Constraint Programming (CP) reasoning, formulatin</span>
                
                <span class="abstract-full" style="display: none;">Large Language Models (LLMs) excel at generating fluent text but struggle to enforce external constraints because they generate tokens sequentially without explicit control mechanisms. GenCP addresses this limitation by combining LLM predictions with Constraint Programming (CP) reasoning, formulating text generation as a Constraint Satisfaction Problem (CSP). In this paper, we improve GenCP by integrating Masked Language Models (MLMs) for domain generation, which allows bidirectional constraint propagation that leverages both past and future tokens. This integration bridges the gap between token-level prediction and structured constraint enforcement, leading to more reliable and constraint-aware text generation. Our evaluation on COLLIE benchmarks demonstrates that incorporating domain preview via MLM calls significantly improves GenCP's performance. Although this approach incurs additional MLM calls and, in some cases, increased backtracking, the overall effect is a more efficient use of LLM inferences and an enhanced ability to generate feasible and meaningful solutions, particularly in tasks with strict content constraints.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 34.2%">
                            LLMs
                        </span>
                <!-- Medicine: 2.2 -->
                    
                <!-- Computer Vision: 2.1 -->
                    
                <!-- HPO and AutoML: 2.1 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- T2I: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.2656
                </span>
                <a href="https://arxiv.org/abs/2505.23945" target="_blank" rel="noopener noreferrer">A Closer Look at Bias and Chain-of-Thought Faithfulness of Large (Vision) Language Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Sriram Balasubramanian, Samyadeep Basu, Soheil Feizi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Chain-of-thought (CoT) reasoning enhances performance of large language models, but questions remain about whether these reasoning traces faithfully reflect the internal processes of the model. We present the first comprehensive study of CoT faithfulness in large vision-language models (LVLMs), inve</span>
                
                <span class="abstract-full" style="display: none;">Chain-of-thought (CoT) reasoning enhances performance of large language models, but questions remain about whether these reasoning traces faithfully reflect the internal processes of the model. We present the first comprehensive study of CoT faithfulness in large vision-language models (LVLMs), investigating how both text-based and previously unexplored image-based biases affect reasoning and bias articulation. Our work introduces a novel, fine-grained evaluation pipeline for categorizing bias articulation patterns, enabling significantly more precise analysis of CoT reasoning than previous methods. This framework reveals critical distinctions in how models process and respond to different types of biases, providing new insights into LVLM CoT faithfulness. Our findings reveal that subtle image-based biases are rarely articulated compared to explicit text-based ones, even in models specialized for reasoning. Additionally, many models exhibit a previously unidentified phenomenon we term ``inconsistent'' reasoning - correctly reasoning before abruptly changing answers, serving as a potential canary for detecting biased reasoning from unfaithful CoTs. We then apply the same evaluation pipeline to revisit CoT faithfulness in LLMs across various levels of implicit cues. Our findings reveal that current language-only reasoning models continue to struggle with articulating cues that are not overtly stated.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 34.5%">
                            LLMs
                        </span>
                <!-- Medicine: 2.1 -->
                    
                <!-- Datasets: 1.9 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.4 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Robotics: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.2743
                </span>
                <a href="https://arxiv.org/abs/2505.24864" target="_blank" rel="noopener noreferrer">ProRL: Prolonged Reinforcement Learning Expands Reasoning Boundaries in Large Language Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Mingjie Liu, Shizhe Diao, Ximing Lu, Jian Hu, Xin Dong, Yejin Choi, Jan Kautz, Yi Dong
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Recent advances in reasoning-centric language models have highlighted reinforcement learning (RL) as a promising method for aligning models with verifiable rewards. However, it remains contentious whether RL truly expands a model's reasoning capabilities or merely amplifies high-reward outputs alrea</span>
                
                <span class="abstract-full" style="display: none;">Recent advances in reasoning-centric language models have highlighted reinforcement learning (RL) as a promising method for aligning models with verifiable rewards. However, it remains contentious whether RL truly expands a model's reasoning capabilities or merely amplifies high-reward outputs already latent in the base model's distribution, and whether continually scaling up RL compute reliably leads to improved reasoning performance. In this work, we challenge prevailing assumptions by demonstrating that prolonged RL (ProRL) training can uncover novel reasoning strategies that are inaccessible to base models, even under extensive sampling. We introduce ProRL, a novel training methodology that incorporates KL divergence control, reference policy resetting, and a diverse suite of tasks. Our empirical analysis reveals that RL-trained models consistently outperform base models across a wide range of pass@k evaluations, including scenarios where base models fail entirely regardless of the number of attempts. We further show that reasoning boundary improvements correlates strongly with task competence of base model and training duration, suggesting that RL can explore and populate new regions of solution space over time. These findings offer new insights into the conditions under which RL meaningfully expands reasoning boundaries in language models and establish a foundation for future work on long-horizon RL for reasoning. We release model weights to support further research: https://huggingface.co/nvidia/Nemotron-Research-Reasoning-Qwen-1.5B</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 35.7%">
                            LLMs
                        </span>
                <!-- Medicine: 2.5 -->
                    
                <!-- Quantum Computing: 2.0 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Hardware: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.2825
                </span>
                <a href="https://arxiv.org/abs/2505.23982" target="_blank" rel="noopener noreferrer">MSQA: Benchmarking LLMs on Graduate-Level Materials Science Reasoning and Knowledge</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jerry Junyang Cheung, Shiyao Shen, Yuchen Zhuang, Yinghao Li, Rampi Ramprasad, Chao Zhang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Despite recent advances in large language models (LLMs) for materials science, there is a lack of benchmarks for evaluating their domain-specific knowledge and complex reasoning abilities. To bridge this gap, we introduce MSQA, a comprehensive evaluation benchmark of 1,757 graduate-level materials s</span>
                
                <span class="abstract-full" style="display: none;">Despite recent advances in large language models (LLMs) for materials science, there is a lack of benchmarks for evaluating their domain-specific knowledge and complex reasoning abilities. To bridge this gap, we introduce MSQA, a comprehensive evaluation benchmark of 1,757 graduate-level materials science questions in two formats: detailed explanatory responses and binary True/False assessments. MSQA distinctively challenges LLMs by requiring both precise factual knowledge and multi-step reasoning across seven materials science sub-fields, such as structure-property relationships, synthesis processes, and computational modeling. Through experiments with 10 state-of-the-art LLMs, we identify significant gaps in current LLM performance. While API-based proprietary LLMs achieve up to 84.5% accuracy, open-source (OSS) LLMs peak around 60.5%, and domain-specific LLMs often underperform significantly due to overfitting and distributional shifts. MSQA represents the first benchmark to jointly evaluate the factual and reasoning capabilities of LLMs crucial for LLMs in advanced materials science.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 39.5%">
                            LLMs
                        </span>
                <!-- Medicine: 2.8 -->
                    
                <!-- Computer Vision: 2.2 -->
                    
                <!-- Datasets: 2.1 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Blockchain: 2.0 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- 3D: 1.1 -->
                    
                <!-- T2I: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.0565
                </span>
                <a href="https://arxiv.org/abs/2505.23923" target="_blank" rel="noopener noreferrer">ChARM: Character-based Act-adaptive Reward Modeling for Advanced Role-Playing Language Agents</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Feiteng Fang, Ting-En Lin, Yuchuan Wu, Xiong Liu, Xiang Huang, Dingwei Chen, Jing Ye, Haonan Zhang, Liang Zhu, Hamid Alinejad-Rokny, Min Yang, Fei Huang, Yongbin Li
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Role-Playing Language Agents (RPLAs) aim to simulate characters for realistic and engaging human-computer interactions. However, traditional reward models often struggle with scalability and adapting to subjective conversational preferences. We propose ChARM, a Character-based Act-adaptive Reward Mo</span>
                
                <span class="abstract-full" style="display: none;">Role-Playing Language Agents (RPLAs) aim to simulate characters for realistic and engaging human-computer interactions. However, traditional reward models often struggle with scalability and adapting to subjective conversational preferences. We propose ChARM, a Character-based Act-adaptive Reward Model, addressing these challenges through two innovations: (1) an act-adaptive margin that significantly enhances learning efficiency and generalizability, and (2) a self-evolution mechanism leveraging large-scale unlabeled data to improve training coverage. Additionally, we introduce RoleplayPref, the first large-scale preference dataset specifically for RPLAs, featuring 1,108 characters, 13 subcategories, and 16,888 bilingual dialogues, alongside RoleplayEval, a dedicated evaluation benchmark. Experimental results show a 13% improvement over the conventional Bradley-Terry model in preference rankings. Furthermore, applying ChARM-generated rewards to preference learning techniques (e.g., direct preference optimization) achieves state-of-the-art results on CharacterEval and RoleplayEval. Code and dataset are available at https://github.com/calubkk/ChARM.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.0%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.1%">
                            Medicine
                        </span>
                <!-- Computer Vision: 2.8 -->
                    
                <!-- 3D: 2.2 -->
                    
                <!-- GNN: 2.1 -->
                    
                <!-- HPO and AutoML: 1.9 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- T2I: 1.0 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.0949
                </span>
                <a href="https://arxiv.org/abs/2505.24760" target="_blank" rel="noopener noreferrer">REASONING GYM: Reasoning Environments for Reinforcement Learning with Verifiable Rewards</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zafir Stojanovski, Oliver Stanley, Joe Sharratt, Richard Jones, Abdulhakeem Adefioye, Jean Kaddour, Andreas K\"opf
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We introduce Reasoning Gym (RG), a library of reasoning environments for reinforcement learning with verifiable rewards. It provides over 100 data generators and verifiers spanning multiple domains including algebra, arithmetic, computation, cognition, geometry, graph theory, logic, and various comm</span>
                
                <span class="abstract-full" style="display: none;">We introduce Reasoning Gym (RG), a library of reasoning environments for reinforcement learning with verifiable rewards. It provides over 100 data generators and verifiers spanning multiple domains including algebra, arithmetic, computation, cognition, geometry, graph theory, logic, and various common games. Its key innovation is the ability to generate virtually infinite training data with adjustable complexity, unlike most previous reasoning datasets, which are typically fixed. This procedural generation approach allows for continuous evaluation across varying difficulty levels. Our experimental results demonstrate the efficacy of RG in both evaluating and reinforcement learning of reasoning models.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.9%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.3%">
                            Medicine
                        </span>
                <!-- Federated Learning: 2.2 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- HPO and AutoML: 2.0 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Datasets: 1.8 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- 3D: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.1277
                </span>
                <a href="https://arxiv.org/abs/2502.03444" target="_blank" rel="noopener noreferrer">Masked Autoencoders Are Effective Tokenizers for Diffusion Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Hao Chen, Yujin Han, Fangyi Chen, Xiang Li, Yidong Wang, Jindong Wang, Ze Wang, Zicheng Liu, Difan Zou, Bhiksha Raj
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Recent advances in latent diffusion models have demonstrated their effectiveness for high-resolution image synthesis. However, the properties of the latent space from tokenizer for better learning and generation of diffusion models remain under-explored. Theoretically and empirically, we find that i</span>
                
                <span class="abstract-full" style="display: none;">Recent advances in latent diffusion models have demonstrated their effectiveness for high-resolution image synthesis. However, the properties of the latent space from tokenizer for better learning and generation of diffusion models remain under-explored. Theoretically and empirically, we find that improved generation quality is closely tied to the latent distributions with better structure, such as the ones with fewer Gaussian Mixture modes and more discriminative features. Motivated by these insights, we propose MAETok, an autoencoder (AE) leveraging mask modeling to learn semantically rich latent space while maintaining reconstruction fidelity. Extensive experiments validate our analysis, demonstrating that the variational form of autoencoders is not necessary, and a discriminative latent space from AE alone enables state-of-the-art performance on ImageNet generation using only 128 tokens. MAETok achieves significant practical improvements, enabling a gFID of 1.69 with 76x faster training and 31x higher inference throughput for 512x512 generation. Our findings show that the structure of the latent space, rather than variational constraints, is crucial for effective diffusion models. Code and trained models are released.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.7%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.1%">
                            Medicine
                        </span>
                <!-- Computer Vision: 2.1 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- T2I: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.1722
                </span>
                <a href="https://arxiv.org/abs/2505.23809" target="_blank" rel="noopener noreferrer">LLM-Driven E-Commerce Marketing Content Optimization: Balancing Creativity and Conversion</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Haowei Yang, Haotian Lyu, Tianle Zhang, Dingzhou Wang, Yushang Zhao
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">As e-commerce competition intensifies, balancing creative content with conversion effectiveness becomes critical. Leveraging LLMs' language generation capabilities, we propose a framework that integrates prompt engineering, multi-objective fine-tuning, and post-processing to generate marketing copy </span>
                
                <span class="abstract-full" style="display: none;">As e-commerce competition intensifies, balancing creative content with conversion effectiveness becomes critical. Leveraging LLMs' language generation capabilities, we propose a framework that integrates prompt engineering, multi-objective fine-tuning, and post-processing to generate marketing copy that is both engaging and conversion-driven. Our fine-tuning method combines sentiment adjustment, diversity enhancement, and CTA embedding. Through offline evaluations and online A/B tests across categories, our approach achieves a 12.5 % increase in CTR and an 8.3 % increase in CVR while maintaining content novelty. This provides a practical solution for automated copy generation and suggests paths for future multimodal, real-time personalization.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 12.1%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.1%">
                            Medicine
                        </span>
                <!-- 3D: 2.6 -->
                    
                <!-- Computer Vision: 2.2 -->
                    
                <!-- HPO and AutoML: 1.9 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- T2I: 1.7 -->
                    
                <!-- Datasets: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.1841
                </span>
                <a href="https://arxiv.org/abs/2505.20939" target="_blank" rel="noopener noreferrer">Ergonomic Assessment of Work Activities for an Industrial-oriented Wrist Exoskeleton</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Roberto F. Pitzalis, Nicholas Cartocci, Christian Di Natali, Luigi Monica, Darwin G. Caldwell, Giovanni Berselli, Jes\'us Ortiz
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Musculoskeletal disorders (MSD) are the most common cause of work-related injuries and lost production involving approximately 1.7 billion people worldwide and mainly affect low back (more than 50%) and upper limbs (more than 40%). It has a profound effect on both the workers affected and the compan</span>
                
                <span class="abstract-full" style="display: none;">Musculoskeletal disorders (MSD) are the most common cause of work-related injuries and lost production involving approximately 1.7 billion people worldwide and mainly affect low back (more than 50%) and upper limbs (more than 40%). It has a profound effect on both the workers affected and the company. This paper provides an ergonomic assessment of different work activities in a horse saddle-making company, involving 5 workers. This aim guides the design of a wrist exoskeleton to reduce the risk of musculoskeletal diseases wherever it is impossible to automate the production process. This evaluation is done either through subjective and objective measurement, respectively using questionnaires and by measurement of muscle activation with sEMG sensors.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.1%">
                            Medicine
                        </span>
                <!-- LLMs: 3.9 -->
                    
                <!-- Evolutionary Algorithms: 3.2 -->
                    
                <!-- Federated Learning: 2.6 -->
                    
                <!-- Hardware: 2.4 -->
                    
                <!-- Blockchain: 2.4 -->
                    
                <!-- Datasets: 1.7 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Computer Vision: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.1925
                </span>
                <a href="https://arxiv.org/abs/2505.24874" target="_blank" rel="noopener noreferrer">The Road to Generalizable Neuro-Symbolic Learning Should be Paved with Foundation Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Adam Stein, Aaditya Naik, Neelay Velingker, Mayur Naik, Eric Wong
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Neuro-symbolic learning was proposed to address challenges with training neural networks for complex reasoning tasks with the added benefits of interpretability, reliability, and efficiency. Neuro-symbolic learning methods traditionally train neural models in conjunction with symbolic programs, but </span>
                
                <span class="abstract-full" style="display: none;">Neuro-symbolic learning was proposed to address challenges with training neural networks for complex reasoning tasks with the added benefits of interpretability, reliability, and efficiency. Neuro-symbolic learning methods traditionally train neural models in conjunction with symbolic programs, but they face significant challenges that limit them to simplistic problems. On the other hand, purely-neural foundation models now reach state-of-the-art performance through prompting rather than training, but they are often unreliable and lack interpretability. Supplementing foundation models with symbolic programs, which we call neuro-symbolic prompting, provides a way to use these models for complex reasoning tasks. Doing so raises the question: What role does specialized model training as part of neuro-symbolic learning have in the age of foundation models? To explore this question, we highlight three pitfalls of traditional neuro-symbolic learning with respect to the compute, data, and programs leading to generalization problems. This position paper argues that foundation models enable generalizable neuro-symbolic solutions, offering a path towards achieving the original goals of neuro-symbolic learning without the downsides of training from scratch.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.4%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.1%">
                            LLMs
                        </span>
                <!-- Federated Learning: 3.6 -->
                    
                <!-- GNN: 2.6 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.4 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.1957
                </span>
                <a href="https://arxiv.org/abs/2505.24551" target="_blank" rel="noopener noreferrer">Melding the Serverless Control Plane with the Conventional Cluster Manager for Speed and Compatibility</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Leonid Kondrashov, Lazar Cvetkovi\'c, Hancheng Wang, Boxi Zhou, Dhairya Rungta, Dmitrii Ustiugov
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Modern serverless applications, often interactive with highly volatile traffic, challenge system scalability, demanding control planes that deliver low latency and cost efficiency. Analysis of production traces and existing systems reveals that current control plane designs (synchronous and asynchro</span>
                
                <span class="abstract-full" style="display: none;">Modern serverless applications, often interactive with highly volatile traffic, challenge system scalability, demanding control planes that deliver low latency and cost efficiency. Analysis of production traces and existing systems reveals that current control plane designs (synchronous and asynchronous), particularly when built on conventional cluster managers like Kubernetes, struggle with this balance, often wasting significant CPU and memory resources on creating underutilized or idle instances. While clean-slate approaches like Dirigent offer performance gains, they sacrifice compatibility with established cluster management ecosystems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.2%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.4%">
                            Medicine
                        </span>
                <!-- Blockchain: 2.8 -->
                    
                <!-- Hardware: 2.8 -->
                    
                <!-- Computer Vision: 2.6 -->
                    
                <!-- HPO and AutoML: 2.5 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- T2I: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.2081
                </span>
                <a href="https://arxiv.org/abs/2411.14207" target="_blank" rel="noopener noreferrer">HARP: A Large-Scale Higher-Order Ambisonic Room Impulse Response Dataset</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Shivam Saini, J\"urgen Peissig
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This contribution introduces a dataset of 7th-order Ambisonic Room Impulse Responses (HOA-RIRs), created using the Image Source Method. By employing higher-order Ambisonics, our dataset enables precise spatial audio reproduction, a critical requirement for realistic immersive audio applications. Lev</span>
                
                <span class="abstract-full" style="display: none;">This contribution introduces a dataset of 7th-order Ambisonic Room Impulse Responses (HOA-RIRs), created using the Image Source Method. By employing higher-order Ambisonics, our dataset enables precise spatial audio reproduction, a critical requirement for realistic immersive audio applications. Leveraging the virtual simulation, we present a unique microphone configuration, based on the superposition principle, designed to optimize sound field coverage while addressing the limitations of traditional microphone arrays. The presented 64-microphone configuration allows us to capture RIRs directly in the Spherical Harmonics domain. The dataset features a wide range of room configurations, encompassing variations in room geometry, acoustic absorption materials, and source-receiver distances. A detailed description of the simulation setup is provided alongside for an accurate reproduction. The dataset serves as a vital resource for researchers working on spatial audio, particularly in applications involving machine learning to improve room acoustics modeling and sound field synthesis. It further provides a very high level of spatial resolution and realism crucial for tasks such as source localization, reverberation prediction, and immersive sound reproduction.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.2%">
                            Medicine
                        </span>
                <!-- Datasets: 2.7 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Networks: 1.5 -->
                    
                <!-- LLMs: 1.5 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- Robotics: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.2084
                </span>
                <a href="https://arxiv.org/abs/2505.24231" target="_blank" rel="noopener noreferrer">Dynamic Malware Classification of Windows PE Files using CNNs and Greyscale Images Derived from Runtime API Call Argument Conversion</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Md Shahnawaz, Bishwajit Prasad Gond, Durga Prasad Mohapatra
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Malware detection and classification remains a topic of concern for cybersecurity, since it is becoming common for attackers to use advanced obfuscation on their malware to stay undetected. Conventional static analysis is not effective against polymorphic and metamorphic malware as these change thei</span>
                
                <span class="abstract-full" style="display: none;">Malware detection and classification remains a topic of concern for cybersecurity, since it is becoming common for attackers to use advanced obfuscation on their malware to stay undetected. Conventional static analysis is not effective against polymorphic and metamorphic malware as these change their appearance without modifying their behavior, thus defying the analysis by code structure alone. This makes it important to use dynamic detection that monitors malware behavior at runtime. In this paper, we present a dynamic malware categorization framework that extracts API argument calls at the runtime execution of Windows Portable Executable (PE) files. Extracting and encoding the dynamic features of API names, argument return values, and other relative features, we convert raw behavioral data to temporal patterns. To enhance feature portrayal, the generated patterns are subsequently converted into grayscale pictures using a magma colormap. These improved photos are used to teach a Convolutional Neural Network (CNN) model discriminative features, which allows for reliable and accurate malware classification. Results from experiments indicate that our method, with an average accuracy of 98.36% is effective in classifying different classes of malware and benign by integrating dynamic analysis and deep learning. It not only achieves high classification accuracy but also demonstrates significant resilience against typical evasion strategies.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.2%">
                            Medicine
                        </span>
                <!-- LLMs: 4.8 -->
                    
                <!-- Computer Vision: 2.6 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- GNN: 2.3 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- 3D: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.2135
                </span>
                <a href="https://arxiv.org/abs/2405.20710" target="_blank" rel="noopener noreferrer">i$^2$VAE: Interest Information Augmentation with Variational Regularizers for Cross-Domain Sequential Recommendation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Xuying Ning, Wujiang Xu, Tianxin Wei, Xiaolei Liu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Cross-Domain Sequential Recommendation (CDSR) leverages user behaviors across multiple domains to mitigate data sparsity and cold-start challenges in Single-Domain Sequential Recommendation. Existing methods primarily rely on shared users (overlapping users) to learn transferable interest representa</span>
                
                <span class="abstract-full" style="display: none;">Cross-Domain Sequential Recommendation (CDSR) leverages user behaviors across multiple domains to mitigate data sparsity and cold-start challenges in Single-Domain Sequential Recommendation. Existing methods primarily rely on shared users (overlapping users) to learn transferable interest representations. However, these approaches have limited information propagation, benefiting mainly overlapping users and those with rich interaction histories while neglecting non-overlapping (cold-start) and long-tailed users, who constitute the majority in real-world scenarios. To address this issue, we propose i$^2$VAE, a novel variational autoencoder (VAE)-based framework that enhances user interest learning with mutual information-based regularizers. i$^2$VAE improves recommendations for cold-start and long-tailed users while maintaining strong performance across all user groups. Specifically, cross-domain and disentangling regularizers extract transferable features for cold-start users, while a pseudo-sequence generator synthesizes interactions for long-tailed users, refined by a denoising regularizer to filter noise and preserve meaningful interest signals. Extensive experiments demonstrate that i$^2$VAE outperforms state-of-the-art methods, underscoring its effectiveness in real-world CDSR applications.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.8%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.4%">
                            Medicine
                        </span>
                <!-- Computer Vision: 3.2 -->
                    
                <!-- GNN: 2.5 -->
                    
                <!-- HPO and AutoML: 2.2 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- 3D: 2.0 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- T2I: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.2176
                </span>
                <a href="https://arxiv.org/abs/2505.24640" target="_blank" rel="noopener noreferrer">Efficient Text Encoders for Labor Market Analysis</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jens-Joris Decorte, Jeroen Van Hautte, Chris Develder, Thomas Demeester
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Labor market analysis relies on extracting insights from job advertisements, which provide valuable yet unstructured information on job titles and corresponding skill requirements. While state-of-the-art methods for skill extraction achieve strong performance, they depend on large language models (L</span>
                
                <span class="abstract-full" style="display: none;">Labor market analysis relies on extracting insights from job advertisements, which provide valuable yet unstructured information on job titles and corresponding skill requirements. While state-of-the-art methods for skill extraction achieve strong performance, they depend on large language models (LLMs), which are computationally expensive and slow. In this paper, we propose \textbf{ConTeXT-match}, a novel contrastive learning approach with token-level attention that is well-suited for the extreme multi-label classification task of skill classification. \textbf{ConTeXT-match} significantly improves skill extraction efficiency and performance, achieving state-of-the-art results with a lightweight bi-encoder model. To support robust evaluation, we introduce \textbf{Skill-XL}, a new benchmark with exhaustive, sentence-level skill annotations that explicitly address the redundancy in the large label space. Finally, we present \textbf{JobBERT V2}, an improved job title normalization model that leverages extracted skills to produce high-quality job title representations. Experiments demonstrate that our models are efficient, accurate, and scalable, making them ideal for large-scale, real-time labor market analysis.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.9%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.8%">
                            Medicine
                        </span>
                <!-- Computer Vision: 3.0 -->
                    
                <!-- GNN: 2.8 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- HPO and AutoML: 1.9 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- T2I: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.255
                </span>
                <a href="https://arxiv.org/abs/2504.20966" target="_blank" rel="noopener noreferrer">Softpick: No Attention Sink, No Massive Activations with Rectified Softmax</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zayd M. K. Zuhri, Erland Hilman Fuadi, Alham Fikri Aji
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We introduce softpick, a rectified, not sum-to-one, drop-in replacement for softmax in transformer attention mechanisms that eliminates attention sink and massive activations. Our experiments with 340M and 1.8B parameter models demonstrate that softpick achieves 0\% sink rate consistently. The softp</span>
                
                <span class="abstract-full" style="display: none;">We introduce softpick, a rectified, not sum-to-one, drop-in replacement for softmax in transformer attention mechanisms that eliminates attention sink and massive activations. Our experiments with 340M and 1.8B parameter models demonstrate that softpick achieves 0\% sink rate consistently. The softpick transformers produce hidden states with significantly lower kurtosis and creates sparse attention maps. Quantized models using softpick outperform softmax on standard benchmarks, with a particularly pronounced advantage at lower bit precisions. Our analysis and discussion shows how softpick has the potential to open new possibilities for quantization, low-precision training, sparsity optimization, pruning, and interpretability. Our code is available at https://github.com/zaydzuhri/softpick-attention</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.7%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.6%">
                            Medicine
                        </span>
                <!-- HPO and AutoML: 2.4 -->
                    
                <!-- Computer Vision: 2.4 -->
                    
                <!-- Decision Trees: 2.1 -->
                    
                <!-- Quantum Computing: 2.1 -->
                    
                <!-- 3D: 1.9 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- T2I: 1.4 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.2887
                </span>
                <a href="https://arxiv.org/abs/2410.02671" target="_blank" rel="noopener noreferrer">Unsupervised Point Cloud Completion through Unbalanced Optimal Transport</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Taekyung Lee, Jaemoo Choi, Jaewoong Choi, Myungjoo Kang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Unpaired point cloud completion is crucial for real-world applications, where ground-truth data for complete point clouds are often unavailable. By learning a completion map from unpaired incomplete and complete point cloud data, this task avoids the reliance on paired datasets. In this paper, we pr</span>
                
                <span class="abstract-full" style="display: none;">Unpaired point cloud completion is crucial for real-world applications, where ground-truth data for complete point clouds are often unavailable. By learning a completion map from unpaired incomplete and complete point cloud data, this task avoids the reliance on paired datasets. In this paper, we propose the \textit{Unbalanced Optimal Transport Map for Unpaired Point Cloud Completion (\textbf{UOT-UPC})} model, which formulates the unpaired completion task as the (Unbalanced) Optimal Transport (OT) problem. Our method employs a Neural OT model learning the UOT map using neural networks. Our model is the first attempt to leverage UOT for unpaired point cloud completion, achieving competitive or superior performance on both single-category and multi-category benchmarks. In particular, our approach is especially robust under the class imbalance problem, which is frequently encountered in real-world unpaired point cloud completion scenarios. The code is available at https://github.com/LEETK99/UOT-UPC.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.0%">
                            Medicine
                        </span>
                <!-- Computer Vision: 3.9 -->
                    
                <!-- GNN: 3.2 -->
                    
                <!-- 3D: 2.2 -->
                    
                <!-- HPO and AutoML: 2.2 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- LLMs: 1.6 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.293
                </span>
                <a href="https://arxiv.org/abs/2505.24197" target="_blank" rel="noopener noreferrer">Learning API Functionality from Demonstrations for Tool-based Agents</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Bhrij Patel, Ashish Jagmohan, Aditya Vempaty
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Digital tool-based agents that invoke external Application Programming Interfaces (APIs) often rely on documentation to understand API functionality. However, such documentation is frequently missing, outdated, privatized, or inconsistent-hindering the development of reliable, general-purpose agents</span>
                
                <span class="abstract-full" style="display: none;">Digital tool-based agents that invoke external Application Programming Interfaces (APIs) often rely on documentation to understand API functionality. However, such documentation is frequently missing, outdated, privatized, or inconsistent-hindering the development of reliable, general-purpose agents. In this work, we propose learning API functionality directly from demonstrations as a new paradigm applicable in scenarios without documentation. Using existing API benchmarks, we collect demonstrations from both expert API-based agents and from self-exploration. To understand what information demonstrations must convey for successful task completion, we extensively study how the number of demonstrations and the use of LLM-generated summaries and evaluations affect the task success rate of the API-based agent. Our experiments across 3 datasets and 5 models show that learning functionality from demonstrations remains a non-trivial challenge, even for state-of-the-art LLMs. We find that providing explicit function calls and natural language critiques significantly improves the agent's task success rate due to more accurate parameter filling. We analyze failure modes, identify sources of error, and highlight key open challenges for future work in documentation-free, self-improving, API-based agents.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.8%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.4%">
                            Medicine
                        </span>
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.3182
                </span>
                <a href="https://arxiv.org/abs/2505.16192" target="_blank" rel="noopener noreferrer">VLM-R$^3$: Region Recognition, Reasoning, and Refinement for Enhanced Multimodal Chain-of-Thought</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Chaoya Jiang, Yongrui Heng, Wei Ye, Han Yang, Haiyang Xu, Ming Yan, Ji Zhang, Fei Huang, Shikun Zhang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Recently, reasoning-based MLLMs have achieved a degree of success in generating long-form textual reasoning chains. However, they still struggle with complex tasks that necessitate dynamic and iterative focusing on and revisiting of visual regions to achieve precise grounding of textual reasoning in</span>
                
                <span class="abstract-full" style="display: none;">Recently, reasoning-based MLLMs have achieved a degree of success in generating long-form textual reasoning chains. However, they still struggle with complex tasks that necessitate dynamic and iterative focusing on and revisiting of visual regions to achieve precise grounding of textual reasoning in visual evidence. We introduce \textbf{VLM-R$^3$} (\textbf{V}isual \textbf{L}anguage \textbf{M}odel with \textbf{R}egion \textbf{R}ecognition and \textbf{R}easoning), a framework that equips an MLLM with the ability to (i) decide \emph{when} additional visual evidence is needed, (ii) determine \emph{where} to ground within the image, and (iii) seamlessly weave the relevant sub-image content back into an interleaved chain-of-thought. The core of our method is \textbf{Region-Conditioned Reinforcement Policy Optimization (R-GRPO)}, a training paradigm that rewards the model for selecting informative regions, formulating appropriate transformations (e.g.\ crop, zoom), and integrating the resulting visual context into subsequent reasoning steps. To bootstrap this policy, we compile a modest but carefully curated Visuo-Lingual Interleaved Rationale (VLIR) corpus that provides step-level supervision on region selection and textual justification. Extensive experiments on MathVista, ScienceQA, and other benchmarks show that VLM-R$^3$ sets a new state of the art in zero-shot and few-shot settings, with the largest gains appearing on questions demanding subtle spatial reasoning or fine-grained visual cue extraction.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.2%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.1%">
                            Medicine
                        </span>
                <!-- Computer Vision: 1.9 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- 3D: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.329
                </span>
                <a href="https://arxiv.org/abs/2505.23872" target="_blank" rel="noopener noreferrer">Parameter-Free Bio-Inspired Channel Attention for Enhanced Cardiac MRI Reconstruction</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Anam Hashmi, Julia Dietlmeier, Kathleen M. Curran, Noel E. O'Connor
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Attention is a fundamental component of the human visual recognition system. The inclusion of attention in a convolutional neural network amplifies relevant visual features and suppresses the less important ones. Integrating attention mechanisms into convolutional neural networks enhances model perf</span>
                
                <span class="abstract-full" style="display: none;">Attention is a fundamental component of the human visual recognition system. The inclusion of attention in a convolutional neural network amplifies relevant visual features and suppresses the less important ones. Integrating attention mechanisms into convolutional neural networks enhances model performance and interpretability. Spatial and channel attention mechanisms have shown significant advantages across many downstream tasks in medical imaging. While existing attention modules have proven to be effective, their design often lacks a robust theoretical underpinning. In this study, we address this gap by proposing a non-linear attention architecture for cardiac MRI reconstruction and hypothesize that insights from ecological principles can guide the development of effective and efficient attention mechanisms. Specifically, we investigate a non-linear ecological difference equation that describes single-species population growth to devise a parameter-free attention module surpassing current state-of-the-art parameter-free methods.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.5%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.6%">
                            LLMs
                        </span>
                <!-- GNN: 1.8 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.0 -->
                    
                <!-- T2I: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.3371
                </span>
                <a href="https://arxiv.org/abs/2505.24223" target="_blank" rel="noopener noreferrer">Automated Structured Radiology Report Generation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jean-Benoit Delbrouck, Justin Xu, Johannes Moll, Alois Thomas, Zhihong Chen, Sophie Ostmeier, Asfandyar Azhar, Kelvin Zhenghao Li, Andrew Johnston, Christian Bluethgen, Eduardo Reis, Mohamed Muneer, Maya Varma, Curtis Langlotz
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Automated radiology report generation from chest X-ray (CXR) images has the potential to improve clinical efficiency and reduce radiologists' workload. However, most datasets, including the publicly available MIMIC-CXR and CheXpert Plus, consist entirely of free-form reports, which are inherently va</span>
                
                <span class="abstract-full" style="display: none;">Automated radiology report generation from chest X-ray (CXR) images has the potential to improve clinical efficiency and reduce radiologists' workload. However, most datasets, including the publicly available MIMIC-CXR and CheXpert Plus, consist entirely of free-form reports, which are inherently variable and unstructured. This variability poses challenges for both generation and evaluation: existing models struggle to produce consistent, clinically meaningful reports, and standard evaluation metrics fail to capture the nuances of radiological interpretation. To address this, we introduce Structured Radiology Report Generation (SRRG), a new task that reformulates free-text radiology reports into a standardized format, ensuring clarity, consistency, and structured clinical reporting. We create a novel dataset by restructuring reports using large language models (LLMs) following strict structured reporting desiderata. Additionally, we introduce SRR-BERT, a fine-grained disease classification model trained on 55 labels, enabling more precise and clinically informed evaluation of structured reports. To assess report quality, we propose F1-SRR-BERT, a metric that leverages SRR-BERT's hierarchical disease taxonomy to bridge the gap between free-text variability and structured clinical reporting. We validate our dataset through a reader study conducted by five board-certified radiologists and extensive benchmarking experiments.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 16.1%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.7%">
                            Medicine
                        </span>
                <!-- 3D: 2.1 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Datasets: 1.7 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- T2I: 1.1 -->
                    
                <!-- Hardware: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.3557
                </span>
                <a href="https://arxiv.org/abs/2505.10238" target="_blank" rel="noopener noreferrer">MTVCrafter: 4D Motion Tokenization for Open-World Human Image Animation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yanbo Ding, Xirui Hu, Zhizhi Guo, Chi Zhang, Yali Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Human image animation has gained increasing attention and developed rapidly due to its broad applications in digital humans. However, existing methods rely largely on 2D-rendered pose images for motion guidance, which limits generalization and discards essential 3D information for open-world animati</span>
                
                <span class="abstract-full" style="display: none;">Human image animation has gained increasing attention and developed rapidly due to its broad applications in digital humans. However, existing methods rely largely on 2D-rendered pose images for motion guidance, which limits generalization and discards essential 3D information for open-world animation. To tackle this problem, we propose MTVCrafter (Motion Tokenization Video Crafter), the first framework that directly models raw 3D motion sequences (i.e., 4D motion) for human image animation. Specifically, we introduce 4DMoT (4D motion tokenizer) to quantize 3D motion sequences into 4D motion tokens. Compared to 2D-rendered pose images, 4D motion tokens offer more robust spatio-temporal cues and avoid strict pixel-level alignment between pose image and character, enabling more flexible and disentangled control. Then, we introduce MV-DiT (Motion-aware Video DiT). By designing unique motion attention with 4D positional encodings, MV-DiT can effectively leverage motion tokens as 4D compact yet expressive context for human image animation in the complex 3D world. Hence, it marks a significant step forward in this field and opens a new direction for pose-guided human video generation. Experiments show that our MTVCrafter achieves state-of-the-art results with an FID-VID of 6.98, surpassing the second-best by 65%. Powered by robust motion tokens, MTVCrafter also generalizes well to diverse open-world characters (single/multiple, full/half-body) across various styles and scenarios. Our video demos and code are on: https://github.com/DINGYANB/MTVCrafter.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.8%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.1%">
                            Medicine
                        </span>
                <!-- Computer Vision: 3.3 -->
                    
                <!-- 3D: 3.2 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Federated Learning: 1.6 -->
                    
                <!-- T2I: 1.5 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.3599
                </span>
                <a href="https://arxiv.org/abs/2505.23996" target="_blank" rel="noopener noreferrer">Is Your Model Fairly Certain? Uncertainty-Aware Fairness Evaluation for LLMs</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yinong Oliver Wang, Nivedha Sivakumar, Falaah Arif Khan, Rin Metcalf Susa, Adam Golinski, Natalie Mackraz, Barry-John Theobald, Luca Zappella, Nicholas Apostoloff
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The recent rapid adoption of large language models (LLMs) highlights the critical need for benchmarking their fairness. Conventional fairness metrics, which focus on discrete accuracy-based evaluations (i.e., prediction correctness), fail to capture the implicit impact of model uncertainty (e.g., hi</span>
                
                <span class="abstract-full" style="display: none;">The recent rapid adoption of large language models (LLMs) highlights the critical need for benchmarking their fairness. Conventional fairness metrics, which focus on discrete accuracy-based evaluations (i.e., prediction correctness), fail to capture the implicit impact of model uncertainty (e.g., higher model confidence about one group over another despite similar accuracy). To address this limitation, we propose an uncertainty-aware fairness metric, UCerF, to enable a fine-grained evaluation of model fairness that is more reflective of the internal bias in model decisions compared to conventional fairness measures. Furthermore, observing data size, diversity, and clarity issues in current datasets, we introduce a new gender-occupation fairness evaluation dataset with 31,756 samples for co-reference resolution, offering a more diverse and suitable dataset for evaluating modern LLMs. We establish a benchmark, using our metric and dataset, and apply it to evaluate the behavior of ten open-source LLMs. For example, Mistral-7B exhibits suboptimal fairness due to high confidence in incorrect predictions, a detail overlooked by Equalized Odds but captured by UCerF. Overall, our proposed LLM benchmark, which evaluates fairness with uncertainty awareness, paves the way for developing more transparent and accountable AI systems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 11.7%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.1%">
                            Medicine
                        </span>
                <!-- Federated Learning: 2.3 -->
                    
                <!-- Computer Vision: 2.0 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Datasets: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.388
                </span>
                <a href="https://arxiv.org/abs/2503.02041" target="_blank" rel="noopener noreferrer">Interpolating Neural Network-Tensor Decomposition (INN-TD): a scalable and interpretable approach for large-scale physics-based problems</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jiachen Guo, Xiaoyu Xie, Chanwook Park, Hantao Zhang, Matthew Politis, Gino Domel, Thomas J. R. Hughes, Wing Kam Liu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Deep learning has been extensively employed as a powerful function approximator for modeling physics-based problems described by partial differential equations (PDEs). Despite their popularity, standard deep learning models often demand prohibitively large computational resources and yield limited a</span>
                
                <span class="abstract-full" style="display: none;">Deep learning has been extensively employed as a powerful function approximator for modeling physics-based problems described by partial differential equations (PDEs). Despite their popularity, standard deep learning models often demand prohibitively large computational resources and yield limited accuracy when scaling to large-scale, high-dimensional physical problems. Their black-box nature further hinders the application in industrial problems where interpretability and high precision are critical. To overcome these challenges, this paper introduces Interpolating Neural Network-Tensor Decomposition (INN-TD), a scalable and interpretable framework that has the merits of both machine learning and finite element methods for modeling large-scale physical systems. By integrating locally supported interpolation functions from finite element into the network architecture, INN-TD achieves a sparse learning structure with enhanced accuracy, faster training/solving speed, and reduced memory footprint. This makes it particularly effective for tackling large-scale high-dimensional parametric PDEs in training, solving, and inverse optimization tasks in physical problems where high precision is required.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.0%">
                            Medicine
                        </span>
                <!-- LLMs: 3.9 -->
                    
                <!-- Quantum Computing: 2.3 -->
                    
                <!-- HPO and AutoML: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Computer Vision: 1.9 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Datasets: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.3939
                </span>
                <a href="https://arxiv.org/abs/2503.20771" target="_blank" rel="noopener noreferrer">Disentangled Source-Free Personalization for Facial Expression Recognition with Neutral Target Data</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Masoumeh Sharafi, Emma Ollivier, Muhammad Osama Zeeshan, Soufiane Belharbi, Marco Pedersoli, Alessandro Lameiras Koerich, Simon Bacon, Eric Granger
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Facial Expression Recognition (FER) from videos is a crucial task in various application areas, such as human-computer interaction and health diagnosis and monitoring (e.g., assessing pain and depression). Beyond the challenges of recognizing subtle emotional or health states, the effectiveness of d</span>
                
                <span class="abstract-full" style="display: none;">Facial Expression Recognition (FER) from videos is a crucial task in various application areas, such as human-computer interaction and health diagnosis and monitoring (e.g., assessing pain and depression). Beyond the challenges of recognizing subtle emotional or health states, the effectiveness of deep FER models is often hindered by the considerable inter-subject variability in expressions. Source-free (unsupervised) domain adaptation (SFDA) methods may be employed to adapt a pre-trained source model using only unlabeled target domain data, thereby avoiding data privacy, storage, and transmission issues. Typically, SFDA methods adapt to a target domain dataset corresponding to an entire population and assume it includes data from all recognition classes. However, collecting such comprehensive target data can be difficult or even impossible for FER in healthcare applications. In many real-world scenarios, it may be feasible to collect a short neutral control video (which displays only neutral expressions) from target subjects before deployment. These videos can be used to adapt a model to better handle the variability of expressions among subjects. This paper introduces the Disentangled SFDA (DSFDA) method to address the challenge posed by adapting models with missing target expression data. DSFDA leverages data from a neutral target control video for end-to-end generation and adaptation of target data with missing non-neutral data. Our method learns to disentangle features related to expressions and identity while generating the missing non-neutral expression data for the target subject, thereby enhancing model accuracy. Additionally, our self-supervision strategy improves model adaptation by reconstructing target images that maintain the same identity and source expression.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.0%">
                            Medicine
                        </span>
                <!-- Federated Learning: 2.8 -->
                    
                <!-- LLMs: 2.7 -->
                    
                <!-- Computer Vision: 2.6 -->
                    
                <!-- Decision Trees: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.415
                </span>
                <a href="https://arxiv.org/abs/2505.23977" target="_blank" rel="noopener noreferrer">VisualSphinx: Large-Scale Synthetic Vision Logic Puzzles for RL</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yichen Feng, Zhangchen Xu, Fengqing Jiang, Yuetai Li, Bhaskar Ramasubramanian, Luyao Niu, Bill Yuchen Lin, Radha Poovendran
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Vision language models (VLMs) are expected to perform effective multimodal reasoning and make logically coherent decisions, which is critical to tasks such as diagram understanding and spatial problem solving. However, current VLM reasoning lacks large-scale and well-structured training datasets. To</span>
                
                <span class="abstract-full" style="display: none;">Vision language models (VLMs) are expected to perform effective multimodal reasoning and make logically coherent decisions, which is critical to tasks such as diagram understanding and spatial problem solving. However, current VLM reasoning lacks large-scale and well-structured training datasets. To bridge this gap, we propose VisualSphinx, a first-of-its-kind large-scale synthetic visual logical reasoning training data. To tackle the challenge of image synthesis with grounding answers, we propose a rule-to-image synthesis pipeline, which extracts and expands puzzle rules from seed questions and generates the code of grounding synthesis image synthesis for puzzle sample assembly. Experiments demonstrate that VLM trained using GRPO on VisualSphinx benefit from logical coherence and readability of our dataset and exhibit improved performance on logical reasoning tasks. The enhanced reasoning capabilities developed from VisualSphinx also benefit other reasoning tasks such as algebraic reasoning, arithmetic reasoning and geometry reasoning.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 9.9%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.3%">
                            Medicine
                        </span>
                <!-- Computer Vision: 2.5 -->
                    
                <!-- Datasets: 2.4 -->
                    
                <!-- Hardware: 2.2 -->
                    
                <!-- Blockchain: 2.0 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- T2I: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4156
                </span>
                <a href="https://arxiv.org/abs/2505.24160" target="_blank" rel="noopener noreferrer">Beyond the LUMIR challenge: The pathway to foundational registration models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Junyu Chen, Shuwen Wei, Joel Honkamaa, Pekka Marttinen, Hang Zhang, Min Liu, Yichao Zhou, Zuopeng Tan, Zhuoyuan Wang, Yi Wang, Hongchao Zhou, Shunbo Hu, Yi Zhang, Qian Tao, Lukas F\"orner, Thomas Wendler, Bailiang Jian, Benedikt Wiestler, Tim Hable, Jin Kim, Dan Ruan, Frederic Madesta, Thilo Sentker, Wiebke Heyer, Lianrui Zuo, Yuwei Dai, Jing Wu, Jerry L. Prince, Harrison Bai, Yong Du, Yihao Liu, Alessa Hering, Reuben Dorent, Lasse Hansen, Mattias P. Heinrich, Aaron Carass
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Medical image challenges have played a transformative role in advancing the field, catalyzing algorithmic innovation and establishing new performance standards across diverse clinical applications. Image registration, a foundational task in neuroimaging pipelines, has similarly benefited from the Le</span>
                
                <span class="abstract-full" style="display: none;">Medical image challenges have played a transformative role in advancing the field, catalyzing algorithmic innovation and establishing new performance standards across diverse clinical applications. Image registration, a foundational task in neuroimaging pipelines, has similarly benefited from the Learn2Reg initiative. Building on this foundation, we introduce the Large-scale Unsupervised Brain MRI Image Registration (LUMIR) challenge, a next-generation benchmark designed to assess and advance unsupervised brain MRI registration. Distinct from prior challenges that leveraged anatomical label maps for supervision, LUMIR removes this dependency by providing over 4,000 preprocessed T1-weighted brain MRIs for training without any label maps, encouraging biologically plausible deformation modeling through self-supervision. In addition to evaluating performance on 590 held-out test subjects, LUMIR introduces a rigorous suite of zero-shot generalization tasks, spanning out-of-domain imaging modalities (e.g., FLAIR, T2-weighted, T2*-weighted), disease populations (e.g., Alzheimer's disease), acquisition protocols (e.g., 9.4T MRI), and species (e.g., macaque brains). A total of 1,158 subjects and over 4,000 image pairs were included for evaluation. Performance was assessed using both segmentation-based metrics (Dice coefficient, 95th percentile Hausdorff distance) and landmark-based registration accuracy (target registration error). Across both in-domain and zero-shot tasks, deep learning-based methods consistently achieved state-of-the-art accuracy while producing anatomically plausible deformation fields. The top-performing deep learning-based models demonstrated diffeomorphic properties and inverse consistency, outperforming several leading optimization-based methods, and showing strong robustness to most domain shifts, the exception being a drop in performance on out-of-domain contrasts.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.0%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.1%">
                            LLMs
                        </span>
                <!-- Computer Vision: 4.0 -->
                    
                <!-- Blockchain: 2.0 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4201
                </span>
                <a href="https://arxiv.org/abs/2502.04959" target="_blank" rel="noopener noreferrer">No Task Left Behind: Isotropic Model Merging with Common and Task-Specific Subspaces</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Daniel Marczak, Simone Magistri, Sebastian Cygert, Bart{\l}omiej Twardowski, Andrew D. Bagdanov, Joost van de Weijer
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Model merging integrates the weights of multiple task-specific models into a single multi-task model. Despite recent interest in the problem, a significant performance gap between the combined and single-task models remains. In this paper, we investigate the key characteristics of task matrices -- w</span>
                
                <span class="abstract-full" style="display: none;">Model merging integrates the weights of multiple task-specific models into a single multi-task model. Despite recent interest in the problem, a significant performance gap between the combined and single-task models remains. In this paper, we investigate the key characteristics of task matrices -- weight update matrices applied to a pre-trained model -- that enable effective merging. We show that alignment between singular components of task-specific and merged matrices strongly correlates with performance improvement over the pre-trained model. Based on this, we propose an isotropic merging framework that flattens the singular value spectrum of task matrices, enhances alignment, and reduces the performance gap. Additionally, we incorporate both common and task-specific subspaces to further improve alignment and performance. Our proposed approach achieves state-of-the-art performance on vision and language tasks across various sets of tasks and model scales. This work advances the understanding of model merging dynamics, offering an effective methodology to merge models without requiring additional training. Code is available at https://github.com/danielm1405/iso-merging .</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.9%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.4%">
                            Medicine
                        </span>
                <!-- Federated Learning: 3.3 -->
                    
                <!-- Computer Vision: 2.4 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4268
                </span>
                <a href="https://arxiv.org/abs/2306.04542" target="_blank" rel="noopener noreferrer">On the Design Fundamentals of Diffusion Models: A Survey</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ziyi Chang, George Alex Koulieris, Hyung Jin Chang, Hubert P. H. Shum
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Diffusion models are learning pattern-learning systems to model and sample from data distributions with three functional components namely the forward process, the reverse process, and the sampling process. The components of diffusion models have gained significant attention with many design factors</span>
                
                <span class="abstract-full" style="display: none;">Diffusion models are learning pattern-learning systems to model and sample from data distributions with three functional components namely the forward process, the reverse process, and the sampling process. The components of diffusion models have gained significant attention with many design factors being considered in common practice. Existing reviews have primarily focused on higher-level solutions, covering less on the design fundamentals of components. This study seeks to address this gap by providing a comprehensive and coherent review of seminal designable factors within each functional component of diffusion models. This provides a finer-grained perspective of diffusion models, benefiting future studies in the analysis of individual components, the design factors for different purposes, and the implementation of diffusion models.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.7%">
                            Medicine
                        </span>
                <!-- LLMs: 4.4 -->
                    
                <!-- Federated Learning: 4.1 -->
                    
                <!-- Hardware: 3.1 -->
                    
                <!-- Blockchain: 3.1 -->
                    
                <!-- Evolutionary Algorithms: 2.3 -->
                    
                <!-- Bayesian Optimization: 1.8 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Computer Vision: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4284
                </span>
                <a href="https://arxiv.org/abs/2505.17502" target="_blank" rel="noopener noreferrer">Demonstration of Quantum-Secure Communications in a Nuclear Reactor</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Konstantinos Gkouliaras, Vasileios Theos, True Miller, Brian Jowers, George Kennedy, Andy Grant, Terry Cronin, Philip G. Evans, Stylianos Chatzidakis
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Quantum key distribution (QKD), one of the latest cryptographic techniques, founded on the laws of quantum mechanics rather than mathematical complexity, promises for the first time unconditional secure remote communications. Integrating this technology into the next generation nuclear systems - des</span>
                
                <span class="abstract-full" style="display: none;">Quantum key distribution (QKD), one of the latest cryptographic techniques, founded on the laws of quantum mechanics rather than mathematical complexity, promises for the first time unconditional secure remote communications. Integrating this technology into the next generation nuclear systems - designed for universal data collection and real-time sharing as well as cutting-edge instrumentation and increased dependency on digital technologies - could provide significant benefits enabling secure, unattended, and autonomous operation in remote areas, e.g., microreactors and fission batteries. However, any practical implementation on a critical reactor system must meet strict requirements on latency, control system compatibility, stability, and performance under operational transients. Here, we report the complete end-to-end demonstration of a phase-encoding decoy-state BB84 protocol QKD system under prototypic conditions on Purdue's fully digital nuclear reactor, PUR-1. The system was installed in PUR-1 successfully executing real-time encryption and decryption of 2,000 signals over optic fiber distances up to 82 km using OTP-based encryption and up to 140 km with AES-based encryption. For a core of 68 signals, OTP-secure communication was achieved for up to 135 km. The QKD system maintained a stable secret key rate of 320 kbps and a quantum bit error of 3.8% at 54 km. Our results demonstrate that OTP-based encryption introduces minimal latency while the more key-efficient AES and ASCON encryption schemes can significantly increase the number of signals encrypted without latency penalties. Additionally, implementation of a dynamic key pool ensures several hours of secure key availability during potential system downtimes. This work shows the potential of quantum-based secure remote communications for future digitally driven nuclear reactor technologies.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.7%">
                            Medicine
                        </span>
                <!-- Quantum Computing: 2.9 -->
                    
                <!-- Hardware: 2.6 -->
                    
                <!-- LLMs: 2.2 -->
                    
                <!-- Blockchain: 2.1 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.0 -->
                    
                <!-- Cryptography: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4423
                </span>
                <a href="https://arxiv.org/abs/2505.02746" target="_blank" rel="noopener noreferrer">Using Knowledge Graphs to harvest datasets for efficient CLIP model training</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Simon Ging, Sebastian Walter, Jelena Bratuli\'c, Johannes Dienert, Hannah Bast, Thomas Brox
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Training high-quality CLIP models typically requires enormous datasets, which limits the development of domain-specific models -- especially in areas that even the largest CLIP models do not cover well -- and drives up training costs. This poses challenges for scientific research that needs fine-gra</span>
                
                <span class="abstract-full" style="display: none;">Training high-quality CLIP models typically requires enormous datasets, which limits the development of domain-specific models -- especially in areas that even the largest CLIP models do not cover well -- and drives up training costs. This poses challenges for scientific research that needs fine-grained control over the training procedure of CLIP models. In this work, we show that by employing smart web search strategies enhanced with knowledge graphs, a robust CLIP model can be trained from scratch with considerably less data. Specifically, we demonstrate that an expert foundation model for living organisms can be built using just 10M images. Moreover, we introduce EntityNet, a dataset comprising 33M images paired with 46M text descriptions, which enables the training of a generic CLIP model in significantly reduced time.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.3%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.5%">
                            Medicine
                        </span>
                <!-- Federated Learning: 3.0 -->
                    
                <!-- Computer Vision: 2.4 -->
                    
                <!-- GNN: 2.1 -->
                    
                <!-- Bayesian Optimization: 2.0 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4817
                </span>
                <a href="https://arxiv.org/abs/2503.11101" target="_blank" rel="noopener noreferrer">A Survey on Self-supervised Contrastive Learning for Multimodal Text-Image Analysis</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Asifullah Khan, Laiba Asmatullah, Anza Malik, Shahzaib Khan, Hamna Asif
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Self-supervised learning is a machine learning approach that generates implicit labels by learning underlined patterns and extracting discriminative features from unlabeled data without manual labelling. Contrastive learning introduces the concept of "positive" and "negative" samples, where positive</span>
                
                <span class="abstract-full" style="display: none;">Self-supervised learning is a machine learning approach that generates implicit labels by learning underlined patterns and extracting discriminative features from unlabeled data without manual labelling. Contrastive learning introduces the concept of "positive" and "negative" samples, where positive pairs (e.g., variation of the same image/object) are brought together in the embedding space, and negative pairs (e.g., views from different images/objects) are pushed farther away. This methodology has shown significant improvements in image understanding and image text analysis without much reliance on labeled data. In this paper, we comprehensively discuss the terminologies, recent developments and applications of contrastive learning with respect to text-image models. Specifically, we provide an overview of the approaches of contrastive learning in text-image models in recent years. Secondly, we categorize the approaches based on different model structures. Thirdly, we further introduce and discuss the latest advances of the techniques used in the process such as pretext tasks for both images and text, architectural structures, and key trends. Lastly, we discuss the recent state-of-art applications of self-supervised contrastive learning Text-Image based models.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.4%">
                            Medicine
                        </span>
                <!-- LLMs: 3.0 -->
                    
                <!-- Federated Learning: 2.5 -->
                    
                <!-- Blockchain: 2.1 -->
                    
                <!-- Reinforcement Learning: 2.0 -->
                    
                <!-- Computer Vision: 1.9 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.0 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4858
                </span>
                <a href="https://arxiv.org/abs/2505.21680" target="_blank" rel="noopener noreferrer">multivariateGPT: a decoder-only transformer for multivariate categorical and numeric data</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Andrew J. Loza, Jun Yup Kim, Shangzheng Song, Yihang Liu, Joseph J. Y. Sung, R Andrew Taylor, Dennis L. Shung
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Real-world processes often generate data that are a mix of categorical and numeric values that are recorded at irregular and informative intervals. Discrete token-based approaches are limited in numeric representation capacity while methods like neural ordinary differential equations are not well su</span>
                
                <span class="abstract-full" style="display: none;">Real-world processes often generate data that are a mix of categorical and numeric values that are recorded at irregular and informative intervals. Discrete token-based approaches are limited in numeric representation capacity while methods like neural ordinary differential equations are not well suited for categorical data or informative sampling and require augmentation to handle certain classes of trajectories. Here, we present multivariateGPT, a single architecture for modeling sequences of mixed categorical (including tokenized text) and numeric data. This is accomplished with an autoregressive sequence decomposition, embedding scheme, and loss function that extend the next token prediction task to likelihood estimation of the joint distribution of next token class and value. We demonstrate how this approach can efficiently learn to generalize patterns in simple physical systems and model complex time series including electrocardiograms and multivariate electronic health record data. This work extends the utility of transformer based models to additional classes of data.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.7%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.2%">
                            Medicine
                        </span>
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Datasets: 1.7 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.4 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4942
                </span>
                <a href="https://arxiv.org/abs/2505.02712" target="_blank" rel="noopener noreferrer">Graph Neural Network-Based Reinforcement Learning for Controlling Biological Networks: The GATTACA Framework</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Andrzej Mizera, Jakub Zarzycki
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Cellular reprogramming, the artificial transformation of one cell type into another, has been attracting increasing research attention due to its therapeutic potential for complex diseases. However, discovering reprogramming strategies through classical wet-lab experiments is hindered by lengthy tim</span>
                
                <span class="abstract-full" style="display: none;">Cellular reprogramming, the artificial transformation of one cell type into another, has been attracting increasing research attention due to its therapeutic potential for complex diseases. However, discovering reprogramming strategies through classical wet-lab experiments is hindered by lengthy time commitments and high costs. In this study, we explore the use of deep reinforcement learning (DRL) to control Boolean network models of complex biological systems, such as gene regulatory networks and signalling pathway networks. We formulate a novel control problem for Boolean network models under the asynchronous update mode in the context of cellular reprogramming. To facilitate scalability, we consider our previously introduced concept of a pseudo-attractor and we improve our procedure for effective identification of pseudo-attractor states. Finally, we devise a computational framework to solve the control problem. To leverage the structure of biological systems, we incorporate graph neural networks with graph convolutions into the artificial neural network approximator for the action-value function learned by the DRL agent. Experiments on a number of large real-world biological networks from literature demonstrate the scalability and effectiveness of our approach.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.5%">
                            Medicine
                        </span>
                <!-- Federated Learning: 3.6 -->
                    
                <!-- GNN: 2.8 -->
                    
                <!-- Reinforcement Learning: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- LLMs: 2.0 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Bayesian Optimization: 1.9 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.5021
                </span>
                <a href="https://arxiv.org/abs/2505.23964" target="_blank" rel="noopener noreferrer">Acoustic Classification of Maritime Vessels using Learnable Filterbanks</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jonas Elsborg, Tejs Vegge, Arghya Bhowmik
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Reliably monitoring and recognizing maritime vessels based on acoustic signatures is complicated by the variability of different recording scenarios. A robust classification framework must be able to generalize across diverse acoustic environments and variable source-sensor distances. To this end, w</span>
                
                <span class="abstract-full" style="display: none;">Reliably monitoring and recognizing maritime vessels based on acoustic signatures is complicated by the variability of different recording scenarios. A robust classification framework must be able to generalize across diverse acoustic environments and variable source-sensor distances. To this end, we present a deep learning model with robust performance across different recording scenarios. Using a trainable spectral front-end and temporal feature encoder to learn a Gabor filterbank, the model can dynamically emphasize different frequency components. Trained on the VTUAD hydrophone recordings from the Strait of Georgia, our model, CATFISH, achieves a state-of-the-art 96.63 % percent test accuracy across varying source-sensor distances, surpassing the previous benchmark by over 12 percentage points. We present the model, justify our architectural choices, analyze the learned Gabor filters, and perform ablation studies on sensor data fusion and attention-based pooling.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.5%">
                            Medicine
                        </span>
                <!-- Federated Learning: 4.6 -->
                    
                <!-- Computer Vision: 3.1 -->
                    
                <!-- Evolutionary Algorithms: 2.5 -->
                    
                <!-- LLMs: 2.3 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.5299
                </span>
                <a href="https://arxiv.org/abs/2505.23773" target="_blank" rel="noopener noreferrer">LightDSA: A Python-Based Hybrid Digital Signature Library and Performance Analysis of RSA, DSA, ECDSA and EdDSA in Variable Configurations, Elliptic Curve Forms and Curves</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Sefik Serengil, Alper Ozpinar
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Digital signature algorithms (DSAs) are fundamental to cryptographic security, ensuring data integrity and authentication. While RSA, DSA, ECDSA, and EdDSA are widely used, their performance varies significantly depending on key sizes, hash functions, and elliptic curve configurations. In this paper</span>
                
                <span class="abstract-full" style="display: none;">Digital signature algorithms (DSAs) are fundamental to cryptographic security, ensuring data integrity and authentication. While RSA, DSA, ECDSA, and EdDSA are widely used, their performance varies significantly depending on key sizes, hash functions, and elliptic curve configurations. In this paper, we introduce LightDSA, a hybrid and configurable digital signature library that supports RSA, DSA, ECDSA, and EdDSA with flexible form and curve selection, open sourced at https://github.com/serengil/LightDSA. Unlike conventional implementations that impose strict curve-form mappings - such as Weierstrass for ECDSA and Edwards for EdDSA LightDSA - allows arbitrary combinations, enabling a broader performance evaluation. We analyze the computational efficiency of these algorithms across various configurations, comparing key generation, signing, and verification times. Our results provide insights into the trade-offs between security and efficiency, guiding the selection of optimal configurations for different cryptographic needs.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.5%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.9%">
                            Medicine
                        </span>
                <!-- Hardware: 3.0 -->
                    
                <!-- Blockchain: 2.5 -->
                    
                <!-- Computer Vision: 2.2 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- 3D: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.5537
                </span>
                <a href="https://arxiv.org/abs/2505.24063" target="_blank" rel="noopener noreferrer">TCM-Ladder: A Benchmark for Multimodal Question Answering on Traditional Chinese Medicine</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jiacheng Xie, Yang Yu, Ziyang Zhang, Shuai Zeng, Jiaxuan He, Ayush Vasireddy, Xiaoting Tang, Congyu Guo, Lening Zhao, Congcong Jing, Guanghui An, Dong Xu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Traditional Chinese Medicine (TCM), as an effective alternative medicine, has been receiving increasing attention. In recent years, the rapid development of large language models (LLMs) tailored for TCM has underscored the need for an objective and comprehensive evaluation framework to assess their </span>
                
                <span class="abstract-full" style="display: none;">Traditional Chinese Medicine (TCM), as an effective alternative medicine, has been receiving increasing attention. In recent years, the rapid development of large language models (LLMs) tailored for TCM has underscored the need for an objective and comprehensive evaluation framework to assess their performance on real-world tasks. However, existing evaluation datasets are limited in scope and primarily text-based, lacking a unified and standardized multimodal question-answering (QA) benchmark. To address this issue, we introduce TCM-Ladder, the first multimodal QA dataset specifically designed for evaluating large TCM language models. The dataset spans multiple core disciplines of TCM, including fundamental theory, diagnostics, herbal formulas, internal medicine, surgery, pharmacognosy, and pediatrics. In addition to textual content, TCM-Ladder incorporates various modalities such as images and videos. The datasets were constructed using a combination of automated and manual filtering processes and comprise 52,000+ questions in total. These questions include single-choice, multiple-choice, fill-in-the-blank, diagnostic dialogue, and visual comprehension tasks. We trained a reasoning model on TCM-Ladder and conducted comparative experiments against 9 state-of-the-art general domain and 5 leading TCM-specific LLMs to evaluate their performance on the datasets. Moreover, we propose Ladder-Score, an evaluation method specifically designed for TCM question answering that effectively assesses answer quality regarding terminology usage and semantic expression. To our knowledge, this is the first work to evaluate mainstream general domain and TCM-specific LLMs on a unified multimodal benchmark. The datasets and leaderboard are publicly available at https://tcmladder.com or https://54.211.107.106 and will be continuously updated.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 12.2%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.8%">
                            Medicine
                        </span>
                <!-- Computer Vision: 3.0 -->
                    
                <!-- Hardware: 2.3 -->
                    
                <!-- Datasets: 2.3 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.5667
                </span>
                <a href="https://arxiv.org/abs/2505.24578" target="_blank" rel="noopener noreferrer">Neuro-Symbolic Operator for Interpretable and Generalizable Characterization of Complex Piezoelectric Systems</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Abhishek Chandra, Taniya Kapoor, Mitrofan Curti, Koen Tiels, Elena A. Lomonova
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Complex piezoelectric systems are foundational in industrial applications. Their performance, however, is challenged by the nonlinear voltage-displacement hysteretic relationships. Efficient characterization methods are, therefore, essential for reliable design, monitoring, and maintenance. Recently</span>
                
                <span class="abstract-full" style="display: none;">Complex piezoelectric systems are foundational in industrial applications. Their performance, however, is challenged by the nonlinear voltage-displacement hysteretic relationships. Efficient characterization methods are, therefore, essential for reliable design, monitoring, and maintenance. Recently proposed neural operator methods serve as surrogates for system characterization but face two pressing issues: interpretability and generalizability. State-of-the-art (SOTA) neural operators are black-boxes, providing little insight into the learned operator. Additionally, generalizing them to novel voltages and predicting displacement profiles beyond the training domain is challenging, limiting their practical use. To address these limitations, this paper proposes a neuro-symbolic operator (NSO) framework that derives the analytical operators governing hysteretic relationships. NSO first learns a Fourier neural operator mapping voltage fields to displacement profiles, followed by a library-based sparse model discovery method, generating white-box parsimonious models governing the underlying hysteresis. These models enable accurate and interpretable prediction of displacement profiles across varying and out-of-distribution voltage fields, facilitating generalizability. The potential of NSO is demonstrated by accurately predicting voltage-displacement hysteresis, including butterfly-shaped relationships. Moreover, NSO predicts displacement profiles even for noisy and low-fidelity voltage data, emphasizing its robustness. The results highlight the advantages of NSO compared to SOTA neural operators and model discovery methods on several evaluation metrics. Consequently, NSO contributes to characterizing complex piezoelectric systems while improving the interpretability and generalizability of neural operators, essential for design, monitoring, maintenance, and other real-world scenarios.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.3%">
                            Medicine
                        </span>
                <!-- LLMs: 3.7 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- Hardware: 2.2 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- HPO and AutoML: 1.8 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.5895
                </span>
                <a href="https://arxiv.org/abs/2405.02696" target="_blank" rel="noopener noreferrer">DiffuseTrace: A Transparent and Flexible Watermarking Scheme for Latent Diffusion Model</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Liangqi Lei, Keke Gai, Jing Yu, Liehuang Zhu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Latent Diffusion Models (LDMs) enable a wide range of applications but raise ethical concerns regarding illegal utilization. Adding watermarks to generative model outputs is a vital technique employed for copyright tracking and mitigating potential risks associated with Artificial Intelligence (AI)-</span>
                
                <span class="abstract-full" style="display: none;">Latent Diffusion Models (LDMs) enable a wide range of applications but raise ethical concerns regarding illegal utilization. Adding watermarks to generative model outputs is a vital technique employed for copyright tracking and mitigating potential risks associated with Artificial Intelligence (AI)-generated contents. However, post-processed watermarking methods are unable to withstand generative watermark attacks and there exists a trade-off between image fidelity and watermark strength. Therefore, we propose a novel technique called DiffuseTrace. DiffuseTrace does not rely on fine-tuning of the diffusion model components. The multi-bit watermark is a embedded into the image space semantically without compromising image quality. The watermark component can be utilized as a plug-in in arbitrary diffusion models. We validate through experiments the effectiveness and flexibility of DiffuseTrace. Under 8 types of image processing watermark attacks and 3 types of generative watermark attacks, DiffuseTrace maintains watermark detection rate of 99% and attribution accuracy of over 94%.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.9%">
                            Medicine
                        </span>
                <!-- LLMs: 4.9 -->
                    
                <!-- Hardware: 2.2 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Datasets: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.6102
                </span>
                <a href="https://arxiv.org/abs/2505.23780" target="_blank" rel="noopener noreferrer">More-than-Human Storytelling: Designing Longitudinal Narrative Engagements with Generative AI</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: \'Emilie Fabre, Katie Seaborn, Shuta Koiwai, Mizuki Watanabe, Paul Riesch
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Longitudinal engagement with generative AI (GenAI) storytelling agents is a timely but less charted domain. We explored multi-generational experiences with "Dreamsmithy," a daily dream-crafting app, where participants (N = 28) co-created stories with AI narrator "Makoto" every day. Reflections and i</span>
                
                <span class="abstract-full" style="display: none;">Longitudinal engagement with generative AI (GenAI) storytelling agents is a timely but less charted domain. We explored multi-generational experiences with "Dreamsmithy," a daily dream-crafting app, where participants (N = 28) co-created stories with AI narrator "Makoto" every day. Reflections and interactions were captured through a two-week diary study. Reflexive thematic analysis revealed themes likes "oscillating ambivalence" and "socio-chronological bonding," highlighting the complex dynamics that emerged between individuals and the AI narrator over time. Findings suggest that while people appreciated the personal notes, opportunities for reflection, and AI creativity, limitations in narrative coherence and control occasionally caused frustration. The results underscore the potential of GenAI for longitudinal storytelling, but also raise critical questions about user agency and ethics. We contribute initial empirical insights and design considerations for developing adaptive, more-than-human storytelling systems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.8%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.9%">
                            LLMs
                        </span>
                <!-- Hardware: 2.5 -->
                    
                <!-- Blockchain: 2.3 -->
                    
                <!-- HPO and AutoML: 1.8 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.6152
                </span>
                <a href="https://arxiv.org/abs/2505.19713" target="_blank" rel="noopener noreferrer">CAD-Coder: Text-to-CAD Generation with Chain-of-Thought and Geometric Reward</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yandong Guan, Xilin Wang, Xingxi Ming, Jing Zhang, Dong Xu, Qian Yu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In this work, we introduce CAD-Coder, a novel framework that reformulates text-to-CAD as the generation of CadQuery scripts - a Python-based, parametric CAD language. This representation enables direct geometric validation, a richer modeling vocabulary, and seamless integration with existing LLMs. T</span>
                
                <span class="abstract-full" style="display: none;">In this work, we introduce CAD-Coder, a novel framework that reformulates text-to-CAD as the generation of CadQuery scripts - a Python-based, parametric CAD language. This representation enables direct geometric validation, a richer modeling vocabulary, and seamless integration with existing LLMs. To further enhance code validity and geometric fidelity, we propose a two-stage learning pipeline: (1) supervised fine-tuning on paired text-CadQuery data, and (2) reinforcement learning with Group Reward Policy Optimization (GRPO), guided by a CAD-specific reward comprising both a geometric reward (Chamfer Distance) and a format reward. We also introduce a chain-of-thought (CoT) planning process to improve model reasoning, and construct a large-scale, high-quality dataset of 110K text-CadQuery-3D model triplets and 1.5K CoT samples via an automated pipeline. Extensive experiments demonstrate that CAD-Coder enables LLMs to generate diverse, valid, and complex CAD models directly from natural language, advancing the state of the art of text-to-CAD generation and geometric reasoning.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 9.6%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.1%">
                            Medicine
                        </span>
                <!-- Federated Learning: 2.2 -->
                    
                <!-- Reinforcement Learning: 2.0 -->
                    
                <!-- 3D: 2.0 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- T2I: 1.2 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.6184
                </span>
                <a href="https://arxiv.org/abs/2505.24401" target="_blank" rel="noopener noreferrer">S3CE-Net: Spike-guided Spatiotemporal Semantic Coupling and Expansion Network for Long Sequence Event Re-Identification</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Xianheng Ma, Hongchen Tan, Xiuping Liu, Yi Zhang, Huasheng Wang, Jiang Liu, Ying Chen, Hantao Liu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In this paper, we leverage the advantages of event cameras to resist harsh lighting conditions, reduce background interference, achieve high time resolution, and protect facial information to study the long-sequence event-based person re-identification (Re-ID) task. To this end, we propose a simple </span>
                
                <span class="abstract-full" style="display: none;">In this paper, we leverage the advantages of event cameras to resist harsh lighting conditions, reduce background interference, achieve high time resolution, and protect facial information to study the long-sequence event-based person re-identification (Re-ID) task. To this end, we propose a simple and efficient long-sequence event Re-ID model, namely the Spike-guided Spatiotemporal Semantic Coupling and Expansion Network (S3CE-Net). To better handle asynchronous event data, we build S3CE-Net based on spiking neural networks (SNNs). The S3CE-Net incorporates the Spike-guided Spatial-temporal Attention Mechanism (SSAM) and the Spatiotemporal Feature Sampling Strategy (STFS). The SSAM is designed to carry out semantic interaction and association in both spatial and temporal dimensions, leveraging the capabilities of SNNs. The STFS involves sampling spatial feature subsequences and temporal feature subsequences from the spatiotemporal dimensions, driving the Re-ID model to perceive broader and more robust effective semantics. Notably, the STFS introduces no additional parameters and is only utilized during the training stage. Therefore, S3CE-Net is a low-parameter and high-efficiency model for long-sequence event-based person Re-ID. Extensive experiments have verified that our S3CE-Net achieves outstanding performance on many mainstream long-sequence event-based person Re-ID datasets. Code is available at:https://github.com/Mhsunshine/SC3E_Net.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.9%">
                            Medicine
                        </span>
                <!-- Computer Vision: 4.0 -->
                    
                <!-- LLMs: 3.4 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.6643
                </span>
                <a href="https://arxiv.org/abs/2505.24260" target="_blank" rel="noopener noreferrer">Generative AI for Urban Design: A Stepwise Approach Integrating Human Expertise with Multimodal Diffusion Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Mingyi He, Yuebing Liang, Shenhao Wang, Yunhan Zheng, Qingyi Wang, Dingyi Zhuang, Li Tian, Jinhua Zhao
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Urban design is a multifaceted process that demands careful consideration of site-specific constraints and collaboration among diverse professionals and stakeholders. The advent of generative artificial intelligence (GenAI) offers transformative potential by improving the efficiency of design genera</span>
                
                <span class="abstract-full" style="display: none;">Urban design is a multifaceted process that demands careful consideration of site-specific constraints and collaboration among diverse professionals and stakeholders. The advent of generative artificial intelligence (GenAI) offers transformative potential by improving the efficiency of design generation and facilitating the communication of design ideas. However, most existing approaches are not well integrated with human design workflows. They often follow end-to-end pipelines with limited control, overlooking the iterative nature of real-world design. This study proposes a stepwise generative urban design framework that integrates multimodal diffusion models with human expertise to enable more adaptive and controllable design processes. Instead of generating design outcomes in a single end-to-end process, the framework divides the process into three key stages aligned with established urban design workflows: (1) road network and land use planning, (2) building layout planning, and (3) detailed planning and rendering. At each stage, multimodal diffusion models generate preliminary designs based on textual prompts and image-based constraints, which can then be reviewed and refined by human designers. We design an evaluation framework to assess the fidelity, compliance, and diversity of the generated designs. Experiments using data from Chicago and New York City demonstrate that our framework outperforms baseline models and end-to-end approaches across all three dimensions. This study underscores the benefits of multimodal diffusion models and stepwise generation in preserving human control and facilitating iterative refinements, laying the groundwork for human-AI interaction in urban design solutions.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 9.0%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.2%">
                            Medicine
                        </span>
                <!-- Hardware: 3.8 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Datasets: 1.9 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Computer Vision: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.6805
                </span>
                <a href="https://arxiv.org/abs/2505.24739" target="_blank" rel="noopener noreferrer">Contrast-Invariant Self-supervised Segmentation for Quantitative Placental MRI</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Xinliu Zhong, Ruiying Liu, Emily S. Nichols, Xuzhe Zhang, Andrew F. Laine, Emma G. Duerden, Yun Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Accurate placental segmentation is essential for quantitative analysis of the placenta. However, this task is particularly challenging in T2*-weighted placental imaging due to: (1) weak and inconsistent boundary contrast across individual echoes; (2) the absence of manual ground truth annotations fo</span>
                
                <span class="abstract-full" style="display: none;">Accurate placental segmentation is essential for quantitative analysis of the placenta. However, this task is particularly challenging in T2*-weighted placental imaging due to: (1) weak and inconsistent boundary contrast across individual echoes; (2) the absence of manual ground truth annotations for all echo times; and (3) motion artifacts across echoes caused by fetal and maternal movement. In this work, we propose a contrast-augmented segmentation framework that leverages complementary information across multi-echo T2*-weighted MRI to learn robust, contrast-invariant representations. Our method integrates: (i) masked autoencoding (MAE) for self-supervised pretraining on unlabeled multi-echo slices; (ii) masked pseudo-labeling (MPL) for unsupervised domain adaptation across echo times; and (iii) global-local collaboration to align fine-grained features with global anatomical context. We further introduce a semantic matching loss to encourage representation consistency across echoes of the same subject. Experiments on a clinical multi-echo placental MRI dataset demonstrate that our approach generalizes effectively across echo times and outperforms both single-echo and naive fusion baselines. To our knowledge, this is the first work to systematically exploit multi-echo T2*-weighted MRI for placental segmentation.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.7%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.2%">
                            LLMs
                        </span>
                <!-- Computer Vision: 3.7 -->
                    
                <!-- Federated Learning: 2.6 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.6938
                </span>
                <a href="https://arxiv.org/abs/2501.18160" target="_blank" rel="noopener noreferrer">RepoAudit: An Autonomous LLM-Agent for Repository-Level Code Auditing</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jinyao Guo, Chengpeng Wang, Xiangzhe Xu, Zian Su, Xiangyu Zhang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Code auditing is the process of reviewing code with the aim of identifying bugs. Large Language Models (LLMs) have demonstrated promising capabilities for this task without requiring compilation, while also supporting user-friendly customization. However, auditing a code repository with LLMs poses s</span>
                
                <span class="abstract-full" style="display: none;">Code auditing is the process of reviewing code with the aim of identifying bugs. Large Language Models (LLMs) have demonstrated promising capabilities for this task without requiring compilation, while also supporting user-friendly customization. However, auditing a code repository with LLMs poses significant challenges: limited context windows and hallucinations can degrade the quality of bug reports, and analyzing large-scale repositories incurs substantial time and token costs, hindering efficiency and scalability.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 18.0%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.7%">
                            Medicine
                        </span>
                <!-- Blockchain: 2.9 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- Evolutionary Algorithms: 2.3 -->
                    
                <!-- Hardware: 2.2 -->
                    
                <!-- Datasets: 1.9 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.7127
                </span>
                <a href="https://arxiv.org/abs/2505.23806" target="_blank" rel="noopener noreferrer">MedOrchestra: A Hybrid Cloud-Local LLM Approach for Clinical Data Interpretation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Sihyeon Lee, Hyunjoo Song, Jong-chan Lee, Yoon Jin Lee, Boram Lee, Hee-Eon Lim, Dongyeong Kim, Jinwook Seo, Bohyoung Kim
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Deploying large language models (LLMs) in clinical settings faces critical trade-offs: cloud LLMs, with their extensive parameters and superior performance, pose risks to sensitive clinical data privacy, while local LLMs preserve privacy but often fail at complex clinical interpretation tasks. We pr</span>
                
                <span class="abstract-full" style="display: none;">Deploying large language models (LLMs) in clinical settings faces critical trade-offs: cloud LLMs, with their extensive parameters and superior performance, pose risks to sensitive clinical data privacy, while local LLMs preserve privacy but often fail at complex clinical interpretation tasks. We propose MedOrchestra, a hybrid framework where a cloud LLM decomposes complex clinical tasks into manageable subtasks and prompt generation, while a local LLM executes these subtasks in a privacy-preserving manner. Without accessing clinical data, the cloud LLM generates and validates subtask prompts using clinical guidelines and synthetic test cases. The local LLM executes subtasks locally and synthesizes outputs generated by the cloud LLM. We evaluate MedOrchestra on pancreatic cancer staging using 100 radiology reports under NCCN guidelines. On free-text reports, MedOrchestra achieves 70.21% accuracy, outperforming local model baselines (without guideline: 48.94%, with guideline: 56.59%) and board-certified clinicians (gastroenterologists: 59.57%, surgeons: 65.96%, radiologists: 55.32%). On structured reports, MedOrchestra reaches 85.42% accuracy, showing clear superiority across all settings.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 16.5%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.4%">
                            Medicine
                        </span>
                <!-- 3D: 2.1 -->
                    
                <!-- Decision Trees: 1.8 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- T2I: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.7139
                </span>
                <a href="https://arxiv.org/abs/2505.24086" target="_blank" rel="noopener noreferrer">ComposeAnything: Composite Object Priors for Text-to-Image Generation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zeeshan Khan, Shizhe Chen, Cordelia Schmid
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Generating images from text involving complex and novel object arrangements remains a significant challenge for current text-to-image (T2I) models. Although prior layout-based methods improve object arrangements using spatial constraints with 2D layouts, they often struggle to capture 3D positioning</span>
                
                <span class="abstract-full" style="display: none;">Generating images from text involving complex and novel object arrangements remains a significant challenge for current text-to-image (T2I) models. Although prior layout-based methods improve object arrangements using spatial constraints with 2D layouts, they often struggle to capture 3D positioning and sacrifice quality and coherence. In this work, we introduce ComposeAnything, a novel framework for improving compositional image generation without retraining existing T2I models. Our approach first leverages the chain-of-thought reasoning abilities of LLMs to produce 2.5D semantic layouts from text, consisting of 2D object bounding boxes enriched with depth information and detailed captions. Based on this layout, we generate a spatial and depth aware coarse composite of objects that captures the intended composition, serving as a strong and interpretable prior that replaces stochastic noise initialization in diffusion-based T2I models. This prior guides the denoising process through object prior reinforcement and spatial-controlled denoising, enabling seamless generation of compositional objects and coherent backgrounds, while allowing refinement of inaccurate priors. ComposeAnything outperforms state-of-the-art methods on the T2I-CompBench and NSR-1K benchmarks for prompts with 2D/3D spatial arrangements, high object counts, and surreal compositions. Human evaluations further demonstrate that our model generates high-quality images with compositions that faithfully reflect the text.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.1%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.2%">
                            Medicine
                        </span>
                <!-- Computer Vision: 4.9 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- T2I: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.7165
                </span>
                <a href="https://arxiv.org/abs/2504.19062" target="_blank" rel="noopener noreferrer">Versatile Framework for Song Generation with Prompt-based Control</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yu Zhang, Wenxiang Guo, Changhao Pan, Zhiyuan Zhu, Ruiqi Li, Jingyu Lu, Rongjie Huang, Ruiyuan Zhang, Zhiqing Hong, Ziyue Jiang, Zhou Zhao
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Song generation focuses on producing controllable high-quality songs based on various prompts. However, existing methods struggle to generate vocals and accompaniments with prompt-based control and proper alignment. Additionally, they fall short in supporting various tasks. To address these challeng</span>
                
                <span class="abstract-full" style="display: none;">Song generation focuses on producing controllable high-quality songs based on various prompts. However, existing methods struggle to generate vocals and accompaniments with prompt-based control and proper alignment. Additionally, they fall short in supporting various tasks. To address these challenges, we introduce VersBand, a multi-task song generation framework for synthesizing high-quality, aligned songs with prompt-based control. VersBand comprises these primary models: 1) VocalBand, a decoupled model, leverages the flow-matching method for generating singing styles, pitches, and mel-spectrograms, allowing fast, high-quality vocal generation with style control. 2) AccompBand, a flow-based transformer model, incorporates the Band-MOE, selecting suitable experts for enhanced quality, alignment, and control. This model allows for generating controllable, high-quality accompaniments aligned with vocals. 3) Two generation models, LyricBand for lyrics and MelodyBand for melodies, contribute to the comprehensive multi-task song generation system, allowing for extensive control based on multiple prompts. Experimental results demonstrate that VersBand performs better over baseline models across multiple song generation tasks using objective and subjective metrics. Audio samples are available at https://aaronz345.github.io/VersBandDemo.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 8.0%">
                            Medicine
                        </span>
                <!-- LLMs: 3.7 -->
                    
                <!-- Computer Vision: 3.5 -->
                    
                <!-- Federated Learning: 2.6 -->
                    
                <!-- Evolutionary Algorithms: 2.5 -->
                    
                <!-- HPO and AutoML: 2.1 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- 3D: 1.8 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- T2I: 1.6 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.7309
                </span>
                <a href="https://arxiv.org/abs/2502.10682" target="_blank" rel="noopener noreferrer">CAE-Net: Generalized Deepfake Image Detection using Convolution and Attention Mechanisms with Spatial and Frequency Domain Features</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Kafi Anan, Anindya Bhattacharjee, Ashir Intesher, Kaidul Islam, Abrar Assaeem Fuad, Utsab Saha, Hafiz Imtiaz
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Effective deepfake detection tools are becoming increasingly essential to the growing usage of deepfakes in unethical practices. There exists a wide range of deepfake generation techniques, which makes it challenging to develop an accurate universal detection mechanism. The 2025 IEEE Signal Processi</span>
                
                <span class="abstract-full" style="display: none;">Effective deepfake detection tools are becoming increasingly essential to the growing usage of deepfakes in unethical practices. There exists a wide range of deepfake generation techniques, which makes it challenging to develop an accurate universal detection mechanism. The 2025 IEEE Signal Processing Cup (\textit{DFWild-Cup} competition) provided a diverse dataset of deepfake images containing significant class imbalance. The images in the dataset are generated from multiple deepfake image generators, for training machine learning model(s) to emphasize the generalization of deepfake detection. To this end, we proposed a disjoint set-based multistage training method to address the class imbalance and devised an ensemble-based architecture \emph{CAE-Net}. Our architecture consists of a convolution- and attention-based ensemble network, and employs three different neural network architectures: EfficientNet, Data-Efficient Image Transformer (DeiT), and ConvNeXt with wavelet transform to capture both local and global features of deepfakes. We visualize the specific regions that these models focus on for classification using Grad-CAM, and empirically demonstrate the effectiveness of these models in grouping real and fake images into cohesive clusters using t-SNE plots. Individually, the EfficientNet B0 architecture has achieved 90.79\% accuracy, whereas the ConvNeXt and the DeiT architecture have achieved 89.49\% and 89.32\% accuracy, respectively. With these networks, our weighted ensemble model achieves an excellent accuracy of 94.63\% on the validation dataset of the SP Cup 2025 competition. The equal error rate of 4.72\% and the Area Under the ROC curve of 97.37\% further confirm the stability of our proposed method. Finally, the robustness of our proposed model against adversarial perturbation attacks is tested as well, showing the inherent defensive properties of the ensemble approach.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.9%">
                            Medicine
                        </span>
                <!-- Federated Learning: 3.2 -->
                    
                <!-- LLMs: 2.3 -->
                    
                <!-- Datasets: 2.1 -->
                    
                <!-- Computer Vision: 1.9 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.4 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.7342
                </span>
                <a href="https://arxiv.org/abs/2505.24415" target="_blank" rel="noopener noreferrer">Boosting Automatic Exercise Evaluation Through Musculoskeletal Simulation-Based IMU Data Augmentation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Andreas Spilz, Heiko Oppel, Michael Munz
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Automated evaluation of movement quality holds significant potential for enhancing physiotherapeutic treatments and sports training by providing objective, real-time feedback. However, the effectiveness of deep learning models in assessing movements captured by inertial measurement units (IMUs) is o</span>
                
                <span class="abstract-full" style="display: none;">Automated evaluation of movement quality holds significant potential for enhancing physiotherapeutic treatments and sports training by providing objective, real-time feedback. However, the effectiveness of deep learning models in assessing movements captured by inertial measurement units (IMUs) is often hampered by limited data availability, class imbalance, and label ambiguity. In this work, we present a novel data augmentation method that generates realistic IMU data using musculoskeletal simulations integrated with systematic modifications of movement trajectories. Crucially, our approach ensures biomechanical plausibility and allows for automatic, reliable labeling by combining inverse kinematic parameters with a knowledge-based evaluation strategy. Extensive evaluations demonstrate that augmented variants closely resembles real-world data, significantly improving the classification accuracy and generalization capability of neural network models. Additionally, we highlight the benefits of augmented data for patient-specific fine-tuning scenarios, particularly when only limited subject-specific training examples are available. Our findings underline the practicality and efficacy of this augmentation method in overcoming common challenges faced by deep learning applications in physiotherapeutic exercise evaluation.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.3%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.8%">
                            LLMs
                        </span>
                <!-- Federated Learning: 2.7 -->
                    
                <!-- Computer Vision: 2.2 -->
                    
                <!-- Datasets: 2.1 -->
                    
                <!-- HPO and AutoML: 1.8 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.7576
                </span>
                <a href="https://arxiv.org/abs/2408.05178" target="_blank" rel="noopener noreferrer">ECG-FM: An Open Electrocardiogram Foundation Model</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Kaden McKeen, Sameer Masood, Augustin Toma, Barry Rubin, Bo Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Conventional task-specific electrocardiogram (ECG) analysis models require large annotated datasets to train. Foundation models mitigate this burden by leveraging self-supervised pretraining; however, the scarcity of open-weight ECG foundation models hinders adoption and cross-study comparability. W</span>
                
                <span class="abstract-full" style="display: none;">Conventional task-specific electrocardiogram (ECG) analysis models require large annotated datasets to train. Foundation models mitigate this burden by leveraging self-supervised pretraining; however, the scarcity of open-weight ECG foundation models hinders adoption and cross-study comparability. We present ECG-FM, an open foundation model for ECG analysis, and conduct a study using a dataset of 1.5 million ECGs. ECG-FM is a transformer-based model pretrained using a hybrid contrastive and generative self-supervised learning approach. Our downstream tasks include predicting reduced left ventricular ejection fraction (LVEF) and ECG interpretation labels, where we release a benchmark task on the MIMIC-IV-ECG dataset. We affirm that ECG-FM is robust, label-efficient, and functionally discriminative by showcasing data scaling experiments, performing a latent space analysis, and generating saliency maps. ECG-FM markedly outperforms task-specific models in the small-to-medium-scale data regime and demonstrates cross-dataset generalizability, achieving high AUROC on many clinically salient labels such as atrial fibrillation (0.996) and LVEF<=40% (0.929). We release our code, model weights, and benchmark task at https://github.com/bowang-lab/ECG-FM/.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 8.0%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.2%">
                            LLMs
                        </span>
                <!-- Computer Vision: 2.0 -->
                    
                <!-- Decision Trees: 1.9 -->
                    
                <!-- Datasets: 1.8 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.7704
                </span>
                <a href="https://arxiv.org/abs/2505.24040" target="_blank" rel="noopener noreferrer">MedPAIR: Measuring Physicians and AI Relevance Alignment in Medical Question Answering</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yuexing Hao, Kumail Alhamoud, Hyewon Jeong, Haoran Zhang, Isha Puri, Philip Torr, Mike Schaekermann, Ariel D. Stern, Marzyeh Ghassemi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Large Language Models (LLMs) have demonstrated remarkable performance on various medical question-answering (QA) benchmarks, including standardized medical exams. However, correct answers alone do not ensure correct logic, and models may reach accurate conclusions through flawed processes. In this s</span>
                
                <span class="abstract-full" style="display: none;">Large Language Models (LLMs) have demonstrated remarkable performance on various medical question-answering (QA) benchmarks, including standardized medical exams. However, correct answers alone do not ensure correct logic, and models may reach accurate conclusions through flawed processes. In this study, we introduce the MedPAIR (Medical Dataset Comparing Physicians and AI Relevance Estimation and Question Answering) dataset to evaluate how physician trainees and LLMs prioritize relevant information when answering QA questions. We obtain annotations on 1,300 QA pairs from 36 physician trainees, labeling each sentence within the question components for relevance. We compare these relevance estimates to those for LLMs, and further evaluate the impact of these "relevant" subsets on downstream task performance for both physician trainees and LLMs. We find that LLMs are frequently not aligned with the content relevance estimates of physician trainees. After filtering out physician trainee-labeled irrelevant sentences, accuracy improves for both the trainees and the LLMs. All LLM and physician trainee-labeled data are available at: http://medpair.csail.mit.edu/.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 16.0%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.5%">
                            Medicine
                        </span>
                <!-- Computer Vision: 3.3 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.8509
                </span>
                <a href="https://arxiv.org/abs/2401.04139" target="_blank" rel="noopener noreferrer">CCNETS: A Modular Causal Learning Framework for Pattern Recognition in Imbalanced Datasets</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Hanbeot Park, Yunjeong Cho, Hoon-Hee Kim
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Handling class imbalance remains a central challenge in machine learning, particularly in pattern recognition tasks where rare but critical events-such as fraudulent transactions or medical anomalies-must be identified accurately. Traditional generative models offer a potential remedy through data a</span>
                
                <span class="abstract-full" style="display: none;">Handling class imbalance remains a central challenge in machine learning, particularly in pattern recognition tasks where rare but critical events-such as fraudulent transactions or medical anomalies-must be identified accurately. Traditional generative models offer a potential remedy through data augmentation but often treat generation and classification as independent processes, leading to distribution mismatch and limited classifier benefit. To address these shortcomings, we propose Causal Cooperative Networks (CCNETS), a modular learning framework that integrates generation, inference, and reconstruction within a unified causal paradigm. CCNETS comprises three cooperative modules: an Explainer for latent feature abstraction, a Reasoner for label prediction, and a Producer for context-aware data generation. These components interact through a causal feedback loop, where classification results guide targeted sample synthesis. A key innovation, the Zoint mechanism, enables adaptive fusion of latent and observable features, enhancing semantic richness and enabling robust decision-making under uncertainty. We evaluate CCNETS on a real-world credit card fraud detection dataset with extreme imbalance (fraud cases < 0.2%). Across three experimental setups-including synthetic training, amplified generation, and direct classifier comparison-CCNETS outperforms baseline methods, achieving higher F1 scores, precision, and recall. Models trained on CCNETS-generated data also demonstrate superior generalization under limited data conditions. These results establish CCNETS as a scalable, interpretable, and hybrid soft computing framework. By causally aligning synthetic data with classifier objectives, CCNETS advances imbalanced pattern recognition and opens new directions for robust, modular learning in real-world applications.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 9.3%">
                            Medicine
                        </span>
                <!-- LLMs: 3.6 -->
                    
                <!-- 3D: 2.5 -->
                    
                <!-- Datasets: 2.4 -->
                    
                <!-- Computer Vision: 2.0 -->
                    
                <!-- Decision Trees: 1.9 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- T2I: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.8797
                </span>
                <a href="https://arxiv.org/abs/2505.13455" target="_blank" rel="noopener noreferrer">Spatiotemporal Emotional Synchrony in Dyadic Interactions: The Role of Speech Conditions in Facial and Vocal Affective Alignment</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Von Ralph Dane Marquez Herbuela, Yukie Nagai
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Understanding how humans express and synchronize emotions across multiple communication channels particularly facial expressions and speech has significant implications for emotion recognition systems and human computer interaction. Motivated by the notion that non-overlapping speech promotes cleare</span>
                
                <span class="abstract-full" style="display: none;">Understanding how humans express and synchronize emotions across multiple communication channels particularly facial expressions and speech has significant implications for emotion recognition systems and human computer interaction. Motivated by the notion that non-overlapping speech promotes clearer emotional coordination, while overlapping speech disrupts synchrony, this study examines how these conversational dynamics shape the spatial and temporal alignment of arousal and valence across facial and vocal modalities. Using dyadic interactions from the IEMOCAP dataset, we extracted continuous emotion estimates via EmoNet (facial video) and a Wav2Vec2-based model (speech audio). Segments were categorized based on speech overlap, and emotional alignment was assessed using Pearson correlation, lag adjusted analysis, and Dynamic Time Warping (DTW). Across analyses, non overlapping speech was associated with more stable and predictable emotional synchrony than overlapping speech. While zero-lag correlations were low and not statistically different, non overlapping speech showed reduced variability, especially for arousal. Lag adjusted correlations and best-lag distributions revealed clearer, more consistent temporal alignment in these segments. In contrast, overlapping speech exhibited higher variability and flatter lag profiles, though DTW indicated unexpectedly tighter alignment suggesting distinct coordination strategies. Notably, directionality patterns showed that facial expressions more often preceded speech during turn-taking, while speech led during simultaneous vocalizations. These findings underscore the importance of conversational structure in regulating emotional communication and provide new insight into the spatial and temporal dynamics of multimodal affective alignment in real world interaction.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 11.5%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.1%">
                            Medicine
                        </span>
                <!-- Blockchain: 2.8 -->
                    
                <!-- Computer Vision: 2.6 -->
                    
                <!-- Datasets: 2.5 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- 3D: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.9111
                </span>
                <a href="https://arxiv.org/abs/2504.03169" target="_blank" rel="noopener noreferrer">REJEPA: A Novel Joint-Embedding Predictive Architecture for Efficient Remote Sensing Image Retrieval</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Shabnam Choudhury, Yash Salunkhe, Sarthak Mehrotra, Biplab Banerjee
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The rapid expansion of remote sensing image archives demands the development of strong and efficient techniques for content-based image retrieval (RS-CBIR). This paper presents REJEPA (Retrieval with Joint-Embedding Predictive Architecture), an innovative self-supervised framework designed for unimo</span>
                
                <span class="abstract-full" style="display: none;">The rapid expansion of remote sensing image archives demands the development of strong and efficient techniques for content-based image retrieval (RS-CBIR). This paper presents REJEPA (Retrieval with Joint-Embedding Predictive Architecture), an innovative self-supervised framework designed for unimodal RS-CBIR. REJEPA utilises spatially distributed context token encoding to forecast abstract representations of target tokens, effectively capturing high-level semantic features and eliminating unnecessary pixel-level details. In contrast to generative methods that focus on pixel reconstruction or contrastive techniques that depend on negative pairs, REJEPA functions within feature space, achieving a reduction in computational complexity of 40-60% when compared to pixel-reconstruction baselines like Masked Autoencoders (MAE). To guarantee strong and varied representations, REJEPA incorporates Variance-Invariance-Covariance Regularisation (VICReg), which prevents encoder collapse by promoting feature diversity and reducing redundancy. The method demonstrates an estimated enhancement in retrieval accuracy of 5.1% on BEN-14K (S1), 7.4% on BEN-14K (S2), 6.0% on FMoW-RGB, and 10.1% on FMoW-Sentinel compared to prominent SSL techniques, including CSMAE-SESD, Mask-VLM, SatMAE, ScaleMAE, and SatMAE++, on extensive RS benchmarks BEN-14K (multispectral and SAR data), FMoW-RGB and FMoW-Sentinel. Through effective generalisation across sensor modalities, REJEPA establishes itself as a sensor-agnostic benchmark for efficient, scalable, and precise RS-CBIR, addressing challenges like varying resolutions, high object density, and complex backgrounds with computational efficiency.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 8.3%">
                            Medicine
                        </span>
                <!-- LLMs: 4.1 -->
                    
                <!-- Computer Vision: 2.8 -->
                    
                <!-- Hardware: 2.4 -->
                    
                <!-- Blockchain: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- Datasets: 1.8 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- GNN: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.9138
                </span>
                <a href="https://arxiv.org/abs/2505.24167" target="_blank" rel="noopener noreferrer">Pretraining Deformable Image Registration Networks with Random Images</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Junyu Chen, Shuwen Wei, Yihao Liu, Aaron Carass, Yong Du
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Recent advances in deep learning-based medical image registration have shown that training deep neural networks~(DNNs) does not necessarily require medical images. Previous work showed that DNNs trained on randomly generated images with carefully designed noise and contrast properties can still gene</span>
                
                <span class="abstract-full" style="display: none;">Recent advances in deep learning-based medical image registration have shown that training deep neural networks~(DNNs) does not necessarily require medical images. Previous work showed that DNNs trained on randomly generated images with carefully designed noise and contrast properties can still generalize well to unseen medical data. Building on this insight, we propose using registration between random images as a proxy task for pretraining a foundation model for image registration. Empirical results show that our pretraining strategy improves registration accuracy, reduces the amount of domain-specific data needed to achieve competitive performance, and accelerates convergence during downstream training, thereby enhancing computational efficiency.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 9.4%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.1%">
                            LLMs
                        </span>
                <!-- GNN: 2.7 -->
                    
                <!-- Computer Vision: 2.5 -->
                    
                <!-- Quantum Computing: 2.3 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- HPO and AutoML: 2.1 -->
                    
                <!-- Decision Trees: 1.8 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- T2I: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.9224
                </span>
                <a href="https://arxiv.org/abs/2505.24830" target="_blank" rel="noopener noreferrer">Improving Reliability and Explainability of Medical Question Answering through Atomic Fact Checking in Retrieval-Augmented LLMs</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Juraj Vladika, Annika Domres, Mai Nguyen, Rebecca Moser, Jana Nano, Felix Busch, Lisa C. Adams, Keno K. Bressem, Denise Bernhardt, Stephanie E. Combs, Kai J. Borm, Florian Matthes, Jan C. Peeken
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Large language models (LLMs) exhibit extensive medical knowledge but are prone to hallucinations and inaccurate citations, which pose a challenge to their clinical adoption and regulatory compliance. Current methods, such as Retrieval Augmented Generation, partially address these issues by grounding</span>
                
                <span class="abstract-full" style="display: none;">Large language models (LLMs) exhibit extensive medical knowledge but are prone to hallucinations and inaccurate citations, which pose a challenge to their clinical adoption and regulatory compliance. Current methods, such as Retrieval Augmented Generation, partially address these issues by grounding answers in source documents, but hallucinations and low fact-level explainability persist. In this work, we introduce a novel atomic fact-checking framework designed to enhance the reliability and explainability of LLMs used in medical long-form question answering. This method decomposes LLM-generated responses into discrete, verifiable units called atomic facts, each of which is independently verified against an authoritative knowledge base of medical guidelines. This approach enables targeted correction of errors and direct tracing to source literature, thereby improving the factual accuracy and explainability of medical Q&amp;A. Extensive evaluation using multi-reader assessments by medical experts and an automated open Q&amp;A benchmark demonstrated significant improvements in factual accuracy and explainability. Our framework achieved up to a 40% overall answer improvement and a 50% hallucination detection rate. The ability to trace each atomic fact back to the most relevant chunks from the database provides a granular, transparent explanation of the generated responses, addressing a major gap in current medical AI applications. This work represents a crucial step towards more trustworthy and reliable clinical applications of LLMs, addressing key prerequisites for clinical application and fostering greater confidence in AI-assisted healthcare.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 18.4%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.1%">
                            Medicine
                        </span>
                <!-- Blockchain: 1.7 -->
                    
                <!-- Datasets: 1.7 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Quantum Computing: 1.0 -->
                    
                <!-- GNN: 1.0 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.9382
                </span>
                <a href="https://arxiv.org/abs/2505.24053" target="_blank" rel="noopener noreferrer">3DGEER: Exact and Efficient Volumetric Rendering with 3D Gaussians</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zixun Huang, Cho-Ying Wu, Yuliang Guo, Xinyu Huang, Liu Ren
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">3D Gaussian Splatting (3DGS) marks a significant milestone in balancing the quality and efficiency of differentiable rendering. However, its high efficiency stems from an approximation of projecting 3D Gaussians onto the image plane as 2D Gaussians, which inherently limits rendering quality--particu</span>
                
                <span class="abstract-full" style="display: none;">3D Gaussian Splatting (3DGS) marks a significant milestone in balancing the quality and efficiency of differentiable rendering. However, its high efficiency stems from an approximation of projecting 3D Gaussians onto the image plane as 2D Gaussians, which inherently limits rendering quality--particularly under large Field-of-View (FoV) camera inputs. While several recent works have extended 3DGS to mitigate these approximation errors, none have successfully achieved both exactness and high efficiency simultaneously. In this work, we introduce 3DGEER, an Exact and Efficient Volumetric Gaussian Rendering method. Starting from first principles, we derive a closed-form expression for the density integral along a ray traversing a 3D Gaussian distribution. This formulation enables precise forward rendering with arbitrary camera models and supports gradient-based optimization of 3D Gaussian parameters. To ensure both exactness and real-time performance, we propose an efficient method for computing a tight Particle Bounding Frustum (PBF) for each 3D Gaussian, enabling accurate and efficient ray-Gaussian association. We also introduce a novel Bipolar Equiangular Projection (BEAP) representation to accelerate ray association under generic camera models. BEAP further provides a more uniform ray sampling strategy to apply supervision, which empirically improves reconstruction quality. Experiments on multiple pinhole and fisheye datasets show that our method consistently outperforms prior methods, establishing a new state-of-the-art in real-time neural rendering.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #76aa96" title="Confidence: 9.4%">
                            3D
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.3%">
                            Medicine
                        </span>
                <!-- LLMs: 4.9 -->
                    
                <!-- Computer Vision: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Federated Learning: 1.6 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- T2I: 1.2 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.9392
                </span>
                <a href="https://arxiv.org/abs/2505.23834" target="_blank" rel="noopener noreferrer">Patient-Aware Feature Alignment for Robust Lung Sound Classification:Cohesion-Separation and Global Alignment Losses</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Seung Gyu Jeong, Seong Eun Kim
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Lung sound classification is vital for early diagnosis of respiratory diseases. However, biomedical signals often exhibit inter-patient variability even among patients with the same symptoms, requiring a learning approach that considers individual differences. We propose a Patient-Aware Feature Alig</span>
                
                <span class="abstract-full" style="display: none;">Lung sound classification is vital for early diagnosis of respiratory diseases. However, biomedical signals often exhibit inter-patient variability even among patients with the same symptoms, requiring a learning approach that considers individual differences. We propose a Patient-Aware Feature Alignment (PAFA) framework with two novel losses, Patient Cohesion-Separation Loss (PCSL) and Global Patient Alignment Loss (GPAL). PCSL clusters features of the same patient while separating those from other patients to capture patient variability, whereas GPAL draws each patient's centroid toward a global center, preventing feature space fragmentation. Our method achieves outstanding results on the ICBHI dataset with a score of 64.84\% for four-class and 72.08\% for two-class classification. These findings highlight PAFA's ability to capture individualized patterns and demonstrate performance gains in distinct patient clusters, offering broader applications for patient-centered healthcare.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 9.7%">
                            Medicine
                        </span>
                <!-- LLMs: 3.0 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Computer Vision: 1.9 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                <!-- Bayesian Optimization: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.9719
                </span>
                <a href="https://arxiv.org/abs/2505.24475" target="_blank" rel="noopener noreferrer">SPPSFormer: High-quality Superpoint-based Transformer for Roof Plane Instance Segmentation from Point Clouds</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Cheng Zeng, Xiatian Qi, Chi Chen, Kai Sun, Wangle Zhang, Yuxuan Liu, Yan Meng, Bisheng Yang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Transformers have been seldom employed in point cloud roof plane instance segmentation, which is the focus of this study, and existing superpoint Transformers suffer from limited performance due to the use of low-quality superpoints. To address this challenge, we establish two criteria that high-qua</span>
                
                <span class="abstract-full" style="display: none;">Transformers have been seldom employed in point cloud roof plane instance segmentation, which is the focus of this study, and existing superpoint Transformers suffer from limited performance due to the use of low-quality superpoints. To address this challenge, we establish two criteria that high-quality superpoints for Transformers should satisfy and introduce a corresponding two-stage superpoint generation process. The superpoints generated by our method not only have accurate boundaries, but also exhibit consistent geometric sizes and shapes, both of which greatly benefit the feature learning of superpoint Transformers. To compensate for the limitations of deep learning features when the training set size is limited, we incorporate multidimensional handcrafted features into the model. Additionally, we design a decoder that combines a Kolmogorov-Arnold Network with a Transformer module to improve instance prediction and mask extraction. Finally, our network's predictions are refined using traditional algorithm-based postprocessing. For evaluation, we annotated a real-world dataset and corrected annotation errors in the existing RoofN3D dataset. Experimental results show that our method achieves state-of-the-art performance on our dataset, as well as both the original and reannotated RoofN3D datasets. Moreover, our model is not sensitive to plane boundary annotations during training, significantly reducing the annotation burden. Through comprehensive experiments, we also identified key factors influencing roof plane segmentation performance: in addition to roof types, variations in point cloud density, density uniformity, and 3D point precision have a considerable impact. These findings underscore the importance of incorporating data augmentation strategies that account for point cloud quality to enhance model robustness under diverse and challenging conditions.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.9%">
                            Medicine
                        </span>
                <!-- LLMs: 2.6 -->
                    
                <!-- GNN: 2.5 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- 3D: 1.9 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Hardware: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.9749
                </span>
                <a href="https://arxiv.org/abs/2505.24199" target="_blank" rel="noopener noreferrer">Intuitionistic Fuzzy Sets for Large Language Model Data Annotation: A Novel Approach to Side-by-Side Preference Labeling</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yimin Du
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The quality of human preference data is crucial for training and evaluating large language models (LLMs), particularly in reinforcement learning from human feedback (RLHF) and direct preference optimization (DPO) scenarios. Traditional side-by-side (SBS) annotation approaches often struggle with inh</span>
                
                <span class="abstract-full" style="display: none;">The quality of human preference data is crucial for training and evaluating large language models (LLMs), particularly in reinforcement learning from human feedback (RLHF) and direct preference optimization (DPO) scenarios. Traditional side-by-side (SBS) annotation approaches often struggle with inherent uncertainty, annotator disagreement, and the complexity of preference judgments. This paper introduces a novel framework based on intuitionistic fuzzy sets (IFS) for modeling and aggregating human preferences in LLM data annotation tasks. Our approach captures not only the degree of preference but also the uncertainty and hesitation inherent in human judgment through membership, non-membership, and hesitation degrees. We propose an IFS-based annotation protocol that enables more nuanced preference modeling, develops aggregation methods for handling annotator disagreement, and introduces quality metrics for preference data assessment. Experimental validation on multiple datasets demonstrates that our IFS-based approach significantly improves annotation consistency, reduces annotator fatigue, and produces higher-quality preference data compared to traditional binary and Likert-scale methods. The resulting preference datasets lead to improved model performance in downstream tasks, with 12.3\% improvement in win-rate against baseline models and 15.7\% reduction in annotation time. Our framework provides a principled approach to handling uncertainty in human preference annotation and offers practical benefits for large-scale LLM training.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 12.1%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.8%">
                            Medicine
                        </span>
                <!-- Datasets: 2.3 -->
                    
                <!-- Decision Trees: 2.1 -->
                    
                <!-- Computer Vision: 2.0 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- GNN: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.0004
                </span>
                <a href="https://arxiv.org/abs/2505.24247" target="_blank" rel="noopener noreferrer">50 Years of Automated Face Recognition</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Minchul Kim, Anil Jain, Xiaoming Liu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Over the past 50 years, automated face recognition has evolved from rudimentary, handcrafted systems into sophisticated deep learning models that rival and often surpass human performance. This paper chronicles the history and technological progression of FR, from early geometric and statistical met</span>
                
                <span class="abstract-full" style="display: none;">Over the past 50 years, automated face recognition has evolved from rudimentary, handcrafted systems into sophisticated deep learning models that rival and often surpass human performance. This paper chronicles the history and technological progression of FR, from early geometric and statistical methods to modern deep neural architectures leveraging massive real and AI-generated datasets. We examine key innovations that have shaped the field, including developments in dataset, loss function, neural network design and feature fusion. We also analyze how the scale and diversity of training data influence model generalization, drawing connections between dataset growth and benchmark improvements. Recent advances have achieved remarkable milestones: state-of-the-art face verification systems now report False Negative Identification Rates of 0.13% against a 12.4 million gallery in NIST FRVT evaluations for 1:N visa-to-border matching. While recent advances have enabled remarkable accuracy in high- and low-quality face scenarios, numerous challenges persist. While remarkable progress has been achieved, several open research problems remain. We outline critical challenges and promising directions for future face recognition research, including scalability, multi-modal fusion, synthetic identity generation, and explainable systems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.9%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.1%">
                            Medicine
                        </span>
                <!-- Hardware: 2.5 -->
                    
                <!-- Datasets: 2.3 -->
                    
                <!-- Blockchain: 2.2 -->
                    
                <!-- Computer Vision: 2.1 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- 3D: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.0087
                </span>
                <a href="https://arxiv.org/abs/2505.24042" target="_blank" rel="noopener noreferrer">Advancing Digital Accessibility In Digital Pharmacy, Healthcare, And Wearable Devices: Inclusive Solutions for Enhanced Patient Engagement</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Vishnu Ramineni, Balaji Shesharao Ingole, Nikhil Kumar Pulipeta, Balakrishna Pothineni, Aditya Gupta
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Modern healthcare facilities demand digital accessibility to guarantee equal access to telemedicine platforms, online pharmacy services, and health monitoring devices that can be worn or are handy. With the rising call for the implementation of robust digital healthcare solutions, people with disabi</span>
                
                <span class="abstract-full" style="display: none;">Modern healthcare facilities demand digital accessibility to guarantee equal access to telemedicine platforms, online pharmacy services, and health monitoring devices that can be worn or are handy. With the rising call for the implementation of robust digital healthcare solutions, people with disabilities encounter impediments in their endeavor of managing and getting accustomed to these modern technologies owing to insufficient accessibility features. The paper highlights the role of comprehensive solutions for enhanced patient engagement and usability, particularly, in digital pharmacy, healthcare, and wearable devices. Besides, it elucidates the key obstructions faced by users experiencing auditory, visual, cognitive, and motor impairments. Through a kind consideration of present accessibility guidelines, practices, and emerging technologies, the paper provides a holistic overview by offering innovative solutions, accentuating the vitality of compliance with Web Content Accessibility Guidelines (WCAG), Americans with Disabilities Act (ADA), and other regulatory structures to foster easy access to digital healthcare services. Moreover, there is due focus on using AI-driven tools, speech-activated interfaces, and tactile feedback in wearable health devices to assist persons with disabilities. The outcome of the research explicates the necessity of prioritizing accessibility for individuals with disabilities and cultivating a culture where healthcare providers, policymakers, and officials build a patient-centered digital healthcare ecosystem that is all-encompassing in nature.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.0%">
                            Medicine
                        </span>
                <!-- LLMs: 3.3 -->
                    
                <!-- Evolutionary Algorithms: 2.4 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Computer Vision: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.0111
                </span>
                <a href="https://arxiv.org/abs/2505.24287" target="_blank" rel="noopener noreferrer">EgoExOR: An Ego-Exo-Centric Operating Room Dataset for Surgical Activity Understanding</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ege \"Ozsoy, Arda Mamur, Felix Tristram, Chantal Pellegrini, Magdalena Wysocki, Benjamin Busam, Nassir Navab
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Operating rooms (ORs) demand precise coordination among surgeons, nurses, and equipment in a fast-paced, occlusion-heavy environment, necessitating advanced perception models to enhance safety and efficiency. Existing datasets either provide partial egocentric views or sparse exocentric multi-view c</span>
                
                <span class="abstract-full" style="display: none;">Operating rooms (ORs) demand precise coordination among surgeons, nurses, and equipment in a fast-paced, occlusion-heavy environment, necessitating advanced perception models to enhance safety and efficiency. Existing datasets either provide partial egocentric views or sparse exocentric multi-view context, but do not explore the comprehensive combination of both. We introduce EgoExOR, the first OR dataset and accompanying benchmark to fuse first-person and third-person perspectives. Spanning 94 minutes (84,553 frames at 15 FPS) of two emulated spine procedures, Ultrasound-Guided Needle Insertion and Minimally Invasive Spine Surgery, EgoExOR integrates egocentric data (RGB, gaze, hand tracking, audio) from wearable glasses, exocentric RGB and depth from RGB-D cameras, and ultrasound imagery. Its detailed scene graph annotations, covering 36 entities and 22 relations (568,235 triplets), enable robust modeling of clinical interactions, supporting tasks like action recognition and human-centric perception. We evaluate the surgical scene graph generation performance of two adapted state-of-the-art models and offer a new baseline that explicitly leverages EgoExOR's multimodal and multi-perspective signals. This new dataset and benchmark set a new foundation for OR perception, offering a rich, multimodal resource for next-generation clinical perception.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 8.5%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.8%">
                            LLMs
                        </span>
                <!-- Datasets: 2.8 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.0165
                </span>
                <a href="https://arxiv.org/abs/2505.24852" target="_blank" rel="noopener noreferrer">Chameleon: A MatMul-Free Temporal Convolutional Network Accelerator for End-to-End Few-Shot and Continual Learning from Sequential Data</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Douwe den Blanken, Charlotte Frenkel
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">On-device learning at the edge enables low-latency, private personalization with improved long-term robustness and reduced maintenance costs. Yet, achieving scalable, low-power end-to-end on-chip learning, especially from real-world sequential data with a limited number of examples, is an open chall</span>
                
                <span class="abstract-full" style="display: none;">On-device learning at the edge enables low-latency, private personalization with improved long-term robustness and reduced maintenance costs. Yet, achieving scalable, low-power end-to-end on-chip learning, especially from real-world sequential data with a limited number of examples, is an open challenge. Indeed, accelerators supporting error backpropagation optimize for learning performance at the expense of inference efficiency, while simplified learning algorithms often fail to reach acceptable accuracy targets. In this work, we present Chameleon, leveraging three key contributions to solve these challenges. (i) A unified learning and inference architecture supports few-shot learning (FSL), continual learning (CL) and inference at only 0.5% area overhead to the inference logic. (ii) Long temporal dependencies are efficiently captured with temporal convolutional networks (TCNs), enabling the first demonstration of end-to-end on-chip FSL and CL on sequential data and inference on 16-kHz raw audio. (iii) A dual-mode, matrix-multiplication-free compute array allows either matching the power consumption of state-of-the-art inference-only keyword spotting (KWS) accelerators or enabling $4.3\times$ higher peak GOPS. Fabricated in 40-nm CMOS, Chameleon sets new accuracy records on Omniglot for end-to-end on-chip FSL (96.8%, 5-way 1-shot, 98.8%, 5-way 5-shot) and CL (82.2% final accuracy for learning 250 classes with 10 shots), while maintaining an inference accuracy of 93.3% on the 12-class Google Speech Commands dataset at an extreme-edge power budget of 3.1 $\mu$W.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 8.7%">
                            Medicine
                        </span>
                <!-- Hardware: 2.7 -->
                    
                <!-- Computer Vision: 2.6 -->
                    
                <!-- Federated Learning: 2.6 -->
                    
                <!-- LLMs: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.0311
                </span>
                <a href="https://arxiv.org/abs/2505.24255" target="_blank" rel="noopener noreferrer">Effects of Theory of Mind and Prosocial Beliefs on Steering Human-Aligned Behaviors of LLMs in Ultimatum Games</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Neemesh Yadav, Palakorn Achananuparp, Jing Jiang, Ee-Peng Lim
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Large Language Models (LLMs) have shown potential in simulating human behaviors and performing theory-of-mind (ToM) reasoning, a crucial skill for complex social interactions. In this study, we investigate the role of ToM reasoning in aligning agentic behaviors with human norms in negotiation tasks,</span>
                
                <span class="abstract-full" style="display: none;">Large Language Models (LLMs) have shown potential in simulating human behaviors and performing theory-of-mind (ToM) reasoning, a crucial skill for complex social interactions. In this study, we investigate the role of ToM reasoning in aligning agentic behaviors with human norms in negotiation tasks, using the ultimatum game as a controlled environment. We initialized LLM agents with different prosocial beliefs (including Greedy, Fair, and Selfless) and reasoning methods like chain-of-thought (CoT) and varying ToM levels, and examined their decision-making processes across diverse LLMs, including reasoning models like o3-mini and DeepSeek-R1 Distilled Qwen 32B. Results from 2,700 simulations indicated that ToM reasoning enhances behavior alignment, decision-making consistency, and negotiation outcomes. Consistent with previous findings, reasoning models exhibit limited capability compared to models with ToM reasoning, different roles of the game benefits with different orders of ToM reasoning. Our findings contribute to the understanding of ToM's role in enhancing human-AI interaction and cooperative decision-making. The code used for our experiments can be found at https://github.com/Stealth-py/UltimatumToM.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 38.6%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.5%">
                            Medicine
                        </span>
                <!-- Datasets: 2.2 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.0337
                </span>
                <a href="https://arxiv.org/abs/2505.24705" target="_blank" rel="noopener noreferrer">RT-X Net: RGB-Thermal cross attention network for Low-Light Image Enhancement</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Raman Jha, Adithya Lenka, Mani Ramanagopal, Aswin Sankaranarayanan, Kaushik Mitra
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In nighttime conditions, high noise levels and bright illumination sources degrade image quality, making low-light image enhancement challenging. Thermal images provide complementary information, offering richer textures and structural details. We propose RT-X Net, a cross-attention network that fus</span>
                
                <span class="abstract-full" style="display: none;">In nighttime conditions, high noise levels and bright illumination sources degrade image quality, making low-light image enhancement challenging. Thermal images provide complementary information, offering richer textures and structural details. We propose RT-X Net, a cross-attention network that fuses RGB and thermal images for nighttime image enhancement. We leverage self-attention networks for feature extraction and a cross-attention mechanism for fusion to effectively integrate information from both modalities. To support research in this domain, we introduce the Visible-Thermal Image Enhancement Evaluation (V-TIEE) dataset, comprising 50 co-located visible and thermal images captured under diverse nighttime conditions. Extensive evaluations on the publicly available LLVIP dataset and our V-TIEE dataset demonstrate that RT-X Net outperforms state-of-the-art methods in low-light image enhancement. The code and the V-TIEE can be found here https://github.com/jhakrraman/rt-xnet.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 8.1%">
                            Medicine
                        </span>
                <!-- LLMs: 4.5 -->
                    
                <!-- Computer Vision: 3.4 -->
                    
                <!-- Datasets: 2.2 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- T2I: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.0377
                </span>
                <a href="https://arxiv.org/abs/2504.16181" target="_blank" rel="noopener noreferrer">CLIP-IT: CLIP-based Pairing for Histology Images Classification</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Banafsheh Karimian, Giulia Avanzato, Soufian Belharbi, Luke McCaffrey, Mohammadhadi Shateri, Eric Granger
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Multimodal learning has shown significant promise for improving medical image analysis by integrating information from complementary data sources. This is widely employed for training vision-language models (VLMs) for cancer detection based on histology images and text reports. However, one of the m</span>
                
                <span class="abstract-full" style="display: none;">Multimodal learning has shown significant promise for improving medical image analysis by integrating information from complementary data sources. This is widely employed for training vision-language models (VLMs) for cancer detection based on histology images and text reports. However, one of the main limitations in training these VLMs is the requirement for large paired datasets, raising concerns over privacy, and data collection, annotation, and maintenance costs. To address this challenge, we introduce CLIP-IT method to train a vision backbone model to classify histology images by pairing them with privileged textual information from an external source. At first, the modality pairing step relies on a CLIP-based model to match histology images with semantically relevant textual report data from external sources, creating an augmented multimodal dataset without the need for manually paired samples. Then, we propose a multimodal training procedure that distills the knowledge from the paired text modality to the unimodal image classifier for enhanced performance without the need for the textual data during inference. A parameter-efficient fine-tuning method is used to efficiently address the misalignment between the main (image) and paired (text) modalities. During inference, the improved unimodal histology classifier is used, with only minimal additional computational complexity. Our experiments on challenging PCAM, CRC, and BACH histology image datasets show that CLIP-IT can provide a cost-effective approach to leverage privileged textual information and outperform unimodal classifiers for histology.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 8.8%">
                            Medicine
                        </span>
                <!-- Computer Vision: 4.6 -->
                    
                <!-- Federated Learning: 2.3 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- LLMs: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.1013
                </span>
                <a href="https://arxiv.org/abs/2505.24537" target="_blank" rel="noopener noreferrer">ASP Chef grows Mustache to look better</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Mario Alviano, Wolfgang Faber, Luis Angel Rodriguez Reiners
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We present ASP Chef Mustache, an extension of ASP Chef that enhances template-based rendering of ASP solutions using a logic-less templating system inspired by Mustache. Our approach integrates data visualization frameworks such as Tabulator, Chart.js, and vis.js, enabling interactive representation</span>
                
                <span class="abstract-full" style="display: none;">We present ASP Chef Mustache, an extension of ASP Chef that enhances template-based rendering of ASP solutions using a logic-less templating system inspired by Mustache. Our approach integrates data visualization frameworks such as Tabulator, Chart.js, and vis.js, enabling interactive representations of ASP interpretations as tables, charts, and graphs. Mustache queries in templates support advanced constructs for formatting, sorting, and multi-stage expansion, facilitating the generation of rich, structured outputs. We demonstrate the power of this framework through a series of use cases, including data analysis for the Italian VQR, visualization of blocking sets in graphs, and scheduling problems. The result is a versatile tool for bridging declarative problem solving and modern web-based visual analytics.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.1%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.5%">
                            LLMs
                        </span>
                <!-- Hardware: 2.4 -->
                    
                <!-- Datasets: 2.3 -->
                    
                <!-- Blockchain: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 2.2 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.1204
                </span>
                <a href="https://arxiv.org/abs/2505.24375" target="_blank" rel="noopener noreferrer">Spatiotemporal Analysis of Forest Machine Operations Using 3D Video Classification</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Maciej Wielgosz, Simon Berg, Heikki Korpunen, Stephan Hoffmann
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper presents a deep learning-based framework for classifying forestry operations from dashcam video footage. Focusing on four key work elements - crane-out, cutting-and-to-processing, driving, and processing - the approach employs a 3D ResNet-50 architecture implemented with PyTorchVideo. Tra</span>
                
                <span class="abstract-full" style="display: none;">This paper presents a deep learning-based framework for classifying forestry operations from dashcam video footage. Focusing on four key work elements - crane-out, cutting-and-to-processing, driving, and processing - the approach employs a 3D ResNet-50 architecture implemented with PyTorchVideo. Trained on a manually annotated dataset of field recordings, the model achieves strong performance, with a validation F1 score of 0.88 and precision of 0.90. These results underscore the effectiveness of spatiotemporal convolutional networks for capturing both motion patterns and appearance in real-world forestry environments.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 9.2%">
                            Medicine
                        </span>
                <!-- LLMs: 3.1 -->
                    
                <!-- Evolutionary Algorithms: 2.5 -->
                    
                <!-- Hardware: 2.5 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- Blockchain: 2.0 -->
                    
                <!-- 3D: 1.9 -->
                    
                <!-- Datasets: 1.8 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.142
                </span>
                <a href="https://arxiv.org/abs/2503.14753" target="_blank" rel="noopener noreferrer">Dexterous Control of an 11-DOF Redundant Robot for CT-Guided Needle Insertion With Task-Oriented Weighted Policies</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Peihan Zhang, Florian Richter, Ishan Duriseti, Albert Hsiao, Sean Tutton, Alexander Norbash, Michael Yip
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Computed tomography (CT)-guided needle biopsies are critical for diagnosing a range of conditions, including lung cancer, but present challenges such as limited in-bore space, prolonged procedure times, and radiation exposure. Robotic assistance offers a promising solution by improving needle trajec</span>
                
                <span class="abstract-full" style="display: none;">Computed tomography (CT)-guided needle biopsies are critical for diagnosing a range of conditions, including lung cancer, but present challenges such as limited in-bore space, prolonged procedure times, and radiation exposure. Robotic assistance offers a promising solution by improving needle trajectory accuracy, reducing radiation exposure, and enabling real-time adjustments. In our previous work, we introduced a redundant robotic platform designed for dexterous needle insertion within the confined CT bore. However, its limited base mobility restricts flexible deployment in clinical settings. In this study, we present an improved 11-degree-of-freedom (DOF) robotic system that integrates a 6-DOF robotic base with a 5-DOF cable-driven end-effector, significantly enhancing workspace flexibility and precision. With the hyper-redundant degrees of freedom, we introduce a weighted inverse kinematics controller with a two-stage priority scheme for large-scale movement and fine in-bore adjustments, along with a null-space control strategy to optimize dexterity. We validate our system through both simulation and real-world experiments, demonstrating superior tracking accuracy and enhanced manipulability in CT-guided procedures. The study provides a strong case for hyper-redundancy and null-space control formulations for robot-assisted needle biopsy scenarios.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 10.0%">
                            Medicine
                        </span>
                <!-- LLMs: 4.0 -->
                    
                <!-- Hardware: 2.2 -->
                    
                <!-- Computer Vision: 1.9 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- T2I: 1.2 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.1477
                </span>
                <a href="https://arxiv.org/abs/2505.24065" target="_blank" rel="noopener noreferrer">Cross-Modal Characterization of Thin Film MoS$_2$ Using Generative Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Isaiah A. Moses, Chen Chen, Joan M. Redwing, Wesley F. Reinhart
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The growth and characterization of materials using empirical optimization typically requires a significant amount of expert time, experience, and resources. Several complementary characterization methods are routinely performed to determine the quality and properties of a grown sample. Machine learn</span>
                
                <span class="abstract-full" style="display: none;">The growth and characterization of materials using empirical optimization typically requires a significant amount of expert time, experience, and resources. Several complementary characterization methods are routinely performed to determine the quality and properties of a grown sample. Machine learning (ML) can support the conventional approaches by using historical data to guide and provide speed and efficiency to the growth and characterization of materials. Specifically, ML can provide quantitative information from characterization data that is typically obtained from a different modality. In this study, we have investigated the feasibility of projecting the quantitative metric from microscopy measurements, such as atomic force microscopy (AFM), using data obtained from spectroscopy measurements, like Raman spectroscopy. Generative models were also trained to generate the full and specific features of the Raman and photoluminescence spectra from each other and the AFM images of the thin film MoS$_2$. The results are promising and have provided a foundational guide for the use of ML for the cross-modal characterization of materials for their accelerated, efficient, and cost-effective discovery.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 8.6%">
                            Medicine
                        </span>
                <!-- LLMs: 2.5 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Datasets: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                <!-- Computer Vision: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.1729
                </span>
                <a href="https://arxiv.org/abs/2505.24351" target="_blank" rel="noopener noreferrer">A Novel Coronary Artery Registration Method Based on Super-pixel Particle Swarm Optimization</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Peng Qi, Wenxi Qu, Tianliang Yao, Haonan Ma, Dylan Wintle, Yinyi Lai, Giorgos Papanastasiou, Chengjia Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Percutaneous Coronary Intervention (PCI) is a minimally invasive procedure that improves coronary blood flow and treats coronary artery disease. Although PCI typically requires 2D X-ray angiography (XRA) to guide catheter placement at real-time, computed tomography angiography (CTA) may substantiall</span>
                
                <span class="abstract-full" style="display: none;">Percutaneous Coronary Intervention (PCI) is a minimally invasive procedure that improves coronary blood flow and treats coronary artery disease. Although PCI typically requires 2D X-ray angiography (XRA) to guide catheter placement at real-time, computed tomography angiography (CTA) may substantially improve PCI by providing precise information of 3D vascular anatomy and status. To leverage real-time XRA and detailed 3D CTA anatomy for PCI, accurate multimodal image registration of XRA and CTA is required, to guide the procedure and avoid complications. This is a challenging process as it requires registration of images from different geometrical modalities (2D -> 3D and vice versa), with variations in contrast and noise levels. In this paper, we propose a novel multimodal coronary artery image registration method based on a swarm optimization algorithm, which effectively addresses challenges such as large deformations, low contrast, and noise across these imaging modalities. Our algorithm consists of two main modules: 1) preprocessing of XRA and CTA images separately, and 2) a registration module based on feature extraction using the Steger and Superpixel Particle Swarm Optimization algorithms. Our technique was evaluated on a pilot dataset of 28 pairs of XRA and CTA images from 10 patients who underwent PCI. The algorithm was compared with four state-of-the-art (SOTA) methods in terms of registration accuracy, robustness, and efficiency. Our method outperformed the selected SOTA baselines in all aspects. Experimental results demonstrate the significant effectiveness of our algorithm, surpassing the previous benchmarks and proposes a novel clinical approach that can potentially have merit for improving patient outcomes in coronary artery disease.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 8.0%">
                            Medicine
                        </span>
                <!-- LLMs: 4.9 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- Evolutionary Algorithms: 2.3 -->
                    
                <!-- Datasets: 2.1 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.1778
                </span>
                <a href="https://arxiv.org/abs/2505.23797" target="_blank" rel="noopener noreferrer">Detection of Suicidal Risk on Social Media: A Hybrid Model</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zaihan Yang, Ryan Leonard, Hien Tran, Rory Driscoll, Chadbourne Davis
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Suicidal thoughts and behaviors are increasingly recognized as a critical societal concern, highlighting the urgent need for effective tools to enable early detection of suicidal risk. In this work, we develop robust machine learning models that leverage Reddit posts to automatically classify them i</span>
                
                <span class="abstract-full" style="display: none;">Suicidal thoughts and behaviors are increasingly recognized as a critical societal concern, highlighting the urgent need for effective tools to enable early detection of suicidal risk. In this work, we develop robust machine learning models that leverage Reddit posts to automatically classify them into four distinct levels of suicide risk severity. We frame this as a multi-class classification task and propose a RoBERTa-TF-IDF-PCA Hybrid model, integrating the deep contextual embeddings from Robustly Optimized BERT Approach (RoBERTa), a state-of-the-art deep learning transformer model, with the statistical term-weighting of TF-IDF, further compressed with PCA, to boost the accuracy and reliability of suicide risk assessment. To address data imbalance and overfitting, we explore various data resampling techniques and data augmentation strategies to enhance model generalization. Additionally, we compare our model's performance against that of using RoBERTa only, the BERT model and other traditional machine learning classifiers. Experimental results demonstrate that the hybrid model can achieve improved performance, giving a best weighted $F_{1}$ score of 0.7512.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 8.7%">
                            Medicine
                        </span>
                <!-- LLMs: 4.2 -->
                    
                <!-- Federated Learning: 3.7 -->
                    
                <!-- Computer Vision: 1.9 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.1779
                </span>
                <a href="https://arxiv.org/abs/2504.00459" target="_blank" rel="noopener noreferrer">Graphical Models and Efficient Inference Methods for Multivariate Phase Probability Distributions</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Andrew S. Perley, Todd P. Coleman
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Multivariate phase relationships are important to characterize and understand numerous physical, biological, and chemical systems, from electromagnetic waves to neural oscillations. These systems exhibit complex spatiotemporal dynamics and intricate interdependencies among their constituent elements</span>
                
                <span class="abstract-full" style="display: none;">Multivariate phase relationships are important to characterize and understand numerous physical, biological, and chemical systems, from electromagnetic waves to neural oscillations. These systems exhibit complex spatiotemporal dynamics and intricate interdependencies among their constituent elements. While classical models of multivariate phase relationships, such as the wave equation and Kuramoto model, give theoretical models to describe phenomena, the development of statistical tools for hypothesis testing and inference for multivariate phase relationships in complex systems remains limited. This paper introduces a novel probabilistic modeling framework to characterize multivariate phase relationships, with wave-like phenomena serving as a key example. This approach describes spatial patterns and interactions between oscillators through a pairwise exponential family distribution. Building upon the literature of graphical model inference, including methods like Ising models, graphical lasso, and interaction screening, this work bridges the gap between classical wave dynamics and modern statistical approaches. Efficient inference methods are introduced, leveraging the Chow-Liu algorithm for directed tree approximations and interaction screening for general graphical models. Simulated experiments demonstrate the utility of these methods for uncovering wave properties and sparse interaction structures, highlighting their applicability to diverse scientific domains. This framework establishes a new paradigm for statistical modeling of multivariate phase relationships, providing a powerful toolset for exploring the complexity of these systems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.3%">
                            Medicine
                        </span>
                <!-- LLMs: 3.3 -->
                    
                <!-- Hardware: 2.8 -->
                    
                <!-- Evolutionary Algorithms: 2.2 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.2467
                </span>
                <a href="https://arxiv.org/abs/2505.24481" target="_blank" rel="noopener noreferrer">ACM-UNet: Adaptive Integration of CNNs and Mamba for Efficient Medical Image Segmentation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jing Huang, Yongkang Zhao, Yuhan Li, Zhitao Dai, Cheng Chen, Qiying Lai
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The U-shaped encoder-decoder architecture with skip connections has become a prevailing paradigm in medical image segmentation due to its simplicity and effectiveness. While many recent works aim to improve this framework by designing more powerful encoders and decoders, employing advanced convoluti</span>
                
                <span class="abstract-full" style="display: none;">The U-shaped encoder-decoder architecture with skip connections has become a prevailing paradigm in medical image segmentation due to its simplicity and effectiveness. While many recent works aim to improve this framework by designing more powerful encoders and decoders, employing advanced convolutional neural networks (CNNs) for local feature extraction, Transformers or state space models (SSMs) such as Mamba for global context modeling, or hybrid combinations of both, these methods often struggle to fully utilize pretrained vision backbones (e.g., ResNet, ViT, VMamba) due to structural mismatches. To bridge this gap, we introduce ACM-UNet, a general-purpose segmentation framework that retains a simple UNet-like design while effectively incorporating pretrained CNNs and Mamba models through a lightweight adapter mechanism. This adapter resolves architectural incompatibilities and enables the model to harness the complementary strengths of CNNs and SSMs-namely, fine-grained local detail extraction and long-range dependency modeling. Additionally, we propose a hierarchical multi-scale wavelet transform module in the decoder to enhance feature fusion and reconstruction fidelity. Extensive experiments on the Synapse and ACDC benchmarks demonstrate that ACM-UNet achieves state-of-the-art performance while remaining computationally efficient. Notably, it reaches 85.12% Dice Score and 13.89mm HD95 on the Synapse dataset with 17.93G FLOPs, showcasing its effectiveness and scalability. Code is available at: https://github.com/zyklcode/ACM-UNet.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 9.7%">
                            Medicine
                        </span>
                <!-- LLMs: 4.9 -->
                    
                <!-- Computer Vision: 2.8 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.2694
                </span>
                <a href="https://arxiv.org/abs/2409.18745" target="_blank" rel="noopener noreferrer">A study on the effects of mixed explicit and implicit communications in human-virtual-agent interactions</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ana Christina Almada Campos, Bruno Vilhena Adorno
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Communication between humans and robots (or virtual agents) is essential for interaction and often inspired by human communication, which uses gestures, facial expressions, gaze direction, and other explicit and implicit means. This work presents an interaction experiment where humans and virtual ag</span>
                
                <span class="abstract-full" style="display: none;">Communication between humans and robots (or virtual agents) is essential for interaction and often inspired by human communication, which uses gestures, facial expressions, gaze direction, and other explicit and implicit means. This work presents an interaction experiment where humans and virtual agents interact through explicit (gestures, manual entries using mouse and keyboard, voice, sound, and information on screen) and implicit (gaze direction, location, facial expressions, and raise of eyebrows) communication to evaluate the effect of mixed explicit-implicit communication against purely explicit communication. Results obtained using Bayesian parameter estimation show that the number of errors and task execution time did not significantly change when mixed explicit and implicit communications were used, and neither the perceived efficiency of the interaction. In contrast, acceptance, sociability, and transparency of the virtual agent increased when using mixed communication modalities (88.3%, 92%, and 92.9% of the effect size posterior distribution of each variable, respectively, were above the upper limit of the region of practical equivalence). This suggests that task-related measures, such as time, number of errors, and perceived efficiency of the interaction, have not been influenced by the communication type in our particular experiment. However, the improvement of subjective measures related to the virtual agent, such as acceptance, sociability, and transparency, suggests that humans are more receptive to mixed explicit and implicit communications.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.8%">
                            Medicine
                        </span>
                <!-- LLMs: 4.7 -->
                    
                <!-- Blockchain: 3.1 -->
                    
                <!-- Hardware: 2.9 -->
                    
                <!-- Datasets: 2.0 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.2873
                </span>
                <a href="https://arxiv.org/abs/2505.24269" target="_blank" rel="noopener noreferrer">INSIGHT: A Survey of In-Network Systems for Intelligent, High-Efficiency AI and Topology Optimization</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Aleksandr Algazinov, Joydeep Chandra, Matt Laing
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In-network computation represents a transformative approach to addressing the escalating demands of Artificial Intelligence (AI) workloads on network infrastructure. By leveraging the processing capabilities of network devices such as switches, routers, and Network Interface Cards (NICs), this parad</span>
                
                <span class="abstract-full" style="display: none;">In-network computation represents a transformative approach to addressing the escalating demands of Artificial Intelligence (AI) workloads on network infrastructure. By leveraging the processing capabilities of network devices such as switches, routers, and Network Interface Cards (NICs), this paradigm enables AI computations to be performed directly within the network fabric, significantly reducing latency, enhancing throughput, and optimizing resource utilization. This paper provides a comprehensive analysis of optimizing in-network computation for AI, exploring the evolution of programmable network architectures, such as Software-Defined Networking (SDN) and Programmable Data Planes (PDPs), and their convergence with AI. It examines methodologies for mapping AI models onto resource-constrained network devices, addressing challenges like limited memory and computational capabilities through efficient algorithm design and model compression techniques. The paper also highlights advancements in distributed learning, particularly in-network aggregation, and the potential of federated learning to enhance privacy and scalability. Frameworks like Planter and Quark are discussed for simplifying development, alongside key applications such as intelligent network monitoring, intrusion detection, traffic management, and Edge AI. Future research directions, including runtime programmability, standardized benchmarks, and new applications paradigms, are proposed to advance this rapidly evolving field. This survey underscores the potential of in-network AI to create intelligent, efficient, and responsive networks capable of meeting the demands of next-generation AI applications.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.1%">
                            Medicine
                        </span>
                <!-- LLMs: 4.4 -->
                    
                <!-- Hardware: 4.2 -->
                    
                <!-- Blockchain: 3.2 -->
                    
                <!-- Evolutionary Algorithms: 2.2 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- Datasets: 2.1 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.3354
                </span>
                <a href="https://arxiv.org/abs/2502.19668" target="_blank" rel="noopener noreferrer">SuPreME: A Supervised Pre-training Framework for Multimodal ECG Representation Learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Mingsheng Cai, Jiuming Jiang, Wenhao Huang, Che Liu, Rossella Arcucci
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Cardiovascular diseases are a leading cause of death and disability worldwide. Electrocardiogram (ECG) is critical for diagnosing and monitoring cardiac health, but obtaining large-scale annotated ECG datasets is labor-intensive and time-consuming. Recent ECG Self-Supervised Learning (eSSL) methods </span>
                
                <span class="abstract-full" style="display: none;">Cardiovascular diseases are a leading cause of death and disability worldwide. Electrocardiogram (ECG) is critical for diagnosing and monitoring cardiac health, but obtaining large-scale annotated ECG datasets is labor-intensive and time-consuming. Recent ECG Self-Supervised Learning (eSSL) methods mitigate this by learning features without extensive labels but fail to capture fine-grained clinical semantics and require extensive task-specific fine-tuning. To address these challenges, we propose $\textbf{SuPreME}$, a $\textbf{Su}$pervised $\textbf{Pre}$-training framework for $\textbf{M}$ultimodal $\textbf{E}$CG representation learning. SuPreME is pre-trained using structured diagnostic labels derived from ECG report entities through a one-time offline extraction with Large Language Models (LLMs), which help denoise, standardize cardiac concepts, and improve clinical representation learning. By fusing ECG signals with textual cardiac queries instead of fixed labels, SuPreME enables zero-shot classification of unseen conditions without further fine-tuning. We evaluate SuPreME on six downstream datasets covering 106 cardiac conditions, achieving superior zero-shot AUC performance of $77.20\%$, surpassing state-of-the-art eSSLs by $4.98\%$. Results demonstrate SuPreME's effectiveness in leveraging structured, clinically relevant knowledge for high-quality ECG representations.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 9.9%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.3%">
                            LLMs
                        </span>
                <!-- Federated Learning: 2.2 -->
                    
                <!-- HPO and AutoML: 2.1 -->
                    
                <!-- 3D: 2.0 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- Blockchain: 2.0 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- Datasets: 1.8 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.3823
                </span>
                <a href="https://arxiv.org/abs/2505.24016" target="_blank" rel="noopener noreferrer">BeaverTalk: Oregon State University's IWSLT 2025 Simultaneous Speech Translation System</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Matthew Raffel, Victor Agostinelli, Lizhong Chen
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper discusses the construction, fine-tuning, and deployment of BeaverTalk, a cascaded system for speech-to-text translation as part of the IWSLT 2025 simultaneous translation task. The system architecture employs a VAD segmenter for breaking a speech stream into segments, Whisper Large V2 for</span>
                
                <span class="abstract-full" style="display: none;">This paper discusses the construction, fine-tuning, and deployment of BeaverTalk, a cascaded system for speech-to-text translation as part of the IWSLT 2025 simultaneous translation task. The system architecture employs a VAD segmenter for breaking a speech stream into segments, Whisper Large V2 for automatic speech recognition (ASR), and Gemma 3 12B for simultaneous translation. Regarding the simultaneous translation LLM, it is fine-tuned via low-rank adaptors (LoRAs) for a conversational prompting strategy that leverages a single prior-sentence memory bank from the source language as context. The cascaded system participated in the English$\rightarrow$German and English$\rightarrow$Chinese language directions for both the low and high latency regimes. In particular, on the English$\rightarrow$German task, the system achieves a BLEU of 24.64 and 27.83 at a StreamLAAL of 1837.86 and 3343.73, respectively. Then, on the English$\rightarrow$Chinese task, the system achieves a BLEU of 34.07 and 37.23 at a StreamLAAL of 2216.99 and 3521.35, respectively.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 8.7%">
                            Medicine
                        </span>
                <!-- Hardware: 4.9 -->
                    
                <!-- LLMs: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Networks: 1.1 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.4049
                </span>
                <a href="https://arxiv.org/abs/2505.24108" target="_blank" rel="noopener noreferrer">Federated Foundation Model for GI Endoscopy Images</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Alina Devkota, Annahita Amireskandari, Joel Palko, Shyam Thakkar, Donald Adjeroh, Xiajun Jiang, Binod Bhattarai, Prashnna K. Gyawali
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Gastrointestinal (GI) endoscopy is essential in identifying GI tract abnormalities in order to detect diseases in their early stages and improve patient outcomes. Although deep learning has shown success in supporting GI diagnostics and decision-making, these models require curated datasets with lab</span>
                
                <span class="abstract-full" style="display: none;">Gastrointestinal (GI) endoscopy is essential in identifying GI tract abnormalities in order to detect diseases in their early stages and improve patient outcomes. Although deep learning has shown success in supporting GI diagnostics and decision-making, these models require curated datasets with labels that are expensive to acquire. Foundation models offer a promising solution by learning general-purpose representations, which can be finetuned for specific tasks, overcoming data scarcity. Developing foundation models for medical imaging holds significant potential, but the sensitive and protected nature of medical data presents unique challenges. Foundation model training typically requires extensive datasets, and while hospitals generate large volumes of data, privacy restrictions prevent direct data sharing, making foundation model training infeasible in most scenarios. In this work, we propose a FL framework for training foundation models for gastroendoscopy imaging, enabling data to remain within local hospital environments while contributing to a shared model. We explore several established FL algorithms, assessing their suitability for training foundation models without relying on task-specific labels, conducting experiments in both homogeneous and heterogeneous settings. We evaluate the trained foundation model on three critical downstream tasks--classification, detection, and segmentation--and demonstrate that it achieves improved performance across all tasks, highlighting the effectiveness of our approach in a federated, privacy-preserving setting.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 9.4%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.0%">
                            LLMs
                        </span>
                <!-- Computer Vision: 2.5 -->
                    
                <!-- Federated Learning: 2.3 -->
                    
                <!-- Decision Trees: 2.0 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.4512
                </span>
                <a href="https://arxiv.org/abs/2505.23781" target="_blank" rel="noopener noreferrer">Unified AI for Accurate Audio Anomaly Detection</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Hamideh Khaleghpour, Brett McKinney
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper presents a unified AI framework for high-accuracy audio anomaly detection by integrating advanced noise reduction, feature extraction, and machine learning modeling techniques. The approach combines spectral subtraction and adaptive filtering to enhance audio quality, followed by feature </span>
                
                <span class="abstract-full" style="display: none;">This paper presents a unified AI framework for high-accuracy audio anomaly detection by integrating advanced noise reduction, feature extraction, and machine learning modeling techniques. The approach combines spectral subtraction and adaptive filtering to enhance audio quality, followed by feature extraction using traditional methods like MFCCs and deep embeddings from pre-trained models such as OpenL3. The modeling pipeline incorporates classical models (SVM, Random Forest), deep learning architectures (CNNs), and ensemble methods to boost robustness and accuracy. Evaluated on benchmark datasets including TORGO and LibriSpeech, the proposed framework demonstrates superior performance in precision, recall, and classification of slurred vs. normal speech. This work addresses challenges in noisy environments and real-time applications and provides a scalable solution for audio-based anomaly detection.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 9.8%">
                            Medicine
                        </span>
                <!-- LLMs: 4.9 -->
                    
                <!-- Computer Vision: 4.0 -->
                    
                <!-- HPO and AutoML: 2.3 -->
                    
                <!-- Decision Trees: 2.2 -->
                    
                <!-- Hardware: 2.2 -->
                    
                <!-- Datasets: 2.0 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.4568
                </span>
                <a href="https://arxiv.org/abs/2505.24792" target="_blank" rel="noopener noreferrer">Lightweight Relational Embedding in Task-Interpolated Few-Shot Networks for Enhanced Gastrointestinal Disease Classification</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Xinliu Zhong, Leo Hwa Liang, Angela S. Koh, Yeo Si Yong
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Traditional diagnostic methods like colonoscopy are invasive yet critical tools necessary for accurately diagnosing colorectal cancer (CRC). Detection of CRC at early stages is crucial for increasing patient survival rates. However, colonoscopy is dependent on obtaining adequate and high-quality end</span>
                
                <span class="abstract-full" style="display: none;">Traditional diagnostic methods like colonoscopy are invasive yet critical tools necessary for accurately diagnosing colorectal cancer (CRC). Detection of CRC at early stages is crucial for increasing patient survival rates. However, colonoscopy is dependent on obtaining adequate and high-quality endoscopic images. Prolonged invasive procedures are inherently risky for patients, while suboptimal or insufficient images hamper diagnostic accuracy. These images, typically derived from video frames, often exhibit similar patterns, posing challenges in discrimination. To overcome these challenges, we propose a novel Deep Learning network built on a Few-Shot Learning architecture, which includes a tailored feature extractor, task interpolation, relational embedding, and a bi-level routing attention mechanism. The Few-Shot Learning paradigm enables our model to rapidly adapt to unseen fine-grained endoscopic image patterns, and the task interpolation augments the insufficient images artificially from varied instrument viewpoints. Our relational embedding approach discerns critical intra-image features and captures inter-image transitions between consecutive endoscopic frames, overcoming the limitations of Convolutional Neural Networks (CNNs). The integration of a light-weight attention mechanism ensures a concentrated analysis of pertinent image regions. By training on diverse datasets, the model's generalizability and robustness are notably improved for handling endoscopic images. Evaluated on Kvasir dataset, our model demonstrated superior performance, achieving an accuracy of 90.1\%, precision of 0.845, recall of 0.942, and an F1 score of 0.891. This surpasses current state-of-the-art methods, presenting a promising solution to the challenges of invasive colonoscopy by optimizing CRC detection through advanced image analysis.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 10.6%">
                            Medicine
                        </span>
                <!-- Federated Learning: 2.5 -->
                    
                <!-- LLMs: 2.5 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- GNN: 2.1 -->
                    
                <!-- Computer Vision: 1.9 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.5128
                </span>
                <a href="https://arxiv.org/abs/2505.24214" target="_blank" rel="noopener noreferrer">Benchmarking Foundation Models for Zero-Shot Biometric Tasks</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Redwan Sony, Parisa Farmanifard, Hamzeh Alzwairy, Nitish Shukla, Arun Ross
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The advent of foundation models, particularly Vision-Language Models (VLMs) and Multi-modal Large Language Models (MLLMs), has redefined the frontiers of artificial intelligence, enabling remarkable generalization across diverse tasks with minimal or no supervision. Yet, their potential in biometric</span>
                
                <span class="abstract-full" style="display: none;">The advent of foundation models, particularly Vision-Language Models (VLMs) and Multi-modal Large Language Models (MLLMs), has redefined the frontiers of artificial intelligence, enabling remarkable generalization across diverse tasks with minimal or no supervision. Yet, their potential in biometric recognition and analysis remains relatively underexplored. In this work, we introduce a comprehensive benchmark that evaluates the zero-shot and few-shot performance of state-of-the-art publicly available VLMs and MLLMs across six biometric tasks spanning the face and iris modalities: face verification, soft biometric attribute prediction (gender and race), iris recognition, presentation attack detection (PAD), and face manipulation detection (morphs and deepfakes). A total of 41 VLMs were used in this evaluation. Experiments show that embeddings from these foundation models can be used for diverse biometric tasks with varying degrees of success. For example, in the case of face verification, a True Match Rate (TMR) of 96.77 percent was obtained at a False Match Rate (FMR) of 1 percent on the Labeled Face in the Wild (LFW) dataset, without any fine-tuning. In the case of iris recognition, the TMR at 1 percent FMR on the IITD-R-Full dataset was 97.55 percent without any fine-tuning. Further, we show that applying a simple classifier head to these embeddings can help perform DeepFake detection for faces, Presentation Attack Detection (PAD) for irides, and extract soft biometric attributes like gender and ethnicity from faces with reasonably high accuracy. This work reiterates the potential of pretrained models in achieving the long-term vision of Artificial General Intelligence.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.3%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.3%">
                            Medicine
                        </span>
                <!-- Federated Learning: 2.6 -->
                    
                <!-- Computer Vision: 2.1 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Datasets: 1.8 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.5334
                </span>
                <a href="https://arxiv.org/abs/2505.24249" target="_blank" rel="noopener noreferrer">Harnessing Foundation Models for Robust and Generalizable 6-DOF Bronchoscopy Localization</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Qingyao Tian, Huai Liao, Xinyan Huang, Bingyu Yang, Hongbin Liu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Vision-based 6-DOF bronchoscopy localization offers a promising solution for accurate and cost-effective interventional guidance. However, existing methods struggle with 1) limited generalization across patient cases due to scarce labeled data, and 2) poor robustness under visual degradation, as bro</span>
                
                <span class="abstract-full" style="display: none;">Vision-based 6-DOF bronchoscopy localization offers a promising solution for accurate and cost-effective interventional guidance. However, existing methods struggle with 1) limited generalization across patient cases due to scarce labeled data, and 2) poor robustness under visual degradation, as bronchoscopy procedures frequently involve artifacts such as occlusions and motion blur that impair visual information. To address these challenges, we propose PANSv2, a generalizable and robust bronchoscopy localization framework. Motivated by PANS that leverages multiple visual cues for pose likelihood measurement, PANSv2 integrates depth estimation, landmark detection, and centerline constraints into a unified pose optimization framework that evaluates pose probability and solves for the optimal bronchoscope pose. To further enhance generalization capabilities, we leverage the endoscopic foundation model EndoOmni for depth estimation and the video foundation model EndoMamba for landmark detection, incorporating both spatial and temporal analyses. Pretrained on diverse endoscopic datasets, these models provide stable and transferable visual representations, enabling reliable performance across varied bronchoscopy scenarios. Additionally, to improve robustness to visual degradation, we introduce an automatic re-initialization module that detects tracking failures and re-establishes pose using landmark detections once clear views are available. Experimental results on bronchoscopy dataset encompassing 10 patient cases show that PANSv2 achieves the highest tracking success rate, with an 18.1% improvement in SR-5 (percentage of absolute trajectory error under 5 mm) compared to existing methods, showing potential towards real clinical usage.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 11.0%">
                            Medicine
                        </span>
                <!-- LLMs: 4.5 -->
                    
                <!-- Computer Vision: 3.7 -->
                    
                <!-- 3D: 2.2 -->
                    
                <!-- HPO and AutoML: 1.8 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.5932
                </span>
                <a href="https://arxiv.org/abs/2502.09263" target="_blank" rel="noopener noreferrer">Can Classic GNNs Be Strong Baselines for Graph-level Tasks? Simple Architectures Meet Excellence</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yuankai Luo, Lei Shi, Xiao-Ming Wu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Message-passing Graph Neural Networks (GNNs) are often criticized for their limited expressiveness, issues like over-smoothing and over-squashing, and challenges in capturing long-range dependencies. Conversely, Graph Transformers (GTs) are regarded as superior due to their employment of global atte</span>
                
                <span class="abstract-full" style="display: none;">Message-passing Graph Neural Networks (GNNs) are often criticized for their limited expressiveness, issues like over-smoothing and over-squashing, and challenges in capturing long-range dependencies. Conversely, Graph Transformers (GTs) are regarded as superior due to their employment of global attention mechanisms, which potentially mitigate these challenges. Literature frequently suggests that GTs outperform GNNs in graph-level tasks, especially for graph classification and regression on small molecular graphs. In this study, we explore the untapped potential of GNNs through an enhanced framework, GNN+, which integrates six widely used techniques: edge feature integration, normalization, dropout, residual connections, feed-forward networks, and positional encoding, to effectively tackle graph-level tasks. We conduct a systematic re-evaluation of three classic GNNs (GCN, GIN, and GatedGCN) enhanced by the GNN+ framework across 14 well-known graph-level datasets. Our results reveal that, contrary to prevailing beliefs, these classic GNNs consistently match or surpass the performance of GTs, securing top-three rankings across all datasets and achieving first place in eight. Furthermore, they demonstrate greater efficiency, running several times faster than GTs on many datasets. This highlights the potential of simple GNN architectures, challenging the notion that complex mechanisms in GTs are essential for superior graph-level performance. Our source code is available at https://github.com/LUOyk1999/GNNPlus.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #b243cd" title="Confidence: 6.1%">
                            GNN
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.1%">
                            LLMs
                        </span>
                <!-- Medicine: 2.9 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Blockchain: 2.0 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.6085
                </span>
                <a href="https://arxiv.org/abs/2505.23984" target="_blank" rel="noopener noreferrer">Improved Accuracy in Pelvic Tumor Resections Using a Real-Time Vision-Guided Surgical System</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Vahid Danesh, Paul Arauz, Maede Boroji, Andrew Zhu, Mia Cottone, Elaine Gould, Fazel A. Khan, Imin Kao
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Pelvic bone tumor resections remain significantly challenging due to complex three-dimensional anatomy and limited surgical visualization. Current navigation systems and patient-specific instruments, while accurate, present limitations including high costs, radiation exposure, workflow disruption, l</span>
                
                <span class="abstract-full" style="display: none;">Pelvic bone tumor resections remain significantly challenging due to complex three-dimensional anatomy and limited surgical visualization. Current navigation systems and patient-specific instruments, while accurate, present limitations including high costs, radiation exposure, workflow disruption, long production time, and lack of reusability. This study evaluates a real-time vision-guided surgical system combined with modular jigs to improve accuracy in pelvic bone tumor resections. A vision-guided surgical system combined with modular cutting jigs and real-time optical tracking was developed and validated. Five female pelvis sawbones were used, with each hemipelvis randomly assigned to either the vision-guided and modular jig system or traditional freehand method. A total of twenty resection planes were analyzed for each method. Accuracy was assessed by measuring distance and angular deviations from the planned resection planes. The vision-guided and modular jig system significantly improved resection accuracy compared to the freehand method, reducing the mean distance deviation from 2.07 $\pm$ 1.71 mm to 1.01 $\pm$ 0.78 mm (p=0.0193). In particular, all specimens resected using the vision-guided system exhibited errors of less than 3 mm. Angular deviations also showed significant improvements with roll angle deviation reduced from 15.36 $\pm$ 17.57$^\circ$ to 4.21 $\pm$ 3.46$^\circ$ (p=0.0275), and pitch angle deviation decreased from 6.17 $\pm$ 4.58$^\circ$ to 1.84 $\pm$ 1.48$^\circ$ (p<0.001). The proposed vision-guided and modular jig system significantly improves the accuracy of pelvic bone tumor resections while maintaining workflow efficiency. This cost-effective solution provides real-time guidance without the need for referencing external monitors, potentially improving surgical outcomes in complex pelvic bone tumor cases.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 12.2%">
                            Medicine
                        </span>
                <!-- LLMs: 4.0 -->
                    
                <!-- Computer Vision: 3.0 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- 3D: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.6091
                </span>
                <a href="https://arxiv.org/abs/2505.24172" target="_blank" rel="noopener noreferrer">Heterogeneous Graph Masked Contrastive Learning for Robust Recommendation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Lei Sang, Yu Wang, Yiwen Zhang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Heterogeneous graph neural networks (HGNNs) have demonstrated their superiority in exploiting auxiliary information for recommendation tasks. However, graphs constructed using meta-paths in HGNNs are usually too dense and contain a large number of noise edges. The propagation mechanism of HGNNs prop</span>
                
                <span class="abstract-full" style="display: none;">Heterogeneous graph neural networks (HGNNs) have demonstrated their superiority in exploiting auxiliary information for recommendation tasks. However, graphs constructed using meta-paths in HGNNs are usually too dense and contain a large number of noise edges. The propagation mechanism of HGNNs propagates even small amounts of noise in a graph to distant neighboring nodes, thereby affecting numerous node embeddings. To address this limitation, we introduce a novel model, named Masked Contrastive Learning (MCL), to enhance recommendation robustness to noise. MCL employs a random masking strategy to augment the graph via meta-paths, reducing node sensitivity to specific neighbors and bolstering embedding robustness. Furthermore, MCL employs contrastive cross-view on a Heterogeneous Information Network (HIN) from two perspectives: one-hop neighbors and meta-path neighbors. This approach acquires embeddings capturing both local and high-order structures simultaneously for recommendation. Empirical evaluations on three real-world datasets confirm the superiority of our approach over existing recommendation methods.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #b243cd" title="Confidence: 7.3%">
                            GNN
                        </span>
                <!-- LLMs: 3.8 -->
                    
                <!-- Medicine: 2.8 -->
                    
                <!-- Federated Learning: 2.5 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.6633
                </span>
                <a href="https://arxiv.org/abs/2505.24802" target="_blank" rel="noopener noreferrer">ByzFL: Research Framework for Robust Federated Learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Marc Gonz\'alez, Rachid Guerraoui, Rafael Pinot, Geovani Rizk, John Stephan, Fran\c{c}ois Ta\"iani
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We present ByzFL, an open-source Python library for developing and benchmarking robust federated learning (FL) algorithms. ByzFL provides a unified and extensible framework that includes implementations of state-of-the-art robust aggregators, a suite of configurable attacks, and tools for simulating</span>
                
                <span class="abstract-full" style="display: none;">We present ByzFL, an open-source Python library for developing and benchmarking robust federated learning (FL) algorithms. ByzFL provides a unified and extensible framework that includes implementations of state-of-the-art robust aggregators, a suite of configurable attacks, and tools for simulating a variety of FL scenarios, including heterogeneous data distributions, multiple training algorithms, and adversarial threat models. The library enables systematic experimentation via a single JSON-based configuration file and includes built-in utilities for result visualization. Compatible with PyTorch tensors and NumPy arrays, ByzFL is designed to facilitate reproducible research and rapid prototyping of robust FL solutions. ByzFL is available at https://byzfl.epfl.ch/, with source code hosted on GitHub: https://github.com/LPD-EPFL/byzfl.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 10.7%">
                            Medicine
                        </span>
                <!-- LLMs: 4.8 -->
                    
                <!-- Federated Learning: 2.8 -->
                    
                <!-- Hardware: 2.5 -->
                    
                <!-- Datasets: 2.4 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Computer Vision: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.6898
                </span>
                <a href="https://arxiv.org/abs/2505.23867" target="_blank" rel="noopener noreferrer">Infi-Med: Low-Resource Medical MLLMs with Robust Reasoning Evaluation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zeyu Liu, Zhitian Hou, Yining Di, Kejing Yang, Zhijie Sang, Congkai Xie, Jingwen Yang, Siyuan Liu, Jialu Wang, Chunming Li, Ming Li, Hongxia Yang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Multimodal large language models (MLLMs) have demonstrated promising prospects in healthcare, particularly for addressing complex medical tasks, supporting multidisciplinary treatment (MDT), and enabling personalized precision medicine. However, their practical deployment faces critical challenges i</span>
                
                <span class="abstract-full" style="display: none;">Multimodal large language models (MLLMs) have demonstrated promising prospects in healthcare, particularly for addressing complex medical tasks, supporting multidisciplinary treatment (MDT), and enabling personalized precision medicine. However, their practical deployment faces critical challenges in resource efficiency, diagnostic accuracy, clinical considerations, and ethical privacy. To address these limitations, we propose Infi-Med, a comprehensive framework for medical MLLMs that introduces three key innovations: (1) a resource-efficient approach through curating and constructing high-quality supervised fine-tuning (SFT) datasets with minimal sample requirements, with a forward-looking design that extends to both pretraining and posttraining phases; (2) enhanced multimodal reasoning capabilities for cross-modal integration and clinical task understanding; and (3) a systematic evaluation system that assesses model performance across medical modalities and task types. Our experiments demonstrate that Infi-Med achieves state-of-the-art (SOTA) performance in general medical reasoning while maintaining rapid adaptability to clinical scenarios. The framework establishes a solid foundation for deploying MLLMs in real-world healthcare settings by balancing model effectiveness with operational constraints.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 16.4%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 12.0%">
                            Medicine
                        </span>
                <!-- 3D: 2.6 -->
                    
                <!-- Computer Vision: 2.0 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- T2I: 1.5 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.7745
                </span>
                <a href="https://arxiv.org/abs/2505.24101" target="_blank" rel="noopener noreferrer">A SHAP-based explainable multi-level stacking ensemble learning method for predicting the length of stay in acute stroke</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zhenran Xu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Length of stay (LOS) prediction in acute stroke is critical for improving care planning. Existing machine learning models have shown suboptimal predictive performance, limited generalisability, and have overlooked system-level factors. We aimed to enhance model efficiency, performance, and interpret</span>
                
                <span class="abstract-full" style="display: none;">Length of stay (LOS) prediction in acute stroke is critical for improving care planning. Existing machine learning models have shown suboptimal predictive performance, limited generalisability, and have overlooked system-level factors. We aimed to enhance model efficiency, performance, and interpretability by refining predictors and developing an interpretable multi-level stacking ensemble model. Data were accessed from the biennial Stroke Foundation Acute Audit (2015, 2017, 2019, 2021) in Australia. Models were developed for ischaemic and haemorrhagic stroke separately. The outcome was prolonged LOS (the LOS above the 75th percentile). Candidate predictors (ischaemic: n=89; haemorrhagic: n=83) were categorised into patient, clinical, and system domains. Feature selection with correlation-based approaches was used to refine key predictors. The evaluation of models included discrimination (AUC), calibration curves, and interpretability (SHAP plots). In ischaemic stroke (N=12,575), prolonged LOS was >=9 days, compared to >=11 days in haemorrhagic stroke (N=1,970). The ensemble model achieved superior performance [AUC: 0.824 (95% CI: 0.801-0.846)] and statistically outperformed logistic regression [AUC: 0.805 (95% CI: 0.782-0.829); P=0.0004] for ischaemic. However, the model [AUC: 0.843 (95% CI: 0.790-0.895)] did not statistically outperform logistic regression [AUC: 0.828 (95% CI: 0.774-0.882); P=0.136] for haemorrhagic. SHAP analysis identified shared predictors for both types of stroke: rehabilitation assessment, urinary incontinence, stroke unit care, inability to walk independently, physiotherapy, and stroke care coordinators involvement. An explainable ensemble model effectively predicted the prolonged LOS in ischaemic stroke. Further validation in larger cohorts is needed for haemorrhagic stroke.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 11.8%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.3%">
                            LLMs
                        </span>
                <!-- Computer Vision: 2.9 -->
                    
                <!-- Hardware: 2.3 -->
                    
                <!-- HPO and AutoML: 1.8 -->
                    
                <!-- Decision Trees: 1.8 -->
                    
                <!-- Datasets: 1.7 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.8439
                </span>
                <a href="https://arxiv.org/abs/2412.01506" target="_blank" rel="noopener noreferrer">Structured 3D Latents for Scalable and Versatile 3D Generation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jianfeng Xiang, Zelong Lv, Sicheng Xu, Yu Deng, Ruicheng Wang, Bowen Zhang, Dong Chen, Xin Tong, Jiaolong Yang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We introduce a novel 3D generation method for versatile and high-quality 3D asset creation. The cornerstone is a unified Structured LATent (SLAT) representation which allows decoding to different output formats, such as Radiance Fields, 3D Gaussians, and meshes. This is achieved by integrating a spa</span>
                
                <span class="abstract-full" style="display: none;">We introduce a novel 3D generation method for versatile and high-quality 3D asset creation. The cornerstone is a unified Structured LATent (SLAT) representation which allows decoding to different output formats, such as Radiance Fields, 3D Gaussians, and meshes. This is achieved by integrating a sparsely-populated 3D grid with dense multiview visual features extracted from a powerful vision foundation model, comprehensively capturing both structural (geometry) and textural (appearance) information while maintaining flexibility during decoding. We employ rectified flow transformers tailored for SLAT as our 3D generation models and train models with up to 2 billion parameters on a large 3D asset dataset of 500K diverse objects. Our model generates high-quality results with text or image conditions, significantly surpassing existing methods, including recent ones at similar scales. We showcase flexible output format selection and local 3D editing capabilities which were not offered by previous models. Code, model, and data will be released.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #76aa96" title="Confidence: 12.5%">
                            3D
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 8.3%">
                            Medicine
                        </span>
                <!-- LLMs: 4.8 -->
                    
                <!-- HPO and AutoML: 2.0 -->
                    
                <!-- Datasets: 1.9 -->
                    
                <!-- Computer Vision: 1.9 -->
                    
                <!-- T2I: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- GNN: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.8635
                </span>
                <a href="https://arxiv.org/abs/2505.24085" target="_blank" rel="noopener noreferrer">DeepBoost-AF: A Novel Unsupervised Feature Learning and Gradient Boosting Fusion for Robust Atrial Fibrillation Detection in Raw ECG Signals</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Alireza Jafari, Fereshteh Yousefirizi, Vahid Seydi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Atrial fibrillation (AF) is a prevalent cardiac arrhythmia associated with elevated health risks, where timely detection is pivotal for mitigating stroke-related morbidity. This study introduces an innovative hybrid methodology integrating unsupervised deep learning and gradient boosting models to i</span>
                
                <span class="abstract-full" style="display: none;">Atrial fibrillation (AF) is a prevalent cardiac arrhythmia associated with elevated health risks, where timely detection is pivotal for mitigating stroke-related morbidity. This study introduces an innovative hybrid methodology integrating unsupervised deep learning and gradient boosting models to improve AF detection. A 19-layer deep convolutional autoencoder (DCAE) is coupled with three boosting classifiers-AdaBoost, XGBoost, and LightGBM (LGBM)-to harness their complementary advantages while addressing individual limitations. The proposed framework uniquely combines DCAE with gradient boosting, enabling end-to-end AF identification devoid of manual feature extraction. The DCAE-LGBM model attains an F1-score of 95.20%, sensitivity of 99.99%, and inference latency of four seconds, outperforming existing methods and aligning with clinical deployment requirements. The DCAE integration significantly enhances boosting models, positioning this hybrid system as a reliable tool for automated AF detection in clinical settings.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 13.4%">
                            Medicine
                        </span>
                <!-- LLMs: 5.0 -->
                    
                <!-- HPO and AutoML: 2.6 -->
                    
                <!-- Datasets: 2.5 -->
                    
                <!-- Computer Vision: 2.4 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.9596
                </span>
                <a href="https://arxiv.org/abs/2505.24245" target="_blank" rel="noopener noreferrer">LTM3D: Bridging Token Spaces for Conditional 3D Generation with Auto-Regressive Diffusion Framework</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Xin Kang, Zihan Zheng, Lei Chu, Yue Gao, Jiahao Li, Hao Pan, Xuejin Chen, Yan Lu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We present LTM3D, a Latent Token space Modeling framework for conditional 3D shape generation that integrates the strengths of diffusion and auto-regressive (AR) models. While diffusion-based methods effectively model continuous latent spaces and AR models excel at capturing inter-token dependencies</span>
                
                <span class="abstract-full" style="display: none;">We present LTM3D, a Latent Token space Modeling framework for conditional 3D shape generation that integrates the strengths of diffusion and auto-regressive (AR) models. While diffusion-based methods effectively model continuous latent spaces and AR models excel at capturing inter-token dependencies, combining these paradigms for 3D shape generation remains a challenge. To address this, LTM3D features a Conditional Distribution Modeling backbone, leveraging a masked autoencoder and a diffusion model to enhance token dependency learning. Additionally, we introduce Prefix Learning, which aligns condition tokens with shape latent tokens during generation, improving flexibility across modalities. We further propose a Latent Token Reconstruction module with Reconstruction-Guided Sampling to reduce uncertainty and enhance structural fidelity in generated shapes. Our approach operates in token space, enabling support for multiple 3D representations, including signed distance fields, point clouds, meshes, and 3D Gaussian Splatting. Extensive experiments on image- and text-conditioned shape generation tasks demonstrate that LTM3D outperforms existing methods in prompt fidelity and structural accuracy while offering a generalizable framework for multi-modal, multi-representation 3D generation.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 9.8%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #76aa96" title="Confidence: 9.5%">
                            3D
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.8%">
                            LLMs
                        </span>
                <!-- Computer Vision: 2.1 -->
                    
                <!-- T2I: 1.9 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.2924
                </span>
                <a href="https://arxiv.org/abs/2505.24348" target="_blank" rel="noopener noreferrer">A 3D Mobile Crowdsensing Framework for Sustainable Urban Digital Twins</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Taku Yamazaki (Shibaura Institute of Technology), Kaito Watanabe (Shibaura Institute of Technology), Tatsuya Kase (Shibaura Institute of Technology), Kenta Hasegawa (Shibaura Institute of Technology), Koki Saida (Shibaura Institute of Technology), Takumi Miyoshi (Shibaura Institute of Technology)
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In this article, we propose a 3D mobile crowdsensing (3D-MCS) framework aimed at sustainable urban digital twins (UDTs). The framework comprises four key mechanisms: (1) the 3D-MCS mechanism, consisting of active and passive models; (2) the Geohash-based spatial information management mechanism; (3)</span>
                
                <span class="abstract-full" style="display: none;">In this article, we propose a 3D mobile crowdsensing (3D-MCS) framework aimed at sustainable urban digital twins (UDTs). The framework comprises four key mechanisms: (1) the 3D-MCS mechanism, consisting of active and passive models; (2) the Geohash-based spatial information management mechanism; (3) the dynamic point cloud integration mechanism for UDTs; and (4) the web-based real-time visualizer for 3D-MCS and UDTs. The active sensing model features a gamified 3D-MCS approach, where participants collect point cloud data through an augmented reality territory coloring game. In contrast, the passive sensing model employs a wearable 3D-MCS approach, where participants wear smartphones around their necks without disrupting daily activities. The spatial information management mechanism efficiently partitions the space into regions using Geohash. The dynamic point cloud integration mechanism incorporates point clouds collected by 3D-MCS into UDTs through global and local point cloud registration. Finally, we evaluated the proposed framework through real-world experiments. We verified the effectiveness of the proposed 3D-MCS models from the perspectives of subjective evaluation and data collection and analysis. Furthermore, we analyzed the performance of the dynamic point cloud integration using a dataset.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 13.2%">
                            Medicine
                        </span>
                <!-- Federated Learning: 3.4 -->
                    
                <!-- LLMs: 3.2 -->
                    
                <!-- Hardware: 2.5 -->
                    
                <!-- Bayesian Optimization: 2.3 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- GNN: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.305
                </span>
                <a href="https://arxiv.org/abs/2404.04599" target="_blank" rel="noopener noreferrer">Local Test for Unitarily Invariant Properties of Bipartite Quantum States</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Kean Chen, Qisheng Wang, Zhicheng Zhang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We study the power of local test for bipartite quantum states. Our central result is that, for properties of bipartite pure states, unitary invariance on one part implies an optimal (over all global testers) local tester acting only on the other part. As an application, we show that</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 5.8%">
                            Quantum Computing
                        </span>
                <!-- Medicine: 4.1 -->
                    
                <!-- Federated Learning: 3.6 -->
                    
                <!-- Evolutionary Algorithms: 3.1 -->
                    
                <!-- LLMs: 2.6 -->
                    
                <!-- Bayesian Optimization: 2.3 -->
                    
                <!-- Blockchain: 2.2 -->
                    
                <!-- GNN: 2.1 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Math: 1.5 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.5279
                </span>
                <a href="https://arxiv.org/abs/2410.15432" target="_blank" rel="noopener noreferrer">MedDiff-FM: A Diffusion-based Foundation Model for Versatile Medical Image Applications</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yongrui Yu, Yannian Gu, Shaoting Zhang, Xiaofan Zhang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Diffusion models have achieved significant success in both natural image and medical image domains, encompassing a wide range of applications. Previous investigations in medical images have often been constrained to specific anatomical regions, particular applications, and limited datasets, resultin</span>
                
                <span class="abstract-full" style="display: none;">Diffusion models have achieved significant success in both natural image and medical image domains, encompassing a wide range of applications. Previous investigations in medical images have often been constrained to specific anatomical regions, particular applications, and limited datasets, resulting in isolated diffusion models. This paper introduces a diffusion-based foundation model to address a diverse range of medical image tasks, namely MedDiff-FM. MedDiff-FM leverages 3D CT images from multiple publicly available datasets, covering anatomical regions from head to abdomen, to pre-train a diffusion foundation model, and explores the capabilities of the diffusion foundation model across a variety of application scenarios. The diffusion foundation model handles multi-level integrated image processing both at the image-level and patch-level, utilizes position embedding to establish multi-level spatial relationships, and leverages region classes and anatomical structures to capture certain anatomical regions. MedDiff-FM manages several downstream tasks seamlessly, including image denoising, anomaly detection, and image synthesis. MedDiff-FM is also capable of performing super-resolution, lesion generation, and lesion inpainting by rapidly fine-tuning the diffusion foundation model using ControlNet with task-specific conditions. The experimental results demonstrate the effectiveness of MedDiff-FM in addressing diverse downstream medical image tasks.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 15.1%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.6%">
                            LLMs
                        </span>
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Datasets: 1.7 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- T2I: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.8358
                </span>
                <a href="https://arxiv.org/abs/2505.17677" target="_blank" rel="noopener noreferrer">Towards Dynamic 3D Reconstruction of Hand-Instrument Interaction in Ophthalmic Surgery</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ming Hu, Zhengdi Yu, Feilong Tang, Kaiwen Chen, Yulong Li, Imran Razzak, Junjun He, Tolga Birdal, Kaijing Zhou, Zongyuan Ge
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Accurate 3D reconstruction of hands and instruments is critical for vision-based analysis of ophthalmic microsurgery, yet progress has been hampered by the lack of realistic, large-scale datasets and reliable annotation tools. In this work, we introduce OphNet-3D, the first extensive RGB-D dynamic 3</span>
                
                <span class="abstract-full" style="display: none;">Accurate 3D reconstruction of hands and instruments is critical for vision-based analysis of ophthalmic microsurgery, yet progress has been hampered by the lack of realistic, large-scale datasets and reliable annotation tools. In this work, we introduce OphNet-3D, the first extensive RGB-D dynamic 3D reconstruction dataset for ophthalmic surgery, comprising 41 sequences from 40 surgeons and totaling 7.1 million frames, with fine-grained annotations of 12 surgical phases, 10 instrument categories, dense MANO hand meshes, and full 6-DoF instrument poses. To scalably produce high-fidelity labels, we design a multi-stage automatic annotation pipeline that integrates multi-view data observation, data-driven motion prior with cross-view geometric consistency and biomechanical constraints, along with a combination of collision-aware interaction constraints for instrument interactions. Building upon OphNet-3D, we establish two challenging benchmarks-bimanual hand pose estimation and hand-instrument interaction reconstruction-and propose two dedicated architectures: H-Net for dual-hand mesh recovery and OH-Net for joint reconstruction of two-hand-two-instrument interactions. These models leverage a novel spatial reasoning module with weak-perspective camera modeling and collision-aware center-based representation. Both architectures outperform existing methods by substantial margins, achieving improvements of over 2mm in Mean Per Joint Position Error (MPJPE) and up to 23% in ADD-S metrics for hand and instrument reconstruction, respectively.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 13.8%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.7%">
                            LLMs
                        </span>
                <!-- Datasets: 3.1 -->
                    
                <!-- Hardware: 2.3 -->
                    
                <!-- 3D: 2.2 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.3331
                </span>
                <a href="https://arxiv.org/abs/2406.18354" target="_blank" rel="noopener noreferrer">Kolmogorov-Arnold Graph Neural Networks</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Gianluca De Carlo, Andrea Mastropietro, Aris Anagnostopoulos
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Graph neural networks (GNNs) excel in learning from network-like data but often lack interpretability, making their application challenging in domains requiring transparent decision-making. We propose the Graph Kolmogorov-Arnold Network (GKAN), a novel GNN model leveraging spline-based activation fu</span>
                
                <span class="abstract-full" style="display: none;">Graph neural networks (GNNs) excel in learning from network-like data but often lack interpretability, making their application challenging in domains requiring transparent decision-making. We propose the Graph Kolmogorov-Arnold Network (GKAN), a novel GNN model leveraging spline-based activation functions on edges to enhance both accuracy and interpretability. Our experiments on five benchmark datasets demonstrate that GKAN outperforms state-of-the-art GNN models in node classification, link prediction, and graph classification tasks. In addition to the improved accuracy, GKAN's design inherently provides clear insights into the model's decision-making process, eliminating the need for post-hoc explainability techniques. This paper discusses the methodology, performance, and interpretability of GKAN, highlighting its potential for applications in domains where interpretability is crucial.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #b243cd" title="Confidence: 11.3%">
                            GNN
                        </span>
                <!-- LLMs: 3.7 -->
                    
                <!-- Computer Vision: 3.2 -->
                    
                <!-- Medicine: 3.0 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Decision Trees: 1.8 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                <!-- Datasets: 1.0 -->
                    
                <!-- Bayesian Optimization: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.8284
                </span>
                <a href="https://arxiv.org/abs/2505.24039" target="_blank" rel="noopener noreferrer">Advancing Digital Accessibility: Integrating AR/VR and Health Tech for Inclusive Healthcare Solutions</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Vishnu Ramineni, Shivareddy Devarapalli, Balakrishna Pothineni, Prema Kumar Veerapaneni, Aditya Gupta, Pankaj Gupta
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Modern healthcare domain incorporates a feature of digital accessibility to ensure seamless flow of online services for the patients. However, this feature of digital accessibility poses a challenge particularly for patients with disabilities. To eradicate this issue and provide immersive and user-f</span>
                
                <span class="abstract-full" style="display: none;">Modern healthcare domain incorporates a feature of digital accessibility to ensure seamless flow of online services for the patients. However, this feature of digital accessibility poses a challenge particularly for patients with disabilities. To eradicate this issue and provide immersive and user-friendly experiences, evolving technologies like Augmented Reality (AR) and Virtual Reality (VR) are integrated in medical applications to enhance accessibility. The present research paper aims to study inclusivity and accessibility features of AR/VR in revolutionizing healthcare practices especially in domains like telemedicine, patient education, assistive tools, and rehabilitation for persons with disabilities. The current trends of advancements and case studies are also analyzed to measure the efficacy of AR/VR in healthcare. Moreover, the paper entails a detailed analysis of the challenges of its adoption particularly technical limitations, implementation costs, and regulatory aspects. Finally, the paper concludes with recommendations for integrating AR/VR to foster a more equitable and inclusive healthcare system and provide individuals with auditory, visual, and motor impairments with digital healthcare solutions.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 12.7%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.3%">
                            LLMs
                        </span>
                <!-- Hardware: 2.3 -->
                    
                <!-- Datasets: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.8832
                </span>
                <a href="https://arxiv.org/abs/2505.24780" target="_blank" rel="noopener noreferrer">QGAN-based data augmentation for hybrid quantum-classical neural networks</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Run-Ze He, Jun-Jian Su, Su-Juan Qin, Zheng-Ping Jin, Fei Gao
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Quantum neural networks converge faster and achieve higher accuracy than classical models. However, data augmentation in quantum machine learning remains underexplored. To tackle data scarcity, we integrate quantum generative adversarial networks (QGANs) with hybrid quantum-classical neural networks</span>
                
                <span class="abstract-full" style="display: none;">Quantum neural networks converge faster and achieve higher accuracy than classical models. However, data augmentation in quantum machine learning remains underexplored. To tackle data scarcity, we integrate quantum generative adversarial networks (QGANs) with hybrid quantum-classical neural networks (HQCNNs) to develop an augmentation framework. We propose two strategies: a general approach to enhance data processing and classification across HQCNNs, and a customized strategy that dynamically generates samples tailored to the HQCNN's performance on specific data categories, improving its ability to learn from complex datasets. Simulation experiments on the MNIST dataset demonstrate that QGAN outperforms traditional data augmentation methods and classical GANs. Compared to baseline DCGAN, QGAN achieves comparable performance with half the parameters, balancing efficiency and effectiveness. This suggests that QGANs can simplify models and generate high-quality data, enhancing HQCNN accuracy and performance. These findings pave the way for applying quantum data augmentation techniques in machine learning.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.8%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 5.8%">
                            Quantum Computing
                        </span>
                <!-- Decision Trees: 3.1 -->
                    
                <!-- LLMs: 3.1 -->
                    
                <!-- Computer Vision: 2.7 -->
                    
                <!-- GNN: 2.6 -->
                    
                <!-- HPO and AutoML: 2.3 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -5.6235
                </span>
                <a href="https://arxiv.org/abs/2505.24421" target="_blank" rel="noopener noreferrer">pyMEAL: A Multi-Encoder Augmentation-Aware Learning for Robust and Generalizable Medical Image Translation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Abdul-mojeed Olabisi Ilyas, Adeleke Maradesa, Jamal Banzi, Jianpan Huang, Henry K. F. Mak, Kannie W. Y. Chan
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Medical imaging is critical for diagnostics, but clinical adoption of advanced AI-driven imaging faces challenges due to patient variability, image artifacts, and limited model generalization. While deep learning has transformed image analysis, 3D medical imaging still suffers from data scarcity and</span>
                
                <span class="abstract-full" style="display: none;">Medical imaging is critical for diagnostics, but clinical adoption of advanced AI-driven imaging faces challenges due to patient variability, image artifacts, and limited model generalization. While deep learning has transformed image analysis, 3D medical imaging still suffers from data scarcity and inconsistencies due to acquisition protocols, scanner differences, and patient motion. Traditional augmentation uses a single pipeline for all transformations, disregarding the unique traits of each augmentation and struggling with large data volumes.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 24.4%">
                            Medicine
                        </span>
                <!-- LLMs: 3.7 -->
                    
                <!-- Hardware: 2.8 -->
                    
                <!-- 3D: 2.1 -->
                    
                <!-- Computer Vision: 2.0 -->
                    
                <!-- HPO and AutoML: 1.9 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- GNN: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -5.9899
                </span>
                <a href="https://arxiv.org/abs/2401.14319" target="_blank" rel="noopener noreferrer">A Quantum "Lifting Theorem" for Constructions of Pseudorandom Generators from Random Oracles</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jonathan Katz, Ben Sela
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We study the (quantum) security of pseudorandom generators (PRGs) constructed from random oracles. We prove a "lifting theorem" showing, roughly, that if such a PRG is unconditionally secure against classical adversaries making polynomially many queries to the random oracle, then it is also (uncondi</span>
                
                <span class="abstract-full" style="display: none;">We study the (quantum) security of pseudorandom generators (PRGs) constructed from random oracles. We prove a "lifting theorem" showing, roughly, that if such a PRG is unconditionally secure against classical adversaries making polynomially many queries to the random oracle, then it is also (unconditionally) secure against quantum adversaries in the same sense. As a result of independent interest, we also show that any pseudo-deterministic quantum-oracle algorithm (i.e., a quantum algorithm that with high probability returns the same value on repeated executions) can be simulated by a computationally unbounded but query bounded classical-oracle algorithm with only a polynomial blowup in the number of queries. This implies as a corollary that our lifting theorem holds even for PRGs that themselves make quantum queries to the random oracle.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 10.5%">
                            Quantum Computing
                        </span>
                <!-- Networks: 2.5 -->
                    
                <!-- Federated Learning: 2.3 -->
                    
                <!-- Cryptography: 2.3 -->
                    
                <!-- Math: 2.2 -->
                    
                <!-- LLMs: 2.1 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- Bayesian Optimization: 1.6 -->
                    
                <!-- Game Theory: 1.3 -->
                    
                <!-- Medicine: 1.3 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -6.7226
                </span>
                <a href="https://arxiv.org/abs/2505.23879" target="_blank" rel="noopener noreferrer">CNN-LSTM Hybrid Model for AI-Driven Prediction of COVID-19 Severity from Spike Sequences and Clinical Data</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Caio Cheohen, Vinn\'icius M. S. Gomes, Manuela L. da Silva
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The COVID-19 pandemic, caused by SARS-CoV-2, highlighted the critical need for accurate prediction of disease severity to optimize healthcare resource allocation and patient management. The spike protein, which facilitates viral entry into host cells, exhibits high mutation rates, particularly in th</span>
                
                <span class="abstract-full" style="display: none;">The COVID-19 pandemic, caused by SARS-CoV-2, highlighted the critical need for accurate prediction of disease severity to optimize healthcare resource allocation and patient management. The spike protein, which facilitates viral entry into host cells, exhibits high mutation rates, particularly in the receptor-binding domain, influencing viral pathogenicity. Artificial intelligence approaches, such as deep learning, offer promising solutions for leveraging genomic and clinical data to predict disease outcomes. Objective: This study aimed to develop a hybrid CNN-LSTM deep learning model to predict COVID-19 severity using spike protein sequences and associated clinical metadata from South American patients. Methods: We retrieved 9,570 spike protein sequences from the GISAID database, of which 3,467 met inclusion criteria after standardization. The dataset included 2,313 severe and 1,154 mild cases. A feature engineering pipeline extracted features from sequences, while demographic and clinical variables were one-hot encoded. A hybrid CNN-LSTM architecture was trained, combining CNN layers for local pattern extraction and an LSTM layer for long-term dependency modeling. Results: The model achieved an F1 score of 82.92%, ROC-AUC of 0.9084, precision of 83.56%, and recall of 82.85%, demonstrating robust classification performance. Training stabilized at 85% accuracy with minimal overfitting. The most prevalent lineages (P.1, AY.99.2) and clades (GR, GK) aligned with regional epidemiological trends, suggesting potential associations between viral genetics and clinical outcomes. Conclusion: The CNN-LSTM hybrid model effectively predicted COVID-19 severity using spike protein sequences and clinical data, highlighting the utility of AI in genomic surveillance and precision public health. Despite limitations, this approach provides a framework for early severity prediction in future outbreaks.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 26.9%">
                            Medicine
                        </span>
                <!-- LLMs: 4.2 -->
                    
                <!-- Datasets: 2.9 -->
                    
                <!-- Hardware: 2.6 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- 3D: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -7.6711
                </span>
                <a href="https://arxiv.org/abs/2505.22362" target="_blank" rel="noopener noreferrer">Directed Homophily-Aware Graph Neural Network</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Aihu Zhang, Jiaxing Xu, Mengcheng Lan, Shili Xiang, Yiping Ke
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Graph Neural Networks (GNNs) have achieved significant success in various learning tasks on graph-structured data. Nevertheless, most GNNs struggle to generalize to heterophilic neighborhoods. Additionally, many GNNs ignore the directional nature of real-world graphs, resulting in suboptimal perform</span>
                
                <span class="abstract-full" style="display: none;">Graph Neural Networks (GNNs) have achieved significant success in various learning tasks on graph-structured data. Nevertheless, most GNNs struggle to generalize to heterophilic neighborhoods. Additionally, many GNNs ignore the directional nature of real-world graphs, resulting in suboptimal performance on directed graphs with asymmetric structures. In this work, we propose Directed Homophily-aware Graph Neural Network (DHGNN), a novel framework that addresses these limitations by incorporating homophily-aware and direction-sensitive components. DHGNN employs a resettable gating mechanism to adaptively modulate message contributions based on homophily levels and informativeness, and a structure-aware noise-tolerant fusion module to effectively integrate node representations from the original and reverse directions. Extensive experiments on both homophilic and heterophilic directed graph datasets demonstrate that DHGNN outperforms state-of-the-art methods in node classification and link prediction. In particular, DHGNN improves over the best baseline by up to 15.07% in link prediction. Our analysis further shows that the gating mechanism captures directional homophily gaps and fluctuating homophily across layers, providing deeper insights into message-passing behavior on complex graph structures.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #b243cd" title="Confidence: 18.3%">
                            GNN
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.4%">
                            LLMs
                        </span>
                <!-- Computer Vision: 3.1 -->
                    
                <!-- Medicine: 2.0 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -10.5632
                </span>
                <a href="https://arxiv.org/abs/2505.24309" target="_blank" rel="noopener noreferrer">Supporting Long-term Transactions in Smart Contracts Generated from Business Process Model and Notation (BPMN) Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Christian Gang Liu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">To alleviate difficulties in writing smart contracts for distributed blockchain applications, as other research, we propose transformation of Business Process Model and Notation (BPMN) models into blockchain smart contracts. Unlike other research, we use Discrete Event Hierarchical State Machine (DE</span>
                
                <span class="abstract-full" style="display: none;">To alleviate difficulties in writing smart contracts for distributed blockchain applications, as other research, we propose transformation of Business Process Model and Notation (BPMN) models into blockchain smart contracts. Unlike other research, we use Discrete Event Hierarchical State Machine (DE-HSM) multi-modal modeling to identify collaborative trade transactions that need to be supported by the smart contract and describe how the trade transactions, that may be nested, are supported by a transaction mechanism. We describe algorithms to (i) identify the nested trade transactions and to (ii) transform the BPMN model into blockchains smart contracts that include a transaction mechanism to enforce the transactional properties for the identified trade transactions. The developed proof of concept shows that our approach to automated transformation of BPMN models into smart contracts with the support of privacy and cross-chain interoperability is feasible. The thesis examines and evaluates automatically generated alternative transaction mechanisms to support such transactions using three use cases of varying degree of complexity, namely order processing, supply chain management, and a multi-faceted trade use case. The research enriches the academic dialogue on blockchain technology and smart contracts and proposes potential avenues for future research.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #3cc377" title="Confidence: 7.7%">
                            Blockchain
                        </span>
                <!-- Medicine: 4.1 -->
                    
                <!-- LLMs: 3.9 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -14.7453
                </span>
                <a href="https://arxiv.org/abs/2505.24765" target="_blank" rel="noopener noreferrer">Supervised Quantum Machine Learning: A Future Outlook from Qubits to Enterprise Applications</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Srikanth Thudumu, Jason Fisher, Hung Du
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Supervised Quantum Machine Learning (QML) represents an intersection of quantum computing and classical machine learning, aiming to use quantum resources to support model training and inference. This paper reviews recent developments in supervised QML, focusing on methods such as variational quantum</span>
                
                <span class="abstract-full" style="display: none;">Supervised Quantum Machine Learning (QML) represents an intersection of quantum computing and classical machine learning, aiming to use quantum resources to support model training and inference. This paper reviews recent developments in supervised QML, focusing on methods such as variational quantum circuits, quantum neural networks, and quantum kernel methods, along with hybrid quantum-classical workflows. We examine recent experimental studies that show partial indications of quantum advantage and describe current limitations including noise, barren plateaus, scalability issues, and the lack of formal proofs of performance improvement over classical methods. The main contribution is a ten-year outlook (2025-2035) that outlines possible developments in supervised QML, including a roadmap describing conditions under which QML may be used in applied research and enterprise systems over the next decade.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 23.9%">
                            Quantum Computing
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.4%">
                            LLMs
                        </span>
                <!-- Medicine: 2.5 -->
                    
                <!-- Blockchain: 2.0 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                <!-- 3D: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -18.013
                </span>
                <a href="https://arxiv.org/abs/2505.23860" target="_blank" rel="noopener noreferrer">Quantum computing and artificial intelligence: status and perspectives</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Giovanni Acampora, Andris Ambainis, Natalia Ares, Leonardo Banchi, Pallavi Bhardwaj, Daniele Binosi, G. Andrew D. Briggs, Tommaso Calarco, Vedran Dunjko, Jens Eisert, Olivier Ezratty, Paul Erker, Federico Fedele, Elies Gil-Fuster, Martin G\"arttner, Mats Granath, Markus Heyl, Iordanis Kerenidis, Matthias Klusch, Anton Frisk Kockum, Richard Kueng, Mario Krenn, J\"org L\"assig, Antonio Macaluso, Sabrina Maniscalco, Florian Marquardt, Kristel Michielsen, Gorka Mu\~noz-Gil, Daniel M\"ussig, Hendrik Poulsen Nautrup, Evert van Nieuwenburg, Roman Orus, J\"org Schmiedmayer, Markus Schmitt, Philipp Slusallek, Filippo Vicentini, Christof Weitenberg, Frank K. Wilhelm
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This white paper discusses and explores the various points of intersection between quantum computing and artificial intelligence (AI). It describes how quantum computing could support the development of innovative AI solutions. It also examines use cases of classical AI that can empower research and</span>
                
                <span class="abstract-full" style="display: none;">This white paper discusses and explores the various points of intersection between quantum computing and artificial intelligence (AI). It describes how quantum computing could support the development of innovative AI solutions. It also examines use cases of classical AI that can empower research and development in quantum technologies, with a focus on quantum computing and quantum sensing. The purpose of this white paper is to provide a long-term research agenda aimed at addressing foundational questions about how AI and quantum computing interact and benefit one another. It concludes with a set of recommendations and challenges, including how to orchestrate the proposed theoretical work, align quantum AI developments with quantum hardware roadmaps, estimate both classical and quantum resources - especially with the goal of mitigating and optimizing energy consumption - advance this emerging hybrid software engineering discipline, and enhance European industrial competitiveness while considering societal implications.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 22.4%">
                            Quantum Computing
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.4%">
                            LLMs
                        </span>
                <!-- Medicine: 4.7 -->
                    
                <!-- Blockchain: 3.0 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Datasets: 1.8 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -22.2108
                </span>
                <a href="https://arxiv.org/abs/2410.10946" target="_blank" rel="noopener noreferrer">Equivalence checking of quantum circuits via intermediary matrix product operator</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Aaron Sander, Lukas Burgholzer, Robert Wille
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">As quantum computing advances, the complexity of quantum circuits is rapidly increasing, driving the need for robust methods to aid in their design. Equivalence checking plays a vital role in identifying errors that may arise during compilation and optimization of these circuits and is a critical st</span>
                
                <span class="abstract-full" style="display: none;">As quantum computing advances, the complexity of quantum circuits is rapidly increasing, driving the need for robust methods to aid in their design. Equivalence checking plays a vital role in identifying errors that may arise during compilation and optimization of these circuits and is a critical step in quantum circuit verification. In this work, we introduce a novel method based on Matrix Product Operators (MPOs) for determining the equivalence of quantum circuits. Our approach contracts tensorized quantum gates from two circuits into an intermediary MPO, exploiting their reversibility to determine their equivalence or non-equivalence. Our results show that this method offers significant scalability improvements over existing methods, with polynomial scaling in circuit width and depth for the practical use cases we explore. We expect that this work sets the new standard for scalable equivalence checking of quantum circuits and will become a crucial tool for the validation of increasingly complex quantum systems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 30.5%">
                            Quantum Computing
                        </span>
                <!-- LLMs: 3.8 -->
                    
                <!-- Evolutionary Algorithms: 3.2 -->
                    
                <!-- Medicine: 2.5 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Computer Vision: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- Hardware: 1.1 -->
                    
                
            </div>
        </div>
        
    </div>
    
    
    <div id="jsonPopup" class="json-popup">
        <pre id="jsonContent"></pre>
        <button onclick="copyJson()">Copy to Clipboard</button>
        <button onclick="closePopup()">Close</button>
    </div>

    <script>
        function extractPaperData(paperElement) {
            const titleElement = paperElement.querySelector('.paper-title a');
            const metaElement = paperElement.querySelector('.paper-meta');
            const abstractElement = paperElement.querySelector('.paper-abstract');
            const tagsElement = paperElement.querySelector('.paper-tags');
            
            // Get the date from the parent date-section header
            const dateSection = paperElement.closest('.date-section');
            const dateText = dateSection.querySelector('.date-header').textContent.trim();
            
            const authorsText = metaElement.textContent.replace('Authors:', '').trim();
            
            const paperData = {
                title: titleElement.textContent,
                url: titleElement.href,
                authors: authorsText.split(',').map(author => author.trim()),
                created: dateText,
                abstract: abstractElement.querySelector('.abstract-full').textContent
            };
            
            return paperData;
        }

        function showJson(paperElement) {
            const popup = document.getElementById('jsonPopup');
            const content = document.getElementById('jsonContent');
            const paperData = extractPaperData(paperElement);
            content.textContent = JSON.stringify(paperData, null, null);
            popup.style.display = 'block';
            document.addEventListener('click', function closePopupOnClick(event) {
                if (!popup.contains(event.target)) {
                    popup.style.display = 'none';
                    document.removeEventListener('click', closePopupOnClick);
                }
            });
        }
        function toggleAbstract(element) {
            const abstract = element.parentElement;
            const short = abstract.querySelector('.abstract-short');
            const full = abstract.querySelector('.abstract-full');
            const lowConfidenceTags = abstract.parentElement.querySelectorAll('.tag-badge.low-confidence');
            
            if (element.textContent === '... more') {
                short.style.display = 'none';
                full.style.display = 'inline';
                element.textContent = ' less';
                lowConfidenceTags.forEach(tag => tag.style.display = 'inline-block');
            } else {
                short.style.display = 'inline';
                full.style.display = 'none';
                element.textContent = '... more';
                lowConfidenceTags.forEach(tag => tag.style.display = 'none');
            }
        }

        function closePopup() {
            document.getElementById('jsonPopup').style.display = 'none';
        }

        function copyJson() {
            const content = document.getElementById('jsonContent').textContent;
            navigator.clipboard.writeText(content).catch(() => {
                // If clipboard API is not available, just show the popup
                alert('Could not copy to clipboard. JSON is displayed in the popup.');
            });
        }

        // Close popup when clicking outside
        window.onclick = function(event) {
            const popup = document.getElementById('jsonPopup');
            if (event.target === popup) {
                popup.style.display = 'none';
            }
        }
    </script>
</body>
</html> 