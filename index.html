<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv Frontpage</title>
    <style>
        body {
            font-family: sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
        }
        .paper {
            margin-bottom: 30px;
            margin-top: 30px;
            padding: 20px;
            border: 1px solid #ddd;
            border-radius: 5px;
        }
        .paper-title {
            font-size: 1.2em;
            font-weight: bold;
            margin-bottom: 10px;
        }
        .paper-meta {
            color: #666;
            font-size: 0.9em;
            margin-bottom: 10px;
        }
        .paper-abstract {
            margin-bottom: 10px;
        }
        .abstract-short {
            display: inline;
        }
        .abstract-full {
            display: none;
        }
        .more-link {
            color: blue;
            cursor: pointer;
            text-decoration: underline;
        }
        .tag-badge {
            display: inline-block;
            padding: 3px 8px;
            margin-right: 5px;
            margin-bottom: 5px;
            border-radius: 3px;
            font-size: 0.8em;
            color: white;
        }
        .tag-badge.high-confidence {
            opacity: 1;
        }
        .tag-badge.low-confidence {
            opacity: 0.6;
            display: none;
        }
        .interestingness-score {
            display: inline-block;
            padding: 3px 8px;
            margin-right: 10px;
            color: white;
            border-radius: 3px;
            font-weight: bold;
        }
        .interestingness-positive {
            background-color: #4CAF50;
        }
        .interestingness-negative {
            background-color: #f44336;
        }
        .last-updated {
            text-align: right;
            color: #666;
            font-size: 0.9em;
            margin-top: 20px;
            margin-bottom: 20px;
        }
        .intro {
            text-align: center;
            max-width: 60em;
            margin: 0 auto;
            color: #888;
        }
        .copy-icon {
            display: inline-block;
            width: 16px;
            height: 16px;
            cursor: pointer;
            margin-left: 5px;
            opacity: 0.5;
        }
        .copy-icon:hover {
            opacity: 1;
        }
        .json-popup {
            display: none;
            position: fixed;
            top: 20px;
            right: 20px;
            background: white;
            padding: 20px;
            border: 1px solid #ddd;
            border-radius: 5px;
            max-width: 500px;
            max-height: 300px;
            overflow: auto;
            box-shadow: 0 0 10px rgba(0,0,0,0.1);
        }
        a {
            color: inherit;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        h1 {
            text-align: center;
        }
        h1 a {
            text-decoration: underline;
        }
    </style>
</head>
<body>
    <h1>
        <a href="https://github.com/DataWraith/arxiv-frontpage">DataWraith's</a> ArXiv Frontpage
    </h1>

    <div class="last-updated">
        Last updated: 2025-04-14
    </div>

    <p class="intro">
        This frontpage is made by scraping ArXiv's computer science RSS feed and tagging papers with a classifier.
    </p>

    <p class="intro">
        Each tag is weighted according to my preferences to compute a paper's <i>interestingness</i> score.
    </p>
    
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -2.4945
            </span>
            <a href="https://arxiv.org/abs/2410.23029" target="_blank" rel="noopener noreferrer">Planning and Learning in Risk-Aware Restless Multi-Arm Bandit Problem</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Nima Akbarzadeh, Yossiri Adulyasak, Erick Delage | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">In restless multi-arm bandits, a central agent is tasked with optimally distributing limited resources across several bandits (arms), with each arm being a Markov decision process. In this work, we generalize the traditional restless multi-arm bandit problem with a risk-neutral objective by incorpor</span>
            
            <span class="abstract-full" style="display: none;">In restless multi-arm bandits, a central agent is tasked with optimally distributing limited resources across several bandits (arms), with each arm being a Markov decision process. In this work, we generalize the traditional restless multi-arm bandit problem with a risk-neutral objective by incorporating risk-awareness. We establish indexability conditions for the case of a risk-aware objective and provide a solution based on Whittle index. In addition, we address the learning problem when the true transition probabilities are unknown by proposing a Thompson sampling approach and show that it achieves bounded regret that scales sublinearly with the number of episodes and quadratically with the number of arms. The efficacy of our method in reducing risk exposure in restless multi-arm bandits is illustrated through a set of numerical experiments in the contexts of machine replacement and patient scheduling applications under both planning and learning setups.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.6 -->
                
            <!-- Medicine: 4.4 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- Math: 2.2 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- SpikingNN: 1.3 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Robotics: 1.1 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- Multi-armed Bandit: 1.0 -->
                
            <!-- HPO and AutoML: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -2.8275
            </span>
            <a href="https://arxiv.org/abs/2405.15172" target="_blank" rel="noopener noreferrer">Learning the Distribution Map in Reverse Causal Performative Prediction</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Daniele Bracale, Subha Maity, Moulinath Banerjee, Yuekai Sun | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">In numerous predictive scenarios, the predictive model affects the sampling distribution; for example, job applicants often meticulously craft their resumes to navigate through a screening systems. Such shifts in distribution are particularly prevalent in the realm of social computing, yet, the stra</span>
            
            <span class="abstract-full" style="display: none;">In numerous predictive scenarios, the predictive model affects the sampling distribution; for example, job applicants often meticulously craft their resumes to navigate through a screening systems. Such shifts in distribution are particularly prevalent in the realm of social computing, yet, the strategies to learn these shifts from data remain remarkably limited. Inspired by a microeconomic model that adeptly characterizes agents' behavior within labor markets, we introduce a novel approach to learn the distribution shift. Our method is predicated on a reverse causal model, wherein the predictive model instigates a distribution shift exclusively through a finite set of agents' actions. Within this framework, we employ a microfoundation model for the agents' actions and develop a statistically justified methodology to learn the distribution shift map, which we demonstrate to be effective in minimizing the performative prediction risk.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.3 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- Quantum Computing: 3.3 -->
                
            <!-- Reinforcement Learning: 2.3 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Federated Learning: 1.7 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Robotics: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- Multi-armed Bandit: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.1104
            </span>
            <a href="https://arxiv.org/abs/2504.08550" target="_blank" rel="noopener noreferrer">Proxy-Anchor and EVT-Driven Continual Learning Method for Generalized Category Discovery</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Alireza Fathalizadeh, Roozbeh Razavi-Far | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Continual generalized category discovery has been introduced and studied in the literature as a method that aims to continuously discover and learn novel categories in incoming data batches while avoiding catastrophic forgetting of previously learned categories. A key component in addressing this ch</span>
            
            <span class="abstract-full" style="display: none;">Continual generalized category discovery has been introduced and studied in the literature as a method that aims to continuously discover and learn novel categories in incoming data batches while avoiding catastrophic forgetting of previously learned categories. A key component in addressing this challenge is the model's ability to separate novel samples, where Extreme Value Theory (EVT) has been effectively employed. In this work, we propose a novel method that integrates EVT with proxy anchors to define boundaries around proxies using a probability of inclusion function, enabling the rejection of unknown samples. Additionally, we introduce a novel EVT-based loss function to enhance the learned representation, achieving superior performance compared to other deep-metric learning methods in similar settings. Using the derived probability functions, novel samples are effectively separated from previously known categories. However, category discovery within these novel samples can sometimes overestimate the number of new categories. To mitigate this issue, we propose a novel EVT-based approach to reduce the model size and discard redundant proxies. We also incorporate experience replay and knowledge distillation mechanisms during the continual learning stage to prevent catastrophic forgetting. Experimental results demonstrate that our proposed approach outperforms state-of-the-art methods in continual generalized category discovery scenarios.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.0 -->
                
            <!-- Medicine: 4.8 -->
                
            <!-- Quantum Computing: 3.5 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- Reinforcement Learning: 2.2 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Federated Learning: 1.8 -->
                
            <!-- Math: 1.6 -->
                
            <!-- T2I: 1.5 -->
                
            <!-- Evolutionary Algorithms: 1.3 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- Robotics: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- HPO and AutoML: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.2294
            </span>
            <a href="https://arxiv.org/abs/2504.08098" target="_blank" rel="noopener noreferrer">Semicontinuity bounds for the von Neumann entropy and partial majorization</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: M. E. Shirokov | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We consider families of tight upper bounds on the difference $S(\rho)-S(\sigma)$ with the rank/energy constraint imposed on the state $\rho$ which are valid provided that the state $\rho$ partially majorizes the state $\sigma$ and is close to the state $\sigma$ w.r.t. the trace norm.</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 5.4 -->
                
            <!-- Quantum Computing: 4.4 -->
                
            <!-- Medicine: 4.2 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- Math: 2.9 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Federated Learning: 1.7 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- Multi-armed Bandit: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Robotics: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.2432
            </span>
            <a href="https://arxiv.org/abs/2504.08552" target="_blank" rel="noopener noreferrer">Towards an Evaluation Framework for Explainable Artificial Intelligence Systems for Health and Well-being</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Esperan\c{c}a Amengual-Alcover, Antoni Jaume-i-Cap\'o, Miquel Mir\'o-Nicolau, Gabriel Moy\`a-Alcover, Antonia Paniza-Fullana | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">The integration of Artificial Intelligence in the development of computer systems presents a new challenge: make intelligent systems explainable to humans. This is especially vital in the field of health and well-being, where transparency in decision support systems enables healthcare professionals </span>
            
            <span class="abstract-full" style="display: none;">The integration of Artificial Intelligence in the development of computer systems presents a new challenge: make intelligent systems explainable to humans. This is especially vital in the field of health and well-being, where transparency in decision support systems enables healthcare professionals to understand and trust automated decisions and predictions. To address this need, tools are required to guide the development of explainable AI systems. In this paper, we introduce an evaluation framework designed to support the development of explainable AI systems for health and well-being. Additionally, we present a case study that illustrates the application of the framework in practice. We believe that our framework can serve as a valuable tool not only for developing explainable AI systems in healthcare but also for any AI system that has a significant impact on individuals.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.8 -->
                
            <!-- Medicine: 5.1 -->
                
            <!-- Quantum Computing: 3.7 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- Math: 2.0 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- GNN: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- Robotics: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- HPO and AutoML: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.3939
            </span>
            <a href="https://arxiv.org/abs/2504.08547" target="_blank" rel="noopener noreferrer">Globally Optimal Data-Association-Free Landmark-Based Localization Using Semidefinite Relaxations</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Vassili Korotkine, Mitchell Cohen, James Richard Forbes | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">This paper proposes a semidefinite relaxation for landmark-based localization with unknown data associations in planar environments. The proposed method simultaneously solves for the optimal robot states and data associations in a globally optimal fashion. Relative position measurements to known lan</span>
            
            <span class="abstract-full" style="display: none;">This paper proposes a semidefinite relaxation for landmark-based localization with unknown data associations in planar environments. The proposed method simultaneously solves for the optimal robot states and data associations in a globally optimal fashion. Relative position measurements to known landmarks are used, but the data association is unknown in tha tthe robot does not know which landmark each measurement is generated from. The relaxation is shown to be tight in a majority of cases for moderate noise levels. The proposed algorithm is compared to local Gauss-Newton baselines initialized at the dead-reckoned trajectory, and is shown to significantly improve convergence to the problem's global optimum in simulation and experiment. Accompanying software and supplementary material may be found at https://github.com/vkorotkine/certifiable_uda_loc .</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.8 -->
                
            <!-- Medicine: 4.5 -->
                
            <!-- Quantum Computing: 4.3 -->
                
            <!-- Networks: 3.6 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Multi-armed Bandit: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.4534
            </span>
            <a href="https://arxiv.org/abs/2411.03976" target="_blank" rel="noopener noreferrer">HRDecoder: High-Resolution Decoder Network for Fundus Image Lesion Segmentation</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Ziyuan Ding, Yixiong Liang, Shichao Kan, Qing Liu | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">High resolution is crucial for precise segmentation in fundus images, yet handling high-resolution inputs incurs considerable GPU memory costs, with diminishing performance gains as overhead increases. To address this issue while tackling the challenge of segmenting tiny objects, recent studies have</span>
            
            <span class="abstract-full" style="display: none;">High resolution is crucial for precise segmentation in fundus images, yet handling high-resolution inputs incurs considerable GPU memory costs, with diminishing performance gains as overhead increases. To address this issue while tackling the challenge of segmenting tiny objects, recent studies have explored local-global fusion methods. These methods preserve fine details using local regions and capture long-range context information from downscaled global images. However, the necessity of multiple forward passes inevitably incurs significant computational overhead, adversely affecting inference speed. In this paper, we propose HRDecoder, a simple High-Resolution Decoder network for fundus lesion segmentation. It integrates a high-resolution representation learning module to capture fine-grained local features and a high-resolution fusion module to fuse multi-scale predictions. Our method effectively improves the overall segmentation accuracy of fundus lesions while consuming reasonable memory and computational overhead, and maintaining satisfying inference speed. Experimental results on the IDRiD and DDR datasets demonstrate the effectiveness of our method. Code is available at https://github.com/CVIU-CSU/HRDecoder.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.4 -->
                
            <!-- Medicine: 5.0 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 2.8 -->
                
            <!-- GNN: 2.2 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Federated Learning: 1.7 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Robotics: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- HPO and AutoML: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.4674
            </span>
            <a href="https://arxiv.org/abs/2504.07994" target="_blank" rel="noopener noreferrer">Evaluating the Fitness of Ontologies for the Task of Question Generation</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Samah Alkhuzaey, Floriana Grasso, Terry R. Payne, Valentina Tamma | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Ontology-based question generation is an important application of semantic-aware systems that enables the creation of large question banks for diverse learning environments. The effectiveness of these systems, both in terms of the calibre and cognitive difficulty of the resulting questions, depends </span>
            
            <span class="abstract-full" style="display: none;">Ontology-based question generation is an important application of semantic-aware systems that enables the creation of large question banks for diverse learning environments. The effectiveness of these systems, both in terms of the calibre and cognitive difficulty of the resulting questions, depends heavily on the quality and modelling approach of the underlying ontologies, making it crucial to assess their fitness for this task. To date, there has been no comprehensive investigation into the specific ontology aspects or characteristics that affect the question generation process. Therefore, this paper proposes a set of requirements and task-specific metrics for evaluating the fitness of ontologies for question generation tasks in pedagogical settings. Using the ROMEO methodology, a structured framework for deriving task-specific metrics, an expert-based approach is employed to assess the performance of various ontologies in Automatic Question Generation (AQG) tasks, which is then evaluated over a set of ontologies. Our results demonstrate that ontology characteristics significantly impact the effectiveness of question generation, with different ontologies exhibiting varying performance levels. This highlights the importance of assessing ontology quality with respect to AQG tasks.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.2 -->
                
            <!-- Quantum Computing: 4.6 -->
                
            <!-- Medicine: 4.5 -->
                
            <!-- Networks: 3.0 -->
                
            <!-- Math: 2.5 -->
                
            <!-- Reinforcement Learning: 2.2 -->
                
            <!-- GNN: 1.5 -->
                
            <!-- Pathfinding: 1.3 -->
                
            <!-- Federated Learning: 1.3 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Robotics: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- HPO and AutoML: 1.1 -->
                
            <!-- Hardware: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.483
            </span>
            <a href="https://arxiv.org/abs/2408.11278" target="_blank" rel="noopener noreferrer">The Key of Parameter Skew in Federated Learning</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Junfeng Liao, Sifan Wang, Ye Yuan, Riquan Zhang | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Federated Learning (FL) has emerged as an excellent solution for performing deep learning on different data owners without exchanging raw data. However, statistical heterogeneity in FL presents a key challenge, leading to a phenomenon of skewness in local model parameter distributions that researche</span>
            
            <span class="abstract-full" style="display: none;">Federated Learning (FL) has emerged as an excellent solution for performing deep learning on different data owners without exchanging raw data. However, statistical heterogeneity in FL presents a key challenge, leading to a phenomenon of skewness in local model parameter distributions that researchers have largely overlooked. In this work, we propose the concept of parameter skew to describe the phenomenon that can substantially affect the accuracy of global model parameter estimation. Additionally, we introduce FedSA, an aggregation strategy to obtain a high-quality global model, to address the implication from parameter skew. Specifically, we categorize parameters into high-dispersion and low-dispersion groups based on the coefficient of variation. For high-dispersion parameters, Micro-Classes (MIC) and Macro-Classes (MAC) represent the dispersion at the micro and macro levels, respectively, forming the foundation of FedSA. To evaluate the effectiveness of FedSA, we conduct extensive experiments with different FL algorithms on three computer vision datasets. FedSA outperforms eight state-of-the-art baselines by about 4.7% in test accuracy.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.8 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 4.4 -->
                
            <!-- Networks: 2.9 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.9 -->
                
            <!-- GNN: 1.7 -->
                
            <!-- Federated Learning: 1.7 -->
                
            <!-- Evolutionary Algorithms: 1.3 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- Pathfinding: 1.3 -->
                
            <!-- SpikingNN: 1.3 -->
                
            <!-- Robotics: 1.1 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- HPO and AutoML: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.5084
            </span>
            <a href="https://arxiv.org/abs/2504.08249" target="_blank" rel="noopener noreferrer">Neural Network-assisted Interval Reachability for Systems with Control Barrier Function-Based Safe Controllers</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Damola Ajeyemi, Saber Jafarpour, Emiliano Dall'Anese | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Control Barrier Functions (CBFs) have been widely utilized in the design of optimization-based controllers and filters for dynamical systems to ensure forward invariance of a given set of safe states. While CBF-based controllers offer safety guarantees, they can compromise the performance of the sys</span>
            
            <span class="abstract-full" style="display: none;">Control Barrier Functions (CBFs) have been widely utilized in the design of optimization-based controllers and filters for dynamical systems to ensure forward invariance of a given set of safe states. While CBF-based controllers offer safety guarantees, they can compromise the performance of the system, leading to undesirable behaviors such as unbounded trajectories and emergence of locally stable spurious equilibria. Computing reachable sets for systems with CBF-based controllers is an effective approach for runtime performance and stability verification, and can potentially serve as a tool for trajectory re-planning. In this paper, we propose a computationally efficient interval reachability method for performance verification of systems with optimization-based controllers by: (i) approximating the optimization-based controller by a pre-trained neural network to avoid solving optimization problems repeatedly, and (ii) using mixed monotone theory to construct an embedding system that leverages state-of-the-art neural network verification algorithms for bounding the output of the neural network. Results in terms of closeness of solutions of trajectories of the system with the optimization-based controller and the neural network are derived. Using a single trajectory of the embedding system along with our closeness of solutions result, we obtain an over-approximation of the reachable set of the system with optimization-based controllers. Numerical results are presented to corroborate the technical findings.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.7 -->
                
            <!-- Medicine: 4.4 -->
                
            <!-- Quantum Computing: 3.0 -->
                
            <!-- Networks: 2.9 -->
                
            <!-- Math: 2.3 -->
                
            <!-- Reinforcement Learning: 2.2 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- SpikingNN: 1.4 -->
                
            <!-- Robotics: 1.3 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.5625
            </span>
            <a href="https://arxiv.org/abs/2504.04962" target="_blank" rel="noopener noreferrer">A refined operational semantics for FreeCHR</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Sascha Rechenberger, Thom Fr\"uhwirth | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Constraint Handling Rules (CHR) is a rule-based programming language that which is typically embedded into a general-purpose language with a plethora of implementations. However, the existing implementations often re-invent the way to embed CHR, which impedes maintenance and weakens assertions of co</span>
            
            <span class="abstract-full" style="display: none;">Constraint Handling Rules (CHR) is a rule-based programming language that which is typically embedded into a general-purpose language with a plethora of implementations. However, the existing implementations often re-invent the way to embed CHR, which impedes maintenance and weakens assertions of correctness. To formalize and thereby unify the embedding of CHR into arbitrary host languages, we recently introduced the framework FreeCHR and proved it to be a valid representation of classical CHR. Until now, this framework only includes a translation of the very abstract operational semantics of CHR which, due to its abstract nature, introduces several practical issues. In this paper we present a definition of the refined operational semantics for FreeCHR and prove it to be both, a valid concretization of the very abstract semantics of FreeCHR, and an equivalent representation of the refined semantics of CHR. This will establish implementations of FreeCHR as equivalent in behavior and expressiveness to existing implementations of CHR. This is an extended preprint of a paper submitted to the the 41st International Conference on Logic Programming.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.2 -->
                
            <!-- Medicine: 4.1 -->
                
            <!-- Quantum Computing: 3.3 -->
                
            <!-- Networks: 2.6 -->
                
            <!-- Reinforcement Learning: 2.5 -->
                
            <!-- Math: 2.2 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.5631
            </span>
            <a href="https://arxiv.org/abs/2504.08057" target="_blank" rel="noopener noreferrer">Vector Quantized-Elites: Unsupervised and Problem-Agnostic Quality-Diversity Optimization</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Constantinos Tsakonas, Konstantinos Chatzilygeroudis | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Quality-Diversity algorithms have transformed optimization by prioritizing the discovery of diverse, high-performing solutions over a single optimal result. However, traditional Quality-Diversity methods, such as MAP-Elites, rely heavily on predefined behavioral descriptors and complete prior knowle</span>
            
            <span class="abstract-full" style="display: none;">Quality-Diversity algorithms have transformed optimization by prioritizing the discovery of diverse, high-performing solutions over a single optimal result. However, traditional Quality-Diversity methods, such as MAP-Elites, rely heavily on predefined behavioral descriptors and complete prior knowledge of the task to define the behavioral space grid, limiting their flexibility and applicability. In this work, we introduce Vector Quantized-Elites (VQ-Elites), a novel Quality-Diversity algorithm that autonomously constructs a structured behavioral space grid using unsupervised learning, eliminating the need for prior task-specific knowledge. At the core of VQ-Elites is the integration of Vector Quantized Variational Autoencoders, which enables the dynamic learning of behavioral descriptors and the generation of a structured, rather than unstructured, behavioral space grid - a significant advancement over existing unsupervised Quality-Diversity approaches. This design establishes VQ-Elites as a flexible, robust, and task-agnostic optimization framework. To further enhance the performance of unsupervised Quality-Diversity algorithms, we introduce two key components: behavioral space bounding and cooperation mechanisms, which significantly improve convergence and performance. We validate VQ-Elites on robotic arm pose-reaching and mobile robot space-covering tasks. The results demonstrate its ability to efficiently generate diverse, high-quality solutions, emphasizing its adaptability, scalability, robustness to hyperparameters, and potential to extend Quality-Diversity optimization to complex, previously inaccessible domains.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.7 -->
                
            <!-- Medicine: 4.8 -->
                
            <!-- Quantum Computing: 4.3 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- GNN: 1.7 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- SpikingNN: 1.4 -->
                
            <!-- Robotics: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.3 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- HPO and AutoML: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.5719
            </span>
            <a href="https://arxiv.org/abs/2404.10550" target="_blank" rel="noopener noreferrer">Analytical Approximation of the ELBO Gradient in the Context of the Clutter Problem</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Roumen Nikolaev Popov | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We propose an analytical solution for approximating the gradient of the Evidence Lower Bound (ELBO) in variational inference problems where the statistical model is a Bayesian network consisting of observations drawn from a mixture of a Gaussian distribution embedded in unrelated clutter, known as t</span>
            
            <span class="abstract-full" style="display: none;">We propose an analytical solution for approximating the gradient of the Evidence Lower Bound (ELBO) in variational inference problems where the statistical model is a Bayesian network consisting of observations drawn from a mixture of a Gaussian distribution embedded in unrelated clutter, known as the clutter problem. The method employs the reparameterization trick to move the gradient operator inside the expectation and relies on the assumption that, because the likelihood factorizes over the observed data, the variational distribution is generally more compactly supported than the Gaussian distribution in the likelihood factors. This allows efficient local approximation of the individual likelihood factors, which leads to an analytical solution for the integral defining the gradient expectation. We integrate the proposed gradient approximation as the expectation step in an EM (Expectation Maximization) algorithm for maximizing ELBO and test against classical deterministic approaches in Bayesian inference, such as the Laplace approximation, Expectation Propagation and Mean-Field Variational Inference. The proposed method demonstrates good accuracy and rate of convergence together with linear computational complexity.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 5.1 -->
                
            <!-- Medicine: 4.3 -->
                
            <!-- Networks: 3.9 -->
                
            <!-- Quantum Computing: 3.1 -->
                
            <!-- Math: 2.6 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- GNN: 1.6 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- SpikingNN: 1.4 -->
                
            <!-- Pathfinding: 1.4 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.5917
            </span>
            <a href="https://arxiv.org/abs/2504.08716" target="_blank" rel="noopener noreferrer">ModernBERT or DeBERTaV3? Examining Architecture and Data Influence on Transformer Encoder Models Performance</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Wissam Antoun, Beno\^it Sagot, Djam\'e Seddah | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Pretrained transformer-encoder models like DeBERTaV3 and ModernBERT introduce architectural advancements aimed at improving efficiency and performance. Although the authors of ModernBERT report improved performance over DeBERTaV3 on several benchmarks, the lack of disclosed training data and the abs</span>
            
            <span class="abstract-full" style="display: none;">Pretrained transformer-encoder models like DeBERTaV3 and ModernBERT introduce architectural advancements aimed at improving efficiency and performance. Although the authors of ModernBERT report improved performance over DeBERTaV3 on several benchmarks, the lack of disclosed training data and the absence of comparisons using a shared dataset make it difficult to determine whether these gains are due to architectural improvements or differences in training data. In this work, we conduct a controlled study by pretraining ModernBERT on the same dataset as CamemBERTaV2, a DeBERTaV3 French model, isolating the effect of model design. Our results show that the previous model generation remains superior in sample efficiency and overall benchmark performance, with ModernBERT's primary advantage being faster training and inference speed. However, the new proposed model still provides meaningful architectural improvements compared to earlier models such as BERT and RoBERTa. Additionally, we observe that high-quality pre-training data accelerates convergence but does not significantly improve final performance, suggesting potential benchmark saturation. These findings show the importance of disentangling pretraining data from architectural innovations when evaluating transformer models.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 9.5 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 4.4 -->
                
            <!-- Networks: 3.0 -->
                
            <!-- Math: 2.0 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- SpikingNN: 1.3 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- HPO and AutoML: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.6045
            </span>
            <a href="https://arxiv.org/abs/2409.19075" target="_blank" rel="noopener noreferrer">Meta-RTL: Reinforcement-Based Meta-Transfer Learning for Low-Resource Commonsense Reasoning</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Yu Fu, Jie He, Yifan Yang, Qun Liu, Deyi Xiong | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Meta learning has been widely used to exploit rich-resource source tasks to improve the performance of low-resource target tasks. Unfortunately, most existing meta learning approaches treat different source tasks equally, ignoring the relatedness of source tasks to the target task in knowledge trans</span>
            
            <span class="abstract-full" style="display: none;">Meta learning has been widely used to exploit rich-resource source tasks to improve the performance of low-resource target tasks. Unfortunately, most existing meta learning approaches treat different source tasks equally, ignoring the relatedness of source tasks to the target task in knowledge transfer. To mitigate this issue, we propose a reinforcement-based multi-source meta-transfer learning framework (Meta-RTL) for low-resource commonsense reasoning. In this framework, we present a reinforcement-based approach to dynamically estimating source task weights that measure the contribution of the corresponding tasks to the target task in the meta-transfer learning. The differences between the general loss of the meta model and task-specific losses of source-specific temporal meta models on sampled target data are fed into the policy network of the reinforcement learning module as rewards. The policy network is built upon LSTMs that capture long-term dependencies on source task weight estimation across meta learning iterations. We evaluate the proposed Meta-RTL using both BERT and ALBERT as the backbone of the meta model on three commonsense reasoning benchmark datasets. Experimental results demonstrate that Meta-RTL substantially outperforms strong baselines and previous task selection strategies and achieves larger improvements on extremely low-resource settings.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.1 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 3.2 -->
                
            <!-- Networks: 2.8 -->
                
            <!-- Reinforcement Learning: 2.5 -->
                
            <!-- Math: 2.0 -->
                
            <!-- Federated Learning: 1.8 -->
                
            <!-- GNN: 1.7 -->
                
            <!-- SpikingNN: 1.4 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Robotics: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.685
            </span>
            <a href="https://arxiv.org/abs/2504.08525" target="_blank" rel="noopener noreferrer">Task Memory Engine (TME): Enhancing State Awareness for Multi-Step LLM Agent Tasks</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Ye Ye | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Large Language Models (LLMs) are increasingly used as autonomous agents for multi-step tasks. However, most existing frameworks fail to maintain a structured understanding of the task state, often relying on linear prompt concatenation or shallow memory buffers. This leads to brittle performance, fr</span>
            
            <span class="abstract-full" style="display: none;">Large Language Models (LLMs) are increasingly used as autonomous agents for multi-step tasks. However, most existing frameworks fail to maintain a structured understanding of the task state, often relying on linear prompt concatenation or shallow memory buffers. This leads to brittle performance, frequent hallucinations, and poor long-range coherence. In this work, we propose the Task Memory Engine (TME), a lightweight and structured memory module that tracks task execution using a hierarchical Task Memory Tree (TMT). Each node in the tree corresponds to a task step, storing relevant input, output, status, and sub-task relationships. We introduce a prompt synthesis method that dynamically generates LLM prompts based on the active node path, significantly improving execution consistency and contextual grounding. Through case studies and comparative experiments on multi-step agent tasks, we demonstrate that TME leads to better task completion accuracy and more interpretable behavior with minimal implementation overhead. The full implementation of TME is available at https://github.com/biubiutomato/TME-Agent.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 10.6 -->
                
            <!-- Medicine: 4.0 -->
                
            <!-- Quantum Computing: 3.3 -->
                
            <!-- Networks: 3.0 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Robotics: 1.8 -->
                
            <!-- Math: 1.6 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.6886
            </span>
            <a href="https://arxiv.org/abs/2504.08626" target="_blank" rel="noopener noreferrer">Task-conditioned Ensemble of Expert Models for Continuous Learning</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Renu Sharma, Debasmita Pal, Arun Ross | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">One of the major challenges in machine learning is maintaining the accuracy of the deployed model (e.g., a classifier) in a non-stationary environment. The non-stationary environment results in distribution shifts and, consequently, a degradation in accuracy. Continuous learning of the deployed mode</span>
            
            <span class="abstract-full" style="display: none;">One of the major challenges in machine learning is maintaining the accuracy of the deployed model (e.g., a classifier) in a non-stationary environment. The non-stationary environment results in distribution shifts and, consequently, a degradation in accuracy. Continuous learning of the deployed model with new data could be one remedy. However, the question arises as to how we should update the model with new training data so that it retains its accuracy on the old data while adapting to the new data. In this work, we propose a task-conditioned ensemble of models to maintain the performance of the existing model. The method involves an ensemble of expert models based on task membership information. The in-domain models-based on the local outlier concept (different from the expert models) provide task membership information dynamically at run-time to each probe sample. To evaluate the proposed method, we experiment with three setups: the first represents distribution shift between tasks (LivDet-Iris-2017), the second represents distribution shift both between and within tasks (LivDet-Iris-2020), and the third represents disjoint distribution between tasks (Split MNIST). The experiments highlight the benefits of the proposed method. The source code is available at https://github.com/iPRoBe-lab/Continuous_Learning_FE_DM.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.7 -->
                
            <!-- Medicine: 4.1 -->
                
            <!-- Quantum Computing: 3.5 -->
                
            <!-- Networks: 2.8 -->
                
            <!-- Math: 2.2 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- Federated Learning: 1.7 -->
                
            <!-- GNN: 1.7 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- SpikingNN: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.6999
            </span>
            <a href="https://arxiv.org/abs/2408.13880" target="_blank" rel="noopener noreferrer">On classical advice, sampling advise and complexity assumptions for learning separations</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Jordi P\'erez-Guijarro | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">In this paper, we study the relationship between advice in the form of a training set and classical advice. We do this by analyzing the class \textbf{BPP/samp} and certain variants of it. Specifically, our main result demonstrates that \textbf{BPP/samp} is a proper subset of the class \textbf{P/poly</span>
            
            <span class="abstract-full" style="display: none;">In this paper, we study the relationship between advice in the form of a training set and classical advice. We do this by analyzing the class \textbf{BPP/samp} and certain variants of it. Specifically, our main result demonstrates that \textbf{BPP/samp} is a proper subset of the class \textbf{P/poly}. This result remains valid when considering quantum advice and a quantum generalization of the training set. Finally, leveraging the insights gained from these proofs, we identify sufficient and necessary complexity assumptions for the existence of concept classes that exhibit a quantum learning speed-up in the worst-case scenario, i.e., when accurate results are required for all inputs, and in the average-case scenario.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 9.0 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 3.2 -->
                
            <!-- Networks: 3.0 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- Pathfinding: 1.3 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.7214
            </span>
            <a href="https://arxiv.org/abs/2504.08682" target="_blank" rel="noopener noreferrer">Bayesian optimization for mixed variables using an adaptive dimension reduction process: applications to aircraft design</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Paul Saves, Nathalie Bartoli, Youssef Diouane, Thierry Lefebvre, Joseph Morlier, Christophe David, Eric Nguyen Van, S\'ebastien Defoort | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Multidisciplinary design optimization methods aim at adapting numerical optimization techniques to the design of engineering systems involving multiple disciplines. In this context, a large number of mixed continuous, integer and categorical variables might arise during the optimization process and </span>
            
            <span class="abstract-full" style="display: none;">Multidisciplinary design optimization methods aim at adapting numerical optimization techniques to the design of engineering systems involving multiple disciplines. In this context, a large number of mixed continuous, integer and categorical variables might arise during the optimization process and practical applications involve a large number of design variables. Recently, there has been a growing interest in mixed variables constrained Bayesian optimization but most existing approaches severely increase the number of the hyperparameters related to the surrogate model. In this paper, we address this issue by constructing surrogate models using less hyperparameters. The reduction process is based on the partial least squares method. An adaptive procedure for choosing the number of hyperparameters is proposed. The performance of the proposed approach is confirmed on analytical tests as well as two real applications related to aircraft design. A significant improvement is obtained compared to genetic algorithms.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.4 -->
                
            <!-- Medicine: 4.1 -->
                
            <!-- Quantum Computing: 3.5 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- Reinforcement Learning: 2.2 -->
                
            <!-- Math: 2.1 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Federated Learning: 1.7 -->
                
            <!-- Robotics: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.729
            </span>
            <a href="https://arxiv.org/abs/2503.15854" target="_blank" rel="noopener noreferrer">Persistent Stiefel-Whitney Classes of Tangent Bundles</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Dongwoo Gang | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Stiefel-Whitney classes are invariants of the tangent bundle of a smooth manifold, represented as cohomology classes of the base manifold. These classes are essential in obstruction theory, embedding problems, and cobordism theory. In this work, we first reestablish an appropriate notion of vector b</span>
            
            <span class="abstract-full" style="display: none;">Stiefel-Whitney classes are invariants of the tangent bundle of a smooth manifold, represented as cohomology classes of the base manifold. These classes are essential in obstruction theory, embedding problems, and cobordism theory. In this work, we first reestablish an appropriate notion of vector bundles in a persistent setting, allowing characteristic classes to be interpreted through topological data analysis. Next, we propose a concrete algorithm to compute persistent cohomology classes that represent the Stiefel-Whitney classes of the tangent bundle of a smooth manifold. Given a point cloud, we construct a \v{C}ech or alpha filtration. By applying the Wu formula in this setting, we derive a sequence of persistent cohomology classes from the filtration. We show that if the filtration is homotopy equivalent to a smooth manifold, then one of these persistent cohomology classes corresponds to the $k$-th Stiefel-Whitney class of the tangent bundle of that manifold. To demonstrate the effectiveness of our approach, we present experiments on real-world datasets, including applications to complex manifolds, image patches, and molecular conformation space.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.3 -->
                
            <!-- Medicine: 4.5 -->
                
            <!-- Quantum Computing: 3.3 -->
                
            <!-- Networks: 2.7 -->
                
            <!-- Reinforcement Learning: 2.2 -->
                
            <!-- Math: 2.1 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- SpikingNN: 1.4 -->
                
            <!-- Robotics: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.7321
            </span>
            <a href="https://arxiv.org/abs/2503.18236" target="_blank" rel="noopener noreferrer">Research impact evaluation based on effective authorship contribution sensitivity: h-leadership index</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Hardik A. Jain, Rohitash Chandra | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">The evaluation of a researcher's performance has traditionally relied on various bibliometric measures, with the h-index being one of the most prominent. However, the h-index only accounts for the number of citations received in a publication and does not account for other factors such as the number</span>
            
            <span class="abstract-full" style="display: none;">The evaluation of a researcher's performance has traditionally relied on various bibliometric measures, with the h-index being one of the most prominent. However, the h-index only accounts for the number of citations received in a publication and does not account for other factors such as the number of authors or their specific contributions in collaborative works. Therefore, the h-index has been placed on scrutiny as it has motivated academic integrity issues where non-contributing authors get authorship merely for raising their h-index. In this study, we comprehensively evaluate existing metrics in their ability to account for authorship contribution by their position and introduce a novel variant of the h-index, known as the h-leadership index. The h-leadership index aims to advance the fair evaluation of academic contributions in multi-authored publications by giving importance to authorship position beyond the first and last authors, focused by Stanford's ranking of the top 2 \% of world scientists. We assign weighted citations based on a modified complementary unit Gaussian curve, ensuring that the contributions of middle authors are appropriately recognised. We apply the h-leadership index to analyse the top 50 researchers across the Group of 8 (Go8) universities in Australia, demonstrating its potential to provide a more balanced assessment of research performance. We provide open-source software for extending the work further.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.7 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 3.4 -->
                
            <!-- Networks: 3.0 -->
                
            <!-- Math: 2.3 -->
                
            <!-- Reinforcement Learning: 2.2 -->
                
            <!-- GNN: 1.7 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- SpikingNN: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.7329
            </span>
            <a href="https://arxiv.org/abs/2504.08450" target="_blank" rel="noopener noreferrer">Well-Posedness of Discretizations for Fractional Elasto-Plasticity</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Michael Feischl, David Niederkofler, Barbara Wohlmuth | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We consider a fractional plasticity model based on linear isotropic and kinematic hardening as well as a standard von-Mises yield function, where the flow rule is replaced by a Riesz--Caputo fractional derivative. The resulting mathematical model is typically non-local and non-smooth. Our numerical </span>
            
            <span class="abstract-full" style="display: none;">We consider a fractional plasticity model based on linear isotropic and kinematic hardening as well as a standard von-Mises yield function, where the flow rule is replaced by a Riesz--Caputo fractional derivative. The resulting mathematical model is typically non-local and non-smooth. Our numerical algorithm is based on the well-known radial return mapping and exploits that the kernel is finitely supported. We propose explicit and implicit discretizations of the model and show the well-posedness of the explicit in time discretization in combination with a standard finite element approach in space. Our numerical results in 2D and 3D illustrate the performance of the algorithm and the influence of the fractional parameter.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 5.7 -->
                
            <!-- Medicine: 3.9 -->
                
            <!-- Quantum Computing: 3.7 -->
                
            <!-- Networks: 3.0 -->
                
            <!-- Math: 2.8 -->
                
            <!-- Reinforcement Learning: 2.2 -->
                
            <!-- GNN: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- SpikingNN: 1.3 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- T2I: 1.0 -->
                
            <!-- Hardware: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.734
            </span>
            <a href="https://arxiv.org/abs/2504.08667" target="_blank" rel="noopener noreferrer">Faster shortest-path algorithms using the acyclic-connected tree</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Elis Stefansson, Oliver Biggar, Karl H. Johansson | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">This paper gives a fixed-parameter linear algorithm for the single-source shortest path problem (SSSP) on directed graphs. The parameter in question is the nesting width, a measure of the extent to which a graph can be represented as a nested collection of graphs. We present a novel directed graph d</span>
            
            <span class="abstract-full" style="display: none;">This paper gives a fixed-parameter linear algorithm for the single-source shortest path problem (SSSP) on directed graphs. The parameter in question is the nesting width, a measure of the extent to which a graph can be represented as a nested collection of graphs. We present a novel directed graph decomposition called the acyclic-connected tree (A-C tree), which breaks the graph into a recursively nested sequence of strongly connected components in topological order. We prove that the A-C tree is optimal in the sense that its width, the size of the largest nested graph, is equal to the nesting width of the graph. We then provide a linear-time algorithm for constructing the A-C tree of any graph. Finally, we show how the A-C tree allows us to construct a simple variant of Dijkstra's algorithm which achieves a time complexity of $O(e+n\log w)$, where $n$ ($e$) is the number of nodes (arcs) in the graph and $w$ is the nesting width. The idea is to apply the shortest path algorithm separately to each component in the order dictated by the A-C tree. We obtain an asymptotic improvement over Dijkstra's algorithm: when $w=n$, our algorithm reduces to Dijkstra's algorithm, but it is faster when $w \in o(n)$, and linear-time for classes of graphs with bounded width, such as directed acyclic graphs.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 5.4 -->
                
            <!-- Medicine: 4.0 -->
                
            <!-- Quantum Computing: 3.5 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- Math: 2.7 -->
                
            <!-- Reinforcement Learning: 2.2 -->
                
            <!-- GNN: 1.7 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- Pathfinding: 1.4 -->
                
            <!-- SpikingNN: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.75
            </span>
            <a href="https://arxiv.org/abs/2504.07596" target="_blank" rel="noopener noreferrer">Boosting Universal LLM Reward Design through Heuristic Reward Observation Space Evolution</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Zen Kit Heng, Zimeng Zhao, Tianhao Wu, Yuanfei Wang, Mingdong Wu, Yangang Wang, Hao Dong | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Large Language Models (LLMs) are emerging as promising tools for automated reinforcement learning (RL) reward design, owing to their robust capabilities in commonsense reasoning and code generation. By engaging in dialogues with RL agents, LLMs construct a Reward Observation Space (ROS) by selecting</span>
            
            <span class="abstract-full" style="display: none;">Large Language Models (LLMs) are emerging as promising tools for automated reinforcement learning (RL) reward design, owing to their robust capabilities in commonsense reasoning and code generation. By engaging in dialogues with RL agents, LLMs construct a Reward Observation Space (ROS) by selecting relevant environment states and defining their internal operations. However, existing frameworks have not effectively leveraged historical exploration data or manual task descriptions to iteratively evolve this space. In this paper, we propose a novel heuristic framework that enhances LLM-driven reward design by evolving the ROS through a table-based exploration caching mechanism and a text-code reconciliation strategy. Our framework introduces a state execution table, which tracks the historical usage and success rates of environment states, overcoming the Markovian constraint typically found in LLM dialogues and facilitating more effective exploration. Furthermore, we reconcile user-provided task descriptions with expert-defined success criteria using structured prompts, ensuring alignment in reward design objectives. Comprehensive evaluations on benchmark RL tasks demonstrate the effectiveness and stability of the proposed framework. Code and video demos are available at jingjjjjjie.github.io/LLM2Reward.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 11.3 -->
                
            <!-- Medicine: 4.4 -->
                
            <!-- Quantum Computing: 3.3 -->
                
            <!-- Networks: 2.9 -->
                
            <!-- Reinforcement Learning: 2.5 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.7633
            </span>
            <a href="https://arxiv.org/abs/2504.08579" target="_blank" rel="noopener noreferrer">Analysis of the Unscented Transform Controller for Systems with Bounded Nonlinearities</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Siddharth A. Dinkar, Ram Padmanabhan, Anna Clarke, Per-Olof Gutman, Melkior Ornik | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">In this paper, we present an analysis of the Unscented Transform Controller (UTC), a technique to control nonlinear systems motivated as a dual to the Unscented Kalman Filter (UKF). We consider linear, discrete-time systems augmented by a bounded nonlinear function of the state. For such systems, we</span>
            
            <span class="abstract-full" style="display: none;">In this paper, we present an analysis of the Unscented Transform Controller (UTC), a technique to control nonlinear systems motivated as a dual to the Unscented Kalman Filter (UKF). We consider linear, discrete-time systems augmented by a bounded nonlinear function of the state. For such systems, we review 1-step and N-step versions of the UTC. Using a Lyapunov-based analysis, we prove that the states and inputs converge to a bounded ball around the origin, whose radius depends on the bound on the nonlinearity. Using examples of a fighter jet model and a quadcopter, we demonstrate that the UTC achieves satisfactory regulation and tracking performance on these nonlinear models.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.0 -->
                
            <!-- Medicine: 4.1 -->
                
            <!-- Quantum Computing: 3.4 -->
                
            <!-- Networks: 2.8 -->
                
            <!-- Math: 2.6 -->
                
            <!-- Reinforcement Learning: 2.4 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- T2I: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.7912
            </span>
            <a href="https://arxiv.org/abs/2411.14695" target="_blank" rel="noopener noreferrer">Anti-Forgetting Adaptation for Unsupervised Person Re-identification</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Hao Chen, Francois Bremond, Nicu Sebe, Shiliang Zhang | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Regular unsupervised domain adaptive person re-identification (ReID) focuses on adapting a model from a source domain to a fixed target domain. However, an adapted ReID model can hardly retain previously-acquired knowledge and generalize to unseen data. In this paper, we propose a Dual-level Joint A</span>
            
            <span class="abstract-full" style="display: none;">Regular unsupervised domain adaptive person re-identification (ReID) focuses on adapting a model from a source domain to a fixed target domain. However, an adapted ReID model can hardly retain previously-acquired knowledge and generalize to unseen data. In this paper, we propose a Dual-level Joint Adaptation and Anti-forgetting (DJAA) framework, which incrementally adapts a model to new domains without forgetting source domain and each adapted target domain. We explore the possibility of using prototype and instance-level consistency to mitigate the forgetting during the adaptation. Specifically, we store a small number of representative image samples and corresponding cluster prototypes in a memory buffer, which is updated at each adaptation step. With the buffered images and prototypes, we regularize the image-to-image similarity and image-to-prototype similarity to rehearse old knowledge. After the multi-step adaptation, the model is tested on all seen domains and several unseen domains to validate the generalization ability of our method. Extensive experiments demonstrate that our proposed method significantly improves the anti-forgetting, generalization and backward-compatible ability of an unsupervised person ReID model.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.3 -->
                
            <!-- Medicine: 4.4 -->
                
            <!-- Quantum Computing: 3.4 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- Reinforcement Learning: 2.2 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Federated Learning: 1.7 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- T2I: 1.4 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.8102
            </span>
            <a href="https://arxiv.org/abs/2504.08654" target="_blank" rel="noopener noreferrer">The Invisible EgoHand: 3D Hand Forecasting through EgoBody Pose Estimation</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Masashi Hatano, Zhifan Zhu, Hideo Saito, Dima Damen | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Forecasting hand motion and pose from an egocentric perspective is essential for understanding human intention. However, existing methods focus solely on predicting positions without considering articulation, and only when the hands are visible in the field of view. This limitation overlooks the fac</span>
            
            <span class="abstract-full" style="display: none;">Forecasting hand motion and pose from an egocentric perspective is essential for understanding human intention. However, existing methods focus solely on predicting positions without considering articulation, and only when the hands are visible in the field of view. This limitation overlooks the fact that approximate hand positions can still be inferred even when they are outside the camera's view. In this paper, we propose a method to forecast the 3D trajectories and poses of both hands from an egocentric video, both in and out of the field of view. We propose a diffusion-based transformer architecture for Egocentric Hand Forecasting, EgoH4, which takes as input the observation sequence and camera poses, then predicts future 3D motion and poses for both hands of the camera wearer. We leverage full-body pose information, allowing other joints to provide constraints on hand motion. We denoise the hand and body joints along with a visibility predictor for hand joints and a 3D-to-2D reprojection loss that minimizes the error when hands are in-view. We evaluate EgoH4 on the Ego-Exo4D dataset, combining subsets with body and hand annotations. We train on 156K sequences and evaluate on 34K sequences, respectively. EgoH4 improves the performance by 3.4cm and 5.1cm over the baseline in terms of ADE for hand trajectory forecasting and MPJPE for hand pose forecasting. Project page: https://masashi-hatano.github.io/EgoH4/</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.1 -->
                
            <!-- Medicine: 4.4 -->
                
            <!-- Quantum Computing: 3.6 -->
                
            <!-- Networks: 3.0 -->
                
            <!-- Reinforcement Learning: 2.5 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.8192
            </span>
            <a href="https://arxiv.org/abs/2410.05837" target="_blank" rel="noopener noreferrer">A noise-corrected Langevin algorithm and sampling by half-denoising</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Aapo Hyv\"arinen | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">The Langevin algorithm is a classic method for sampling from a given pdf in a real space. In its basic version, it only requires knowledge of the gradient of the log-density, also called the score function. However, in deep learning, it is often easier to learn the so-called "noisy-data score functi</span>
            
            <span class="abstract-full" style="display: none;">The Langevin algorithm is a classic method for sampling from a given pdf in a real space. In its basic version, it only requires knowledge of the gradient of the log-density, also called the score function. However, in deep learning, it is often easier to learn the so-called "noisy-data score function", i.e. the gradient of the log-density of noisy data, more precisely when Gaussian noise is added to the data. Such an estimate is biased and complicates the use of the Langevin method. Here, we propose a noise-corrected version of the Langevin algorithm, where the bias due to noisy data is removed, at least regarding first-order terms. Unlike diffusion models, our algorithm needs to know the noisy score function for one single noise level only. We further propose a simple special case which has an interesting intuitive interpretation of iteratively adding noise the data and then attempting to remove half of that noise.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 5.5 -->
                
            <!-- Medicine: 4.4 -->
                
            <!-- Quantum Computing: 3.7 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- Math: 2.2 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- GNN: 1.5 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- SpikingNN: 1.4 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.8217
            </span>
            <a href="https://arxiv.org/abs/2504.08005" target="_blank" rel="noopener noreferrer">Extremum Seeking Control for Multivariable Maps under Actuator Saturation</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Enzo Ferreira Tomaz Silva, Pedro Henrique Silva Coutinho, Tiago Roux Oliveira, Miroslav Krsti\'c | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">This paper deals with the gradient-based extremum seeking control for multivariable maps under actuator saturation. By exploiting a polytopic embedding of the unknown Hessian, we derive a LMI-based synthesis condition to ensure that the origin of the average closed-loop error system is exponentially</span>
            
            <span class="abstract-full" style="display: none;">This paper deals with the gradient-based extremum seeking control for multivariable maps under actuator saturation. By exploiting a polytopic embedding of the unknown Hessian, we derive a LMI-based synthesis condition to ensure that the origin of the average closed-loop error system is exponentially stable. Then, the convergence of the extremum seeking control system under actuator saturation to the unknown optimal point is proved by employing Lyapunov stability and averaging theories. Numerical simulations illustrate the efficacy of the proposed approach.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.0 -->
                
            <!-- Medicine: 3.9 -->
                
            <!-- Quantum Computing: 3.7 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- Math: 2.4 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Federated Learning: 1.3 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- Hardware: 1.0 -->
                
            <!-- T2I: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.8229
            </span>
            <a href="https://arxiv.org/abs/2504.08608" target="_blank" rel="noopener noreferrer">Discretization Error Analysis of a High Order Unfitted Space-Time Method for moving domain problems</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Fabian Heimann, Christoph Lehrenfeld, Janosch Preu{\ss} | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We present a numerical analysis of a higher order unfitted space-time Finite Element method applied to a convection-diffusion model problem posed on a moving bulk domain. The method uses isoparametric space-time mappings for the geometry approximation of level set domains and has been presented and </span>
            
            <span class="abstract-full" style="display: none;">We present a numerical analysis of a higher order unfitted space-time Finite Element method applied to a convection-diffusion model problem posed on a moving bulk domain. The method uses isoparametric space-time mappings for the geometry approximation of level set domains and has been presented and investigated computationally in [Heimann, Lehrenfeld, Preu{\ss}, SIAM J. Sci. Comp. 45(2), 2023, B139 - B165]. Recently, in [Heimann, Lehrenfeld, IMA J. Numer. Anal., 2025] error bounds for the geometry approximation have been proven. In this paper we prove stability and accuracy including the influence of the geometry approximation.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.2 -->
                
            <!-- Medicine: 4.1 -->
                
            <!-- Quantum Computing: 3.6 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- Math: 2.1 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.8282
            </span>
            <a href="https://arxiv.org/abs/2411.00928" target="_blank" rel="noopener noreferrer">A Bregman firmly nonexpansive proximal operator for baryconvex optimization</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Mastane Achab | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We present a generalization of the proximal operator defined through a convex combination of convex objectives, where the coefficients are updated in a minimax fashion. We prove that this new operator is Bregman firmly nonexpansive with respect to a Bregman divergence that combines Euclidean and inf</span>
            
            <span class="abstract-full" style="display: none;">We present a generalization of the proximal operator defined through a convex combination of convex objectives, where the coefficients are updated in a minimax fashion. We prove that this new operator is Bregman firmly nonexpansive with respect to a Bregman divergence that combines Euclidean and information geometries; and that its fixed points are given by the critical points of a certain nonconvex function. Finally, we derive the associated continuous flows.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.3 -->
                
            <!-- Medicine: 4.1 -->
                
            <!-- Quantum Computing: 3.5 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- Math: 2.3 -->
                
            <!-- Reinforcement Learning: 2.2 -->
                
            <!-- Robotics: 2.0 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.84
            </span>
            <a href="https://arxiv.org/abs/2402.10674" target="_blank" rel="noopener noreferrer">Border subrank via a generalised Hilbert-Mumford criterion</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Benjamin Biaggi, Chia-Yu Chang, Jan Draisma, Filip Rupniewski | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We show that the border subrank of a sufficiently general tensor in $(\mathbb{C}^n)^{\otimes d}$ is $\mathcal{O}(n^{1/(d-1)})$ for $n \to \infty$. Since this matches the growth rate $\Theta(n^{1/(d-1)})$ for the generic (non-border) subrank recently established by Derksen-Makam-Zuiddam, we find that</span>
            
            <span class="abstract-full" style="display: none;">We show that the border subrank of a sufficiently general tensor in $(\mathbb{C}^n)^{\otimes d}$ is $\mathcal{O}(n^{1/(d-1)})$ for $n \to \infty$. Since this matches the growth rate $\Theta(n^{1/(d-1)})$ for the generic (non-border) subrank recently established by Derksen-Makam-Zuiddam, we find that the generic border subrank has the same growth rate. In our proof, we use a generalisation of the Hilbert-Mumford criterion that we believe will be of independent interest.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.4 -->
                
            <!-- Medicine: 4.0 -->
                
            <!-- Quantum Computing: 3.6 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- Math: 2.6 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.8441
            </span>
            <a href="https://arxiv.org/abs/2504.08518" target="_blank" rel="noopener noreferrer">A Complete Formal Specification and Verification of the BESW software control system of the Maeslant Storm Surge Barrier</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Adrian Beers (Eindhoven University of Technology), Jore Booy (Eindhoven University of Technology), Jan Friso Groote (Eindhoven University of Technology), Johan van den Bogaard (Rijkswaterstaat), Mark Bouwman (Rijkswaterstaat) | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">The Maeslant Barrier is a storm surge barrier that protects Rotterdam and its harbour from storm surges in the North Sea. Its software control consists of three major components, one of which is BesW. BesW is responsible for all the movements of the barrier except for pushing and pulling it. In this</span>
            
            <span class="abstract-full" style="display: none;">The Maeslant Barrier is a storm surge barrier that protects Rotterdam and its harbour from storm surges in the North Sea. Its software control consists of three major components, one of which is BesW. BesW is responsible for all the movements of the barrier except for pushing and pulling it. In this document, we report on the complete formal specification of BesW in mCRL2. All its behaviour has been specified, including manual and testing modes. Furthermore, all fault situations have been taken into account. The formalisation allows formal verification of all behavioural properties, formulated in the modal $\mu$-calculus, with the constraints that water levels only have a restricted number of values and not all combinations of failures of pumps and valves are allowed.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.6 -->
                
            <!-- Medicine: 4.3 -->
                
            <!-- Quantum Computing: 3.6 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- Math: 2.1 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.8458
            </span>
            <a href="https://arxiv.org/abs/2504.07968" target="_blank" rel="noopener noreferrer">Sensing for Communication: RIS-Assisted ISAC Coordination Gain Enhancement With Imperfect CSI</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Xiaohui Li, Qi Zhu, Yunpei Chen, Chadi Assi, Yifei Yuan | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Integrated sensing and communication (ISAC) has the potential to facilitate coordination gains from mutual assistance between sensing and communication (S&amp;C), especially sensing-aided communication enhancement (SACE). Reconfigurable intelligent surface (RIS) is another potential technique for ac</span>
            
            <span class="abstract-full" style="display: none;">Integrated sensing and communication (ISAC) has the potential to facilitate coordination gains from mutual assistance between sensing and communication (S&amp;C), especially sensing-aided communication enhancement (SACE). Reconfigurable intelligent surface (RIS) is another potential technique for achieving resource-efficient communication enhancement. Therefore, this paper proposes an innovative RIS-assisted SACE (R-SACE) mechanism with the goal of improving the systemic communication performance of the ISAC system in practical scenarios where the channel status information (CSI) is imperfectly known. In the proposed R-SACE mechanism, a dual-functional base station (BS) provides downlink communication services to both the communication user and the dynamically changing target that is detected using the communication signals. RIS assists in both sensing and communications of the BS. A typical scenario is investigated in which either or both the direct and RIS-assisted reflected communication links are available depending on sensing results. The average systemic throughput (AST) over the entire timeline of the R-SACE mechanism is maximized by jointly optimizing both temporal and spatial resources under the probabilistic constraint and the sensing performance, transmission power, and communication interference constraints. The non-convex probabilistic mixed optimization problem is transformed and then solved by the proposed fixed-point iterative (FPI) algorithm. Simulation results demonstrate that the proposed FPI algorithm and R-SACE mechanism outperform the baseline algorithms and communication enhancement mechanisms in achieving higher systemic communication performance.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.4 -->
                
            <!-- Medicine: 4.3 -->
                
            <!-- Networks: 3.7 -->
                
            <!-- Quantum Computing: 3.5 -->
                
            <!-- Math: 2.4 -->
                
            <!-- Reinforcement Learning: 2.3 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Federated Learning: 1.8 -->
                
            <!-- SpikingNN: 1.3 -->
                
            <!-- Robotics: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- T2I: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.8488
            </span>
            <a href="https://arxiv.org/abs/2504.08148" target="_blank" rel="noopener noreferrer">Orchestrating Agents and Data for Enterprise: A Blueprint Architecture for Compound AI</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Eser Kandogan, Nikita Bhutani, Dan Zhang, Rafael Li Chen, Sairam Gurajada, Estevam Hruschka | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Large language models (LLMs) have gained significant interest in industry due to their impressive capabilities across a wide range of tasks. However, the widespread adoption of LLMs presents several challenges, such as integration into existing applications and infrastructure, utilization of company</span>
            
            <span class="abstract-full" style="display: none;">Large language models (LLMs) have gained significant interest in industry due to their impressive capabilities across a wide range of tasks. However, the widespread adoption of LLMs presents several challenges, such as integration into existing applications and infrastructure, utilization of company proprietary data, models, and APIs, and meeting cost, quality, responsiveness, and other requirements. To address these challenges, there is a notable shift from monolithic models to compound AI systems, with the premise of more powerful, versatile, and reliable applications. However, progress thus far has been piecemeal, with proposals for agentic workflows, programming models, and extended LLM capabilities, without a clear vision of an overall architecture. In this paper, we propose a 'blueprint architecture' for compound AI systems for orchestrating agents and data for enterprise applications. In our proposed architecture the key orchestration concept is 'streams' to coordinate the flow of data and instructions among agents. Existing proprietary models and APIs in the enterprise are mapped to 'agents', defined in an 'agent registry' that serves agent metadata and learned representations for search and planning. Agents can utilize proprietary data through a 'data registry' that similarly registers enterprise data of various modalities. Tying it all together, data and task 'planners' break down, map, and optimize tasks and queries for given quality of service (QoS) requirements such as cost, accuracy, and latency. We illustrate an implementation of the architecture for a use-case in the HR domain and discuss opportunities and challenges for 'agentic AI' in the enterprise.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 11.3 -->
                
            <!-- Medicine: 4.8 -->
                
            <!-- Quantum Computing: 3.4 -->
                
            <!-- Networks: 3.0 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.8506
            </span>
            <a href="https://arxiv.org/abs/2412.16739" target="_blank" rel="noopener noreferrer">UNEM: UNrolled Generalized EM for Transductive Few-Shot Learning</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Long Zhou, Fereshteh Shakeri, Aymen Sadraoui, Mounir Kaaniche, Jean-Christophe Pesquet, Ismail Ben Ayed | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Transductive few-shot learning has recently triggered wide attention in computer vision. Yet, current methods introduce key hyper-parameters, which control the prediction statistics of the test batches, such as the level of class balance, affecting performances significantly. Such hyper-parameters a</span>
            
            <span class="abstract-full" style="display: none;">Transductive few-shot learning has recently triggered wide attention in computer vision. Yet, current methods introduce key hyper-parameters, which control the prediction statistics of the test batches, such as the level of class balance, affecting performances significantly. Such hyper-parameters are empirically grid-searched over validation data, and their configurations may vary substantially with the target dataset and pre-training model, making such empirical searches both sub-optimal and computationally intractable. In this work, we advocate and introduce the unrolling paradigm, also referred to as "learning to optimize", in the context of few-shot learning, thereby learning efficiently and effectively a set of optimized hyper-parameters. Specifically, we unroll a generalization of the ubiquitous Expectation-Maximization (EM) optimizer into a neural network architecture, mapping each of its iterates to a layer and learning a set of key hyper-parameters over validation data. Our unrolling approach covers various statistical feature distributions and pre-training paradigms, including recent foundational vision-language models and standard vision-only classifiers. We report comprehensive experiments, which cover a breadth of fine-grained downstream image classification tasks, showing significant gains brought by the proposed unrolled EM algorithm over iterative variants. The achieved improvements reach up to 10% and 7.5% on vision-only and vision-language benchmarks, respectively.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.4 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 3.5 -->
                
            <!-- Networks: 2.9 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- Math: 1.9 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- SpikingNN: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.8536
            </span>
            <a href="https://arxiv.org/abs/2410.10370" target="_blank" rel="noopener noreferrer">Innovative Thinking, Infinite Humor: Humor Research of Large Language Models through Structured Thought Leaps</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Han Wang, Yilin Zhao, Dian Li, Xiaohan Wang, Gang Liu, Xuguang Lan, Hui Wang | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Humor is previously regarded as a gift exclusive to humans for the following reasons. Humor is a culturally nuanced aspect of human language, presenting challenges for its understanding and generation. Humor generation necessitates a multi-hop reasoning process, with each hop founded on proper ratio</span>
            
            <span class="abstract-full" style="display: none;">Humor is previously regarded as a gift exclusive to humans for the following reasons. Humor is a culturally nuanced aspect of human language, presenting challenges for its understanding and generation. Humor generation necessitates a multi-hop reasoning process, with each hop founded on proper rationales. Although many studies, such as those related to GPT-o1, focus on logical reasoning with reflection and correction, they still fall short in humor generation. Due to the sparsity of the knowledge graph in creative thinking, it is arduous to achieve multi-hop reasoning. Consequently, in this paper, we propose a more robust framework for addressing the humor reasoning task, named LoL. LoL aims to inject external information to mitigate the sparsity of the knowledge graph, thereby enabling multi-hop reasoning. In the first stage of LoL, we put forward an automatic instruction-evolution method to incorporate the deeper and broader thinking processes underlying humor. Judgment-oriented instructions are devised to enhance the model's judgment capability, dynamically supplementing and updating the sparse knowledge graph. Subsequently, through reinforcement learning, the reasoning logic for each online-generated response is extracted using GPT-4o. In this process, external knowledge is re-introduced to aid the model in logical reasoning and the learning of human preferences. Finally, experimental results indicate that the combination of these two processes can enhance both the model's judgment ability and its generative capacity. These findings deepen our comprehension of the creative capabilities of large language models (LLMs) and offer approaches to boost LLMs' creative abilities for cross-domain innovative applications.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 10.4 -->
                
            <!-- Medicine: 4.2 -->
                
            <!-- Quantum Computing: 3.7 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- Math: 1.9 -->
                
            <!-- GNN: 1.7 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- SpikingNN: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.3 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- Robotics: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.8629
            </span>
            <a href="https://arxiv.org/abs/2504.08253" target="_blank" rel="noopener noreferrer">Knowledge Distillation for Underwater Feature Extraction and Matching via GAN-synthesized Images</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Jinghe Yang, Mingming Gong, Ye Pu | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Autonomous Underwater Vehicles (AUVs) play a crucial role in underwater exploration. Vision-based methods offer cost-effective solutions for localization and mapping in the absence of conventional sensors like GPS and LIDAR. However, underwater environments present significant challenges for feature</span>
            
            <span class="abstract-full" style="display: none;">Autonomous Underwater Vehicles (AUVs) play a crucial role in underwater exploration. Vision-based methods offer cost-effective solutions for localization and mapping in the absence of conventional sensors like GPS and LIDAR. However, underwater environments present significant challenges for feature extraction and matching due to image blurring and noise caused by attenuation, scattering, and the interference of \textit{marine snow}. In this paper, we aim to improve the robustness of the feature extraction and matching in the turbid underwater environment using the cross-modal knowledge distillation method that transfers the in-air feature extraction models to underwater settings using synthetic underwater images as the medium. We first propose a novel adaptive GAN-synthesis method to estimate water parameters and underwater noise distribution, to generate environment-specific synthetic underwater images. We then introduce a general knowledge distillation framework compatible with different teacher models. The evaluation of GAN-based synthesis highlights the significance of the new components, i.e. GAN-synthesized noise and forward scattering, in the proposed model. Additionally, the downstream application of feature extraction and matching (VSLAM) on real underwater sequences validates the effectiveness of the transferred model.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.2 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 3.6 -->
                
            <!-- Networks: 3.0 -->
                
            <!-- Math: 2.0 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- GNN: 1.7 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Pathfinding: 1.3 -->
                
            <!-- Robotics: 1.3 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.8663
            </span>
            <a href="https://arxiv.org/abs/2504.08180" target="_blank" rel="noopener noreferrer">A Vulnerability Code Intent Summary Dataset</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Yifan Huang, Weisong Sun, Yubin Qu | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">In the era of Large Language Models (LLMs), the code summarization technique boosts a lot, along with the emergence of many new significant works. However, the potential of code summarization in the Computer Security Area still remains explored. Can we generate a code summary of a code snippet for i</span>
            
            <span class="abstract-full" style="display: none;">In the era of Large Language Models (LLMs), the code summarization technique boosts a lot, along with the emergence of many new significant works. However, the potential of code summarization in the Computer Security Area still remains explored. Can we generate a code summary of a code snippet for its security intention? Thus, this work proposes an innovative large-scale multi-perspective Code Intent Summary Dataset named BADS , aiming to increase the understanding of a given code snippet and reduce the risk in the code developing process. The procedure of establishing a dataset can be divided into four steps: First, we collect samples of codes with known vulnerabilities as well as code generated by AI from multiple sources. Second, we do the data clean and format unification, then do the data combination. Third, we utilize the LLM to automatically Annotate the code snippet. Last, We do the human evaluation to double-check. The dataset contains X code examples which cover Y categories of vulnerability. Our data are from Z open-source projects and CVE entries, and compared to existing work, our dataset not only contains original code but also code function summary and security intent summary, providing context information for research in code security analysis. All information is in CSV format. The contributions of this paper are four-fold: the establishment of a high-quality, multi-perspective Code Intent Summary Dataset; an innovative method in data collection and processing; A new multi-perspective code analysis framework that promotes cross-disciplinary research in the fields of software engineering and cybersecurity; improving the practicality and scalability of the research outcomes by considering the code length limitations in real-world applications. Our dataset and related tools have been publicly released on GitHub.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.5 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 3.6 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- Math: 2.2 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- GNN: 1.7 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Hardware: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.8665
            </span>
            <a href="https://arxiv.org/abs/2412.15279" target="_blank" rel="noopener noreferrer">Functional connectomes of neural networks</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Tananun Songdechakraiwut, Yutong Wu | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">The human brain is a complex system, and understanding its mechanisms has been a long-standing challenge in neuroscience. The study of the functional connectome, which maps the functional connections between different brain regions, has provided valuable insights through various advanced analysis te</span>
            
            <span class="abstract-full" style="display: none;">The human brain is a complex system, and understanding its mechanisms has been a long-standing challenge in neuroscience. The study of the functional connectome, which maps the functional connections between different brain regions, has provided valuable insights through various advanced analysis techniques developed over the years. Similarly, neural networks, inspired by the brain's architecture, have achieved notable success in diverse applications but are often noted for their lack of interpretability. In this paper, we propose a novel approach that bridges neural networks and human brain functions by leveraging brain-inspired techniques. Our approach, grounded in the insights from the functional connectome, offers scalable ways to characterize topology of large neural networks using stable statistical and machine learning techniques. Our empirical analysis demonstrates its capability to enhance the interpretability of neural networks, providing a deeper understanding of their underlying mechanisms.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.2 -->
                
            <!-- Medicine: 4.5 -->
                
            <!-- Quantum Computing: 3.4 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- GNN: 2.2 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- Evolutionary Algorithms: 1.4 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.8703
            </span>
            <a href="https://arxiv.org/abs/2501.01167" target="_blank" rel="noopener noreferrer">Weighted approximate sampling recovery and integration based on B-spline interpolation and quasi-interpolation</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Dinh D\~ung | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We propose novel methods for approximate sampling recovery and integration of functions in the Freud-weighted Sobolev space $W^r_{p,w}(\mathbb{R})$. The approximation error of sampling recovery is measured in the norm of the Freud-weighted Lebesgue space $L_{q,w}(\mathbb{R})$. Namely, we construct e</span>
            
            <span class="abstract-full" style="display: none;">We propose novel methods for approximate sampling recovery and integration of functions in the Freud-weighted Sobolev space $W^r_{p,w}(\mathbb{R})$. The approximation error of sampling recovery is measured in the norm of the Freud-weighted Lebesgue space $L_{q,w}(\mathbb{R})$. Namely, we construct equidistant compact-supported B-spline quasi-interpolation and interpolation sampling algorithms $Q_{\rho,m}$ and $P_{\rho,m}$ which are asymptotically optimal in terms of the sampling $n$-widths $\varrho_n(\boldsymbol{W}^r_{p,w}(\mathbb{R}), L_{q,w}(\mathbb{R}))$ for every pair $p,q \in [1,\infty]$, and prove the right convergence rate of these sampling $n$-widths, where $\boldsymbol{W}^r_{p,w}(\mathbb{R})$ denotes the unit ball in $W^r_{p,w}(\mathbb{R})$. The algorithms $Q_{\rho,m}$ and $P_{\rho,m}$ are based on truncated scaled B-spline quasi-interpolation and interpolation, respectively. We also prove the asymptotical optimality and right convergence rate of the equidistant quadratures generated from $Q_{\rho,m}$ and $P_{\rho,m}$, for Freud-weighted numerical integration of functions in $W^r_{p,w}(\mathbb{R})$.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.9 -->
                
            <!-- Medicine: 4.3 -->
                
            <!-- Quantum Computing: 3.6 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- Math: 2.4 -->
                
            <!-- Reinforcement Learning: 2.2 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- SpikingNN: 1.3 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- T2I: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.8733
            </span>
            <a href="https://arxiv.org/abs/2504.08341" target="_blank" rel="noopener noreferrer">Deep learning-based moment closure for multi-phase computation of semiclassical limit of the Schr\"odinger equation</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Jin Woo Jang, Jae Yong Lee, Liu Liu, Zhenyi Zhu | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We present a deep learning approach for computing multi-phase solutions to the semiclassical limit of the Schr\"odinger equation. Traditional methods require deriving a multi-phase ansatz to close the moment system of the Liouville equation, a process that is often computationally intensive and impr</span>
            
            <span class="abstract-full" style="display: none;">We present a deep learning approach for computing multi-phase solutions to the semiclassical limit of the Schr\"odinger equation. Traditional methods require deriving a multi-phase ansatz to close the moment system of the Liouville equation, a process that is often computationally intensive and impractical. Our method offers an efficient alternative by introducing a novel two-stage neural network framework to close the $2N\times 2N$ moment system, where $N$ represents the number of phases in the solution ansatz. In the first stage, we train neural networks to learn the mapping between higher-order moments and lower-order moments (along with their derivatives). The second stage incorporates physics-informed neural networks (PINNs), where we substitute the learned higher-order moments to systematically close the system. We provide theoretical guarantees for the convergence of both the loss functions and the neural network approximations. Numerical experiments demonstrate the effectiveness of our method for one- and two-dimensional problems with various phase numbers $N$ in the multi-phase solutions. The results confirm the accuracy and computational efficiency of the proposed approach compared to conventional techniques.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.2 -->
                
            <!-- Medicine: 4.5 -->
                
            <!-- Networks: 3.6 -->
                
            <!-- Quantum Computing: 3.5 -->
                
            <!-- Reinforcement Learning: 2.5 -->
                
            <!-- Math: 2.3 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- SpikingNN: 1.6 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Robotics: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.8736
            </span>
            <a href="https://arxiv.org/abs/2504.08372" target="_blank" rel="noopener noreferrer">eST$^2$ Miner -- Process Discovery Based on Firing Partial Orders</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Sabine Folz-Weinstein, Christian Rennert, Lisa Luise Mannel, Robin Bergenthum, Wil van der Aalst | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Process discovery generates process models from event logs. Traditionally, an event log is defined as a multiset of traces, where each trace is a sequence of events. The total order of the events in a sequential trace is typically based on their temporal occurrence. However, real-life processes are </span>
            
            <span class="abstract-full" style="display: none;">Process discovery generates process models from event logs. Traditionally, an event log is defined as a multiset of traces, where each trace is a sequence of events. The total order of the events in a sequential trace is typically based on their temporal occurrence. However, real-life processes are partially ordered by nature. Different activities can occur in different parts of the process and, thus, independently of each other. Therefore, the temporal total order of events does not necessarily reflect their causal order, as also causally unrelated events may be ordered in time. Only partial orders allow to express concurrency, duration, overlap, and uncertainty of events. Consequently, there is a growing need for process mining algorithms that can directly handle partially ordered input. In this paper, we combine two well-established and efficient algorithms, the eST Miner from the process mining community and the Firing LPO algorithm from the Petri net community, to introduce the eST$^2$ Miner. The eST$^2$ Miner is a process discovery algorithm that can directly handle partially ordered input, gives strong formal guarantees, offers good runtime and excellent space complexity, and can, thus, be used in real-life applications.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.3 -->
                
            <!-- Medicine: 4.4 -->
                
            <!-- Quantum Computing: 3.6 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- Reinforcement Learning: 2.2 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.878
            </span>
            <a href="https://arxiv.org/abs/2411.10212" target="_blank" rel="noopener noreferrer">Embedding Byzantine Fault Tolerance into Federated Learning via Consistency Scoring</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Youngjoon Lee, Jinu Gong, Joonhyuk Kang | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Given sufficient data from multiple edge devices, federated learning (FL) enables training a shared model without transmitting private data to a central server. However, FL is generally vulnerable to Byzantine attacks from compromised edge devices, which can significantly degrade the model performan</span>
            
            <span class="abstract-full" style="display: none;">Given sufficient data from multiple edge devices, federated learning (FL) enables training a shared model without transmitting private data to a central server. However, FL is generally vulnerable to Byzantine attacks from compromised edge devices, which can significantly degrade the model performance. In this paper, we propose a intuitive plugin that can be integrated into existing FL techniques to achieve Byzantine-Resilience. Key idea is to generate virtual data samples and evaluate model consistency scores across local updates to effectively filter out compromised edge devices. By utilizing this scoring mechanism before the aggregation phase, the proposed plugin enables existing FL techniques to become robust against Byzantine attacks while maintaining their original benefits. Numerical results on medical image classification task validate that plugging the proposed approach into representative FL algorithms, effectively achieves Byzantine resilience. Furthermore, the proposed plugin maintains the original convergence properties of the base FL algorithms when no Byzantine attacks are present.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.1 -->
                
            <!-- Medicine: 4.3 -->
                
            <!-- Quantum Computing: 3.5 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- Reinforcement Learning: 2.2 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Federated Learning: 1.9 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.8807
            </span>
            <a href="https://arxiv.org/abs/2504.08122" target="_blank" rel="noopener noreferrer">Threading the Needle: Test and Evaluation of Early Stage UAS Capabilities to Autonomously Navigate GPS-Denied Environments in the DARPA Fast Lightweight Autonomy (FLA) Program</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Adam Norton, Holly Yanco | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">The DARPA Fast Lightweight Autonomy (FLA) program (2015 - 2018) served as a significant milestone in the development of UAS, particularly for autonomous navigation through unknown GPS-denied environments. Three performing teams developed UAS using a common hardware platform, focusing their contribut</span>
            
            <span class="abstract-full" style="display: none;">The DARPA Fast Lightweight Autonomy (FLA) program (2015 - 2018) served as a significant milestone in the development of UAS, particularly for autonomous navigation through unknown GPS-denied environments. Three performing teams developed UAS using a common hardware platform, focusing their contributions on autonomy algorithms and sensing. Several experiments were conducted that spanned indoor and outdoor environments, increasing in complexity over time. This paper reviews the testing methodology developed in order to benchmark and compare the performance of each team, each of the FLA Phase 1 experiments that were conducted, and a summary of the Phase 1 results.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.0 -->
                
            <!-- Medicine: 4.5 -->
                
            <!-- Quantum Computing: 3.7 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- Math: 2.1 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- GNN: 1.7 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.8848
            </span>
            <a href="https://arxiv.org/abs/2504.08019" target="_blank" rel="noopener noreferrer">DGFamba: Learning Flow Factorized State Space for Visual Domain Generalization</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Qi Bi, Jingjun Yi, Hao Zheng, Haolan Zhan, Wei Ji, Yawen Huang, Yuexiang Li | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Domain generalization aims to learn a representation from the source domain, which can be generalized to arbitrary unseen target domains. A fundamental challenge for visual domain generalization is the domain gap caused by the dramatic style variation whereas the image content is stable. The realm o</span>
            
            <span class="abstract-full" style="display: none;">Domain generalization aims to learn a representation from the source domain, which can be generalized to arbitrary unseen target domains. A fundamental challenge for visual domain generalization is the domain gap caused by the dramatic style variation whereas the image content is stable. The realm of selective state space, exemplified by VMamba, demonstrates its global receptive field in representing the content. However, the way exploiting the domain-invariant property for selective state space is rarely explored. In this paper, we propose a novel Flow Factorized State Space model, dubbed as DG-Famba, for visual domain generalization. To maintain domain consistency, we innovatively map the style-augmented and the original state embeddings by flow factorization. In this latent flow space, each state embedding from a certain style is specified by a latent probability path. By aligning these probability paths in the latent space, the state embeddings are able to represent the same content distribution regardless of the style differences. Extensive experiments conducted on various visual domain generalization settings show its state-of-the-art performance.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.4 -->
                
            <!-- Medicine: 4.4 -->
                
            <!-- Quantum Computing: 3.5 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- GNN: 2.2 -->
                
            <!-- Math: 2.0 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Federated Learning: 1.7 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.8885
            </span>
            <a href="https://arxiv.org/abs/2504.03120" target="_blank" rel="noopener noreferrer">Distributed Resilience-Aware Control in Multi-Robot Networks</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Haejoon Lee, Dimitra Panagou | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Ensuring resilient consensus in multi-robot systems with misbehaving agents remains a challenge, as many existing network resilience properties are inherently combinatorial and globally defined. While previous works have proposed control laws to enhance or preserve resilience in multi-robot networks</span>
            
            <span class="abstract-full" style="display: none;">Ensuring resilient consensus in multi-robot systems with misbehaving agents remains a challenge, as many existing network resilience properties are inherently combinatorial and globally defined. While previous works have proposed control laws to enhance or preserve resilience in multi-robot networks, they often assume a fixed topology with known resilience properties, or require global state knowledge. These assumptions may be impractical in physically-constrained environments, where safety and resilience requirements are conflicting, or when misbehaving agents corrupt the shared information. In this work, we propose a distributed control law that enables each robot to guarantee resilient consensus and safety during its navigation without fixed topologies using only locally available information. To this end, we establish a new sufficient condition for resilient consensus in time-varying networks based on the degree of non-misbehaving or normal agents. Using this condition, we design a Control Barrier Function (CBF)-based controller that guarantees resilient consensus and collision avoidance without requiring estimates of global state and/or control actions of all other robots. Finally, we validate our method through simulations.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.7 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 3.6 -->
                
            <!-- Networks: 2.9 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Math: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- T2I: 1.4 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.8949
            </span>
            <a href="https://arxiv.org/abs/2412.09404" target="_blank" rel="noopener noreferrer">Opinion de-polarization of social networks with GNNs</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Konstantinos Mylonas, Thrasyvoulos Spyropoulos | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Nowadays, social media is the ground for political debate and exchange of opinions. There is a significant amount of research that suggests that social media are highly polarized. A phenomenon that is commonly observed is the echo chamber structure, where users are organized in polarized communities</span>
            
            <span class="abstract-full" style="display: none;">Nowadays, social media is the ground for political debate and exchange of opinions. There is a significant amount of research that suggests that social media are highly polarized. A phenomenon that is commonly observed is the echo chamber structure, where users are organized in polarized communities and form connections only with similar-minded individuals, limiting themselves to consume specific content. In this paper we explore a way to decrease the polarization of networks with two echo chambers. Particularly, we observe that if some users adopt a moderate opinion about a topic, the polarization of the network decreases. Based on this observation, we propose an efficient algorithm to identify a good set of K users, such that if they adopt a moderate stance around a topic, the polarization is minimized. Our algorithm employs a Graph Neural Network and thus it can handle large graphs more effectively than other approaches</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.4 -->
                
            <!-- Medicine: 4.3 -->
                
            <!-- Quantum Computing: 3.6 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- Reinforcement Learning: 2.2 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.3 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.8953
            </span>
            <a href="https://arxiv.org/abs/2504.07993" target="_blank" rel="noopener noreferrer">Towards Simple Machine Learning Baselines for GNSS RFI Detection</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Viktor Ivanov, Richard C. Wilson, Maurizio Scaramuzza | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Machine learning research in GNSS radio frequency interference (RFI) detection often lacks a proper justification for the decisions made in deep learning-based model architectures. Our paper challenges the status quo in machine learning approaches for GNSS RFI detection, revealing the potentially mi</span>
            
            <span class="abstract-full" style="display: none;">Machine learning research in GNSS radio frequency interference (RFI) detection often lacks a proper justification for the decisions made in deep learning-based model architectures. Our paper challenges the status quo in machine learning approaches for GNSS RFI detection, revealing the potentially misleading track of current research and highlighting alternative directions. Our position advocates for a shift in focus from solely pursuing novel model designs to critically evaluating the utility of complex black box deep learning methods against simpler and more interpretable machine learning baselines. Our findings demonstrate the need for the creation of simple baselines and suggest the need for more exploration and development of simple and interpretable machine learning methods for the detection of GNSS RFIs. The increment of model complexity in the state-of-the-art deep learning-based models often provides very little improvement. Thanks to a unique dataset from Swiss Air Force and Swiss Air-Rescue (Rega), preprocessed by Swiss Air Navigation Services Ltd. (Skyguide), we demonstrate the effectiveness of a simple machine learning baseline for GNSS RFI detection on real-world large-scale aircraft data containing flight recordings impacted by real jamming. The experimental results indicate that our solution successfully detects potential GNSS RFI with 91% accuracy outperforming state-of-the-art deep learning architectures. We believe that our work offers insights and suggestions for the field to move forward.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.2 -->
                
            <!-- Medicine: 6.0 -->
                
            <!-- Quantum Computing: 4.6 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- Math: 2.1 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- GNN: 1.7 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- Evolutionary Algorithms: 1.3 -->
                
            <!-- Robotics: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- HPO and AutoML: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.8973
            </span>
            <a href="https://arxiv.org/abs/2504.08505" target="_blank" rel="noopener noreferrer">POD-Based Sparse Stochastic Estimation of Wind Turbine Blade Vibrations</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Lorenzo Schena, Wim Munters, Jan Helsen, Miguel A. Mendez | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">This study presents a framework for estimating the full vibrational state of wind turbine blades from sparse deflection measurements. The identification is performed in a reduced-order space obtained from a Proper Orthogonal Decomposition (POD) of high-fidelity aeroelastic simulations based on Geome</span>
            
            <span class="abstract-full" style="display: none;">This study presents a framework for estimating the full vibrational state of wind turbine blades from sparse deflection measurements. The identification is performed in a reduced-order space obtained from a Proper Orthogonal Decomposition (POD) of high-fidelity aeroelastic simulations based on Geometrically Exact Beam Theory (GEBT). In this space, a Reduced Order Model (ROM) is constructed using a linear stochastic estimator, and further enhanced through Kalman fusion with a quasi-steady model of azimuthal dynamics driven by measured wind speed. The performance of the proposed estimator is assessed in a synthetic environment replicating turbulent inflow and measurement noise over a wide range of operating conditions. Results demonstrate the method's ability to accurately reconstruct three-dimensional deformations and accelerations using noisy displacement and acceleration measurements at only four spatial locations. These findings highlight the potential of the proposed framework for real-time blade monitoring, optimal sensor placement, and active load control in wind turbine systems.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.3 -->
                
            <!-- Medicine: 4.2 -->
                
            <!-- Networks: 3.9 -->
                
            <!-- Quantum Computing: 3.6 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- Math: 2.1 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Robotics: 1.8 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.9146
            </span>
            <a href="https://arxiv.org/abs/2504.08348" target="_blank" rel="noopener noreferrer">Geometric Consistency Refinement for Single Image Novel View Synthesis via Test-Time Adaptation of Diffusion Models</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Josef Bengtson, David Nilsson, Fredrik Kahl | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Diffusion models for single image novel view synthesis (NVS) can generate highly realistic and plausible images, but they are limited in the geometric consistency to the given relative poses. The generated images often show significant errors with respect to the epipolar constraints that should be f</span>
            
            <span class="abstract-full" style="display: none;">Diffusion models for single image novel view synthesis (NVS) can generate highly realistic and plausible images, but they are limited in the geometric consistency to the given relative poses. The generated images often show significant errors with respect to the epipolar constraints that should be fulfilled, as given by the target pose. In this paper we address this issue by proposing a methodology to improve the geometric correctness of images generated by a diffusion model for single image NVS. We formulate a loss function based on image matching and epipolar constraints, and optimize the starting noise in a diffusion sampling process such that the generated image should both be a realistic image and fulfill geometric constraints derived from the given target pose. Our method does not require training data or fine-tuning of the diffusion models, and we show that we can apply it to multiple state-of-the-art models for single image NVS. The method is evaluated on the MegaScenes dataset and we show that geometric consistency is improved compared to the baseline models while retaining the quality of the generated images.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.2 -->
                
            <!-- Medicine: 4.3 -->
                
            <!-- Quantum Computing: 3.5 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- Math: 2.4 -->
                
            <!-- Reinforcement Learning: 2.2 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Federated Learning: 1.8 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- Robotics: 1.3 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.9154
            </span>
            <a href="https://arxiv.org/abs/2504.08365" target="_blank" rel="noopener noreferrer">Location-Oriented Sound Event Localization and Detection with Spatial Mapping and Regression Localization</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Xueping Zhang, Yaxiong Chen, Ruilin Yao, Yunfei Zi, Shengwu Xiong | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Sound Event Localization and Detection (SELD) combines the Sound Event Detection (SED) with the corresponding Direction Of Arrival (DOA). Recently, adopted event oriented multi-track methods affect the generality in polyphonic environments due to the limitation of the number of tracks. To enhance th</span>
            
            <span class="abstract-full" style="display: none;">Sound Event Localization and Detection (SELD) combines the Sound Event Detection (SED) with the corresponding Direction Of Arrival (DOA). Recently, adopted event oriented multi-track methods affect the generality in polyphonic environments due to the limitation of the number of tracks. To enhance the generality in polyphonic environments, we propose Spatial Mapping and Regression Localization for SELD (SMRL-SELD). SMRL-SELD segments the 3D spatial space, mapping it to a 2D plane, and a new regression localization loss is proposed to help the results converge toward the location of the corresponding event. SMRL-SELD is location-oriented, allowing the model to learn event features based on orientation. Thus, the method enables the model to process polyphonic sounds regardless of the number of overlapping events. We conducted experiments on STARSS23 and STARSS22 datasets and our proposed SMRL-SELD outperforms the existing SELD methods in overall evaluation and polyphony environments.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.4 -->
                
            <!-- Medicine: 4.5 -->
                
            <!-- Quantum Computing: 3.7 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- Math: 2.1 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Federated Learning: 1.7 -->
                
            <!-- GNN: 1.7 -->
                
            <!-- SpikingNN: 1.4 -->
                
            <!-- Pathfinding: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- Robotics: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.917
            </span>
            <a href="https://arxiv.org/abs/2504.08377" target="_blank" rel="noopener noreferrer">Proofs as Explanations: Short Certificates for Reliable Predictions</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Avrim Blum, Steve Hanneke, Chirag Pabbaraju, Donya Saless | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We consider a model for explainable AI in which an explanation for a prediction $h(x)=y$ consists of a subset $S'$ of the training data (if it exists) such that all classifiers $h' \in H$ that make at most $b$ mistakes on $S'$ predict $h'(x)=y$. Such a set $S'$ serves as a proof that $x$ indeed has </span>
            
            <span class="abstract-full" style="display: none;">We consider a model for explainable AI in which an explanation for a prediction $h(x)=y$ consists of a subset $S'$ of the training data (if it exists) such that all classifiers $h' \in H$ that make at most $b$ mistakes on $S'$ predict $h'(x)=y$. Such a set $S'$ serves as a proof that $x$ indeed has label $y$ under the assumption that (1) the target function $h^\star$ belongs to $H$, and (2) the set $S$ contains at most $b$ corrupted points. For example, if $b=0$ and $H$ is the family of linear classifiers in $\mathbb{R}^d$, and if $x$ lies inside the convex hull of the positive data points in $S$ (and hence every consistent linear classifier labels $x$ as positive), then Carath\'eodory's theorem states that $x$ lies inside the convex hull of $d+1$ of those points. So, a set $S'$ of size $d+1$ could be released as an explanation for a positive prediction, and would serve as a short proof of correctness of the prediction under the assumption of realizability.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.1 -->
                
            <!-- Medicine: 4.3 -->
                
            <!-- Quantum Computing: 3.7 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- Math: 2.1 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- SpikingNN: 1.3 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.9359
            </span>
            <a href="https://arxiv.org/abs/2504.08428" target="_blank" rel="noopener noreferrer">Standardization of Weighted Ranking Correlation Coefficients</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Pierangelo Lombardo | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">A relevant problem in statistics is defining the correlation of two rankings of a list of items. Kendall's tau and Spearman's rho are two well established correlation coefficients, characterized by a symmetric form that ensures zero expected value between two pairs of rankings randomly chosen with u</span>
            
            <span class="abstract-full" style="display: none;">A relevant problem in statistics is defining the correlation of two rankings of a list of items. Kendall's tau and Spearman's rho are two well established correlation coefficients, characterized by a symmetric form that ensures zero expected value between two pairs of rankings randomly chosen with uniform probability. However, in recent years, several weighted versions of the original Spearman and Kendall coefficients have emerged that take into account the greater importance of top ranks compared to low ranks, which is common in many contexts. The weighting schemes break the symmetry, causing a non-zero expected value between two random rankings. This issue is very relevant, as it undermines the concept of uncorrelation between rankings. In this paper, we address this problem by proposing a standardization function $g(x)$ that maps a correlation ranking coefficient $\Gamma$ in a standard form $g(\Gamma)$ that has zero expected value, while maintaining the relevant statistical properties of $\Gamma$.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.7 -->
                
            <!-- Medicine: 4.3 -->
                
            <!-- Quantum Computing: 3.7 -->
                
            <!-- Networks: 3.0 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Hardware: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.9416
            </span>
            <a href="https://arxiv.org/abs/2504.05058" target="_blank" rel="noopener noreferrer">Not All Data Are Unlearned Equally</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Aravind Krishnan, Siva Reddy, Marius Mosbach | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Machine unlearning is concerned with the task of removing knowledge learned from particular data points from a trained model. In the context of large language models (LLMs), unlearning has recently received increased attention, particularly for removing knowledge about named entities from models for</span>
            
            <span class="abstract-full" style="display: none;">Machine unlearning is concerned with the task of removing knowledge learned from particular data points from a trained model. In the context of large language models (LLMs), unlearning has recently received increased attention, particularly for removing knowledge about named entities from models for privacy purposes. While various approaches have been proposed to address the unlearning problem, most existing approaches treat all data points to be unlearned equally, i.e., unlearning that Montreal is a city in Canada is treated exactly the same as unlearning the phone number of the first author of this paper. In this work, we show that this all data is equal assumption does not hold for LLM unlearning. We study how the success of unlearning depends on the frequency of the knowledge we want to unlearn in the pre-training data of a model and find that frequency strongly affects unlearning, i.e., more frequent knowledge is harder to unlearn. Additionally, we uncover a misalignment between probability and generation-based evaluations of unlearning and show that this problem worsens as models become larger. Overall, our experiments highlight the need for better evaluation practices and novel methods for LLM unlearning that take the training data of models into account.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.8 -->
                
            <!-- Medicine: 4.4 -->
                
            <!-- Quantum Computing: 3.7 -->
                
            <!-- Networks: 3.0 -->
                
            <!-- Math: 2.3 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- GNN: 1.7 -->
                
            <!-- Federated Learning: 1.7 -->
                
            <!-- SpikingNN: 1.4 -->
                
            <!-- Robotics: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.9483
            </span>
            <a href="https://arxiv.org/abs/2403.10444" target="_blank" rel="noopener noreferrer">Block Verification Accelerates Speculative Decoding</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Ziteng Sun, Uri Mendlovic, Yaniv Leviathan, Asaf Aharoni, Jae Hun Ro, Ahmad Beirami, Ananda Theertha Suresh | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Speculative decoding is an effective method for lossless acceleration of large language models during inference. It uses a fast model to draft a block of tokens which are then verified in parallel by the target model, and provides a guarantee that the output is distributed identically to a sample fr</span>
            
            <span class="abstract-full" style="display: none;">Speculative decoding is an effective method for lossless acceleration of large language models during inference. It uses a fast model to draft a block of tokens which are then verified in parallel by the target model, and provides a guarantee that the output is distributed identically to a sample from the target model. In prior works, draft verification is performed independently token-by-token. Surprisingly, we show that this approach is not optimal. We propose Block Verification, a simple draft verification algorithm that verifies the entire block jointly and provides additional wall-clock speedup. We prove that the proposed mechanism is optimal in the expected number of tokens produced each iteration and specifically is never worse than the standard token-level verification. Empirically, block verification provides modest but consistent wall-clock speedups over the standard token verification algorithm of 5%-8% in a range of tasks and datasets. Given that block verification does not increase code complexity, maintains the strong lossless guarantee of the standard speculative decoding verification algorithm, cannot deteriorate performance, and, in fact, consistently improves it, it can be used as a good default in speculative decoding implementations.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.7 -->
                
            <!-- Medicine: 4.4 -->
                
            <!-- Quantum Computing: 3.6 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- Math: 2.5 -->
                
            <!-- Reinforcement Learning: 2.3 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.9516
            </span>
            <a href="https://arxiv.org/abs/2305.15932" target="_blank" rel="noopener noreferrer">BUCA: A Binary Classification Approach to Unsupervised Commonsense Question Answering</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Jie He, Simon Chi Lok U, V\'ictor Guti\'errez-Basulto, Jeff Z. Pan | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Unsupervised commonsense reasoning (UCR) is becoming increasingly popular as the construction of commonsense reasoning datasets is expensive, and they are inevitably limited in their scope. A popular approach to UCR is to fine-tune language models with external knowledge (e.g., knowledge graphs), bu</span>
            
            <span class="abstract-full" style="display: none;">Unsupervised commonsense reasoning (UCR) is becoming increasingly popular as the construction of commonsense reasoning datasets is expensive, and they are inevitably limited in their scope. A popular approach to UCR is to fine-tune language models with external knowledge (e.g., knowledge graphs), but this usually requires a large number of training examples. In this paper, we propose to transform the downstream multiple choice question answering task into a simpler binary classification task by ranking all candidate answers according to their reasonableness. To this end, for training the model, we convert the knowledge graph triples into reasonable and unreasonable texts. Extensive experimental results show the effectiveness of our approach on various multiple choice question answering benchmarks. Furthermore, compared with existing UCR approaches using KGs, ours is less data hungry. Our code is available at https://github.com/probe2/BUCA.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 9.0 -->
                
            <!-- Medicine: 4.5 -->
                
            <!-- Quantum Computing: 3.6 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.9625
            </span>
            <a href="https://arxiv.org/abs/2410.13262" target="_blank" rel="noopener noreferrer">Membership Testing for Semantic Regular Expressions</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Yifei Huang, Matin Amini, Alexis Le Glaunec, Konstantinos Mamouras, Mukund Raghothaman | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">SMORE (Chen et al., 2023) recently proposed the concept of semantic regular expressions that extend the classical formalism with a primitive to query external oracles such as databases and large language models (LLMs). Such patterns can be used to identify lines of text containing references to sema</span>
            
            <span class="abstract-full" style="display: none;">SMORE (Chen et al., 2023) recently proposed the concept of semantic regular expressions that extend the classical formalism with a primitive to query external oracles such as databases and large language models (LLMs). Such patterns can be used to identify lines of text containing references to semantic concepts such as cities, celebrities, political entities, etc. The focus in their paper was on automatically synthesizing semantic regular expressions from positive and negative examples. In this paper, we study the membership testing problem:</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.5 -->
                
            <!-- Medicine: 4.1 -->
                
            <!-- Quantum Computing: 3.7 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- SpikingNN: 1.3 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.9807
            </span>
            <a href="https://arxiv.org/abs/2504.08272" target="_blank" rel="noopener noreferrer">Palmprint De-Identification Using Diffusion Model for High-Quality and Diverse Synthesis</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Licheng Yan, Bob Zhang, Andrew Beng Jin Teoh, Lu Leng, Shuyi Li, Yuqi Wang, Ziyuan Yang | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Palmprint recognition techniques have advanced significantly in recent years, enabling reliable recognition even when palmprints are captured in uncontrolled or challenging environments. However, this strength also introduces new risks, as publicly available palmprint images can be misused by advers</span>
            
            <span class="abstract-full" style="display: none;">Palmprint recognition techniques have advanced significantly in recent years, enabling reliable recognition even when palmprints are captured in uncontrolled or challenging environments. However, this strength also introduces new risks, as publicly available palmprint images can be misused by adversaries for malicious activities. Despite this growing concern, research on methods to obscure or anonymize palmprints remains largely unexplored. Thus, it is essential to develop a palmprint de-identification technique capable of removing identity-revealing features while retaining the image's utility and preserving non-sensitive information. In this paper, we propose a training-free framework that utilizes pre-trained diffusion models to generate diverse, high-quality palmprint images that conceal identity features for de-identification purposes. To ensure greater stability and controllability in the synthesis process, we incorporate a semantic-guided embedding fusion alongside a prior interpolation mechanism. We further propose the de-identification ratio, a novel metric for intuitive de-identification assessment. Extensive experiments across multiple palmprint datasets and recognition methods demonstrate that our method effectively conceals identity-related traits with significant diversity across de-identified samples. The de-identified samples preserve high visual fidelity and maintain excellent usability, achieving a balance between de-identification and retaining non-identity information.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 9.3 -->
                
            <!-- Medicine: 4.5 -->
                
            <!-- Quantum Computing: 3.6 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- GNN: 2.2 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- Federated Learning: 1.8 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.9818
            </span>
            <a href="https://arxiv.org/abs/2504.08666" target="_blank" rel="noopener noreferrer">Variability-Driven User-Story Generation using LLM and Triadic Concept Analysis</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Alexandre Bazin (Huaxi), Alain Gutierrez (Huaxi), Marianne Huchard (Huaxi), Pierre Martin (Huaxi), Yulin (Huaxi), Zhang | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">A widely used Agile practice for requirements is to produce a set of user stories (also called ``agile product backlog''), which roughly includes a list of pairs (role, feature), where the role handles the feature for a certain purpose. In the context of Software Product Lines, the requirements for </span>
            
            <span class="abstract-full" style="display: none;">A widely used Agile practice for requirements is to produce a set of user stories (also called ``agile product backlog''), which roughly includes a list of pairs (role, feature), where the role handles the feature for a certain purpose. In the context of Software Product Lines, the requirements for a family of similar systems is thus a family of user-story sets, one per system, leading to a 3-dimensional dataset composed of sets of triples (system, role, feature). In this paper, we combine Triadic Concept Analysis (TCA) and Large Language Model (LLM) prompting to suggest the user-story set required to develop a new system relying on the variability logic of an existing system family. This process consists in 1) computing 3-dimensional variability expressed as a set of TCA implications, 2) providing the designer with intelligible design options, 3) capturing the designer's selection of options, 4) proposing a first user-story set corresponding to this selection, 5) consolidating its validity according to the implications identified in step 1, while completing it if necessary, and 6) leveraging LLM to have a more comprehensive website. This process is evaluated with a dataset comprising the user-story sets of 67 similar-purpose websites.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.8 -->
                
            <!-- Medicine: 4.3 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Pathfinding: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.9839
            </span>
            <a href="https://arxiv.org/abs/2504.08230" target="_blank" rel="noopener noreferrer">Object Oriented-Based Metrics to Predict Fault Proneness in Software Design</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Areeb Ahmed Mir, Muhammad Raees, Afzal Ahmed | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">In object-oriented software design, various metrics predict software systems' fault proneness. Fault predictions can considerably improve the quality of the development process and the software product. In this paper, we look at the relationship between object-oriented software metrics and their imp</span>
            
            <span class="abstract-full" style="display: none;">In object-oriented software design, various metrics predict software systems' fault proneness. Fault predictions can considerably improve the quality of the development process and the software product. In this paper, we look at the relationship between object-oriented software metrics and their implications on fault proneness. Such relationships can help determine metrics that help determine software faults. Studies indicate that object-oriented metrics are indeed a good predictor of software fault proneness, however, there are some differences among existing work as to which metric is most apt for predicting software faults.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.6 -->
                
            <!-- Medicine: 4.3 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Networks: 3.0 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.9901
            </span>
            <a href="https://arxiv.org/abs/2501.10261" target="_blank" rel="noopener noreferrer">Logarithmic Regret for Nonlinear Control</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: James Wang, Bruce D. Lee, Ingvar Ziemann, Nikolai Matni | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We address the problem of learning to control an unknown nonlinear dynamical system through sequential interactions. Motivated by high-stakes applications in which mistakes can be catastrophic, such as robotics and healthcare, we study situations where it is possible for fast sequential learning to </span>
            
            <span class="abstract-full" style="display: none;">We address the problem of learning to control an unknown nonlinear dynamical system through sequential interactions. Motivated by high-stakes applications in which mistakes can be catastrophic, such as robotics and healthcare, we study situations where it is possible for fast sequential learning to occur. Fast sequential learning is characterized by the ability of the learning agent to incur logarithmic regret relative to a fully-informed baseline. We demonstrate that fast sequential learning is achievable in a diverse class of continuous control problems where the system dynamics depend smoothly on unknown parameters, provided the optimal control policy is persistently exciting. Additionally, we derive a regret bound which grows with the square root of the number of interactions for cases where the optimal policy is not persistently exciting. Our results provide the first regret bounds for controlling nonlinear dynamical systems depending nonlinearly on unknown parameters. We validate the trends our theory predicts in simulation on a simple dynamical system.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.0 -->
                
            <!-- Medicine: 4.4 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- Math: 2.5 -->
                
            <!-- Reinforcement Learning: 2.3 -->
                
            <!-- GNN: 1.7 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- SpikingNN: 1.3 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.9949
            </span>
            <a href="https://arxiv.org/abs/2407.17139" target="_blank" rel="noopener noreferrer">A Reduced Order Model conditioned on monitoring features for estimation and uncertainty quantification in engineered systems</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Konstantinos Vlachas, Thomas Simpson, Anthony Garland, D. Dane Quinn, Charbel Farhat, Eleni Chatzi | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Reduced Order Models (ROMs) form essential tools across engineering domains by virtue of their function as surrogates for computationally intensive digital twinning simulators. Although purely data-driven methods are available for ROM construction, schemes that allow to retain a portion of the physi</span>
            
            <span class="abstract-full" style="display: none;">Reduced Order Models (ROMs) form essential tools across engineering domains by virtue of their function as surrogates for computationally intensive digital twinning simulators. Although purely data-driven methods are available for ROM construction, schemes that allow to retain a portion of the physics tend to enhance the interpretability and generalization of ROMs. However, physics-based techniques can adversely scale when dealing with nonlinear systems that feature parametric dependencies. This study introduces a generative physics-based ROM that is suited for nonlinear systems with parametric dependencies and is additionally able to quantify the confidence associated with the respective estimates. A main contribution of this work is the conditioning of these parametric ROMs to features that can be derived from monitoring measurements, feasibly in an online fashion. This is contrary to most existing ROM schemes, which remain restricted to the prescription of the physics-based, and usually a priori unknown, system parameters. Our work utilizes conditional Variational Autoencoders to continuously map the required reduction bases to a feature vector extracted from limited output measurements, while additionally allowing for a probabilistic assessment of the ROM-estimated Quantities of Interest. An auxiliary task using a neural network-based parametrization of suitable probability distributions is introduced to re-establish the link with physical model parameters. We verify the proposed scheme on a series of simulated case studies incorporating effects of geometric and material nonlinearity under parametric dependencies related to system properties and input load characteristics.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 5.5 -->
                
            <!-- Medicine: 4.4 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- Reinforcement Learning: 2.5 -->
                
            <!-- Math: 2.2 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- SpikingNN: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -3.997
            </span>
            <a href="https://arxiv.org/abs/2504.07378" target="_blank" rel="noopener noreferrer">BRepFormer: Transformer-Based B-rep Geometric Feature Recognition</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Yongkang Dai, Xiaoshui Huang, Yunpeng Bai, Hao Guo, Hongping Gan, Ling Yang, Yilei Shi | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Recognizing geometric features on B-rep models is a cornerstone technique for multimedia content-based retrieval and has been widely applied in intelligent manufacturing. However, previous research often merely focused on Machining Feature Recognition (MFR), falling short in effectively capturing th</span>
            
            <span class="abstract-full" style="display: none;">Recognizing geometric features on B-rep models is a cornerstone technique for multimedia content-based retrieval and has been widely applied in intelligent manufacturing. However, previous research often merely focused on Machining Feature Recognition (MFR), falling short in effectively capturing the intricate topological and geometric characteristics of complex geometry features. In this paper, we propose BRepFormer, a novel transformer-based model to recognize both machining feature and complex CAD models' features. BRepFormer encodes and fuses the geometric and topological features of the models. Afterwards, BRepFormer utilizes a transformer architecture for feature propagation and a recognition head to identify geometry features. During each iteration of the transformer, we incorporate a bias that combines edge features and topology features to reinforce geometric constraints on each face. In addition, we also proposed a dataset named Complex B-rep Feature Dataset (CBF), comprising 20,000 B-rep models. By covering more complex B-rep models, it is better aligned with industrial applications. The experimental results demonstrate that BRepFormer achieves state-of-the-art accuracy on the MFInstSeg, MFTRCAD, and our CBF datasets.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.5 -->
                
            <!-- Medicine: 5.1 -->
                
            <!-- Quantum Computing: 3.4 -->
                
            <!-- Networks: 2.8 -->
                
            <!-- Reinforcement Learning: 2.3 -->
                
            <!-- GNN: 2.3 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Federated Learning: 1.7 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.0008
            </span>
            <a href="https://arxiv.org/abs/2504.08619" target="_blank" rel="noopener noreferrer">Analyzing 16,193 LLM Papers for Fun and Profits</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Zhiqiu Xia, Lang Zhu, Bingzhe Li, Feng Chen, Qiannan Li, Hang Liu | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Large Language Models (LLMs) are reshaping the landscape of computer science research, driving significant shifts in research priorities across diverse conferences and fields. This study provides a comprehensive analysis of the publication trend of LLM-related papers in 77 top-tier computer science </span>
            
            <span class="abstract-full" style="display: none;">Large Language Models (LLMs) are reshaping the landscape of computer science research, driving significant shifts in research priorities across diverse conferences and fields. This study provides a comprehensive analysis of the publication trend of LLM-related papers in 77 top-tier computer science conferences over the past six years (2019-2024). We approach this analysis from four distinct perspectives: (1) We investigate how LLM research is driving topic shifts within major conferences. (2) We adopt a topic modeling approach to identify various areas of LLM-related topic growth and reveal the topics of concern at different conferences. (3) We explore distinct contribution patterns of academic and industrial institutions. (4) We study the influence of national origins on LLM development trajectories. Synthesizing the findings from these diverse analytical angles, we derive ten key insights that illuminate the dynamics and evolution of the LLM research ecosystem.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 9.2 -->
                
            <!-- Medicine: 4.2 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 2.9 -->
                
            <!-- Reinforcement Learning: 2.2 -->
                
            <!-- Math: 2.0 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.3 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.0075
            </span>
            <a href="https://arxiv.org/abs/2502.12634" target="_blank" rel="noopener noreferrer">Context-Aware Lifelong Sequential Modeling for Online Click-Through Rate Prediction</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Ting Guo, Zhaoyang Yang, Qinsong Zeng, Ming Chen | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Lifelong sequential modeling (LSM) is becoming increasingly critical in social media recommendation systems for predicting the click-through rate (CTR) of items presented to users. Central to this process is the attention mechanism, which extracts interest representations with respect to candidate i</span>
            
            <span class="abstract-full" style="display: none;">Lifelong sequential modeling (LSM) is becoming increasingly critical in social media recommendation systems for predicting the click-through rate (CTR) of items presented to users. Central to this process is the attention mechanism, which extracts interest representations with respect to candidate items from the user sequence. Typically, attention mechanisms operate in a point-wise manner, focusing solely on the relevance of individual items in the sequence to the candidate item. In contrast, context-aware LSM aims to also consider adjacent items in the user behavior sequence to better assess the importance of each item. In this paper, we propose the Context-Aware Interest Network (CAIN), which utilizes the Temporal Convolutional Network (TCN) to create context-aware representations for each item throughout the lifelong sequence. These enhanced representations are then used in the attention mechanism instead of the original item representations to derive context-aware interest representations. Building upon this TCN framework, we propose the Multi-Scope Interest Aggregator (MSIA) module, which incorporates multiple TCN layers and their corresponding attention modules to capture interest representations across varying context scopes. Furthermore, we introduce the Personalized Extractor Generation (PEG) module, which generates convolution filters based on users' basic profile features. These personalized filters are then used in the TCN layers instead of the original global filters to generate more user-specific representations. We conducted extensive experiments on both a public dataset and an industrial dataset from the WeChat Channels platform. The results demonstrate that CAIN outperforms existing methods in terms of prediction accuracy and online performance metrics.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.3 -->
                
            <!-- Medicine: 4.4 -->
                
            <!-- Quantum Computing: 3.7 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Federated Learning: 1.9 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Robotics: 1.3 -->
                
            <!-- Pathfinding: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.0131
            </span>
            <a href="https://arxiv.org/abs/2504.08376" target="_blank" rel="noopener noreferrer">String Problems in the Congested Clique Model</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Shay Golan, Matan Kraus | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">In this paper we present algorithms for several string problems in the Congested Clique model. In the Congested Clique model, $n$ nodes (computers) are used to solve some problem. The input to the problem is distributed among the nodes, and the communication between the nodes is conducted in rounds.</span>
            
            <span class="abstract-full" style="display: none;">In this paper we present algorithms for several string problems in the Congested Clique model. In the Congested Clique model, $n$ nodes (computers) are used to solve some problem. The input to the problem is distributed among the nodes, and the communication between the nodes is conducted in rounds. In each round, every node is allowed to send an $O(\log n)$-bit message to every other node in the network.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.4 -->
                
            <!-- Medicine: 4.2 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- Math: 2.1 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Federated Learning: 1.7 -->
                
            <!-- Reinforcement Learning: 1.7 -->
                
            <!-- Pathfinding: 1.5 -->
                
            <!-- Robotics: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.0134
            </span>
            <a href="https://arxiv.org/abs/2504.08421" target="_blank" rel="noopener noreferrer">Poisson multi-Bernoulli mixture filter for trajectory measurements</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Marco Fontana, \'Angel F. Garc\'ia-Fern\'andez, Simon Maskell | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">This paper presents a Poisson multi-Bernoulli mixture (PMBM) filter for multi-target filtering based on sensor measurements that are sets of trajectories in the last two-time step window. The proposed filter, the trajectory measurement PMBM (TM-PMBM) filter, propagates a PMBM density on the set of t</span>
            
            <span class="abstract-full" style="display: none;">This paper presents a Poisson multi-Bernoulli mixture (PMBM) filter for multi-target filtering based on sensor measurements that are sets of trajectories in the last two-time step window. The proposed filter, the trajectory measurement PMBM (TM-PMBM) filter, propagates a PMBM density on the set of target states. In prediction, the filter obtains the PMBM density on the set of trajectories over the last two time steps. This density is then updated with the set of trajectory measurements. After the update step, the PMBM posterior on the set of two-step trajectories is marginalised to obtain a PMBM density on the set of target states. The filter provides a closed-form solution for multi-target filtering based on sets of trajectory measurements, estimating the set of target states at the end of each time window. Additionally, the paper proposes computationally lighter alternatives to the TM-PMBM filter by deriving a Poisson multi-Bernoulli (PMB) density through Kullback-Leibler divergence minimisation in an augmented space with auxiliary variables. The performance of the proposed filters are evaluated in a simulation study.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.4 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Medicine: 4.1 -->
                
            <!-- Networks: 3.0 -->
                
            <!-- Math: 2.6 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- GNN: 1.5 -->
                
            <!-- SpikingNN: 1.3 -->
                
            <!-- Pathfinding: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Robotics: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Hardware: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.0156
            </span>
            <a href="https://arxiv.org/abs/2504.07987" target="_blank" rel="noopener noreferrer">mixEEG: Enhancing EEG Federated Learning for Cross-subject EEG Classification with Tailored mixup</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Xuan-Hao Liu, Bao-Liang Lu, Wei-Long Zheng | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">The cross-subject electroencephalography (EEG) classification exhibits great challenges due to the diversity of cognitive processes and physiological structures between different subjects. Modern EEG models are based on neural networks, demanding a large amount of data to achieve high performance an</span>
            
            <span class="abstract-full" style="display: none;">The cross-subject electroencephalography (EEG) classification exhibits great challenges due to the diversity of cognitive processes and physiological structures between different subjects. Modern EEG models are based on neural networks, demanding a large amount of data to achieve high performance and generalizability. However, privacy concerns associated with EEG pose significant limitations to data sharing between different hospitals and institutions, resulting in the lack of large dataset for most EEG tasks. Federated learning (FL) enables multiple decentralized clients to collaboratively train a global model without direct communication of raw data, thus preserving privacy. For the first time, we investigate the cross-subject EEG classification in the FL setting. In this paper, we propose a simple yet effective framework termed mixEEG. Specifically, we tailor the vanilla mixup considering the unique properties of the EEG modality. mixEEG shares the unlabeled averaged data of the unseen subject rather than simply sharing raw data under the domain adaptation setting, thus better preserving privacy and offering an averaged label as pseudo-label. Extensive experiments are conducted on an epilepsy detection and an emotion recognition dataset. The experimental result demonstrates that our mixEEG enhances the transferability of global model for cross-subject EEG classification consistently across different datasets and model architectures. Code is published at: https://github.com/XuanhaoLiu/mixEEG.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.4 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 3.7 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- Federated Learning: 2.0 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- SpikingNN: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- Robotics: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.0159
            </span>
            <a href="https://arxiv.org/abs/2504.08616" target="_blank" rel="noopener noreferrer">Preserving Privacy Without Compromising Accuracy: Machine Unlearning for Handwritten Text Recognition</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Lei Kang, Xuanshuo Fu, Lluis Gomez, Alicia Forn\'es, Ernest Valveny, Dimosthenis Karatzas | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Handwritten Text Recognition (HTR) is essential for document analysis and digitization. However, handwritten data often contains user-identifiable information, such as unique handwriting styles and personal lexicon choices, which can compromise privacy and erode trust in AI services. Legislation lik</span>
            
            <span class="abstract-full" style="display: none;">Handwritten Text Recognition (HTR) is essential for document analysis and digitization. However, handwritten data often contains user-identifiable information, such as unique handwriting styles and personal lexicon choices, which can compromise privacy and erode trust in AI services. Legislation like the ``right to be forgotten'' underscores the necessity for methods that can expunge sensitive information from trained models. Machine unlearning addresses this by selectively removing specific data from models without necessitating complete retraining. Yet, it frequently encounters a privacy-accuracy tradeoff, where safeguarding privacy leads to diminished model performance. In this paper, we introduce a novel two-stage unlearning strategy for a multi-head transformer-based HTR model, integrating pruning and random labeling. Our proposed method utilizes a writer classification head both as an indicator and a trigger for unlearning, while maintaining the efficacy of the recognition head. To our knowledge, this represents the first comprehensive exploration of machine unlearning within HTR tasks. We further employ Membership Inference Attacks (MIA) to evaluate the effectiveness of unlearning user-identifiable information. Extensive experiments demonstrate that our approach effectively preserves privacy while maintaining model accuracy, paving the way for new research directions in the document analysis community. Our code will be publicly available upon acceptance.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.0 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 3.6 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.018
            </span>
            <a href="https://arxiv.org/abs/2504.08202" target="_blank" rel="noopener noreferrer">Harnessing the Unseen: The Hidden Influence of Intrinsic Knowledge in Long-Context Language Models</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Yu Fu, Haz Sameen Shahgir, Hui Liu, Xianfeng Tang, Qi He, Yue Dong | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Recent advances in long-context models (LCMs), designed to handle extremely long input contexts, primarily focus on utilizing external contextual information, often leaving the influence of large language models' intrinsic knowledge underexplored. In this work, we investigate how this intrinsic know</span>
            
            <span class="abstract-full" style="display: none;">Recent advances in long-context models (LCMs), designed to handle extremely long input contexts, primarily focus on utilizing external contextual information, often leaving the influence of large language models' intrinsic knowledge underexplored. In this work, we investigate how this intrinsic knowledge affects content generation and demonstrate that its impact becomes increasingly pronounced as context length extends. Furthermore, we show that the model's ability to utilize intrinsic knowledge, which we call intrinsic retrieval ability, does not improve simultaneously with its ability to leverage contextual knowledge through extrinsic retrieval ability. Moreover, better extrinsic retrieval can interfere with the model's ability to use its own knowledge effectively, limiting its full potential. To bridge this gap, we design a simple yet effective Hybrid Needle-in-a-Haystack test that evaluates models based on their capabilities across both retrieval abilities, rather than solely emphasizing extrinsic retrieval ability. Our experimental results reveal that Qwen-2.5 models significantly outperform Llama-3.1 models, demonstrating superior intrinsic retrieval ability. Moreover, even the more powerful Llama-3.1-70B-Instruct model fails to exhibit better performance under LCM conditions, highlighting the importance of evaluating models from a dual-retrieval perspective.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 9.3 -->
                
            <!-- Medicine: 4.4 -->
                
            <!-- Quantum Computing: 3.7 -->
                
            <!-- Networks: 2.9 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.0221
            </span>
            <a href="https://arxiv.org/abs/2504.02281" target="_blank" rel="noopener noreferrer">Parallel Market Environments for FinRL Contests</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Keyi Wang, Kairong Xiao, Xiao-Yang Liu Yanglet | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Financial reinforcement learning has attracted lots of attention recently. From 2023 to 2025, we have organized three FinRL Contests featuring different financial tasks. Large language models have a strong capability to process financial documents. By integrating LLM-generated signals into the state</span>
            
            <span class="abstract-full" style="display: none;">Financial reinforcement learning has attracted lots of attention recently. From 2023 to 2025, we have organized three FinRL Contests featuring different financial tasks. Large language models have a strong capability to process financial documents. By integrating LLM-generated signals into the state, trading agents can take smarter actions based on both structured market data and unstructured financial documents. In this paper, we summarize the parallel market environments for tasks used in FinRL Contests 2023-2025. To address the sampling bottleneck during training, we introduce GPU-optimized parallel market environments to address the sampling bottleneck. In particular, two new tasks incorporate LLM-generated signals and all tasks support massively parallel simulation. Contestants have used these market environments to train robust and powerful trading agents for both stock and cryptocurrency trading tasks.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.6 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 3.6 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- GNN: 2.3 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 1.6 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.0308
            </span>
            <a href="https://arxiv.org/abs/2504.08590" target="_blank" rel="noopener noreferrer">Playpen: An Environment for Exploring Learning Through Conversational Interaction</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Nicola Horst, Davide Mazzaccara, Antonia Schmidt, Michael Sullivan, Filippo Moment\`e, Luca Franceschetti, Philipp Sadler, Sherzod Hakimov, Alberto Testoni, Raffaella Bernardi, Raquel Fern\'andez, Alexander Koller, Oliver Lemon, David Schlangen, Mario Giulianelli, Alessandro Suglia | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Are we running out of learning signal? Predicting the next word in an existing text has turned out to be a powerful signal, at least at scale. But there are signs that we are running out of this resource. In recent months, interaction between learner and feedback-giver has come into focus, both for </span>
            
            <span class="abstract-full" style="display: none;">Are we running out of learning signal? Predicting the next word in an existing text has turned out to be a powerful signal, at least at scale. But there are signs that we are running out of this resource. In recent months, interaction between learner and feedback-giver has come into focus, both for "alignment" (with a reward model judging the quality of instruction following attempts) and for improving "reasoning" (process- and outcome-based verifiers judging reasoning steps). In this paper, we explore to what extent synthetic interaction in what we call Dialogue Games -- goal-directed and rule-governed activities driven predominantly by verbal actions -- can provide a learning signal, and how this signal can be used. We introduce an environment for producing such interaction data (with the help of a Large Language Model as counterpart to the learner model), both offline and online. We investigate the effects of supervised fine-tuning on this data, as well as reinforcement learning setups such as DPO, and GRPO; showing that all of these approaches achieve some improvements in in-domain games, but only GRPO demonstrates the ability to generalise to out-of-domain games as well as retain competitive performance in reference-based tasks. We release the framework and the baseline training setups in the hope that this can foster research in this promising new direction.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 9.0 -->
                
            <!-- Medicine: 4.2 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.0 -->
                
            <!-- Math: 2.0 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Hardware: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.0312
            </span>
            <a href="https://arxiv.org/abs/2504.08198" target="_blank" rel="noopener noreferrer">The More is not the Merrier: Investigating the Effect of Client Size on Federated Learning</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Eleanor Wallach, Sage Siler, Jing Deng | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Federated Learning (FL) has been introduced as a way to keep data local to clients while training a shared machine learning model, as clients train on their local data and send trained models to a central aggregator. It is expected that FL will have a huge implication on Mobile Edge Computing, the I</span>
            
            <span class="abstract-full" style="display: none;">Federated Learning (FL) has been introduced as a way to keep data local to clients while training a shared machine learning model, as clients train on their local data and send trained models to a central aggregator. It is expected that FL will have a huge implication on Mobile Edge Computing, the Internet of Things, and Cross-Silo FL. In this paper, we focus on the widely used FedAvg algorithm to explore the effect of the number of clients in FL. We find a significant deterioration of learning accuracy for FedAvg as the number of clients increases. To address this issue for a general application, we propose a method called Knowledgeable Client Insertion (KCI) that introduces a very small number of knowledgeable clients to the MEC setting. These knowledgeable clients are expected to have accumulated a large set of data samples to help with training. With the help of KCI, the learning accuracy of FL increases much faster even with a normal FedAvg aggregation technique. We expect this approach to be able to provide great privacy protection for clients against security attacks such as model inversion attacks. Our code is available at https://github.com/Eleanor-W/KCI_for_FL.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.0 -->
                
            <!-- Medicine: 4.4 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- Math: 2.1 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- GNN: 1.6 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.3 -->
                
            <!-- SpikingNN: 1.3 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.0325
            </span>
            <a href="https://arxiv.org/abs/2410.05852" target="_blank" rel="noopener noreferrer">A$^3$L-FEC: Age-Aware Application Layer Forward Error Correction Flow Control</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Sajjad Baghaee, Elif Uysal | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Age of Information (AoI) is a metric and KPI that has been developed for measuring and controlling data freshness. Optimization of AoI in a real-life network requires adapting the rate and timing of transmissions to varying network conditions. The vast majority of previous research on the control of</span>
            
            <span class="abstract-full" style="display: none;">Age of Information (AoI) is a metric and KPI that has been developed for measuring and controlling data freshness. Optimization of AoI in a real-life network requires adapting the rate and timing of transmissions to varying network conditions. The vast majority of previous research on the control of AoI has been theoretical, using idealized models that ignored certain implementation aspects. As such, there is still a gap between the research on AoI and real-world protocols. In this paper we present an effort toward closing this gap by introducing an age-aware flow control algorithm. The algorithm, Age-Aware Application Layer Forward Error Correction (A$^3$L-FEC), is a packet generation mechanism operating on top of the User Datagram Protocol (UDP). The purpose is to control the peak Age of the end-to-end packet flow, specifically to reduce the rate of so-called "Age Violations," i.e., events where the peak age exceeds a given threshold. Evaluations in Mininet-WiFi and MATLAB indicate that A$3$L-FEC reduces age violations compared to two related protocols in the literature, namely TCP-BBR and ACP+.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.6 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- Math: 1.9 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.036
            </span>
            <a href="https://arxiv.org/abs/2412.04156" target="_blank" rel="noopener noreferrer">WalkSAT is linear on random 2-SAT</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Petra Berenbrink, Amin Coja-Oghlan, Colin Cooper, Thorsten G\"otte, Lukas Hintze, Pavel Zakharov | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">In an influential article Papadimitriou [FOCS 1991] proved that a local search algorithm called WalkSAT finds a satisfying assignment of a satisfiable 2-CNF with $n$ variables in $O(n^2)$ expected time. Variants of the WalkSAT algorithm have become a mainstay of practical SAT solving (e.g., [Hoos an</span>
            
            <span class="abstract-full" style="display: none;">In an influential article Papadimitriou [FOCS 1991] proved that a local search algorithm called WalkSAT finds a satisfying assignment of a satisfiable 2-CNF with $n$ variables in $O(n^2)$ expected time. Variants of the WalkSAT algorithm have become a mainstay of practical SAT solving (e.g., [Hoos and St\"utzle 2000]). In the present article we analyse the expected running time of WalkSAT on random 2-SAT instances. Answering a question raised by Alekhnovich and Ben-Sasson [SICOMP 2007], we show that WalkSAT runs in linear expected time for all clause/variable densities up to the random 2-SAT satisfiability threshold.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.5 -->
                
            <!-- Medicine: 4.2 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- Math: 2.1 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.0414
            </span>
            <a href="https://arxiv.org/abs/2504.08001" target="_blank" rel="noopener noreferrer">Linguistic Interpretability of Transformer-based Language Models: a systematic review</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Miguel L\'opez-Otal, Jorge Gracia, Jordi Bernad, Carlos Bobed, Luc\'ia Pitarch-Ballesteros, Emma Angl\'es-Herrero | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Language models based on the Transformer architecture achieve excellent results in many language-related tasks, such as text classification or sentiment analysis. However, despite the architecture of these models being well-defined, little is known about how their internal computations help them ach</span>
            
            <span class="abstract-full" style="display: none;">Language models based on the Transformer architecture achieve excellent results in many language-related tasks, such as text classification or sentiment analysis. However, despite the architecture of these models being well-defined, little is known about how their internal computations help them achieve their results. This renders these models, as of today, a type of 'black box' systems. There is, however, a line of research -- 'interpretability' -- aiming to learn how information is encoded inside these models. More specifically, there is work dedicated to studying whether Transformer-based models possess knowledge of linguistic phenomena similar to human speakers -- an area we call 'linguistic interpretability' of these models. In this survey we present a comprehensive analysis of 160 research works, spread across multiple languages and models -- including multilingual ones -- that attempt to discover linguistic information from the perspective of several traditional Linguistics disciplines: Syntax, Morphology, Lexico-Semantics and Discourse. Our survey fills a gap in the existing interpretability literature, which either not focus on linguistic knowledge in these models or present some limitations -- e.g. only studying English-based models. Our survey also focuses on Pre-trained Language Models not further specialized for a downstream task, with an emphasis on works that use interpretability techniques that explore models' internal representations.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.1 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Networks: 2.9 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 1.8 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.0418
            </span>
            <a href="https://arxiv.org/abs/2411.08998" target="_blank" rel="noopener noreferrer">Microfoundation Inference for Strategic Prediction</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Daniele Bracale, Subha Maity, Felipe Maia Polo, Seamus Somerstep, Moulinath Banerjee, Yuekai Sun | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Often in prediction tasks, the predictive model itself can influence the distribution of the target variable, a phenomenon termed performative prediction. Generally, this influence stems from strategic actions taken by stakeholders with a vested interest in predictive models. A key challenge that hi</span>
            
            <span class="abstract-full" style="display: none;">Often in prediction tasks, the predictive model itself can influence the distribution of the target variable, a phenomenon termed performative prediction. Generally, this influence stems from strategic actions taken by stakeholders with a vested interest in predictive models. A key challenge that hinders the widespread adaptation of performative prediction in machine learning is that practitioners are generally unaware of the social impacts of their predictions. To address this gap, we propose a methodology for learning the distribution map that encapsulates the long-term impacts of predictive models on the population. Specifically, we model agents' responses as a cost-adjusted utility maximization problem and propose estimates for said cost. Our approach leverages optimal transport to align pre-model exposure (ex ante) and post-model exposure (ex post) distributions. We provide a rate of convergence for this proposed estimate and assess its quality through empirical demonstrations on a credit-scoring dataset.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.7 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 3.6 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Federated Learning: 1.7 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- SpikingNN: 1.3 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.0441
            </span>
            <a href="https://arxiv.org/abs/2504.08205" target="_blank" rel="noopener noreferrer">EO-VLM: VLM-Guided Energy Overload Attacks on Vision Models</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Minjae Seo, Myoungsung You, Junhee Lee, Jaehan Kim, Hwanjo Heo, Jintae Oh, Jinwoo Kim | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Vision models are increasingly deployed in critical applications such as autonomous driving and CCTV monitoring, yet they remain susceptible to resource-consuming attacks. In this paper, we introduce a novel energy-overloading attack that leverages vision language model (VLM) prompts to generate adv</span>
            
            <span class="abstract-full" style="display: none;">Vision models are increasingly deployed in critical applications such as autonomous driving and CCTV monitoring, yet they remain susceptible to resource-consuming attacks. In this paper, we introduce a novel energy-overloading attack that leverages vision language model (VLM) prompts to generate adversarial images targeting vision models. These images, though imperceptible to the human eye, significantly increase GPU energy consumption across various vision models, threatening the availability of these systems. Our framework, EO-VLM (Energy Overload via VLM), is model-agnostic, meaning it is not limited by the architecture or type of the target vision model. By exploiting the lack of safety filters in VLMs like DALL-E 3, we create adversarial noise images without requiring prior knowledge or internal structure of the target vision models. Our experiments demonstrate up to a 50% increase in energy consumption, revealing a critical vulnerability in current vision models.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.8 -->
                
            <!-- Medicine: 4.5 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Networks: 3.0 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.046
            </span>
            <a href="https://arxiv.org/abs/2407.15317" target="_blank" rel="noopener noreferrer">Open-CD: A Comprehensive Toolbox for Change Detection</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Kaiyu Li, Jiawei Jiang, Andrea Codegoni, Chengxi Han, Yupeng Deng, Keyan Chen, Zhuo Zheng, Hao Chen, Ziyuan Liu, Yuantao Gu, Zhengxia Zou, Zhenwei Shi, Sheng Fang, Deyu Meng, Zhi Wang, Xiangyong Cao | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We present Open-CD, a change detection toolbox that contains a rich set of change detection methods as well as related components and modules. The toolbox started from a series of open source general vision task tools, including OpenMMLab Toolkits, PyTorch Image Models, etc. It gradually evolves int</span>
            
            <span class="abstract-full" style="display: none;">We present Open-CD, a change detection toolbox that contains a rich set of change detection methods as well as related components and modules. The toolbox started from a series of open source general vision task tools, including OpenMMLab Toolkits, PyTorch Image Models, etc. It gradually evolves into a unified platform that covers many popular change detection methods and contemporary modules. It not only includes training and inference codes, but also provides some useful scripts for data analysis. We believe this toolbox is by far the most complete change detection toolbox. In this report, we introduce the various features, supported methods and applications of Open-CD. In addition, we also conduct a benchmarking study on different methods and components. We wish that the toolbox and benchmark could serve the growing research community by providing a flexible toolkit to reimplement existing methods and develop their own new change detectors. Code and models are available at https://github.com/likyoo/open-cd. Pioneeringly, this report also includes brief descriptions of the algorithms supported in Open-CD, mainly contributed by their authors. We sincerely encourage researchers in this field to participate in this project and work together to create a more open community. This toolkit and report will be kept updated.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.5 -->
                
            <!-- Medicine: 4.4 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- Reinforcement Learning: 2.2 -->
                
            <!-- Robotics: 2.1 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- SpikingNN: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.0471
            </span>
            <a href="https://arxiv.org/abs/2411.18822" target="_blank" rel="noopener noreferrer">RelCon: Relative Contrastive Learning for a Motion Foundation Model for Wearable Data</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Maxwell A. Xu, Jaya Narain, Gregory Darnell, Haraldur Hallgrimsson, Hyewon Jeong, Darren Forde, Richard Fineman, Karthik J. Raghuram, James M. Rehg, Shirley Ren | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We present RelCon, a novel self-supervised Relative Contrastive learning approach for training a motion foundation model from wearable accelerometry sensors. First, a learnable distance measure is trained to capture motif similarity and domain-specific semantic information such as rotation invarianc</span>
            
            <span class="abstract-full" style="display: none;">We present RelCon, a novel self-supervised Relative Contrastive learning approach for training a motion foundation model from wearable accelerometry sensors. First, a learnable distance measure is trained to capture motif similarity and domain-specific semantic information such as rotation invariance. Then, the learned distance provides a measurement of semantic similarity between a pair of accelerometry time-series, which we use to train our foundation model to model relative relationships across time and across subjects. The foundation model is trained on 1 billion segments from 87,376 participants, and achieves state-of-the-art performance across multiple downstream tasks, including human activity recognition and gait metric regression. To our knowledge, we are the first to show the generalizability of a foundation model with motion data from wearables across distinct evaluation tasks.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.9 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 3.7 -->
                
            <!-- Networks: 3.7 -->
                
            <!-- Reinforcement Learning: 2.2 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- SpikingNN: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.0504
            </span>
            <a href="https://arxiv.org/abs/2504.08490" target="_blank" rel="noopener noreferrer">Adopting Large Language Models to Automated System Integration</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Robin D. Pesl | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Modern enterprise computing systems integrate numerous subsystems to resolve a common task by yielding emergent behavior. A widespread approach is using services implemented with Web technologies like REST or OpenAPI, which offer an interaction mechanism and service documentation standard, respectiv</span>
            
            <span class="abstract-full" style="display: none;">Modern enterprise computing systems integrate numerous subsystems to resolve a common task by yielding emergent behavior. A widespread approach is using services implemented with Web technologies like REST or OpenAPI, which offer an interaction mechanism and service documentation standard, respectively. Each service represents a specific business functionality, allowing encapsulation and easier maintenance. Despite the reduced maintenance costs on an individual service level, increased integration complexity arises. Consequently, automated service composition approaches have arisen to mitigate this issue. Nevertheless, these approaches have not achieved high acceptance in practice due to their reliance on complex formal modeling. Within this Ph.D. thesis, we analyze the application of Large Language Models (LLMs) to automatically integrate the services based on a natural language input. The result is a reusable service composition, e.g., as program code. While not always generating entirely correct results, the result can still be helpful by providing integration engineers with a close approximation of a suitable solution, which requires little effort to become operational. Our research involves (i) introducing a software architecture for automated service composition using LLMs, (ii) analyzing Retrieval Augmented Generation (RAG) for service discovery, (iii) proposing a novel natural language query-based benchmark for service discovery, and (iv) extending the benchmark to complete service composition scenarios. We have presented our software architecture as Compositio Prompto, the analysis of RAG for service discovery, and submitted a proposal for the service discovery benchmark. Open topics are primarily the extension of the service discovery benchmark to service composition scenarios and the improvements of the service composition generation, e.g., using fine-tuning or LLM agents.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 9.5 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- Math: 2.0 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- GNN: 1.7 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.0508
            </span>
            <a href="https://arxiv.org/abs/2504.07627" target="_blank" rel="noopener noreferrer">Robustness of Online Identification-based Policy Iteration to Noisy Data</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Bowen Song, Andrea Iannelli | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">This article investigates the core mechanisms of indirect data-driven control for unknown systems, focusing on the application of policy iteration (PI) within the context of the linear quadratic regulator (LQR) optimal control problem. Specifically, we consider a setting where data is collected sequ</span>
            
            <span class="abstract-full" style="display: none;">This article investigates the core mechanisms of indirect data-driven control for unknown systems, focusing on the application of policy iteration (PI) within the context of the linear quadratic regulator (LQR) optimal control problem. Specifically, we consider a setting where data is collected sequentially from a linear system subject to exogenous process noise, and is then used to refine estimates of the optimal control policy. We integrate recursive least squares (RLS) for online model estimation within a certainty-equivalent framework, and employ PI to iteratively update the control policy. In this work, we investigate first the convergence behavior of RLS under two different models of adversarial noise, namely point-wise and energy bounded noise, and then we provide a closed-loop analysis of the combined model identification and control design process. This iterative scheme is formulated as an algorithmic dynamical system consisting of the feedback interconnection between two algorithms expressed as discrete-time systems. This system theoretic viewpoint on indirect data-driven control allows us to establish convergence guarantees to the optimal controller in the face of uncertainty caused by noisy data. Simulations illustrate the theoretical results.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.7 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- Math: 2.0 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Federated Learning: 1.7 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- SpikingNN: 1.3 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.0518
            </span>
            <a href="https://arxiv.org/abs/2409.19465" target="_blank" rel="noopener noreferrer">Construction of the Sparsest Maximally r-Robust Graphs</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Haejoon Lee, Dimitra Panagou | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">In recent years, the notion of r-robustness for the communication graph of the network has been introduced to address the challenge of achieving consensus in the presence of misbehaving agents. Higher r-robustness typically implies higher tolerance to malicious information towards achieving resilien</span>
            
            <span class="abstract-full" style="display: none;">In recent years, the notion of r-robustness for the communication graph of the network has been introduced to address the challenge of achieving consensus in the presence of misbehaving agents. Higher r-robustness typically implies higher tolerance to malicious information towards achieving resilient consensus, but it also implies more edges for the communication graph. This in turn conflicts with the need to minimize communication due to limited resources in real-world applications (e.g., multi-robot networks). In this paper, our contributions are twofold. (a) We provide the necessary subgraph structures and tight lower bounds on the number of edges required for graphs with a given number of nodes to achieve maximum robustness. (b) We then use the results of (a) to introduce two classes of graphs that maintain maximum robustness with the least number of edges. Our work is validated through a series of simulations.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.9 -->
                
            <!-- Quantum Computing: 4.1 -->
                
            <!-- Medicine: 4.0 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- Math: 2.8 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- GNN: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- SpikingNN: 1.4 -->
                
            <!-- Pathfinding: 1.3 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- Robotics: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.0737
            </span>
            <a href="https://arxiv.org/abs/2312.00092" target="_blank" rel="noopener noreferrer">Mixture of Gaussian-distributed Prototypes with Generative Modelling for Interpretable and Trustworthy Image Recognition</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Chong Wang, Yuanhong Chen, Fengbei Liu, Yuyuan Liu, Davis James McCarthy, Helen Frazer, Gustavo Carneiro | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Prototypical-part methods, e.g., ProtoPNet, enhance interpretability in image recognition by linking predictions to training prototypes, thereby offering intuitive insights into their decision-making. Existing methods, which rely on a point-based learning of prototypes, typically face two critical i</span>
            
            <span class="abstract-full" style="display: none;">Prototypical-part methods, e.g., ProtoPNet, enhance interpretability in image recognition by linking predictions to training prototypes, thereby offering intuitive insights into their decision-making. Existing methods, which rely on a point-based learning of prototypes, typically face two critical issues: 1) the learned prototypes have limited representation power and are not suitable to detect Out-of-Distribution (OoD) inputs, reducing their decision trustworthiness; and 2) the necessary projection of the learned prototypes back into the space of training images causes a drastic degradation in the predictive performance. Furthermore, current prototype learning adopts an aggressive approach that considers only the most active object parts during training, while overlooking sub-salient object regions which still hold crucial classification information. In this paper, we present a new generative paradigm to learn prototype distributions, termed as Mixture of Gaussian-distributed Prototypes (MGProto). The distribution of prototypes from MGProto enables both interpretable image classification and trustworthy recognition of OoD inputs. The optimisation of MGProto naturally projects the learned prototype distributions back into the training image space, thereby addressing the performance degradation caused by prototype projection. Additionally, we develop a novel and effective prototype mining strategy that considers not only the most active but also sub-salient object parts. To promote model compactness, we further propose to prune MGProto by removing prototypes with low importance priors. Experiments on CUB-200-2011, Stanford Cars, Stanford Dogs, and Oxford-IIIT Pets datasets show that MGProto achieves state-of-the-art image recognition and OoD detection performances, while providing encouraging interpretability results.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.3 -->
                
            <!-- Medicine: 4.8 -->
                
            <!-- Quantum Computing: 3.7 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.0747
            </span>
            <a href="https://arxiv.org/abs/2402.16170" target="_blank" rel="noopener noreferrer">Nonparametric Steady-state Learning for Robust Output Regulation of Nonlinear Output Feedback Systems</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Shimin Wang, Martin Guay, Richard D. Braatz | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">This article addresses the nonadaptive and robust output regulation problem of the general nonlinear output feedback system with error output. The global robust output regulation problem for a class of general output feedback nonlinear systems with an uncertain exosystem and high relative degree can</span>
            
            <span class="abstract-full" style="display: none;">This article addresses the nonadaptive and robust output regulation problem of the general nonlinear output feedback system with error output. The global robust output regulation problem for a class of general output feedback nonlinear systems with an uncertain exosystem and high relative degree can be tackled by constructing a linear generic internal model provided that a continuous nonlinear mapping exists. Leveraging the presented nonadaptive framework facilitates the conversion of the nonlinear robust output regulation problem into a robust nonadaptive stabilization endeavour for the augmented system endowed with Input-to-State Stable dynamics, removing the need for constructing a specific Lyapunov function with positive semidefinite derivatives and the commmonly employed assumption that the nonlinear system should be linear-in-parameter(parameterized) condition. The nonadaptive approach is extended by incorporating the nonparametric learning framework to ensure the feasibility of the nonlinear mapping, which can be classified into a data-driven method. Moreover, the introduced nonparametric learning framework allows the controlled system to learn the dynamics of the steady-state/input behaviour from the signal generated from the internal model with the output error as the feedback. As a result, the nonadaptive/nonparametric approach can be advantageous by guaranteeing convergence of the estimation and tracking error even when the underlying controlled system dynamics are complex or poorly understood. The effectiveness of the theoretical results is illustrated for a benchmark example: a controlled duffing system and two practical examples: a continuously stirred tank reactor and a continuous bioreactor.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 5.1 -->
                
            <!-- Medicine: 5.0 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- Math: 2.7 -->
                
            <!-- Reinforcement Learning: 2.5 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- SpikingNN: 1.4 -->
                
            <!-- Robotics: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.0753
            </span>
            <a href="https://arxiv.org/abs/2504.02790" target="_blank" rel="noopener noreferrer">Dynamic Treewidth in Logarithmic Time</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Tuukka Korhonen | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We present a dynamic data structure that maintains a tree decomposition of width at most $9k+8$ of a dynamic graph with treewidth at most $k$, which is updated by edge insertions and deletions. The amortized update time of our data structure is $2^{O(k)} \log n$, where $n$ is the number of vertices.</span>
            
            <span class="abstract-full" style="display: none;">We present a dynamic data structure that maintains a tree decomposition of width at most $9k+8$ of a dynamic graph with treewidth at most $k$, which is updated by edge insertions and deletions. The amortized update time of our data structure is $2^{O(k)} \log n$, where $n$ is the number of vertices. The data structure also supports maintaining any ``dynamic programming scheme'' on the tree decomposition, providing, for example, a dynamic version of Courcelle's theorem with $O_{k}(\log n)$ amortized update time; the $O_{k}(\cdot)$ notation hides factors that depend on $k$. This improves upon a result of Korhonen, Majewski, Nadara, Pilipczuk, and Soko{\l}owski [FOCS 2023], who gave a similar data structure but with amortized update time $2^{k^{O(1)}} n^{o(1)}$. Furthermore, our data structure is arguably simpler.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.9 -->
                
            <!-- Medicine: 4.3 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- Math: 2.0 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Robotics: 1.9 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.0782
            </span>
            <a href="https://arxiv.org/abs/2403.14174" target="_blank" rel="noopener noreferrer">Unified Static and Dynamic Network: Efficient Temporal Filtering for Video Grounding</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Jingjing Hu, Dan Guo, Kun Li, Zhan Si, Xun Yang, Xiaojun Chang, Meng Wang | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Inspired by the activity-silent and persistent activity mechanisms in human visual perception biology, we design a Unified Static and Dynamic Network (UniSDNet), to learn the semantic association between the video and text/audio queries in a cross-modal environment for efficient video grounding. For</span>
            
            <span class="abstract-full" style="display: none;">Inspired by the activity-silent and persistent activity mechanisms in human visual perception biology, we design a Unified Static and Dynamic Network (UniSDNet), to learn the semantic association between the video and text/audio queries in a cross-modal environment for efficient video grounding. For static modeling, we devise a novel residual structure (ResMLP) to boost the global comprehensive interaction between the video segments and queries, achieving more effective semantic enhancement/supplement. For dynamic modeling, we effectively exploit three characteristics of the persistent activity mechanism in our network design for a better video context comprehension. Specifically, we construct a diffusely connected video clip graph on the basis of 2D sparse temporal masking to reflect the "short-term effect" relationship. We innovatively consider the temporal distance and relevance as the joint "auxiliary evidence clues" and design a multi-kernel Temporal Gaussian Filter to expand the context clue into high-dimensional space, simulating the "complex visual perception", and then conduct element level filtering convolution operations on neighbour clip nodes in message passing stage for finally generating and ranking the candidate proposals. Our UniSDNet is applicable to both Natural Language Video Grounding (NLVG) and Spoken Language Video Grounding (SLVG) tasks. Our UniSDNet achieves SOTA performance on three widely used datasets for NLVG, as well as three datasets for SLVG, e.g., reporting new records at 38.88% R@1,IoU@0.7 on ActivityNet Captions and 40.26% R@1,IoU@0.5 on TACoS. To facilitate this field, we collect two new datasets (Charades-STA Speech and TACoS Speech) for SLVG task. Meanwhile, the inference speed of our UniSDNet is 1.56$\times$ faster than the strong multi-query benchmark. Code is available at: https://github.com/xian-sh/UniSDNet.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.4 -->
                
            <!-- Medicine: 4.8 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- Reinforcement Learning: 2.2 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- T2I: 1.4 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.0835
            </span>
            <a href="https://arxiv.org/abs/2504.08400" target="_blank" rel="noopener noreferrer">A Reproducibility Study of Graph-Based Legal Case Retrieval</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Gregor Donabauer, Udo Kruschwitz | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Legal retrieval is a widely studied area in Information Retrieval (IR) and a key task in this domain is retrieving relevant cases based on a given query case, often done by applying language models as encoders to model case similarity. Recently, Tang et al. proposed CaseLink, a novel graph-based met</span>
            
            <span class="abstract-full" style="display: none;">Legal retrieval is a widely studied area in Information Retrieval (IR) and a key task in this domain is retrieving relevant cases based on a given query case, often done by applying language models as encoders to model case similarity. Recently, Tang et al. proposed CaseLink, a novel graph-based method for legal case retrieval, which models both cases and legal charges as nodes in a network, with edges representing relationships such as references and shared semantics. This approach offers a new perspective on the task by capturing higher-order relationships of cases going beyond the stand-alone level of documents. However, while this shift in approaching legal case retrieval is a promising direction in an understudied area of graph-based legal IR, challenges in reproducing novel results have recently been highlighted, with multiple studies reporting difficulties in reproducing previous findings. Thus, in this work we reproduce CaseLink, a graph-based legal case retrieval method, to support future research in this area of IR. In particular, we aim to assess its reliability and generalizability by (i) first reproducing the original study setup and (ii) applying the approach to an additional dataset. We then build upon the original implementations by (iii) evaluating the approach's performance when using a more sophisticated graph data representation and (iv) using an open large language model (LLM) in the pipeline to address limitations that are known to result from using closed models accessed via an API. Our findings aim to improve the understanding of graph-based approaches in legal IR and contribute to improving reproducibility in the field. To achieve this, we share all our implementations and experimental artifacts with the community.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.6 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.7 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.0888
            </span>
            <a href="https://arxiv.org/abs/2407.18271" target="_blank" rel="noopener noreferrer">Large Language Model for Verilog Generation with Code-Structure-Guided Reinforcement Learning</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Ning Wang, Bingkun Yao, Jie Zhou, Xi Wang, Zhe Jiang, Nan Guan | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Recent advancements in large language models (LLMs) have sparked significant interest in the automatic generation of Register Transfer Level (RTL) designs, particularly using Verilog. Current research on this topic primarily focuses on pre-training and instruction tuning, but the effectiveness of th</span>
            
            <span class="abstract-full" style="display: none;">Recent advancements in large language models (LLMs) have sparked significant interest in the automatic generation of Register Transfer Level (RTL) designs, particularly using Verilog. Current research on this topic primarily focuses on pre-training and instruction tuning, but the effectiveness of these methods is constrained by the limited availability of training data, as public Verilog code is far less abundant than software code. In particular, these methods struggle to effectively capture Verilog parallel code structures, which fundamentally differ from the imperative, sequential control flow typical in most software programming languages. This paper introduces VeriSeek, an LLM enhanced by reinforcement learning using a limited amount of high-quality training data to achieve high Verilog code generation performance. Our reinforcement learning approach employs code structure information as feedback signals to refine the pre-trained model, enabling it to effectively learn important patterns from Verilog code with parallel structures. Experiments show that VeriSeek outperforms state-of-the-art methods across multiple benchmarks.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.6 -->
                
            <!-- Medicine: 4.4 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Evolutionary Algorithms: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.0952
            </span>
            <a href="https://arxiv.org/abs/2408.06631" target="_blank" rel="noopener noreferrer">IFShip: Interpretable Fine-grained Ship Classification with Domain Knowledge-Enhanced Vision-Language Models</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Mingning Guo, Mengwei Wu, Yuxiang Shen, Haifeng Li, Chao Tao | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">End-to-end interpretation currently dominates the remote sensing fine-grained ship classification (RS-FGSC) task. However, the inference process remains uninterpretable, leading to criticisms of these models as "black box" systems. To address this issue, we propose a domain knowledge-enhanced Chain-</span>
            
            <span class="abstract-full" style="display: none;">End-to-end interpretation currently dominates the remote sensing fine-grained ship classification (RS-FGSC) task. However, the inference process remains uninterpretable, leading to criticisms of these models as "black box" systems. To address this issue, we propose a domain knowledge-enhanced Chain-of-Thought (CoT) prompt generation mechanism, which is used to semi-automatically construct a task-specific instruction-following dataset, TITANIC-FGS. By training on TITANIC-FGS, we adapt general-domain vision-language models (VLMs) to the FGSC task, resulting in a model named IFShip. Building upon IFShip, we develop an FGSC visual chatbot that redefines the FGSC problem as a step-by-step reasoning task and conveys the reasoning process in natural language. Experimental results show that IFShip outperforms state-of-the-art FGSC algorithms in both interpretability and classification accuracy. Furthermore, compared to VLMs such as LLaVA and MiniGPT-4, IFShip demonstrates superior performance on the FGSC task. It provides an accurate chain of reasoning when fine-grained ship types are recognizable to the human eye and offers interpretable explanations when they are not.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.5 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 3.7 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Federated Learning: 1.8 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.0978
            </span>
            <a href="https://arxiv.org/abs/2504.08104" target="_blank" rel="noopener noreferrer">Geneshift: Impact of different scenario shift on Jailbreaking LLM</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Tianyi Wu, Zhiwei Xue, Yue Liu, Jiaheng Zhang, Bryan Hooi, See-Kiong Ng | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Jailbreak attacks, which aim to cause LLMs to perform unrestricted behaviors, have become a critical and challenging direction in AI safety. Despite achieving the promising attack success rate using dictionary-based evaluation, existing jailbreak attack methods fail to output detailed contents to sa</span>
            
            <span class="abstract-full" style="display: none;">Jailbreak attacks, which aim to cause LLMs to perform unrestricted behaviors, have become a critical and challenging direction in AI safety. Despite achieving the promising attack success rate using dictionary-based evaluation, existing jailbreak attack methods fail to output detailed contents to satisfy the harmful request, leading to poor performance on GPT-based evaluation. To this end, we propose a black-box jailbreak attack termed GeneShift, by using a genetic algorithm to optimize the scenario shifts. Firstly, we observe that the malicious queries perform optimally under different scenario shifts. Based on it, we develop a genetic algorithm to evolve and select the hybrid of scenario shifts. It guides our method to elicit detailed and actionable harmful responses while keeping the seemingly benign facade, improving stealthiness. Extensive experiments demonstrate the superiority of GeneShift. Notably, GeneShift increases the jailbreak success rate from 0% to 60% when direct prompting alone would fail.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.1 -->
                
            <!-- Medicine: 4.8 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- Reinforcement Learning: 2.2 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.0988
            </span>
            <a href="https://arxiv.org/abs/2504.08278" target="_blank" rel="noopener noreferrer">Interior Point Differential Dynamic Programming, Redux</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Ming Xu, Stephen Gould, Iman Shames | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We present IPDDP2, a structure-exploiting algorithm for solving discrete-time, finite horizon optimal control problems with nonlinear constraints. Inequality constraints are handled using a primal-dual interior point formulation and step acceptance for equality constraints follows a line-search filt</span>
            
            <span class="abstract-full" style="display: none;">We present IPDDP2, a structure-exploiting algorithm for solving discrete-time, finite horizon optimal control problems with nonlinear constraints. Inequality constraints are handled using a primal-dual interior point formulation and step acceptance for equality constraints follows a line-search filter approach. The iterates of the algorithm are derived under the Differential Dynamic Programming (DDP) framework. Our numerical experiments evaluate IPDDP2 on four robotic motion planning problems. IPDDP2 reliably converges to low optimality error and exhibits local quadratic and global convergence from remote starting points. Notably, we showcase the robustness of IPDDP2 by using it to solve a contact-implicit, joint limited acrobot swing-up problem involving complementarity constraints from a range of initial conditions. We provide a full implementation of IPDDP2 in the Julia programming language.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.6 -->
                
            <!-- Medicine: 4.5 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- Math: 2.0 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Robotics: 1.8 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1013
            </span>
            <a href="https://arxiv.org/abs/2504.08222" target="_blank" rel="noopener noreferrer">F$^3$Set: Towards Analyzing Fast, Frequent, and Fine-grained Events from Videos</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Zhaoyu Liu, Kan Jiang, Murong Ma, Zhe Hou, Yun Lin, Jin Song Dong | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Analyzing Fast, Frequent, and Fine-grained (F$^3$) events presents a significant challenge in video analytics and multi-modal LLMs. Current methods struggle to identify events that satisfy all the F$^3$ criteria with high accuracy due to challenges such as motion blur and subtle visual discrepancies</span>
            
            <span class="abstract-full" style="display: none;">Analyzing Fast, Frequent, and Fine-grained (F$^3$) events presents a significant challenge in video analytics and multi-modal LLMs. Current methods struggle to identify events that satisfy all the F$^3$ criteria with high accuracy due to challenges such as motion blur and subtle visual discrepancies. To advance research in video understanding, we introduce F$^3$Set, a benchmark that consists of video datasets for precise F$^3$ event detection. Datasets in F$^3$Set are characterized by their extensive scale and comprehensive detail, usually encompassing over 1,000 event types with precise timestamps and supporting multi-level granularity. Currently, F$^3$Set contains several sports datasets, and this framework may be extended to other applications as well. We evaluated popular temporal action understanding methods on F$^3$Set, revealing substantial challenges for existing techniques. Additionally, we propose a new method, F$^3$ED, for F$^3$ event detections, achieving superior performance. The dataset, model, and benchmark code are available at https://github.com/F3Set/F3Set.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.8 -->
                
            <!-- Medicine: 4.4 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Robotics: 1.9 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1015
            </span>
            <a href="https://arxiv.org/abs/2504.08621" target="_blank" rel="noopener noreferrer">MooseAgent: A LLM Based Multi-agent Framework for Automating Moose Simulation</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Tao Zhang, Zhenhai Liu, Yong Xin, Yongjun Jiao | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">The Finite Element Method (FEM) is widely used in engineering and scientific computing, but its pre-processing, solver configuration, and post-processing stages are often time-consuming and require specialized knowledge. This paper proposes an automated solution framework, MooseAgent, for the multi-</span>
            
            <span class="abstract-full" style="display: none;">The Finite Element Method (FEM) is widely used in engineering and scientific computing, but its pre-processing, solver configuration, and post-processing stages are often time-consuming and require specialized knowledge. This paper proposes an automated solution framework, MooseAgent, for the multi-physics simulation framework MOOSE, which combines large-scale pre-trained language models (LLMs) with a multi-agent system. The framework uses LLMs to understand user-described simulation requirements in natural language and employs task decomposition and multi-round iterative verification strategies to automatically generate MOOSE input files. To improve accuracy and reduce model hallucinations, the system builds and utilizes a vector database containing annotated MOOSE input cards and function documentation. We conducted experimental evaluations on several typical cases, including heat transfer, mechanics, phase field, and multi-physics coupling. The results show that MooseAgent can automate the MOOSE simulation process to a certain extent, especially demonstrating a high success rate when dealing with relatively simple single-physics problems. The main contribution of this research is the proposal of a multi-agent automated framework for MOOSE, which validates its potential in simplifying finite element simulation processes and lowering the user barrier, providing new ideas for the development of intelligent finite element simulation software. The code for the MooseAgent framework proposed in this paper has been open-sourced and is available at https://github.com/taozhan18/MooseAgent</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.5 -->
                
            <!-- Medicine: 4.5 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- Math: 2.0 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1019
            </span>
            <a href="https://arxiv.org/abs/2412.04942" target="_blank" rel="noopener noreferrer">A Federated Approach to Few-Shot Hate Speech Detection for Marginalized Communities</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Haotian Ye, Axel Wisiorek, Antonis Maronikolakis, \"Ozge Ala\c{c}am, Hinrich Sch\"utze | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Hate speech online remains an understudied issue for marginalized communities, particularly in the Global South, which includes developing societies with increasing internet penetration. In this paper, we aim to provide marginalized communities in societies where the dominant language is low-resourc</span>
            
            <span class="abstract-full" style="display: none;">Hate speech online remains an understudied issue for marginalized communities, particularly in the Global South, which includes developing societies with increasing internet penetration. In this paper, we aim to provide marginalized communities in societies where the dominant language is low-resource with a privacy-preserving tool to protect themselves from online hate speech by filtering offensive content in their native languages. Our contributions are twofold: 1) we release REACT (REsponsive hate speech datasets Across ConTexts), a collection of high-quality, culture-specific hate speech detection datasets comprising multiple target groups and low-resource languages, curated by experienced data collectors; 2) we propose a few-shot hate speech detection approach based on federated learning (FL), a privacy-preserving method for collaboratively training a central model that exhibits robustness when tackling different target groups and languages. By keeping training local to user devices, we ensure data privacy while leveraging the collective learning benefits of FL. Furthermore, we explore personalized client models tailored to specific target groups and evaluate their performance. Our findings indicate the overall effectiveness of FL across different target groups, and point to personalization as a promising direction.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.3 -->
                
            <!-- Medicine: 4.3 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- Federated Learning: 1.7 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1029
            </span>
            <a href="https://arxiv.org/abs/2502.17793" target="_blank" rel="noopener noreferrer">SYNTHIA: Novel Concept Design with Affordance Composition</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Hyeonjeong Ha, Xiaomeng Jin, Jeonghwan Kim, Jiateng Liu, Zhenhailong Wang, Khanh Duy Nguyen, Ansel Blume, Nanyun Peng, Kai-Wei Chang, Heng Ji | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Text-to-image (T2I) models enable rapid concept design, making them widely used in AI-driven design. While recent studies focus on generating semantic and stylistic variations of given design concepts, functional coherence--the integration of multiple affordances into a single coherent concept--rema</span>
            
            <span class="abstract-full" style="display: none;">Text-to-image (T2I) models enable rapid concept design, making them widely used in AI-driven design. While recent studies focus on generating semantic and stylistic variations of given design concepts, functional coherence--the integration of multiple affordances into a single coherent concept--remains largely overlooked. In this paper, we introduce SYNTHIA, a framework for generating novel, functionally coherent designs based on desired affordances. Our approach leverages a hierarchical concept ontology that decomposes concepts into parts and affordances, serving as a crucial building block for functionally coherent design. We also develop a curriculum learning scheme based on our ontology that contrastively fine-tunes T2I models to progressively learn affordance composition while maintaining visual novelty. To elaborate, we (i) gradually increase affordance distance, guiding models from basic concept-affordance association to complex affordance compositions that integrate parts of distinct affordances into a single, coherent form, and (ii) enforce visual novelty by employing contrastive objectives to push learned representations away from existing concepts. Experimental results show that SYNTHIA outperforms state-of-the-art T2I models, demonstrating absolute gains of 25.1% and 14.7% for novelty and functional coherence in human evaluation, respectively.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.8 -->
                
            <!-- Medicine: 4.5 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- GNN: 2.2 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Evolutionary Algorithms: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1047
            </span>
            <a href="https://arxiv.org/abs/2504.07589" target="_blank" rel="noopener noreferrer">Copy-and-Paste? Identifying EVM-Inequivalent Code Smells in Multi-chain Reuse Contracts</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Zexu Wang, Jiachi Chen, Tao Zhang, Yu Zhang, Weizhe Zhang, Yuming Feng, Zibin Zheng | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">As the development of Solidity contracts on Ethereum, more developers are reusing them on other compatible blockchains. However, developers may overlook the differences between the designs of the blockchain system, such as the Gas Mechanism and Consensus Protocol, leading to the same contracts on di</span>
            
            <span class="abstract-full" style="display: none;">As the development of Solidity contracts on Ethereum, more developers are reusing them on other compatible blockchains. However, developers may overlook the differences between the designs of the blockchain system, such as the Gas Mechanism and Consensus Protocol, leading to the same contracts on different blockchains not being able to achieve consistent execution as on Ethereum. This inconsistency reveals design flaws in reused contracts, exposing code smells that hinder code reusability, and we define this inconsistency as EVM-Inequivalent Code Smells. In this paper, we conducted the first empirical study to reveal the causes and characteristics of EVM-Inequivalent Code Smells. To ensure the identified smells reflect real developer concerns, we collected and analyzed 1,379 security audit reports and 326 Stack Overflow posts related to reused contracts on EVM-compatible blockchains, such as Binance Smart Chain (BSC) and Polygon. Using the open card sorting method, we defined six types of EVM-Inequivalent Code Smells. For automated detection, we developed a tool named EquivGuard. It employs static taint analysis to identify key paths from different patterns and uses symbolic execution to verify path reachability. Our analysis of 905,948 contracts across six major blockchains shows that EVM-Inequivalent Code Smells are widespread, with an average prevalence of 17.70%. While contracts with code smells do not necessarily lead to financial loss and attacks, their high prevalence and significant asset management underscore the potential threats of reusing these smelly Ethereum contracts. Thus, developers are advised to abandon Copy-and-Paste programming practices and detect EVM-Inequivalent Code Smells before reusing Ethereum contracts.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.3 -->
                
            <!-- Medicine: 4.4 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.0 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1137
            </span>
            <a href="https://arxiv.org/abs/2504.08075" target="_blank" rel="noopener noreferrer">Programs as Singularities</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Daniel Murfet, Will Troiani | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We develop a correspondence between the structure of Turing machines and the structure of singularities of real analytic functions, based on connecting the Ehrhard-Regnier derivative from linear logic with the role of geometry in Watanabe's singular learning theory. The correspondence works by embed</span>
            
            <span class="abstract-full" style="display: none;">We develop a correspondence between the structure of Turing machines and the structure of singularities of real analytic functions, based on connecting the Ehrhard-Regnier derivative from linear logic with the role of geometry in Watanabe's singular learning theory. The correspondence works by embedding ordinary (discrete) Turing machine codes into a family of noisy codes which form a smooth parameter space. On this parameter space we consider a potential function which has Turing machines as critical points. By relating the Taylor series expansion of this potential at such a critical point to combinatorics of error syndromes, we relate the local geometry to internal structure of the Turing machine.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.1 -->
                
            <!-- Medicine: 4.4 -->
                
            <!-- Quantum Computing: 4.1 -->
                
            <!-- Networks: 2.9 -->
                
            <!-- Math: 2.2 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- GNN: 1.7 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Hardware: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1164
            </span>
            <a href="https://arxiv.org/abs/2504.08006" target="_blank" rel="noopener noreferrer">A Python toolkit for dealing with Petri nets over ontological graphs</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Krzysztof Pancerz | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We present theoretical rudiments of Petri nets over ontological graphs as well as the designed and implemented Python toolkit for dealing with such nets. In Petri nets over ontological graphs, the domain knowledge is enclosed in a form of ontologies. In this way, some valuable knowledge (especially </span>
            
            <span class="abstract-full" style="display: none;">We present theoretical rudiments of Petri nets over ontological graphs as well as the designed and implemented Python toolkit for dealing with such nets. In Petri nets over ontological graphs, the domain knowledge is enclosed in a form of ontologies. In this way, some valuable knowledge (especially in terms of semantic relations) can be added to model reasoning and control processes by means of Petri nets. In the implemented approach, ontological graphs are obtained from ontologies built in accordance with the OWL 2 Web Ontology Language. The implemented tool enables the users to define the structure and dynamics of Petri nets over ontological graphs.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.8 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- Reinforcement Learning: 2.2 -->
                
            <!-- Math: 2.0 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Robotics: 1.8 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1218
            </span>
            <a href="https://arxiv.org/abs/2504.07951" target="_blank" rel="noopener noreferrer">Scaling Laws for Native Multimodal Models</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Mustafa Shukor, Enrico Fini, Victor Guilherme Turrisi da Costa, Matthieu Cord, Joshua Susskind, Alaaeldin El-Nouby | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Building general-purpose models that can effectively perceive the world through multimodal signals has been a long-standing goal. Current approaches involve integrating separately pre-trained components, such as connecting vision encoders to LLMs and continuing multimodal training. While such approa</span>
            
            <span class="abstract-full" style="display: none;">Building general-purpose models that can effectively perceive the world through multimodal signals has been a long-standing goal. Current approaches involve integrating separately pre-trained components, such as connecting vision encoders to LLMs and continuing multimodal training. While such approaches exhibit remarkable sample efficiency, it remains an open question whether such late-fusion architectures are inherently superior. In this work, we revisit the architectural design of native multimodal models (NMMs)--those trained from the ground up on all modalities--and conduct an extensive scaling laws study, spanning 457 trained models with different architectures and training mixtures. Our investigation reveals no inherent advantage to late-fusion architectures over early-fusion ones, which do not rely on image encoders. On the contrary, early-fusion exhibits stronger performance at lower parameter counts, is more efficient to train, and is easier to deploy. Motivated by the strong performance of the early-fusion architectures, we show that incorporating Mixture of Experts (MoEs) allows for models that learn modality-specific weights, significantly enhancing performance.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.0 -->
                
            <!-- Medicine: 4.5 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Networks: 3.0 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Federated Learning: 1.8 -->
                
            <!-- Reinforcement Learning: 1.7 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1254
            </span>
            <a href="https://arxiv.org/abs/2504.08470" target="_blank" rel="noopener noreferrer">On the Design of Diffusion-based Neural Speech Codecs</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Pietro Foti, Andreas Brendel | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Recently, neural speech codecs (NSCs) trained as generative models have shown superior performance compared to conventional codecs at low bitrates. Although most state-of-the-art NSCs are trained as Generative Adversarial Networks (GANs), Diffusion Models (DMs), a recent class of generative models, </span>
            
            <span class="abstract-full" style="display: none;">Recently, neural speech codecs (NSCs) trained as generative models have shown superior performance compared to conventional codecs at low bitrates. Although most state-of-the-art NSCs are trained as Generative Adversarial Networks (GANs), Diffusion Models (DMs), a recent class of generative models, represent a promising alternative due to their superior performance in image generation relative to GANs. Consequently, DMs have been successfully applied for audio and speech coding among various other audio generation applications. However, the design of diffusion-based NSCs has not yet been explored in a systematic way. We address this by providing a comprehensive analysis of diffusion-based NSCs divided into three contributions. First, we propose a categorization based on the conditioning and output domains of the DM. This simple conceptual framework allows us to define a design space for diffusion-based NSCs and to assign a category to existing approaches in the literature. Second, we systematically investigate unexplored designs by creating and evaluating new diffusion-based NSCs within the conceptual framework. Finally, we compare the proposed models to existing GAN and DM baselines through objective metrics and subjective listening tests.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.1 -->
                
            <!-- Medicine: 5.0 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.8 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.132
            </span>
            <a href="https://arxiv.org/abs/2504.07583" target="_blank" rel="noopener noreferrer">Do LLMs Understand Your Translations? Evaluating Paragraph-level MT with Question Answering</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Patrick Fernandes, Sweta Agrawal, Emmanouil Zaranis, Andr\'e F. T. Martins, Graham Neubig | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Despite the steady progress in machine translation evaluation, existing automatic metrics struggle to capture how well meaning is preserved beyond sentence boundaries. We posit that reliance on a single intrinsic quality score, trained to mimic human judgments, might be insufficient for evaluating t</span>
            
            <span class="abstract-full" style="display: none;">Despite the steady progress in machine translation evaluation, existing automatic metrics struggle to capture how well meaning is preserved beyond sentence boundaries. We posit that reliance on a single intrinsic quality score, trained to mimic human judgments, might be insufficient for evaluating translations of long, complex passages, and a more ``pragmatic'' approach that assesses how accurately key information is conveyed by a translation in context is needed. We introduce TREQA (Translation Evaluation via Question-Answering), a framework that extrinsically evaluates translation quality by assessing how accurately candidate translations answer reading comprehension questions that target key information in the original source or reference texts. In challenging domains that require long-range understanding, such as literary texts, we show that TREQA is competitive with and, in some cases, outperforms state-of-the-art neural and LLM-based metrics in ranking alternative paragraph-level translations, despite never being explicitly optimized to correlate with human judgments. Furthermore, the generated questions and answers offer interpretability: empirical analysis shows that they effectively target translation errors identified by experts in evaluated datasets. Our code is available at https://github.com/deep-spin/treqa</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.1 -->
                
            <!-- Medicine: 4.5 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Math: 2.0 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Robotics: 1.8 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1327
            </span>
            <a href="https://arxiv.org/abs/2501.18998" target="_blank" rel="noopener noreferrer">Adversarial Attacks on AI-Generated Text Detection Models: A Token Probability-Based Approach Using Embeddings</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Ahmed K. Kadhim, Lei Jiao, Rishad Shafik, Ole-Christoffer Granmo | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">In recent years, text generation tools utilizing Artificial Intelligence (AI) have occasionally been misused across various domains, such as generating student reports or creative writings. This issue prompts plagiarism detection services to enhance their capabilities in identifying AI-generated con</span>
            
            <span class="abstract-full" style="display: none;">In recent years, text generation tools utilizing Artificial Intelligence (AI) have occasionally been misused across various domains, such as generating student reports or creative writings. This issue prompts plagiarism detection services to enhance their capabilities in identifying AI-generated content. Adversarial attacks are often used to test the robustness of AI-text generated detectors. This work proposes a novel textual adversarial attack on the detection models such as Fast-DetectGPT. The method employs embedding models for data perturbation, aiming at reconstructing the AI generated texts to reduce the likelihood of detection of the true origin of the texts. Specifically, we employ different embedding techniques, including the Tsetlin Machine (TM), an interpretable approach in machine learning for this purpose. By combining synonyms and embedding similarity vectors, we demonstrates the state-of-the-art reduction in detection scores against Fast-DetectGPT. Particularly, in the XSum dataset, the detection score decreased from 0.4431 to 0.2744 AUROC, and in the SQuAD dataset, it dropped from 0.5068 to 0.3532 AUROC.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.1 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- Math: 1.9 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- SpikingNN: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1332
            </span>
            <a href="https://arxiv.org/abs/2504.08264" target="_blank" rel="noopener noreferrer">To See or Not to See -- Fingerprinting Devices in Adversarial Environments Amid Advanced Machine Learning</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Justin Feng, Nader Sehatbakhsh | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">The increasing use of the Internet of Things raises security concerns. To address this, device fingerprinting is often employed to authenticate devices, detect adversaries, and identify eavesdroppers in an environment. This requires the ability to discern between legitimate and malicious devices whi</span>
            
            <span class="abstract-full" style="display: none;">The increasing use of the Internet of Things raises security concerns. To address this, device fingerprinting is often employed to authenticate devices, detect adversaries, and identify eavesdroppers in an environment. This requires the ability to discern between legitimate and malicious devices which is achieved by analyzing the unique physical and/or operational characteristics of IoT devices. In the era of the latest progress in machine learning, particularly generative models, it is crucial to methodically examine the current studies in device fingerprinting. This involves explaining their approaches and underscoring their limitations when faced with adversaries armed with these ML tools. To systematically analyze existing methods, we propose a generic, yet simplified, model for device fingerprinting. Additionally, we thoroughly investigate existing methods to authenticate devices and detect eavesdropping, using our proposed model. We further study trends and similarities between works in authentication and eavesdropping detection and present the existing threats and attacks in these domains. Finally, we discuss future directions in fingerprinting based on these trends to develop more secure IoT fingerprinting schemes.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.1 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Networks: 3.6 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Math: 2.0 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1348
            </span>
            <a href="https://arxiv.org/abs/2504.08725" target="_blank" rel="noopener noreferrer">DocAgent: A Multi-Agent System for Automated Code Documentation Generation</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Dayu Yang, Antoine Simoulin, Xin Qian, Xiaoyi Liu, Yuwei Cao, Zhaopu Teng, Grey Yang | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">High-quality code documentation is crucial for software development especially in the era of AI. However, generating it automatically using Large Language Models (LLMs) remains challenging, as existing approaches often produce incomplete, unhelpful, or factually incorrect outputs. We introduce DocAg</span>
            
            <span class="abstract-full" style="display: none;">High-quality code documentation is crucial for software development especially in the era of AI. However, generating it automatically using Large Language Models (LLMs) remains challenging, as existing approaches often produce incomplete, unhelpful, or factually incorrect outputs. We introduce DocAgent, a novel multi-agent collaborative system using topological code processing for incremental context building. Specialized agents (Reader, Searcher, Writer, Verifier, Orchestrator) then collaboratively generate documentation. We also propose a multi-faceted evaluation framework assessing Completeness, Helpfulness, and Truthfulness. Comprehensive experiments show DocAgent significantly outperforms baselines consistently. Our ablation study confirms the vital role of the topological processing order. DocAgent offers a robust approach for reliable code documentation generation in complex and proprietary repositories.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.7 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1364
            </span>
            <a href="https://arxiv.org/abs/2504.03976" target="_blank" rel="noopener noreferrer">OLAF: An Open Life Science Analysis Framework for Conversational Bioinformatics Powered by Large Language Models</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Dylan Riffle, Nima Shirooni, Cody He, Manush Murali, Sovit Nayak, Rishikumar Gopalan, Diego Gonzalez Lopez | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">OLAF (Open Life Science Analysis Framework) is an open-source platform that enables researchers to perform bioinformatics analyses using natural language. By combining large language models (LLMs) with a modular agent-pipe-router architecture, OLAF generates and executes bioinformatics code on real </span>
            
            <span class="abstract-full" style="display: none;">OLAF (Open Life Science Analysis Framework) is an open-source platform that enables researchers to perform bioinformatics analyses using natural language. By combining large language models (LLMs) with a modular agent-pipe-router architecture, OLAF generates and executes bioinformatics code on real scientific data, including formats like .h5ad. The system includes an Angular front end and a Python/Firebase backend, allowing users to run analyses such as single-cell RNA-seq workflows, gene annotation, and data visualization through a simple web interface. Unlike general-purpose AI tools, OLAF integrates code execution, data handling, and scientific libraries in a reproducible, user-friendly environment. It is designed to lower the barrier to computational biology for non-programmers and support transparent, AI-powered life science research.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 9.4 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1405
            </span>
            <a href="https://arxiv.org/abs/2504.08157" target="_blank" rel="noopener noreferrer">A GPU-accelerated simulation of rapid intensification of a tropical cyclone with observed heating</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Soonpil Kang, Francis X. Giraldo, Seth Camp | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">This paper presents a limited-area atmospheric simulation of a tropical cyclone accelerated using GPUs. The OpenACC directive-based programming model is used to port the atmospheric model to the GPU. The GPU implementation of the main functions and kernels is discussed. The GPU-accelerated code prod</span>
            
            <span class="abstract-full" style="display: none;">This paper presents a limited-area atmospheric simulation of a tropical cyclone accelerated using GPUs. The OpenACC directive-based programming model is used to port the atmospheric model to the GPU. The GPU implementation of the main functions and kernels is discussed. The GPU-accelerated code produces high-fidelity simulations of a realistic tropical cyclone forced by observational latent heating. Performance tests show that the GPU-accelerated code yields energy-efficient simulations and scales well in both the strong and weak limit.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.3 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Networks: 3.9 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Math: 2.1 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.141
            </span>
            <a href="https://arxiv.org/abs/2504.08615" target="_blank" rel="noopener noreferrer">Tactile sensing enables vertical obstacle negotiation for elongate many-legged robots</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Juntao He, Baxi Chong, Vincent R Nienhusser, Massimiliano Iaschi, Sehoon Ha, Daniel I. Goldman | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Many-legged elongated robots show promise for reliable mobility on rugged landscapes. However, most studies on these systems focus on motion planning in the 2D horizontal plane (e.g., translation and rotation) without addressing rapid vertical motion. Despite their success on mild rugged terrains, r</span>
            
            <span class="abstract-full" style="display: none;">Many-legged elongated robots show promise for reliable mobility on rugged landscapes. However, most studies on these systems focus on motion planning in the 2D horizontal plane (e.g., translation and rotation) without addressing rapid vertical motion. Despite their success on mild rugged terrains, recent field tests reveal a critical need for 3D behaviors (e.g., climbing or traversing tall obstacles) in real-world application. The challenges of 3D motion planning partially lie in designing sensing and control for a complex high-degree-of-freedom system, typically with over 25 degrees of freedom. To address the first challenge, we propose a tactile antenna system that enables the robot to probe obstacles and gather information about the structure of the environment. Building on this sensory input, we develop a control framework that integrates data from the antenna and foot contact sensors to dynamically adjust the robot's vertical body undulation for effective climbing. With the addition of simple, low-bandwidth tactile sensors, a robot with high static stability and redundancy exhibits predictable climbing performance in complex environments using a simple feedback controller. Laboratory and outdoor experiments demonstrate the robot's ability to climb obstacles up to five times its height. Moreover, the robot exhibits robust climbing capabilities on obstacles covered with flowable, robot-sized random items and those characterized by rapidly changing curvatures. These findings demonstrate an alternative solution to perceive the environment and facilitate effective response for legged robots, paving ways towards future highly capable, low-profile many-legged robots.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.5 -->
                
            <!-- Medicine: 5.3 -->
                
            <!-- Quantum Computing: 3.7 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 1.9 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1467
            </span>
            <a href="https://arxiv.org/abs/2503.17604" target="_blank" rel="noopener noreferrer">OmniScience: A Domain-Specialized LLM for Scientific Reasoning and Discovery</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Vignesh Prabhakar, Md Amirul Islam, Adam Atanas, Yao-Ting Wang, Joah Han, Aastha Jhunjhunwala, Rucha Apte, Robert Clark, Kang Xu, Zihan Wang, Kai Liu | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Large Language Models (LLMs) have demonstrated remarkable potential in advancing scientific knowledge and addressing complex challenges. In this work, we introduce OmniScience, a specialized large reasoning model for general science, developed through three key components: (1) domain adaptive pretra</span>
            
            <span class="abstract-full" style="display: none;">Large Language Models (LLMs) have demonstrated remarkable potential in advancing scientific knowledge and addressing complex challenges. In this work, we introduce OmniScience, a specialized large reasoning model for general science, developed through three key components: (1) domain adaptive pretraining on a carefully curated corpus of scientific literature, (2) instruction tuning on a specialized dataset to guide the model in following domain-specific tasks, and (3) reasoning-based knowledge distillation through fine-tuning to significantly enhance its ability to generate contextually relevant and logically sound responses. We demonstrate the versatility of OmniScience by developing a battery agent that efficiently ranks molecules as potential electrolyte solvents or additives. Comprehensive evaluations reveal that OmniScience is competitive with state-of-the-art large reasoning models on the GPQA Diamond and domain-specific battery benchmarks, while outperforming all public reasoning and non-reasoning models with similar parameter counts. We further demonstrate via ablation experiments that domain adaptive pretraining and reasoning-based knowledge distillation are critical to attain our performance levels, across benchmarks.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 10.7 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- T2I: 1.4 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.148
            </span>
            <a href="https://arxiv.org/abs/2504.08344" target="_blank" rel="noopener noreferrer">EasyGenNet: An Efficient Framework for Audio-Driven Gesture Video Generation Based on Diffusion Model</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Renda Li, Xiaohua Qi, Qiang Ling, Jun Yu, Ziyi Chen, Peng Chang, Mei HanJing Xiao | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Audio-driven cospeech video generation typically involves two stages: speech-to-gesture and gesture-to-video. While significant advances have been made in speech-to-gesture generation, synthesizing natural expressions and gestures remains challenging in gesture-to-video systems. In order to improve </span>
            
            <span class="abstract-full" style="display: none;">Audio-driven cospeech video generation typically involves two stages: speech-to-gesture and gesture-to-video. While significant advances have been made in speech-to-gesture generation, synthesizing natural expressions and gestures remains challenging in gesture-to-video systems. In order to improve the generation effect, previous works adopted complex input and training strategies and required a large amount of data sets for pre-training, which brought inconvenience to practical applications. We propose a simple one-stage training method and a temporal inference method based on a diffusion model to synthesize realistic and continuous gesture videos without the need for additional training of temporal modules.The entire model makes use of existing pre-trained weights, and only a few thousand frames of data are needed for each character at a time to complete fine-tuning. Built upon the video generator, we introduce a new audio-to-video pipeline to synthesize co-speech videos, using 2D human skeleton as the intermediate motion representation. Our experiments show that our method outperforms existing GAN-based and diffusion-based methods.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.1 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 3.7 -->
                
            <!-- Networks: 3.6 -->
                
            <!-- GNN: 2.3 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- T2I: 1.4 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1482
            </span>
            <a href="https://arxiv.org/abs/2412.13478" target="_blank" rel="noopener noreferrer">Efficient Fine-Tuning of Single-Cell Foundation Models Enables Zero-Shot Molecular Perturbation Prediction</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Sepideh Maleki, Jan-Christian Huetter, Kangway V. Chuang, David Richmond, Gabriele Scalia, Tommaso Biancalani | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Predicting transcriptional responses to novel drugs provides a unique opportunity to accelerate biomedical research and advance drug discovery efforts. However, the inherent complexity and high dimensionality of cellular responses, combined with the extremely limited available experimental data, mak</span>
            
            <span class="abstract-full" style="display: none;">Predicting transcriptional responses to novel drugs provides a unique opportunity to accelerate biomedical research and advance drug discovery efforts. However, the inherent complexity and high dimensionality of cellular responses, combined with the extremely limited available experimental data, makes the task challenging. In this study, we leverage single-cell foundation models (FMs) pre-trained on tens of millions of single cells, encompassing multiple cell types, states, and disease annotations, to address molecular perturbation prediction. We introduce a drug-conditional adapter that allows efficient fine-tuning by training less than 1% of the original foundation model, thus enabling molecular conditioning while preserving the rich biological representation learned during pre-training. The proposed strategy allows not only the prediction of cellular responses to novel drugs, but also the zero-shot generalization to unseen cell lines. We establish a robust evaluation framework to assess model performance across different generalization tasks, demonstrating state-of-the-art results across all settings, with significant improvements in the few-shot and zero-shot generalization to new cell lines compared to existing baselines.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.1 -->
                
            <!-- Medicine: 5.2 -->
                
            <!-- Quantum Computing: 3.7 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1512
            </span>
            <a href="https://arxiv.org/abs/2503.05659" target="_blank" rel="noopener noreferrer">A Survey of Large Language Model Empowered Agents for Recommendation and Search: Towards Next-Generation Information Retrieval</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Yu Zhang, Shutong Qiao, Jiaqi Zhang, Tzu-Heng Lin, Chen Gao, Yong Li | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Information technology has profoundly altered the way humans interact with information. The vast amount of content created, shared, and disseminated online has made it increasingly difficult to access relevant information. Over the past two decades, recommender systems and search (collectively refer</span>
            
            <span class="abstract-full" style="display: none;">Information technology has profoundly altered the way humans interact with information. The vast amount of content created, shared, and disseminated online has made it increasingly difficult to access relevant information. Over the past two decades, recommender systems and search (collectively referred to as information retrieval systems) have evolved significantly to address these challenges. Recent advances in large language models (LLMs) have demonstrated capabilities that surpass human performance in various language-related tasks and exhibit general understanding, reasoning, and decision-making abilities. This paper explores the transformative potential of LLM agents in enhancing recommender and search systems. We discuss the motivations and roles of LLM agents, and establish a classification framework to elaborate on the existing research. We highlight the immense potential of LLM agents in addressing current challenges in recommendation and search, providing insights into future research directions. This paper is the first to systematically review and classify the research on LLM agents in these domains, offering a novel perspective on leveraging this advanced AI technology for information retrieval. To help understand the existing works, we list the existing papers on LLM agent based recommendation and search at this link: https://github.com/tsinghua-fib-lab/LLM-Agent-for-Recommendation-and-Search.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 9.4 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Robotics: 1.8 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.3 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.152
            </span>
            <a href="https://arxiv.org/abs/2504.00614" target="_blank" rel="noopener noreferrer">Learning Bipedal Locomotion on Gear-Driven Humanoid Robot Using Foot-Mounted IMUs</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Sotaro Katayama, Yuta Koda, Norio Nagatsuka, Masaya Kinoshita | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Sim-to-real reinforcement learning (RL) for humanoid robots with high-gear ratio actuators remains challenging due to complex actuator dynamics and the absence of torque sensors. To address this, we propose a novel RL framework leveraging foot-mounted inertial measurement units (IMUs). Instead of pu</span>
            
            <span class="abstract-full" style="display: none;">Sim-to-real reinforcement learning (RL) for humanoid robots with high-gear ratio actuators remains challenging due to complex actuator dynamics and the absence of torque sensors. To address this, we propose a novel RL framework leveraging foot-mounted inertial measurement units (IMUs). Instead of pursuing detailed actuator modeling and system identification, we utilize foot-mounted IMU measurements to enhance rapid stabilization capabilities over challenging terrains. Additionally, we propose symmetric data augmentation dedicated to the proposed observation space and random network distillation to enhance bipedal locomotion learning over rough terrain. We validate our approach through hardware experiments on a miniature-sized humanoid EVAL-03 over a variety of environments. The experimental results demonstrate that our method improves rapid stabilization capabilities over non-rigid surfaces and sudden environmental transitions.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.4 -->
                
            <!-- Medicine: 5.1 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- Reinforcement Learning: 2.3 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1546
            </span>
            <a href="https://arxiv.org/abs/2504.08661" target="_blank" rel="noopener noreferrer">Safe Flow Matching: Robot Motion Planning with Control Barrier Functions</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Xiaobing Dai, Dian Yu, Shanshan Zhang, Zewen Yang | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Recent advances in generative modeling have led to promising results in robot motion planning, particularly through diffusion and flow-based models that capture complex, multimodal trajectory distributions. However, these methods are typically trained offline and remain limited when faced with unsee</span>
            
            <span class="abstract-full" style="display: none;">Recent advances in generative modeling have led to promising results in robot motion planning, particularly through diffusion and flow-based models that capture complex, multimodal trajectory distributions. However, these methods are typically trained offline and remain limited when faced with unseen environments or dynamic constraints, often lacking explicit mechanisms to ensure safety during deployment. In this work, we propose, Safe Flow Matching (SafeFM), a motion planning approach for trajectory generation that integrates flow matching with safety guarantees. By incorporating the proposed flow matching barrier functions, SafeFM ensures that generated trajectories remain within safe regions throughout the planning horizon, even in the presence of previously unseen obstacles or state-action constraints. Unlike diffusion-based approaches, our method allows for direct, efficient sampling of constraint-satisfying trajectories, making it well-suited for real-time motion planning. We evaluate SafeFM on a diverse set of tasks, including planar robot navigation and 7-DoF manipulation, demonstrating superior safety, generalization, and planning performance compared to state-of-the-art generative planners. Comprehensive resources are available on the project website: https://safeflowmatching.github.io/SafeFM/</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.9 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1606
            </span>
            <a href="https://arxiv.org/abs/2502.12615" target="_blank" rel="noopener noreferrer">Generalized Hofstadter functions $G, H$ and beyond: numeration systems and discrepancy</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Pierre Letouzey (IRIF, PICUBE) | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Hofstadter's $G$ function is recursively defined via $G(0)=0$ and then $G(n)=n-G(G(n-1))$. Following Hofstadter, a family $(F_k)$ of similar functions is obtained by varying the number $k$ of nested recursive calls in this equation. We study here some Fibonacci-like sequences that are deeply connect</span>
            
            <span class="abstract-full" style="display: none;">Hofstadter's $G$ function is recursively defined via $G(0)=0$ and then $G(n)=n-G(G(n-1))$. Following Hofstadter, a family $(F_k)$ of similar functions is obtained by varying the number $k$ of nested recursive calls in this equation. We study here some Fibonacci-like sequences that are deeply connected with these functions $F_k$. In particular, the Zeckendorf theorem can be adapted to provide digital expansions via sums of terms of these sequences. On these digital expansions, the functions $F_k$ are acting as right shifts of the digits. These Fibonacci-like sequences can be expressed in terms of zeros of the polynomial $X^k{-}X^{k-1}{-}1$. Considering now the discrepancy of each function $F_k$, i.e., the maximal distance between $F_k$ and its linear equivalent, we retrieve the fact that this discrepancy is finite exactly when $k \le 4$. Thanks to that, we solve two twenty-year-old OEIS conjectures stating how close the functions $F_3$ and $F_4$ are from the integer parts of their linear equivalents. Moreover we establish that $F_k$ can coincide exactly with such an integer part only when $k\le 2$, while $F_k$ is almost additive exactly when $k \le 4$. Finally, a nice fractal shape a la Rauzy has been encountered when investigating the discrepancy of $F_3$. Almost all this article has been formalized and verified in the Coq/Rocq proof assistant.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.8 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- Math: 2.1 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1623
            </span>
            <a href="https://arxiv.org/abs/2504.08678" target="_blank" rel="noopener noreferrer">From "Worse is Better" to Better: Lessons from a Mixed Methods Study of Ansible's Challenges</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Carolina Carreira, Nuno Saavedra, Alexandra Mendes, Jo\~ao F. Ferreira | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Infrastructure as Code (IaC) tools have transformed the way IT infrastructure is automated and managed, but their growing adoption has also exposed numerous challenges for practitioners. In this paper, we investigate these challenges through the lens of Ansible, a popular IaC tool. Using a mixed met</span>
            
            <span class="abstract-full" style="display: none;">Infrastructure as Code (IaC) tools have transformed the way IT infrastructure is automated and managed, but their growing adoption has also exposed numerous challenges for practitioners. In this paper, we investigate these challenges through the lens of Ansible, a popular IaC tool. Using a mixed methods approach, we investigate challenges, obstacles, and issues faced by practitioners. We analyze 59,157 posts from Stack Overflow, Reddit, and the Ansible Forum to identify common pain points, complemented by 16 semi-structured interviews with practitioners of varying expertise levels.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.1 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1627
            </span>
            <a href="https://arxiv.org/abs/2504.08727" target="_blank" rel="noopener noreferrer">Visual Chronicles: Using Multimodal LLMs to Analyze Massive Collections of Images</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Boyang Deng, Songyou Peng, Kyle Genova, Gordon Wetzstein, Noah Snavely, Leonidas Guibas, Thomas Funkhouser | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We present a system using Multimodal LLMs (MLLMs) to analyze a large database with tens of millions of images captured at different times, with the aim of discovering patterns in temporal changes. Specifically, we aim to capture frequent co-occurring changes ("trends") across a city over a certain p</span>
            
            <span class="abstract-full" style="display: none;">We present a system using Multimodal LLMs (MLLMs) to analyze a large database with tens of millions of images captured at different times, with the aim of discovering patterns in temporal changes. Specifically, we aim to capture frequent co-occurring changes ("trends") across a city over a certain period. Unlike previous visual analyses, our analysis answers open-ended queries (e.g., "what are the frequent types of changes in the city?") without any predetermined target subjects or training labels. These properties cast prior learning-based or unsupervised visual analysis tools unsuitable. We identify MLLMs as a novel tool for their open-ended semantic understanding capabilities. Yet, our datasets are four orders of magnitude too large for an MLLM to ingest as context. So we introduce a bottom-up procedure that decomposes the massive visual analysis problem into more tractable sub-problems. We carefully design MLLM-based solutions to each sub-problem. During experiments and ablation studies with our system, we find it significantly outperforms baselines and is able to discover interesting trends from images captured in large cities (e.g., "addition of outdoor dining,", "overpass was painted blue," etc.). See more results and interactive demos at https://boyangdeng.com/visual-chronicles.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.5 -->
                
            <!-- Medicine: 4.5 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Evolutionary Algorithms: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1653
            </span>
            <a href="https://arxiv.org/abs/2405.16297" target="_blank" rel="noopener noreferrer">LUCIE: A Lightweight Uncoupled ClImate Emulator with long-term stability and physical consistency for O(1000)-member ensembles</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Haiwen Guan, Troy Arcomano, Ashesh Chattopadhyay, Romit Maulik | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We present a lightweight, easy-to-train, low-resolution, fully data-driven climate emulator, LUCIE, that can be trained on as low as $2$ years of $6$-hourly ERA5 data. Unlike most state-of-the-art AI weather models, LUCIE remains stable and physically consistent for $100$ years of autoregressive sim</span>
            
            <span class="abstract-full" style="display: none;">We present a lightweight, easy-to-train, low-resolution, fully data-driven climate emulator, LUCIE, that can be trained on as low as $2$ years of $6$-hourly ERA5 data. Unlike most state-of-the-art AI weather models, LUCIE remains stable and physically consistent for $100$ years of autoregressive simulation with $100$ ensemble members. Long-term mean climatology from LUCIE's simulation of temperature, wind, precipitation, and humidity matches that of ERA5 data, along with the variability. We further demonstrate how well extreme weather events and their return periods can be estimated from a large ensemble of long-term simulations. We further discuss an improved training strategy with a hard-constrained first-order integrator to suppress autoregressive error growth, a novel spectral regularization strategy to better capture fine-scale dynamics, and finally an optimization algorithm that enables data-limited (as low as $2$ years of $6$-hourly data) training of the emulator without losing stability and physical consistency. Finally, we provide a scaling experiment to compare the long-term bias of LUCIE with respect to the number of training samples. Importantly, LUCIE is an easy to use model that can be trained in just $2.4$h on a single A-100 GPU, allowing for multiple experiments that can explore important scientific questions that could be answered with large ensembles of long-term simulations, e.g., the impact of different variables on the simulation, dynamic response to external forcing, and estimation of extreme weather events, amongst others.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.0 -->
                
            <!-- Medicine: 5.0 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- Reinforcement Learning: 2.2 -->
                
            <!-- Math: 2.1 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.167
            </span>
            <a href="https://arxiv.org/abs/2107.07440" target="_blank" rel="noopener noreferrer">Polytime Algorithms for One-to-Many Matching Games</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Felipe Garrido-Lucero, Rida Laraki | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Matching games is a novel matching model introduced by Garrido-Lucero and Laraki, in which agents' utilities are endogenously determined as the outcome of a strategic game they play simultaneously with the matching process. Matching games encompass most one-to-one matching market models and reinforc</span>
            
            <span class="abstract-full" style="display: none;">Matching games is a novel matching model introduced by Garrido-Lucero and Laraki, in which agents' utilities are endogenously determined as the outcome of a strategic game they play simultaneously with the matching process. Matching games encompass most one-to-one matching market models and reinforce the classical notion of pairwise stability by analyzing their robustness to unilateral deviations within games. In this article, we extend the model to the one-to-many setting, where hospitals can be matched to multiple doctors, and their utility is given by the sum of their game outcomes. We adapt the deferred acceptance with competitions algorithm and the renegotiation process to this new framework and prove that both are polynomial whenever couples play bi-matrix games in mixed strategies.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.7 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 2.9 -->
                
            <!-- Math: 2.1 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- Hardware: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1678
            </span>
            <a href="https://arxiv.org/abs/2504.08100" target="_blank" rel="noopener noreferrer">ContrastiveGaussian: High-Fidelity 3D Generation with Contrastive Learning and Gaussian Splatting</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Junbang Liu, Enpei Huang, Dongxing Mao, Hui Zhang, Xinyuan Song, Yongxin Ni | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Creating 3D content from single-view images is a challenging problem that has attracted considerable attention in recent years. Current approaches typically utilize score distillation sampling (SDS) from pre-trained 2D diffusion models to generate multi-view 3D representations. Although some methods</span>
            
            <span class="abstract-full" style="display: none;">Creating 3D content from single-view images is a challenging problem that has attracted considerable attention in recent years. Current approaches typically utilize score distillation sampling (SDS) from pre-trained 2D diffusion models to generate multi-view 3D representations. Although some methods have made notable progress by balancing generation speed and model quality, their performance is often limited by the visual inconsistencies of the diffusion model outputs. In this work, we propose ContrastiveGaussian, which integrates contrastive learning into the generative process. By using a perceptual loss, we effectively differentiate between positive and negative samples, leveraging the visual inconsistencies to improve 3D generation quality. To further enhance sample differentiation and improve contrastive learning, we incorporate a super-resolution model and introduce another Quantity-Aware Triplet Loss to address varying sample distributions during training. Our experiments demonstrate that our approach achieves superior texture fidelity and improved geometric consistency.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.5 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Federated Learning: 1.7 -->
                
            <!-- Math: 1.6 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1685
            </span>
            <a href="https://arxiv.org/abs/2504.08258" target="_blank" rel="noopener noreferrer">Accelerating Multi-Objective Collaborative Optimization of Doped Thermoelectric Materials via Artificial Intelligence</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Yuxuan Zeng, Wenhao Xie, Wei Cao, Tan Peng, Yue Hou, Ziyu Wang, Jing Shi | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">The thermoelectric performance of materials exhibits complex nonlinear dependencies on both elemental types and their proportions, rendering traditional trial-and-error approaches inefficient and time-consuming for material discovery. In this work, we present a deep learning model capable of accurat</span>
            
            <span class="abstract-full" style="display: none;">The thermoelectric performance of materials exhibits complex nonlinear dependencies on both elemental types and their proportions, rendering traditional trial-and-error approaches inefficient and time-consuming for material discovery. In this work, we present a deep learning model capable of accurately predicting thermoelectric properties of doped materials directly from their chemical formulas, achieving state-of-the-art performance. To enhance interpretability, we further incorporate sensitivity analysis techniques to elucidate how physical descriptors affect the thermoelectric figure of merit (zT). Moreover, we establish a coupled framework that integrates a surrogate model with a multi-objective genetic algorithm to efficiently explore the vast compositional space for high-performance candidates. Experimental validation confirms the discovery of a novel thermoelectric material with superior $zT$ values in the medium-temperature regime.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.9 -->
                
            <!-- Medicine: 5.2 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1717
            </span>
            <a href="https://arxiv.org/abs/2504.08022" target="_blank" rel="noopener noreferrer">ChildlikeSHAPES: Semantic Hierarchical Region Parsing for Animating Figure Drawings</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Astitva Srivastava, Harrison Jesse Smith, Thu Nguyen-Phuoc, Yuting Ye | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Childlike human figure drawings represent one of humanity's most accessible forms of character expression, yet automatically analyzing their contents remains a significant challenge. While semantic segmentation of realistic humans has recently advanced considerably, existing models often fail when c</span>
            
            <span class="abstract-full" style="display: none;">Childlike human figure drawings represent one of humanity's most accessible forms of character expression, yet automatically analyzing their contents remains a significant challenge. While semantic segmentation of realistic humans has recently advanced considerably, existing models often fail when confronted with the abstract, representational nature of childlike drawings. This semantic understanding is a crucial prerequisite for animation tools that seek to modify figures while preserving their unique style. To help achieve this, we propose a novel hierarchical segmentation model, built upon the architecture and pre-trained SAM, to quickly and accurately obtain these semantic labels. Our model achieves higher accuracy than state-of-the-art segmentation models focused on realistic humans and cartoon figures, even after fine-tuning. We demonstrate the value of our model for semantic segmentation through multiple applications: a fully automatic facial animation pipeline, a figure relighting pipeline, improvements to an existing childlike human figure drawing animation method, and generalization to out-of-domain figures. Finally, to support future work in this area, we introduce a dataset of 16,000 childlike drawings with pixel-level annotations across 25 semantic categories. Our work can enable entirely new, easily accessible tools for hand-drawn character animation, and our dataset can enable new lines of inquiry in a variety of graphics and human-centric research fields.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.9 -->
                
            <!-- Medicine: 5.0 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.0 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Robotics: 1.9 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1754
            </span>
            <a href="https://arxiv.org/abs/2504.08165" target="_blank" rel="noopener noreferrer">Findings of the BabyLM Challenge: Sample-Efficient Pretraining on Developmentally Plausible Corpora</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Alex Warstadt, Aaron Mueller, Leshem Choshen, Ethan Wilcox, Chengxu Zhuang, Juan Ciro, Rafael Mosquera, Bhargavi Paranjape, Adina Williams, Tal Linzen, Ryan Cotterell | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Children can acquire language from less than 100 million words of input. Large language models are far less data-efficient: they typically require 3 or 4 orders of magnitude more data and still do not perform as well as humans on many evaluations. These intensive resource demands limit the ability o</span>
            
            <span class="abstract-full" style="display: none;">Children can acquire language from less than 100 million words of input. Large language models are far less data-efficient: they typically require 3 or 4 orders of magnitude more data and still do not perform as well as humans on many evaluations. These intensive resource demands limit the ability of researchers to train new models and use existing models as developmentally plausible cognitive models. The BabyLM Challenge is a communal effort in which participants compete to optimize language model training on a fixed data budget. Submissions are compared on various evaluation tasks targeting grammatical ability, downstream task performance, and generalization. Participants can submit to up to three tracks with progressively looser data restrictions. From over 30 submissions, we extract concrete recommendations on how best to train data-efficient language models, and on where future efforts should (and perhaps should not) focus. The winning submissions using the LTG-BERT architecture (Samuel et al., 2023) outperformed models trained on trillions of words. Other submissions achieved strong results through training on shorter input sequences or training a student model on a pretrained teacher. Curriculum learning attempts, which accounted for a large number of submissions, were largely unsuccessful, though some showed modest improvements.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.7 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- Robotics: 2.0 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1756
            </span>
            <a href="https://arxiv.org/abs/2504.08137" target="_blank" rel="noopener noreferrer">Empowering Vector Architectures for ML: The CAMP Architecture for Matrix Multiplication</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Mohammadreza Esmali Nojehdeh, Hossein Mokhtarnia, Julian Pavon Rivera, Narcis Rodas Quiroga, Roger Figueras Bagu\'e, Enrico Reggiani, Miquel Moreto, Osman Unsal, Adrian Cristal, Eduard Ayguade | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">This study presents the Cartesian Accumulative Matrix Pipeline (CAMP) architecture, a novel approach designed to enhance matrix multiplication in Vector Architectures (VAs) and Single Instruction Multiple Data (SIMD) units. CAMP improves the processing efficiency of Quantized Neural Networks (QNNs).</span>
            
            <span class="abstract-full" style="display: none;">This study presents the Cartesian Accumulative Matrix Pipeline (CAMP) architecture, a novel approach designed to enhance matrix multiplication in Vector Architectures (VAs) and Single Instruction Multiple Data (SIMD) units. CAMP improves the processing efficiency of Quantized Neural Networks (QNNs). Matrix multiplication is a cornerstone of machine learning applications, and its quantized versions are increasingly popular for more efficient operations. Unfortunately, existing VAs and SIMD-support units struggle to efficiently handle these quantized formats. In this work, we propose CAMP, a simple yet effective architecture that leverages a hybrid multiplier. The CAMP architecture significantly advances the performance of vector architectures in handling quantized data, enabling more efficient execution of matrix multiplication across various platforms, specifically targeting the ARMv8 Scalable Vector Extension (SVE) and edge RISC-V SIMD-based architectures. In addition to increasing throughput, CAMP's architectural design also contributes to energy efficiency, making it an effective solution for low-power applications. Evaluations on a range of Large Language Models (LLMs) and Convolutional Neural Networks (CNNs) demonstrate that matrix multiplication operations using the proposed micro-architecture achieve up to 17$\times$ and 23$\times$ performance improvements compared to their respective baselines, the ARM A64FX core and a RISC-V-based edge System-on-Chip (SoC). Furthermore, synthesis and place-and-route (PnR) of the CAMP micro-architecture using Synopsys tools -- targeting ARM TSMC 7nm for A64FX and GlobalFoundries 22nm for the RISC-V SoC -- add only 1\% and 4\% area overhead, respectively, compared to the baseline designs.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.9 -->
                
            <!-- Medicine: 4.8 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.0 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1771
            </span>
            <a href="https://arxiv.org/abs/2504.08329" target="_blank" rel="noopener noreferrer">MedRep: Medical Concept Representation for General Electronic Health Record Foundation Models</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Junmo Kim, Namkyeong Lee, Jiwon Kim, Kwangsoo Kim | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Electronic health record (EHR) foundation models have been an area ripe for exploration with their improved performance in various medical tasks. Despite the rapid advances, there exists a fundamental limitation: Processing unseen medical codes out of the vocabulary. This problem limits the generali</span>
            
            <span class="abstract-full" style="display: none;">Electronic health record (EHR) foundation models have been an area ripe for exploration with their improved performance in various medical tasks. Despite the rapid advances, there exists a fundamental limitation: Processing unseen medical codes out of the vocabulary. This problem limits the generality of EHR foundation models and the integration of models trained with different vocabularies. To deal with this problem, we propose MedRep for EHR foundation models based on the observational medical outcome partnership (OMOP) common data model (CDM), providing the integrated medical concept representations and the basic data augmentation strategy for patient trajectories. For concept representation learning, we enrich the information of each concept with a minimal definition through large language model (LLM) prompts and enhance the text-based representations through graph ontology of OMOP vocabulary. Trajectory augmentation randomly replaces selected concepts with other similar concepts that have closely related representations to let the model practice with the concepts out-of-vocabulary. Finally, we demonstrate that EHR foundation models trained with MedRep better maintain the prediction performance in external datasets. Our code implementation is publicly available at https://github.com/kicarussays/MedRep.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.3 -->
                
            <!-- Medicine: 5.1 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 1.9 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1774
            </span>
            <a href="https://arxiv.org/abs/2504.08208" target="_blank" rel="noopener noreferrer">How Good Are Large Language Models for Course Recommendation in MOOCs?</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Boxuan Ma, Md Akib Zabed Khan, Tianyuan Yang, Agoritsa Polyzou, Shin'ichi Konomi | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Large Language Models (LLMs) have made significant strides in natural language processing and are increasingly being integrated into recommendation systems. However, their potential in educational recommendation systems has yet to be fully explored. This paper investigates the use of LLMs as a gener</span>
            
            <span class="abstract-full" style="display: none;">Large Language Models (LLMs) have made significant strides in natural language processing and are increasingly being integrated into recommendation systems. However, their potential in educational recommendation systems has yet to be fully explored. This paper investigates the use of LLMs as a general-purpose recommendation model, leveraging their vast knowledge derived from large-scale corpora for course recommendation tasks. We explore a variety of approaches, ranging from prompt-based methods to more advanced fine-tuning techniques, and compare their performance against traditional recommendation models. Extensive experiments were conducted on a real-world MOOC dataset, evaluating using LLMs as course recommendation systems across key dimensions such as accuracy, diversity, and novelty. Our results demonstrate that LLMs can achieve good performance comparable to traditional models, highlighting their potential to enhance educational recommendation systems. These findings pave the way for further exploration and development of LLM-based approaches in the context of educational recommendations.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 12.0 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1791
            </span>
            <a href="https://arxiv.org/abs/2504.01153" target="_blank" rel="noopener noreferrer">Catch Me if You Search: When Contextual Web Search Results Affect the Detection of Hallucinations</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Mahjabin Nahar, Eun-Ju Lee, Jin Won Park, Dongwon Lee | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">While we increasingly rely on large language models (LLMs) for various tasks, these models are known to produce inaccurate content or 'hallucinations' with potentially disastrous consequences. The recent integration of web search results into LLMs prompts the question of whether people utilize them </span>
            
            <span class="abstract-full" style="display: none;">While we increasingly rely on large language models (LLMs) for various tasks, these models are known to produce inaccurate content or 'hallucinations' with potentially disastrous consequences. The recent integration of web search results into LLMs prompts the question of whether people utilize them to verify the generated content, thereby avoiding falling victim to hallucinations. This study (N = 560) investigated how the provision of search results, either static (fixed search results) or dynamic (participant-driven searches), affect participants' perceived accuracy and confidence in evaluating LLM-generated content (i.e., genuine, minor hallucination, major hallucination), compared to the control condition (no search results). Findings indicate that participants in both static and dynamic conditions (vs. control) rated hallucinated content to be less accurate. However, those in the dynamic condition rated genuine content as more accurate and demonstrated greater overall confidence in their assessments than those in the static or control conditions. In addition, those higher in need for cognition (NFC) rated major hallucinations to be less accurate than low NFC participants, with no corresponding difference for genuine content or minor hallucinations. These results underscore the potential benefits of integrating web search results into LLMs for the detection of hallucinations, as well as the need for a more nuanced approach when developing human-centered systems, taking user characteristics into account.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 9.3 -->
                
            <!-- Medicine: 4.5 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- Math: 2.0 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1814
            </span>
            <a href="https://arxiv.org/abs/2504.08126" target="_blank" rel="noopener noreferrer">The nature of loops in programming</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Bertrand Meyer | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">In program semantics and verification, reasoning about loops is complicated by the need to produce two separate mathematical arguments: an invariant, for functional properties (ignoring termination); and a variant, for termination (ignoring functional properties). A single and simple definition is p</span>
            
            <span class="abstract-full" style="display: none;">In program semantics and verification, reasoning about loops is complicated by the need to produce two separate mathematical arguments: an invariant, for functional properties (ignoring termination); and a variant, for termination (ignoring functional properties). A single and simple definition is possible, removing this split. A loop is just the limit (a variant of the reflexive transitive closure) of a Noetherian (well-founded) relation. To prove the loop correct there is no need to devise an invariant and a variant; it suffices to identify the relation, yielding both partial correctness and termination. The present note develops the (small) theory and applies it to standard loop examples and proofs of their correctness.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.6 -->
                
            <!-- Medicine: 5.0 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Networks: 3.7 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1856
            </span>
            <a href="https://arxiv.org/abs/2504.08585" target="_blank" rel="noopener noreferrer">Ready, Bid, Go! On-Demand Delivery Using Fleets of Drones with Unknown, Heterogeneous Energy Storage Constraints</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Mohamed S. Talamali, Genki Miyauchi, Thomas Watteyne, Micael S. Couceiro, Roderich Gross | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Unmanned Aerial Vehicles (UAVs) are expected to transform logistics, reducing delivery time, costs, and emissions. This study addresses an on-demand delivery , in which fleets of UAVs are deployed to fulfil orders that arrive stochastically. Unlike previous work, it considers UAVs with heterogeneous</span>
            
            <span class="abstract-full" style="display: none;">Unmanned Aerial Vehicles (UAVs) are expected to transform logistics, reducing delivery time, costs, and emissions. This study addresses an on-demand delivery , in which fleets of UAVs are deployed to fulfil orders that arrive stochastically. Unlike previous work, it considers UAVs with heterogeneous, unknown energy storage capacities and assumes no knowledge of the energy consumption models. We propose a decentralised deployment strategy that combines auction-based task allocation with online learning. Each UAV independently decides whether to bid for orders based on its energy storage charge level, the parcel mass, and delivery distance. Over time, it refines its policy to bid only for orders within its capability. Simulations using realistic UAV energy models reveal that, counter-intuitively, assigning orders to the least confident bidders reduces delivery times and increases the number of successfully fulfilled orders. This strategy is shown to outperform threshold-based methods which require UAVs to exceed specific charge levels at deployment. We propose a variant of the strategy which uses learned policies for forecasting. This enables UAVs with insufficient charge levels to commit to fulfilling orders at specific future times, helping to prioritise early orders. Our work provides new insights into long-term deployment of UAV swarms, highlighting the advantages of decentralised energy-aware decision-making coupled with online learning in real-world dynamic environments.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.7 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- Math: 2.0 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1863
            </span>
            <a href="https://arxiv.org/abs/2504.07836" target="_blank" rel="noopener noreferrer">AerialVG: A Challenging Benchmark for Aerial Visual Grounding by Exploring Positional Relations</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Junli Liu, Qizhi Chen, Zhigang Wang, Yiwen Tang, Yiting Zhang, Chi Yan, Dong Wang, Xuelong Li, Bin Zhao | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Visual grounding (VG) aims to localize target objects in an image based on natural language descriptions. In this paper, we propose AerialVG, a new task focusing on visual grounding from aerial views. Compared to traditional VG, AerialVG poses new challenges, \emph{e.g.}, appearance-based grounding </span>
            
            <span class="abstract-full" style="display: none;">Visual grounding (VG) aims to localize target objects in an image based on natural language descriptions. In this paper, we propose AerialVG, a new task focusing on visual grounding from aerial views. Compared to traditional VG, AerialVG poses new challenges, \emph{e.g.}, appearance-based grounding is insufficient to distinguish among multiple visually similar objects, and positional relations should be emphasized. Besides, existing VG models struggle when applied to aerial imagery, where high-resolution images cause significant difficulties. To address these challenges, we introduce the first AerialVG dataset, consisting of 5K real-world aerial images, 50K manually annotated descriptions, and 103K objects. Particularly, each annotation in AerialVG dataset contains multiple target objects annotated with relative spatial relations, requiring models to perform comprehensive spatial reasoning. Furthermore, we propose an innovative model especially for the AerialVG task, where a Hierarchical Cross-Attention is devised to focus on target regions, and a Relation-Aware Grounding module is designed to infer positional relations. Experimental results validate the effectiveness of our dataset and method, highlighting the importance of spatial reasoning in aerial visual grounding. The code and dataset will be released.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 9.1 -->
                
            <!-- Medicine: 4.4 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- GNN: 2.2 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.3 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1888
            </span>
            <a href="https://arxiv.org/abs/2412.00034" target="_blank" rel="noopener noreferrer">Data-Driven Prescriptive Analytics Applications: A Comprehensive Survey</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Martin Moesmann, Torben Bach Pedersen | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Prescriptive Analytics (PSA), an emerging business analytics field suggesting concrete options for solving business problems, has seen an increasing amount of interest after more than a decade of multidisciplinary research. This paper is a comprehensive survey of existing applications within PSA in </span>
            
            <span class="abstract-full" style="display: none;">Prescriptive Analytics (PSA), an emerging business analytics field suggesting concrete options for solving business problems, has seen an increasing amount of interest after more than a decade of multidisciplinary research. This paper is a comprehensive survey of existing applications within PSA in terms of their use cases, methodologies, and possible future research directions. To ensure a manageable scope, we focus on PSA applications that develop data-driven, automatic workflows, i.e., Data-Driven PSA (DPSA). Following a systematic methodology, we identify and include 104 papers in our survey. As our key contributions, we derive a number of novel taxonomies of the field and use them to analyse the field's temporal development. In terms of use cases, we derive 10 application domains for DPSA, from Healthcare to Manufacturing, and subsumed problem types within each. In terms of individual method usage, we derive 5 method types and map them to a comprehensive taxonomy of method usage within DPSA applications, covering mathematical optimization, data mining and machine learning, probabilistic modelling, domain expertise, as well as simulations. As for combined method usage, we provide a statistical overview of how different method usage combinations are distributed and derive 2 generic workflow patterns along with subsumed workflow patterns, combining methods by either sequential or simultaneous relationships. Finally, we derive 4 possible research directions based on frequently recurring issues among surveyed papers, suggesting new frontiers in terms of methods, tools, and use cases.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.5 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 4.1 -->
                
            <!-- Networks: 3.7 -->
                
            <!-- Reinforcement Learning: 2.2 -->
                
            <!-- Robotics: 1.9 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1902
            </span>
            <a href="https://arxiv.org/abs/2504.08262" target="_blank" rel="noopener noreferrer">A General DoF and Pattern Analyzing Scheme for Electromagnetic Information Theory</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Zhongzhichao Wan, Jieao Zhu, Yongli Yan, Linglong Dai | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Electromagnetic information theory (EIT) is one of the emerging topics for 6G communication due to its potential to reveal the performance limit of wireless communication systems. For EIT, one of the most important research directions is degree of freedom (DoF) analysis. Existing research works on D</span>
            
            <span class="abstract-full" style="display: none;">Electromagnetic information theory (EIT) is one of the emerging topics for 6G communication due to its potential to reveal the performance limit of wireless communication systems. For EIT, one of the most important research directions is degree of freedom (DoF) analysis. Existing research works on DoF analysis for EIT focus on asymptotic conclusions of DoF, which do not well fit the practical wireless communication systems with finite spatial regions and finite frequency bandwidth. In this paper, we use the theoretical analyzing tools from Slepian concentration problem and extend them to three-dimensional space domain and four-dimensional space-time domain under electromagnetic constraints. Then we provide asymptotic DoF conclusions and non-asymptotic DoF analyzing scheme, which suits practical scenarios better, under different scenarios like three-dimensional antenna array. Moreover, we theoretically prove that the channel DoF is upper bounded by the proposed DoF of electromagnetic fields. Finally, we use numerical analysis to provide some insights about the optimal spatial sampling interval of the antenna array, the DoF of three-dimensional antenna array, the impact of unequal antenna spacing, the orthogonal space-time patterns, etc.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.8 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- Math: 2.0 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Federated Learning: 1.7 -->
                
            <!-- SpikingNN: 1.4 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- Robotics: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1915
            </span>
            <a href="https://arxiv.org/abs/2504.07557" target="_blank" rel="noopener noreferrer">Using LLMs for Analyzing AIS Data</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Gaspard Merten, Gilles Dejaegere, Mahmoud Sakr | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Recent research in Large Language Models (LLMs), has had a profound impact across various fields, including mobility data science. This paper explores the and experiment with different approaches to using LLMs for analyzing AIS data. We propose a set of carefully designed queries to assess the reaso</span>
            
            <span class="abstract-full" style="display: none;">Recent research in Large Language Models (LLMs), has had a profound impact across various fields, including mobility data science. This paper explores the and experiment with different approaches to using LLMs for analyzing AIS data. We propose a set of carefully designed queries to assess the reasoning capabilities of LLMs in this kind of tasks. Further, we experiment with four different methods: (1) using LLMs as a natural language interface to a spatial database, (2) reasoning on raw data, (3) reasoning on compressed trajectories, and (4) reasoning on semantic trajectories. We investigate the strengths and weaknesses for the four methods, and discuss the findings. The goal is to provide valuable insights for both researchers and practitioners on selecting the most appropriate LLM-based method depending on their specific data analysis objectives.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 9.1 -->
                
            <!-- Medicine: 4.8 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- Reinforcement Learning: 2.2 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.3 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1917
            </span>
            <a href="https://arxiv.org/abs/2411.18094" target="_blank" rel="noopener noreferrer">Comprehensive Kernel Safety in the Spectre Era: Mitigations and Performance Evaluation (Extended Version)</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Davide Davoli, Martin Avanzini, Tamara Rezk | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">The efficacy of address space layout randomization has been formally demonstrated in a shared-memory model by Abadi et al., contingent on specific assumptions about victim programs. However, modern operating systems, implementing layout randomization in the kernel, diverge from these assumptions and</span>
            
            <span class="abstract-full" style="display: none;">The efficacy of address space layout randomization has been formally demonstrated in a shared-memory model by Abadi et al., contingent on specific assumptions about victim programs. However, modern operating systems, implementing layout randomization in the kernel, diverge from these assumptions and operate on a separate memory model with communication through system calls. In this work, we relax Abadi et al.'s language assumptions while demonstrating that layout randomization offers a comparable safety guarantee in a system with memory separation. However, in practice, speculative execution and side-channels are recognized threats to layout randomization. We show that kernel safety cannot be restored for attackers capable of using side-channels and speculative execution, and introduce enforcement mechanisms that can guarantee speculative kernel safety for safe system calls in the Spectre era. We implement three suitable mechanisms and we evaluate their performance overhead on the Linux kernel.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.9 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Robotics: 1.8 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Reinforcement Learning: 1.7 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1924
            </span>
            <a href="https://arxiv.org/abs/2504.08338" target="_blank" rel="noopener noreferrer">RINGO: Real-time Navigation with a Guiding Trajectory for Aerial Manipulators in Unknown Environments</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Zhang Zhaopeng, Wu Shizhen, Guo Chenfeng, Fang Yongchun, Han Jianda, Liang Xiao | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Motion planning for aerial manipulators in constrained environments has typically been limited to known environments or simplified to that of multi-rotors, which leads to poor adaptability and overly conservative trajectories. This paper presents RINGO:~Real-time Navigation with a Guiding Trajectory</span>
            
            <span class="abstract-full" style="display: none;">Motion planning for aerial manipulators in constrained environments has typically been limited to known environments or simplified to that of multi-rotors, which leads to poor adaptability and overly conservative trajectories. This paper presents RINGO:~Real-time Navigation with a Guiding Trajectory, a novel planning framework that enables aerial manipulators to navigate unknown environments in real time. The proposed method simultaneously considers the positions of both the multi-rotor and the end-effector. A pre-obtained multi-rotor trajectory serves as a guiding reference, allowing the end-effector to generate a smooth, collision-free, and workspace-compatible trajectory. Leveraging the convex hull property of B-spline curves, we theoretically guarantee that the trajectory remains within the reachable workspace. To the best of our knowledge, this is the first work that enables real-time navigation of aerial manipulators in unknown environments. The simulation and experimental results show the effectiveness of the proposed method. The proposed method generates less conservative trajectories than approaches that consider only the multi-rotor.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.0 -->
                
            <!-- Medicine: 4.2 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- Math: 2.1 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- SpikingNN: 1.7 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1951
            </span>
            <a href="https://arxiv.org/abs/2408.08968" target="_blank" rel="noopener noreferrer">Online SLA Decomposition: Enabling Real-Time Adaptation to Evolving Network Systems</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Cyril Shih-Huan Hsu, Danny De Vleeschauwer, Chrysa Papagianni, Paola Grosso | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">When a network slice spans multiple technology domains, it is crucial for each domain to uphold the End-to-End (E2E) Service Level Agreement (SLA) associated with the slice. Consequently, the E2E SLA must be properly decomposed into partial SLAs that are assigned to each domain involved. In a networ</span>
            
            <span class="abstract-full" style="display: none;">When a network slice spans multiple technology domains, it is crucial for each domain to uphold the End-to-End (E2E) Service Level Agreement (SLA) associated with the slice. Consequently, the E2E SLA must be properly decomposed into partial SLAs that are assigned to each domain involved. In a network slice management system with a two-level architecture, comprising an E2E service orchestrator and local domain controllers, we consider that the orchestrator has access only to historical data regarding the responses of local controllers to previous requests, and this information is used to construct a risk model for each domain. In this study, we extend our previous work by investigating the dynamic nature of real-world systems and introducing an online learning-decomposition framework to tackle the dynamicity. We propose a framework that continuously updates the risk models based on the most recent feedback. This approach leverages key components such as online gradient descent and FIFO memory buffers, which enhance the stability and robustness of the overall process. Our empirical study on an analytic model-based simulator demonstrates that the proposed framework outperforms the state-of-the-art static approach, delivering more accurate and resilient SLA decomposition under varying conditions and data limitations. Furthermore, we provide a comprehensive complexity analysis of the proposed solution.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.2 -->
                
            <!-- Medicine: 4.3 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- Reinforcement Learning: 2.3 -->
                
            <!-- GNN: 2.2 -->
                
            <!-- Math: 2.0 -->
                
            <!-- Federated Learning: 1.7 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1997
            </span>
            <a href="https://arxiv.org/abs/2503.17332" target="_blank" rel="noopener noreferrer">CVE-Bench: A Benchmark for AI Agents' Ability to Exploit Real-World Web Application Vulnerabilities</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Yuxuan Zhu, Antony Kellermann, Dylan Bowman, Philip Li, Akul Gupta, Adarsh Danda, Richard Fang, Conner Jensen, Eric Ihli, Jason Benn, Jet Geronimo, Avi Dhir, Sudhit Rao, Kaicheng Yu, Twm Stone, Daniel Kang | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Large language model (LLM) agents are increasingly capable of autonomously conducting cyberattacks, posing significant threats to existing applications. This growing risk highlights the urgent need for a real-world benchmark to evaluate the ability of LLM agents to exploit web application vulnerabil</span>
            
            <span class="abstract-full" style="display: none;">Large language model (LLM) agents are increasingly capable of autonomously conducting cyberattacks, posing significant threats to existing applications. This growing risk highlights the urgent need for a real-world benchmark to evaluate the ability of LLM agents to exploit web application vulnerabilities. However, existing benchmarks fall short as they are limited to abstracted Capture the Flag competitions or lack comprehensive coverage. Building a benchmark for real-world vulnerabilities involves both specialized expertise to reproduce exploits and a systematic approach to evaluating unpredictable threats. To address this challenge, we introduce CVE-Bench, a real-world cybersecurity benchmark based on critical-severity Common Vulnerabilities and Exposures. In CVE-Bench, we design a sandbox framework that enables LLM agents to exploit vulnerable web applications in scenarios that mimic real-world conditions, while also providing effective evaluation of their exploits. Our evaluation shows that the state-of-the-art agent framework can resolve up to 13% of vulnerabilities.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.2 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- GNN: 2.3 -->
                
            <!-- Reinforcement Learning: 2.2 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.1999
            </span>
            <a href="https://arxiv.org/abs/2504.08368" target="_blank" rel="noopener noreferrer">FocalLens: Instruction Tuning Enables Zero-Shot Conditional Image Representations</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Cheng-Yu Hsieh, Pavan Kumar Anasosalu Vasu, Fartash Faghri, Raviteja Vemulapalli, Chun-Liang Li, Ranjay Krishna, Oncel Tuzel, Hadi Pouransari | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Visual understanding is inherently contextual -- what we focus on in an image depends on the task at hand. For instance, given an image of a person holding a bouquet of flowers, we may focus on either the person such as their clothing, or the type of flowers, depending on the context of interest. Ye</span>
            
            <span class="abstract-full" style="display: none;">Visual understanding is inherently contextual -- what we focus on in an image depends on the task at hand. For instance, given an image of a person holding a bouquet of flowers, we may focus on either the person such as their clothing, or the type of flowers, depending on the context of interest. Yet, most existing image encoding paradigms represent an image as a fixed, generic feature vector, overlooking the potential needs of prioritizing varying visual information for different downstream use cases. In this work, we introduce FocalLens, a conditional visual encoding method that produces different representations for the same image based on the context of interest, expressed flexibly through natural language. We leverage vision instruction tuning data and contrastively finetune a pretrained vision encoder to take natural language instructions as additional inputs for producing conditional image representations. Extensive experiments validate that conditional image representation from FocalLens better pronounce the visual features of interest compared to generic features produced by standard vision encoders like CLIP. In addition, we show FocalLens further leads to performance improvements on a range of downstream tasks including image-image retrieval, image classification, and image-text retrieval, with an average gain of 5 and 10 points on the challenging SugarCrepe and MMVP-VLM benchmarks, respectively.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.2 -->
                
            <!-- Medicine: 4.5 -->
                
            <!-- Quantum Computing: 4.1 -->
                
            <!-- Networks: 2.7 -->
                
            <!-- Math: 2.0 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2006
            </span>
            <a href="https://arxiv.org/abs/2504.08464" target="_blank" rel="noopener noreferrer">Nondeterminism makes unary 1-limited automata concise</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Bruno Guillon (UCA, INP Clermont Auvergne, LIMOS), Luca Prigioniero (UCA, INP Clermont Auvergne, LIMOS), Javad Taheri (UCA, INP Clermont Auvergne, LIMOS) | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We investigate the descriptional complexity of different variants of 1-limited automata (1-las), an extension of two-way finite automata (2nfas) characterizing regular languages. In particular, we consider 2nfas with common-guess (2nfas+cg), which are 2nfas equipped with a new kind of nondeterminism</span>
            
            <span class="abstract-full" style="display: none;">We investigate the descriptional complexity of different variants of 1-limited automata (1-las), an extension of two-way finite automata (2nfas) characterizing regular languages. In particular, we consider 2nfas with common-guess (2nfas+cg), which are 2nfas equipped with a new kind of nondeterminism that allows the device to initially annotate each input symbol, before performing a read-only computation over the resulting annotated word. Their deterministic counterparts, namely two-way deterministic finite automata with common-guess (2dfas+cg), still have a nondeterministic annotation phase and can be considered as a restriction of 1-las. We prove exponential lower bounds for the simulations of 2dfas+cg (and thus of 1-las) by deterministic 1-las and by 2nfas. These results are derived from a doubly exponential lower bound for the simulation of 2dfas+cg by one-way deterministic finite automata (1dfas). Our lower bounds are witnessed by unary languages, namely languages defined over a singleton alphabet. As a consequence, we close a question left open in [Pighizzini and Prigioniero. Limited automata and unary languages. Inf. Comput., 266:60-74], about the existence of a double exponential gap between 1-las and 1dfas in the unary case. Lastly, we prove an exponential lower bound for complementing unary 2dfas+cg (and thus unary 1-las).</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.9 -->
                
            <!-- Medicine: 4.4 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- Math: 2.7 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2013
            </span>
            <a href="https://arxiv.org/abs/2504.08531" target="_blank" rel="noopener noreferrer">Embodied Image Captioning: Self-supervised Learning Agents for Spatially Coherent Image Descriptions</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Tommaso Galliena, Tommaso Apicella, Stefano Rosa, Pietro Morerio, Alessio Del Bue, Lorenzo Natale | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We present a self-supervised method to improve an agent's abilities in describing arbitrary objects while actively exploring a generic environment. This is a challenging problem, as current models struggle to obtain coherent image captions due to different camera viewpoints and clutter. We propose a</span>
            
            <span class="abstract-full" style="display: none;">We present a self-supervised method to improve an agent's abilities in describing arbitrary objects while actively exploring a generic environment. This is a challenging problem, as current models struggle to obtain coherent image captions due to different camera viewpoints and clutter. We propose a three-phase framework to fine-tune existing captioning models that enhances caption accuracy and consistency across views via a consensus mechanism. First, an agent explores the environment, collecting noisy image-caption pairs. Then, a consistent pseudo-caption for each object instance is distilled via consensus using a large language model. Finally, these pseudo-captions are used to fine-tune an off-the-shelf captioning model, with the addition of contrastive learning. We analyse the performance of the combination of captioning models, exploration policies, pseudo-labeling methods, and fine-tuning strategies, on our manually labeled test set. Results show that a policy can be trained to mine samples with higher disagreement compared to classical baselines. Our pseudo-captioning method, in combination with all policies, has a higher semantic similarity compared to other existing methods, and fine-tuning improves caption accuracy and consistency by a significant margin. Code and test set annotations available at https://hsp-iit.github.io/embodied-captioning/</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.0 -->
                
            <!-- Medicine: 5.2 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.8 -->
                
            <!-- Math: 2.1 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2041
            </span>
            <a href="https://arxiv.org/abs/2504.08524" target="_blank" rel="noopener noreferrer">Mitigating Timbre Leakage with Universal Semantic Mapping Residual Block for Voice Conversion</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Na Li, Chuke Wang, Yu Gu, Zhifeng Li | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Voice conversion (VC) transforms source speech into a target voice by preserving the content. However, timbre information from the source speaker is inherently embedded in the content representations, causing significant timbre leakage and reducing similarity to the target speaker. To address this, </span>
            
            <span class="abstract-full" style="display: none;">Voice conversion (VC) transforms source speech into a target voice by preserving the content. However, timbre information from the source speaker is inherently embedded in the content representations, causing significant timbre leakage and reducing similarity to the target speaker. To address this, we introduce a residual block to a content extractor. The residual block consists of two weighted branches: 1) universal semantic dictionary based Content Feature Re-expression (CFR) module, supplying timbre-free content representation. 2) skip connection to the original content layer, providing complementary fine-grained information. In the CFR module, each dictionary entry in the universal semantic dictionary represents a phoneme class, computed statistically using speech from multiple speakers, creating a stable, speaker-independent semantic set. We introduce a CFR method to obtain timbre-free content representations by expressing each content frame as a weighted linear combination of dictionary entries using corresponding phoneme posteriors as weights. Extensive experiments across various VC frameworks demonstrate that our approach effectively mitigates timbre leakage and significantly improves similarity to the target speaker.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.3 -->
                
            <!-- Medicine: 4.8 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.6 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- SpikingNN: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2079
            </span>
            <a href="https://arxiv.org/abs/2412.04065" target="_blank" rel="noopener noreferrer">Space to Policy: Scalable Brick Kiln Detection and Automatic Compliance Monitoring with Geospatial Data</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Zeel B Patel, Rishabh Mondal, Shataxi Dubey, Suraj Jaiswal, Sarath Guttikunda, Nipun Batra | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Air pollution kills 7 million people annually. The brick kiln sector significantly contributes to economic development but also accounts for 8-14\% of air pollution in India. Policymakers have implemented compliance measures to regulate brick kilns. Emission inventories are critical for air quality </span>
            
            <span class="abstract-full" style="display: none;">Air pollution kills 7 million people annually. The brick kiln sector significantly contributes to economic development but also accounts for 8-14\% of air pollution in India. Policymakers have implemented compliance measures to regulate brick kilns. Emission inventories are critical for air quality modeling and source apportionment studies. However, the largely unorganized nature of the brick kiln sector necessitates labor-intensive survey efforts for monitoring. Recent efforts by air quality researchers have relied on manual annotation of brick kilns using satellite imagery to build emission inventories, but this approach lacks scalability. Machine-learning-based object detection methods have shown promise for detecting brick kilns; however, previous studies often rely on costly high-resolution imagery and fail to integrate with governmental policies. In this work, we developed a scalable machine-learning pipeline that detected and classified 30638 brick kilns across five states in the Indo-Gangetic Plain using free, moderate-resolution satellite imagery from Planet Labs. Our detections have a high correlation with on-ground surveys. We performed automated compliance analysis based on government policies. In the Delhi airshed, stricter policy enforcement has led to the adoption of efficient brick kiln technologies. This study highlights the need for inclusive policies that balance environmental sustainability with the livelihoods of workers.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.9 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 2.9 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2143
            </span>
            <a href="https://arxiv.org/abs/2504.08486" target="_blank" rel="noopener noreferrer">PlugSelect: Pruning Channels with Plug-and-Play Flexibility for Electroencephalography-based Brain Computer Interface</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Xue Yuan, Keren Shi, Ning Jiang, Jiayuan He | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Automatic minimization and optimization of the number of the electrodes is essential for the practical application of electroencephalography (EEG)-based brain computer interface (BCI). Previous methods typically require additional training costs or rely on prior knowledge assumptions. This study pro</span>
            
            <span class="abstract-full" style="display: none;">Automatic minimization and optimization of the number of the electrodes is essential for the practical application of electroencephalography (EEG)-based brain computer interface (BCI). Previous methods typically require additional training costs or rely on prior knowledge assumptions. This study proposed a novel channel pruning model, plug-and-select (PlugSelect), applicable across a broad range of BCI paradigms with no additional training cost and plug-and-play functionality. It integrates gradients along the input path to globally infer the causal relationships between input channels and outputs, and ranks the contribution sequences to identify the most highly attributed channels. The results showed that for three BCI paradigms, i.e., auditory attention decoding (AAD), motor imagery (MI), affective computation (AC), PlugSelect could reduce the number of channels by at least half while effectively maintaining decoding performance and improving efficiency. The outcome benefits the design of wearable EEG-based devices, facilitating the practical application of BCI technology.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.2 -->
                
            <!-- Quantum Computing: 4.3 -->
                
            <!-- Medicine: 4.2 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- Math: 2.1 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2148
            </span>
            <a href="https://arxiv.org/abs/2308.09549" target="_blank" rel="noopener noreferrer">Quantum and Probabilistic Computers Rigorously Powerful than Traditional Computers, and Derandomization</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Tianrong Lin | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">In this paper, we extend the techniques used in our previous work to show that there exists a probabilistic Turing machine running within time $O(n^k)$ for all $k\in\mathbb{N}_1$ accepting a language $L_d$ which is different from any language in $\mathcal{P}$, and then further to prove that $L_d\in\</span>
            
            <span class="abstract-full" style="display: none;">In this paper, we extend the techniques used in our previous work to show that there exists a probabilistic Turing machine running within time $O(n^k)$ for all $k\in\mathbb{N}_1$ accepting a language $L_d$ which is different from any language in $\mathcal{P}$, and then further to prove that $L_d\in\mathcal{BPP}$, thus separating the complexity class $\mathcal{BPP}$ from the class $\mathcal{P}$ (i.e., $\mathcal{P}\subsetneq\mathcal{BPP}$).</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.3 -->
                
            <!-- Medicine: 4.4 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- GNN: 2.5 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2151
            </span>
            <a href="https://arxiv.org/abs/2503.13983" target="_blank" rel="noopener noreferrer">SpaceVLLM: Endowing Multimodal Large Language Model with Spatio-Temporal Video Grounding Capability</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Jiankang Wang, Zhihan Zhang, Zhihang Liu, Yang Li, Jiannan Ge, Hongtao Xie, Yongdong Zhang | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Multimodal large language models (MLLMs) have made remarkable progress in either temporal or spatial localization. However, they struggle to perform spatio-temporal video grounding. This limitation stems from two major challenges. Firstly, it is difficult to extract accurate spatio-temporal informat</span>
            
            <span class="abstract-full" style="display: none;">Multimodal large language models (MLLMs) have made remarkable progress in either temporal or spatial localization. However, they struggle to perform spatio-temporal video grounding. This limitation stems from two major challenges. Firstly, it is difficult to extract accurate spatio-temporal information of each frame in the video. Secondly, the substantial number of visual tokens makes it challenging to precisely map visual tokens of each frame to their corresponding spatial coordinates. To address these issues, we introduce SpaceVLLM, a MLLM endowed with spatio-temporal video grounding capability. Specifically, we adopt a set of interleaved Spatio-Temporal Aware Queries to capture temporal perception and dynamic spatial information. Moreover, we propose a Query-Guided Space Decoder to establish a corresponding connection between the queries and spatial coordinates. Additionally, due to the lack of spatio-temporal datasets, we construct the Unified Spatio-Temporal Grounding (Uni-STG) dataset, comprising 480K instances across three tasks. This dataset fully exploits the potential of MLLM to simultaneously facilitate localization in both temporal and spatial dimensions. Extensive experiments demonstrate that SpaceVLLM achieves the state-of-the-art performance across 11 benchmarks covering temporal, spatial, spatio-temporal and video understanding tasks, highlighting the effectiveness of our approach. Our code, datasets and model will be released at https://github.com/Jayce1kk/SpaceVLLM.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 9.3 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 4.1 -->
                
            <!-- Networks: 3.0 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.3 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- Pathfinding: 1.3 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2179
            </span>
            <a href="https://arxiv.org/abs/2504.08323" target="_blank" rel="noopener noreferrer">Academic Network Representation via Prediction-Sampling Incorporated Tensor Factorization</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Chunyang Zhang, Xin Liao, Hao Wu | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Accurate representation to an academic network is of great significance to academic relationship mining like predicting scientific impact. A Latent Factorization of Tensors (LFT) model is one of the most effective models for learning the representation of a target network. However, an academic netwo</span>
            
            <span class="abstract-full" style="display: none;">Accurate representation to an academic network is of great significance to academic relationship mining like predicting scientific impact. A Latent Factorization of Tensors (LFT) model is one of the most effective models for learning the representation of a target network. However, an academic network is often High-Dimensional and Incomplete (HDI) because the relationships among numerous network entities are impossible to be fully explored, making it difficult for an LFT model to learn accurate representation of the academic network. To address this issue, this paper proposes a Prediction-sampling-based Latent Factorization of Tensors (PLFT) model with two ideas: 1) constructing a cascade LFT architecture to enhance model representation learning ability via learning academic network hierarchical features, and 2) introducing a nonlinear activation-incorporated predicting-sampling strategy to more accurately learn the network representation via generating new academic network data layer by layer. Experimental results from the three real-world academic network datasets show that the PLFT model outperforms existing models when predicting the unexplored relationships among network entities.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.3 -->
                
            <!-- Medicine: 5.1 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- Math: 2.3 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- Federated Learning: 1.8 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2204
            </span>
            <a href="https://arxiv.org/abs/2504.08553" target="_blank" rel="noopener noreferrer">Uncovering the Structure of Explanation Quality with Spectral Analysis</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Johannes Mae{\ss}, Gr\'egoire Montavon, Shinichi Nakajima, Klaus-Robert M\"uller, Thomas Schnake | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">As machine learning models are increasingly considered for high-stakes domains, effective explanation methods are crucial to ensure that their prediction strategies are transparent to the user. Over the years, numerous metrics have been proposed to assess quality of explanations. However, their prac</span>
            
            <span class="abstract-full" style="display: none;">As machine learning models are increasingly considered for high-stakes domains, effective explanation methods are crucial to ensure that their prediction strategies are transparent to the user. Over the years, numerous metrics have been proposed to assess quality of explanations. However, their practical applicability remains unclear, in particular due to a limited understanding of which specific aspects each metric rewards. In this paper we propose a new framework based on spectral analysis of explanation outcomes to systematically capture the multifaceted properties of different explanation techniques. Our analysis uncovers two distinct factors of explanation quality-stability and target sensitivity-that can be directly observed through spectral decomposition. Experiments on both MNIST and ImageNet show that popular evaluation techniques (e.g., pixel-flipping, entropy) partially capture the trade-offs between these factors. Overall, our framework provides a foundational basis for understanding explanation quality, guiding the development of more reliable techniques for evaluating explanations.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.9 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 4.1 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.3 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2232
            </span>
            <a href="https://arxiv.org/abs/2406.18892" target="_blank" rel="noopener noreferrer">LearnedKV: Integrating LSM and Learned Index for Superior Performance on Storage</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Wenlong Wang, David Hung-Chang Du | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We present LearnedKV, a novel tiered key-value store that seamlessly integrates a Log-Structured Merge (LSM) tree with a Learned Index to achieve superior read and write performance on storage systems. While existing approaches use learned indexes primarily as auxiliary components within LSM trees, </span>
            
            <span class="abstract-full" style="display: none;">We present LearnedKV, a novel tiered key-value store that seamlessly integrates a Log-Structured Merge (LSM) tree with a Learned Index to achieve superior read and write performance on storage systems. While existing approaches use learned indexes primarily as auxiliary components within LSM trees, LearnedKV employs a two-tier design where the LSM tree handles recent write operations while a separate Learned Index accelerates read performance. Our design includes a non-blocking conversion mechanism that efficiently transforms LSM data into a Learned Index during garbage collection, maintaining high performance without interrupting operations. LearnedKV dramatically reduces LSM size through this tiered approach, leading to significant performance gains in both reads and writes. Extensive evaluations across diverse workloads show that LearnedKV outperforms state-of-the-art LSM-based solutions by up to 4.32x for read operations and 1.43x for writes. The system demonstrates robust performance across different data distributions, access patterns, and storage media including both SSDs and HDDs.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.2 -->
                
            <!-- Medicine: 4.8 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2249
            </span>
            <a href="https://arxiv.org/abs/2503.22832" target="_blank" rel="noopener noreferrer">L0-Reasoning Bench: Evaluating Procedural Correctness in Language Models via Simple Program Execution</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Simeng Sun, Cheng-Ping Hsieh, Faisal Ladhak, Erik Arakelyan, Santiago Akle Serano, Boris Ginsburg | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Complex reasoning tasks often rely on the ability to consistently and accurately apply simple rules across incremental steps, a foundational capability which we term "level-0" reasoning. To systematically evaluate this capability, we introduce L0-Bench, a language model benchmark for testing procedu</span>
            
            <span class="abstract-full" style="display: none;">Complex reasoning tasks often rely on the ability to consistently and accurately apply simple rules across incremental steps, a foundational capability which we term "level-0" reasoning. To systematically evaluate this capability, we introduce L0-Bench, a language model benchmark for testing procedural correctness -- the ability to generate correct reasoning processes, complementing existing benchmarks that primarily focus on outcome correctness. Given synthetic Python functions with simple operations, L0-Bench grades models on their ability to generate step-by-step, error-free execution traces. The synthetic nature of L0-Bench enables systematic and scalable generation of test programs along various axes (e.g., number of trace steps). We evaluate a diverse array of recent closed-source and open-weight models on a baseline test set. All models exhibit degradation as the number of target trace steps increases, while larger models and reasoning-enhanced models better maintain correctness over multiple steps. Additionally, we use L0-Bench to explore test-time scaling along three dimensions: input context length, number of solutions for majority voting, and inference steps. Our results suggest substantial room to improve "level-0" reasoning and potential directions to build more reliable reasoning systems.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.1 -->
                
            <!-- Medicine: 4.8 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Robotics: 1.9 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2289
            </span>
            <a href="https://arxiv.org/abs/2401.12452" target="_blank" rel="noopener noreferrer">Self-supervised Learning of LiDAR 3D Point Clouds via 2D-3D Neural Calibration</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Yifan Zhang, Siyu Ren, Junhui Hou, Jinjian Wu, Yixuan Yuan, Guangming Shi | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">This paper introduces a novel self-supervised learning framework for enhancing 3D perception in autonomous driving scenes. Specifically, our approach, namely NCLR, focuses on 2D-3D neural calibration, a novel pretext task that estimates the rigid pose aligning camera and LiDAR coordinate systems. Fi</span>
            
            <span class="abstract-full" style="display: none;">This paper introduces a novel self-supervised learning framework for enhancing 3D perception in autonomous driving scenes. Specifically, our approach, namely NCLR, focuses on 2D-3D neural calibration, a novel pretext task that estimates the rigid pose aligning camera and LiDAR coordinate systems. First, we propose the learnable transformation alignment to bridge the domain gap between image and point cloud data, converting features into a unified representation space for effective comparison and matching. Second, we identify the overlapping area between the image and point cloud with the fused features. Third, we establish dense 2D-3D correspondences to estimate the rigid pose. The framework not only learns fine-grained matching from points to pixels but also achieves alignment of the image and point cloud at a holistic level, understanding their relative pose. We demonstrate the efficacy of NCLR by applying the pre-trained backbone to downstream tasks, such as LiDAR-based 3D semantic segmentation, object detection, and panoptic segmentation. Comprehensive experiments on various datasets illustrate the superiority of NCLR over existing self-supervised methods. The results confirm that joint learning from different modalities significantly enhances the network's understanding abilities and effectiveness of learned representation. The code is publicly available at https://github.com/Eaphan/NCLR.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.2 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2304
            </span>
            <a href="https://arxiv.org/abs/2504.08703" target="_blank" rel="noopener noreferrer">SWE-PolyBench: A multi-language benchmark for repository level evaluation of coding agents</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Muhammad Shihab Rashid, Christian Bock, Yuan Zhuang, Alexander Buccholz, Tim Esler, Simon Valentin, Luca Franceschi, Martin Wistuba, Prabhu Teja Sivaprasad, Woo Jung Kim, Anoop Deoras, Giovanni Zappella, Laurent Callot | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Coding agents powered by large language models have shown impressive capabilities in software engineering tasks, but evaluating their performance across diverse programming languages and real-world scenarios remains challenging. We introduce SWE-PolyBench, a new multi-language benchmark for reposito</span>
            
            <span class="abstract-full" style="display: none;">Coding agents powered by large language models have shown impressive capabilities in software engineering tasks, but evaluating their performance across diverse programming languages and real-world scenarios remains challenging. We introduce SWE-PolyBench, a new multi-language benchmark for repository-level, execution-based evaluation of coding agents. SWE-PolyBench contains 2110 instances from 21 repositories and includes tasks in Java (165), JavaScript (1017), TypeScript (729) and Python (199), covering bug fixes, feature additions, and code refactoring. We provide a task and repository-stratified subsample (SWE-PolyBench500) and release an evaluation harness allowing for fully automated evaluation. To enable a more comprehensive comparison of coding agents, this work also presents a novel set of metrics rooted in syntax tree analysis. We evaluate leading open source coding agents on SWE-PolyBench, revealing their strengths and limitations across languages, task types, and complexity classes. Our experiments show that current agents exhibit uneven performances across languages and struggle with complex problems while showing higher performance on simpler tasks. SWE-PolyBench aims to drive progress in developing more versatile and robust AI coding assistants for real-world software engineering. Our datasets and code are available at: https://github.com/amazon-science/SWE-PolyBench</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.3 -->
                
            <!-- Medicine: 4.5 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- GNN: 2.2 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Robotics: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2313
            </span>
            <a href="https://arxiv.org/abs/2504.08530" target="_blank" rel="noopener noreferrer">LGRPool: Hierarchical Graph Pooling Via Local-Global Regularisation</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Farshad Noravesh, Reza Haffari, Layki Soon, Arghya Pal | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Hierarchical graph pooling(HGP) are designed to consider the fact that conventional graph neural networks(GNN) are inherently flat and are also not multiscale. However, most HGP methods suffer not only from lack of considering global topology of the graph and focusing on the feature learning aspect,</span>
            
            <span class="abstract-full" style="display: none;">Hierarchical graph pooling(HGP) are designed to consider the fact that conventional graph neural networks(GNN) are inherently flat and are also not multiscale. However, most HGP methods suffer not only from lack of considering global topology of the graph and focusing on the feature learning aspect, but also they do not align local and global features since graphs should inherently be analyzed in a multiscale way. LGRPool is proposed in the present paper as a HGP in the framework of expectation maximization in machine learning that aligns local and global aspects of message passing with each other using a regularizer to force the global topological information to be inline with the local message passing at different scales through the representations at different layers of HGP. Experimental results on some graph classification benchmarks show that it slightly outperforms some baselines.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.4 -->
                
            <!-- Medicine: 4.5 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Math: 2.1 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2316
            </span>
            <a href="https://arxiv.org/abs/2502.06674" target="_blank" rel="noopener noreferrer">RAILS: Risk-Aware Iterated Local Search for Joint SLA Decomposition and Service Provider Management in Multi-Domain Networks</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Cyril Shih-Huan Hsu, Chrysa Papagianni, Paola Grosso | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">The emergence of the fifth generation (5G) technology has transformed mobile networks into multi-service environments, necessitating efficient network slicing to meet diverse Service Level Agreements (SLAs). SLA decomposition across multiple network domains, each potentially managed by different ser</span>
            
            <span class="abstract-full" style="display: none;">The emergence of the fifth generation (5G) technology has transformed mobile networks into multi-service environments, necessitating efficient network slicing to meet diverse Service Level Agreements (SLAs). SLA decomposition across multiple network domains, each potentially managed by different service providers, poses a significant challenge due to limited visibility into real-time underlying domain conditions. This paper introduces Risk-Aware Iterated Local Search (RAILS), a novel risk model-driven meta-heuristic framework designed to jointly address SLA decomposition and service provider selection in multi-domain networks. By integrating online risk modeling with iterated local search principles, RAILS effectively navigates the complex optimization landscape, utilizing historical feedback from domain controllers. We formulate the joint problem as a Mixed-Integer Nonlinear Programming (MINLP) problem and prove its NP-hardness. Extensive simulations demonstrate that RAILS achieves near-optimal performance, offering an efficient, real-time solution for adaptive SLA management in modern multi-domain networks.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.3 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.7 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2416
            </span>
            <a href="https://arxiv.org/abs/2406.00004" target="_blank" rel="noopener noreferrer">Navigating the Future of Federated Recommendation Systems with Foundation Models</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Zhiwei Li, Guodong Long, Chunxu Zhang, Honglei Zhang, Jing Jiang, Chengqi Zhang | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Federated Recommendation Systems (FRSs) offer a privacy-preserving alternative to traditional centralized approaches by decentralizing data storage. However, they face persistent challenges such as data sparsity and heterogeneity, largely due to isolated client environments. Recent advances in Found</span>
            
            <span class="abstract-full" style="display: none;">Federated Recommendation Systems (FRSs) offer a privacy-preserving alternative to traditional centralized approaches by decentralizing data storage. However, they face persistent challenges such as data sparsity and heterogeneity, largely due to isolated client environments. Recent advances in Foundation Models (FMs), particularly large language models like ChatGPT, present an opportunity to surmount these issues through powerful, cross-task knowledge transfer. In this position paper, we systematically examine the convergence of FRSs and FMs, illustrating how FM-enhanced frameworks can substantially improve client-side personalization, communication efficiency, and server-side aggregation. We also delve into pivotal challenges introduced by this integration, including privacy-security trade-offs, non-IID data, and resource constraints in federated setups, and propose prospective research directions in areas such as multimodal recommendation, real-time FM adaptation, and explainable federated reasoning. By unifying FRSs with FMs, our position paper provides a forward-looking roadmap for advancing privacy-preserving, high-performance recommendation systems that fully leverage large-scale pre-trained knowledge to enhance local performance.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.3 -->
                
            <!-- Medicine: 4.5 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.253
            </span>
            <a href="https://arxiv.org/abs/2504.08002" target="_blank" rel="noopener noreferrer">More diverse more adaptive: Comprehensive Multi-task Learning for Improved LLM Domain Adaptation in E-commerce</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Tong Piao, Pei Tang, Zhipeng Zhang, Jiaqi Li, Qiao Liu, Zufeng Wu | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">In recent years, Large Language Models (LLMs) have been widely applied across various domains due to their powerful domain adaptation capabilities. Previous studies have suggested that diverse, multi-modal data can enhance LLMs' domain adaptation performance. However, this hypothesis remains insuffi</span>
            
            <span class="abstract-full" style="display: none;">In recent years, Large Language Models (LLMs) have been widely applied across various domains due to their powerful domain adaptation capabilities. Previous studies have suggested that diverse, multi-modal data can enhance LLMs' domain adaptation performance. However, this hypothesis remains insufficiently validated in the e-commerce sector. To address this gap, we propose a comprehensive e-commerce multi-task framework and design empirical experiments to examine the impact of diverse data and tasks on LLMs from two perspectives: "capability comprehensiveness" and "task comprehensiveness." Specifically, we observe significant improvements in LLM performance by progressively introducing tasks related to new major capability areas and by continuously adding subtasks within different major capability domains. Furthermore, we observe that increasing model capacity amplifies the benefits of diversity, suggesting a synergistic relationship between model capacity and data diversity. Finally, we validate the best-performing model from our empirical experiments in the KDD Cup 2024, achieving a rank 5 in Task 1. This outcome demonstrates the significance of our research for advancing LLMs in the e-commerce domain.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 10.6 -->
                
            <!-- Medicine: 5.2 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Federated Learning: 1.7 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- T2I: 1.4 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2554
            </span>
            <a href="https://arxiv.org/abs/2504.08568" target="_blank" rel="noopener noreferrer">Banana Ripeness Level Classification using a Simple CNN Model Trained with Real and Synthetic Datasets</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Luis Chuquimarca, Boris Vintimilla, Sergio Velastin | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">The level of ripeness is essential in determining the quality of bananas. To correctly estimate banana maturity, the metrics of international marketing standards need to be considered. However, the process of assessing the maturity of bananas at an industrial level is still carried out using manual </span>
            
            <span class="abstract-full" style="display: none;">The level of ripeness is essential in determining the quality of bananas. To correctly estimate banana maturity, the metrics of international marketing standards need to be considered. However, the process of assessing the maturity of bananas at an industrial level is still carried out using manual methods. The use of CNN models is an attractive tool to solve the problem, but there is a limitation regarding the availability of sufficient data to train these models reliably. On the other hand, in the state-of-the-art, existing CNN models and the available data have reported that the accuracy results are acceptable in identifying banana maturity. For this reason, this work presents the generation of a robust dataset that combines real and synthetic data for different levels of banana ripeness. In addition, it proposes a simple CNN architecture, which is trained with synthetic data and using the transfer learning technique, the model is improved to classify real data, managing to determine the level of maturity of the banana. The proposed CNN model is evaluated with several architectures, then hyper-parameter configurations are varied, and optimizers are used. The results show that the proposed CNN model reaches a high accuracy of 0.917 and a fast execution time.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.9 -->
                
            <!-- Medicine: 5.1 -->
                
            <!-- Quantum Computing: 4.1 -->
                
            <!-- Networks: 3.9 -->
                
            <!-- Math: 2.6 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- GNN: 1.7 -->
                
            <!-- Federated Learning: 1.7 -->
                
            <!-- SpikingNN: 1.4 -->
                
            <!-- Evolutionary Algorithms: 1.3 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- Robotics: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2568
            </span>
            <a href="https://arxiv.org/abs/2504.08384" target="_blank" rel="noopener noreferrer">Towards Efficient and Robust Moment Retrieval System: A Unified Framework for Multi-Granularity Models and Temporal Reranking</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Huu-Loc Tran, Tinh-Anh Nguyen-Nhu, Huu-Phong Phan-Nguyen, Tien-Huy Nguyen, Nhat-Minh Nguyen-Dich, Anh Dao, Huy-Duc Do, Quan Nguyen, Hoang M. Le, Quang-Vinh Dinh | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Long-form video understanding presents significant challenges for interactive retrieval systems, as conventional methods struggle to process extensive video content efficiently. Existing approaches often rely on single models, inefficient storage, unstable temporal search, and context-agnostic reran</span>
            
            <span class="abstract-full" style="display: none;">Long-form video understanding presents significant challenges for interactive retrieval systems, as conventional methods struggle to process extensive video content efficiently. Existing approaches often rely on single models, inefficient storage, unstable temporal search, and context-agnostic reranking, limiting their effectiveness. This paper presents a novel framework to enhance interactive video retrieval through four key innovations: (1) an ensemble search strategy that integrates coarse-grained (CLIP) and fine-grained (BEIT3) models to improve retrieval accuracy, (2) a storage optimization technique that reduces redundancy by selecting representative keyframes via TransNetV2 and deduplication, (3) a temporal search mechanism that localizes video segments using dual queries for start and end points, and (4) a temporal reranking approach that leverages neighboring frame context to stabilize rankings. Evaluated on known-item search and question-answering tasks, our framework demonstrates substantial improvements in retrieval precision, efficiency, and user interpretability, offering a robust solution for real-world interactive video retrieval applications.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.9 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.6 -->
                
            <!-- GNN: 2.2 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Robotics: 1.8 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- SpikingNN: 1.0 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2573
            </span>
            <a href="https://arxiv.org/abs/2504.08736" target="_blank" rel="noopener noreferrer">GigaTok: Scaling Visual Tokenizers to 3 Billion Parameters for Autoregressive Image Generation</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Tianwei Xiong, Jun Hao Liew, Zilong Huang, Jiashi Feng, Xihui Liu | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">In autoregressive (AR) image generation, visual tokenizers compress images into compact discrete latent tokens, enabling efficient training of downstream autoregressive models for visual generation via next-token prediction. While scaling visual tokenizers improves image reconstruction quality, it o</span>
            
            <span class="abstract-full" style="display: none;">In autoregressive (AR) image generation, visual tokenizers compress images into compact discrete latent tokens, enabling efficient training of downstream autoregressive models for visual generation via next-token prediction. While scaling visual tokenizers improves image reconstruction quality, it often degrades downstream generation quality -- a challenge not adequately addressed in existing literature. To address this, we introduce GigaTok, the first approach to simultaneously improve image reconstruction, generation, and representation learning when scaling visual tokenizers. We identify the growing complexity of latent space as the key factor behind the reconstruction vs. generation dilemma. To mitigate this, we propose semantic regularization, which aligns tokenizer features with semantically consistent features from a pre-trained visual encoder. This constraint prevents excessive latent space complexity during scaling, yielding consistent improvements in both reconstruction and downstream autoregressive generation. Building on semantic regularization, we explore three key practices for scaling tokenizers:(1) using 1D tokenizers for better scalability, (2) prioritizing decoder scaling when expanding both encoder and decoder, and (3) employing entropy loss to stabilize training for billion-scale tokenizers. By scaling to $\bf{3 \space billion}$ parameters, GigaTok achieves state-of-the-art performance in reconstruction, downstream AR generation, and downstream AR representation quality.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.7 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.7 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.258
            </span>
            <a href="https://arxiv.org/abs/2311.16445" target="_blank" rel="noopener noreferrer">CLAP: Isolating Content from Style through Contrastive Learning with Augmented Prompts</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Yichao Cai, Yuhang Liu, Zhen Zhang, Javen Qinfeng Shi | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Contrastive vision-language models, such as CLIP, have garnered considerable attention for various downstream tasks, mainly due to the remarkable generalization ability of the learned features. However, the features they learn often blend content and style information, which somewhat limits their ge</span>
            
            <span class="abstract-full" style="display: none;">Contrastive vision-language models, such as CLIP, have garnered considerable attention for various downstream tasks, mainly due to the remarkable generalization ability of the learned features. However, the features they learn often blend content and style information, which somewhat limits their generalization capabilities under distribution shifts. To address this limitation, we adopt a causal generative perspective for multimodal data and propose contrastive learning with data augmentation to disentangle content features from the original representations. To achieve this, we begin by exploring image augmentation techniques and develop a method to seamlessly integrate them into pre-trained CLIP-like models to extract pure content features. Taking a step further, and recognizing the inherent semantic richness and logical structure of text data, we explore the use of text augmentation to isolate latent content from style features. This enables CLIP-like models' encoders to concentrate on latent content information, refining the representations learned by pre-trained CLIP-like models. Our extensive experiments across diverse datasets demonstrate significant improvements in zero-shot and few-shot classification tasks, alongside enhanced robustness to various perturbations. These results underscore the effectiveness of our proposed methods in refining vision-language representations and advancing the state of the art in multimodal learning.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.1 -->
                
            <!-- Medicine: 5.1 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.0 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- SpikingNN: 1.3 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2589
            </span>
            <a href="https://arxiv.org/abs/2504.08096" target="_blank" rel="noopener noreferrer">Cellular Development Follows the Path of Minimum Action</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Rohola Zandie, Farhan Khodaee, Yufan Xia, Elazer R. Edelman | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Cellular development follows a stochastic yet rule-governed trajectory, though the underlying principles remain elusive. Here, we propose that cellular development follows paths of least action, aligning with foundational physical laws that govern dynamic systems across nature. We introduce a comput</span>
            
            <span class="abstract-full" style="display: none;">Cellular development follows a stochastic yet rule-governed trajectory, though the underlying principles remain elusive. Here, we propose that cellular development follows paths of least action, aligning with foundational physical laws that govern dynamic systems across nature. We introduce a computational framework that takes advantage of the deep connection between the principle of least action and maximum entropy to model developmental processes using Transformers architecture. This approach enables precise quantification of entropy production, information flow curvature, and local irreversibility for developmental asymmetry in single-cell RNA sequence data. Within this unified framework, we provide interpretable metrics: entropy to capture exploration-exploitation trade-offs, curvature to assess plasticity-elasticity dynamics, and entropy production to characterize dedifferentiation and transdifferentiation. We validate our method across both single-cell and embryonic development datasets, demonstrating its ability to reveal hidden thermodynamic and informational constraints shaping cellular fate decisions.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.1 -->
                
            <!-- Medicine: 4.8 -->
                
            <!-- Quantum Computing: 4.1 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2594
            </span>
            <a href="https://arxiv.org/abs/2407.00135" target="_blank" rel="noopener noreferrer">Quantitative Methods in Research Evaluation Citation Indicators, Altmetrics, and Artificial Intelligence</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Mike Thelwall | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">This book critically analyses the value of citation data, altmetrics, and artificial intelligence to support the research evaluation of articles, scholars, departments, universities, countries, and funders. It introduces and discusses indicators that can support research evaluation and analyses thei</span>
            
            <span class="abstract-full" style="display: none;">This book critically analyses the value of citation data, altmetrics, and artificial intelligence to support the research evaluation of articles, scholars, departments, universities, countries, and funders. It introduces and discusses indicators that can support research evaluation and analyses their strengths and weaknesses as well as the generic strengths and weaknesses of the use of indicators for research assessment. The book includes evidence of the comparative value of citations and altmetrics in all broad academic fields primarily through comparisons against article level human expert judgements from the UK Research Excellence Framework 2021. It also discusses the potential applications of traditional artificial intelligence and large language models for research evaluation, with large scale evidence for the former. The book concludes that citation data can be informative and helpful in some research fields for some research evaluation purposes but that indicators are never accurate enough to be described as research quality measures. It also argues that AI may be helpful in limited circumstances for some types of research evaluation.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.5 -->
                
            <!-- Medicine: 4.4 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- Math: 2.1 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2632
            </span>
            <a href="https://arxiv.org/abs/2504.08332" target="_blank" rel="noopener noreferrer">High-dimensional Clustering and Signal Recovery under Block Signals</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Wu Su, Yumou Qiu | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">This paper studies computationally efficient methods and their minimax optimality for high-dimensional clustering and signal recovery under block signal structures. We propose two sets of methods, cross-block feature aggregation PCA (CFA-PCA) and moving average PCA (MA-PCA), designed for sparse and </span>
            
            <span class="abstract-full" style="display: none;">This paper studies computationally efficient methods and their minimax optimality for high-dimensional clustering and signal recovery under block signal structures. We propose two sets of methods, cross-block feature aggregation PCA (CFA-PCA) and moving average PCA (MA-PCA), designed for sparse and dense block signals, respectively. Both methods adaptively utilize block signal structures, applicable to non-Gaussian data with heterogeneous variances and non-diagonal covariance matrices. Specifically, the CFA method utilizes a block-wise U-statistic to aggregate and select block signals non-parametrically from data with unknown cluster labels. We show that the proposed methods are consistent for both clustering and signal recovery under mild conditions and weaker signal strengths than the existing methods without considering block structures of signals. Furthermore, we derive both statistical and computational minimax lower bounds (SMLB and CMLB) for high-dimensional clustering and signal recovery under block signals, where the CMLBs are restricted to algorithms with polynomial computation complexity. The minimax boundaries partition signals into regions of impossibility and possibility. No algorithm (or no polynomial time algorithm) can achieve consistent clustering or signal recovery if the signals fall into the statistical (or computational) region of impossibility. We show that the proposed CFA-PCA and MA-PCA methods can achieve the CMLBs for the sparse and dense block signal regimes, respectively, indicating the proposed methods are computationally minimax optimal. A tuning parameter selection method is proposed based on post-clustering signal recovery results. Simulation studies are conducted to evaluate the proposed methods. A case study on global temperature change demonstrates their utility in practice.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.6 -->
                
            <!-- Medicine: 4.5 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 3.7 -->
                
            <!-- Math: 2.2 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2673
            </span>
            <a href="https://arxiv.org/abs/2504.08440" target="_blank" rel="noopener noreferrer">Speech Command + Speech Emotion: Exploring Emotional Speech Commands as a Compound and Playful Modality</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Ilhan Aslan, Timothy Merritt, Stine S. Johansen, Niels van Berkel | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">In an era of human-computer interaction with increasingly agentic AI systems capable of connecting with users conversationally, speech is an important modality for commanding agents. By recognizing and using speech emotions (i.e., how a command is spoken), we can provide agents with the ability to e</span>
            
            <span class="abstract-full" style="display: none;">In an era of human-computer interaction with increasingly agentic AI systems capable of connecting with users conversationally, speech is an important modality for commanding agents. By recognizing and using speech emotions (i.e., how a command is spoken), we can provide agents with the ability to emotionally accentuate their responses and socially enrich users' perceptions and experiences. To explore the concept and impact of speech emotion commands on user perceptions, we realized a prototype and conducted a user study (N = 14) where speech commands are used to steer two vehicles in a minimalist and retro game style implementation. While both agents execute user commands, only one of the agents uses speech emotion information to adapt its execution behavior. We report on differences in how users perceived each agent, including significant differences in stimulation and dependability, outline implications for designing interactions with agents using emotional speech commands, and provide insights on how users consciously emote, which we describe as "voice acting".</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.4 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Robotics: 1.8 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2675
            </span>
            <a href="https://arxiv.org/abs/2412.14865" target="_blank" rel="noopener noreferrer">Hierarchical Subspaces of Policies for Continual Offline Reinforcement Learning</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Anthony Kobanda, R\'emy Portelas, Odalric-Ambrym Maillard, Ludovic Denoyer | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We consider a Continual Reinforcement Learning setup, where a learning agent must continuously adapt to new tasks while retaining previously acquired skill sets, with a focus on the challenge of avoiding forgetting past gathered knowledge and ensuring scalability with the growing number of tasks. Su</span>
            
            <span class="abstract-full" style="display: none;">We consider a Continual Reinforcement Learning setup, where a learning agent must continuously adapt to new tasks while retaining previously acquired skill sets, with a focus on the challenge of avoiding forgetting past gathered knowledge and ensuring scalability with the growing number of tasks. Such issues prevail in autonomous robotics and video game simulations, notably for navigation tasks prone to topological or kinematic changes. To address these issues, we introduce HiSPO, a novel hierarchical framework designed specifically for continual learning in navigation settings from offline data. Our method leverages distinct policy subspaces of neural networks to enable flexible and efficient adaptation to new tasks while preserving existing knowledge. We demonstrate, through a careful experimental study, the effectiveness of our method in both classical MuJoCo maze environments and complex video game-like navigation simulations, showcasing competitive performances and satisfying adaptability with respect to classical continual learning metrics, in particular regarding the memory usage and efficiency.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.5 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 2.0 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2679
            </span>
            <a href="https://arxiv.org/abs/2401.15912" target="_blank" rel="noopener noreferrer">On PIR and SPIR Over Gaussian MAC</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Or Elimelech, Asaf Cohen | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">This paper revisits the problems of Private Information Retrieval (PIR) and Symmetric PIR (SPIR). In PIR, there are $N$ replicated non-communicating databases containing the same $M$ messages and a user wishing to retrieve one message without revealing the message's index to the databases. SPIR exte</span>
            
            <span class="abstract-full" style="display: none;">This paper revisits the problems of Private Information Retrieval (PIR) and Symmetric PIR (SPIR). In PIR, there are $N$ replicated non-communicating databases containing the same $M$ messages and a user wishing to retrieve one message without revealing the message's index to the databases. SPIR extends this notion further by additionally protecting the privacy of the databases, ensuring that the user learns no information beyond the requested message. However, we assume a block-fading Additive White Gaussian Noise Multiple Access Channel (AWGN MAC) linking the user and the databases.}</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.2 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- Math: 2.2 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.3 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2688
            </span>
            <a href="https://arxiv.org/abs/2504.07199" target="_blank" rel="noopener noreferrer">SemEval-2025 Task 5: LLMs4Subjects -- LLM-based Automated Subject Tagging for a National Technical Library's Open-Access Catalog</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Jennifer D'Souza, Sameer Sadruddin, Holger Israel, Mathias Begoin, Diana Slawig | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We present SemEval-2025 Task 5: LLMs4Subjects, a shared task on automated subject tagging for scientific and technical records in English and German using the GND taxonomy. Participants developed LLM-based systems to recommend top-k subjects, evaluated through quantitative metrics (precision, recall</span>
            
            <span class="abstract-full" style="display: none;">We present SemEval-2025 Task 5: LLMs4Subjects, a shared task on automated subject tagging for scientific and technical records in English and German using the GND taxonomy. Participants developed LLM-based systems to recommend top-k subjects, evaluated through quantitative metrics (precision, recall, F1-score) and qualitative assessments by subject specialists. Results highlight the effectiveness of LLM ensembles, synthetic data generation, and multilingual processing, offering insights into applying LLMs for digital library classification.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.8 -->
                
            <!-- Medicine: 4.5 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.27
            </span>
            <a href="https://arxiv.org/abs/2504.08325" target="_blank" rel="noopener noreferrer">Practical Secure Aggregation by Combining Cryptography and Trusted Execution Environments</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Romain de Laage, Peterson Yuhala, Fran\c{c}ois-Xavier Wicht, Pascal Felber, Christian Cachin, Valerio Schiavoni | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Secure aggregation enables a group of mutually distrustful parties, each holding private inputs, to collaboratively compute an aggregate value while preserving the privacy of their individual inputs. However, a major challenge in adopting secure aggregation approaches for practical applications is t</span>
            
            <span class="abstract-full" style="display: none;">Secure aggregation enables a group of mutually distrustful parties, each holding private inputs, to collaboratively compute an aggregate value while preserving the privacy of their individual inputs. However, a major challenge in adopting secure aggregation approaches for practical applications is the significant computational overhead of the underlying cryptographic protocols, e.g. fully homomorphic encryption. This overhead makes secure aggregation protocols impractical, especially for large datasets. In contrast, hardware-based security techniques such as trusted execution environments (TEEs) enable computation at near-native speeds, making them a promising alternative for reducing the computational burden typically associated with purely cryptographic techniques. Yet, in many scenarios, parties may opt for either cryptographic or hardware-based security mechanisms, highlighting the need for hybrid approaches. In this work, we introduce several secure aggregation architectures that integrate both cryptographic and TEE-based techniques, analyzing the trade-offs between security and performance.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.0 -->
                
            <!-- Quantum Computing: 4.3 -->
                
            <!-- Medicine: 4.3 -->
                
            <!-- Networks: 2.9 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.8 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- Evolutionary Algorithms: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2721
            </span>
            <a href="https://arxiv.org/abs/2409.20052" target="_blank" rel="noopener noreferrer">Mitigating Propensity Bias of Large Language Models for Recommender Systems</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Guixian Zhang, Guan Yuan, Debo Cheng, Lin Liu, Jiuyong Li, Shichao Zhang | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">The rapid development of Large Language Models (LLMs) creates new opportunities for recommender systems, especially by exploiting the side information (e.g., descriptions and analyses of items) generated by these models. However, aligning this side information with collaborative information from his</span>
            
            <span class="abstract-full" style="display: none;">The rapid development of Large Language Models (LLMs) creates new opportunities for recommender systems, especially by exploiting the side information (e.g., descriptions and analyses of items) generated by these models. However, aligning this side information with collaborative information from historical interactions poses significant challenges. The inherent biases within LLMs can skew recommendations, resulting in distorted and potentially unfair user experiences. On the other hand, propensity bias causes side information to be aligned in such a way that it often tends to represent all inputs in a low-dimensional subspace, leading to a phenomenon known as dimensional collapse, which severely restricts the recommender system's ability to capture user preferences and behaviours. To address these issues, we introduce a novel framework named Counterfactual LLM Recommendation (CLLMR). Specifically, we propose a spectrum-based side information encoder that implicitly embeds structural information from historical interactions into the side information representation, thereby circumventing the risk of dimension collapse. Furthermore, our CLLMR approach explores the causal relationships inherent in LLM-based recommender systems. By leveraging counterfactual inference, we counteract the biases introduced by LLMs. Extensive experiments demonstrate that our CLLMR approach consistently enhances the performance of various recommender models.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 10.0 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2729
            </span>
            <a href="https://arxiv.org/abs/2504.08696" target="_blank" rel="noopener noreferrer">SeaView: Software Engineering Agent Visual Interface for Enhanced Workflow</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Timothy Bula, Saurabh Pujar, Luca Buratti, Mihaela Bornea, Avirup Sil | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Auto-regressive LLM-based software engineering (SWE) agents, henceforth SWE agents, have made tremendous progress (>60% on SWE-Bench Verified) on real-world coding challenges including GitHub issue resolution. SWE agents use a combination of reasoning, environment interaction and self-reflection to </span>
            
            <span class="abstract-full" style="display: none;">Auto-regressive LLM-based software engineering (SWE) agents, henceforth SWE agents, have made tremendous progress (>60% on SWE-Bench Verified) on real-world coding challenges including GitHub issue resolution. SWE agents use a combination of reasoning, environment interaction and self-reflection to resolve issues thereby generating "trajectories". Analysis of SWE agent trajectories is difficult, not only as they exceed LLM sequence length (sometimes, greater than 128k) but also because it involves a relatively prolonged interaction between an LLM and the environment managed by the agent. In case of an agent error, it can be hard to decipher, locate and understand its scope. Similarly, it can be hard to track improvements or regression over multiple runs or experiments. While a lot of research has gone into making these SWE agents reach state-of-the-art, much less focus has been put into creating tools to help analyze and visualize agent output. We propose a novel tool called SeaView: Software Engineering Agent Visual Interface for Enhanced Workflow, with a vision to assist SWE-agent researchers to visualize and inspect their experiments. SeaView's novel mechanisms help compare experimental runs with varying hyper-parameters or LLMs, and quickly get an understanding of LLM or environment related problems. Based on our user study, experienced researchers spend between 10 and 30 minutes to gather the information provided by SeaView, while researchers with little experience can spend between 30 minutes to 1 hour to diagnose their experiment.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.9 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Robotics: 2.0 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2751
            </span>
            <a href="https://arxiv.org/abs/2504.08046" target="_blank" rel="noopener noreferrer">Teaching Humans Subtle Differences with DIFFusion</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Mia Chiquier, Orr Avrech, Yossi Gandelsman, Berthy Feng, Katherine Bouman, Carl Vondrick | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Human expertise depends on the ability to recognize subtle visual differences, such as distinguishing diseases, species, or celestial phenomena. We propose a new method to teach novices how to differentiate between nuanced categories in specialized domains. Our method uses generative models to visua</span>
            
            <span class="abstract-full" style="display: none;">Human expertise depends on the ability to recognize subtle visual differences, such as distinguishing diseases, species, or celestial phenomena. We propose a new method to teach novices how to differentiate between nuanced categories in specialized domains. Our method uses generative models to visualize the minimal change in features to transition between classes, i.e., counterfactuals, and performs well even in domains where data is sparse, examples are unpaired, and category boundaries are not easily explained by text. By manipulating the conditioning space of diffusion models, our proposed method DIFFusion disentangles category structure from instance identity, enabling high-fidelity synthesis even in challenging domains. Experiments across six domains show accurate transitions even with limited and unpaired examples across categories. User studies confirm that our generated counterfactuals outperform unpaired examples in teaching perceptual expertise, showing the potential of generative models for specialized visual learning.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.4 -->
                
            <!-- Medicine: 4.5 -->
                
            <!-- Quantum Computing: 4.1 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2768
            </span>
            <a href="https://arxiv.org/abs/2504.08282" target="_blank" rel="noopener noreferrer">Analyzing the Landscape of the Indicator-based Subset Selection Problem</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Keisuke Korogi, Ryoji Tanabe | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">The indicator-based subset selection problem (ISSP) involves finding a point subset that minimizes or maximizes a quality indicator. The ISSP is frequently found in evolutionary multi-objective optimization (EMO). An in-depth understanding of the landscape of the ISSP could be helpful in developing </span>
            
            <span class="abstract-full" style="display: none;">The indicator-based subset selection problem (ISSP) involves finding a point subset that minimizes or maximizes a quality indicator. The ISSP is frequently found in evolutionary multi-objective optimization (EMO). An in-depth understanding of the landscape of the ISSP could be helpful in developing efficient subset selection methods and explaining their performance. However, the landscape of the ISSP is poorly understood. To address this issue, this paper analyzes the landscape of the ISSP by using various traditional landscape analysis measures and exact local optima networks (LONs). This paper mainly investigates how the landscape of the ISSP is influenced by the choice of a quality indicator and the shape of the Pareto front. Our findings provide insightful information about the ISSP. For example, high neutrality and many local optima are observed in the results for ISSP instances with the additive $\epsilon$-indicator.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.3 -->
                
            <!-- Medicine: 3.9 -->
                
            <!-- Quantum Computing: 3.7 -->
                
            <!-- Math: 2.9 -->
                
            <!-- Networks: 2.7 -->
                
            <!-- Reinforcement Learning: 1.6 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- SpikingNN: 1.4 -->
                
            <!-- GNN: 1.4 -->
                
            <!-- Pathfinding: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2811
            </span>
            <a href="https://arxiv.org/abs/2504.08714" target="_blank" rel="noopener noreferrer">Generating Fine Details of Entity Interactions</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Xinyi Gu, Jiayuan Mao | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Images not only depict objects but also encapsulate rich interactions between them. However, generating faithful and high-fidelity images involving multiple entities interacting with each other, is a long-standing challenge. While pre-trained text-to-image models are trained on large-scale datasets </span>
            
            <span class="abstract-full" style="display: none;">Images not only depict objects but also encapsulate rich interactions between them. However, generating faithful and high-fidelity images involving multiple entities interacting with each other, is a long-standing challenge. While pre-trained text-to-image models are trained on large-scale datasets to follow diverse text instructions, they struggle to generate accurate interactions, likely due to the scarcity of training data for uncommon object interactions. This paper introduces InterActing, an interaction-focused dataset with 1000 fine-grained prompts covering three key scenarios: (1) functional and action-based interactions, (2) compositional spatial relationships, and (3) multi-subject interactions. To address interaction generation challenges, we propose a decomposition-augmented refinement procedure. Our approach, DetailScribe, built on Stable Diffusion 3.5, leverages LLMs to decompose interactions into finer-grained concepts, uses a VLM to critique generated images, and applies targeted interventions within the diffusion process in refinement. Automatic and human evaluations show significantly improved image quality, demonstrating the potential of enhanced inference strategies. Our dataset and code are available at https://concepts-ai.com/p/detailscribe/ to facilitate future exploration of interaction-rich image generation.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.8 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 4.1 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2819
            </span>
            <a href="https://arxiv.org/abs/2411.13248" target="_blank" rel="noopener noreferrer">On lower bounds of the density of planar periodic sets without unit distances</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Alexander Tolmachev | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Determining the maximal density $m_1(\mathbb{R}^2)$ of planar sets without unit distances is a fundamental problem in combinatorial geometry. This paper investigates lower bounds for this quantity. We introduce a novel approach to estimating $m_1(\mathbb{R}^2)$ by reformulating the problem as a Maxi</span>
            
            <span class="abstract-full" style="display: none;">Determining the maximal density $m_1(\mathbb{R}^2)$ of planar sets without unit distances is a fundamental problem in combinatorial geometry. This paper investigates lower bounds for this quantity. We introduce a novel approach to estimating $m_1(\mathbb{R}^2)$ by reformulating the problem as a Maximal Independent Set (MIS) problem on graphs constructed from flat torus, focusing on periodic sets with respect to two non-collinear vectors. Our experimental results, supported by theoretical justifications of proposed method, demonstrate that for a sufficiently wide range of parameters this approach does not improve the known lower bound $0.22936 \le m_1(\mathbb{R}^2)$. The best discrete sets found are approximations of Croft's construction. In addition, several open source software packages for MIS problem are compared on this task.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.9 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Math: 2.0 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Evolutionary Algorithms: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2854
            </span>
            <a href="https://arxiv.org/abs/2504.08176" target="_blank" rel="noopener noreferrer">GenXSS: an AI-Driven Framework for Automated Detection of XSS Attacks in WAFs</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Vahid Babaey, Arun Ravindran | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">The increasing reliance on web services has led to a rise in cybersecurity threats, particularly Cross-Site Scripting (XSS) attacks, which target client-side layers of web applications by injecting malicious scripts. Traditional Web Application Firewalls (WAFs) struggle to detect highly obfuscated a</span>
            
            <span class="abstract-full" style="display: none;">The increasing reliance on web services has led to a rise in cybersecurity threats, particularly Cross-Site Scripting (XSS) attacks, which target client-side layers of web applications by injecting malicious scripts. Traditional Web Application Firewalls (WAFs) struggle to detect highly obfuscated and complex attacks, as their rules require manual updates. This paper presents a novel generative AI framework that leverages Large Language Models (LLMs) to enhance XSS mitigation. The framework achieves two primary objectives: (1) generating sophisticated and syntactically validated XSS payloads using in-context learning, and (2) automating defense mechanisms by testing these attacks against a vulnerable application secured by a WAF, classifying bypassing attacks, and generating effective WAF security rules. Experimental results using GPT-4o demonstrate the framework's effectiveness generating 264 XSS payloads, 83% of which were validated, with 80% bypassing ModSecurity WAF equipped with an industry standard security rule set developed by the Open Web Application Security Project (OWASP) to protect against web vulnerabilities. Through rule generation, 86% of previously successful attacks were blocked using only 15 new rules. In comparison, Google Gemini Pro achieved a lower bypass rate of 63%, highlighting performance differences across LLMs.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.1 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.6 -->
                
            <!-- GNN: 2.2 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2868
            </span>
            <a href="https://arxiv.org/abs/2504.08138" target="_blank" rel="noopener noreferrer">Matrix concentration inequalities for dependent binary random variables</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Rados{\l}aw Adamczak, Ioannis Kavvadias | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We prove Bernstein-type matrix concentration inequalities for linear combinations with matrix coefficients of binary random variables satisfying certain $\ell_\infty$-independence assumptions, complementing recent results by Kaufman, Kyng and Solda. For random variables with the Stochastic Covering </span>
            
            <span class="abstract-full" style="display: none;">We prove Bernstein-type matrix concentration inequalities for linear combinations with matrix coefficients of binary random variables satisfying certain $\ell_\infty$-independence assumptions, complementing recent results by Kaufman, Kyng and Solda. For random variables with the Stochastic Covering Property or Strong Rayleigh Property we prove estimates for general functions satisfying certain direction aware matrix bounded difference inequalities, generalizing and strengthening earlier estimates by the first-named author and Polaczyk.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.9 -->
                
            <!-- Medicine: 4.8 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Math: 2.0 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2875
            </span>
            <a href="https://arxiv.org/abs/2504.08358" target="_blank" rel="noopener noreferrer">LMM4LMM: Benchmarking and Evaluating Large-multimodal Image Generation with LMMs</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Jiarui Wang, Huiyu Duan, Yu Zhao, Juntong Wang, Guangtao Zhai, Xiongkuo Min | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Recent breakthroughs in large multimodal models (LMMs) have significantly advanced both text-to-image (T2I) generation and image-to-text (I2T) interpretation. However, many generated images still suffer from issues related to perceptual quality and text-image alignment. Given the high cost and ineff</span>
            
            <span class="abstract-full" style="display: none;">Recent breakthroughs in large multimodal models (LMMs) have significantly advanced both text-to-image (T2I) generation and image-to-text (I2T) interpretation. However, many generated images still suffer from issues related to perceptual quality and text-image alignment. Given the high cost and inefficiency of manual evaluation, an automatic metric that aligns with human preferences is desirable. To this end, we present EvalMi-50K, a comprehensive dataset and benchmark for evaluating large-multimodal image generation, which features (i) comprehensive tasks, encompassing 2,100 extensive prompts across 20 fine-grained task dimensions, and (ii) large-scale human-preference annotations, including 100K mean-opinion scores (MOSs) and 50K question-answering (QA) pairs annotated on 50,400 images generated from 24 T2I models. Based on EvalMi-50K, we propose LMM4LMM, an LMM-based metric for evaluating large multimodal T2I generation from multiple dimensions including perception, text-image correspondence, and task-specific accuracy. Extensive experimental results show that LMM4LMM achieves state-of-the-art performance on EvalMi-50K, and exhibits strong generalization ability on other AI-generated image evaluation benchmark datasets, manifesting the generality of both the EvalMi-50K dataset and LMM4LMM metric. Both EvalMi-50K and LMM4LMM will be released at https://github.com/IntMeGroup/LMM4LMM.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.9 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.289
            </span>
            <a href="https://arxiv.org/abs/2409.16938" target="_blank" rel="noopener noreferrer">Generative Object Insertion in Gaussian Splatting with a Multi-View Diffusion Model</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Hongliang Zhong, Can Wang, Jingbo Zhang, Jing Liao | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Generating and inserting new objects into 3D content is a compelling approach for achieving versatile scene recreation. Existing methods, which rely on SDS optimization or single-view inpainting, often struggle to produce high-quality results. To address this, we propose a novel method for object in</span>
            
            <span class="abstract-full" style="display: none;">Generating and inserting new objects into 3D content is a compelling approach for achieving versatile scene recreation. Existing methods, which rely on SDS optimization or single-view inpainting, often struggle to produce high-quality results. To address this, we propose a novel method for object insertion in 3D content represented by Gaussian Splatting. Our approach introduces a multi-view diffusion model, dubbed MVInpainter, which is built upon a pre-trained stable video diffusion model to facilitate view-consistent object inpainting. Within MVInpainter, we incorporate a ControlNet-based conditional injection module to enable controlled and more predictable multi-view generation. After generating the multi-view inpainted results, we further propose a mask-aware 3D reconstruction technique to refine Gaussian Splatting reconstruction from these sparse inpainted views. By leveraging these fabricate techniques, our approach yields diverse results, ensures view-consistent and harmonious insertions, and produces better object quality. Extensive experiments demonstrate that our approach outperforms existing methods.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.3 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- Reinforcement Learning: 2.2 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- T2I: 1.4 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2913
            </span>
            <a href="https://arxiv.org/abs/2503.14049" target="_blank" rel="noopener noreferrer">A Modular Edge Device Network for Surgery Digitalization</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Vincent Schorp, Fr\'ed\'eric Giraud, Gianluca Parg\"atzi, Michael W\"aspe, Lorenzo von Ritter-Zahony, Marcel Wegmann, Nicola A. Cavalcanti, John Garcia Henao, Nicholas B\"unger, Dominique Cachin, Sebastiano Caprara, Philipp F\"urnstahl, Fabio Carrillo | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Future surgical care demands real-time, integrated data to drive informed decision-making and improve patient outcomes. The pressing need for seamless and efficient data capture in the OR motivates our development of a modular solution that bridges the gap between emerging machine learning technique</span>
            
            <span class="abstract-full" style="display: none;">Future surgical care demands real-time, integrated data to drive informed decision-making and improve patient outcomes. The pressing need for seamless and efficient data capture in the OR motivates our development of a modular solution that bridges the gap between emerging machine learning techniques and interventional medicine. We introduce a network of edge devices, called Data Hubs (DHs), that interconnect diverse medical sensors, imaging systems, and robotic tools via optical fiber and a centralized network switch. Built on the NVIDIA Jetson Orin NX, each DH supports multiple interfaces (HDMI, USB-C, Ethernet) and encapsulates device-specific drivers within Docker containers using the Isaac ROS framework and ROS2. A centralized user interface enables straightforward configuration and real-time monitoring, while an Nvidia DGX computer provides state-of-the-art data processing and storage. We validate our approach through an ultrasound-based 3D anatomical reconstruction experiment that combines medical imaging, pose tracking, and RGB-D data acquisition.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.9 -->
                
            <!-- Medicine: 4.8 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 3.6 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Robotics: 1.8 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2914
            </span>
            <a href="https://arxiv.org/abs/2503.17365" target="_blank" rel="noopener noreferrer">How Effective Is Constitutional AI in Small LLMs? A Study on DeepSeek-R1 and Its Peers</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Antonio-Gabriel Chac\'on Menke (Shibaura Institute of Technology, Kempten University of Applied Sciences), Phan Xuan Tan (Shibaura Institute of Technology) | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Recent incidents highlight safety risks in Large Language Models (LLMs), motivating research into alignment methods like Constitutional AI (CAI). This paper explores CAI's self-critique mechanism on small, uncensored 7-9B parameter models: DeepSeek-R1-8B, Gemma-2-9B, Llama 3.1-8B, and Qwen2.5-7B. We</span>
            
            <span class="abstract-full" style="display: none;">Recent incidents highlight safety risks in Large Language Models (LLMs), motivating research into alignment methods like Constitutional AI (CAI). This paper explores CAI's self-critique mechanism on small, uncensored 7-9B parameter models: DeepSeek-R1-8B, Gemma-2-9B, Llama 3.1-8B, and Qwen2.5-7B. We show that while Llama-based models exhibited significant harm reduction through self-critique, other architectures demonstrated less improvement in harm detection after abliteration. These results suggest CAI's effectiveness may vary depending on model architecture and reasoning capabilities.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.5 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 4.1 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2956
            </span>
            <a href="https://arxiv.org/abs/2504.08166" target="_blank" rel="noopener noreferrer">Learning Object Focused Attention</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Vivek Trivedy, Amani Almalki, Longin Jan Latecki | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We propose an adaptation to the training of Vision Transformers (ViTs) that allows for an explicit modeling of objects during the attention computation. This is achieved by adding a new branch to selected attention layers that computes an auxiliary loss which we call the object-focused attention (OF</span>
            
            <span class="abstract-full" style="display: none;">We propose an adaptation to the training of Vision Transformers (ViTs) that allows for an explicit modeling of objects during the attention computation. This is achieved by adding a new branch to selected attention layers that computes an auxiliary loss which we call the object-focused attention (OFA) loss. We restrict the attention to image patches that belong to the same object class, which allows ViTs to gain a better understanding of configural (or holistic) object shapes by focusing on intra-object patches instead of other patches such as those in the background. Our proposed inductive bias fits easily into the attention framework of transformers since it only adds an auxiliary loss over selected attention layers. Furthermore, our approach has no additional overhead during inference. We also experiment with multiscale masking to further improve the performance of our OFA model and give a path forward for self-supervised learning with our method. Our experimental results demonstrate that ViTs with OFA achieve better classification results than their base models, exhibit a stronger generalization ability to out-of-distribution (OOD) and adversarially corrupted images, and learn representations based on object shapes rather than spurious correlations via general textures. For our OOD setting, we generate a novel dataset using the COCO dataset and Stable Diffusion inpainting which we plan to share with the community.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.6 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 4.1 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Math: 2.0 -->
                
            <!-- Federated Learning: 1.7 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2971
            </span>
            <a href="https://arxiv.org/abs/2409.10410" target="_blank" rel="noopener noreferrer">Sharp Estimates for Optimal Multistage Group Partition Testing</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Guojiang Shao | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">In multistage group testing, the tests within the same stage are considered nonadaptive, while those conducted across different stages are adaptive. Specifically, when the pools within the same stage are disjoint, meaning that the entire set is divided into several disjoint subgroups, it is referred</span>
            
            <span class="abstract-full" style="display: none;">In multistage group testing, the tests within the same stage are considered nonadaptive, while those conducted across different stages are adaptive. Specifically, when the pools within the same stage are disjoint, meaning that the entire set is divided into several disjoint subgroups, it is referred to as a multistage group partition testing problem, denoted as the (n, d, s) problem, where n, d, and s represent the total number of items, defectives, and stages respectively. This paper presents exact solutions for the (n, 1, s) and (n, d, 2) problems for the first time. Additionally, a general dynamic programming approach is developed for the (n, d, s) problem. Significantly we give the sharp upper and lower bounds estimates. If the defective number in unknown but bounded, we can provide an algorithm with an optimal competitive ratio in the asymptotic sense. While assuming the prior distribution of the defective items, we also establish a well performing upper and lower bound estimate to the expectation of optimal strategy</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.4 -->
                
            <!-- Medicine: 4.3 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- Math: 2.3 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.3 -->
                
            <!-- SpikingNN: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.2982
            </span>
            <a href="https://arxiv.org/abs/2504.08271" target="_blank" rel="noopener noreferrer">Self-Stabilizing Weakly Byzantine Perpetual Gathering of Mobile Agents</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Jion Hirose, Ryota Eguchi, Yuichi Sudo | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We study the \emph{Byzantine} gathering problem involving $k$ mobile agents with unique identifiers (IDs), $f$ of which are Byzantine. These agents start the execution of a common algorithm from (possibly different) nodes in an $n$-node network, potentially starting at different times. Once started,</span>
            
            <span class="abstract-full" style="display: none;">We study the \emph{Byzantine} gathering problem involving $k$ mobile agents with unique identifiers (IDs), $f$ of which are Byzantine. These agents start the execution of a common algorithm from (possibly different) nodes in an $n$-node network, potentially starting at different times. Once started, the agents operate in synchronous rounds. We focus on \emph{weakly} Byzantine environments, where Byzantine agents can behave arbitrarily but cannot falsify their IDs. The goal is for all \emph{non-Byzantine} agents to eventually terminate at a single node simultaneously.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.3 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- Math: 2.0 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3051
            </span>
            <a href="https://arxiv.org/abs/2504.06121" target="_blank" rel="noopener noreferrer">A Robust Real-Time Lane Detection Method with Fog-Enhanced Feature Fusion for Foggy Conditions</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Ronghui Zhang, Yuhang Ma, Tengfei Li, Ziyu Lin, Yueying Wu, Junzhou Chen, Lin Zhang, Jia Hu, Tony Z. Qiu, Konghui Guo | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Lane detection is a critical component of Advanced Driver Assistance Systems (ADAS). Existing lane detection algorithms generally perform well under favorable weather conditions. However, their performance degrades significantly in adverse conditions, such as fog, which increases the risk of traffic</span>
            
            <span class="abstract-full" style="display: none;">Lane detection is a critical component of Advanced Driver Assistance Systems (ADAS). Existing lane detection algorithms generally perform well under favorable weather conditions. However, their performance degrades significantly in adverse conditions, such as fog, which increases the risk of traffic accidents. This challenge is compounded by the lack of specialized datasets and methods designed for foggy environments. To address this, we introduce the FoggyLane dataset, captured in real-world foggy scenarios, and synthesize two additional datasets, FoggyCULane and FoggyTusimple, from existing popular lane detection datasets. Furthermore, we propose a robust Fog-Enhanced Network for lane detection, incorporating a Global Feature Fusion Module (GFFM) to capture global relationships in foggy images, a Kernel Feature Fusion Module (KFFM) to model the structural and positional relationships of lane instances, and a Low-level Edge Enhanced Module (LEEM) to address missing edge details in foggy conditions. Comprehensive experiments demonstrate that our method achieves state-of-the-art performance, with F1-scores of 95.04 on FoggyLane, 79.85 on FoggyCULane, and 96.95 on FoggyTusimple. Additionally, with TensorRT acceleration, the method reaches a processing speed of 38.4 FPS on the NVIDIA Jetson AGX Orin, confirming its real-time capabilities and robustness in foggy environments.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.6 -->
                
            <!-- Medicine: 5.1 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3063
            </span>
            <a href="https://arxiv.org/abs/2504.08651" target="_blank" rel="noopener noreferrer">Application of machine learning models to predict the relationship between air pollution, ecosystem degradation, and health disparities and lung cancer in Vietnam</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Ngoc Hong Tran, Lan Kim Vien, Ngoc-Thao Thi Le | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Lung cancer is one of the major causes of death worldwide, and Vietnam is not an exception. This disease is the second most common type of cancer globally and the second most common cause of death in Vietnam, just after liver cancer, with 23,797 fatal cases and 26,262 new cases, or 14.4% of the dise</span>
            
            <span class="abstract-full" style="display: none;">Lung cancer is one of the major causes of death worldwide, and Vietnam is not an exception. This disease is the second most common type of cancer globally and the second most common cause of death in Vietnam, just after liver cancer, with 23,797 fatal cases and 26,262 new cases, or 14.4% of the disease in 2020. Recently, with rising disease rates in Vietnam causing a huge public health burden, lung cancer continues to hold the top position in attention and care. Especially together with climate change, under a variety of types of pollution, deforestation, and modern lifestyles, lung cancer risks are on red alert, particularly in Vietnam. To understand more about the severe disease sources in Vietnam from a diversity of key factors, including environmental features and the current health state, with a particular emphasis on Vietnam's distinct socioeconomic and ecological context, we utilize large datasets such as patient health records and environmental indicators containing necessary information, such as deforestation rate, green cover rate, air pollution, and lung cancer risks, that is collected from well-known governmental sharing websites. Then, we process and connect them and apply analytical methods (heatmap, information gain, p-value, spearman correlation) to determine causal correlations influencing lung cancer risks. Moreover, we deploy machine learning (ML) models (Decision Tree, Random Forest, Support Vector Machine, K-mean clustering) to discover cancer risk patterns. Our experimental results, leveraged by the aforementioned ML models to identify the disease patterns, are promising, particularly, the models as Random Forest, SVM, and PCA are working well on the datasets and give high accuracy (99%), however, the K means clustering has very low accuracy (10%) and does not fit the datasets.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.3 -->
                
            <!-- Medicine: 5.1 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3074
            </span>
            <a href="https://arxiv.org/abs/2504.08054" target="_blank" rel="noopener noreferrer">Multi-Task Learning with Multi-Annotation Triplet Loss for Improved Object Detection</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Meilun Zhou, Aditya Dutt, Alina Zare | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Triplet loss traditionally relies only on class labels and does not use all available information in multi-task scenarios where multiple types of annotations are available. This paper introduces a Multi-Annotation Triplet Loss (MATL) framework that extends triplet loss by incorporating additional an</span>
            
            <span class="abstract-full" style="display: none;">Triplet loss traditionally relies only on class labels and does not use all available information in multi-task scenarios where multiple types of annotations are available. This paper introduces a Multi-Annotation Triplet Loss (MATL) framework that extends triplet loss by incorporating additional annotations, such as bounding box information, alongside class labels in the loss formulation. By using these complementary annotations, MATL improves multi-task learning for tasks requiring both classification and localization. Experiments on an aerial wildlife imagery dataset demonstrate that MATL outperforms conventional triplet loss in both classification and localization. These findings highlight the benefit of using all available annotations for triplet loss in multi-task learning frameworks.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.7 -->
                
            <!-- Medicine: 4.5 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3079
            </span>
            <a href="https://arxiv.org/abs/2411.10193" target="_blank" rel="noopener noreferrer">DiMoDif: Discourse Modality-information Differentiation for Audio-visual Deepfake Detection and Localization</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Christos Koutlis, Symeon Papadopoulos | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Deepfake technology has rapidly advanced and poses significant threats to information integrity and trust in online multimedia. While significant progress has been made in detecting deepfakes, the simultaneous manipulation of audio and visual modalities, sometimes at small parts or in subtle ways, p</span>
            
            <span class="abstract-full" style="display: none;">Deepfake technology has rapidly advanced and poses significant threats to information integrity and trust in online multimedia. While significant progress has been made in detecting deepfakes, the simultaneous manipulation of audio and visual modalities, sometimes at small parts or in subtle ways, presents highly challenging detection scenarios. To address these challenges, we present DiMoDif, an audio-visual deepfake detection framework that leverages the inter-modality differences in machine perception of speech, based on the assumption that in real samples -- in contrast to deepfakes -- visual and audio signals coincide in terms of information. DiMoDif leverages features from deep networks that specialize in visual and audio speech recognition to spot frame-level cross-modal incongruities, and in that way to temporally localize the deepfake forgery. To this end, we devise a hierarchical cross-modal fusion network, integrating adaptive temporal alignment modules and a learned discrepancy mapping layer to explicitly model the subtle differences between visual and audio representations. Then, the detection model is optimized through a composite loss function accounting for frame-level detections and fake intervals localization. DiMoDif outperforms the state-of-the-art on the Deepfake Detection task by 30.5 AUC on the highly challenging AV-Deepfake1M, while it performs exceptionally on FakeAVCeleb and LAV-DF. On the Temporal Forgery Localization task, it outperforms the state-of-the-art by 47.88 AP@0.75 on AV-Deepfake1M, and performs on-par on LAV-DF. Code available at https://github.com/mever-team/dimodif.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.0 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Federated Learning: 1.8 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3088
            </span>
            <a href="https://arxiv.org/abs/2504.08655" target="_blank" rel="noopener noreferrer">TinyCenterSpeed: Efficient Center-Based Object Detection for Autonomous Racing</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Neil Reichlin, Nicolas Baumann, Edoardo Ghignone, Michele Magno | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Perception within autonomous driving is nearly synonymous with Neural Networks (NNs). Yet, the domain of autonomous racing is often characterized by scaled, computationally limited robots used for cost-effectiveness and safety. For this reason, opponent detection and tracking systems typically resor</span>
            
            <span class="abstract-full" style="display: none;">Perception within autonomous driving is nearly synonymous with Neural Networks (NNs). Yet, the domain of autonomous racing is often characterized by scaled, computationally limited robots used for cost-effectiveness and safety. For this reason, opponent detection and tracking systems typically resort to traditional computer vision techniques due to computational constraints. This paper introduces TinyCenterSpeed, a streamlined adaptation of the seminal CenterPoint method, optimized for real-time performance on 1:10 scale autonomous racing platforms. This adaptation is viable even on OBCs powered solely by Central Processing Units (CPUs), as it incorporates the use of an external Tensor Processing Unit (TPU). We demonstrate that, compared to Adaptive Breakpoint Detector (ABD), the current State-of-the-Art (SotA) in scaled autonomous racing, TinyCenterSpeed not only improves detection and velocity estimation by up to 61.38% but also supports multi-opponent detection and estimation. It achieves real-time performance with an inference time of just 7.88 ms on the TPU, significantly reducing CPU utilization 8.3-fold.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.2 -->
                
            <!-- Medicine: 5.0 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3107
            </span>
            <a href="https://arxiv.org/abs/2504.08687" target="_blank" rel="noopener noreferrer">Voice Interaction With Conversational AI Could Facilitate Thoughtful Reflection and Substantive Revision in Writing</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Jiho Kim, Philippe Laban, Xiang 'Anthony' Chen, Kenneth C. Arnold | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Writing well requires not only expressing ideas but also refining them through revision, a process facilitated by reflection. Prior research suggests that feedback delivered through dialogues, such as those in writing center tutoring sessions, can help writers reflect more thoughtfully on their work</span>
            
            <span class="abstract-full" style="display: none;">Writing well requires not only expressing ideas but also refining them through revision, a process facilitated by reflection. Prior research suggests that feedback delivered through dialogues, such as those in writing center tutoring sessions, can help writers reflect more thoughtfully on their work compared to static feedback. Recent advancements in multi-modal large language models (LLMs) now offer new possibilities for supporting interactive and expressive voice-based reflection in writing. In particular, we propose that LLM-generated static feedback can be repurposed as conversation starters, allowing writers to seek clarification, request examples, and ask follow-up questions, thereby fostering deeper reflection on their writing. We argue that voice-based interaction can naturally facilitate this conversational exchange, encouraging writers' engagement with higher-order concerns, facilitating iterative refinement of their reflections, and reduce cognitive load compared to text-based interactions. To investigate these effects, we propose a formative study exploring how text vs. voice input influence writers' reflection and subsequent revisions. Findings from this study will inform the design of intelligent and interactive writing tools, offering insights into how voice-based interactions with LLM-powered conversational agents can support reflection and revision.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.5 -->
                
            <!-- Medicine: 4.8 -->
                
            <!-- Quantum Computing: 4.1 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3126
            </span>
            <a href="https://arxiv.org/abs/2412.04914" target="_blank" rel="noopener noreferrer">Achieving Group Fairness through Independence in Predictive Process Monitoring</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Jari Peeperkorn, Simon De Vos | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Predictive process monitoring focuses on forecasting future states of ongoing process executions, such as predicting the outcome of a particular case. In recent years, the application of machine learning models in this domain has garnered significant scientific attention. When using historical execu</span>
            
            <span class="abstract-full" style="display: none;">Predictive process monitoring focuses on forecasting future states of ongoing process executions, such as predicting the outcome of a particular case. In recent years, the application of machine learning models in this domain has garnered significant scientific attention. When using historical execution data, which may contain biases or exhibit unfair behavior, these biases may be encoded into the trained models. Consequently, when such models are deployed to make decisions or guide interventions for new cases, they risk perpetuating this unwanted behavior. This work addresses group fairness in predictive process monitoring by investigating independence, i.e. ensuring predictions are unaffected by sensitive group membership. We explore independence through metrics for demographic parity such as $\Delta$DP, as well as recently introduced, threshold-independent distribution-based alternatives. Additionally, we propose a composite loss function existing of binary cross-entropy and a distribution-based loss (Wasserstein) to train models that balance predictive performance and fairness, and allow for customizable trade-offs. The effectiveness of both the fairness metrics and the composite loss functions is validated through a controlled experimental setup.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.3 -->
                
            <!-- Medicine: 5.2 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3129
            </span>
            <a href="https://arxiv.org/abs/2504.08266" target="_blank" rel="noopener noreferrer">$\chi$-Boundedness and Neighbourhood Complexity of Bounded Merge-Width Graphs</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Marthe Bonamy, Colin Geniet | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Merge-width, recently introduced by Dreier and Toru\'nczyk, is a common generalisation of bounded expansion classes and twin-width for which the first-order model checking problem remains tractable. We prove that a number of basic properties shared by bounded expansion and bounded twin-width graphs </span>
            
            <span class="abstract-full" style="display: none;">Merge-width, recently introduced by Dreier and Toru\'nczyk, is a common generalisation of bounded expansion classes and twin-width for which the first-order model checking problem remains tractable. We prove that a number of basic properties shared by bounded expansion and bounded twin-width graphs also hold for bounded merge-width graphs: they are $\chi$-bounded, they satisfy the strong Erd\H{o}s-Hajnal property, and their neighbourhood complexity is linear.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.0 -->
                
            <!-- Medicine: 5.0 -->
                
            <!-- Quantum Computing: 4.1 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- Math: 2.0 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Robotics: 1.9 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- SpikingNN: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3193
            </span>
            <a href="https://arxiv.org/abs/2504.05343" target="_blank" rel="noopener noreferrer">AROMA: Autonomous Rank-one Matrix Adaptation</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Hao Nan Sheng, Zhi-yong Wang, Mingrui Yang, Hing Cheung So | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">As large language models continue to grow in size, parameter-efficient fine-tuning (PEFT) has become increasingly crucial. While low-rank adaptation (LoRA) offers a solution through low-rank updates, its static rank allocation may yield suboptimal results. Adaptive low-rank adaptation (AdaLoRA) impr</span>
            
            <span class="abstract-full" style="display: none;">As large language models continue to grow in size, parameter-efficient fine-tuning (PEFT) has become increasingly crucial. While low-rank adaptation (LoRA) offers a solution through low-rank updates, its static rank allocation may yield suboptimal results. Adaptive low-rank adaptation (AdaLoRA) improves this with dynamic allocation but remains sensitive to initial and target rank configurations. We introduce AROMA, a framework that automatically constructs layer-specific updates by iteratively building up rank-one components with very few trainable parameters that gradually diminish to zero. Unlike existing methods that employ rank reduction mechanisms, AROMA introduces a dual-loop architecture for rank growth. The inner loop extracts information from each rank-one subspace, while the outer loop determines the number of rank-one subspaces, i.e., the optimal rank. We reset optimizer states to maintain subspace independence. AROMA significantly reduces parameters compared to LoRA and AdaLoRA while achieving superior performance on natural language understanding and commonsense reasoning tasks, offering new insights into adaptive PEFT. The code is available at \href{https://github.com/ShuDun23/AROMA}{AROMA}.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.5 -->
                
            <!-- Medicine: 4.8 -->
                
            <!-- Quantum Computing: 4.1 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3214
            </span>
            <a href="https://arxiv.org/abs/2504.07976" target="_blank" rel="noopener noreferrer">EquiNO: A Physics-Informed Neural Operator for Multiscale Simulations</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Hamidreza Eivazi, Jendrik-Alexander Tr\"oger, Stefan Wittek, Stefan Hartmann, Andreas Rausch | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Multiscale problems are ubiquitous in physics. Numerical simulations of such problems by solving partial differential equations (PDEs) at high resolution are computationally too expensive for many-query scenarios, e.g., uncertainty quantification, remeshing applications, topology optimization, and s</span>
            
            <span class="abstract-full" style="display: none;">Multiscale problems are ubiquitous in physics. Numerical simulations of such problems by solving partial differential equations (PDEs) at high resolution are computationally too expensive for many-query scenarios, e.g., uncertainty quantification, remeshing applications, topology optimization, and so forth. This limitation has motivated the application of data-driven surrogate models, where the microscale computations are $\textit{substituted}$ with a surrogate, usually acting as a black-box mapping between macroscale quantities. These models offer significant speedups but struggle with incorporating microscale physical constraints, such as the balance of linear momentum and constitutive models. In this contribution, we propose Equilibrium Neural Operator (EquiNO) as a $\textit{complementary}$ physics-informed PDE surrogate for predicting microscale physics and compare it with variational physics-informed neural and operator networks. Our framework, applicable to the so-called multiscale FE$^{\,2}\,$ computations, introduces the FE-OL approach by integrating the finite element (FE) method with operator learning (OL). We apply the proposed FE-OL approach to quasi-static problems of solid mechanics. The results demonstrate that FE-OL can yield accurate solutions even when confronted with a restricted dataset during model development. Our results show that EquiNO achieves speedup factors exceeding 8000-fold compared to traditional methods and offers an optimal balance between data-driven and physics-based strategies.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.0 -->
                
            <!-- Medicine: 4.5 -->
                
            <!-- Quantum Computing: 4.1 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- GNN: 2.2 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3235
            </span>
            <a href="https://arxiv.org/abs/2502.03979" target="_blank" rel="noopener noreferrer">Towards Unified Music Emotion Recognition across Dimensional and Categorical Models</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Jaeyong Kang, Dorien Herremans | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">One of the most significant challenges in Music Emotion Recognition (MER) comes from the fact that emotion labels can be heterogeneous across datasets with regard to the emotion representation, including categorical (e.g., happy, sad) versus dimensional labels (e.g., valence-arousal). In this paper,</span>
            
            <span class="abstract-full" style="display: none;">One of the most significant challenges in Music Emotion Recognition (MER) comes from the fact that emotion labels can be heterogeneous across datasets with regard to the emotion representation, including categorical (e.g., happy, sad) versus dimensional labels (e.g., valence-arousal). In this paper, we present a unified multitask learning framework that combines these two types of labels and is thus able to be trained on multiple datasets. This framework uses an effective input representation that combines musical features (i.e., key and chords) and MERT embeddings. Moreover, knowledge distillation is employed to transfer the knowledge of teacher models trained on individual datasets to a student model, enhancing its ability to generalize across multiple tasks. To validate our proposed framework, we conducted extensive experiments on a variety of datasets, including MTG-Jamendo, DEAM, PMEmo, and EmoMusic. According to our experimental results, the inclusion of musical features, multitask learning, and knowledge distillation significantly enhances performance. In particular, our model outperforms the state-of-the-art models, including the best-performing model from the MediaEval 2021 competition on the MTG-Jamendo dataset. Our work makes a significant contribution to MER by allowing the combination of categorical and dimensional emotion labels in one unified framework, thus enabling training across datasets.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.2 -->
                
            <!-- Medicine: 4.8 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Networks: 2.8 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 2.0 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Federated Learning: 1.7 -->
                
            <!-- SpikingNN: 1.3 -->
                
            <!-- Robotics: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3239
            </span>
            <a href="https://arxiv.org/abs/2504.06176" target="_blank" rel="noopener noreferrer">A Self-Supervised Framework for Space Object Behaviour Characterisation</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Ian Groves, Andrew Campbell, James Fernandes, Diego Ram\'irez Rodr\'iguez, Paul Murray, Massimiliano Vasile, Victoria Nockles | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Foundation Models, pre-trained on large unlabelled datasets before task-specific fine-tuning, are increasingly being applied to specialised domains. Recent examples include ClimaX for climate and Clay for satellite Earth observation, but a Foundation Model for Space Object Behavioural Analysis has n</span>
            
            <span class="abstract-full" style="display: none;">Foundation Models, pre-trained on large unlabelled datasets before task-specific fine-tuning, are increasingly being applied to specialised domains. Recent examples include ClimaX for climate and Clay for satellite Earth observation, but a Foundation Model for Space Object Behavioural Analysis has not yet been developed. As orbital populations grow, automated methods for characterising space object behaviour are crucial for space safety. We present a Space Safety and Sustainability Foundation Model focusing on space object behavioural analysis using light curves (LCs). We implemented a Perceiver-Variational Autoencoder (VAE) architecture, pre-trained with self-supervised reconstruction and masked reconstruction on 227,000 LCs from the MMT-9 observatory. The VAE enables anomaly detection, motion prediction, and LC generation. We fine-tuned the model for anomaly detection & motion prediction using two independent LC simulators (CASSANDRA and GRIAL respectively), using CAD models of boxwing, Sentinel-3, SMOS, and Starlink platforms. Our pre-trained model achieved a reconstruction error of 0.01%, identifying potentially anomalous light curves through reconstruction difficulty. After fine-tuning, the model scored 88% and 82% accuracy, with 0.90 and 0.95 ROC AUC scores respectively in both anomaly detection and motion mode prediction (sun-pointing, spin, etc.). Analysis of high-confidence anomaly predictions on real data revealed distinct patterns including characteristic object profiles and satellite glinting. Here, we demonstrate how self-supervised learning can simultaneously enable anomaly detection, motion prediction, and synthetic data generation from rich representations learned in pre-training. Our work therefore supports space safety and sustainability through automated monitoring and simulation capabilities.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.1 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Robotics: 1.9 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3271
            </span>
            <a href="https://arxiv.org/abs/2504.08395" target="_blank" rel="noopener noreferrer">Human strategies for correcting `human-robot' errors during a laundry sorting task</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Pepita Barnard, Maria J Galvez Trigo, Dominic Price, Sue Cobb, Gisela Reyes-Cruz, Gustavo Berumen, David Branson III, Mojtaba A. Khanesar, Mercedes Torres Torres, Michel Valstar | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Mental models and expectations underlying human-human interaction (HHI) inform human-robot interaction (HRI) with domestic robots. To ease collaborative home tasks by improving domestic robot speech and behaviours for human-robot communication, we designed a study to understand how people communicat</span>
            
            <span class="abstract-full" style="display: none;">Mental models and expectations underlying human-human interaction (HHI) inform human-robot interaction (HRI) with domestic robots. To ease collaborative home tasks by improving domestic robot speech and behaviours for human-robot communication, we designed a study to understand how people communicated when failure occurs. To identify patterns of natural communication, particularly in response to robotic failures, participants instructed Laundrobot to move laundry into baskets using natural language and gestures. Laundrobot either worked error-free, or in one of two error modes. Participants were not advised Laundrobot would be a human actor, nor given information about error modes. Video analysis from 42 participants found speech patterns, included laughter, verbal expressions, and filler words, such as ``oh'' and ``ok'', also, sequences of body movements, including touching one's own face, increased pointing with a static finger, and expressions of surprise. Common strategies deployed when errors occurred, included correcting and teaching, taking responsibility, and displays of frustration. The strength of reaction to errors diminished with exposure, possibly indicating acceptance or resignation. Some used strategies similar to those used to communicate with other technologies, such as smart assistants. An anthropomorphic robot may not be ideally suited to this kind of task. Laundrobot's appearance, morphology, voice, capabilities, and recovery strategies may have impacted how it was perceived. Some participants indicated Laundrobot's actual skills were not aligned with expectations; this made it difficult to know what to expect and how much Laundrobot understood. Expertise, personality, and cultural differences may affect responses, however these were not assessed.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.6 -->
                
            <!-- Medicine: 4.8 -->
                
            <!-- Quantum Computing: 4.1 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3289
            </span>
            <a href="https://arxiv.org/abs/2504.08540" target="_blank" rel="noopener noreferrer">Datasets for Lane Detection in Autonomous Driving: A Comprehensive Review</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: J\"org Gamerdinger, Sven Teufel, Oliver Bringmann | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Accurate lane detection is essential for automated driving, enabling safe and reliable vehicle navigation in a variety of road scenarios. Numerous datasets have been introduced to support the development and evaluation of lane detection algorithms, each differing in terms of the amount of data, sens</span>
            
            <span class="abstract-full" style="display: none;">Accurate lane detection is essential for automated driving, enabling safe and reliable vehicle navigation in a variety of road scenarios. Numerous datasets have been introduced to support the development and evaluation of lane detection algorithms, each differing in terms of the amount of data, sensor types, annotation granularity, environmental conditions, and scenario diversity. This paper provides a comprehensive review of over 30 publicly available lane detection datasets, systematically analysing their characteristics, advantages and limitations. We classify these datasets based on key factors such as sensor resolution, annotation types and diversity of road and weather conditions. By identifying existing challenges and research gaps, we highlight opportunities for future dataset improvements that can further drive innovation in robust lane detection. This survey serves as a resource for researchers seeking appropriate datasets for lane detection, and contributes to the broader goal of advancing autonomous driving.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.4 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 4.3 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3306
            </span>
            <a href="https://arxiv.org/abs/2504.08003" target="_blank" rel="noopener noreferrer">Have we unified image generation and understanding yet? An empirical study of GPT-4o's image generation ability</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Ning Li, Jingran Zhang, Justin Cui | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">OpenAI's multimodal GPT-4o has demonstrated remarkable capabilities in image generation and editing, yet its ability to achieve world knowledge-informed semantic synthesis--seamlessly integrating domain knowledge, contextual reasoning, and instruction adherence--remains unproven. In this study, we s</span>
            
            <span class="abstract-full" style="display: none;">OpenAI's multimodal GPT-4o has demonstrated remarkable capabilities in image generation and editing, yet its ability to achieve world knowledge-informed semantic synthesis--seamlessly integrating domain knowledge, contextual reasoning, and instruction adherence--remains unproven. In this study, we systematically evaluate these capabilities across three critical dimensions: (1) Global Instruction Adherence, (2) Fine-Grained Editing Precision, and (3) Post-Generation Reasoning. While existing benchmarks highlight GPT-4o's strong capabilities in image generation and editing, our evaluation reveals GPT-4o's persistent limitations: the model frequently defaults to literal interpretations of instructions, inconsistently applies knowledge constraints, and struggles with conditional reasoning tasks. These findings challenge prevailing assumptions about GPT-4o's unified understanding and generation capabilities, exposing significant gaps in its dynamic knowledge integration. Our study calls for the development of more robust benchmarks and training strategies that go beyond surface-level alignment, emphasizing context-aware and reasoning-grounded multimodal generation.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.4 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 4.1 -->
                
            <!-- Networks: 3.0 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3337
            </span>
            <a href="https://arxiv.org/abs/2504.08231" target="_blank" rel="noopener noreferrer">Out of Style: RAG's Fragility to Linguistic Variation</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Tianyu Cao, Neel Bhandari, Akhila Yerukola, Akari Asai, Maarten Sap | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Despite the impressive performance of Retrieval-augmented Generation (RAG) systems across various NLP benchmarks, their robustness in handling real-world user-LLM interaction queries remains largely underexplored. This presents a critical gap for practical deployment, where user queries exhibit grea</span>
            
            <span class="abstract-full" style="display: none;">Despite the impressive performance of Retrieval-augmented Generation (RAG) systems across various NLP benchmarks, their robustness in handling real-world user-LLM interaction queries remains largely underexplored. This presents a critical gap for practical deployment, where user queries exhibit greater linguistic variations and can trigger cascading errors across interdependent RAG components. In this work, we systematically analyze how varying four linguistic dimensions (formality, readability, politeness, and grammatical correctness) impact RAG performance. We evaluate two retrieval models and nine LLMs, ranging from 3 to 72 billion parameters, across four information-seeking Question Answering (QA) datasets. Our results reveal that linguistic reformulations significantly impact both retrieval and generation stages, leading to a relative performance drop of up to 40.41% in Recall@5 scores for less formal queries and 38.86% in answer match scores for queries containing grammatical errors. Notably, RAG systems exhibit greater sensitivity to such variations compared to LLM-only generations, highlighting their vulnerability to error propagation due to linguistic shifts. These findings highlight the need for improved robustness techniques to enhance reliability in diverse user interactions.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.6 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 4.1 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- GNN: 2.2 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Math: 1.6 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3344
            </span>
            <a href="https://arxiv.org/abs/2411.17459" target="_blank" rel="noopener noreferrer">WF-VAE: Enhancing Video VAE by Wavelet-Driven Energy Flow for Latent Video Diffusion Model</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Zongjian Li, Bin Lin, Yang Ye, Liuhan Chen, Xinhua Cheng, Shenghai Yuan, Li Yuan | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Video Variational Autoencoder (VAE) encodes videos into a low-dimensional latent space, becoming a key component of most Latent Video Diffusion Models (LVDMs) to reduce model training costs. However, as the resolution and duration of generated videos increase, the encoding cost of Video VAEs becomes</span>
            
            <span class="abstract-full" style="display: none;">Video Variational Autoencoder (VAE) encodes videos into a low-dimensional latent space, becoming a key component of most Latent Video Diffusion Models (LVDMs) to reduce model training costs. However, as the resolution and duration of generated videos increase, the encoding cost of Video VAEs becomes a limiting bottleneck in training LVDMs. Moreover, the block-wise inference method adopted by most LVDMs can lead to discontinuities of latent space when processing long-duration videos. The key to addressing the computational bottleneck lies in decomposing videos into distinct components and efficiently encoding the critical information. Wavelet transform can decompose videos into multiple frequency-domain components and improve the efficiency significantly, we thus propose Wavelet Flow VAE (WF-VAE), an autoencoder that leverages multi-level wavelet transform to facilitate low-frequency energy flow into latent representation. Furthermore, we introduce a method called Causal Cache, which maintains the integrity of latent space during block-wise inference. Compared to state-of-the-art video VAEs, WF-VAE demonstrates superior performance in both PSNR and LPIPS metrics, achieving 2x higher throughput and 4x lower memory consumption while maintaining competitive reconstruction quality. Our code and models are available at https://github.com/PKU-YuanGroup/WF-VAE.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.3 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3357
            </span>
            <a href="https://arxiv.org/abs/2504.08399" target="_blank" rel="noopener noreferrer">Beyond Self-Reports: Multi-Observer Agents for Personality Assessment in Large Language Models</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Yin Jou Huang, Rafik Hadfi | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">There is a growing interest in assessing the personality traits of Large language models (LLMs). However, traditional personality assessments based on self-report questionnaires may fail to capture their true behavioral nuances due to inherent biases and meta-knowledge contamination. This paper intr</span>
            
            <span class="abstract-full" style="display: none;">There is a growing interest in assessing the personality traits of Large language models (LLMs). However, traditional personality assessments based on self-report questionnaires may fail to capture their true behavioral nuances due to inherent biases and meta-knowledge contamination. This paper introduces a novel multi-observer framework for LLM personality assessment that draws inspiration from informant-report methods in psychology. Instead of relying solely on self-assessments, our approach employs multiple observer agents configured with a specific relationship context (e.g., family, friend, or workplace) to simulate interactive scenarios with a subject LLM. These observers engage in dialogues and subsequently provide ratings across the Big Five personality dimensions. Our experiments reveal that LLMs possess systematic biases in self-report personality ratings. Moreover, aggregating observer ratings effectively reduces non-systematic biases and achieves optimal reliability with 5-7 observers. The findings highlight the significant impact of relationship context on personality perception and demonstrate that a multi-observer paradigm yields a more robust and context-sensitive evaluation of LLM personality traits.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 9.2 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- GNN: 2.3 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3362
            </span>
            <a href="https://arxiv.org/abs/2504.08172" target="_blank" rel="noopener noreferrer">Enhanced Cooperative Perception Through Asynchronous Vehicle to Infrastructure Framework with Delay Mitigation for Connected and Automated Vehicles</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Nithish Kumar Saravanan, Varun Jammula, Yezhou Yang, Jeffrey Wishart, Junfeng Zhao | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Perception is a key component of Automated vehicles (AVs). However, sensors mounted to the AVs often encounter blind spots due to obstructions from other vehicles, infrastructure, or objects in the surrounding area. While recent advancements in planning and control algorithms help AVs react to sudde</span>
            
            <span class="abstract-full" style="display: none;">Perception is a key component of Automated vehicles (AVs). However, sensors mounted to the AVs often encounter blind spots due to obstructions from other vehicles, infrastructure, or objects in the surrounding area. While recent advancements in planning and control algorithms help AVs react to sudden object appearances from blind spots at low speeds and less complex scenarios, challenges remain at high speeds and complex intersections. Vehicle to Infrastructure (V2I) technology promises to enhance scene representation for AVs in complex intersections, providing sufficient time and distance to react to adversary vehicles violating traffic rules. Most existing methods for infrastructure-based vehicle detection and tracking rely on LIDAR, RADAR or sensor fusion methods, such as LIDAR-Camera and RADAR-Camera. Although LIDAR and RADAR provide accurate spatial information, the sparsity of point cloud data limits its ability to capture detailed object contours of objects far away, resulting in inaccurate 3D object detection results. Furthermore, the absence of LIDAR or RADAR at every intersection increases the cost of implementing V2I technology. To address these challenges, this paper proposes a V2I framework that utilizes monocular traffic cameras at road intersections to detect 3D objects. The results from the roadside unit (RSU) are then combined with the on-board system using an asynchronous late fusion method to enhance scene representation. Additionally, the proposed framework provides a time delay compensation module to compensate for the processing and transmission delay from the RSU. Lastly, the V2I framework is tested by simulating and validating a scenario similar to the one described in an industry report by Waymo. The results show that the proposed method improves the scene representation and the AV's perception range, giving enough time and space to react to adversary vehicles.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.3 -->
                
            <!-- Medicine: 5.0 -->
                
            <!-- Quantum Computing: 4.1 -->
                
            <!-- Networks: 3.7 -->
                
            <!-- Math: 2.2 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3364
            </span>
            <a href="https://arxiv.org/abs/2504.05118" target="_blank" rel="noopener noreferrer">VAPO: Efficient and Reliable Reinforcement Learning for Advanced Reasoning Tasks</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Yu Yue, Yufeng Yuan, Qiying Yu, Xiaochen Zuo, Ruofei Zhu, Wenyuan Xu, Jiaze Chen, Chengyi Wang, TianTian Fan, Zhengyin Du, Xiangpeng Wei, Xiangyu Yu, Gaohong Liu, Juncai Liu, Lingjun Liu, Haibin Lin, Zhiqi Lin, Bole Ma, Chi Zhang, Mofan Zhang, Wang Zhang, Hang Zhu, Ru Zhang, Xin Liu, Mingxuan Wang, Yonghui Wu, Lin Yan | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We present VAPO, Value-based Augmented Proximal Policy Optimization framework for reasoning models., a novel framework tailored for reasoning models within the value-based paradigm. Benchmarked the AIME 2024 dataset, VAPO, built on the Qwen 32B pre-trained model, attains a state-of-the-art score of </span>
            
            <span class="abstract-full" style="display: none;">We present VAPO, Value-based Augmented Proximal Policy Optimization framework for reasoning models., a novel framework tailored for reasoning models within the value-based paradigm. Benchmarked the AIME 2024 dataset, VAPO, built on the Qwen 32B pre-trained model, attains a state-of-the-art score of $\mathbf{60.4}$. In direct comparison under identical experimental settings, VAPO outperforms the previously reported results of DeepSeek-R1-Zero-Qwen-32B and DAPO by more than 10 points. The training process of VAPO stands out for its stability and efficiency. It reaches state-of-the-art performance within a mere 5,000 steps. Moreover, across multiple independent runs, no training crashes occur, underscoring its reliability. This research delves into long chain-of-thought (long-CoT) reasoning using a value-based reinforcement learning framework. We pinpoint three key challenges that plague value-based methods: value model bias, the presence of heterogeneous sequence lengths, and the sparsity of reward signals. Through systematic design, VAPO offers an integrated solution that effectively alleviates these challenges, enabling enhanced performance in long-CoT reasoning tasks.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.2 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3385
            </span>
            <a href="https://arxiv.org/abs/2410.24127" target="_blank" rel="noopener noreferrer">More global randomness from less random local gates</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Ryotaro Suzuki, Hosho Katsura, Yosuke Mitsuhashi, Tomohiro Soejima, Jens Eisert, Nobuyuki Yoshioka | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Random circuits giving rise to unitary designs are key tools in quantum information science and many-body physics. In this work, we investigate a class of random quantum circuits with a specific gate structure. Within this framework, we prove that one-dimensional structured random circuits with non-</span>
            
            <span class="abstract-full" style="display: none;">Random circuits giving rise to unitary designs are key tools in quantum information science and many-body physics. In this work, we investigate a class of random quantum circuits with a specific gate structure. Within this framework, we prove that one-dimensional structured random circuits with non-Haar random local gates can exhibit substantially more global randomness compared to Haar random circuits with the same underlying circuit architecture. In particular, we derive all the exact eigenvalues and eigenvectors of the second-moment operators for these structured random circuits under a solvable condition, by establishing a link to the Kitaev chain, and show that their spectral gaps can exceed those of Haar random circuits. Our findings have applications in improving circuit depth bounds for randomized benchmarking and the generation of approximate unitary 2-designs from shallow random circuits.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.9 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 4.3 -->
                
            <!-- Networks: 2.8 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 2.0 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3389
            </span>
            <a href="https://arxiv.org/abs/2504.08526" target="_blank" rel="noopener noreferrer">Hallucination, reliability, and the role of generative AI in science</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Charles Rathkopf | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Generative AI is increasingly used in scientific domains, from protein folding to climate modeling. But these models produce distinctive errors known as hallucinations - outputs that are incorrect yet superficially plausible. Worse, some arguments suggest that hallucinations are an inevitable conseq</span>
            
            <span class="abstract-full" style="display: none;">Generative AI is increasingly used in scientific domains, from protein folding to climate modeling. But these models produce distinctive errors known as hallucinations - outputs that are incorrect yet superficially plausible. Worse, some arguments suggest that hallucinations are an inevitable consequence of the mechanisms underlying generative inference. Fortunately, such arguments rely on a conception of hallucination defined solely with respect to internal properties of the model, rather than in reference to the empirical target system. This conception fails to distinguish epistemically benign errors from those that threaten scientific inference. I introduce the concept of corrosive hallucination to capture the epistemically troubling subclass: misrepresentations that are substantively misleading and resistant to systematic anticipation. I argue that although corrosive hallucinations do pose a threat to scientific reliability, they are not inevitable. Scientific workflows such as those surrounding AlphaFold and GenCast, both of which serve as case studies, can neutralize their effects by imposing theoretical constraints during training, and by strategically screening for errors at inference time. When embedded in such workflows, generative AI can reliably contribute to scientific knowledge.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.7 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- Math: 2.0 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.343
            </span>
            <a href="https://arxiv.org/abs/2504.08415" target="_blank" rel="noopener noreferrer">Constrained Machine Learning Through Hyperspherical Representation</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Gaetano Signorelli, Michele Lombardi | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">The problem of ensuring constraints satisfaction on the output of machine learning models is critical for many applications, especially in safety-critical domains. Modern approaches rely on penalty-based methods at training time, which do not guarantee to avoid constraints violations; or constraint-</span>
            
            <span class="abstract-full" style="display: none;">The problem of ensuring constraints satisfaction on the output of machine learning models is critical for many applications, especially in safety-critical domains. Modern approaches rely on penalty-based methods at training time, which do not guarantee to avoid constraints violations; or constraint-specific model architectures (e.g., for monotonocity); or on output projection, which requires to solve an optimization problem that might be computationally demanding. We present the Hypersherical Constrained Representation, a novel method to enforce constraints in the output space for convex and bounded feasibility regions (generalizable to star domains). Our method operates on a different representation system, where Euclidean coordinates are converted into hyperspherical coordinates relative to the constrained region, which can only inherently represent feasible points. Experiments on a synthetic and a real-world dataset show that our method has predictive performance comparable to the other approaches, can guarantee 100% constraint satisfaction, and has a minimal computational cost at inference time.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.9 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- GNN: 2.2 -->
                
            <!-- Math: 2.1 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3462
            </span>
            <a href="https://arxiv.org/abs/2504.08246" target="_blank" rel="noopener noreferrer">Spectral Normalization for Lipschitz-Constrained Policies on Learning Humanoid Locomotion</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Jaeyong Shin, Woohyun Cha, Donghyeon Kim, Junhyeok Cha, Jaeheung Park | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Reinforcement learning (RL) has shown great potential in training agile and adaptable controllers for legged robots, enabling them to learn complex locomotion behaviors directly from experience. However, policies trained in simulation often fail to transfer to real-world robots due to unrealistic as</span>
            
            <span class="abstract-full" style="display: none;">Reinforcement learning (RL) has shown great potential in training agile and adaptable controllers for legged robots, enabling them to learn complex locomotion behaviors directly from experience. However, policies trained in simulation often fail to transfer to real-world robots due to unrealistic assumptions such as infinite actuator bandwidth and the absence of torque limits. These conditions allow policies to rely on abrupt, high-frequency torque changes, which are infeasible for real actuators with finite bandwidth.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.0 -->
                
            <!-- Medicine: 4.8 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3501
            </span>
            <a href="https://arxiv.org/abs/2504.08624" target="_blank" rel="noopener noreferrer">TorchFX: A modern approach to Audio DSP with PyTorch and GPU acceleration</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Matteo Spanio, Antonio Rod\`a | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">The burgeoning complexity and real-time processing demands of audio signals necessitate optimized algorithms that harness the computational prowess of Graphics Processing Units (GPUs). Existing Digital Signal Processing (DSP) libraries often fall short in delivering the requisite efficiency and flex</span>
            
            <span class="abstract-full" style="display: none;">The burgeoning complexity and real-time processing demands of audio signals necessitate optimized algorithms that harness the computational prowess of Graphics Processing Units (GPUs). Existing Digital Signal Processing (DSP) libraries often fall short in delivering the requisite efficiency and flexibility, particularly in integrating Artificial Intelligence (AI) models. In response, we introduce TorchFX: a GPU-accelerated Python library for DSP, specifically engineered to facilitate sophisticated audio signal processing. Built atop the PyTorch framework, TorchFX offers an Object-Oriented interface that emulates the usability of torchaudio, enhancing functionality with a novel pipe operator for intuitive filter chaining. This library provides a comprehensive suite of Finite Impulse Response (FIR) and Infinite Impulse Response (IIR) filters, with a focus on multichannel audio files, thus facilitating the integration of DSP and AI-based approaches. Our benchmarking results demonstrate significant efficiency gains over traditional libraries like SciPy, particularly in multichannel contexts. Despite current limitations in GPU compatibility, ongoing developments promise broader support and real-time processing capabilities. TorchFX aims to become a useful tool for the community, contributing to innovation and progress in DSP with GPU acceleration. TorchFX is publicly available on GitHub at https://github.com/matteospanio/torchfx.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.6 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3542
            </span>
            <a href="https://arxiv.org/abs/2504.08480" target="_blank" rel="noopener noreferrer">Toward Realistic Adversarial Attacks in IDS: A Novel Feasibility Metric for Transferability</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Sabrine Ennaji, Elhadj Benkhelifa, Luigi Vincenzo Mancini | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Transferability-based adversarial attacks exploit the ability of adversarial examples, crafted to deceive a specific source Intrusion Detection System (IDS) model, to also mislead a target IDS model without requiring access to the training data or any internal model parameters. These attacks exploit</span>
            
            <span class="abstract-full" style="display: none;">Transferability-based adversarial attacks exploit the ability of adversarial examples, crafted to deceive a specific source Intrusion Detection System (IDS) model, to also mislead a target IDS model without requiring access to the training data or any internal model parameters. These attacks exploit common vulnerabilities in machine learning models to bypass security measures and compromise systems. Although the transferability concept has been widely studied, its practical feasibility remains limited due to assumptions of high similarity between source and target models. This paper analyzes the core factors that contribute to transferability, including feature alignment, model architectural similarity, and overlap in the data distributions that each IDS examines. We propose a novel metric, the Transferability Feasibility Score (TFS), to assess the feasibility and reliability of such attacks based on these factors. Through experimental evidence, we demonstrate that TFS and actual attack success rates are highly correlated, addressing the gap between theoretical understanding and real-world impact. Our findings provide needed guidance for designing more realistic transferable adversarial attacks, developing robust defenses, and ultimately improving the security of machine learning-based IDS in critical systems.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.8 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 4.3 -->
                
            <!-- Networks: 3.6 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3627
            </span>
            <a href="https://arxiv.org/abs/2504.08128" target="_blank" rel="noopener noreferrer">Certified to Drive: A Policy Proposal for Mandatory Training on Semi-Automated Vehicles</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Soumita Mukherjee (Pennsylvania State University), Varun Darshana Parekh (Pennsylvania State University), Nikhil Tayal (Tezmee Inc.) | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Although the Boeing 737 Max incidents resulted from a mix of design shortcomings, regulatory oversights, and systemic issues, they also highlight a critical gap in pilot training on managing automated systems during abnormal conditions. This example demonstrates the urgent need for focused, concise </span>
            
            <span class="abstract-full" style="display: none;">Although the Boeing 737 Max incidents resulted from a mix of design shortcomings, regulatory oversights, and systemic issues, they also highlight a critical gap in pilot training on managing automated systems during abnormal conditions. This example demonstrates the urgent need for focused, concise training on human-automation interaction - a need that is equally critical for operators of Level 2 ADAS-equipped vehicles, as discussed in detail later in this article. The lack of structured education for semi-automated vehicle operators mirrors similar risks in other industries, where formal training is critical for safe operation. Two policy recommendations are proposed. First, governments should create concise, official resources in accessible and official format to educate drivers on system capabilities and limitations. Second, mandatory training and certification programs should be introduced, combining theoretical and hands-on components to prepare drivers for real-world scenarios. These measures will improve driver understanding, reduce misuse, and foster public trust in semi-automated vehicle technologies. By addressing the knowledge gap, policymakers can ensure a safer, more responsible transition to automation, maximizing its benefits while minimizing risks to public safety.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.9 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.8 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Evolutionary Algorithms: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3629
            </span>
            <a href="https://arxiv.org/abs/2504.08049" target="_blank" rel="noopener noreferrer">Patch distribution modeling framework adaptive cosine estimator (PaDiM-ACE) for anomaly detection and localization in synthetic aperture radar imagery</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Angelina Ibarra, Joshua Peeples | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">This work presents a new approach to anomaly detection and localization in synthetic aperture radar imagery (SAR), expanding upon the existing patch distribution modeling framework (PaDiM). We introduce the adaptive cosine estimator (ACE) detection statistic. PaDiM uses the Mahalanobis distance at i</span>
            
            <span class="abstract-full" style="display: none;">This work presents a new approach to anomaly detection and localization in synthetic aperture radar imagery (SAR), expanding upon the existing patch distribution modeling framework (PaDiM). We introduce the adaptive cosine estimator (ACE) detection statistic. PaDiM uses the Mahalanobis distance at inference, an unbounded metric. ACE instead uses the cosine similarity metric, providing bounded anomaly detection scores. The proposed method is evaluated across multiple SAR datasets, with performance metrics including the area under the receiver operating curve (AUROC) at the image and pixel level, aiming for increased performance in anomaly detection and localization of SAR imagery. The code is publicly available: https://github.com/Advanced-Vision-and-Learning-Lab/PaDiM-LACE.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.7 -->
                
            <!-- Medicine: 5.0 -->
                
            <!-- Quantum Computing: 4.1 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- GNN: 2.2 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Robotics: 1.8 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Evolutionary Algorithms: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3653
            </span>
            <a href="https://arxiv.org/abs/2504.07099" target="_blank" rel="noopener noreferrer">Beyond the Time Domain: Recent Advances on Frequency Transforms in Time Series Analysis</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Qianru Zhang, Peng Yang, Honggang Wen, Xinzhu Li, Haixin Wang, Fang Sun, Zezheng Song, Zhichen Lai, Rui Ma, Ruihua Han, Tailin Wu, Siu-Ming Yiu, Yizhou Sun, Hongzhi Yin | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">The field of time series analysis has seen significant progress, yet traditional methods predominantly operate in temporal or spatial domains, overlooking the potential of frequency-based representations. This survey addresses this gap by providing the first comprehensive review of frequency transfo</span>
            
            <span class="abstract-full" style="display: none;">The field of time series analysis has seen significant progress, yet traditional methods predominantly operate in temporal or spatial domains, overlooking the potential of frequency-based representations. This survey addresses this gap by providing the first comprehensive review of frequency transform techniques-Fourier, Laplace, and Wavelet Transforms-in time series. We systematically explore their applications, strengths, and limitations, offering a comprehensive review and an up-to-date pipeline of recent advancements. By highlighting their transformative potential in time series applications including finance, molecular, weather, etc. This survey serves as a foundational resource for researchers, bridging theoretical insights with practical implementations. A curated GitHub repository further supports reproducibility and future research.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.3 -->
                
            <!-- Medicine: 5.0 -->
                
            <!-- Quantum Computing: 4.1 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3653
            </span>
            <a href="https://arxiv.org/abs/2504.04120" target="_blank" rel="noopener noreferrer">Transformer representation learning is necessary for dynamic multi-modal physiological data on small-cohort patients</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Bingxu Wang, Yapeng Wang, Kunzhi Cai, Yuqi Zhang, Zeyi Zhou, Yachong Guo, Wei Wang, Qing Zhou | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Postoperative delirium (POD), a severe neuropsychiatric complication affecting nearly 50% of high-risk surgical patients, is defined as an acute disorder of attention and cognition, It remains significantly underdiagnosed in the intensive care units (ICUs) due to subjective monitoring methods. Early</span>
            
            <span class="abstract-full" style="display: none;">Postoperative delirium (POD), a severe neuropsychiatric complication affecting nearly 50% of high-risk surgical patients, is defined as an acute disorder of attention and cognition, It remains significantly underdiagnosed in the intensive care units (ICUs) due to subjective monitoring methods. Early and accurate diagnosis of POD is critical and achievable. Here, we propose a POD prediction framework comprising a Transformer representation model followed by traditional machine learning algorithms. Our approaches utilizes multi-modal physiological data, including amplitude-integrated electroencephalography (aEEG), vital signs, electrocardiographic monitor data as well as hemodynamic parameters. We curated the first multi-modal POD dataset encompassing two patient types and evaluated the various Transformer architectures for representation learning. Empirical results indicate a consistent improvements of sensitivity and Youden index in patient TYPE I using Transformer representations, particularly our fusion adaptation of Pathformer. By enabling effective delirium diagnosis from postoperative day 1 to 3, our extensive experimental findings emphasize the potential of multi-modal physiological data and highlight the necessity of representation learning via multi-modal Transformer architecture in clinical diagnosis.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.4 -->
                
            <!-- Medicine: 5.1 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Robotics: 1.8 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3678
            </span>
            <a href="https://arxiv.org/abs/2504.08444" target="_blank" rel="noopener noreferrer">Collapsing Catalytic Classes</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Michal Kouck\'y, Ian Mertz, Edward Pyne, Sasha Sami | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">A catalytic machine is a space-bounded Turing machine with additional access to a second, much larger work tape, with the caveat that this tape is full, and its contents must be preserved by the computation. Catalytic machines were defined by Buhrman et al. (STOC 2014), who, alongside many follow-up</span>
            
            <span class="abstract-full" style="display: none;">A catalytic machine is a space-bounded Turing machine with additional access to a second, much larger work tape, with the caveat that this tape is full, and its contents must be preserved by the computation. Catalytic machines were defined by Buhrman et al. (STOC 2014), who, alongside many follow-up works, exhibited the power of catalytic space ($CSPACE$) and in particular catalytic logspace machines ($CL$) beyond that of traditional space-bounded machines.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.6 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Math: 2.0 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3681
            </span>
            <a href="https://arxiv.org/abs/2504.08410" target="_blank" rel="noopener noreferrer">PMNI: Pose-free Multi-view Normal Integration for Reflective and Textureless Surface Reconstruction</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Mingzhi Pei, Xu Cao, Xiangyi Wang, Heng Guo, Zhanyu Ma | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Reflective and textureless surfaces remain a challenge in multi-view 3D reconstruction.Both camera pose calibration and shape reconstruction often fail due to insufficient or unreliable cross-view visual features. To address these issues, we present PMNI (Pose-free Multi-view Normal Integration), a </span>
            
            <span class="abstract-full" style="display: none;">Reflective and textureless surfaces remain a challenge in multi-view 3D reconstruction.Both camera pose calibration and shape reconstruction often fail due to insufficient or unreliable cross-view visual features. To address these issues, we present PMNI (Pose-free Multi-view Normal Integration), a neural surface reconstruction method that incorporates rich geometric information by leveraging surface normal maps instead of RGB images. By enforcing geometric constraints from surface normals and multi-view shape consistency within a neural signed distance function (SDF) optimization framework, PMNI simultaneously recovers accurate camera poses and high-fidelity surface geometry. Experimental results on synthetic and real-world datasets show that our method achieves state-of-the-art performance in the reconstruction of reflective surfaces, even without reliable initial camera poses.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.7 -->
                
            <!-- Medicine: 5.1 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3728
            </span>
            <a href="https://arxiv.org/abs/2504.08234" target="_blank" rel="noopener noreferrer">Bringing Structure to Naturalness: On the Naturalness of ASTs</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Profir-Petru P\^ar\c{t}achi, Mahito Sugiyama | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Source code comes in different shapes and forms. Previous research has already shown code to be more predictable than natural language as well as highlighted its statistical predictability at the token level: source code can be natural. More recently, the structure of code -- control flow, syntax gr</span>
            
            <span class="abstract-full" style="display: none;">Source code comes in different shapes and forms. Previous research has already shown code to be more predictable than natural language as well as highlighted its statistical predictability at the token level: source code can be natural. More recently, the structure of code -- control flow, syntax graphs, abstract syntax trees etc. -- has been successfully used to improve the state-of-the-art on numerous tasks: code suggestion, code summarisation, method naming etc. This body of work implicitly assumes that structured representations of code are similarly statistically predictable, i.e. that a structured view of code is also natural. We consider that this view should be made explicit and propose directly studying the Structured Naturalness Hypothesis. Beyond just naming existing research that assumes this hypothesis and formulating it, we also provide evidence in the case of trees: TreeLSTM models over ASTs for some languages, such as Ruby, are competitive with $n$-gram models while handling the syntax token issue highlighted by previous research 'for free'. For other languages, such as Java or Python, we find tree models to perform worse, suggesting that downstream task improvement is uncorrelated to the language modelling task. Further, we show how such naturalness signals can be employed for near state-of-the-art results on just-in-time defect prediction while forgoing manual feature engineering work.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.9 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 4.3 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- Math: 2.1 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Reinforcement Learning: 1.7 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3781
            </span>
            <a href="https://arxiv.org/abs/2504.08154" target="_blank" rel="noopener noreferrer">Investigating Vision-Language Model for Point Cloud-based Vehicle Classification</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Yiqiao Li, Jie Wei, Camille Kamga | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Heavy-duty trucks pose significant safety challenges due to their large size and limited maneuverability compared to passenger vehicles. A deeper understanding of truck characteristics is essential for enhancing the safety perspective of cooperative autonomous driving. Traditional LiDAR-based truck </span>
            
            <span class="abstract-full" style="display: none;">Heavy-duty trucks pose significant safety challenges due to their large size and limited maneuverability compared to passenger vehicles. A deeper understanding of truck characteristics is essential for enhancing the safety perspective of cooperative autonomous driving. Traditional LiDAR-based truck classification methods rely on extensive manual annotations, which makes them labor-intensive and costly. The rapid advancement of large language models (LLMs) trained on massive datasets presents an opportunity to leverage their few-shot learning capabilities for truck classification. However, existing vision-language models (VLMs) are primarily trained on image datasets, which makes it challenging to directly process point cloud data. This study introduces a novel framework that integrates roadside LiDAR point cloud data with VLMs to facilitate efficient and accurate truck classification, which supports cooperative and safe driving environments. This study introduces three key innovations: (1) leveraging real-world LiDAR datasets for model development, (2) designing a preprocessing pipeline to adapt point cloud data for VLM input, including point cloud registration for dense 3D rendering and mathematical morphological techniques to enhance feature representation, and (3) utilizing in-context learning with few-shot prompting to enable vehicle classification with minimally labeled training data. Experimental results demonstrate encouraging performance of this method and present its potential to reduce annotation efforts while improving classification accuracy.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 9.1 -->
                
            <!-- Medicine: 5.3 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 3.7 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.3 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.381
            </span>
            <a href="https://arxiv.org/abs/2503.15711" target="_blank" rel="noopener noreferrer">VPAL: A novel method to reduce reconstruction time for 5D free-running imaging</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Yitong Yang, Muhammad Naeem, Marly Van Assen, Jerome Yerly, Davide Piccini, Matthias Stuber, John Oshinski, Matthias Chung | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Purpose: Ferumoxytal-enhanced 5D free-running whole heart CMR provides image quality comparable to CTA, but requires hours-long reconstruction time, preventing clinical usage. This study developed a variable projection augmented Lagrangian (VPAL) method for 5D motion-resolved image reconstruction an</span>
            
            <span class="abstract-full" style="display: none;">Purpose: Ferumoxytal-enhanced 5D free-running whole heart CMR provides image quality comparable to CTA, but requires hours-long reconstruction time, preventing clinical usage. This study developed a variable projection augmented Lagrangian (VPAL) method for 5D motion-resolved image reconstruction and compared it with alternating direction method of multipliers (ADMM) in five numerical simulations and 15 in-vivo pediatric data set.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.6 -->
                
            <!-- Medicine: 4.8 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3833
            </span>
            <a href="https://arxiv.org/abs/2504.08578" target="_blank" rel="noopener noreferrer">Knowledge Distillation for Multimodal Egocentric Action Recognition Robust to Missing Modalities</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Maria Santos-Villafranca, Dustin Carri\'on-Ojeda, Alejandro Perez-Yus, Jesus Bermudez-Cameo, Jose J. Guerrero, Simone Schaub-Meyer | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Action recognition is an essential task in egocentric vision due to its wide range of applications across many fields. While deep learning methods have been proposed to address this task, most rely on a single modality, typically video. However, including additional modalities may improve the robust</span>
            
            <span class="abstract-full" style="display: none;">Action recognition is an essential task in egocentric vision due to its wide range of applications across many fields. While deep learning methods have been proposed to address this task, most rely on a single modality, typically video. However, including additional modalities may improve the robustness of the approaches to common issues in egocentric videos, such as blurriness and occlusions. Recent efforts in multimodal egocentric action recognition often assume the availability of all modalities, leading to failures or performance drops when any modality is missing. To address this, we introduce an efficient multimodal knowledge distillation approach for egocentric action recognition that is robust to missing modalities (KARMMA) while still benefiting when multiple modalities are available. Our method focuses on resource-efficient development by leveraging pre-trained models as unimodal feature extractors in our teacher model, which distills knowledge into a much smaller and faster student model. Experiments on the Epic-Kitchens and Something-Something datasets demonstrate that our student model effectively handles missing modalities while reducing its accuracy drop in this scenario.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.9 -->
                
            <!-- Medicine: 4.8 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 2.0 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Evolutionary Algorithms: 1.3 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3837
            </span>
            <a href="https://arxiv.org/abs/2504.07414" target="_blank" rel="noopener noreferrer">Decomposition-Based Optimal Bounds for Privacy Amplification via Shuffling</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Pengcheng Su, Haibo Cheng, Ping Wang | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Shuffling has been shown to amplify differential privacy guarantees, offering a stronger privacy-utility trade-off. To characterize and compute this amplification, two fundamental analytical frameworks have been proposed: the privacy blanket by Balle et al. (CRYPTO 2019) and the clone paradigm (incl</span>
            
            <span class="abstract-full" style="display: none;">Shuffling has been shown to amplify differential privacy guarantees, offering a stronger privacy-utility trade-off. To characterize and compute this amplification, two fundamental analytical frameworks have been proposed: the privacy blanket by Balle et al. (CRYPTO 2019) and the clone paradigm (including both the standard clone and stronger clone) by Feldman et al. (FOCS 2021, SODA 2023). All these methods rely on decomposing local randomizers.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.9 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.3958
            </span>
            <a href="https://arxiv.org/abs/2504.08233" target="_blank" rel="noopener noreferrer">A 120 lines code for isogeometric topology optimization and its extension to 3D in MATLAB</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Xianda Xie, Zhihui Ou, Aodi Yang, Xiaobing Li, Shuting Wang | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">In this paper, a compact and efficient code implementation is presented for isogeometric topology optimization (ITO) approach. With the aid of B\.ezier extraction technique, a derived explicit stiffness matrix computation formula is applied to all B-spline IGA elements with rectangular shape under l</span>
            
            <span class="abstract-full" style="display: none;">In this paper, a compact and efficient code implementation is presented for isogeometric topology optimization (ITO) approach. With the aid of B\.ezier extraction technique, a derived explicit stiffness matrix computation formula is applied to all B-spline IGA elements with rectangular shape under linear elasticity assumption. Using the aforementioned explicit formula, the stiffness matrix calculation and updating of IGA are significantly simplified, which leads to the current ITO code implemented only in one main function without calling subroutines, such as IGA mesh generation and Gaussian quadrature. Both two-dimensional (2D) and three-dimensional (3D) cases are taken into consideration, which result into iga_top120 and iga_top3D257 MATLAB codes for 2D and 3D design problems. Numerical examples validate the effectiveness of our open-source codes, with several user-defined input parameters basically identical to those used in top88 and top3D. Therefore, iga_top120 and iga_top3D257 provide an effective entry for the code transforming from FEM-based TO into ITO.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.4 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 4.3 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.4024
            </span>
            <a href="https://arxiv.org/abs/2504.08102" target="_blank" rel="noopener noreferrer">Multi-view autoencoders for Fake News Detection</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Ingryd V. S. T. Pereira, George D. C. Cavalcanti, Rafael M. O. Cruz | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Given the volume and speed at which fake news spreads across social media, automatic fake news detection has become a highly important task. However, this task presents several challenges, including extracting textual features that contain relevant information about fake news. Research about fake ne</span>
            
            <span class="abstract-full" style="display: none;">Given the volume and speed at which fake news spreads across social media, automatic fake news detection has become a highly important task. However, this task presents several challenges, including extracting textual features that contain relevant information about fake news. Research about fake news detection shows that no single feature extraction technique consistently outperforms the others across all scenarios. Nevertheless, different feature extraction techniques can provide complementary information about the textual data and enable a more comprehensive representation of the content. This paper proposes using multi-view autoencoders to generate a joint feature representation for fake news detection by integrating several feature extraction techniques commonly used in the literature. Experiments on fake news datasets show a significant improvement in classification performance compared to individual views (feature representations). We also observed that selecting a subset of the views instead of composing a latent space with all the views can be advantageous in terms of accuracy and computational effort. For further details, including source codes, figures, and datasets, please refer to the project's repository: https://github.com/ingrydpereira/multiview-fake-news.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.5 -->
                
            <!-- Medicine: 4.8 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- Math: 2.1 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.404
            </span>
            <a href="https://arxiv.org/abs/2501.01421" target="_blank" rel="noopener noreferrer">R-SCoRe: Revisiting Scene Coordinate Regression for Robust Large-Scale Visual Localization</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Xudong Jiang, Fangjinhua Wang, Silvano Galliani, Christoph Vogel, Marc Pollefeys | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Learning-based visual localization methods that use scene coordinate regression (SCR) offer the advantage of smaller map sizes. However, on datasets with complex illumination changes or image-level ambiguities, it remains a less robust alternative to feature matching methods. This work aims to close</span>
            
            <span class="abstract-full" style="display: none;">Learning-based visual localization methods that use scene coordinate regression (SCR) offer the advantage of smaller map sizes. However, on datasets with complex illumination changes or image-level ambiguities, it remains a less robust alternative to feature matching methods. This work aims to close the gap. We introduce a covisibility graph-based global encoding learning and data augmentation strategy, along with a depth-adjusted reprojection loss to facilitate implicit triangulation. Additionally, we revisit the network architecture and local feature extraction module. Our method achieves state-of-the-art on challenging large-scale datasets without relying on network ensembles or 3D supervision. On Aachen Day-Night, we are 10$\times$ more accurate than previous SCR methods with similar map sizes and require at least 5$\times$ smaller map sizes than any other SCR method while still delivering superior accuracy. Code is available at: https://github.com/cvg/scrstudio .</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.2 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.4146
            </span>
            <a href="https://arxiv.org/abs/2504.08722" target="_blank" rel="noopener noreferrer">Deriving the Gradients of Some Popular Optimal Transport Algorithms</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Fangzhou Xie | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">In this note, I review entropy-regularized Monge-Kantorovich problem in Optimal Transport, and derive the gradients of several popular algorithms popular in Computational Optimal Transport, including the Sinkhorn algorithms, Wasserstein Barycenter algorithms, and the Wasserstein Dictionary Learning </span>
            
            <span class="abstract-full" style="display: none;">In this note, I review entropy-regularized Monge-Kantorovich problem in Optimal Transport, and derive the gradients of several popular algorithms popular in Computational Optimal Transport, including the Sinkhorn algorithms, Wasserstein Barycenter algorithms, and the Wasserstein Dictionary Learning algorithms.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.8 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 4.4 -->
                
            <!-- Networks: 2.8 -->
                
            <!-- Math: 1.7 -->
                
            <!-- GNN: 1.7 -->
                
            <!-- Reinforcement Learning: 1.7 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- Federated Learning: 1.3 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Hardware: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.4164
            </span>
            <a href="https://arxiv.org/abs/2504.08359" target="_blank" rel="noopener noreferrer">Kernel-Level Energy-Efficient Neural Architecture Search for Tabular Dataset</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Hoang-Loc La, Phuong Hoai Ha | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Many studies estimate energy consumption using proxy metrics like memory usage, FLOPs, and inference latency, with the assumption that reducing these metrics will also lower energy consumption in neural networks. This paper, however, takes a different approach by introducing an energy-efficient Neur</span>
            
            <span class="abstract-full" style="display: none;">Many studies estimate energy consumption using proxy metrics like memory usage, FLOPs, and inference latency, with the assumption that reducing these metrics will also lower energy consumption in neural networks. This paper, however, takes a different approach by introducing an energy-efficient Neural Architecture Search (NAS) method that directly focuses on identifying architectures that minimize energy consumption while maintaining acceptable accuracy. Unlike previous methods that primarily target vision and language tasks, the approach proposed here specifically addresses tabular datasets. Remarkably, the optimal architecture suggested by this method can reduce energy consumption by up to 92% compared to architectures recommended by conventional NAS.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.7 -->
                
            <!-- Medicine: 4.5 -->
                
            <!-- Quantum Computing: 4.3 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- GNN: 2.2 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Federated Learning: 1.8 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.4173
            </span>
            <a href="https://arxiv.org/abs/2504.08340" target="_blank" rel="noopener noreferrer">All-in-Memory Stochastic Computing using ReRAM</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Jo\~ao Paulo C. de Lima, Mehran Shoushtari Moghadam, Sercan Aygun, Jeronimo Castrillon, M. Hassan Najafi, Asif Ali Khan | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">As the demand for efficient, low-power computing in embedded and edge devices grows, traditional computing methods are becoming less effective for handling complex tasks. Stochastic computing (SC) offers a promising alternative by approximating complex arithmetic operations, such as addition and mul</span>
            
            <span class="abstract-full" style="display: none;">As the demand for efficient, low-power computing in embedded and edge devices grows, traditional computing methods are becoming less effective for handling complex tasks. Stochastic computing (SC) offers a promising alternative by approximating complex arithmetic operations, such as addition and multiplication, using simple bitwise operations, like majority or AND, on random bit-streams. While SC operations are inherently fault-tolerant, their accuracy largely depends on the length and quality of the stochastic bit-streams (SBS). These bit-streams are typically generated by CMOS-based stochastic bit-stream generators that consume over 80% of the SC system's power and area. Current SC solutions focus on optimizing the logic gates but often neglect the high cost of moving the bit-streams between memory and processor. This work leverages the physics of emerging ReRAM devices to implement the entire SC flow in place: (1) generating low-cost true random numbers and SBSs, (2) conducting SC operations, and (3) converting SBSs back to binary. Considering the low reliability of ReRAM cells, we demonstrate how SC's robustness to errors copes with ReRAM's variability. Our evaluation shows significant improvements in throughput (1.39x, 2.16x) and energy consumption (1.15x, 2.8x) over state-of-the-art (CMOS- and ReRAM-based) solutions, respectively, with an average image quality drop of 5% across multiple SBS lengths and image processing tasks.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.6 -->
                
            <!-- Medicine: 4.5 -->
                
            <!-- Quantum Computing: 4.4 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.4189
            </span>
            <a href="https://arxiv.org/abs/2504.08684" target="_blank" rel="noopener noreferrer">A Dataset For Computational Reproducibility</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: L\'azaro Costa, Susana Barbosa, J\'acome Cunha | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Ensuring the reproducibility of scientific work is crucial as it allows the consistent verification of scientific claims and facilitates the advancement of knowledge by providing a reliable foundation for future research. However, scientific work based on computational artifacts, such as scripts for</span>
            
            <span class="abstract-full" style="display: none;">Ensuring the reproducibility of scientific work is crucial as it allows the consistent verification of scientific claims and facilitates the advancement of knowledge by providing a reliable foundation for future research. However, scientific work based on computational artifacts, such as scripts for statistical analysis or software prototypes, faces significant challenges in achieving reproducibility. These challenges are based on the variability of computational environments, rapid software evolution, and inadequate documentation of procedures. As a consequence, such artifacts often are not (easily) reproducible, undermining the credibility of scientific findings.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.6 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 4.6 -->
                
            <!-- Networks: 2.9 -->
                
            <!-- Math: 2.0 -->
                
            <!-- Reinforcement Learning: 1.7 -->
                
            <!-- GNN: 1.6 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.4254
            </span>
            <a href="https://arxiv.org/abs/2504.08430" target="_blank" rel="noopener noreferrer">A Hybrid ABM-PDE Framework for Real-World Infectious Disease Simulations</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Kristina Maier, Tim O. F. Conrad | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">This paper presents a hybrid modeling approach that couples an Agent-Based Model (ABM) with a partial differential equation (PDE) model in an epidemic setting to simulate the spatial spread of infectious diseases using a compartmental structure with seven health states. The goal is to reduce the com</span>
            
            <span class="abstract-full" style="display: none;">This paper presents a hybrid modeling approach that couples an Agent-Based Model (ABM) with a partial differential equation (PDE) model in an epidemic setting to simulate the spatial spread of infectious diseases using a compartmental structure with seven health states. The goal is to reduce the computational complexity of a full-ABM by introducing a coupled ABM-PDE model that offers significantly faster simulations while maintaining comparable accuracy. Our results demonstrate that the hybrid model not only reduces the overall simulation runtime (defined as the number of runs required for stable results multiplied by the duration of a single run) but also achieves smaller errors across both 25% and 100% population samples. The coupling mechanism ensures consistency at the model interface: agents crossing from the ABM into the PDE domain are removed and represented as density contributions at the corresponding grid node, while surplus density in the PDE domain is used to generate agents with plausible trajectories derived from mobile phone data. We evaluate the hybrid model using real-world mobility and infection data for the Berlin-Brandenburg region in Germany, showing that it captures the core epidemiological dynamics while enabling efficient large-scale simulations.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.7 -->
                
            <!-- Medicine: 4.8 -->
                
            <!-- Quantum Computing: 4.3 -->
                
            <!-- Networks: 3.9 -->
                
            <!-- Math: 2.1 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.3 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.4291
            </span>
            <a href="https://arxiv.org/abs/2504.08713" target="_blank" rel="noopener noreferrer">ProtoECGNet: Case-Based Interpretable Deep Learning for Multi-Label ECG Classification with Contrastive Learning</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Sahil Sethi, David Chen, Thomas Statchen, Michael C. Burkhart, Nipun Bhandari, Bashar Ramadan, Brett Beaulieu-Jones | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Deep learning-based electrocardiogram (ECG) classification has shown impressive performance but clinical adoption has been slowed by the lack of transparent and faithful explanations. Post hoc methods such as saliency maps may fail to reflect a model's true decision process. Prototype-based reasonin</span>
            
            <span class="abstract-full" style="display: none;">Deep learning-based electrocardiogram (ECG) classification has shown impressive performance but clinical adoption has been slowed by the lack of transparent and faithful explanations. Post hoc methods such as saliency maps may fail to reflect a model's true decision process. Prototype-based reasoning offers a more transparent alternative by grounding decisions in similarity to learned representations of real ECG segments, enabling faithful, case-based explanations. We introduce ProtoECGNet, a prototype-based deep learning model for interpretable, multi-label ECG classification. ProtoECGNet employs a structured, multi-branch architecture that reflects clinical interpretation workflows: it integrates a 1D CNN with global prototypes for rhythm classification, a 2D CNN with time-localized prototypes for morphology-based reasoning, and a 2D CNN with global prototypes for diffuse abnormalities. Each branch is trained with a prototype loss designed for multi-label learning, combining clustering, separation, diversity, and a novel contrastive loss that encourages appropriate separation between prototypes of unrelated classes while allowing clustering for frequently co-occurring diagnoses. We evaluate ProtoECGNet on all 71 diagnostic labels from the PTB-XL dataset, demonstrating competitive performance relative to state-of-the-art black-box models while providing structured, case-based explanations. To assess prototype quality, we conduct a structured clinician review of the final model's projected prototypes, finding that they are rated as representative and clear. ProtoECGNet shows that prototype learning can be effectively scaled to complex, multi-label time-series classification, offering a practical path toward transparent and trustworthy deep learning models for clinical decision support.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.0 -->
                
            <!-- Medicine: 5.7 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.4305
            </span>
            <a href="https://arxiv.org/abs/2211.10882" target="_blank" rel="noopener noreferrer">Multi-head Ensemble of Smoothed Classifiers for Certified Robustness</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Kun Fang, Qinghua Tao, Yingwen Wu, Tao Li, Xiaolin Huang, Jie Yang | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Randomized Smoothing (RS) is a promising technique for certified robustness, and recently in RS the ensemble of multiple Deep Neural Networks (DNNs) has shown state-of-the-art performances due to its variance reduction effect over Gaussian noises. However, such an ensemble brings heavy computation b</span>
            
            <span class="abstract-full" style="display: none;">Randomized Smoothing (RS) is a promising technique for certified robustness, and recently in RS the ensemble of multiple Deep Neural Networks (DNNs) has shown state-of-the-art performances due to its variance reduction effect over Gaussian noises. However, such an ensemble brings heavy computation burdens in both training and certification, and yet under-exploits individual DNNs and their mutual effects, as the communication between these classifiers is commonly ignored in optimization. In this work, we consider a novel ensemble-based training way for a single DNN with multiple augmented heads, named as SmOothed Multi-head Ensemble (SOME). In SOME, similar to the pursuit of variance reduction via ensemble, an ensemble of multiple heads imposed with a cosine constraint inside a single DNN is employed with much cheaper training and certification computation overloads in RS. In such network structure, an associated training strategy is designed by introducing a circular communication flow among those augmented heads. That is, each head teaches its neighbor with the self-paced learning strategy using smoothed losses, which are specifically designed in relation to certified robustness. The deployed multi-head structure and the circular-teaching scheme in SOME jointly contribute to the diversities among multiple heads and benefit their ensemble, leading to a competitively stronger certifiably-robust RS-based defense than ensembling multiple DNNs (effectiveness) at the cost of much less computational expenses (efficiency), verified by extensive experiments and discussions.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.1 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 4.4 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- Hardware: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.4335
            </span>
            <a href="https://arxiv.org/abs/2504.08219" target="_blank" rel="noopener noreferrer">VL-UR: Vision-Language-guided Universal Restoration of Images Degraded by Adverse Weather Conditions</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Ziyan Liu, Yuxu Lu, Huashan Yu, Dong yang | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Image restoration is critical for improving the quality of degraded images, which is vital for applications like autonomous driving, security surveillance, and digital content enhancement. However, existing methods are often tailored to specific degradation scenarios, limiting their adaptability to </span>
            
            <span class="abstract-full" style="display: none;">Image restoration is critical for improving the quality of degraded images, which is vital for applications like autonomous driving, security surveillance, and digital content enhancement. However, existing methods are often tailored to specific degradation scenarios, limiting their adaptability to the diverse and complex challenges in real-world environments. Moreover, real-world degradations are typically non-uniform, highlighting the need for adaptive and intelligent solutions. To address these issues, we propose a novel vision-language-guided universal restoration (VL-UR) framework. VL-UR leverages a zero-shot contrastive language-image pre-training (CLIP) model to enhance image restoration by integrating visual and semantic information. A scene classifier is introduced to adapt CLIP, generating high-quality language embeddings aligned with degraded images while predicting degraded types for complex scenarios. Extensive experiments across eleven diverse degradation settings demonstrate VL-UR's state-of-the-art performance, robustness, and adaptability. This positions VL-UR as a transformative solution for modern image restoration challenges in dynamic, real-world environments.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.0 -->
                
            <!-- Medicine: 5.1 -->
                
            <!-- Quantum Computing: 4.1 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- GNN: 2.2 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.435
            </span>
            <a href="https://arxiv.org/abs/2404.09247" target="_blank" rel="noopener noreferrer">Generalization Error Bounds for Learning under Censored Feedback</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Yifan Yang, Ali Payani, Parinaz Naghizadeh | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Generalization error bounds from learning theory provide statistical guarantees on how well an algorithm will perform on previously unseen data. In this paper, we characterize the impacts of data non-IIDness due to censored feedback (a.k.a. selective labeling bias) on such bounds. Censored feedback </span>
            
            <span class="abstract-full" style="display: none;">Generalization error bounds from learning theory provide statistical guarantees on how well an algorithm will perform on previously unseen data. In this paper, we characterize the impacts of data non-IIDness due to censored feedback (a.k.a. selective labeling bias) on such bounds. Censored feedback is ubiquitous in many real-world online selection and classification tasks (e.g., hiring, lending, recommendation systems) where the true label of a data point is only revealed if a favorable decision is made (e.g., accepting a candidate, approving a loan, displaying an ad), and remains unknown otherwise. We first derive an extension of the well-known Dvoretzky-Kiefer-Wolfowitz (DKW) inequality, which characterizes the gap between empirical and theoretical data distribution CDFs learned from IID data, to problems with non-IID data due to censored feedback. We then use this CDF error bound to provide a bound on the generalization error guarantees of a classifier trained on such non-IID data. We show that existing generalization error bounds (which do not account for censored feedback) fail to correctly capture the model's generalization guarantees, verifying the need for our bounds. We further analyze the effectiveness of (pure and bounded) exploration techniques, proposed by recent literature as a way to alleviate censored feedback, on improving our error bounds. Together, our findings illustrate how a decision maker should account for the trade-off between strengthening the generalization guarantees of an algorithm and the costs incurred in data collection when future data availability is limited by censored feedback.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.3 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 4.3 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- Math: 2.2 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Federated Learning: 1.7 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- SpikingNN: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.443
            </span>
            <a href="https://arxiv.org/abs/2409.00536" target="_blank" rel="noopener noreferrer">Formal Verification and Control with Conformal Prediction</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Lars Lindemann, Yiqi Zhao, Xinyi Yu, George J. Pappas, Jyotirmoy V. Deshmukh | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">In this survey, we design formal verification and control algorithms for autonomous systems with practical safety guarantees using conformal prediction (CP), a statistical tool for uncertainty quantification. We focus on learning-enabled autonomous systems (LEASs) in which the complexity of learning</span>
            
            <span class="abstract-full" style="display: none;">In this survey, we design formal verification and control algorithms for autonomous systems with practical safety guarantees using conformal prediction (CP), a statistical tool for uncertainty quantification. We focus on learning-enabled autonomous systems (LEASs) in which the complexity of learning-enabled components (LECs) is a major bottleneck that hampers the use of existing model-based verification and design techniques. Instead, we advocate for the use of CP, and we will demonstrate its use in formal verification, systems and control theory, and robotics. We argue that CP is specifically useful due to its simplicity (easy to understand, use, and modify), generality (requires no assumptions on learned models and data distributions, i.e., is distribution-free), and efficiency (real-time capable and accurate).</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.8 -->
                
            <!-- Medicine: 4.8 -->
                
            <!-- Quantum Computing: 4.4 -->
                
            <!-- Networks: 2.9 -->
                
            <!-- Math: 2.1 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.3 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.4435
            </span>
            <a href="https://arxiv.org/abs/2504.08274" target="_blank" rel="noopener noreferrer">Generalized Multilingual Text-to-Speech Generation with Language-Aware Style Adaptation</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Haowei Lou, Hye-young Paik, Sheng Li, Wen Hu, Lina Yao | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Text-to-Speech (TTS) models can generate natural, human-like speech across multiple languages by transforming phonemes into waveforms. However, multilingual TTS remains challenging due to discrepancies in phoneme vocabularies and variations in prosody and speaking style across languages. Existing ap</span>
            
            <span class="abstract-full" style="display: none;">Text-to-Speech (TTS) models can generate natural, human-like speech across multiple languages by transforming phonemes into waveforms. However, multilingual TTS remains challenging due to discrepancies in phoneme vocabularies and variations in prosody and speaking style across languages. Existing approaches either train separate models for each language, which achieve high performance at the cost of increased computational resources, or use a unified model for multiple languages that struggles to capture fine-grained, language-specific style variations. In this work, we propose LanStyleTTS, a non-autoregressive, language-aware style adaptive TTS framework that standardizes phoneme representations and enables fine-grained, phoneme-level style control across languages. This design supports a unified multilingual TTS model capable of producing accurate and high-quality speech without the need to train language-specific models. We evaluate LanStyleTTS by integrating it with several state-of-the-art non-autoregressive TTS architectures. Results show consistent performance improvements across different model backbones. Furthermore, we investigate a range of acoustic feature representations, including mel-spectrograms and autoencoder-derived latent features. Our experiments demonstrate that latent encodings can significantly reduce model size and computational cost while preserving high-quality speech generation.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.4 -->
                
            <!-- Medicine: 5.0 -->
                
            <!-- Quantum Computing: 4.3 -->
                
            <!-- Networks: 3.0 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Math: 1.6 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.4474
            </span>
            <a href="https://arxiv.org/abs/2412.03332" target="_blank" rel="noopener noreferrer">On Approximability of $\ell_2^2$ Min-Sum Clustering</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Karthik C. S., Euiwoong Lee, Yuval Rabani, Chris Schwiegelshohn, Samson Zhou | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">The $\ell_2^2$ min-sum $k$-clustering problem is to partition an input set into clusters $C_1,\ldots,C_k$ to minimize $\sum_{i=1}^k\sum_{p,q\in C_i}\|p-q\|_2^2$. Although $\ell_2^2$ min-sum $k$-clustering is NP-hard, it is not known whether it is NP-hard to approximate $\ell_2^2$ min-sum $k$-cluster</span>
            
            <span class="abstract-full" style="display: none;">The $\ell_2^2$ min-sum $k$-clustering problem is to partition an input set into clusters $C_1,\ldots,C_k$ to minimize $\sum_{i=1}^k\sum_{p,q\in C_i}\|p-q\|_2^2$. Although $\ell_2^2$ min-sum $k$-clustering is NP-hard, it is not known whether it is NP-hard to approximate $\ell_2^2$ min-sum $k$-clustering beyond a certain factor.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.4 -->
                
            <!-- Medicine: 4.8 -->
                
            <!-- Quantum Computing: 4.3 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.4505
            </span>
            <a href="https://arxiv.org/abs/2504.08315" target="_blank" rel="noopener noreferrer">Annealed Mean Field Descent Is Highly Effective for Quadratic Unconstrained Binary Optimization</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Kyo Kuroki, Thiem Van Chu, Masato Motomura, Kazushi Kawamura | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">In recent years, formulating various combinatorial optimization problems as Quadratic Unconstrained Binary Optimization (QUBO) has gained significant attention as a promising approach for efficiently obtaining optimal or near-optimal solutions. While QUBO offers a general-purpose framework, existing</span>
            
            <span class="abstract-full" style="display: none;">In recent years, formulating various combinatorial optimization problems as Quadratic Unconstrained Binary Optimization (QUBO) has gained significant attention as a promising approach for efficiently obtaining optimal or near-optimal solutions. While QUBO offers a general-purpose framework, existing solvers often struggle with performance variability across different problems.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.6 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 4.5 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Evolutionary Algorithms: 1.4 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.4552
            </span>
            <a href="https://arxiv.org/abs/2402.04613" target="_blank" rel="noopener noreferrer">Wasserstein Gradient Flows for Moreau Envelopes of f-Divergences in Reproducing Kernel Hilbert Spaces</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Viktor Stein, Sebastian Neumayer, Nicolaj Rux, Gabriele Steidl | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Commonly used $f$-divergences of measures, e.g., the Kullback-Leibler divergence, are subject to limitations regarding the support of the involved measures. A remedy is regularizing the $f$-divergence by a squared maximum mean discrepancy (MMD) associated with a characteristic kernel $K$. We use the</span>
            
            <span class="abstract-full" style="display: none;">Commonly used $f$-divergences of measures, e.g., the Kullback-Leibler divergence, are subject to limitations regarding the support of the involved measures. A remedy is regularizing the $f$-divergence by a squared maximum mean discrepancy (MMD) associated with a characteristic kernel $K$. We use the kernel mean embedding to show that this regularization can be rewritten as the Moreau envelope of some function on the associated reproducing kernel Hilbert space. Then, we exploit well-known results on Moreau envelopes in Hilbert spaces to analyze the MMD-regularized $f$-divergences, particularly their gradients. Subsequently, we use our findings to analyze Wasserstein gradient flows of MMD-regularized $f$-divergences. We provide proof-of-the-concept numerical examples for flows starting from empirical measures. Here, we cover $f$-divergences with infinite and finite recession constants. Lastly, we extend our results to the tight variational formulation of $f$-divergences and numerically compare the resulting flows.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.6 -->
                
            <!-- Quantum Computing: 4.5 -->
                
            <!-- Medicine: 4.4 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- Math: 2.3 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.464
            </span>
            <a href="https://arxiv.org/abs/2504.08481" target="_blank" rel="noopener noreferrer">A Hybrid Fully Convolutional CNN-Transformer Model for Inherently Interpretable Medical Image Classification</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Kerol Djoumessi, Samuel Ofosu Mensah, Philipp Berens | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">In many medical imaging tasks, convolutional neural networks (CNNs) efficiently extract local features hierarchically. More recently, vision transformers (ViTs) have gained popularity, using self-attention mechanisms to capture global dependencies, but lacking the inherent spatial localization of co</span>
            
            <span class="abstract-full" style="display: none;">In many medical imaging tasks, convolutional neural networks (CNNs) efficiently extract local features hierarchically. More recently, vision transformers (ViTs) have gained popularity, using self-attention mechanisms to capture global dependencies, but lacking the inherent spatial localization of convolutions. Therefore, hybrid models combining CNNs and ViTs have been developed to combine the strengths of both architectures. However, such hybrid CNN-ViT models are difficult to interpret, which hinders their application in medical imaging. In this work, we introduce an interpretable-by-design hybrid fully convolutional CNN-Transformer architecture for medical image classification. Unlike widely used post-hoc saliency methods for ViTs, our approach generates faithful and localized evidence maps that directly reflect the model's decision process. We evaluated our method on two medical image classification tasks using color fundus images. Our model not only achieves state-of-the-art predictive performance compared to both black-box and interpretable models but also provides class-specific sparse evidence maps in a single forward pass. The code is available at: https://anonymous.4open.science/r/Expl-CNN-Transformer/.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.5 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 4.3 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.4646
            </span>
            <a href="https://arxiv.org/abs/2503.16681" target="_blank" rel="noopener noreferrer">GauRast: Enhancing GPU Triangle Rasterizers to Accelerate 3D Gaussian Splatting</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Sixu Li, Ben Keller, Yingyan Celine Lin, Brucek Khailany | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">3D intelligence leverages rich 3D features and stands as a promising frontier in AI, with 3D rendering fundamental to many downstream applications. 3D Gaussian Splatting (3DGS), an emerging high-quality 3D rendering method, requires significant computation, making real-time execution on existing GPU</span>
            
            <span class="abstract-full" style="display: none;">3D intelligence leverages rich 3D features and stands as a promising frontier in AI, with 3D rendering fundamental to many downstream applications. 3D Gaussian Splatting (3DGS), an emerging high-quality 3D rendering method, requires significant computation, making real-time execution on existing GPU-equipped edge devices infeasible. Previous efforts to accelerate 3DGS rely on dedicated accelerators that require substantial integration overhead and hardware costs. This work proposes an acceleration strategy that leverages the similarities between the 3DGS pipeline and the highly optimized conventional graphics pipeline in modern GPUs. Instead of developing a dedicated accelerator, we enhance existing GPU rasterizer hardware to efficiently support 3DGS operations. Our results demonstrate a 23$\times$ increase in processing speed and a 24$\times$ reduction in energy consumption, with improvements yielding 6$\times$ faster end-to-end runtime for the original 3DGS algorithm and 4$\times$ for the latest efficiency-improved pipeline, achieving 24 FPS and 46 FPS respectively. These enhancements incur only a minimal area overhead of 0.2\% relative to the entire SoC chip area, underscoring the practicality and efficiency of our approach for enabling 3DGS rendering on resource-constrained platforms.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.4 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 4.3 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Evolutionary Algorithms: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.4741
            </span>
            <a href="https://arxiv.org/abs/2504.08383" target="_blank" rel="noopener noreferrer">Generation of Zoomable maps with Rivers and Fjords</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Torben {\AE}. Mogensen, Emil N. Isenbecker | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">This paper presents a method for generating maps with rivers and fjords. The method is based on recursive subdivision of triangles and allows unlimited zoom on details without requiring generation of a full map at high resolution.</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.0 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 4.3 -->
                
            <!-- Networks: 4.0 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.4756
            </span>
            <a href="https://arxiv.org/abs/2502.18791" target="_blank" rel="noopener noreferrer">Can LLMs Help Uncover Insights about LLMs? A Large-Scale, Evolving Literature Analysis of Frontier LLMs</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Jungsoo Park, Junmo Kang, Gabriel Stanovsky, Alan Ritter | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">The surge of LLM studies makes synthesizing their findings challenging. Analysis of experimental results from literature can uncover important trends across studies, but the time-consuming nature of manual data extraction limits its use. Our study presents a semi-automated approach for literature an</span>
            
            <span class="abstract-full" style="display: none;">The surge of LLM studies makes synthesizing their findings challenging. Analysis of experimental results from literature can uncover important trends across studies, but the time-consuming nature of manual data extraction limits its use. Our study presents a semi-automated approach for literature analysis that accelerates data extraction using LLMs. It automatically identifies relevant arXiv papers, extracts experimental results and related attributes, and organizes them into a structured dataset, LLMEvalDB. We then conduct an automated literature analysis of frontier LLMs, reducing the effort of paper surveying and data extraction by more than 93% compared to manual approaches. We validate LLMEvalDB by showing that it reproduces key findings from a recent manual analysis of Chain-of-Thought (CoT) reasoning and also uncovers new insights that go beyond it, showing, for example, that in-context examples benefit coding and multimodal tasks but offer limited gains in math reasoning tasks compared to zero-shot CoT. Our automatically updatable dataset enables continuous tracking of target models by extracting evaluation studies as new data becomes available. Through LLMEvalDB and empirical analysis, we provide insights into LLMs while facilitating ongoing literature analyses of their behavior.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.2 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 4.3 -->
                
            <!-- Networks: 3.6 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.481
            </span>
            <a href="https://arxiv.org/abs/2504.08161" target="_blank" rel="noopener noreferrer">Rethinking the Foundations for Continual Reinforcement Learning</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Michael Bowling, Esraa Elelimy | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Algorithms and approaches for continual reinforcement learning have gained increasing attention. Much of this early progress rests on the foundations and standard practices of traditional reinforcement learning, without questioning if they are well-suited to the challenges of continual learning agen</span>
            
            <span class="abstract-full" style="display: none;">Algorithms and approaches for continual reinforcement learning have gained increasing attention. Much of this early progress rests on the foundations and standard practices of traditional reinforcement learning, without questioning if they are well-suited to the challenges of continual learning agents. We suggest that many core foundations of traditional RL are, in fact, antithetical to the goals of continual reinforcement learning. We enumerate four such foundations: the Markov decision process formalism, a focus on optimal policies, the expected sum of rewards as the primary evaluation metric, and episodic benchmark environments that embrace the other three foundations. Shedding such sacredly held and taught concepts is not easy. They are self-reinforcing in that each foundation depends upon and holds up the others, making it hard to rethink each in isolation. We propose an alternative set of all four foundations that are better suited to the continual learning setting. We hope to spur on others in rethinking the traditional foundations, proposing and critiquing alternatives, and developing new algorithms and approaches enabled by better-suited foundations.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.9 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 4.5 -->
                
            <!-- Networks: 3.0 -->
                
            <!-- Math: 2.2 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.487
            </span>
            <a href="https://arxiv.org/abs/2411.17729" target="_blank" rel="noopener noreferrer">Fast convolution algorithm for state space models</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Gregory Beylkin | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We present an unconditionally stable algorithm for applying matrix transfer function of a linear time invariant system (LTI) in time domain. The state matrix of an LTI system used for modeling long range dependencies in state space models (SSMs) has eigenvalues close to $1$. The standard recursion d</span>
            
            <span class="abstract-full" style="display: none;">We present an unconditionally stable algorithm for applying matrix transfer function of a linear time invariant system (LTI) in time domain. The state matrix of an LTI system used for modeling long range dependencies in state space models (SSMs) has eigenvalues close to $1$. The standard recursion defining LTI system becomes unstable if the $m\times m$ state matrix has just one eigenvalue with absolute value even slightly greater than 1. This may occur when approximating a state matrix by a structured matrix to reduce the cost of matrix-vector multiplication from $\mathcal{O}\left(m^{2}\right)$ to $\mathcal{O}\left(m\right)$ or $\mathcal{O}\left(m\log m\right).$ We introduce an unconditionally stable algorithm that uses an approximation of the rational transfer function in the z-domain by a matrix polynomial of degree $2^{N+1}-1$, where $N$ is chosen to achieve any user-selected accuracy. Using a cascade implementation in time domain, applying such transfer function to compute $L$ states requires no more than $2L$ matrix-vector multiplications (whereas the standard recursion requires $L$ matrix-vector multiplications). However, using unconditionally stable algorithm, it is not necessary to assure that an approximate state matrix has all eigenvalues with absolute values strictly less than 1 i.e., within the desired accuracy, the absolute value of some eigenvalues may possibly exceed $1$. Consequently, this algorithm allows one to use a wider variety of structured approximations to reduce the cost of matrix-vector multiplication and we briefly describe several of them to be used for this purpose.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.6 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 4.4 -->
                
            <!-- Networks: 3.6 -->
                
            <!-- Math: 2.0 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.4904
            </span>
            <a href="https://arxiv.org/abs/2504.08635" target="_blank" rel="noopener noreferrer">Latent Diffusion Autoencoders: Toward Efficient and Meaningful Unsupervised Representation Learning in Medical Imaging</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Gabriele Lozupone, Alessandro Bria, Francesco Fontanella, Frederick J. A. Meijer, Claudio De Stefano, Henkjan Huisman | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">This study presents Latent Diffusion Autoencoder (LDAE), a novel encoder-decoder diffusion-based framework for efficient and meaningful unsupervised learning in medical imaging, focusing on Alzheimer disease (AD) using brain MR from the ADNI database as a case study. Unlike conventional diffusion au</span>
            
            <span class="abstract-full" style="display: none;">This study presents Latent Diffusion Autoencoder (LDAE), a novel encoder-decoder diffusion-based framework for efficient and meaningful unsupervised learning in medical imaging, focusing on Alzheimer disease (AD) using brain MR from the ADNI database as a case study. Unlike conventional diffusion autoencoders operating in image space, LDAE applies the diffusion process in a compressed latent representation, improving computational efficiency and making 3D medical imaging representation learning tractable. To validate the proposed approach, we explore two key hypotheses: (i) LDAE effectively captures meaningful semantic representations on 3D brain MR associated with AD and ageing, and (ii) LDAE achieves high-quality image generation and reconstruction while being computationally efficient. Experimental results support both hypotheses: (i) linear-probe evaluations demonstrate promising diagnostic performance for AD (ROC-AUC: 90%, ACC: 84%) and age prediction (MAE: 4.1 years, RMSE: 5.2 years); (ii) the learned semantic representations enable attribute manipulation, yielding anatomically plausible modifications; (iii) semantic interpolation experiments show strong reconstruction of missing scans, with SSIM of 0.969 (MSE: 0.0019) for a 6-month gap. Even for longer gaps (24 months), the model maintains robust performance (SSIM > 0.93, MSE < 0.004), indicating an ability to capture temporal progression trends; (iv) compared to conventional diffusion autoencoders, LDAE significantly increases inference throughput (20x faster) while also enhancing reconstruction quality. These findings position LDAE as a promising framework for scalable medical imaging applications, with the potential to serve as a foundation model for medical image analysis. Code available at https://github.com/GabrieleLozupone/LDAE</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.7 -->
                
            <!-- Medicine: 5.0 -->
                
            <!-- Quantum Computing: 4.3 -->
                
            <!-- Networks: 4.0 -->
                
            <!-- Reinforcement Learning: 2.2 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Evolutionary Algorithms: 1.3 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.4947
            </span>
            <a href="https://arxiv.org/abs/2310.08948" target="_blank" rel="noopener noreferrer">Federated Class-Incremental Learning with Prompting</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Xin Luo, Fang-Yi Liang, Jiale Liu, Yu-Wei Zhan, Zhen-Duo Chen, Xin-Shun Xu | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">As Web technology continues to develop, it has become increasingly common to use data stored on different clients. At the same time, federated learning has received widespread attention due to its ability to protect data privacy when let models learn from data which is distributed across various cli</span>
            
            <span class="abstract-full" style="display: none;">As Web technology continues to develop, it has become increasingly common to use data stored on different clients. At the same time, federated learning has received widespread attention due to its ability to protect data privacy when let models learn from data which is distributed across various clients. However, most existing works assume that the client's data are fixed. In real-world scenarios, such an assumption is most likely not true as data may be continuously generated and new classes may also appear. To this end, we focus on the practical and challenging federated class-incremental learning (FCIL) problem. For FCIL, the local and global models may suffer from catastrophic forgetting on old classes caused by the arrival of new classes and the data distributions of clients are non-independent and identically distributed (non-iid).</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.3 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 4.3 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- GNN: 2.2 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Federated Learning: 1.8 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.4969
            </span>
            <a href="https://arxiv.org/abs/2504.08299" target="_blank" rel="noopener noreferrer">Data-driven Estimator Synthesis with Instantaneous Noise</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Felix Br\"andle, Frank Allg\"ower | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Data-driven controller design based on data informativity has gained popularity due to its straightforward applicability, while providing rigorous guarantees. However, applying this framework to the estimator synthesis problem introduces technical challenges, which can only be solved so far by addin</span>
            
            <span class="abstract-full" style="display: none;">Data-driven controller design based on data informativity has gained popularity due to its straightforward applicability, while providing rigorous guarantees. However, applying this framework to the estimator synthesis problem introduces technical challenges, which can only be solved so far by adding restrictive assumptions. In this work, we remove these restrictions to improve performance guarantees. Moreover, our parameterization allows the integration of additional structural knowledge, such as bounds on parameters. Our findings are validated using numerical examples.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.7 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 4.5 -->
                
            <!-- Networks: 3.0 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.4978
            </span>
            <a href="https://arxiv.org/abs/2504.08640" target="_blank" rel="noopener noreferrer">Do LLMs trust AI regulation? Emerging behaviour of game-theoretic LLM agents</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Alessio Buscemi, Daniele Proverbio, Paolo Bova, Nataliya Balabanova, Adeela Bashir, Theodor Cimpeanu, Henrique Correia da Fonseca, Manh Hong Duong, Elias Fernandez Domingos, Antonio M. Fernandes, Marcus Krellner, Ndidi Bianca Ogbo, Simon T. Powers, Fernando P. Santos, Zia Ush Shamszaman, Zhao Song, Alessandro Di Stefano, The Anh Han | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">There is general agreement that fostering trust and cooperation within the AI development ecosystem is essential to promote the adoption of trustworthy AI systems. By embedding Large Language Model (LLM) agents within an evolutionary game-theoretic framework, this paper investigates the complex inte</span>
            
            <span class="abstract-full" style="display: none;">There is general agreement that fostering trust and cooperation within the AI development ecosystem is essential to promote the adoption of trustworthy AI systems. By embedding Large Language Model (LLM) agents within an evolutionary game-theoretic framework, this paper investigates the complex interplay between AI developers, regulators and users, modelling their strategic choices under different regulatory scenarios. Evolutionary game theory (EGT) is used to quantitatively model the dilemmas faced by each actor, and LLMs provide additional degrees of complexity and nuances and enable repeated games and incorporation of personality traits. Our research identifies emerging behaviours of strategic AI agents, which tend to adopt more "pessimistic" (not trusting and defective) stances than pure game-theoretic agents. We observe that, in case of full trust by users, incentives are effective to promote effective regulation; however, conditional trust may deteriorate the "social pact". Establishing a virtuous feedback between users' trust and regulators' reputation thus appears to be key to nudge developers towards creating safe AI. However, the level at which this trust emerges may depend on the specific LLM used for testing. Our results thus provide guidance for AI regulation systems, and help predict the outcome of strategic LLM agents, should they be used to aid regulation itself.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.8 -->
                
            <!-- Quantum Computing: 4.6 -->
                
            <!-- Medicine: 4.4 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.5018
            </span>
            <a href="https://arxiv.org/abs/2504.07792" target="_blank" rel="noopener noreferrer">Breaking the Barriers: Video Vision Transformers for Word-Level Sign Language Recognition</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Alexander Brettmann, Jakob Gr\"avinghoff, Marlene R\"uschoff, Marie Westhues | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Sign language is a fundamental means of communication for the deaf and hard-of-hearing (DHH) community, enabling nuanced expression through gestures, facial expressions, and body movements. Despite its critical role in facilitating interaction within the DHH population, significant barriers persist </span>
            
            <span class="abstract-full" style="display: none;">Sign language is a fundamental means of communication for the deaf and hard-of-hearing (DHH) community, enabling nuanced expression through gestures, facial expressions, and body movements. Despite its critical role in facilitating interaction within the DHH population, significant barriers persist due to the limited fluency in sign language among the hearing population. Overcoming this communication gap through automatic sign language recognition (SLR) remains a challenge, particularly at a dynamic word-level, where temporal and spatial dependencies must be effectively recognized. While Convolutional Neural Networks (CNNs) have shown potential in SLR, they are computationally intensive and have difficulties in capturing global temporal dependencies between video sequences. To address these limitations, we propose a Video Vision Transformer (ViViT) model for word-level American Sign Language (ASL) recognition. Transformer models make use of self-attention mechanisms to effectively capture global relationships across spatial and temporal dimensions, which makes them suitable for complex gesture recognition tasks. The VideoMAE model achieves a Top-1 accuracy of 75.58% on the WLASL100 dataset, highlighting its strong performance compared to traditional CNNs with 65.89%. Our study demonstrates that transformer-based architectures have great potential to advance SLR, overcome communication barriers and promote the inclusion of DHH individuals.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.3 -->
                
            <!-- Medicine: 5.2 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.5033
            </span>
            <a href="https://arxiv.org/abs/2504.00615" target="_blank" rel="noopener noreferrer">Towards Responsible and Trustworthy Educational Data Mining: Comparing Symbolic, Sub-Symbolic, and Neural-Symbolic AI Methods</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Danial Hooshyar, Eve Kikas, Yeongwook Yang, Gustav \v{S}\'ir, Raija H\"am\"al\"ainen, Tommi K\"arkk\"ainen, Roger Azevedo | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Given the demand for responsible and trustworthy AI for education, this study evaluates symbolic, sub-symbolic, and neural-symbolic AI (NSAI) in terms of generalizability and interpretability. Our extensive experiments on balanced and imbalanced self-regulated learning datasets of Estonian primary s</span>
            
            <span class="abstract-full" style="display: none;">Given the demand for responsible and trustworthy AI for education, this study evaluates symbolic, sub-symbolic, and neural-symbolic AI (NSAI) in terms of generalizability and interpretability. Our extensive experiments on balanced and imbalanced self-regulated learning datasets of Estonian primary school students predicting 7th-grade mathematics national test performance showed that symbolic and sub-symbolic methods performed well on balanced data but struggled to identify low performers in imbalanced datasets. Interestingly, symbolic and sub-symbolic methods emphasized different factors in their decision-making: symbolic approaches primarily relied on cognitive and motivational factors, while sub-symbolic methods focused more on cognitive aspects, learnt knowledge, and the demographic variable of gender -- yet both largely overlooked metacognitive factors. The NSAI method, on the other hand, showed advantages by: (i) being more generalizable across both classes -- even in imbalanced datasets -- as its symbolic knowledge component compensated for the underrepresented class; and (ii) relying on a more integrated set of factors in its decision-making, including motivation, (meta)cognition, and learnt knowledge, thus offering a comprehensive and theoretically grounded interpretability framework. These contrasting findings highlight the need for a holistic comparison of AI methods before drawing conclusions based solely on predictive performance. They also underscore the potential of hybrid, human-centred NSAI methods to address the limitations of other AI families and move us closer to responsible AI for education. Specifically, by enabling stakeholders to contribute to AI design, NSAI aligns learned patterns with theoretical constructs, incorporates factors like motivation and metacognition, and strengthens the trustworthiness and responsibility of educational data mining.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.5 -->
                
            <!-- Medicine: 4.8 -->
                
            <!-- Quantum Computing: 4.4 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- Math: 2.0 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.504
            </span>
            <a href="https://arxiv.org/abs/2504.08296" target="_blank" rel="noopener noreferrer">Generative AI for Film Creation: A Survey of Recent Advances</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Ruihan Zhang, Borou Yu, Jiajian Min, Yetong Xin, Zheng Wei, Juncheng Nemo Shi, Mingzhen Huang, Xianghao Kong, Nix Liu Xin, Shanshan Jiang, Praagya Bahuguna, Mark Chan, Khushi Hora, Lijian Yang, Yongqi Liang, Runhe Bian, Yunlei Liu, Isabela Campillo Valencia, Patricia Morales Tredinick, Ilia Kozlov, Sijia Jiang, Peiwen Huang, Na Chen, Xuanxuan Liu, Anyi Rao | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Generative AI (GenAI) is transforming filmmaking, equipping artists with tools like text-to-image and image-to-video diffusion, neural radiance fields, avatar generation, and 3D synthesis. This paper examines the adoption of these technologies in filmmaking, analyzing workflows from recent AI-driven</span>
            
            <span class="abstract-full" style="display: none;">Generative AI (GenAI) is transforming filmmaking, equipping artists with tools like text-to-image and image-to-video diffusion, neural radiance fields, avatar generation, and 3D synthesis. This paper examines the adoption of these technologies in filmmaking, analyzing workflows from recent AI-driven films to understand how GenAI contributes to character creation, aesthetic styling, and narration. We explore key strategies for maintaining character consistency, achieving stylistic coherence, and ensuring motion continuity. Additionally, we highlight emerging trends such as the growing use of 3D generation and the integration of real footage with AI-generated elements.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.0 -->
                
            <!-- Medicine: 4.8 -->
                
            <!-- Quantum Computing: 4.5 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Reinforcement Learning: 1.7 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.5046
            </span>
            <a href="https://arxiv.org/abs/2504.08389" target="_blank" rel="noopener noreferrer">Light-YOLOv8-Flame: A Lightweight High-Performance Flame Detection Algorithm</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Jiawei Lan, Zhibiao Wang, Haoyang Yu, Ye Tao, Wenhua Cui | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Fire detection algorithms, particularly those based on computer vision, encounter significant challenges such as high computational costs and delayed response times, which hinder their application in real-time systems. To address these limitations, this paper introduces Light-YOLOv8-Flame, a lightwe</span>
            
            <span class="abstract-full" style="display: none;">Fire detection algorithms, particularly those based on computer vision, encounter significant challenges such as high computational costs and delayed response times, which hinder their application in real-time systems. To address these limitations, this paper introduces Light-YOLOv8-Flame, a lightweight flame detection algorithm specifically designed for fast and efficient real-time deployment. The proposed model enhances the YOLOv8 architecture through the substitution of the original C2f module with the FasterNet Block module. This new block combines Partial Convolution (PConv) and Convolution (Conv) layers, reducing both computational complexity and model size. A dataset comprising 7,431 images, representing both flame and non-flame scenarios, was collected and augmented for training purposes. Experimental findings indicate that the modified YOLOv8 model achieves a 0.78% gain in mean average precision (mAP) and a 2.05% boost in recall, while reducing the parameter count by 25.34%, with only a marginal decrease in precision by 0.82%. These findings highlight that Light-YOLOv8-Flame offers enhanced detection performance and speed, making it well-suited for real-time fire detection on resource-constrained devices.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.0 -->
                
            <!-- Medicine: 5.4 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Math: 2.0 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.5079
            </span>
            <a href="https://arxiv.org/abs/2406.13896" target="_blank" rel="noopener noreferrer">SMORE: Simultaneous Map and Object REconstruction</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Nathaniel Chodosh, Anish Madan, Simon Lucey, Deva Ramanan | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We present a method for dynamic surface reconstruction of large-scale urban scenes from LiDAR. Depth-based reconstructions tend to focus on small-scale objects or large-scale SLAM reconstructions that treat moving objects as outliers. We take a holistic perspective and optimize a compositional model</span>
            
            <span class="abstract-full" style="display: none;">We present a method for dynamic surface reconstruction of large-scale urban scenes from LiDAR. Depth-based reconstructions tend to focus on small-scale objects or large-scale SLAM reconstructions that treat moving objects as outliers. We take a holistic perspective and optimize a compositional model of a dynamic scene that decomposes the world into rigidly-moving objects and the background. To achieve this, we take inspiration from recent novel view synthesis methods and frame the reconstruction problem as a global optimization over neural surfaces, ego poses, and object poses, which minimizes the error between composed spacetime surfaces and input LiDAR scans. In contrast to view synthesis methods, which typically minimize 2D errors with gradient descent, we minimize a 3D point-to-surface error by coordinate descent, which we decompose into registration and surface reconstruction steps. Each step can be handled well by off-the-shelf methods without any re-training. We analyze the surface reconstruction step for rolling-shutter LiDARs, and show that deskewing operations common in continuous time SLAM can be applied to dynamic objects as well, improving results over prior art by an order of magnitude. Beyond pursuing dynamic reconstruction as a goal in and of itself, we propose that such a system can be used to auto-label partially annotated sequences and produce ground truth annotation for hard-to-label problems such as depth completion and scene flow.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.8 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- Math: 2.0 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Robotics: 1.9 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.5083
            </span>
            <a href="https://arxiv.org/abs/2504.08328" target="_blank" rel="noopener noreferrer">Towards generalizable single-cell perturbation modeling via the Conditional Monge Gap</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Alice Driessen, Benedek Harsanyi, Marianna Rapsomaniki, Jannis Born | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Learning the response of single-cells to various treatments offers great potential to enable targeted therapies. In this context, neural optimal transport (OT) has emerged as a principled methodological framework because it inherently accommodates the challenges of unpaired data induced by cell dest</span>
            
            <span class="abstract-full" style="display: none;">Learning the response of single-cells to various treatments offers great potential to enable targeted therapies. In this context, neural optimal transport (OT) has emerged as a principled methodological framework because it inherently accommodates the challenges of unpaired data induced by cell destruction during data acquisition. However, most existing OT approaches are incapable of conditioning on different treatment contexts (e.g., time, drug treatment, drug dosage, or cell type) and we still lack methods that unanimously show promising generalization performance to unseen treatments. Here, we propose the Conditional Monge Gap which learns OT maps conditionally on arbitrary covariates. We demonstrate its value in predicting single-cell perturbation responses conditional to one or multiple drugs, a drug dosage, or combinations thereof. We find that our conditional models achieve results comparable and sometimes even superior to the condition-specific state-of-the-art on scRNA-seq as well as multiplexed protein imaging data. Notably, by aggregating data across conditions we perform cross-task learning which unlocks remarkable generalization abilities to unseen drugs or drug dosages, widely outperforming other conditional models in capturing heterogeneity (i.e., higher moments) in the perturbed population. Finally, by scaling to hundreds of conditions and testing on unseen drugs, we narrow the gap between structure-based and effect-based drug representations, suggesting a promising path to the successful prediction of perturbation effects for unseen treatments.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.1 -->
                
            <!-- Medicine: 4.8 -->
                
            <!-- Quantum Computing: 4.4 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.5194
            </span>
            <a href="https://arxiv.org/abs/2504.08718" target="_blank" rel="noopener noreferrer">EMO-X: Efficient Multi-Person Pose and Shape Estimation in One-Stage</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Haohang Jian, Jinlu Zhang, Junyi Wu, Zhigang Tu | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Expressive Human Pose and Shape Estimation (EHPS) aims to jointly estimate human pose, hand gesture, and facial expression from monocular images. Existing methods predominantly rely on Transformer-based architectures, which suffer from quadratic complexity in self-attention, leading to substantial c</span>
            
            <span class="abstract-full" style="display: none;">Expressive Human Pose and Shape Estimation (EHPS) aims to jointly estimate human pose, hand gesture, and facial expression from monocular images. Existing methods predominantly rely on Transformer-based architectures, which suffer from quadratic complexity in self-attention, leading to substantial computational overhead, especially in multi-person scenarios. Recently, Mamba has emerged as a promising alternative to Transformers due to its efficient global modeling capability. However, it remains limited in capturing fine-grained local dependencies, which are essential for precise EHPS. To address these issues, we propose EMO-X, the Efficient Multi-person One-stage model for multi-person EHPS. Specifically, we explore a Scan-based Global-Local Decoder (SGLD) that integrates global context with skeleton-aware local features to iteratively enhance human tokens. Our EMO-X leverages the superior global modeling capability of Mamba and designs a local bidirectional scan mechanism for skeleton-aware local refinement. Comprehensive experiments demonstrate that EMO-X strikes an excellent balance between efficiency and accuracy. Notably, it achieves a significant reduction in computational complexity, requiring 69.8% less inference time compared to state-of-the-art (SOTA) methods, while outperforming most of them in accuracy.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.8 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 4.3 -->
                
            <!-- Networks: 3.7 -->
                
            <!-- GNN: 2.3 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Federated Learning: 1.7 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Evolutionary Algorithms: 1.3 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.5229
            </span>
            <a href="https://arxiv.org/abs/2504.08260" target="_blank" rel="noopener noreferrer">Evaluating the Bias in LLMs for Surveying Opinion and Decision Making in Healthcare</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Yonchanok Khaokaew, Flora D. Salim, Andreas Z\"ufle, Hao Xue, Taylor Anderson, Matthew Scotch, David J Heslop | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Generative agents have been increasingly used to simulate human behaviour in silico, driven by large language models (LLMs). These simulacra serve as sandboxes for studying human behaviour without compromising privacy or safety. However, it remains unclear whether such agents can truly represent rea</span>
            
            <span class="abstract-full" style="display: none;">Generative agents have been increasingly used to simulate human behaviour in silico, driven by large language models (LLMs). These simulacra serve as sandboxes for studying human behaviour without compromising privacy or safety. However, it remains unclear whether such agents can truly represent real individuals. This work compares survey data from the Understanding America Study (UAS) on healthcare decision-making with simulated responses from generative agents. Using demographic-based prompt engineering, we create digital twins of survey respondents and analyse how well different LLMs reproduce real-world behaviours. Our findings show that some LLMs fail to reflect realistic decision-making, such as predicting universal vaccine acceptance. However, Llama 3 captures variations across race and Income more accurately but also introduces biases not present in the UAS data. This study highlights the potential of generative agents for behavioural research while underscoring the risks of bias from both LLMs and prompting strategies.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.4 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 4.5 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.5259
            </span>
            <a href="https://arxiv.org/abs/2502.16701" target="_blank" rel="noopener noreferrer">Beyond Release: Access Considerations for Generative AI Systems</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Irene Solaiman, Rishi Bommasani, Dan Hendrycks, Ariel Herbert-Voss, Yacine Jernite, Aviya Skowron, Andrew Trask | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Generative AI release decisions determine whether system components are made available, but release does not address many other elements that change how users and stakeholders are able to engage with a system. Beyond release, access to system components informs potential risks and benefits. Access r</span>
            
            <span class="abstract-full" style="display: none;">Generative AI release decisions determine whether system components are made available, but release does not address many other elements that change how users and stakeholders are able to engage with a system. Beyond release, access to system components informs potential risks and benefits. Access refers to practical needs, infrastructurally, technically, and societally, in order to use available components in some way. We deconstruct access along three axes: resourcing, technical usability, and utility. Within each category, a set of variables per system component clarify tradeoffs. For example, resourcing requires access to computing infrastructure to serve model weights. We also compare the accessibility of four high performance language models, two open-weight and two closed-weight, showing similar considerations for all based instead on access variables. Access variables set the foundation for being able to scale or increase access to users; we examine the scale of access and how scale affects ability to manage and intervene on risks. This framework better encompasses the landscape and risk-benefit tradeoffs of system releases to inform system release decisions, research, and policy.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.4 -->
                
            <!-- Medicine: 5.0 -->
                
            <!-- Quantum Computing: 4.4 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- Math: 1.9 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.5394
            </span>
            <a href="https://arxiv.org/abs/2504.08192" target="_blank" rel="noopener noreferrer">SAEs $\textit{Can}$ Improve Unlearning: Dynamic Sparse Autoencoder Guardrails for Precision Unlearning in LLMs</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Aashiq Muhamed, Jacopo Bonato, Mona Diab, Virginia Smith | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Machine unlearning is a promising approach to improve LLM safety by removing unwanted knowledge from the model. However, prevailing gradient-based unlearning methods suffer from issues such as high computational costs, hyperparameter instability, poor sequential unlearning capability, vulnerability </span>
            
            <span class="abstract-full" style="display: none;">Machine unlearning is a promising approach to improve LLM safety by removing unwanted knowledge from the model. However, prevailing gradient-based unlearning methods suffer from issues such as high computational costs, hyperparameter instability, poor sequential unlearning capability, vulnerability to relearning attacks, low data efficiency, and lack of interpretability. While Sparse Autoencoders are well-suited to improve these aspects by enabling targeted activation-based unlearning, prior approaches underperform gradient-based methods. This work demonstrates that, contrary to these earlier findings, SAEs can significantly improve unlearning when employed dynamically. We introduce $\textbf{Dynamic DAE Guardrails}$ (DSG), a novel method for precision unlearning that leverages principled feature selection and a dynamic classifier. Our experiments show DSG substantially outperforms leading unlearning methods, achieving superior forget-utility trade-offs. DSG addresses key drawbacks of gradient-based approaches for unlearning -- offering enhanced computational efficiency and stability, robust performance in sequential unlearning, stronger resistance to relearning attacks, better data efficiency including zero-shot settings, and more interpretable unlearning.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.2 -->
                
            <!-- Medicine: 5.0 -->
                
            <!-- Quantum Computing: 4.4 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- Evolutionary Algorithms: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.5422
            </span>
            <a href="https://arxiv.org/abs/2406.14567" target="_blank" rel="noopener noreferrer">DragPoser: Motion Reconstruction from Variable Sparse Tracking Signals via Latent Space Optimization</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Jose Luis Ponton, Eduard Pujol, Andreas Aristidou, Carlos Andujar, Nuria Pelechano | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">High-quality motion reconstruction that follows the user's movements can be achieved by high-end mocap systems with many sensors. However, obtaining such animation quality with fewer input devices is gaining popularity as it brings mocap closer to the general public. The main challenges include the </span>
            
            <span class="abstract-full" style="display: none;">High-quality motion reconstruction that follows the user's movements can be achieved by high-end mocap systems with many sensors. However, obtaining such animation quality with fewer input devices is gaining popularity as it brings mocap closer to the general public. The main challenges include the loss of end-effector accuracy in learning-based approaches, or the lack of naturalness and smoothness in IK-based solutions. In addition, such systems are often finely tuned to a specific number of trackers and are highly sensitive to missing data e.g., in scenarios where a sensor is occluded or malfunctions. In response to these challenges, we introduce DragPoser, a novel deep-learning-based motion reconstruction system that accurately represents hard and dynamic on-the-fly constraints, attaining real-time high end-effectors position accuracy. This is achieved through a pose optimization process within a structured latent space. Our system requires only one-time training on a large human motion dataset, and then constraints can be dynamically defined as losses, while the pose is iteratively refined by computing the gradients of these losses within the latent space. To further enhance our approach, we incorporate a Temporal Predictor network, which employs a Transformer architecture to directly encode temporality within the latent space. This network ensures the pose optimization is confined to the manifold of valid poses and also leverages past pose data to predict temporally coherent poses. Results demonstrate that DragPoser surpasses both IK-based and the latest data-driven methods in achieving precise end-effector positioning, while it produces natural poses and temporally coherent motion. In addition, our system showcases robustness against on-the-fly constraint modifications, and exhibits exceptional adaptability to various input configurations and changes.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.7 -->
                
            <!-- Medicine: 5.0 -->
                
            <!-- Quantum Computing: 4.5 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- Math: 2.1 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- Hardware: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.5497
            </span>
            <a href="https://arxiv.org/abs/2504.08675" target="_blank" rel="noopener noreferrer">X2BR: High-Fidelity 3D Bone Reconstruction from a Planar X-Ray Image with Hybrid Neural Implicit Methods</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Gokce Guven, H. Fatih Ugurdag, Hasan F. Ates | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Accurate 3D bone reconstruction from a single planar X-ray remains a challenge due to anatomical complexity and limited input data. We propose X2BR, a hybrid neural implicit framework that combines continuous volumetric reconstruction with template-guided non-rigid registration. The core network, X2</span>
            
            <span class="abstract-full" style="display: none;">Accurate 3D bone reconstruction from a single planar X-ray remains a challenge due to anatomical complexity and limited input data. We propose X2BR, a hybrid neural implicit framework that combines continuous volumetric reconstruction with template-guided non-rigid registration. The core network, X2B, employs a ConvNeXt-based encoder to extract spatial features from X-rays and predict high-fidelity 3D bone occupancy fields without relying on statistical shape models. To further refine anatomical accuracy, X2BR integrates a patient-specific template mesh, constructed using YOLOv9-based detection and the SKEL biomechanical skeleton model. The coarse reconstruction is aligned to the template using geodesic-based coherent point drift, enabling anatomically consistent 3D bone volumes. Experimental results on a clinical dataset show that X2B achieves the highest numerical accuracy, with an IoU of 0.952 and Chamfer-L1 distance of 0.005, outperforming recent baselines including X2V and D2IM-Net. Building on this, X2BR incorporates anatomical priors via YOLOv9-based bone detection and biomechanical template alignment, leading to reconstructions that, while slightly lower in IoU (0.875), offer superior anatomical realism, especially in rib curvature and vertebral alignment. This numerical accuracy vs. visual consistency trade-off between X2B and X2BR highlights the value of hybrid frameworks for clinically relevant 3D reconstructions.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.0 -->
                
            <!-- Medicine: 5.3 -->
                
            <!-- Quantum Computing: 4.3 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- GNN: 2.2 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.5503
            </span>
            <a href="https://arxiv.org/abs/2504.08040" target="_blank" rel="noopener noreferrer">Can Reasoning LLMs Enhance Clinical Document Classification?</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Akram Mustafa, Usman Naseem, Mostafa Rahimi Azghadi | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Clinical document classification is essential for converting unstructured medical texts into standardised ICD-10 diagnoses, yet it faces challenges due to complex medical language, privacy constraints, and limited annotated datasets. Large Language Models (LLMs) offer promising improvements in accur</span>
            
            <span class="abstract-full" style="display: none;">Clinical document classification is essential for converting unstructured medical texts into standardised ICD-10 diagnoses, yet it faces challenges due to complex medical language, privacy constraints, and limited annotated datasets. Large Language Models (LLMs) offer promising improvements in accuracy and efficiency for this task. This study evaluates the performance and consistency of eight LLMs; four reasoning (Qwen QWQ, Deepseek Reasoner, GPT o3 Mini, Gemini 2.0 Flash Thinking) and four non-reasoning (Llama 3.3, GPT 4o Mini, Gemini 2.0 Flash, Deepseek Chat); in classifying clinical discharge summaries using the MIMIC-IV dataset. Using cTAKES to structure clinical narratives, models were assessed across three experimental runs, with majority voting determining final predictions. Results showed that reasoning models outperformed non-reasoning models in accuracy (71% vs 68%) and F1 score (67% vs 60%), with Gemini 2.0 Flash Thinking achieving the highest accuracy (75%) and F1 score (76%). However, non-reasoning models demonstrated greater stability (91% vs 84% consistency). Performance varied across ICD-10 codes, with reasoning models excelling in complex cases but struggling with abstract categories. Findings indicate a trade-off between accuracy and consistency, suggesting that a hybrid approach could optimise clinical coding. Future research should explore multi-label classification, domain-specific fine-tuning, and ensemble methods to enhance model reliability in real-world applications.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.4 -->
                
            <!-- Medicine: 5.0 -->
                
            <!-- Quantum Computing: 4.4 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.3 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.5526
            </span>
            <a href="https://arxiv.org/abs/2504.08223" target="_blank" rel="noopener noreferrer">Stochastic Momentum ADMM for nonconvex and nonsmooth optimization with application to PnP algorithm</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Kangkang Deng, Shuchang Zhang, Boyu Wang, Jiachen Jin, Juan Zhou, Hongxia Wang | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">This paper introduces a single-loop Stochastic Momentum Alternating Direction Method of Multipliers (SMADMM) for tackling a class of nonconvex and nonsmooth optimization problems. We establish that SMADMM achieves an optimal oracle complexity of $\mathcal{O}(\epsilon^{-\frac{3}{2}})$ in the online s</span>
            
            <span class="abstract-full" style="display: none;">This paper introduces a single-loop Stochastic Momentum Alternating Direction Method of Multipliers (SMADMM) for tackling a class of nonconvex and nonsmooth optimization problems. We establish that SMADMM achieves an optimal oracle complexity of $\mathcal{O}(\epsilon^{-\frac{3}{2}})$ in the online setting, where only stochastic first-order oracle, is available. In particular, SMADMM requires only $\mathcal{O}(1)$ stochastic gradient evaluations per iteration and avoids the need for restarting with large batch gradient estimates. This is the first stochastic ADMM method achieving optimal oracle complexity for nonconvex and nonsmooth problems, requiring $\mathcal{O}(1)$ batch size. Furthermore, we extend our method by integrating it with plug-and-play (PnP) priors, resulting in the PnP-SMADMM algorithm. Numerical experiments on classification, CT image reconstruction and phase retrieve demonstrate the practical effectiveness of our approach and validate the theoretical findings.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.3 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 4.5 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- Math: 2.1 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.554
            </span>
            <a href="https://arxiv.org/abs/2405.08190" target="_blank" rel="noopener noreferrer">Barren plateaus are amplified by the dimension of qudits</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Lucas Friedrich, Tiago de Souza Farias, Jonas Maziero | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Variational Quantum Algorithms (VQAs) have emerged as pivotal strategies for attaining quantum advantage in diverse scientific and technological domains, notably within Quantum Neural Networks. However, despite their potential, VQAs encounter significant obstacles, chief among them being the vanishi</span>
            
            <span class="abstract-full" style="display: none;">Variational Quantum Algorithms (VQAs) have emerged as pivotal strategies for attaining quantum advantage in diverse scientific and technological domains, notably within Quantum Neural Networks. However, despite their potential, VQAs encounter significant obstacles, chief among them being the vanishing gradient problem, commonly referred to as barren plateaus. In this article, through meticulous analysis, we demonstrate that existing literature implicitly suggests the intrinsic influence of qudit dimensionality on barren plateaus. To instantiate these findings, we present numerical results that exemplify the impact of qudit dimensionality on barren plateaus. Therefore, despite the proposition of various error mitigation techniques, our results call for further scrutiny about their efficacy in the context of VQAs with qudits.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.1 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 4.6 -->
                
            <!-- Networks: 3.0 -->
                
            <!-- Math: 2.0 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Hardware: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.5568
            </span>
            <a href="https://arxiv.org/abs/2410.21443" target="_blank" rel="noopener noreferrer">TACO: Adversarial Camouflage Optimization on Trucks to Fool Object Detectors</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Adonisz Dimitriu, Tam\'as Michaletzky, Viktor Remeli | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Adversarial attacks threaten the reliability of machine learning models in critical applications like autonomous vehicles and defense systems. As object detectors become more robust with models like YOLOv8, developing effective adversarial methodologies is increasingly challenging. We present Truck </span>
            
            <span class="abstract-full" style="display: none;">Adversarial attacks threaten the reliability of machine learning models in critical applications like autonomous vehicles and defense systems. As object detectors become more robust with models like YOLOv8, developing effective adversarial methodologies is increasingly challenging. We present Truck Adversarial Camouflage Optimization (TACO), a novel framework that generates adversarial camouflage patterns on 3D vehicle models to deceive state-of-the-art object detectors. Adopting Unreal Engine 5, TACO integrates differentiable rendering with a Photorealistic Rendering Network to optimize adversarial textures targeted at YOLOv8. To ensure the generated textures are both effective in deceiving detectors and visually plausible, we introduce the Convolutional Smooth Loss function, a generalized smooth loss function. Experimental evaluations demonstrate that TACO significantly degrades YOLOv8's detection performance, achieving an AP@0.5 of 0.0099 on unseen test data. Furthermore, these adversarial patterns exhibit strong transferability to other object detection models such as Faster R-CNN and earlier YOLO versions.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.0 -->
                
            <!-- Medicine: 5.2 -->
                
            <!-- Quantum Computing: 4.4 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.5637
            </span>
            <a href="https://arxiv.org/abs/2504.08414" target="_blank" rel="noopener noreferrer">Adversarial Examples in Environment Perception for Automated Driving (Review)</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Jun Yan, Huilin Yin | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">The renaissance of deep learning has led to the massive development of automated driving. However, deep neural networks are vulnerable to adversarial examples. The perturbations of adversarial examples are imperceptible to human eyes but can lead to the false predictions of neural networks. It poses</span>
            
            <span class="abstract-full" style="display: none;">The renaissance of deep learning has led to the massive development of automated driving. However, deep neural networks are vulnerable to adversarial examples. The perturbations of adversarial examples are imperceptible to human eyes but can lead to the false predictions of neural networks. It poses a huge risk to artificial intelligence (AI) applications for automated driving. This survey systematically reviews the development of adversarial robustness research over the past decade, including the attack and defense methods and their applications in automated driving. The growth of automated driving pushes forward the realization of trustworthy AI applications. This review lists significant references in the research history of adversarial examples.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.6 -->
                
            <!-- Medicine: 5.3 -->
                
            <!-- Quantum Computing: 4.3 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- Math: 2.1 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 1.7 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- SpikingNN: 1.3 -->
                
            <!-- Robotics: 1.3 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.5637
            </span>
            <a href="https://arxiv.org/abs/2504.08308" target="_blank" rel="noopener noreferrer">ScalerEval: Automated and Consistent Evaluation Testbed for Auto-scalers in Microservices</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Shuaiyu Xie, Jian Wang, Yang Luo, Yunqing Yong, Yuzhen Tan, Bing Li | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Auto-scaling is an automated approach that dynamically provisions resources for microservices to accommodate fluctuating workloads. Despite the introduction of many sophisticated auto-scaling algorithms, evaluating auto-scalers remains time-consuming and labor-intensive, as it requires the implement</span>
            
            <span class="abstract-full" style="display: none;">Auto-scaling is an automated approach that dynamically provisions resources for microservices to accommodate fluctuating workloads. Despite the introduction of many sophisticated auto-scaling algorithms, evaluating auto-scalers remains time-consuming and labor-intensive, as it requires the implementation of numerous fundamental interfaces, complex manual operations, and in-depth domain knowledge. Besides, frequent human intervention can inevitably introduce operational errors, leading to inconsistencies in the evaluation of different auto-scalers. To address these issues, we present ScalerEval, an end-to-end automated and consistent testbed for auto-scalers in microservices. ScalerEval integrates essential fundamental interfaces for implementation of auto-scalers and further orchestrates a one-click evaluation workflow for researchers. The source code is publicly available at \href{https://github.com/WHU-AISE/ScalerEval}{https://github.com/WHU-AISE/ScalerEval}.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.6 -->
                
            <!-- Medicine: 5.7 -->
                
            <!-- Quantum Computing: 4.3 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Hardware: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.5804
            </span>
            <a href="https://arxiv.org/abs/2504.08051" target="_blank" rel="noopener noreferrer">Compositional Flows for 3D Molecule and Synthesis Pathway Co-design</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Tony Shen, Seonghwan Seo, Ross Irwin, Kieran Didi, Simon Olsson, Woo Youn Kim, Martin Ester | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Many generative applications, such as synthesis-based 3D molecular design, involve constructing compositional objects with continuous features. Here, we introduce Compositional Generative Flows (CGFlow), a novel framework that extends flow matching to generate objects in compositional steps while mo</span>
            
            <span class="abstract-full" style="display: none;">Many generative applications, such as synthesis-based 3D molecular design, involve constructing compositional objects with continuous features. Here, we introduce Compositional Generative Flows (CGFlow), a novel framework that extends flow matching to generate objects in compositional steps while modeling continuous states. Our key insight is that modeling compositional state transitions can be formulated as a straightforward extension of the flow matching interpolation process. We further build upon the theoretical foundations of generative flow networks (GFlowNets), enabling reward-guided sampling of compositional structures. We apply CGFlow to synthesizable drug design by jointly designing the molecule's synthetic pathway with its 3D binding pose. Our approach achieves state-of-the-art binding affinity on all 15 targets from the LIT-PCBA benchmark, and 5.8$\times$ improvement in sampling efficiency compared to 2D synthesis-based baseline. To our best knowledge, our method is also the first to achieve state of-art-performance in both Vina Dock (-9.38) and AiZynth success rate (62.2\%) on the CrossDocked benchmark.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.3 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.5873
            </span>
            <a href="https://arxiv.org/abs/2504.08581" target="_blank" rel="noopener noreferrer">FMLGS: Fast Multilevel Language Embedded Gaussians for Part-level Interactive Agents</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Xin Tan, Yuzhou Ji, He Zhu, Yuan Xie | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">The semantically interactive radiance field has long been a promising backbone for 3D real-world applications, such as embodied AI to achieve scene understanding and manipulation. However, multi-granularity interaction remains a challenging task due to the ambiguity of language and degraded quality </span>
            
            <span class="abstract-full" style="display: none;">The semantically interactive radiance field has long been a promising backbone for 3D real-world applications, such as embodied AI to achieve scene understanding and manipulation. However, multi-granularity interaction remains a challenging task due to the ambiguity of language and degraded quality when it comes to queries upon object components. In this work, we present FMLGS, an approach that supports part-level open-vocabulary query within 3D Gaussian Splatting (3DGS). We propose an efficient pipeline for building and querying consistent object- and part-level semantics based on Segment Anything Model 2 (SAM2). We designed a semantic deviation strategy to solve the problem of language ambiguity among object parts, which interpolates the semantic features of fine-grained targets for enriched information. Once trained, we can query both objects and their describable parts using natural language. Comparisons with other state-of-the-art methods prove that our method can not only better locate specified part-level targets, but also achieve first-place performance concerning both speed and accuracy, where FMLGS is 98 x faster than LERF, 4 x faster than LangSplat and 2.5 x faster than LEGaussians. Meanwhile, we further integrate FMLGS as a virtual agent that can interactively navigate through 3D scenes, locate targets, and respond to user demands through a chat interface, which demonstrates the potential of our work to be further expanded and applied in the future.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.6 -->
                
            <!-- Quantum Computing: 4.7 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- Evolutionary Algorithms: 1.3 -->
                
            <!-- SpikingNN: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.5897
            </span>
            <a href="https://arxiv.org/abs/2312.05114" target="_blank" rel="noopener noreferrer">The Inadequacy of Similarity-based Privacy Metrics: Privacy Attacks against "Truly Anonymous" Synthetic Datasets</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Georgi Ganev, Emiliano De Cristofaro | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Generative models producing synthetic data are meant to provide a privacy-friendly approach to releasing data. However, their privacy guarantees are only considered robust when models satisfy Differential Privacy (DP). Alas, this is not a ubiquitous standard, as many leading companies (and, in fact,</span>
            
            <span class="abstract-full" style="display: none;">Generative models producing synthetic data are meant to provide a privacy-friendly approach to releasing data. However, their privacy guarantees are only considered robust when models satisfy Differential Privacy (DP). Alas, this is not a ubiquitous standard, as many leading companies (and, in fact, research papers) use ad-hoc privacy metrics based on testing the statistical similarity between synthetic and real data.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.6 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.5909
            </span>
            <a href="https://arxiv.org/abs/2504.08638" target="_blank" rel="noopener noreferrer">Transformer Learns Optimal Variable Selection in Group-Sparse Classification</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Chenyang Zhang, Xuran Meng, Yuan Cao | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Transformers have demonstrated remarkable success across various applications. However, the success of transformers have not been understood in theory. In this work, we give a case study of how transformers can be trained to learn a classic statistical model with "group sparsity", where the input va</span>
            
            <span class="abstract-full" style="display: none;">Transformers have demonstrated remarkable success across various applications. However, the success of transformers have not been understood in theory. In this work, we give a case study of how transformers can be trained to learn a classic statistical model with "group sparsity", where the input variables form multiple groups, and the label only depends on the variables from one of the groups. We theoretically demonstrate that, a one-layer transformer trained by gradient descent can correctly leverage the attention mechanism to select variables, disregarding irrelevant ones and focusing on those beneficial for classification. We also demonstrate that a well-pretrained one-layer transformer can be adapted to new downstream tasks to achieve good prediction accuracy with a limited number of samples. Our study sheds light on how transformers effectively learn structured data.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.3 -->
                
            <!-- Medicine: 4.8 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 3.0 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Robotics: 1.9 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.5914
            </span>
            <a href="https://arxiv.org/abs/2504.08106" target="_blank" rel="noopener noreferrer">A Case Study on Evaluating Genetic Algorithms for Early Building Design Optimization: Comparison with Random and Grid Searches</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Farnaz Nazari, Wei Yan | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">In early-stage architectural design, optimization algorithms are essential for efficiently exploring large and complex design spaces under tight computational constraints. While prior research has benchmarked various optimization methods, their findings often lack generalizability to real-world, dom</span>
            
            <span class="abstract-full" style="display: none;">In early-stage architectural design, optimization algorithms are essential for efficiently exploring large and complex design spaces under tight computational constraints. While prior research has benchmarked various optimization methods, their findings often lack generalizability to real-world, domain-specific problems, particularly in early building design optimization for energy performance. This study evaluates the effectiveness of Genetic Algorithms (GAs) for early design optimization, focusing on their ability to find near-optimal solutions within limited timeframes. Using a constrained case study, we compare a simple GA to two baseline methods, Random Search (RS) and Grid Search (GS), with each algorithm tested 10 times to enhance the reliability of the conclusions. Our findings show that while RS may miss optimal solutions due to its stochastic nature, it was unexpectedly effective under tight computational limits. Despite being more systematic, GS was outperformed by RS, likely due to the irregular design search space. This suggests that, under strict computational constraints, lightweight methods like RS can sometimes outperform more complex approaches like GA. As this study is limited to a single case under specific constraints, future research should investigate a broader range of design scenarios and computational settings to validate and generalize the findings. Additionally, the potential of Random Search or hybrid optimization methods should be further investigated, particularly in contexts with strict computational limitations.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.0 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 4.7 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.5916
            </span>
            <a href="https://arxiv.org/abs/2504.08646" target="_blank" rel="noopener noreferrer">MBE-ARI: A Multimodal Dataset Mapping Bi-directional Engagement in Animal-Robot Interaction</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Ian Noronha, Advait Prasad Jawaji, Juan Camilo Soto, Jiajun An, Yan Gu, Upinder Kaur | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Animal-robot interaction (ARI) remains an unexplored challenge in robotics, as robots struggle to interpret the complex, multimodal communication cues of animals, such as body language, movement, and vocalizations. Unlike human-robot interaction, which benefits from established datasets and framewor</span>
            
            <span class="abstract-full" style="display: none;">Animal-robot interaction (ARI) remains an unexplored challenge in robotics, as robots struggle to interpret the complex, multimodal communication cues of animals, such as body language, movement, and vocalizations. Unlike human-robot interaction, which benefits from established datasets and frameworks, animal-robot interaction lacks the foundational resources needed to facilitate meaningful bidirectional communication. To bridge this gap, we present the MBE-ARI (Multimodal Bidirectional Engagement in Animal-Robot Interaction), a novel multimodal dataset that captures detailed interactions between a legged robot and cows. The dataset includes synchronized RGB-D streams from multiple viewpoints, annotated with body pose and activity labels across interaction phases, offering an unprecedented level of detail for ARI research. Additionally, we introduce a full-body pose estimation model tailored for quadruped animals, capable of tracking 39 keypoints with a mean average precision (mAP) of 92.7%, outperforming existing benchmarks in animal pose estimation. The MBE-ARI dataset and our pose estimation framework lay a robust foundation for advancing research in animal-robot interaction, providing essential tools for developing perception, reasoning, and interaction frameworks needed for effective collaboration between robots and animals. The dataset and resources are publicly available at https://github.com/RISELabPurdue/MBE-ARI/, inviting further exploration and development in this critical area.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.0 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Robotics: 2.0 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.5956
            </span>
            <a href="https://arxiv.org/abs/2504.08469" target="_blank" rel="noopener noreferrer">Artifact detection and localization in single-channel mobile EEG for sleep research using deep learning and attention mechanisms</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Khrystyna Semkiv, Jia Zhang, Maria Laura Ferster, Walter Karlen | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Artifacts in the electroencephalogram (EEG) degrade signal quality and impact the analysis of brain activity. Current methods for detecting artifacts in sleep EEG rely on simple threshold-based algorithms that require manual intervention, which is time-consuming and impractical due to the vast volum</span>
            
            <span class="abstract-full" style="display: none;">Artifacts in the electroencephalogram (EEG) degrade signal quality and impact the analysis of brain activity. Current methods for detecting artifacts in sleep EEG rely on simple threshold-based algorithms that require manual intervention, which is time-consuming and impractical due to the vast volume of data that novel mobile recording systems generate. We propose a convolutional neural network (CNN) model incorporating a convolutional block attention module (CNN-CBAM) to detect and identify the location of artifacts in the sleep EEG with attention maps. We benchmarked this model against six other machine learning and signal processing approaches. We trained/tuned all models on 72 manually annotated EEG recordings obtained during home-based monitoring from 18 healthy participants with a mean (SD) age of 68.05 y ($\pm$5.02). We tested them on 26 separate recordings from 6 healthy participants with a mean (SD) age of 68.33 y ($\pm$4.08), with contained artifacts in 4\% of epochs. CNN-CBAM achieved the highest area under the receiver operating characteristic curve (0.88), sensitivity (0.81), and specificity (0.86) when compared to the other approaches. The attention maps from CNN-CBAM localized artifacts within the epoch with a sensitivity of 0.71 and specificity of 0.67. This work demonstrates the feasibility of automating the detection and localization of artifacts in wearable sleep EEG.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.6 -->
                
            <!-- Medicine: 5.1 -->
                
            <!-- Quantum Computing: 4.5 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- Math: 2.1 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- SpikingNN: 1.3 -->
                
            <!-- Robotics: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Hardware: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.6047
            </span>
            <a href="https://arxiv.org/abs/2504.08227" target="_blank" rel="noopener noreferrer">DaemonSec: Examining the Role of Machine Learning for Daemon Security in Linux Environments</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Sheikh Muhammad Farjad | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">DaemonSec is an early-stage startup exploring machine learning (ML)-based security for Linux daemons, a critical yet often overlooked attack surface. While daemon security remains underexplored, conventional defenses struggle against adaptive threats and zero-day exploits. To assess the perspectives</span>
            
            <span class="abstract-full" style="display: none;">DaemonSec is an early-stage startup exploring machine learning (ML)-based security for Linux daemons, a critical yet often overlooked attack surface. While daemon security remains underexplored, conventional defenses struggle against adaptive threats and zero-day exploits. To assess the perspectives of IT professionals on ML-driven daemon protection, a systematic interview study based on semi-structured interviews was conducted with 22 professionals from industry and academia. The study evaluates adoption, feasibility, and trust in ML-based security solutions. While participants recognized the potential of ML for real-time anomaly detection, findings reveal skepticism toward full automation, limited security awareness among non-security roles, and concerns about patching delays creating attack windows. This paper presents the methods, key findings, and implications for advancing ML-driven daemon security in industry.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.7 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 4.7 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.6411
            </span>
            <a href="https://arxiv.org/abs/2407.08797" target="_blank" rel="noopener noreferrer">Deep Inverse Design for High-Level Synthesis</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Ping Chang, Tosiron Adegbija, Yuchao Liao, Claudio Talarico, Ao Li, Janet Roveda | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">High-level synthesis (HLS) has significantly advanced the automation of digital circuits design, yet the need for expertise and time in pragma tuning remains challenging. Existing solutions for the design space exploration (DSE) adopt either heuristic methods, lacking essential information for furth</span>
            
            <span class="abstract-full" style="display: none;">High-level synthesis (HLS) has significantly advanced the automation of digital circuits design, yet the need for expertise and time in pragma tuning remains challenging. Existing solutions for the design space exploration (DSE) adopt either heuristic methods, lacking essential information for further optimization potential, or predictive models, missing sufficient generalization due to the time-consuming nature of HLS and the exponential growth of the design space. To address these challenges, we propose Deep Inverse Design for HLS (DID4HLS), a novel approach that integrates graph neural networks and generative models. DID4HLS iteratively optimizes hardware designs aimed at compute-intensive algorithms by learning conditional distributions of design features from post-HLS data. Compared to four state-of-the-art DSE baselines, our method achieved an average improvement of 42.8% on average distance to reference set (ADRS) compared to the best-performing baselines across six benchmarks, while demonstrating high robustness and efficiency. The code is available at https://github.com/PingChang818/DID4HLS.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.2 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 4.5 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- GNN: 2.3 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Federated Learning: 1.7 -->
                
            <!-- Robotics: 1.3 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.6432
            </span>
            <a href="https://arxiv.org/abs/2504.08536" target="_blank" rel="noopener noreferrer">Explainability and Continual Learning meet Federated Learning at the Network Edge</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Thomas Tsouparopoulos, Iordanis Koutsopoulos | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">As edge devices become more capable and pervasive in wireless networks, there is growing interest in leveraging their collective compute power for distributed learning. However, optimizing learning at the network edge entails unique challenges, particularly when moving beyond conventional settings a</span>
            
            <span class="abstract-full" style="display: none;">As edge devices become more capable and pervasive in wireless networks, there is growing interest in leveraging their collective compute power for distributed learning. However, optimizing learning at the network edge entails unique challenges, particularly when moving beyond conventional settings and objectives. While Federated Learning (FL) has emerged as a key paradigm for distributed model training, critical challenges persist. First, existing approaches often overlook the trade-off between predictive accuracy and interpretability. Second, they struggle to integrate inherently explainable models such as decision trees because their non-differentiable structure makes them not amenable to backpropagation-based training algorithms. Lastly, they lack meaningful mechanisms for continual Machine Learning (ML) model adaptation through Continual Learning (CL) in resource-limited environments. In this paper, we pave the way for a set of novel optimization problems that emerge in distributed learning at the network edge with wirelessly interconnected edge devices, and we identify key challenges and future directions. Specifically, we discuss how Multi-objective optimization (MOO) can be used to address the trade-off between predictive accuracy and explainability when using complex predictive models. Next, we discuss the implications of integrating inherently explainable tree-based models into distributed learning settings. Finally, we investigate how CL strategies can be effectively combined with FL to support adaptive, lifelong learning when limited-size buffers are used to store past data for retraining. Our approach offers a cohesive set of tools for designing privacy-preserving, adaptive, and trustworthy ML solutions tailored to the demands of edge computing and intelligent services.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.4 -->
                
            <!-- Quantum Computing: 4.9 -->
                
            <!-- Medicine: 4.3 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- Reinforcement Learning: 2.3 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- Evolutionary Algorithms: 1.3 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.7089
            </span>
            <a href="https://arxiv.org/abs/2504.08437" target="_blank" rel="noopener noreferrer">Customizing Spider Silk: Generative Models with Mechanical Property Conditioning for Protein Engineering</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Neeru Dubey, Elin Karlsson, Miguel Angel Redondo, Johan Reimeg{\aa}rd, Anna Rising, Hedvig Kjellstr\"om | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">The remarkable mechanical properties of spider silk, including its tensile strength and extensibility, are primarily governed by the repetitive regions of the proteins that constitute the fiber, the major ampullate spidroins (MaSps). However, establishing correlations between mechanical characterist</span>
            
            <span class="abstract-full" style="display: none;">The remarkable mechanical properties of spider silk, including its tensile strength and extensibility, are primarily governed by the repetitive regions of the proteins that constitute the fiber, the major ampullate spidroins (MaSps). However, establishing correlations between mechanical characteristics and repeat sequences is challenging due to the intricate sequence-structure-function relationships of MaSps and the limited availability of annotated datasets. In this study, we present a novel computational framework for designing MaSp repeat sequences with customizable mechanical properties. To achieve this, we developed a lightweight GPT-based generative model by distilling the pre-trained ProtGPT2 protein language model. The distilled model was subjected to multilevel fine-tuning using curated subsets of the Spider Silkome dataset. Specifically, we adapt the model for MaSp repeat generation using 6,000 MaSp repeat sequences and further refine it with 572 repeats associated with experimentally determined fiber-level mechanical properties. Our model generates biologically plausible MaSp repeat regions tailored to specific mechanical properties while also predicting those properties for given sequences. Validation includes sequence-level analysis, assessing physicochemical attributes and expected distribution of key motifs as well as secondary structure compositions. A correlation study using BLAST on the Spider Silkome dataset and a test set of MaSp repeats with known mechanical properties further confirmed the predictive accuracy of the model. This framework advances the rational design of spider silk-inspired biomaterials, offering a versatile tool for engineering protein sequences with tailored mechanical attributes.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.0 -->
                
            <!-- Medicine: 5.4 -->
                
            <!-- Quantum Computing: 3.8 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Federated Learning: 1.7 -->
                
            <!-- Hardware: 1.4 -->
                
            <!-- SpikingNN: 1.3 -->
                
            <!-- Robotics: 1.3 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.71
            </span>
            <a href="https://arxiv.org/abs/2504.08484" target="_blank" rel="noopener noreferrer">Physics-informed data-driven control without persistence of excitation</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Martina Vanelli, Julien M. Hendrickx | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We show that data that is not sufficiently informative to allow for system re-identification can still provide meaningful information when combined with external or physical knowledge of the system, such as bounded system matrix norms. We then illustrate how this information can be leveraged for saf</span>
            
            <span class="abstract-full" style="display: none;">We show that data that is not sufficiently informative to allow for system re-identification can still provide meaningful information when combined with external or physical knowledge of the system, such as bounded system matrix norms. We then illustrate how this information can be leveraged for safety and energy minimization problems and to enhance predictions in unmodelled dynamics. This preliminary work outlines key ideas toward using limited data for effective control by integrating physical knowledge of the system and exploiting interpolation conditions.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.5 -->
                
            <!-- Medicine: 4.4 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- Math: 2.2 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Robotics: 1.8 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.7135
            </span>
            <a href="https://arxiv.org/abs/2411.02702" target="_blank" rel="noopener noreferrer">Corners in Quasirandom Groups via Sparse Mixing</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Michael Jaber, Shachar Lovett, Anthony Ostuni | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We improve the best known upper bounds on the density of corner-free sets over quasirandom groups from inverse poly-logarithmic to quasi-polynomial. We make similarly substantial improvements to the best known lower bounds on the communication complexity of a large class of permutation functions in </span>
            
            <span class="abstract-full" style="display: none;">We improve the best known upper bounds on the density of corner-free sets over quasirandom groups from inverse poly-logarithmic to quasi-polynomial. We make similarly substantial improvements to the best known lower bounds on the communication complexity of a large class of permutation functions in the 3-player Number-on-Forehead model. Underpinning both results is a general combinatorial theorem that extends the recent work of Kelley, Lovett, and Meka (STOC'24), itself a development of ideas from the breakthrough result of Kelley and Meka on three-term arithmetic progressions (FOCS'23).</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.0 -->
                
            <!-- Quantum Computing: 5.0 -->
                
            <!-- Medicine: 4.4 -->
                
            <!-- Math: 3.7 -->
                
            <!-- Networks: 2.9 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- Robotics: 1.3 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.7297
            </span>
            <a href="https://arxiv.org/abs/2503.04847" target="_blank" rel="noopener noreferrer">Role of Databases in GenAI Applications</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Santosh Bhupathi | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Generative AI (GenAI) is transforming industries by enabling intelligent content generation, automation, and decision-making. However, the effectiveness of GenAI applications depends significantly on efficient data storage, retrieval, and contextual augmentation. This paper explores the critical rol</span>
            
            <span class="abstract-full" style="display: none;">Generative AI (GenAI) is transforming industries by enabling intelligent content generation, automation, and decision-making. However, the effectiveness of GenAI applications depends significantly on efficient data storage, retrieval, and contextual augmentation. This paper explores the critical role of databases in GenAI workflows, emphasizing the importance of choosing the right database architecture to optimize performance, accuracy, and scalability. It categorizes database roles into conversational context (key-value/document databases), situational context (relational databases/data lakehouses), and semantic context (vector databases) each serving a distinct function in enriching AI-generated responses. Additionally, the paper highlights real-time query processing, vector search for semantic retrieval, and the impact of database selection on model efficiency and scalability. By leveraging a multi-database approach, GenAI applications can achieve more context-aware, personalized, and high-performing AI-driven solutions.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.9 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 4.9 -->
                
            <!-- Networks: 3.7 -->
                
            <!-- Math: 2.0 -->
                
            <!-- GNN: 1.8 -->
                
            <!-- Reinforcement Learning: 1.7 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- Evolutionary Algorithms: 1.3 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Robotics: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.7496
            </span>
            <a href="https://arxiv.org/abs/2504.08364" target="_blank" rel="noopener noreferrer">DRIP: DRop unImportant data Points -- Enhancing Machine Learning Efficiency with Grad-CAM-Based Real-Time Data Prioritization for On-Device Training</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Marcus R\"ub, Daniel Konegen, Axel Sikora, Daniel Mueller-Gritschneder | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Selecting data points for model training is critical in machine learning. Effective selection methods can reduce the labeling effort, optimize on-device training for embedded systems with limited data storage, and enhance the model performance. This paper introduces a novel algorithm that uses Grad-</span>
            
            <span class="abstract-full" style="display: none;">Selecting data points for model training is critical in machine learning. Effective selection methods can reduce the labeling effort, optimize on-device training for embedded systems with limited data storage, and enhance the model performance. This paper introduces a novel algorithm that uses Grad-CAM to make online decisions about retaining or discarding data points. Optimized for embedded devices, the algorithm computes a unique DRIP Score to quantify the importance of each data point. This enables dynamic decision-making on whether a data point should be stored for potential retraining or discarded without compromising model performance. Experimental evaluations on four benchmark datasets demonstrate that our approach can match or even surpass the accuracy of models trained on the entire dataset, all while achieving storage savings of up to 39\%. To our knowledge, this is the first algorithm that makes online decisions about data point retention without requiring access to the entire dataset.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.4 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 4.8 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- Reinforcement Learning: 2.2 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- SpikingNN: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.7597
            </span>
            <a href="https://arxiv.org/abs/2504.08659" target="_blank" rel="noopener noreferrer">BowelRCNN: Region-based Convolutional Neural Network System for Bowel Sound Auscultation</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Igor Matynia, Robert Nowak | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Sound events representing intestinal activity detection is a diagnostic tool with potential to identify gastrointestinal conditions. This article introduces BowelRCNN, a novel bowel sound detection system that uses audio recording, spectrogram analysys and region-based convolutional neural network (</span>
            
            <span class="abstract-full" style="display: none;">Sound events representing intestinal activity detection is a diagnostic tool with potential to identify gastrointestinal conditions. This article introduces BowelRCNN, a novel bowel sound detection system that uses audio recording, spectrogram analysys and region-based convolutional neural network (RCNN) architecture. The system was trained and validated on a real recording dataset gathered from 19 patients, comprising 60 minutes of prepared and annotated audio data. BowelRCNN achieved a classification accuracy of 96% and an F1 score of 71%. This research highlights the feasibility of using CNN architectures for bowel sound auscultation, achieving results comparable to those of recurrent-convolutional methods.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.8 -->
                
            <!-- Medicine: 5.6 -->
                
            <!-- Quantum Computing: 4.5 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.7602
            </span>
            <a href="https://arxiv.org/abs/2504.08593" target="_blank" rel="noopener noreferrer">Hands-On: Segmenting Individual Signs from Continuous Sequences</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Low Jian He, Harry Walsh, Ozge Mercanoglu Sincan, Richard Bowden | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">This work tackles the challenge of continuous sign language segmentation, a key task with huge implications for sign language translation and data annotation. We propose a transformer-based architecture that models the temporal dynamics of signing and frames segmentation as a sequence labeling probl</span>
            
            <span class="abstract-full" style="display: none;">This work tackles the challenge of continuous sign language segmentation, a key task with huge implications for sign language translation and data annotation. We propose a transformer-based architecture that models the temporal dynamics of signing and frames segmentation as a sequence labeling problem using the Begin-In-Out (BIO) tagging scheme. Our method leverages the HaMeR hand features, and is complemented with 3D Angles. Extensive experiments show that our model achieves state-of-the-art results on the DGS Corpus, while our features surpass prior benchmarks on BSLCorpus.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.5 -->
                
            <!-- Quantum Computing: 4.9 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- Evolutionary Algorithms: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.7638
            </span>
            <a href="https://arxiv.org/abs/2504.08660" target="_blank" rel="noopener noreferrer">Channel Estimation by Infinite Width Convolutional Networks</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Mohammed Mallik, Guillaume Villemaud | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">In wireless communications, estimation of channels in OFDM systems spans frequency and time, which relies on sparse collections of pilot data, posing an ill-posed inverse problem. Moreover, deep learning estimators require large amounts of training data, computational resources, and true channels to</span>
            
            <span class="abstract-full" style="display: none;">In wireless communications, estimation of channels in OFDM systems spans frequency and time, which relies on sparse collections of pilot data, posing an ill-posed inverse problem. Moreover, deep learning estimators require large amounts of training data, computational resources, and true channels to produce accurate channel estimates, which are not realistic. To address this, a convolutional neural tangent kernel (CNTK) is derived from an infinitely wide convolutional network whose training dynamics can be expressed by a closed-form equation. This CNTK is used to impute the target matrix and estimate the missing channel response using only the known values available at pilot locations. This is a promising solution for channel estimation that does not require a large training set. Numerical results on realistic channel datasets demonstrate that our strategy accurately estimates the channels without a large dataset and significantly outperforms deep learning methods in terms of speed, accuracy, and computational resources.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.8 -->
                
            <!-- Medicine: 5.5 -->
                
            <!-- Quantum Computing: 4.7 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- Reinforcement Learning: 2.3 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Evolutionary Algorithms: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.7787
            </span>
            <a href="https://arxiv.org/abs/2504.08213" target="_blank" rel="noopener noreferrer">Big Meaning: Qualitative Analysis on Large Bodies of Data Using AI</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Samuel Flanders, Melati Nungsari, Mark Cheong Wing Loong | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">This study introduces a framework that leverages AI-generated descriptive codes to indicate a text's fecundity--the density of unique human-generated codes--in thematic analysis. Rather than replacing human interpretation, AI-generated codes guide the selection of texts likely to yield richer qualit</span>
            
            <span class="abstract-full" style="display: none;">This study introduces a framework that leverages AI-generated descriptive codes to indicate a text's fecundity--the density of unique human-generated codes--in thematic analysis. Rather than replacing human interpretation, AI-generated codes guide the selection of texts likely to yield richer qualitative insights. Using a dataset of 2,530 Malaysian news articles on refugee attitudes, we compare AI-selected documents to randomly chosen ones by having three human coders independently derive codes. The results demonstrate that AI-selected texts exhibit approximately twice the fecundity. Our findings support the use of AI-generated codes as an effective proxy for identifying documents with a high potential for meaning-making in thematic analysis.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.2 -->
                
            <!-- Medicine: 5.0 -->
                
            <!-- Quantum Computing: 4.9 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.7878
            </span>
            <a href="https://arxiv.org/abs/2504.08456" target="_blank" rel="noopener noreferrer">Generalization Bounds in Hybrid Quantum-Classical Machine Learning Models</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Tongyan Wu, Amine Bentellis, Alona Sakhnenko, Jeanette Miriam Lorenz | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Hybrid classical-quantum models aim to harness the strengths of both quantum computing and classical machine learning, but their practical potential remains poorly understood. In this work, we develop a unified mathematical framework for analyzing generalization in hybrid models, offering insight in</span>
            
            <span class="abstract-full" style="display: none;">Hybrid classical-quantum models aim to harness the strengths of both quantum computing and classical machine learning, but their practical potential remains poorly understood. In this work, we develop a unified mathematical framework for analyzing generalization in hybrid models, offering insight into how these systems learn from data. We establish a novel generalization bound of the form $O\big( \sqrt{\frac{T\log{T}}{N}} + \frac{\alpha}{\sqrt{N}}\big)$ for $N$ training data points, $T$ trainable quantum gates, and bounded fully-connected layers $||F|| \leq \alpha$. This bound decomposes cleanly into quantum and classical contributions, extending prior work on both components and clarifying their interaction. We apply our results to the quantum-classical convolutional neural network (QCCNN), an architecture that integrates quantum convolutional layers with classical processing. Alongside the bound, we highlight conceptual limitations of applying classical statistical learning theory in the hybrid setting and suggest promising directions for future theoretical work.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.7 -->
                
            <!-- Quantum Computing: 5.2 -->
                
            <!-- Medicine: 4.4 -->
                
            <!-- Networks: 3.0 -->
                
            <!-- Reinforcement Learning: 2.1 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Robotics: 1.5 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- Pathfinding: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.8061
            </span>
            <a href="https://arxiv.org/abs/2504.08182" target="_blank" rel="noopener noreferrer">Particle Hit Clustering and Identification Using Point Set Transformers in Liquid Argon Time Projection Chambers</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Edgar E. Robles, Alejando Yankelevich, Wenjie Wu, Jianming Bian, Pierre Baldi | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Liquid argon time projection chambers are often used in neutrino physics and dark-matter searches because of their high spatial resolution. The images generated by these detectors are extremely sparse, as the energy values detected by most of the detector are equal to 0, meaning that despite their h</span>
            
            <span class="abstract-full" style="display: none;">Liquid argon time projection chambers are often used in neutrino physics and dark-matter searches because of their high spatial resolution. The images generated by these detectors are extremely sparse, as the energy values detected by most of the detector are equal to 0, meaning that despite their high resolution, most of the detector is unused in a particular interaction. Instead of representing all of the empty detections, the interaction is usually stored as a sparse matrix, a list of detection locations paired with their energy values. Traditional machine learning methods that have been applied to particle reconstruction such as convolutional neural networks (CNNs), however, cannot operate over data stored in this way and therefore must have the matrix fully instantiated as a dense matrix. Operating on dense matrices requires a lot of memory and computation time, in contrast to directly operating on the sparse matrix. We propose a machine learning model using a point set neural network that operates over a sparse matrix, greatly improving both processing speed and accuracy over methods that instantiate the dense matrix, as well as over other methods that operate over sparse matrices. Compared to competing state-of-the-art methods, our method improves classification performance by 14%, segmentation performance by more than 22%, while taking 80% less time and using 66% less memory. Compared to state-of-the-art CNN methods, our method improves classification performance by more than 86%, segmentation performance by more than 71%, while reducing runtime by 91% and reducing memory usage by 61%.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.2 -->
                
            <!-- Medicine: 4.5 -->
                
            <!-- Quantum Computing: 3.7 -->
                
            <!-- Networks: 3.1 -->
                
            <!-- Robotics: 2.2 -->
                
            <!-- Math: 2.0 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- Blockchain: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.8431
            </span>
            <a href="https://arxiv.org/abs/2503.10790" target="_blank" rel="noopener noreferrer">Quantum Error Detection For Early Term Fault-Tolerant Quantum Algorithms</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Tom Ginsberg, Vyom Patel | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Quantum error detection (QED) offers a promising pathway to fault tolerance in near-term quantum devices by balancing error suppression with minimal resource overhead. However, its practical utility hinges on optimizing design parameters-such as syndrome measurement frequency-to avoid diminishing re</span>
            
            <span class="abstract-full" style="display: none;">Quantum error detection (QED) offers a promising pathway to fault tolerance in near-term quantum devices by balancing error suppression with minimal resource overhead. However, its practical utility hinges on optimizing design parameters-such as syndrome measurement frequency-to avoid diminishing returns from detection overhead. In this work, we present a comprehensive framework for fault-tolerant compilation and simulation of quantum algorithms using [[n, n-2, 2]] codes, which enable low-qubit-overhead error detection and a simple nearly fault-tolerant universal set of operations. We demonstrate and analyze our pipeline with a purely statistical interpretation and through the implementation of Grover's search algorithm. Our results are used to answer the question is quantum error detection a worthwhile avenue for early-term fault tolerance, and if so how can we get the most out of it? Simulations under the circuit-level noise model reveal that finding optimal syndrome schedules improves algorithm success probabilities by an average of 6.7x but eventual statistical limits from post-selection in noisy/resource-limited regimes constrain scalability. Furthermore, we propose a simple data-driven approach to predict fault tolerant compilation parameters, such as optimal syndrome schedules, and expected fault tolerant performance gains based on circuit and noise features. These results provide actionable guidelines for implementing QED in early-term quantum experiments and underscore its role as a pragmatic, constant-overhead error mitigation layer for shallow algorithms. To aid in further research, we release all simulation data computed for this work and provide an experimental QED compiler at https://codeqraft.xyz/qed.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.7 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 4.4 -->
                
            <!-- Networks: 3.0 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Math: 1.6 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- T2I: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Hardware: 1.2 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.8434
            </span>
            <a href="https://arxiv.org/abs/2504.07989" target="_blank" rel="noopener noreferrer">Regional Tiny Stories: Using Small Models to Compare Language Learning and Tokenizer Performance</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Nirvan Patil, Malhar Abhay Inamdar, Agnivo Gosai, Guruprasad Pathak, Anish Joshi, Aryan Sagavekar, Anish Joshirao, Raj Dandekar, Rajat Dandekar, Sreedath Panat | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Small Language Models (SLMs) offer efficient alternatives to LLMs for specific domains. The 2023 TinyStories study developed an English dataset that allows SLMs with 1 to 10 million parameters to produce coherent outputs. Our research expands this framework by translating the original dataset into I</span>
            
            <span class="abstract-full" style="display: none;">Small Language Models (SLMs) offer efficient alternatives to LLMs for specific domains. The 2023 TinyStories study developed an English dataset that allows SLMs with 1 to 10 million parameters to produce coherent outputs. Our research expands this framework by translating the original dataset into Indian languages and creating synthetic data using LLMs. We focus on Hindi, Marathi, and Bengali, evaluating SLMs for regional language processing and understanding linguistic complexity. We show that SLMs efficiently process regional languages with significantly fewer parameters than LLMs, providing a complementary framework for ``inference based evaluation" of tokenization strategies and linguistic complexity. Our analysis shows that language-specific tokenizers outperform general-purpose ones for Indian languages. Empirical validations, supported by information-theoretic and morphological analyses, provides fundamental understanding behind the better performance of Hindi models over Marathi and Bengali. Additionally, we show that synthetic datasets outperform translated content for training SLMs. Correlation analyses reveal cross-linguistic patterns and language-specific relationships between creativity, grammatical precision, and narrative completeness. These findings advance both the practical application of SLMs to underserved languages and our theoretical understanding of neural language development.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.5 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.6 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.8529
            </span>
            <a href="https://arxiv.org/abs/2503.16469" target="_blank" rel="noopener noreferrer">Enhancing Human-Robot Interaction in Healthcare: A Study on Nonverbal Communication Cues and Trust Dynamics with NAO Robot Caregivers</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: S M Taslim Uddin Raju | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">As the population of older adults increases, so will the need for both human and robot care providers. While traditional practices involve hiring human caregivers to serve meals and attend to basic needs, older adults often require continuous companionship and health monitoring. However, hiring huma</span>
            
            <span class="abstract-full" style="display: none;">As the population of older adults increases, so will the need for both human and robot care providers. While traditional practices involve hiring human caregivers to serve meals and attend to basic needs, older adults often require continuous companionship and health monitoring. However, hiring human caregivers for this job costs a lot of money. However, using a robot like Nao could be cheaper and still helpful. This study explores the integration of humanoid robots, particularly Nao, in health monitoring and caregiving for older adults. Using a mixed-methods approach with a within-subject factorial design, we investigated the effectiveness of nonverbal communication modalities, including touch, gestures, and LED patterns, in enhancing human-robot interactions. Our results indicate that Nao's touch-based health monitoring was well-received by participants, with positive ratings across various dimensions. LED patterns were perceived as more effective and accurate compared to hand and head gestures. Moreover, longer interactions were associated with higher trust levels and perceived empathy, highlighting the importance of prolonged engagement in fostering trust in human-robot interactions. Despite limitations, our study contributes valuable insights into the potential of humanoid robots to improve health monitoring and caregiving for older adults.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.0 -->
                
            <!-- Medicine: 5.5 -->
                
            <!-- Quantum Computing: 4.8 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Reinforcement Learning: 1.7 -->
                
            <!-- Federated Learning: 1.3 -->
                
            <!-- Robotics: 1.3 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- Pathfinding: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.8815
            </span>
            <a href="https://arxiv.org/abs/2504.08150" target="_blank" rel="noopener noreferrer">Beyond Feature Importance: Feature Interactions in Predicting Post-Stroke Rigidity with Graph Explainable AI</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Jiawei Xu, Yonggeon Lee, Anthony Elkommos Youssef, Eunjin Yun, Tinglin Huang, Tianjian Guo, Hamidreza Saber, Rex Ying, Ying Ding | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">This study addresses the challenge of predicting post-stroke rigidity by emphasizing feature interactions through graph-based explainable AI. Post-stroke rigidity, characterized by increased muscle tone and stiffness, significantly affects survivors' mobility and quality of life. Despite its prevale</span>
            
            <span class="abstract-full" style="display: none;">This study addresses the challenge of predicting post-stroke rigidity by emphasizing feature interactions through graph-based explainable AI. Post-stroke rigidity, characterized by increased muscle tone and stiffness, significantly affects survivors' mobility and quality of life. Despite its prevalence, early prediction remains limited, delaying intervention. We analyze 519K stroke hospitalization records from the Healthcare Cost and Utilization Project dataset, where 43% of patients exhibited rigidity. We compare traditional approaches such as Logistic Regression, XGBoost, and Transformer with graph-based models like Graphormer and Graph Attention Network. These graph models inherently capture feature interactions and incorporate intrinsic or post-hoc explainability. Our results show that graph-based methods outperform others (AUROC 0.75), identifying key predictors such as NIH Stroke Scale and APR-DRG mortality risk scores. They also uncover interactions missed by conventional models. This research provides a novel application of graph-based XAI in stroke prognosis, with potential to guide early identification and personalized rehabilitation strategies.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.2 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 4.4 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -4.9169
            </span>
            <a href="https://arxiv.org/abs/2504.08489" target="_blank" rel="noopener noreferrer">Statistically guided deep learning</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Michael Kohler, Adam Krzyzak | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We present a theoretically well-founded deep learning algorithm for nonparametric regression. It uses over-parametrized deep neural networks with logistic activation function, which are fitted to the given data via gradient descent. We propose a special topology of these networks, a special random i</span>
            
            <span class="abstract-full" style="display: none;">We present a theoretically well-founded deep learning algorithm for nonparametric regression. It uses over-parametrized deep neural networks with logistic activation function, which are fitted to the given data via gradient descent. We propose a special topology of these networks, a special random initialization of the weights, and a data-dependent choice of the learning rate and the number of gradient descent steps. We prove a theoretical bound on the expected $L_2$ error of this estimate, and illustrate its finite sample size performance by applying it to simulated data. Our results show that a theoretical analysis of deep learning which takes into account simultaneously optimization, generalization and approximation can result in a new deep learning estimate which has an improved finite sample performance.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 5.6 -->
                
            <!-- Medicine: 5.1 -->
                
            <!-- Quantum Computing: 3.5 -->
                
            <!-- Networks: 3.5 -->
                
            <!-- Reinforcement Learning: 2.5 -->
                
            <!-- Math: 2.1 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Robotics: 1.8 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Hardware: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -5.0825
            </span>
            <a href="https://arxiv.org/abs/2504.08623" target="_blank" rel="noopener noreferrer">Enterprise-Grade Security for the Model Context Protocol (MCP): Frameworks and Mitigation Strategies</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Vineeth Sai Narajala, Idan Habler | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">The Model Context Protocol (MCP), introduced by Anthropic, provides a standardized framework for artificial intelligence (AI) systems to interact with external data sources and tools in real-time. While MCP offers significant advantages for AI integration and capability extension, it introduces nove</span>
            
            <span class="abstract-full" style="display: none;">The Model Context Protocol (MCP), introduced by Anthropic, provides a standardized framework for artificial intelligence (AI) systems to interact with external data sources and tools in real-time. While MCP offers significant advantages for AI integration and capability extension, it introduces novel security challenges that demand rigorous analysis and mitigation. This paper builds upon foundational research into MCP architecture and preliminary security assessments to deliver enterprise-grade mitigation frameworks and detailed technical implementation strategies. Through systematic threat modeling and analysis of MCP implementations and analysis of potential attack vectors, including sophisticated threats like tool poisoning, we present actionable security patterns tailored for MCP implementers and adopters. The primary contribution of this research lies in translating theoretical security concerns into a practical, implementable framework with actionable controls, thereby providing essential guidance for the secure enterprise adoption and governance of integrated AI systems.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.1 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Robotics: 1.8 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- SpikingNN: 1.0 -->
                
            <!-- Pathfinding: 1.0 -->
                
            <!-- Blockchain: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -5.0908
            </span>
            <a href="https://arxiv.org/abs/2504.08072" target="_blank" rel="noopener noreferrer">X-DECODE: EXtreme Deblurring with Curriculum Optimization and Domain Equalization</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Sushant Gautam, Jingdao Chen | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Restoring severely blurred images remains a significant challenge in computer vision, impacting applications in autonomous driving, medical imaging, and photography. This paper introduces a novel training strategy based on curriculum learning to improve the robustness of deep learning models for ext</span>
            
            <span class="abstract-full" style="display: none;">Restoring severely blurred images remains a significant challenge in computer vision, impacting applications in autonomous driving, medical imaging, and photography. This paper introduces a novel training strategy based on curriculum learning to improve the robustness of deep learning models for extreme image deblurring. Unlike conventional approaches that train on only low to moderate blur levels, our method progressively increases the difficulty by introducing images with higher blur severity over time, allowing the model to adapt incrementally. Additionally, we integrate perceptual and hinge loss during training to enhance fine detail restoration and improve training stability. We experimented with various curriculum learning strategies and explored the impact of the train-test domain gap on the deblurring performance. Experimental results on the Extreme-GoPro dataset showed that our method outperforms the next best method by 14% in SSIM, whereas experiments on the Extreme-KITTI dataset showed that our method outperforms the next best by 18% in SSIM. Ablation studies showed that a linear curriculum progression outperforms step-wise, sigmoid, and exponential progressions, while hyperparameter settings such as the training blur percentage and loss function formulation all play important roles in addressing extreme blur artifacts. Datasets and code are available at https://github.com/RAPTOR-MSSTATE/XDECODE</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 6.5 -->
                
            <!-- Medicine: 4.6 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Robotics: 1.9 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Blockchain: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -5.1605
            </span>
            <a href="https://arxiv.org/abs/2412.04332" target="_blank" rel="noopener noreferrer">Liquid: Language Models are Scalable and Unified Multi-modal Generators</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Junfeng Wu, Yi Jiang, Chuofan Ma, Yuliang Liu, Hengshuang Zhao, Zehuan Yuan, Song Bai, Xiang Bai | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">We present Liquid, an auto-regressive generation paradigm that seamlessly integrates visual comprehension and generation by tokenizing images into discrete codes and learning these code embeddings alongside text tokens within a shared feature space for both vision and language. Unlike previous multi</span>
            
            <span class="abstract-full" style="display: none;">We present Liquid, an auto-regressive generation paradigm that seamlessly integrates visual comprehension and generation by tokenizing images into discrete codes and learning these code embeddings alongside text tokens within a shared feature space for both vision and language. Unlike previous multimodal large language model (MLLM), Liquid achieves this integration using a single large language model (LLM), eliminating the need for external pretrained visual embeddings such as CLIP. For the first time, Liquid uncovers a scaling law that performance drop unavoidably brought by the unified training of visual and language tasks diminishes as the model size increases. Furthermore, the unified token space enables visual generation and comprehension tasks to mutually enhance each other, effectively removing the typical interference seen in earlier models. We show that existing LLMs can serve as strong foundations for Liquid, saving 100x in training costs while outperforming Chameleon in multimodal capabilities and maintaining language performance comparable to mainstream LLMs like LLAMA2. Liquid also outperforms models like SD v2.1 and SD-XL (FID of 5.47 on MJHQ-30K), excelling in both vision-language and text-only tasks. This work demonstrates that LLMs such as Qwen2.5 and GEMMA2 are powerful multimodal generators, offering a scalable solution for enhancing both vision-language understanding and generation. The code and models will be released at https://github.com/FoundationVision/Liquid.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 9.2 -->
                
            <!-- Medicine: 4.7 -->
                
            <!-- Quantum Computing: 4.1 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Robotics: 2.0 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Blockchain: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -5.164
            </span>
            <a href="https://arxiv.org/abs/2504.08554" target="_blank" rel="noopener noreferrer">Boosting-inspired online learning with transfer for railway maintenance</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Diogo Risca, Afonso Louren\c{c}o, Goreti Marreiros | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">The integration of advanced sensor technologies with deep learning algorithms has revolutionized fault diagnosis in railway systems, particularly at the wheel-track interface. Although numerous models have been proposed to detect irregularities such as wheel out-of-roundness, they often fall short i</span>
            
            <span class="abstract-full" style="display: none;">The integration of advanced sensor technologies with deep learning algorithms has revolutionized fault diagnosis in railway systems, particularly at the wheel-track interface. Although numerous models have been proposed to detect irregularities such as wheel out-of-roundness, they often fall short in real-world applications due to the dynamic and nonstationary nature of railway operations. This paper introduces BOLT-RM (Boosting-inspired Online Learning with Transfer for Railway Maintenance), a model designed to address these challenges using continual learning for predictive maintenance. By allowing the model to continuously learn and adapt as new data become available, BOLT-RM overcomes the issue of catastrophic forgetting that often plagues traditional models. It retains past knowledge while improving predictive accuracy with each new learning episode, using a boosting-like knowledge sharing mechanism to adapt to evolving operational conditions such as changes in speed, load, and track irregularities. The methodology is validated through comprehensive multi-domain simulations of train-track dynamic interactions, which capture realistic railway operating conditions. The proposed BOLT-RM model demonstrates significant improvements in identifying wheel anomalies, establishing a reliable sequence for maintenance interventions.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.7 -->
                
            <!-- Medicine: 5.1 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Reinforcement Learning: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Robotics: 1.7 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- Hardware: 1.3 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Blockchain: 1.0 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -5.172
            </span>
            <a href="https://arxiv.org/abs/2504.08418" target="_blank" rel="noopener noreferrer">seeBias: A Comprehensive Tool for Assessing and Visualizing AI Fairness</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Yilin Ning, Yian Ma, Mingxuan Liu, Xin Li, Nan Liu | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Fairness in artificial intelligence (AI) prediction models is increasingly emphasized to support responsible adoption in high-stakes domains such as health care and criminal justice. Guidelines and implementation frameworks highlight the importance of both predictive accuracy and equitable outcomes.</span>
            
            <span class="abstract-full" style="display: none;">Fairness in artificial intelligence (AI) prediction models is increasingly emphasized to support responsible adoption in high-stakes domains such as health care and criminal justice. Guidelines and implementation frameworks highlight the importance of both predictive accuracy and equitable outcomes. However, current fairness toolkits often evaluate classification performance disparities in isolation, with limited attention to other critical aspects such as calibration. To address these gaps, we present seeBias, an R package for comprehensive evaluation of model fairness and predictive performance. seeBias offers an integrated evaluation across classification, calibration, and other performance domains, providing a more complete view of model behavior. It includes customizable visualizations to support transparent reporting and responsible AI implementation. Using public datasets from criminal justice and healthcare, we demonstrate how seeBias supports fairness evaluations, and uncovers disparities that conventional fairness metrics may overlook. The R package is available on GitHub, and a Python version is under development.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.2 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 4.2 -->
                
            <!-- Networks: 3.4 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Robotics: 1.8 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- Blockchain: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -5.3055
            </span>
            <a href="https://arxiv.org/abs/2504.08457" target="_blank" rel="noopener noreferrer">A Comparative Study of Recommender Systems under Big Data Constraints</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Arimondo Scrivano | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Recommender Systems (RS) have become essential tools in a wide range of digital services, from e-commerce and streaming platforms to news and social media. As the volume of user-item interactions grows exponentially, especially in Big Data environments, selecting the most appropriate RS model become</span>
            
            <span class="abstract-full" style="display: none;">Recommender Systems (RS) have become essential tools in a wide range of digital services, from e-commerce and streaming platforms to news and social media. As the volume of user-item interactions grows exponentially, especially in Big Data environments, selecting the most appropriate RS model becomes a critical task. This paper presents a comparative study of several state-of-the-art recommender algorithms, including EASE-R, SLIM, SLIM with ElasticNet regularization, Matrix Factorization (FunkSVD and ALS), P3Alpha, and RP3Beta. We evaluate these models according to key criteria such as scalability, computational complexity, predictive accuracy, and interpretability. The analysis considers both their theoretical underpinnings and practical applicability in large-scale scenarios. Our results highlight that while models like SLIM and SLIM-ElasticNet offer high accuracy and interpretability, they suffer from high computational costs, making them less suitable for real-time applications. In contrast, algorithms such as EASE-R and RP3Beta achieve a favorable balance between performance and scalability, proving more effective in large-scale environments. This study aims to provide guidelines for selecting the most appropriate recommender approach based on specific Big Data constraints and system requirements.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.3 -->
                
            <!-- Quantum Computing: 4.6 -->
                
            <!-- Medicine: 4.4 -->
                
            <!-- Networks: 3.8 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Robotics: 1.9 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Math: 1.7 -->
                
            <!-- Federated Learning: 1.5 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.1 -->
                
            <!-- Blockchain: 1.1 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -5.4075
            </span>
            <a href="https://arxiv.org/abs/2504.08281" target="_blank" rel="noopener noreferrer">ELSA: A Style Aligned Dataset for Emotionally Intelligent Language Generation</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Vishal Gandhi, Sagar Gandhi | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Advancements in emotion aware language processing increasingly shape vital NLP applications ranging from conversational AI and affective computing to computational psychology and creative content generation. Existing emotion datasets either lack emotional granularity or fail to capture necessary sty</span>
            
            <span class="abstract-full" style="display: none;">Advancements in emotion aware language processing increasingly shape vital NLP applications ranging from conversational AI and affective computing to computational psychology and creative content generation. Existing emotion datasets either lack emotional granularity or fail to capture necessary stylistic diversity, limiting the advancement of effective emotion conditioned text generation systems. Seeking to bridge this crucial gap between granularity and style diversity, this paper introduces a novel systematically constructed dataset named ELSA Emotion and Language Style Alignment Dataset leveraging fine grained emotion taxonomies adapted from existing sources such as dair ai emotion dataset and GoEmotions taxonomy. This dataset comprises multiple emotionally nuanced variations of original sentences regenerated across distinct contextual styles such as conversational, formal, poetic, and narrative, using advanced Large Language Models LLMs. Rigorous computational evaluation using metrics such as perplexity, embedding variance, readability, lexical diversity, and semantic coherence measures validates the datasets emotional authenticity, linguistic fluency, and textual diversity. Comprehensive metric analyses affirm its potential to support deeper explorations into emotion conditioned style adaptive text generation. By enabling precision tuned emotionally nuanced language modeling, our dataset creates fertile ground for research on fine grained emotional control, prompt driven explanation, interpretability, and style adaptive expressive language generation with LLMs.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 8.0 -->
                
            <!-- Medicine: 4.5 -->
                
            <!-- Quantum Computing: 4.0 -->
                
            <!-- Networks: 3.2 -->
                
            <!-- GNN: 2.0 -->
                
            <!-- Robotics: 1.9 -->
                
            <!-- Math: 1.8 -->
                
            <!-- Reinforcement Learning: 1.7 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- Evolutionary Algorithms: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Blockchain: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -5.4093
            </span>
            <a href="https://arxiv.org/abs/2504.08152" target="_blank" rel="noopener noreferrer">Dynamics of collective minds in online communities</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Seungwoong Ha, Henrik Olsson, Kresimir Jaksic, Max Pellert, Mirta Galesic | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">How communities respond to diverse societal challenges, from economic crises to political upheavals, is shaped by their collective minds - shared representations of ongoing events and current topics. In turn, collective minds are shaped by a continuous stream of influences, amplified by the rapid ri</span>
            
            <span class="abstract-full" style="display: none;">How communities respond to diverse societal challenges, from economic crises to political upheavals, is shaped by their collective minds - shared representations of ongoing events and current topics. In turn, collective minds are shaped by a continuous stream of influences, amplified by the rapid rise of online platforms. Online communities must understand these influences to maintain healthy discourse and avoid being manipulated, but understanding is hindered by limited observations and the inability to conduct counterfactual experiments. Here, we show how collective minds in online news communities can be influenced by different editorial agenda-setting practices and aspects of community dynamics, and how these influences can be reversed. We develop a computational model of collective minds, calibrated and validated with data from 400 million comments across five U.S. online news platforms and a large-scale survey. The model enables us to describe and experiment with a variety of influences and derive quantitative insights into their magnitude and persistence in different communities. We find that some editorial influences can be reversed relatively rapidly, but others, such as amplification and reframing of certain topics, as well as community influences such as trolling and counterspeech, tend to persist and durably change the collective mind. These findings illuminate ways collective minds can be manipulated and pathways for communities to maintain healthy and authentic collective discourse amid ongoing societal challenges.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- LLMs: 7.1 -->
                
            <!-- Medicine: 4.9 -->
                
            <!-- Quantum Computing: 3.9 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- Robotics: 2.1 -->
                
            <!-- GNN: 1.9 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Reinforcement Learning: 1.8 -->
                
            <!-- Federated Learning: 1.4 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Evolutionary Algorithms: 1.1 -->
                
            <!-- SpikingNN: 1.1 -->
                
            <!-- Blockchain: 1.0 -->
                
            
        </div>
    </div>
    
    <div class="paper">
        <div class="paper-title">
            <span class="interestingness-score interestingness-negative">
                -5.5124
            </span>
            <a href="https://arxiv.org/abs/2504.08310" target="_blank" rel="noopener noreferrer">DeQompile: quantum circuit decompilation using genetic programming for explainable quantum architecture search</a>
            <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
        </div>
        <div class="paper-meta">
            Authors: Shubing Xie, Aritra Sarkar, Sebastian Feld | Date: 2025-04-14
        </div>
        <div class="paper-abstract">
            <span class="abstract-short">Demonstrating quantum advantage using conventional quantum algorithms remains challenging on current noisy gate-based quantum computers. Automated quantum circuit synthesis via quantum machine learning has emerged as a promising solution, employing trainable parametric quantum circuits to alleviate </span>
            
            <span class="abstract-full" style="display: none;">Demonstrating quantum advantage using conventional quantum algorithms remains challenging on current noisy gate-based quantum computers. Automated quantum circuit synthesis via quantum machine learning has emerged as a promising solution, employing trainable parametric quantum circuits to alleviate this. The circuit ansatz in these solutions is often designed through reinforcement learning-based quantum architecture search when the domain knowledge of the problem and hardware are not effective. However, the interpretability of these synthesized circuits remains a significant bottleneck, limiting their scalability and applicability across diverse problem domains.</span>
            <span class="more-link" onclick="toggleAbstract(this)">... more</span>
            
        </div>
        <div class="paper-tags"><!-- Quantum Computing: 6.3 -->
                
            <!-- LLMs: 6.2 -->
                
            <!-- Medicine: 4.8 -->
                
            <!-- Networks: 3.3 -->
                
            <!-- GNN: 2.1 -->
                
            <!-- Reinforcement Learning: 2.0 -->
                
            <!-- Math: 1.9 -->
                
            <!-- Evolutionary Algorithms: 1.6 -->
                
            <!-- Federated Learning: 1.6 -->
                
            <!-- Robotics: 1.4 -->
                
            <!-- Hardware: 1.2 -->
                
            <!-- SpikingNN: 1.2 -->
                
            <!-- T2I: 1.1 -->
                
            <!-- Pathfinding: 1.0 -->
                
            
        </div>
    </div>
    
    
    <div id="jsonPopup" class="json-popup">
        <pre id="jsonContent"></pre>
        <button onclick="copyJson()">Copy to Clipboard</button>
        <button onclick="closePopup()">Close</button>
    </div>

    <script>
        function extractPaperData(paperElement) {
            const titleElement = paperElement.querySelector('.paper-title a');
            const metaElement = paperElement.querySelector('.paper-meta');
            const abstractElement = paperElement.querySelector('.paper-abstract');
            const tagsElement = paperElement.querySelector('.paper-tags');
            
            const authorsText = metaElement.textContent.split('|')[0].replace('Authors:', '').trim();
            const dateText = metaElement.textContent.split('|')[1].replace('Date:', '').trim();
            
            const paperData = {
                title: titleElement.textContent,
                url: titleElement.href,
                authors: authorsText.split(',').map(author => author.trim()),
                created: dateText,
                abstract: abstractElement.querySelector('.abstract-full').textContent
            };
            
            return paperData;
        }

        function showJson(paperElement) {
            const popup = document.getElementById('jsonPopup');
            const content = document.getElementById('jsonContent');
            const paperData = extractPaperData(paperElement);
            content.textContent = JSON.stringify(paperData, null, null);
            popup.style.display = 'block';
            document.addEventListener('click', function closePopupOnClick(event) {
                if (!popup.contains(event.target)) {
                    popup.style.display = 'none';
                    document.removeEventListener('click', closePopupOnClick);
                }
            });
        }
        function toggleAbstract(element) {
            const abstract = element.parentElement;
            const short = abstract.querySelector('.abstract-short');
            const full = abstract.querySelector('.abstract-full');
            const lowConfidenceTags = abstract.parentElement.querySelectorAll('.tag-badge.low-confidence');
            
            if (element.textContent === '... more') {
                short.style.display = 'none';
                full.style.display = 'inline';
                element.textContent = ' less';
                lowConfidenceTags.forEach(tag => tag.style.display = 'inline-block');
            } else {
                short.style.display = 'inline';
                full.style.display = 'none';
                element.textContent = '... more';
                lowConfidenceTags.forEach(tag => tag.style.display = 'none');
            }
        }

        function closePopup() {
            document.getElementById('jsonPopup').style.display = 'none';
        }

        function copyJson() {
            const content = document.getElementById('jsonContent').textContent;
            navigator.clipboard.writeText(content).catch(() => {
                // If clipboard API is not available, just show the popup
                alert('Could not copy to clipboard. JSON is displayed in the popup.');
            });
        }

        // Close popup when clicking outside
        window.onclick = function(event) {
            const popup = document.getElementById('jsonPopup');
            if (event.target === popup) {
                popup.style.display = 'none';
            }
        }
    </script>
</body>
</html> 