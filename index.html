<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv Frontpage</title>
    <style>
        body {
            font-family: sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
        }
        .paper {
            margin-bottom: 30px;
            margin-top: 30px;
            padding: 20px;
            border: 1px solid #ddd;
            border-radius: 5px;
        }
        .paper-title {
            font-size: 1.2em;
            font-weight: bold;
            margin-bottom: 10px;
        }
        .paper-meta {
            color: #666;
            font-size: 0.9em;
            margin-bottom: 10px;
        }
        .paper-abstract {
            margin-bottom: 10px;
        }
        .abstract-short {
            display: inline;
        }
        .abstract-full {
            display: none;
        }
        .more-link {
            color: blue;
            cursor: pointer;
            text-decoration: underline;
        }
        .tag-badge {
            display: inline-block;
            padding: 3px 8px;
            margin-right: 5px;
            margin-bottom: 5px;
            border-radius: 3px;
            font-size: 0.8em;
            color: white;
        }
        .tag-badge.high-confidence {
            opacity: 1;
        }
        .tag-badge.low-confidence {
            opacity: 0.6;
            display: none;
        }
        .interestingness-score {
            display: inline-block;
            padding: 3px 8px;
            margin-right: 10px;
            color: white;
            border-radius: 3px;
            font-weight: bold;
        }
        .interestingness-positive {
            background-color: #4CAF50;
        }
        .interestingness-negative {
            background-color: #f44336;
        }
        .interestingness-neutral {
            background-color: #9e9e9e;
        }
        .last-updated {
            text-align: right;
            color: #666;
            font-size: 0.9em;
            margin-top: 20px;
            margin-bottom: 20px;
        }
        .intro {
            text-align: center;
            max-width: 60em;
            margin: 0 auto;
            color: #888;
        }
        .copy-icon {
            display: inline-block;
            width: 16px;
            height: 16px;
            cursor: pointer;
            margin-left: 5px;
            opacity: 0.5;
        }
        .copy-icon:hover {
            opacity: 1;
        }
        .json-popup {
            display: none;
            position: fixed;
            top: 20px;
            right: 20px;
            background: white;
            padding: 20px;
            border: 1px solid #ddd;
            border-radius: 5px;
            max-width: 500px;
            max-height: 300px;
            overflow: auto;
            box-shadow: 0 0 10px rgba(0,0,0,0.1);
        }
        a {
            color: inherit;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        h1 {
            text-align: center;
        }
        h1 a {
            text-decoration: underline;
        }
        .date-section {
            margin-bottom: 40px;
        }
        .date-header {
            color: #666;
            font-size: 1.5em;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 2px solid #eee;
        }
    </style>
</head>
<body>
    <h1>
        <a href="https://github.com/DataWraith/arxiv-frontpage">DataWraith's</a> ArXiv Frontpage
    </h1>

    <div class="last-updated">
        Last updated: 2025-05-27
    </div>

    <p class="intro">
        This frontpage is made by scraping ArXiv's computer science RSS feed and tagging papers with a classifier.
    </p>

    <p class="intro">
        Each tag is weighted according to my preferences to compute a paper's <i>interestingness</i> score.
    </p>
    
    
    <div class="date-section">
        <h2 class="date-header">2025-05-27</h2>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.8123
                </span>
                <a href="https://arxiv.org/abs/2405.10148" target="_blank" rel="noopener noreferrer">SpecDETR: A Transformer-based Hyperspectral Point Object Detection Network</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zhaoxu Li, Wei An, Gaowei Guo, Longguang Wang, Yingqian Wang, Zaiping Lin
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Hyperspectral target detection (HTD) aims to identify specific materials based on spectral information in hyperspectral imagery and can detect extremely small-sized objects, some of which occupy a smaller than one-pixel area. However, existing HTD methods are developed based on per-pixel binary clas</span>
                
                <span class="abstract-full" style="display: none;">Hyperspectral target detection (HTD) aims to identify specific materials based on spectral information in hyperspectral imagery and can detect extremely small-sized objects, some of which occupy a smaller than one-pixel area. However, existing HTD methods are developed based on per-pixel binary classification, neglecting the three-dimensional cube structure of hyperspectral images (HSIs) that integrates both spatial and spectral dimensions. The synergistic existence of spatial and spectral features in HSIs enable objects to simultaneously exhibit both, yet the per-pixel HTD framework limits the joint expression of these features. In this paper, we rethink HTD from the perspective of spatial-spectral synergistic representation and propose hyperspectral point object detection as an innovative task framework. We introduce SpecDETR, the first specialized network for hyperspectral multi-class point object detection, which eliminates dependence on pre-trained backbone networks commonly required by vision-based object detectors. SpecDETR uses a multi-layer Transformer encoder with self-excited subpixel-scale attention modules to directly extract deep spatial-spectral joint features from hyperspectral cubes. We develop a simulated hyperspectral point object detection benchmark termed SPOD, and for the first time, evaluate and compare the performance of visual object detection networks and HTD methods on hyperspectral point object detection. Extensive experiments demonstrate that our proposed SpecDETR outperforms SOTA visual object detection networks and HTD methods. Our code and dataset are available at https://github.com/ZhaoxuLi123/SpecDETR.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 13.9%">
                            Computer Vision
                        </span>
                <!-- Medicine: 3.8 -->
                    
                <!-- LLMs: 2.8 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.6452
                </span>
                <a href="https://arxiv.org/abs/2505.19731" target="_blank" rel="noopener noreferrer">Accelerating Nash Learning from Human Feedback via Mirror Prox</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Daniil Tiapkin, Daniele Calandriello, Denis Belomestny, Eric Moulines, Alexey Naumov, Kashif Rasul, Michal Valko, Pierre Menard
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Traditional Reinforcement Learning from Human Feedback (RLHF) often relies on reward models, frequently assuming preference structures like the Bradley-Terry model, which may not accurately capture the complexities of real human preferences (e.g., intransitivity). Nash Learning from Human Feedback (</span>
                
                <span class="abstract-full" style="display: none;">Traditional Reinforcement Learning from Human Feedback (RLHF) often relies on reward models, frequently assuming preference structures like the Bradley-Terry model, which may not accurately capture the complexities of real human preferences (e.g., intransitivity). Nash Learning from Human Feedback (NLHF) offers a more direct alternative by framing the problem as finding a Nash equilibrium of a game defined by these preferences. In this work, we introduce Nash Mirror Prox ($\mathtt{Nash-MP}$), an online NLHF algorithm that leverages the Mirror Prox optimization scheme to achieve fast and stable convergence to the Nash equilibrium. Our theoretical analysis establishes that Nash-MP exhibits last-iterate linear convergence towards the $\beta$-regularized Nash equilibrium. Specifically, we prove that the KL-divergence to the optimal policy decreases at a rate of order $(1+2\beta)^{-N/2}$, where $N$ is a number of preference queries. We further demonstrate last-iterate linear convergence for the exploitability gap and uniformly for the span semi-norm of log-probabilities, with all these rates being independent of the size of the action space. Furthermore, we propose and analyze an approximate version of Nash-MP where proximal steps are estimated using stochastic policy gradients, making the algorithm closer to applications. Finally, we detail a practical implementation strategy for fine-tuning large language models and present experiments that demonstrate its competitive performance and compatibility with existing methods.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #44f899" title="Confidence: 5.2%">
                            Reinforcement Learning
                        </span>
                <!-- Federated Learning: 4.0 -->
                    
                <!-- LLMs: 2.7 -->
                    
                <!-- Bayesian Optimization: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Medicine: 1.8 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Math: 1.4 -->
                    
                <!-- Game Theory: 1.2 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                <!-- Hardware: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.3527
                </span>
                <a href="https://arxiv.org/abs/2505.20001" target="_blank" rel="noopener noreferrer">NEXT: Multi-Grained Mixture of Experts via Text-Modulation for Multi-Modal Object Re-ID</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Shihao Li, Chenglong Li, Aihua Zheng, Andong Lu, Jin Tang, Jixin Ma
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Multi-modal object re-identification (ReID) aims to extract identity features across heterogeneous spectral modalities to enable accurate recognition and retrieval in complex real-world scenarios. However, most existing methods rely on implicit feature fusion structures, making it difficult to model</span>
                
                <span class="abstract-full" style="display: none;">Multi-modal object re-identification (ReID) aims to extract identity features across heterogeneous spectral modalities to enable accurate recognition and retrieval in complex real-world scenarios. However, most existing methods rely on implicit feature fusion structures, making it difficult to model fine-grained recognition strategies under varying challenging conditions. Benefiting from the powerful semantic understanding capabilities of Multi-modal Large Language Models (MLLMs), the visual appearance of an object can be effectively translated into descriptive text. In this paper, we propose a reliable multi-modal caption generation method based on attribute confidence, which significantly reduces the unknown recognition rate of MLLMs in multi-modal semantic generation and improves the quality of generated text. Additionally, we propose a novel ReID framework NEXT, the Multi-grained Mixture of Experts via Text-Modulation for Multi-modal Object Re-Identification. Specifically, we decouple the recognition problem into semantic and structural expert branches to separately capture modality-specific appearance and intrinsic structure. For semantic recognition, we propose the Text-Modulated Semantic-sampling Experts (TMSE), which leverages randomly sampled high-quality semantic texts to modulate expert-specific sampling of multi-modal features and mining intra-modality fine-grained semantic cues. Then, to recognize coarse-grained structure features, we propose the Context-Shared Structure-aware Experts (CSSE) that focuses on capturing the holistic object structure across modalities and maintains inter-modality structural consistency through a soft routing mechanism. Finally, we propose the Multi-Modal Feature Aggregation (MMFA), which adopts a unified feature fusion strategy to simply and effectively integrate semantic and structural expert outputs into the final identity representations.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.0%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.5%">
                            Computer Vision
                        </span>
                <!-- Federated Learning: 3.9 -->
                    
                <!-- Medicine: 3.4 -->
                    
                <!-- GNN: 2.6 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.313
                </span>
                <a href="https://arxiv.org/abs/2505.18986" target="_blank" rel="noopener noreferrer">VL-SAM-V2: Open-World Object Detection with General and Specific Query Fusion</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zhiwei Lin, Yongtao Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Current perception models have achieved remarkable success by leveraging large-scale labeled datasets, but still face challenges in open-world environments with novel objects. To address this limitation, researchers introduce open-set perception models to detect or segment arbitrary test-time user-i</span>
                
                <span class="abstract-full" style="display: none;">Current perception models have achieved remarkable success by leveraging large-scale labeled datasets, but still face challenges in open-world environments with novel objects. To address this limitation, researchers introduce open-set perception models to detect or segment arbitrary test-time user-input categories. However, open-set models rely on human involvement to provide predefined object categories as input during inference. More recently, researchers have framed a more realistic and challenging task known as open-ended perception that aims to discover unseen objects without requiring any category-level input from humans at inference time. Nevertheless, open-ended models suffer from low performance compared to open-set models. In this paper, we present VL-SAM-V2, an open-world object detection framework that is capable of discovering unseen objects while achieving favorable performance. To achieve this, we combine queries from open-set and open-ended models and propose a general and specific query fusion module to allow different queries to interact. By adjusting queries from open-set models, we enable VL-SAM-V2 to be evaluated in the open-set or open-ended mode. In addition, to learn more diverse queries, we introduce ranked learnable queries to match queries with proposals from open-ended models by sorting. Moreover, we design a denoising point training strategy to facilitate the training process. Experimental results on LVIS show that our method surpasses the previous open-set and open-ended methods, especially on rare objects.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.4%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 6.6%">
                            Computer Vision
                        </span>
                <!-- Federated Learning: 3.1 -->
                    
                <!-- GNN: 3.1 -->
                    
                <!-- 3D: 2.1 -->
                    
                <!-- Medicine: 2.0 -->
                    
                <!-- HPO and AutoML: 2.0 -->
                    
                <!-- Decision Trees: 1.8 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- T2I: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.3056
                </span>
                <a href="https://arxiv.org/abs/2412.00592" target="_blank" rel="noopener noreferrer">LiDAR-EDIT: LiDAR Data Generation by Editing the Object Layouts in Real-World Scenes</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Shing-Hei Ho, Bao Thach, Minghan Zhu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We present LiDAR-EDIT, a novel paradigm for generating synthetic LiDAR data for autonomous driving. Our framework edits real-world LiDAR scans by introducing new object layouts while preserving the realism of the background environment. Compared to end-to-end frameworks that generate LiDAR point clo</span>
                
                <span class="abstract-full" style="display: none;">We present LiDAR-EDIT, a novel paradigm for generating synthetic LiDAR data for autonomous driving. Our framework edits real-world LiDAR scans by introducing new object layouts while preserving the realism of the background environment. Compared to end-to-end frameworks that generate LiDAR point clouds from scratch, LiDAR-EDIT offers users full control over the object layout, including the number, type, and pose of objects, while keeping most of the original real-world background. Our method also provides object labels for the generated data. Compared to novel view synthesis techniques, our framework allows for the creation of counterfactual scenarios with object layouts significantly different from the original real-world scene. LiDAR-EDIT uses spherical voxelization to enforce correct LiDAR projective geometry in the generated point clouds by construction. During object removal and insertion, generative models are employed to fill the unseen background and object parts that were occluded in the original real LiDAR scans. Experimental results demonstrate that our framework produces realistic LiDAR scans with practical value for downstream tasks.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.7%">
                            Computer Vision
                        </span>
                <!-- Medicine: 3.0 -->
                    
                <!-- Federated Learning: 2.7 -->
                    
                <!-- LLMs: 2.5 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2972
                </span>
                <a href="https://arxiv.org/abs/2405.14273" target="_blank" rel="noopener noreferrer">A fast algorithm to minimize prediction loss of the optimal solution in inverse optimization problem of MILP</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Akira Kitaoka
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We consider the inverse optimization problem of estimating the weights of the objective function such that the given solution is an optimal solution for a mixed integer linear program (MILP). In this inverse optimization problem, the known methods exhibit inefficient convergence. Specifically, if $d</span>
                
                <span class="abstract-full" style="display: none;">We consider the inverse optimization problem of estimating the weights of the objective function such that the given solution is an optimal solution for a mixed integer linear program (MILP). In this inverse optimization problem, the known methods exhibit inefficient convergence. Specifically, if $d$ denotes the dimension of the weights and $k$ the number of iterations, then the error of the weights is bounded by $O(k^{-1/(d-1)})$, leading to slow convergence as $d$ increases. We propose a projected subgradient method with a step size of $k^{-1/2}$ based on suboptimality loss. We theoretically show and demonstrate that the proposed method efficiently learns the weights. In particular, we show that there exists a constant $\gamma > 0$ such that the distance between the learned and true weights is bounded by $ O\left(k^{-1/(1+\gamma)} \exp\left(-\frac{\gamma k^{1/2}}{2+\gamma}\right)\right), $ or the optimal solution is exactly recovered. Furthermore, experiments demonstrate that the proposed method solves the inverse optimization problems of MILP using fewer than $1/7$ the number of MILP calls required by known methods, and converges within a finite number of iterations.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #31bb31" title="Confidence: 13.0%">
                            Bayesian Optimization
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #b3ebae" title="Confidence: 5.9%">
                            Federated Learning
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #a49950" title="Confidence: 5.3%">
                            Math
                        </span>
                <!-- Reinforcement Learning: 4.2 -->
                    
                <!-- Evolutionary Algorithms: 3.2 -->
                    
                <!-- Networks: 2.0 -->
                    
                <!-- Cryptography: 1.4 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Medicine: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Finance: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2944
                </span>
                <a href="https://arxiv.org/abs/2409.19833" target="_blank" rel="noopener noreferrer">HazyDet: Open-Source Benchmark for Drone-View Object Detection with Depth-Cues in Hazy Scenes</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Changfeng Feng, Zhenyuan Chen, Xiang Li, Chunping Wang, Jian Yang, Ming-Ming Cheng, Yimian Dai, Qiang Fu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Object detection from aerial platforms under adverse atmospheric conditions, particularly haze, is paramount for robust drone autonomy. Yet, this domain remains largely underexplored, primarily hindered by the absence of specialized benchmarks. To bridge this gap, we present \textit{HazyDet}, the fi</span>
                
                <span class="abstract-full" style="display: none;">Object detection from aerial platforms under adverse atmospheric conditions, particularly haze, is paramount for robust drone autonomy. Yet, this domain remains largely underexplored, primarily hindered by the absence of specialized benchmarks. To bridge this gap, we present \textit{HazyDet}, the first, large-scale benchmark specifically designed for drone-view object detection in hazy conditions. Comprising 383,000 real-world instances derived from both naturally hazy captures and synthetically hazed scenes augmented from clear images, HazyDet provides a challenging and realistic testbed for advancing detection algorithms. To address the severe visual degradation induced by haze, we propose the Depth-Conditioned Detector (DeCoDet), a novel architecture that integrates a Depth-Conditioned Kernel to dynamically modulate feature representations based on depth cues. The practical efficacy and robustness of DeCoDet are further enhanced by its training with a Progressive Domain Fine-Tuning (PDFT) strategy to navigate synthetic-to-real domain shifts, and a Scale-Invariant Refurbishment Loss (SIRLoss) to ensure resilient learning from potentially noisy depth annotations. Comprehensive empirical validation on HazyDet substantiates the superiority of our unified DeCoDet framework, which achieves state-of-the-art performance, surpassing the closest competitor by a notable +1.5\% mAP on challenging real-world hazy test scenarios. Our dataset and toolkit are available at https://github.com/GrokCV/HazyDet.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.5%">
                            Computer Vision
                        </span>
                <!-- Medicine: 4.5 -->
                    
                <!-- Federated Learning: 2.5 -->
                    
                <!-- GNN: 2.3 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- LLMs: 1.8 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Hardware: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2775
                </span>
                <a href="https://arxiv.org/abs/2505.04119" target="_blank" rel="noopener noreferrer">GAPrompt: Geometry-Aware Point Cloud Prompt for 3D Vision Model</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zixiang Ai, Zichen Liu, Yuanhang Lei, Zhenyu Cui, Xu Zou, Jiahuan Zhou
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Pre-trained 3D vision models have gained significant attention for their promising performance on point cloud data. However, fully fine-tuning these models for downstream tasks is computationally expensive and storage-intensive. Existing parameter-efficient fine-tuning (PEFT) approaches, which focus</span>
                
                <span class="abstract-full" style="display: none;">Pre-trained 3D vision models have gained significant attention for their promising performance on point cloud data. However, fully fine-tuning these models for downstream tasks is computationally expensive and storage-intensive. Existing parameter-efficient fine-tuning (PEFT) approaches, which focus primarily on input token prompting, struggle to achieve competitive performance due to their limited ability to capture the geometric information inherent in point clouds. To address this challenge, we propose a novel Geometry-Aware Point Cloud Prompt (GAPrompt) that leverages geometric cues to enhance the adaptability of 3D vision models. First, we introduce a Point Prompt that serves as an auxiliary input alongside the original point cloud, explicitly guiding the model to capture fine-grained geometric details. Additionally, we present a Point Shift Prompter designed to extract global shape information from the point cloud, enabling instance-specific geometric adjustments at the input level. Moreover, our proposed Prompt Propagation mechanism incorporates the shape information into the model's feature extraction process, further strengthening its ability to capture essential geometric characteristics. Extensive experiments demonstrate that GAPrompt significantly outperforms state-of-the-art PEFT methods and achieves competitive results compared to full fine-tuning on various benchmarks, while utilizing only 2.19% of trainable parameters. Our code is available at https://github.com/zhoujiahuan1991/ICML2025-VGP.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.5%">
                            Computer Vision
                        </span>
                <!-- GNN: 4.6 -->
                    
                <!-- Medicine: 3.9 -->
                    
                <!-- 3D: 3.7 -->
                    
                <!-- Federated Learning: 2.9 -->
                    
                <!-- LLMs: 2.6 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.4 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Hardware: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2646
                </span>
                <a href="https://arxiv.org/abs/2505.19420" target="_blank" rel="noopener noreferrer">ADD-SLAM: Adaptive Dynamic Dense SLAM with Gaussian Splatting</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Wenhua Wu, Chenpeng Su, Siting Zhu, Tianchen Deng, Zhe Liu, Hesheng Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Recent advancements in Neural Radiance Fields (NeRF) and 3D Gaussian-based Simultaneous Localization and Mapping (SLAM) methods have demonstrated exceptional localization precision and remarkable dense mapping performance. However, dynamic objects introduce critical challenges by disrupting scene co</span>
                
                <span class="abstract-full" style="display: none;">Recent advancements in Neural Radiance Fields (NeRF) and 3D Gaussian-based Simultaneous Localization and Mapping (SLAM) methods have demonstrated exceptional localization precision and remarkable dense mapping performance. However, dynamic objects introduce critical challenges by disrupting scene consistency, leading to tracking drift and mapping artifacts. Existing methods that employ semantic segmentation or object detection for dynamic identification and filtering typically rely on predefined categorical priors, while discarding dynamic scene information crucial for robotic applications such as dynamic obstacle avoidance and environmental interaction. To overcome these challenges, we propose ADD-SLAM: an Adaptive Dynamic Dense SLAM framework based on Gaussian splitting. We design an adaptive dynamic identification mechanism grounded in scene consistency analysis, comparing geometric and textural discrepancies between real-time observations and historical maps. Ours requires no predefined semantic category priors and adaptively discovers scene dynamics. Precise dynamic object recognition effectively mitigates interference from moving targets during localization. Furthermore, we propose a dynamic-static separation mapping strategy that constructs a temporal Gaussian model to achieve online incremental dynamic modeling. Experiments conducted on multiple dynamic datasets demonstrate our method's flexible and accurate dynamic segmentation capabilities, along with state-of-the-art performance in both localization and mapping.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 6.1%">
                            Computer Vision
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.9%">
                            LLMs
                        </span>
                <!-- Medicine: 4.0 -->
                    
                <!-- 3D: 3.7 -->
                    
                <!-- HPO and AutoML: 1.9 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- T2I: 1.6 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2631
                </span>
                <a href="https://arxiv.org/abs/2405.05648" target="_blank" rel="noopener noreferrer">ASGrasp: Generalizable Transparent Object Reconstruction and 6-DoF Grasp Detection from RGB-D Active Stereo Camera</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jun Shi, Yong A, Yixiang Jin, Dingzhe Li, Haoyu Niu, Zhezhu Jin, He Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In this paper, we tackle the problem of grasping transparent and specular objects. This issue holds importance, yet it remains unsolved within the field of robotics due to failure of recover their accurate geometry by depth cameras. For the first time, we propose ASGrasp, a 6-DoF grasp detection net</span>
                
                <span class="abstract-full" style="display: none;">In this paper, we tackle the problem of grasping transparent and specular objects. This issue holds importance, yet it remains unsolved within the field of robotics due to failure of recover their accurate geometry by depth cameras. For the first time, we propose ASGrasp, a 6-DoF grasp detection network that uses an RGB-D active stereo camera. ASGrasp utilizes a two-layer learning-based stereo network for the purpose of transparent object reconstruction, enabling material-agnostic object grasping in cluttered environments. In contrast to existing RGB-D based grasp detection methods, which heavily depend on depth restoration networks and the quality of depth maps generated by depth cameras, our system distinguishes itself by its ability to directly utilize raw IR and RGB images for transparent object geometry reconstruction. We create an extensive synthetic dataset through domain randomization, which is based on GraspNet-1Billion. Our experiments demonstrate that ASGrasp can achieve over 90% success rate for generalizable transparent object grasping in both simulation and the real via seamless sim-to-real transfer. Our method significantly outperforms SOTA networks and even surpasses the performance upper bound set by perfect visible point cloud inputs.Project page: https://pku-epic.github.io/ASGrasp</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.3%">
                            Computer Vision
                        </span>
                <!-- LLMs: 4.1 -->
                    
                <!-- Medicine: 3.7 -->
                    
                <!-- Federated Learning: 2.9 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Quantum Computing: 2.0 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2617
                </span>
                <a href="https://arxiv.org/abs/2505.19227" target="_blank" rel="noopener noreferrer">Scaling Laws for Gradient Descent and Sign Descent for Linear Bigram Models under Zipf's Law</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Frederik Kunstner, Francis Bach
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Recent works have highlighted optimization difficulties faced by gradient descent in training the first and last layers of transformer-based language models, which are overcome by optimizers such as Adam. These works suggest that the difficulty is linked to the heavy-tailed distribution of words in </span>
                
                <span class="abstract-full" style="display: none;">Recent works have highlighted optimization difficulties faced by gradient descent in training the first and last layers of transformer-based language models, which are overcome by optimizers such as Adam. These works suggest that the difficulty is linked to the heavy-tailed distribution of words in text data, where the frequency of the $k$th most frequent word $\pi_k$ is proportional to $1/k$, following Zipf's law. To better understand the impact of the data distribution on training performance, we study a linear bigram model for next-token prediction when the tokens follow a power law $\pi_k \propto 1/k^\alpha$ parameterized by the exponent $\alpha > 0$. We derive optimization scaling laws for deterministic gradient descent and sign descent as a proxy for Adam as a function of the exponent $\alpha$. Existing theoretical investigations in scaling laws assume that the eigenvalues of the data decay as a power law with exponent $\alpha > 1$. This assumption effectively makes the problem ``finite dimensional'' as most of the loss comes from a few of the largest eigencomponents. In comparison, we show that the problem is more difficult when the data have heavier tails. The case $\alpha = 1$ as found in text data is ``worst-case'' for gradient descent, in that the number of iterations required to reach a small relative error scales almost linearly with dimension. While the performance of sign descent also depends on the dimension, for Zipf-distributed data the number of iterations scales only with the square-root of the dimension, leading to a large improvement for large vocabularies.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #31bb31" title="Confidence: 6.3%">
                            Bayesian Optimization
                        </span>
                <!-- Math: 2.8 -->
                    
                <!-- Federated Learning: 2.8 -->
                    
                <!-- Reinforcement Learning: 2.3 -->
                    
                <!-- Networks: 2.0 -->
                    
                <!-- Medicine: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Cryptography: 1.6 -->
                    
                <!-- Finance: 1.4 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Game Theory: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2421
                </span>
                <a href="https://arxiv.org/abs/2405.07760" target="_blank" rel="noopener noreferrer">CAGES: Cost-Aware Gradient Entropy Search for Efficient Local Multi-Fidelity Bayesian Optimization</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Wei-Ting Tang, Joel A. Paulson
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Bayesian optimization (BO) is a popular approach for optimizing expensive-to-evaluate black-box objective functions. An important challenge in BO is its application to high-dimensional search spaces due in large part to the curse of dimensionality. One way to overcome this challenge is to focus on l</span>
                
                <span class="abstract-full" style="display: none;">Bayesian optimization (BO) is a popular approach for optimizing expensive-to-evaluate black-box objective functions. An important challenge in BO is its application to high-dimensional search spaces due in large part to the curse of dimensionality. One way to overcome this challenge is to focus on local BO methods that aim to efficiently learn gradients, which have shown strong empirical performance on high-dimensional problems including policy search in reinforcement learning (RL). Current local BO methods assume access to only a single high-fidelity information source whereas, in many problems, one has access to multiple cheaper approximations of the objective. We propose a novel algorithm, Cost-Aware Gradient Entropy Search (CAGES), for local BO of multi-fidelity black-box functions. CAGES makes no assumption about the relationship between different information sources, making it more flexible than other multi-fidelity methods. It also employs a new information-theoretic acquisition function, which enables systematic identification of samples that maximize the information gain about the unknown gradient per evaluation cost. We demonstrate CAGES can achieve significant performance improvements compared to other state-of-the-art methods on synthetic and benchmark RL problems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #31bb31" title="Confidence: 7.3%">
                            Bayesian Optimization
                        </span>
                <!-- Federated Learning: 3.3 -->
                    
                <!-- GNN: 2.9 -->
                    
                <!-- Evolutionary Algorithms: 2.6 -->
                    
                <!-- LLMs: 2.6 -->
                    
                <!-- Computer Vision: 1.9 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Reinforcement Learning: 1.8 -->
                    
                <!-- Networks: 1.7 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Hardware: 1.1 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Medicine: 1.0 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2157
                </span>
                <a href="https://arxiv.org/abs/2505.20021" target="_blank" rel="noopener noreferrer">Decomposing Complex Visual Comprehension into Atomic Visual Skills for Vision Language Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Hyunsik Chae, Seungwoo Yoon, Jaden Park, Chloe Yewon Chun, Yongin Cho, Mu Cai, Yong Jae Lee, Ernest K. Ryu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Recent Vision-Language Models (VLMs) have demonstrated impressive multimodal comprehension and reasoning capabilities, yet they often struggle with trivially simple visual tasks. In this work, we focus on the domain of basic 2D Euclidean geometry and systematically categorize the fundamental, indivi</span>
                
                <span class="abstract-full" style="display: none;">Recent Vision-Language Models (VLMs) have demonstrated impressive multimodal comprehension and reasoning capabilities, yet they often struggle with trivially simple visual tasks. In this work, we focus on the domain of basic 2D Euclidean geometry and systematically categorize the fundamental, indivisible visual perception skills, which we refer to as atomic visual skills. We then introduce the Atomic Visual Skills Dataset (AVSD) for evaluating VLMs on the atomic visual skills. Using AVSD, we benchmark state-of-the-art VLMs and find that they struggle with these tasks, despite being trivial for adult humans. Our findings highlight the need for purpose-built datasets to train and evaluate VLMs on atomic, rather than composite, visual perception tasks.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.6%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.3%">
                            Computer Vision
                        </span>
                <!-- Medicine: 4.3 -->
                    
                <!-- Hardware: 2.2 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- T2I: 1.1 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- 3D: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2128
                </span>
                <a href="https://arxiv.org/abs/2505.19850" target="_blank" rel="noopener noreferrer">DISCOVER: Automated Curricula for Sparse-Reward Reinforcement Learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Leander Diaz-Bone, Marco Bagatella, Jonas H\"ubotter, Andreas Krause
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Sparse-reward reinforcement learning (RL) can model a wide range of highly complex tasks. Solving sparse-reward tasks is RL's core premise - requiring efficient exploration coupled with long-horizon credit assignment - and overcoming these challenges is key for building self-improving agents with su</span>
                
                <span class="abstract-full" style="display: none;">Sparse-reward reinforcement learning (RL) can model a wide range of highly complex tasks. Solving sparse-reward tasks is RL's core premise - requiring efficient exploration coupled with long-horizon credit assignment - and overcoming these challenges is key for building self-improving agents with superhuman ability. We argue that solving complex and high-dimensional tasks requires solving simpler tasks that are relevant to the target task. In contrast, most prior work designs strategies for selecting exploratory tasks with the objective of solving any task, making exploration of challenging high-dimensional, long-horizon tasks intractable. We find that the sense of direction, necessary for effective exploration, can be extracted from existing RL algorithms, without needing any prior information. Based on this finding, we propose a method for directed sparse-reward goal-conditioned very long-horizon RL (DISCOVER), which selects exploratory goals in the direction of the target task. We connect DISCOVER to principled exploration in bandits, formally bounding the time until the target task becomes achievable in terms of the agent's initial distance to the target, but independent of the volume of the space of all tasks. Empirically, we perform a thorough evaluation in high-dimensional environments. We find that the directed goal selection of DISCOVER solves exploration problems that are beyond the reach of prior state-of-the-art exploration methods in RL.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #31bb31" title="Confidence: 5.1%">
                            Bayesian Optimization
                        </span>
                <!-- LLMs: 3.4 -->
                    
                <!-- Reinforcement Learning: 3.0 -->
                    
                <!-- Federated Learning: 2.9 -->
                    
                <!-- Medicine: 2.5 -->
                    
                <!-- Math: 2.3 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Game Theory: 1.2 -->
                    
                <!-- Hardware: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2008
                </span>
                <a href="https://arxiv.org/abs/2505.19841" target="_blank" rel="noopener noreferrer">Efficient Deconvolution in Populational Inverse Problems</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Arnaud Vadeboncoeur, Mark Girolami, Andrew M. Stuart
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This work is focussed on the inversion task of inferring the distribution over parameters of interest leading to multiple sets of observations. The potential to solve such distributional inversion problems is driven by increasing availability of data, but a major roadblock is blind deconvolution, ar</span>
                
                <span class="abstract-full" style="display: none;">This work is focussed on the inversion task of inferring the distribution over parameters of interest leading to multiple sets of observations. The potential to solve such distributional inversion problems is driven by increasing availability of data, but a major roadblock is blind deconvolution, arising when the observational noise distribution is unknown. However, when data originates from collections of physical systems, a population, it is possible to leverage this information to perform deconvolution. To this end, we propose a methodology leveraging large data sets of observations, collected from different instantiations of the same physical processes, to simultaneously deconvolve the data corrupting noise distribution, and to identify the distribution over model parameters defining the physical processes. A parameter-dependent mathematical model of the physical process is employed. A loss function characterizing the match between the observed data and the output of the mathematical model is defined; it is minimized as a function of the both the parameter inputs to the model of the physics and the parameterized observational noise. This coupled problem is addressed with a modified gradient descent algorithm that leverages specific structure in the noise model. Furthermore, a new active learning scheme is proposed, based on adaptive empirical measures, to train a surrogate model to be accurate in parameter regions of interest; this approach accelerates computation and enables automatic differentiation of black-box, potentially nondifferentiable, code computing parameter-to-solution maps. The proposed methodology is demonstrated on porous medium flow, damped elastodynamics, and simplified models of atmospheric dynamics.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #b3ebae" title="Confidence: 6.7%">
                            Federated Learning
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #31bb31" title="Confidence: 5.7%">
                            Bayesian Optimization
                        </span>
                <!-- Evolutionary Algorithms: 2.5 -->
                    
                <!-- Medicine: 2.1 -->
                    
                <!-- Reinforcement Learning: 2.0 -->
                    
                <!-- Networks: 1.6 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Math: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Hardware: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.1966
                </span>
                <a href="https://arxiv.org/abs/2307.12179" target="_blank" rel="noopener noreferrer">Leveraging Knowledge Graphs for Zero-Shot Object-agnostic State Classification</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Filipos Gouidis, Theodore Patkos, Antonis Argyros, Dimitris Plexousakis
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We investigate the problem of Object State Classification (OSC) as a zero-shot learning problem. Specifically, we propose the first Object-agnostic State Classification (OaSC) method that infers the state of a certain object without relying on the knowledge or the estimation of the object class. In </span>
                
                <span class="abstract-full" style="display: none;">We investigate the problem of Object State Classification (OSC) as a zero-shot learning problem. Specifically, we propose the first Object-agnostic State Classification (OaSC) method that infers the state of a certain object without relying on the knowledge or the estimation of the object class. In that direction, we capitalize on Knowledge Graphs (KGs) for structuring and organizing knowledge, which, in combination with visual information, enable the inference of the states of objects in object/state pairs that have not been encountered in the method's training set. A series of experiments investigate the performance of the proposed method in various settings, against several hypotheses and in comparison with state of the art approaches for object attribute classification. The experimental results demonstrate that the knowledge of an object class is not decisive for the prediction of its state. Moreover, the proposed OaSC method outperforms existing methods in all datasets and benchmarks by a great margin.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #31bb31" title="Confidence: 5.1%">
                            Bayesian Optimization
                        </span>
                <!-- Federated Learning: 3.8 -->
                    
                <!-- Medicine: 2.6 -->
                    
                <!-- Computer Vision: 2.5 -->
                    
                <!-- Reinforcement Learning: 2.5 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Math: 1.8 -->
                    
                <!-- LLMs: 1.7 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.0157
                </span>
                <a href="https://arxiv.org/abs/2505.19737" target="_blank" rel="noopener noreferrer">Weighted Leave-One-Out Cross Validation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Luc Pronzato (RT-UQ), Maria-Jo\~ao Rendas
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We present a weighted version of Leave-One-Out (LOO) cross-validation for estimating the Integrated Squared Error (ISE) when approximating an unknown function by a predictor that depends linearly on evaluations of the function over a finite collection of sites. The method relies on the construction </span>
                
                <span class="abstract-full" style="display: none;">We present a weighted version of Leave-One-Out (LOO) cross-validation for estimating the Integrated Squared Error (ISE) when approximating an unknown function by a predictor that depends linearly on evaluations of the function over a finite collection of sites. The method relies on the construction of the best linear estimator of the squared prediction error at an arbitrary unsampled site based on squared LOO residuals, assuming that the function is a realization of a Gaussian Process (GP). A theoretical analysis of performance of the ISE estimator is presented, and robustness with respect to the choice of the GP kernel is investigated first analytically, then through numerical examples. Overall, the estimation of ISE is significantly more precise than with classical, unweighted, LOO cross validation. Application to model selection is briefly considered through examples.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #31bb31" title="Confidence: 6.3%">
                            Bayesian Optimization
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #a49950" title="Confidence: 5.9%">
                            Math
                        </span>
                <!-- Federated Learning: 3.4 -->
                    
                <!-- Networks: 2.5 -->
                    
                <!-- Medicine: 2.4 -->
                    
                <!-- Evolutionary Algorithms: 2.3 -->
                    
                <!-- Cryptography: 2.1 -->
                    
                <!-- Reinforcement Learning: 1.8 -->
                    
                <!-- Finance: 1.5 -->
                    
                <!-- Game Theory: 1.2 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- LLMs: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18793" target="_blank" rel="noopener noreferrer">Genie Centurion: Accelerating Scalable Real-World Robot Training with Human Rewind-and-Refine Guidance</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Wenhao Wang, Jianheng Song, Chiming Liu, Jiayao Ma, Siyuan Feng, Jingyuan Wang, Yuxin Jiang, Kylin Chen, Sikang Zhan, Yi Wang, Tong Meng, Modi Shi, Xindong He, Guanghui Ren, Yang Yang, Maoqing Yao
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">While Vision-Language-Action (VLA) models show strong generalizability in various tasks, real-world deployment of robotic policy still requires large-scale, high-quality human expert demonstrations. However, passive data collection via human teleoperation is costly, hard to scale, and often biased t</span>
                
                <span class="abstract-full" style="display: none;">While Vision-Language-Action (VLA) models show strong generalizability in various tasks, real-world deployment of robotic policy still requires large-scale, high-quality human expert demonstrations. However, passive data collection via human teleoperation is costly, hard to scale, and often biased toward passive demonstrations with limited diversity. To address this, we propose Genie Centurion (GCENT), a scalable and general data collection paradigm based on human rewind-and-refine guidance. When the robot execution failures occur, GCENT enables the system revert to a previous state with a rewind mechanism, after which a teleoperator provides corrective demonstrations to refine the policy. This framework supports a one-human-to-many-robots supervision scheme with a Task Sentinel module, which autonomously predicts task success and solicits human intervention when necessary, enabling scalable supervision. Empirical results show that GCENT achieves up to 40% higher task success rates than state-of-the-art data collection methods, and reaches comparable performance using less than half the data. We also quantify the data yield-to-effort ratio under multi-robot scenarios, demonstrating GCENT's potential for scalable and cost-efficient robot policy training in real-world environments.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.1 -->
                    
                <!-- LLMs: 3.9 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- GNN: 2.1 -->
                    
                <!-- Computer Vision: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Networks: 1.3 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18798" target="_blank" rel="noopener noreferrer">Governing Equation Discovery from Data Based on Differential Invariants</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Lexiang Hu, Yikang Li, Zhouchen Lin
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The explicit governing equation is one of the simplest and most intuitive forms for characterizing physical laws. However, directly discovering partial differential equations (PDEs) from data poses significant challenges, primarily in determining relevant terms from a vast search space. Symmetry, as</span>
                
                <span class="abstract-full" style="display: none;">The explicit governing equation is one of the simplest and most intuitive forms for characterizing physical laws. However, directly discovering partial differential equations (PDEs) from data poses significant challenges, primarily in determining relevant terms from a vast search space. Symmetry, as a crucial prior knowledge in scientific fields, has been widely applied in tasks such as designing equivariant networks and guiding neural PDE solvers. In this paper, we propose a pipeline for governing equation discovery based on differential invariants, which can losslessly reduce the search space of existing equation discovery methods while strictly adhering to symmetry. Specifically, we compute the set of differential invariants corresponding to the infinitesimal generators of the symmetry group and select them as the relevant terms for equation discovery. Taking DI-SINDy (SINDy based on Differential Invariants) as an example, we demonstrate that its success rate and accuracy in PDE discovery surpass those of other symmetry-informed governing equation discovery methods across a series of PDEs.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 3.6 -->
                    
                <!-- Federated Learning: 2.6 -->
                    
                <!-- Medicine: 2.6 -->
                    
                <!-- Hardware: 2.4 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18806" target="_blank" rel="noopener noreferrer">Mal-D2GAN: Double-Detector based GAN for Malware Generation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Nam Hoang Thanh, Trung Pham Duy, Lam Bui Thu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Machine learning (ML) has been developed to detect malware in recent years. Most researchers focused their efforts on improving the detection performance but ignored the robustness of the ML models. In addition, many machine learning algorithms are very vulnerable to intentional attacks. To solve th</span>
                
                <span class="abstract-full" style="display: none;">Machine learning (ML) has been developed to detect malware in recent years. Most researchers focused their efforts on improving the detection performance but ignored the robustness of the ML models. In addition, many machine learning algorithms are very vulnerable to intentional attacks. To solve these problems, adversarial malware examples are generated by GANs to enhance the robustness of the malware detector. However, since current GAN models suffer from limitations such as unstable training and weak adversarial examples, we propose the Mal-D2GAN model to address these problems. Specifically, the Mal-D2GAN architecture was designed with double-detector and a least square loss function and tested on a dataset of 20,000 samples. The results show that the Mal-D2GAN model reduced the detection accuracy (true positive rate) in 8 malware detectors. The performance was then compared with that of the existing MalGAN and Mal- LSGAN models.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 3.6 -->
                    
                <!-- Computer Vision: 3.1 -->
                    
                <!-- Medicine: 3.1 -->
                    
                <!-- LLMs: 2.1 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Bayesian Optimization: 1.7 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18810" target="_blank" rel="noopener noreferrer">Discrete gradient methods for port-Hamiltonian differential-algebraic equations</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Philipp L. Kinon, Riccardo Morandin, Philipp Schulze
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Discrete gradient methods are a powerful tool for the time discretization of dynamical systems, since they are structure-preserving regardless of the form of the total energy. In this work, we discuss the application of discrete gradient methods to the system class of nonlinear port-Hamiltonian diff</span>
                
                <span class="abstract-full" style="display: none;">Discrete gradient methods are a powerful tool for the time discretization of dynamical systems, since they are structure-preserving regardless of the form of the total energy. In this work, we discuss the application of discrete gradient methods to the system class of nonlinear port-Hamiltonian differential-algebraic equations - as they emerge from the port- and energy-based modeling of physical systems in various domains. We introduce a novel numerical scheme tailored for semi-explicit differential-algebraic equations and further address more general settings using the concepts of discrete gradient pairs and Dirac-dissipative structures. Additionally, the behavior under system transformations is investigated and we demonstrate that under suitable assumptions port-Hamiltonian differential-algebraic equations admit a representation which consists of a parametrized port-Hamiltonian semi-explicit system and an unstructured equation. Finally, we present the application to multibody system dynamics and discuss numerical results to demonstrate the capabilities of our approach.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 5.0 -->
                    
                <!-- LLMs: 3.2 -->
                    
                <!-- Federated Learning: 3.0 -->
                    
                <!-- Bayesian Optimization: 2.2 -->
                    
                <!-- Reinforcement Learning: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- GNN: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18818" target="_blank" rel="noopener noreferrer">Automated Verification of Monotonic Data Structure Traversals in C</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Matthew Sotoudeh
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Bespoke data structure operations are common in real-world C code. We identify one common subclass, monotonic data structure traversals (MDSTs), that iterate monotonically through the structure. For example, strlen iterates from start to end of a character array until a null byte is found, and a bin</span>
                
                <span class="abstract-full" style="display: none;">Bespoke data structure operations are common in real-world C code. We identify one common subclass, monotonic data structure traversals (MDSTs), that iterate monotonically through the structure. For example, strlen iterates from start to end of a character array until a null byte is found, and a binary search tree insert iterates from the tree root towards a leaf. We describe a new automated verification tool, Shrinker, to verify MDSTs written in C. Shrinker uses a new program analysis strategy called scapegoating size descent, which is designed to take advantage of the fact that many MDSTs produce very similar traces when executed on an input (e.g., some large list) as when executed on a 'shrunk' version of the input (e.g., the same list but with its first element deleted). We introduce a new benchmark set containing over one hundred instances proving correctness, equivalence, and memory safety properties of dozens of MDSTs found in major C codebases including Linux, NetBSD, OpenBSD, QEMU, Git, and Musl. Shrinker significantly increases the number of monotonic string and list traversals that can be verified vs. a portfolio of state-of-the-art tools.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 3.9 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- Networks: 2.0 -->
                    
                <!-- Medicine: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- Bayesian Optimization: 1.6 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Cryptography: 1.3 -->
                    
                <!-- Math: 1.3 -->
                    
                <!-- Game Theory: 1.3 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18824" target="_blank" rel="noopener noreferrer">FlatAttention: Dataflow and Fabric Collectives Co-Optimization for Efficient Multi-Head Attention on Tile-Based Many-PE Accelerators</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Chi Zhang, Luca Colagrande, Renzo Andri, Thomas Benz, Gamze Islamoglu, Alessandro Nadalini, Francesco Conti, Yawei Li, Luca Benini
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Multi-Head Attention (MHA) is a critical computational kernel in transformer-based AI models. Emerging scalable tile-based accelerator architectures integrate increasing numbers of tightly-packed processing elements (PEs) with tensor units. MHA dataflow mapping is crucial for achieving high utilizat</span>
                
                <span class="abstract-full" style="display: none;">Multi-Head Attention (MHA) is a critical computational kernel in transformer-based AI models. Emerging scalable tile-based accelerator architectures integrate increasing numbers of tightly-packed processing elements (PEs) with tensor units. MHA dataflow mapping is crucial for achieving high utilization of the available units. We propose FlatAttention, a new dataflow for MHA on tile-based many-PE accelerators, minimizing costly main memory (HBM) accesses by leveraging collective primitives integrated into the on-chip network fabric. FlatAttention achieves up to 89.3% utilization, and 4.1x performance speedup over FlashAttention-3 dataflow on tile-based accelerators whilst reducing HBM traffic by 16x. Through algorithm-architecture co-exploration, we identify an optimal configuration for a large scaled-out tile-based accelerator featuring a 32x32 tile mesh with 1024 TFLOPS @ FP16 peak performance, comparable to the state-of-the-art Nvidia H100 GPU. FlatAttention in this configuration achieves up to 1.3x higher utilization over FlashAttention-3 on the H100 GPU. Meanwhile, this tile-based accelerator configuration requires 40% less HBM bandwidth compared to the H100, enabling a 1.8x reduction in die size, estimated on the same technology node.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Hardware: 2.6 -->
                    
                <!-- Medicine: 2.5 -->
                    
                <!-- Computer Vision: 2.5 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- LLMs: 2.0 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Networks: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- Cryptography: 1.2 -->
                    
                <!-- 3D: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18825" target="_blank" rel="noopener noreferrer">How to build a consistency model: Learning flow maps via self-distillation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Nicholas M. Boffi, Michael S. Albergo, Eric Vanden-Eijnden
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Building on the framework proposed in Boffi et al. (2024), we present a systematic approach for learning flow maps associated with flow and diffusion models. Flow map-based models, commonly known as consistency models, encompass recent efforts to improve the efficiency of generative models based on </span>
                
                <span class="abstract-full" style="display: none;">Building on the framework proposed in Boffi et al. (2024), we present a systematic approach for learning flow maps associated with flow and diffusion models. Flow map-based models, commonly known as consistency models, encompass recent efforts to improve the efficiency of generative models based on solutions to differential equations. By exploiting a relationship between the velocity field underlying a continuous-time flow and the instantaneous rate of change of the flow map, we show how to convert existing distillation schemes into direct training algorithms via self-distillation, eliminating the need for pre-trained models. We empirically evaluate several instantiations of our framework, finding that high-dimensional tasks like image synthesis benefit from objective functions that avoid temporal and spatial derivatives of the flow map, while lower-dimensional tasks can benefit from objectives incorporating higher-order derivatives to capture sharp features.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 3.5 -->
                    
                <!-- LLMs: 3.1 -->
                    
                <!-- Evolutionary Algorithms: 2.4 -->
                    
                <!-- Medicine: 2.4 -->
                    
                <!-- Reinforcement Learning: 2.1 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Bayesian Optimization: 1.7 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Networks: 1.1 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18828" target="_blank" rel="noopener noreferrer">Improved Regret and Contextual Linear Extension for Pandora's Box and Prophet Inequality</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Junyan Liu, Ziyun Chen, Kun Wang, Haipeng Luo, Lillian J. Ratliff
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We study the Pandora's Box problem in an online learning setting with semi-bandit feedback. In each round, the learner sequentially pays to open up to $n$ boxes with unknown reward distributions, observes rewards upon opening, and decides when to stop. The utility of the learner is the maximum obser</span>
                
                <span class="abstract-full" style="display: none;">We study the Pandora's Box problem in an online learning setting with semi-bandit feedback. In each round, the learner sequentially pays to open up to $n$ boxes with unknown reward distributions, observes rewards upon opening, and decides when to stop. The utility of the learner is the maximum observed reward minus the cumulative cost of opened boxes, and the goal is to minimize regret defined as the gap between the cumulative expected utility and that of the optimal policy. We propose a new algorithm that achieves $\widetilde{O}(\sqrt{nT})$ regret after $T$ rounds, which improves the $\widetilde{O}(n\sqrt{T})$ bound of Agarwal et al. [2024] and matches the known lower bound up to logarithmic factors. To better capture real-life applications, we then extend our results to a natural but challenging contextual linear setting, where each box's expected reward is linear in some known but time-varying $d$-dimensional context and the noise distribution is fixed over time. We design an algorithm that learns both the linear function and the noise distributions, achieving $\widetilde{O}(nd\sqrt{T})$ regret. Finally, we show that our techniques also apply to the online Prophet Inequality problem, where the learner must decide immediately whether or not to accept a revealed reward. In both non-contextual and contextual settings, our approach achieves similar improvements and regret bounds.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Reinforcement Learning: 3.9 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- LLMs: 2.2 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- Medicine: 1.4 -->
                    
                <!-- Networks: 1.3 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- Math: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18836" target="_blank" rel="noopener noreferrer">Distributed Incremental SAT Solving with Mallob: Report and Case Study with Hierarchical Planning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Dominik Schreiber
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This report describes an extension of the distributed job scheduling and SAT solving platform Mallob by incremental SAT solving, embedded in a case study on SAT-based hierarchical planning. We introduce a low-latency interface for incremental jobs and specifically for IPASIR-style incremental SAT so</span>
                
                <span class="abstract-full" style="display: none;">This report describes an extension of the distributed job scheduling and SAT solving platform Mallob by incremental SAT solving, embedded in a case study on SAT-based hierarchical planning. We introduce a low-latency interface for incremental jobs and specifically for IPASIR-style incremental SAT solving to Mallob. This also allows to process many independent planning instances in parallel via Mallob's scheduling capabilities. In an experiment where 587 planning inputs are resolved in parallel on 2348 cores, we observe significant speedups for several planning domains where SAT solving constitutes a major part of the planner's running time. These findings indicate that our approach to distributed incremental SAT solving may be useful for a wide range of SAT applications.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.7 -->
                    
                <!-- Medicine: 3.0 -->
                    
                <!-- Evolutionary Algorithms: 2.2 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Networks: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Game Theory: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18838" target="_blank" rel="noopener noreferrer">Unconditionally Stable Mixed Finite Element Methods for Darcy Flow</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Maicon R. Correa, Abimael F. D. Loula
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Unconditionally stable finite element methods for Darcy flow are derived by adding least-squares residual forms of the governing equations to the classical mixed formulations. The proposed methods are free of mesh dependent stabilization parameters and allow the use of the classical continuous Lagra</span>
                
                <span class="abstract-full" style="display: none;">Unconditionally stable finite element methods for Darcy flow are derived by adding least-squares residual forms of the governing equations to the classical mixed formulations. The proposed methods are free of mesh dependent stabilization parameters and allow the use of the classical continuous Lagrangian finite element spaces of any order for the velocity and the potential. Stability, convergence and error estimates are derived and numerical experiments are presented to demonstrate the flexibility of the proposed finite element formulations and to confirm the predicted rates of convergence.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 3.3 -->
                    
                <!-- Hardware: 3.0 -->
                    
                <!-- Bayesian Optimization: 2.7 -->
                    
                <!-- Federated Learning: 2.6 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- Math: 1.6 -->
                    
                <!-- LLMs: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18839" target="_blank" rel="noopener noreferrer">DNF Learning via Locally Mixing Random Walks</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Josh Alman, Shivam Nadimpalli, Shyamal Patel, Rocco A. Servedio
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We give two results on PAC learning DNF formulas using membership queries in the challenging "distribution-free" learning framework, where learning algorithms must succeed for an arbitrary and unknown distribution over $\{0,1\}^n$.</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.1 -->
                    
                <!-- LLMs: 3.3 -->
                    
                <!-- Quantum Computing: 2.5 -->
                    
                <!-- HPO and AutoML: 2.3 -->
                    
                <!-- Blockchain: 2.1 -->
                    
                <!-- GNN: 2.1 -->
                    
                <!-- Computer Vision: 2.0 -->
                    
                <!-- Decision Trees: 2.0 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Game Theory: 1.1 -->
                    
                <!-- Cryptography: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Networks: 1.1 -->
                    
                <!-- Datasets: 1.0 -->
                    
                <!-- RAG: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18850" target="_blank" rel="noopener noreferrer">The Theory of the Unique Latent Pattern: A Formal Epistemic Framework for Structural Singularity in Complex Systems</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Mohamed Aly Bouke
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper introduces the Theory of the Unique Latent Pattern (ULP), a formal epistemic framework that redefines the origin of apparent complexity in dynamic systems. Rather than attributing unpredictability to intrinsic randomness or emergent nonlinearity, ULP asserts that every analyzable system i</span>
                
                <span class="abstract-full" style="display: none;">This paper introduces the Theory of the Unique Latent Pattern (ULP), a formal epistemic framework that redefines the origin of apparent complexity in dynamic systems. Rather than attributing unpredictability to intrinsic randomness or emergent nonlinearity, ULP asserts that every analyzable system is governed by a structurally unique, deterministic generative mechanism, one that remains hidden not due to ontological indeterminacy, but due to epistemic constraints. The theory is formalized using a non-universal generative mapping \( \mathcal{F}_S(P_S, t) \), where each system \( S \) possesses its own latent structure \( P_S \), irreducible and non-replicable across systems. Observed irregularities are modeled as projections of this generative map through observer-limited interfaces, introducing epistemic noise \( \varepsilon_S(t) \) as a measure of incomplete access. By shifting the locus of uncertainty from the system to the observer, ULP reframes chaos as a context-relative failure of representation. We contrast this position with foundational paradigms in chaos theory, complexity science, and statistical learning. While they assume or model shared randomness or collective emergence, ULP maintains that every instance harbors a singular structural identity. Although conceptual, the theory satisfies the criterion of falsifiability in the Popperian sense, it invites empirical challenge by asserting that no two systems governed by distinct latent mechanisms will remain indistinguishable under sufficient resolution. This opens avenues for structurally individuated models in AI, behavioral inference, and epistemic diagnostics.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 3.2 -->
                    
                <!-- Medicine: 2.0 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Bayesian Optimization: 1.9 -->
                    
                <!-- Networks: 1.8 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Game Theory: 1.7 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Cryptography: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Math: 1.4 -->
                    
                <!-- Finance: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Datasets: 1.0 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                <!-- Hardware: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18854" target="_blank" rel="noopener noreferrer">Three-Dimensional Nonlinear Guidance with Impact Time and Field-of-view Constraints</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ashok R Samrat, Swati Singh, Shashi Ranjan Kumar
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper addresses the time-constrained interception of targets at a predetermined time with bounded field-of-view capability of the seeker-equipped interceptors. We propose guidance laws using the effective lead angle and velocity lead angles of the interceptor to achieve a successful interceptio</span>
                
                <span class="abstract-full" style="display: none;">This paper addresses the time-constrained interception of targets at a predetermined time with bounded field-of-view capability of the seeker-equipped interceptors. We propose guidance laws using the effective lead angle and velocity lead angles of the interceptor to achieve a successful interception of the target. The former scheme extends the existing two-dimensional guidance strategy to a three-dimensional setting. We have shown that such an extension may result in high-frequency switching in the input demand, which may degrade the interceptor's performance. To overcome the potential limitations of such a guidance strategy, we propose an elegant solution using the velocity lead angles and the range error with a backstepping technique. Using the velocity lead angles as virtual inputs, the effective lead angle profile is subsequently regulated to satisfy the seeker's field-of-view bound. Unlike the existing strategies, the proposed guidance strategy does not rely on the time-to-go estimate, which is an appealing feature of the design, as the time-to-go estimate may not always be available with high precision. We provide a theoretical analysis of the error variable and subsequently analytically derive the bounds on achievable impact times. Numerical simulations are performed to support the theoretical findings. The performance of the proposed guidance strategy is compared with that of an existing one, and it has been shown to yield better performance. Finally, a study on different choices of virtual inputs is also provided.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Math: 3.8 -->
                    
                <!-- Networks: 3.7 -->
                    
                <!-- Reinforcement Learning: 3.4 -->
                    
                <!-- Federated Learning: 2.9 -->
                    
                <!-- Cryptography: 2.8 -->
                    
                <!-- Finance: 2.0 -->
                    
                <!-- Bayesian Optimization: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Game Theory: 1.3 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Medicine: 1.1 -->
                    
                <!-- Pathfinding: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18857" target="_blank" rel="noopener noreferrer">Hierarchical-embedding autoencoder with a predictor (HEAP) as efficient architecture for learning long-term evolution of complex multi-scale physical systems</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Alexander Khrabry, Edward Startsev, Andrew Powis, Igor Kaganovich
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We propose a novel efficient architecture for learning long-term evolution in complex multi-scale physical systems which is based on the idea of separation of scales. Structures of various scales that dynamically emerge in the system interact with each other only locally. Structures of similar scale</span>
                
                <span class="abstract-full" style="display: none;">We propose a novel efficient architecture for learning long-term evolution in complex multi-scale physical systems which is based on the idea of separation of scales. Structures of various scales that dynamically emerge in the system interact with each other only locally. Structures of similar scale can interact directly when they are in contact and indirectly when they are parts of larger structures that interact directly. This enables modeling a multi-scale system in an efficient way, where interactions between small-scale features that are apart from each other do not need to be modeled. The hierarchical fully-convolutional autoencoder transforms the state of a physical system not just into a single embedding layer, as it is done conventionally, but into a series of embedding layers which encode structures of various scales preserving spatial information at a corresponding resolution level. Shallower layers embed smaller structures on a finer grid, while deeper layers embed larger structures on a coarser grid. The predictor advances all embedding layers in sync. Interactions between features of various scales are modeled using a combination of convolutional operators. We compare the performance of our model to variations of a conventional ResNet architecture in application to the Hasegawa-Wakatani turbulence. A multifold improvement in long-term prediction accuracy was observed for crucial statistical characteristics of this system.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 3.3 -->
                    
                <!-- Federated Learning: 3.2 -->
                    
                <!-- Evolutionary Algorithms: 2.9 -->
                    
                <!-- LLMs: 2.3 -->
                    
                <!-- Bayesian Optimization: 2.2 -->
                    
                <!-- Reinforcement Learning: 2.0 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Networks: 1.8 -->
                    
                <!-- Game Theory: 1.7 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Math: 1.3 -->
                    
                <!-- Hardware: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18861" target="_blank" rel="noopener noreferrer">Securing Credit Inquiries: The Role of Real-Time User Approval in Preventing SSN Identity Theft</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Gogulakrishnan Thiyagarajan, Vinay Bist, Prabhudarshi Nayak
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Unauthorized credit inquiries are also a central entry point for identity theft, with Social Security Numbers (SSNs) being widely utilized in fraudulent cases. Traditional credit inquiry systems do not usually possess strict user authentication, making them vulnerable to unauthorized access. This pa</span>
                
                <span class="abstract-full" style="display: none;">Unauthorized credit inquiries are also a central entry point for identity theft, with Social Security Numbers (SSNs) being widely utilized in fraudulent cases. Traditional credit inquiry systems do not usually possess strict user authentication, making them vulnerable to unauthorized access. This paper proposes a real-time user authorization system to enhance security by enforcing explicit user approval before processing any credit inquiry. The system employs real-time verification and approval techniques. This ensures that the authorized user only approves or rejects a credit check request. It minimizes the risks of interference by third parties. Apart from enhancing security, this system complies with regulations like the General Data Protection Regulation (GDPR) and the Fair Credit Reporting Act (FCRA) while maintaining a seamless user experience. This article discusses the technical issues, scaling-up issues, and ways of implementing real-time user authorization in financial systems. Through this framework, financial institutions can drastically minimize the risk of identity theft, avert unauthorized credit checks, and increase customer trust in the credit verification system.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.5 -->
                    
                <!-- Medicine: 3.2 -->
                    
                <!-- Blockchain: 2.2 -->
                    
                <!-- Networks: 2.2 -->
                    
                <!-- Cryptography: 1.9 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Game Theory: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Finance: 1.2 -->
                    
                <!-- Math: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18872" target="_blank" rel="noopener noreferrer">Zero Trust Cybersecurity: Procedures and Considerations in Context</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Brady D. Lund, Tae Hee Lee, Ziang Wang, Ting Wang, Nishith Reddy Mannuru
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In response to the increasing complexity and sophistication of cyber threats, particularly those enhanced by advancements in artificial intelligence, traditional security methods are proving insufficient. This paper explores the Zero Trust cybersecurity framework, which operates on the principle of </span>
                
                <span class="abstract-full" style="display: none;">In response to the increasing complexity and sophistication of cyber threats, particularly those enhanced by advancements in artificial intelligence, traditional security methods are proving insufficient. This paper explores the Zero Trust cybersecurity framework, which operates on the principle of never trust, always verify to mitigate vulnerabilities within organizations. Specifically, it examines the applicability of Zero Trust principles in environments where large volumes of information are exchanged, such as schools and libraries. The discussion highlights the importance of continuous authentication, least privilege access, and breach assumption. The findings underscore avenues for future research that may help preserve the security of these vulnerable organizations.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.8 -->
                    
                <!-- Blockchain: 4.0 -->
                    
                <!-- Medicine: 2.7 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Quantum Computing: 2.0 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.4 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Math: 1.2 -->
                    
                <!-- Game Theory: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18876" target="_blank" rel="noopener noreferrer">DiffusionRL: Efficient Training of Diffusion Policies for Robotic Grasping Using RL-Adapted Large-Scale Datasets</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Maria Makarova, Qian Liu, Dzmitry Tsetserukou
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Diffusion models have been successfully applied in areas such as image, video, and audio generation. Recent works show their promise for sequential decision-making and dexterous manipulation, leveraging their ability to model complex action distributions. However, challenges persist due to the data </span>
                
                <span class="abstract-full" style="display: none;">Diffusion models have been successfully applied in areas such as image, video, and audio generation. Recent works show their promise for sequential decision-making and dexterous manipulation, leveraging their ability to model complex action distributions. However, challenges persist due to the data limitations and scenario-specific adaptation needs. In this paper, we address these challenges by proposing an optimized approach to training diffusion policies using large, pre-built datasets that are enhanced using Reinforcement Learning (RL). Our end-to-end pipeline leverages RL-based enhancement of the DexGraspNet dataset, lightweight diffusion policy training on a dexterous manipulation task for a five-fingered robotic hand, and a pose sampling algorithm for validation. The pipeline achieved a high success rate of 80% for three DexGraspNet objects. By eliminating manual data collection, our approach lowers barriers to adopting diffusion models in robotics, enhancing generalization and robustness for real-world applications.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.7 -->
                    
                <!-- Medicine: 4.5 -->
                    
                <!-- Hardware: 2.4 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- T2I: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18879" target="_blank" rel="noopener noreferrer">Efficient Online Random Sampling via Randomness Recycling</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Thomas L. Draper, Feras A. Saad
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">``Randomness recycling'' is a powerful algorithmic technique for reusing a fraction of the random information consumed by a randomized algorithm to reduce its entropy requirements. This article presents a family of efficient randomness recycling algorithms for sampling a sequence $X_1, X_2, X_3, \do</span>
                
                <span class="abstract-full" style="display: none;">``Randomness recycling'' is a powerful algorithmic technique for reusing a fraction of the random information consumed by a randomized algorithm to reduce its entropy requirements. This article presents a family of efficient randomness recycling algorithms for sampling a sequence $X_1, X_2, X_3, \dots$ of discrete random variables whose joint distribution follows an arbitrary stochastic process. We develop randomness recycling strategies to reduce the entropy cost of a variety of prominent sampling algorithms, which include uniform sampling, inverse transform sampling, lookup table sampling, alias sampling, and discrete distribution generating (DDG) tree sampling. Our method achieves an expected amortized entropy cost of $H(X_1,\dots,X_k)/k + \varepsilon$ input random bits per output sample using $O(\log(1/\varepsilon))$ space, which is arbitrarily close to the optimal Shannon entropy rate. The combination of space, time, and entropy properties of our method improve upon the Han and Hoshi interval algorithm and Knuth and Yao entropy-optimal algorithm for sampling a discrete random sequence. An empirical evaluation of the algorithm shows that it achieves state-of-the-art runtime performance on the Fisher-Yates shuffle when using a cryptographically secure pseudorandom number generator. Accompanying the manuscript is a performant random sampling library in the C programming language.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Evolutionary Algorithms: 3.2 -->
                    
                <!-- Federated Learning: 3.2 -->
                    
                <!-- Medicine: 2.6 -->
                    
                <!-- Networks: 2.5 -->
                    
                <!-- LLMs: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- Math: 1.6 -->
                    
                <!-- Bayesian Optimization: 1.6 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Finance: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Cryptography: 1.2 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                <!-- Datasets: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18884" target="_blank" rel="noopener noreferrer">LORE: Lagrangian-Optimized Robust Embeddings for Visual Encoders</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Borna Khodabandeh, Amirabbas Afzali, Amirhossein Afsharrad, Seyed Shahabeddin Mousavi, Sanjay Lall, Sajjad Amini, Seyed-Mohsen Moosavi-Dezfooli
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Visual encoders have become fundamental components in modern computer vision pipelines. However, ensuring robustness against adversarial perturbations remains a critical challenge. Recent efforts have explored both supervised and unsupervised adversarial fine-tuning strategies. We identify two key l</span>
                
                <span class="abstract-full" style="display: none;">Visual encoders have become fundamental components in modern computer vision pipelines. However, ensuring robustness against adversarial perturbations remains a critical challenge. Recent efforts have explored both supervised and unsupervised adversarial fine-tuning strategies. We identify two key limitations in these approaches: (i) they often suffer from instability, especially during the early stages of fine-tuning, resulting in suboptimal convergence and degraded performance on clean data, and (ii) they exhibit a suboptimal trade-off between robustness and clean data accuracy, hindering the simultaneous optimization of both objectives. To overcome these challenges, we propose Lagrangian-Optimized Robust Embeddings (LORE), a novel unsupervised adversarial fine-tuning framework. LORE utilizes constrained optimization, which offers a principled approach to balancing competing goals, such as improving robustness while preserving nominal performance. By enforcing embedding-space proximity constraints, LORE effectively maintains clean data performance throughout adversarial fine-tuning. Extensive experiments show that LORE significantly improves zero-shot adversarial robustness with minimal degradation in clean data accuracy. Furthermore, we demonstrate the effectiveness of the adversarially fine-tuned CLIP image encoder in out-of-distribution generalization and enhancing the interpretability of image embeddings.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.8 -->
                    
                <!-- Medicine: 2.7 -->
                    
                <!-- Blockchain: 2.5 -->
                    
                <!-- Computer Vision: 2.4 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18885" target="_blank" rel="noopener noreferrer">The Parameterized Complexity of Computing the Linear Vertex Arboricity</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Alexander Erhardt, Alexander Wolff
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The \emph{linear vertex arboricity} of a graph is the smallest number of sets into which the vertices of a graph can be partitioned so that each of these sets induces a linear forest. Chaplick et al. [JoCG 2020] showed that, somewhat surprisingly, the linear vertex arboricity of a graph is the same </span>
                
                <span class="abstract-full" style="display: none;">The \emph{linear vertex arboricity} of a graph is the smallest number of sets into which the vertices of a graph can be partitioned so that each of these sets induces a linear forest. Chaplick et al. [JoCG 2020] showed that, somewhat surprisingly, the linear vertex arboricity of a graph is the same as the \emph{3D weak line cover number} of the graph, that is, the minimum number of straight lines necessary to cover the vertices of a crossing-free straight-line drawing of the graph in $\mathbb{R}^3$. Chaplick et al. [JGAA 2023] showed that deciding whether a given graph has linear vertex arboricity 2 is NP-hard.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Math: 4.3 -->
                    
                <!-- Networks: 3.9 -->
                    
                <!-- Cryptography: 3.0 -->
                    
                <!-- Bayesian Optimization: 2.8 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- GNN: 2.2 -->
                    
                <!-- Game Theory: 2.0 -->
                    
                <!-- Pathfinding: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Finance: 1.5 -->
                    
                <!-- Medicine: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- LLMs: 1.3 -->
                    
                <!-- Hardware: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18892" target="_blank" rel="noopener noreferrer">Climate Implications of Diffusion-based Generative Visual AI Systems and their Mass Adoption</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Vanessa Utz, Steve DiPaola
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Climate implications of rapidly developing digital technologies, such as blockchains and the associated crypto mining and NFT minting, have been well documented and their massive GPU energy use has been identified as a cause for concern. However, we postulate that due to their more mainstream consum</span>
                
                <span class="abstract-full" style="display: none;">Climate implications of rapidly developing digital technologies, such as blockchains and the associated crypto mining and NFT minting, have been well documented and their massive GPU energy use has been identified as a cause for concern. However, we postulate that due to their more mainstream consumer appeal, the GPU use of text-prompt based diffusion AI art systems also requires thoughtful considerations. Given the recent explosion in the number of highly sophisticated generative art systems and their rapid adoption by consumers and creative professionals, the impact of these systems on the climate needs to be carefully considered. In this work, we report on the growth of diffusion-based visual AI systems, their patterns of use, growth and the implications on the climate. Our estimates show that the mass adoption of these tools potentially contributes considerably to global energy consumption. We end this paper with our thoughts on solutions and future areas of inquiry as well as associated difficulties, including the lack of publicly available data.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 4.5 -->
                    
                <!-- LLMs: 3.8 -->
                    
                <!-- Blockchain: 3.3 -->
                    
                <!-- Hardware: 2.8 -->
                    
                <!-- Evolutionary Algorithms: 2.7 -->
                    
                <!-- Medicine: 2.3 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18894" target="_blank" rel="noopener noreferrer">Digital Overconsumption and Waste: A Closer Look at the Impacts of Generative AI</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Vanessa Utz, Steve DiPaola
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Generative Artificial Intelligence (AI) systems currently contribute negatively to the production of digital waste, via the associated energy consumption and the related CO2 emissions. At this moment, a discussion is urgently needed on the replication of harmful consumer behavior, such as overconsum</span>
                
                <span class="abstract-full" style="display: none;">Generative Artificial Intelligence (AI) systems currently contribute negatively to the production of digital waste, via the associated energy consumption and the related CO2 emissions. At this moment, a discussion is urgently needed on the replication of harmful consumer behavior, such as overconsumption, in the digital space. We outline our previous work on the climate implications of commercially available generative AI systems and the sentiment of generative AI users when confronted with AI-related climate research. We expand on this work via a discussion of digital overconsumption and waste, other related societal impacts, and a possible solution pathway</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 3.9 -->
                    
                <!-- Blockchain: 3.3 -->
                    
                <!-- LLMs: 3.2 -->
                    
                <!-- Federated Learning: 3.1 -->
                    
                <!-- Evolutionary Algorithms: 2.3 -->
                    
                <!-- Hardware: 2.3 -->
                    
                <!-- Reinforcement Learning: 1.8 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Math: 1.2 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18903" target="_blank" rel="noopener noreferrer">StandUp4AI: A New Multilingual Dataset for Humor Detection in Stand-up Comedy Videos</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Valentin Barriere, Nahuel Gomez, Leo Hemamou, Sofia Callejas, Brian Ravenet
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Aiming towards improving current computational models of humor detection, we propose a new multimodal dataset of stand-up comedies, in seven languages: English, French, Spanish, Italian, Portuguese, Hungarian and Czech. Our dataset of more than 330 hours, is at the time of writing the biggest availa</span>
                
                <span class="abstract-full" style="display: none;">Aiming towards improving current computational models of humor detection, we propose a new multimodal dataset of stand-up comedies, in seven languages: English, French, Spanish, Italian, Portuguese, Hungarian and Czech. Our dataset of more than 330 hours, is at the time of writing the biggest available for this type of task, and the most diverse. The whole dataset is automatically annotated in laughter (from the audience), and the subpart left for model validation is manually annotated. Contrary to contemporary approaches, we do not frame the task of humor detection as a binary sequence classification, but as word-level sequence labeling, in order to take into account all the context of the sequence and to capture the continuous joke tagging mechanism typically occurring in natural conversations. As par with unimodal baselines results, we propose a method for e propose a method to enhance the automatic laughter detection based on Audio Speech Recognition errors. Our code and data are available online: https://tinyurl.com/EMNLPHumourStandUpPublic</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.0 -->
                    
                <!-- LLMs: 3.0 -->
                    
                <!-- Federated Learning: 2.6 -->
                    
                <!-- Computer Vision: 2.4 -->
                    
                <!-- Datasets: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Quantum Computing: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18912" target="_blank" rel="noopener noreferrer">Robust Stability Analysis of Positive Lure System with Neural Network Feedback</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Hamidreza Montazeri Hedesh, Moh. Kamalul Wafi, Bahram Shafai, Milad Siami
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper investigates the robustness of the Lur'e problem under positivity constraints, drawing on results from the positive Aizerman conjecture and the robustness properties of Metzler matrices. Specifically, we consider a control system of Lur'e type in which not only the linear part includes pa</span>
                
                <span class="abstract-full" style="display: none;">This paper investigates the robustness of the Lur'e problem under positivity constraints, drawing on results from the positive Aizerman conjecture and the robustness properties of Metzler matrices. Specifically, we consider a control system of Lur'e type in which not only the linear part includes parametric uncertainty but also the nonlinear sector bound is unknown. We investigate tools from positive linear systems to effectively solve the problems in complicated and uncertain nonlinear systems. By leveraging the positivity characteristic of the system, we derive an explicit formula for the stability radius of Lur'e systems. Furthermore, we extend our analysis to systems with neural network (NN) feedback loops. Building on this approach, we also propose a refinement method for sector bounds of feedforward neural networks (FFNNs). This study introduces a scalable and efficient approach for robustness analysis of both Lur'e and NN-controlled systems. Finally, the proposed results are supported by illustrative examples.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 3.9 -->
                    
                <!-- Federated Learning: 2.9 -->
                    
                <!-- Reinforcement Learning: 2.7 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- LLMs: 1.8 -->
                    
                <!-- Bayesian Optimization: 1.8 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Math: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18925" target="_blank" rel="noopener noreferrer">Words as Geometric Features: Estimating Homography using Optical Character Recognition as Compressed Image Representation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ross Greer, Alisha Ukani, Katherine Izhikevich, Earlence Fernandes, Stefan Savage, Alex C. Snoeren
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Document alignment and registration play a crucial role in numerous real-world applications, such as automated form processing, anomaly detection, and workflow automation. Traditional methods for document alignment rely on image-based features like keypoints, edges, and textures to estimate geometri</span>
                
                <span class="abstract-full" style="display: none;">Document alignment and registration play a crucial role in numerous real-world applications, such as automated form processing, anomaly detection, and workflow automation. Traditional methods for document alignment rely on image-based features like keypoints, edges, and textures to estimate geometric transformations, such as homographies. However, these approaches often require access to the original document images, which may not always be available due to privacy, storage, or transmission constraints. This paper introduces a novel approach that leverages Optical Character Recognition (OCR) outputs as features for homography estimation. By utilizing the spatial positions and textual content of OCR-detected words, our method enables document alignment without relying on pixel-level image data. This technique is particularly valuable in scenarios where only OCR outputs are accessible. Furthermore, the method is robust to OCR noise, incorporating RANSAC to handle outliers and inaccuracies in the OCR data. On a set of test documents, we demonstrate that our OCR-based approach even performs more accurately than traditional image-based methods, offering a more efficient and scalable solution for document registration tasks. The proposed method facilitates applications in document processing, all while reducing reliance on high-dimensional image data.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 3.3 -->
                    
                <!-- Computer Vision: 3.2 -->
                    
                <!-- Medicine: 2.1 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18945" target="_blank" rel="noopener noreferrer">Echo Planning for Autonomous Driving: From Current Observations to Future Trajectories and Back</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jintao Sun, Hu Zhang, Gangyi Ding, Zhedong Zheng
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Modern end-to-end autonomous driving systems suffer from a critical limitation: their planners lack mechanisms to enforce temporal consistency between predicted trajectories and evolving scene dynamics. This absence of self-supervision allows early prediction errors to compound catastrophically over</span>
                
                <span class="abstract-full" style="display: none;">Modern end-to-end autonomous driving systems suffer from a critical limitation: their planners lack mechanisms to enforce temporal consistency between predicted trajectories and evolving scene dynamics. This absence of self-supervision allows early prediction errors to compound catastrophically over time. We introduce Echo Planning, a novel self-correcting framework that establishes a closed-loop Current - Future - Current (CFC) cycle to harmonize trajectory prediction with scene coherence. Our key insight is that plausible future trajectories must be bi-directionally consistent, ie, not only generated from current observations but also capable of reconstructing them. The CFC mechanism first predicts future trajectories from the Bird's-Eye-View (BEV) scene representation, then inversely maps these trajectories back to estimate the current BEV state. By enforcing consistency between the original and reconstructed BEV representations through a cycle loss, the framework intrinsically penalizes physically implausible or misaligned trajectories. Experiments on nuScenes demonstrate state-of-the-art performance, reducing L2 error by 0.04 m and collision rate by 0.12% compared to one-shot planners. Crucially, our method requires no additional supervision, leveraging the CFC cycle as an inductive bias for robust planning. This work offers a deployable solution for safety-critical autonomous systems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 3.9 -->
                    
                <!-- Medicine: 3.0 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- 3D: 2.2 -->
                    
                <!-- GNN: 2.2 -->
                    
                <!-- Quantum Computing: 2.1 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Networks: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18946" target="_blank" rel="noopener noreferrer">SANNet: A Semantic-Aware Agentic AI Networking Framework for Multi-Agent Cross-Layer Coordination</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yong Xiao, Haoran Zhou, Xubo Li, Yayu Gao, Guangming Shi, Ping Zhang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Agentic AI networking (AgentNet) is a novel AI-native networking paradigm that relies on a large number of specialized AI agents to collaborate and coordinate for autonomous decision-making, dynamic environmental adaptation, and complex goal achievement. It has the potential to facilitate real-time </span>
                
                <span class="abstract-full" style="display: none;">Agentic AI networking (AgentNet) is a novel AI-native networking paradigm that relies on a large number of specialized AI agents to collaborate and coordinate for autonomous decision-making, dynamic environmental adaptation, and complex goal achievement. It has the potential to facilitate real-time network management alongside capabilities for self-configuration, self-optimization, and self-adaptation across diverse and complex networking environments, laying the foundation for fully autonomous networking systems in the future. Despite its promise, AgentNet is still in the early stage of development, and there still lacks an effective networking framework to support automatic goal discovery and multi-agent self-orchestration and task assignment. This paper proposes SANNet, a novel semantic-aware agentic AI networking architecture that can infer the semantic goal of the user and automatically assign agents associated with different layers of a mobile system to fulfill the inferred goal. Motivated by the fact that one of the major challenges in AgentNet is that different agents may have different and even conflicting objectives when collaborating for certain goals, we introduce a dynamic weighting-based conflict-resolving mechanism to address this issue. We prove that SANNet can provide theoretical guarantee in both conflict-resolving and model generalization performance for multi-agent collaboration in dynamic environment. We develop a hardware prototype of SANNet based on the open RAN and 5GS core platform. Our experimental results show that SANNet can significantly improve the performance of multi-agent networking systems, even when agents with conflicting objectives are selected to collaborate for the same goal.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 3.9 -->
                    
                <!-- Medicine: 3.2 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18952" target="_blank" rel="noopener noreferrer">Online Knowledge Distillation with Reward Guidance</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Chen Jia
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This work studies knowledge distillation (KD) for large language models (LLMs) through preference optimization. We propose a reward-guided imitation learning framework for sequential KD, formulating a min-max optimization problem between the policy and reward model (RM) to minimize the performance g</span>
                
                <span class="abstract-full" style="display: none;">This work studies knowledge distillation (KD) for large language models (LLMs) through preference optimization. We propose a reward-guided imitation learning framework for sequential KD, formulating a min-max optimization problem between the policy and reward model (RM) to minimize the performance gap between the student and teacher policies. Specifically, the reward optimization is constrained to achieve near-optimality within a confidence set for preference alignment. For preference data construction, we explore both offline and online preference-based KD. Additionally, we reformulate the RM using the $Q$-value function and extend the framework to white-box KD, where the teacher policy's predicted probabilities are accessible. Theoretical analysis and empirical results demonstrate the effectiveness of the proposed framework.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 3.2 -->
                    
                <!-- Computer Vision: 2.9 -->
                    
                <!-- Reinforcement Learning: 2.6 -->
                    
                <!-- LLMs: 2.6 -->
                    
                <!-- Bayesian Optimization: 2.5 -->
                    
                <!-- Federated Learning: 2.5 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18975" target="_blank" rel="noopener noreferrer">FastMamba: A High-Speed and Efficient Mamba Accelerator on FPGA with Accurate Quantization</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Aotao Wang, Haikuo Shao, Shaobo Ma, Zhongfeng Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">State Space Models (SSMs), like recent Mamba2, have achieved remarkable performance and received extensive attention. However, deploying Mamba2 on resource-constrained edge devices encounters many problems: severe outliers within the linear layer challenging the quantization, diverse and irregular e</span>
                
                <span class="abstract-full" style="display: none;">State Space Models (SSMs), like recent Mamba2, have achieved remarkable performance and received extensive attention. However, deploying Mamba2 on resource-constrained edge devices encounters many problems: severe outliers within the linear layer challenging the quantization, diverse and irregular element-wise tensor operations, and hardware-unfriendly nonlinear functions in the SSM block. To address these issues, this paper presents FastMamba, a dedicated accelerator on FPGA with hardware-algorithm co-design to promote the deployment efficiency of Mamba2. Specifically, we successfully achieve 8-bit quantization for linear layers through Hadamard transformation to eliminate outliers. Moreover, a hardware-friendly and fine-grained power-of-two quantization framework is presented for the SSM block and convolution layer, and a first-order linear approximation is developed to optimize the nonlinear functions. Based on the accurate algorithm quantization, we propose an accelerator that integrates parallel vector processing units, pipelined execution dataflow, and an efficient SSM Nonlinear Approximation Unit, which enhances computational efficiency and reduces hardware complexity. Finally, we evaluate FastMamba on Xilinx VC709 FPGA. For the input prefill task on Mamba2-130M, FastMamba achieves 68.80\times and 8.90\times speedup over Intel Xeon 4210R CPU and NVIDIA RTX 3090 GPU, respectively. In the output decode experiment with Mamba2-2.7B, FastMamba attains 6\times higher energy efficiency than RTX 3090 GPU.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.7 -->
                    
                <!-- Computer Vision: 3.5 -->
                    
                <!-- Hardware: 3.3 -->
                    
                <!-- LLMs: 2.5 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18980" target="_blank" rel="noopener noreferrer">Improving Anomalous Sound Detection through Pseudo-anomalous Set Selection and Pseudo-label Utilization under Unlabeled Conditions</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ibuki Kuroyanagi, Takuya Fujimura, Kazuya Takeda, Tomoki Toda
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper addresses performance degradation in anomalous sound detection (ASD) when neither sufficiently similar machine data nor operational state labels are available. We present an integrated pipeline that combines three complementary components derived from prior work and extends them to the un</span>
                
                <span class="abstract-full" style="display: none;">This paper addresses performance degradation in anomalous sound detection (ASD) when neither sufficiently similar machine data nor operational state labels are available. We present an integrated pipeline that combines three complementary components derived from prior work and extends them to the unlabeled ASD setting. First, we adapt an anomaly score based selector to curate external audio data resembling the normal sounds of the target machine. Second, we utilize triplet learning to assign pseudo-labels to unlabeled data, enabling finer classification of operational sounds and detection of subtle anomalies. Third, we employ iterative training to refine both the pseudo-anomalous set selection and pseudo-label assignment, progressively improving detection accuracy. Experiments on the DCASE2022-2024 Task 2 datasets demonstrate that, in unlabeled settings, our approach achieves an average AUC increase of over 6.6 points compared to conventional methods. In labeled settings, incorporating external data from the pseudo-anomalous set further boosts performance. These results highlight the practicality and robustness of our methods in scenarios with scarce machine data and labels, facilitating ASD deployment across diverse industrial settings with minimal annotation effort.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.0 -->
                    
                <!-- Computer Vision: 3.7 -->
                    
                <!-- LLMs: 3.6 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- Decision Trees: 1.8 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Robotics: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18984" target="_blank" rel="noopener noreferrer">Self-supervised learning method using multiple sampling strategies for general-purpose audio representation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ibuki Kuroyanagi, Tatsuya Komatsu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We propose a self-supervised learning method using multiple sampling strategies to obtain general-purpose audio representation. Multiple sampling strategies are used in the proposed method to construct contrastive losses from different perspectives and learn representations based on them. In this st</span>
                
                <span class="abstract-full" style="display: none;">We propose a self-supervised learning method using multiple sampling strategies to obtain general-purpose audio representation. Multiple sampling strategies are used in the proposed method to construct contrastive losses from different perspectives and learn representations based on them. In this study, in addition to the widely used clip-level sampling strategy, we introduce two new strategies, a frame-level strategy and a task-specific strategy. The proposed multiple strategies improve the performance of frame-level classification and other tasks like pitch detection, which are not the focus of the conventional single clip-level sampling strategy. We pre-trained the method on a subset of Audioset and applied it to a downstream task with frozen weights. The proposed method improved clip classification, sound event detection, and pitch detection performance by 25%, 20%, and 3.6%.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 3.5 -->
                    
                <!-- LLMs: 3.1 -->
                    
                <!-- Evolutionary Algorithms: 3.0 -->
                    
                <!-- Medicine: 3.0 -->
                    
                <!-- Computer Vision: 2.2 -->
                    
                <!-- Reinforcement Learning: 2.2 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.4 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18987" target="_blank" rel="noopener noreferrer">Error estimates for the interpolation and approximation of gradients and vector fields on protected Delaunay meshes in $\mathbb{R}^d$</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: David M. Williams, Mathijs Wintraecken
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">One frequently needs to interpolate or approximate gradients on simplicial meshes. Unfortunately, there are very few explicit mathematical results governing the interpolation or approximation of vector-valued functions on Delaunay meshes in more than two dimensions. Most of the existing results are </span>
                
                <span class="abstract-full" style="display: none;">One frequently needs to interpolate or approximate gradients on simplicial meshes. Unfortunately, there are very few explicit mathematical results governing the interpolation or approximation of vector-valued functions on Delaunay meshes in more than two dimensions. Most of the existing results are tailored towards interpolation with piecewise linear polynomials. In contrast, interpolation with piecewise high-order polynomials is not well understood. In particular, the results in this area are sometimes difficult to immediately interpret, or to specialize to the Delaunay setting. In order to address this issue, we derive explicit error estimates for high-order, piecewise polynomial gradient interpolation and approximation on protected Delaunay meshes. In addition, we generalize our analysis beyond gradients, and obtain error estimates for sufficiently-smooth vector fields. Throughout the paper, we show that the quality of interpolation and approximation often depends (in part) on the minimum thickness of simplices in the mesh. Fortunately, the minimum thickness can be precisely controlled on protected Delaunay meshes in $\mathbb{R}^d$.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 3.0 -->
                    
                <!-- Computer Vision: 2.4 -->
                    
                <!-- LLMs: 2.2 -->
                    
                <!-- Math: 2.1 -->
                    
                <!-- Medicine: 2.1 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Game Theory: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18988" target="_blank" rel="noopener noreferrer">NTIRE 2025 Challenge on Video Quality Enhancement for Video Conferencing: Datasets, Methods and Results</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Varun Jain, Zongwei Wu, Quan Zou, Louis Florentin, Henrik Turbell, Sandeep Siddhartha, Radu Timofte, others
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper presents a comprehensive review of the 1st Challenge on Video Quality Enhancement for Video Conferencing held at the NTIRE workshop at CVPR 2025, and highlights the problem statement, datasets, proposed solutions, and results. The aim of this challenge was to design a Video Quality Enhanc</span>
                
                <span class="abstract-full" style="display: none;">This paper presents a comprehensive review of the 1st Challenge on Video Quality Enhancement for Video Conferencing held at the NTIRE workshop at CVPR 2025, and highlights the problem statement, datasets, proposed solutions, and results. The aim of this challenge was to design a Video Quality Enhancement (VQE) model to enhance video quality in video conferencing scenarios by (a) improving lighting, (b) enhancing colors, (c) reducing noise, and (d) enhancing sharpness - giving a professional studio-like effect. Participants were given a differentiable Video Quality Assessment (VQA) model, training, and test videos. A total of 91 participants registered for the challenge. We received 10 valid submissions that were evaluated in a crowdsourced framework.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 3.5 -->
                    
                <!-- LLMs: 3.0 -->
                    
                <!-- Hardware: 2.3 -->
                    
                <!-- Blockchain: 2.0 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Computer Vision: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Networks: 1.2 -->
                    
                <!-- 3D: 1.1 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18994" target="_blank" rel="noopener noreferrer">Designing Pin-pression Gripper and Learning its Dexterous Grasping with Online In-hand Adjustment</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Hewen Xiao, Xiuping Liu, Hang Zhao, Jian Liu, Kai Xu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We introduce a novel design of parallel-jaw grippers drawing inspiration from pin-pression toys. The proposed pin-pression gripper features a distinctive mechanism in which each finger integrates a 2D array of pins capable of independent extension and retraction. This unique design allows the grippe</span>
                
                <span class="abstract-full" style="display: none;">We introduce a novel design of parallel-jaw grippers drawing inspiration from pin-pression toys. The proposed pin-pression gripper features a distinctive mechanism in which each finger integrates a 2D array of pins capable of independent extension and retraction. This unique design allows the gripper to instantaneously customize its finger's shape to conform to the object being grasped by dynamically adjusting the extension/retraction of the pins. In addition, the gripper excels in in-hand re-orientation of objects for enhanced grasping stability again via dynamically adjusting the pins. To learn the dynamic grasping skills of pin-pression grippers, we devise a dedicated reinforcement learning algorithm with careful designs of state representation and reward shaping. To achieve a more efficient grasp-while-lift grasping mode, we propose a curriculum learning scheme. Extensive evaluations demonstrate that our design, together with the learned skills, leads to highly flexible and robust grasping with much stronger generality to unseen objects than alternatives. We also highlight encouraging physical results of sim-to-real transfer on a physically manufactured pin-pression gripper, demonstrating the practical significance of our novel gripper design and grasping skill. Demonstration videos for this paper are available at https://github.com/siggraph-pin-pression-gripper/pin-pression-gripper-video.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 3.8 -->
                    
                <!-- Medicine: 3.1 -->
                    
                <!-- Reinforcement Learning: 2.7 -->
                    
                <!-- LLMs: 2.4 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.4 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18998" target="_blank" rel="noopener noreferrer">Property Directed Reachability with Extended Resolution</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Andrew Luka, Yakir Vizel
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Property Directed Reachability (\textsc{Pdr}), also known as IC3, is a state-of-the-art model checking algorithm widely used for verifying safety properties. While \textsc{Pdr} is effective in finding inductive invariants, its underlying proof system, Resolution, limits its ability to construct shor</span>
                
                <span class="abstract-full" style="display: none;">Property Directed Reachability (\textsc{Pdr}), also known as IC3, is a state-of-the-art model checking algorithm widely used for verifying safety properties. While \textsc{Pdr} is effective in finding inductive invariants, its underlying proof system, Resolution, limits its ability to construct short proofs for certain verification problems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.8 -->
                    
                <!-- HPO and AutoML: 3.4 -->
                    
                <!-- Medicine: 2.9 -->
                    
                <!-- Quantum Computing: 2.5 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- GNN: 2.3 -->
                    
                <!-- Blockchain: 2.1 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Bayesian Optimization: 1.8 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Networks: 1.1 -->
                    
                <!-- T2I: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18999" target="_blank" rel="noopener noreferrer">Lightweight Embeddings with Graph Rewiring for Collaborative Filtering</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Xurong Liang, Tong Chen, Wei Yuan, Hongzhi Yin
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">As recommendation services scale rapidly and their deployment now commonly involves resource-constrained edge devices, GNN-based recommender systems face significant challenges, including high embedding storage costs and runtime latency from graph propagations. Our previous work, LEGCF, effectively </span>
                
                <span class="abstract-full" style="display: none;">As recommendation services scale rapidly and their deployment now commonly involves resource-constrained edge devices, GNN-based recommender systems face significant challenges, including high embedding storage costs and runtime latency from graph propagations. Our previous work, LEGCF, effectively reduced embedding storage costs but struggled to maintain recommendation performance under stricter storage limits. Additionally, LEGCF did not address the extensive runtime computation costs associated with graph propagation, which involves heavy multiplication and accumulation operations (MACs). These challenges consequently hinder effective training and inference on resource-constrained edge devices. To address these limitations, we propose Lightweight Embeddings with Rewired Graph for Graph Collaborative Filtering (LERG), an improved extension of LEGCF. LERG retains LEGCFs compositional codebook structure but introduces quantization techniques to reduce the storage cost, enabling the inclusion of more meta-embeddings within the same storage. To optimize graph propagation, we pretrain the quantized compositional embedding table using the full interaction graph on resource-rich servers, after which a fine-tuning stage is engaged to identify and prune low-contribution entities via a gradient-free binary integer programming approach, constructing a rewired graph that excludes these entities (i.e., user/item nodes) from propagating signals. The quantized compositional embedding table with selective embedding participation and sparse rewired graph are transferred to edge devices which significantly reduce computation memory and inference time. Experiments on three public benchmark datasets, including an industry-scale dataset, demonstrate that LERG achieves superior recommendation performance while dramatically reducing storage and computation costs for graph-based recommendation services.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 5.0 -->
                    
                <!-- GNN: 4.9 -->
                    
                <!-- LLMs: 3.0 -->
                    
                <!-- Computer Vision: 2.6 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- HPO and AutoML: 2.0 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Datasets: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.19001" target="_blank" rel="noopener noreferrer">DARTH: Declarative Recall Through Early Termination for Approximate Nearest Neighbor Search</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Manos Chatzakis, Yannis Papakonstantinou, Themis Palpanas
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Approximate Nearest Neighbor Search (ANNS) presents an inherent tradeoff between performance and recall (i.e., result quality). Each ANNS algorithm provides its own algorithm-dependent parameters to allow applications to influence the recall/performance tradeoff of their searches. This situation is </span>
                
                <span class="abstract-full" style="display: none;">Approximate Nearest Neighbor Search (ANNS) presents an inherent tradeoff between performance and recall (i.e., result quality). Each ANNS algorithm provides its own algorithm-dependent parameters to allow applications to influence the recall/performance tradeoff of their searches. This situation is doubly problematic. First, the application developers have to experiment with these algorithm-dependent parameters to fine-tune the parameters that produce the desired recall for each use case. This process usually takes a lot of effort. Even worse, the chosen parameters may produce good recall for some queries, but bad recall for hard queries. To solve these problems, we present DARTH, a method that uses target declarative recall. DARTH uses a novel method for providing target declarative recall on top of an ANNS index by employing an adaptive early termination strategy integrated into the search algorithm. Through a wide range of experiments, we demonstrate that DARTH effectively meets user-defined recall targets while achieving significant speedups, up to 14.6x (average: 6.8x; median: 5.7x) faster than the search without early termination for HNSW and up to 41.8x (average: 13.6x; median: 8.1x) for IVF. This paper appeared in ACM SIGMOD 2026.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 3.2 -->
                    
                <!-- Medicine: 3.1 -->
                    
                <!-- Evolutionary Algorithms: 2.8 -->
                    
                <!-- LLMs: 2.6 -->
                    
                <!-- Quantum Computing: 2.2 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- 3D: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.19002" target="_blank" rel="noopener noreferrer">Semi-pessimistic Reinforcement Learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jin Zhu, Xin Zhou, Jiaang Yao, Gholamali Aminian, Omar Rivasplata, Simon Little, Lexin Li, Chengchun Shi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Offline reinforcement learning (RL) aims to learn an optimal policy from pre-collected data. However, it faces challenges of distributional shift, where the learned policy may encounter unseen scenarios not covered in the offline data. Additionally, numerous applications suffer from a scarcity of la</span>
                
                <span class="abstract-full" style="display: none;">Offline reinforcement learning (RL) aims to learn an optimal policy from pre-collected data. However, it faces challenges of distributional shift, where the learned policy may encounter unseen scenarios not covered in the offline data. Additionally, numerous applications suffer from a scarcity of labeled reward data. Relying on labeled data alone often leads to a narrow state-action distribution, further amplifying the distributional shift, and resulting in suboptimal policy learning. To address these issues, we first recognize that the volume of unlabeled data is typically substantially larger than that of labeled data. We then propose a semi-pessimistic RL method to effectively leverage abundant unlabeled data. Our approach offers several advantages. It considerably simplifies the learning process, as it seeks a lower bound of the reward function, rather than that of the Q-function or state transition function. It is highly flexible, and can be integrated with a range of model-free and model-based RL algorithms. It enjoys the guaranteed improvement when utilizing vast unlabeled data, but requires much less restrictive conditions. We compare our method with a number of alternative solutions, both analytically and numerically, and demonstrate its clear competitiveness. We further illustrate with an application to adaptive deep brain stimulation for Parkinson's disease.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Reinforcement Learning: 4.7 -->
                    
                <!-- Federated Learning: 3.2 -->
                    
                <!-- Medicine: 3.0 -->
                    
                <!-- LLMs: 2.9 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Bayesian Optimization: 1.6 -->
                    
                <!-- Networks: 1.2 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Robotics: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.19010" target="_blank" rel="noopener noreferrer">Co-AttenDWG: Co-Attentive Dimension-Wise Gating and Expert Fusion for Multi-Modal Offensive Content Detection</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Md. Mithun Hossain, Md. Shakil Hossain, Sudipto Chaki, M. F. Mridha
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Multi-modal learning has become a critical research area because integrating text and image data can significantly improve performance in tasks such as classification, retrieval, and scene understanding. However, despite progress with pre-trained models, current approaches are limited by inadequate </span>
                
                <span class="abstract-full" style="display: none;">Multi-modal learning has become a critical research area because integrating text and image data can significantly improve performance in tasks such as classification, retrieval, and scene understanding. However, despite progress with pre-trained models, current approaches are limited by inadequate cross-modal interactions and static fusion strategies that do not fully exploit the complementary nature of different modalities. To address these shortcomings, we introduce a novel multi-modal Co-AttenDWG architecture that leverages dual-path encoding, co-attention with dimension-wise gating, and advanced expert fusion. Our approach begins by projecting text and image features into a common embedding space, where a dedicated co-attention mechanism enables simultaneous, fine-grained interactions between modalities. This mechanism is further enhanced by a dimension-wise gating network that adaptively regulates the feature contributions at the channel level, ensuring that only the most relevant information is emphasized. In parallel, dual-path encoders refine the representations by processing cross-modal information separately before an additional cross-attention layer further aligns modalities. The refined features are then aggregated via an expert fusion module that combines learned gating and self-attention to produce a robust, unified representation. We validate our approach on the MIMIC and SemEval Memotion 1.0, where experimental results demonstrate significant improvements in cross-modal alignment and state-of-the-art performance, underscoring the potential of our model for a wide range of multi-modal applications.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.5 -->
                    
                <!-- LLMs: 4.2 -->
                    
                <!-- Quantum Computing: 2.0 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- 3D: 1.8 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.19013" target="_blank" rel="noopener noreferrer">Faithful Group Shapley Value</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Kiljae Lee, Ziqi Liu, Weijing Tang, Yuan Zhang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Data Shapley is an important tool for data valuation, which quantifies the contribution of individual data points to machine learning models. In practice, group-level data valuation is desirable when data providers contribute data in batch. However, we identify that existing group-level extensions o</span>
                
                <span class="abstract-full" style="display: none;">Data Shapley is an important tool for data valuation, which quantifies the contribution of individual data points to machine learning models. In practice, group-level data valuation is desirable when data providers contribute data in batch. However, we identify that existing group-level extensions of Data Shapley are vulnerable to shell company attacks, where strategic group splitting can unfairly inflate valuations. We propose Faithful Group Shapley Value (FGSV) that uniquely defends against such attacks. Building on original mathematical insights, we develop a provably fast and accurate approximation algorithm for computing FGSV. Empirical experiments demonstrate that our algorithm significantly outperforms state-of-the-art methods in computational efficiency and approximation accuracy, while ensuring faithful group-level valuation.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.9 -->
                    
                <!-- Medicine: 4.1 -->
                    
                <!-- Quantum Computing: 2.7 -->
                    
                <!-- Decision Trees: 2.7 -->
                    
                <!-- GNN: 2.6 -->
                    
                <!-- Federated Learning: 2.5 -->
                    
                <!-- Bayesian Optimization: 2.1 -->
                    
                <!-- HPO and AutoML: 2.0 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.19026" target="_blank" rel="noopener noreferrer">Staircase Recognition and Location Based on Polarization Vision</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Weifeng Kong, Zhiying Tan
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Staircase is one of the most common structures in artificial scenes. However, it is difficult for humanoid robots and people with lower limb disabilities or visual impairment to cross the scene without the help of sensors and intelligent algorithms. Staircase scene perception technology is a prerequ</span>
                
                <span class="abstract-full" style="display: none;">Staircase is one of the most common structures in artificial scenes. However, it is difficult for humanoid robots and people with lower limb disabilities or visual impairment to cross the scene without the help of sensors and intelligent algorithms. Staircase scene perception technology is a prerequisite for recognition and localization. This technology is of great significance for the mode switching of the robot and the calculation of the footprint position to adapt to the discontinuous terrain. However, there are still many problems that constrain the application of this technology, such as low recognition accuracy, high initial noise from sensors, unstable output signals and high computational requirements. In terms of scene reconstruction, the binocular and time of flight (TOF) reconstruction of the scene can be easily affected by environmental light and the surface material of the target object. In contrast, due to the special structure of the polarizer, the polarization can selectively transmit polarized light in a specific direction and this reconstruction method relies on the polarization information of the object surface. So the advantages of polarization reconstruction are reflected, which are less affected by environmental light and not dependent on the texture information of the object surface. In this paper, in order to achieve the detection of staircase, this paper proposes a contrast enhancement algorithm that integrates polarization and light intensity information, and integrates point cloud segmentation based on YOLOv11. To realize the high-quality reconstruction, we proposed a method of fusing polarized binocular and TOF depth information to realize the three-dimensional (3D) reconstruction of the staircase. Besides, it also proposes a joint calibration algorithm of monocular camera and TOF camera based on ICP registration and improved gray wolf optimization algorithm.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 4.6 -->
                    
                <!-- Medicine: 3.1 -->
                    
                <!-- Evolutionary Algorithms: 2.6 -->
                    
                <!-- Hardware: 2.5 -->
                    
                <!-- Bayesian Optimization: 2.2 -->
                    
                <!-- Reinforcement Learning: 1.9 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Math: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.19027" target="_blank" rel="noopener noreferrer">High Throughput QC-LDPC Decoder With Optimized Schedule Policy in Layered Decoding</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Dongxu Chang, Qingqing Peng, Guanghui Wang, Guiying Yan
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In this study, a scheduling policy of layered decoding for quasi-cycle (QC) low-density parity-check (LDPC) codes with high throughput and good performance is designed. The influence of scheduling on the delay of the decoder's hardware implementation and on the decoding performance are considered si</span>
                
                <span class="abstract-full" style="display: none;">In this study, a scheduling policy of layered decoding for quasi-cycle (QC) low-density parity-check (LDPC) codes with high throughput and good performance is designed. The influence of scheduling on the delay of the decoder's hardware implementation and on the decoding performance are considered simultaneously. Specifically, we analyze the idle time required under various scheduling sequences within a pipelined decoding architecture and formulate the problem as a traveling salesman problem (TSP) aiming at minimizing idle time. Furthermore, considering that different scheduling sequences can affect decoding performance, we refine the graph used to solve the TSP based on scheduling characteristics that promote improved decoding outcomes. Simulation results demonstrate that the identified scheduling sequence achieves a low number of hardware delays while maintaining excellent decoding performance for 5G New Radio (NR) LDPC codes.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 3.4 -->
                    
                <!-- Hardware: 2.4 -->
                    
                <!-- Medicine: 2.4 -->
                    
                <!-- Evolutionary Algorithms: 2.4 -->
                    
                <!-- Reinforcement Learning: 2.1 -->
                    
                <!-- LLMs: 2.1 -->
                    
                <!-- GNN: 2.1 -->
                    
                <!-- Bayesian Optimization: 1.6 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Networks: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.19036" target="_blank" rel="noopener noreferrer">Weak Physics Informed Neural Networks for Geometry Compatible Hyperbolic Conservation Laws on Manifolds</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Hanfei Zhou, Lei Shi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Physics-informed neural networks (PINNs), owing to their mesh-free nature, offer a powerful approach for solving high-dimensional partial differential equations (PDEs) in complex geometries, including irregular domains. This capability effectively circumvents the challenges of mesh generation that t</span>
                
                <span class="abstract-full" style="display: none;">Physics-informed neural networks (PINNs), owing to their mesh-free nature, offer a powerful approach for solving high-dimensional partial differential equations (PDEs) in complex geometries, including irregular domains. This capability effectively circumvents the challenges of mesh generation that traditional numerical methods face in high-dimensional or geometrically intricate settings. While recent studies have extended PINNs to manifolds, the theoretical foundations remain scarce. Existing theoretical analyses of PINNs in Euclidean space often rely on smoothness assumptions for the solutions. However, recent empirical evidence indicates that PINNs may struggle to approximate solutions with low regularity, such as those arising from nonlinear hyperbolic equations. In this paper, we develop a framework for PINNs tailored to the efficient approximation of weak solutions, particularly nonlinear hyperbolic equations defined on manifolds. We introduce a novel weak PINN (wPINN) formulation on manifolds that leverages the well-posedness theory to approximate entropy solutions of geometry-compatible hyperbolic conservation laws on manifolds. Employing tools from approximation theory, we establish a convergence analysis of the algorithm, including an analysis of approximation errors for time-dependent entropy solutions. This analysis provides insight into the accumulation of approximation errors over long time horizons. Notably, the network complexity depends only on the intrinsic dimension, independent of the ambient space dimension. Our results match the minimax rate in the d-dimensional Euclidean space, demonstrating that PINNs can alleviate the curse of dimensionality in the context of low-dimensional manifolds. Finally, we validate the performance of the proposed wPINN framework through numerical experiments, confirming its ability to efficiently approximate entropy solutions on manifolds.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 4.4 -->
                    
                <!-- GNN: 3.2 -->
                    
                <!-- Bayesian Optimization: 3.1 -->
                    
                <!-- Evolutionary Algorithms: 2.5 -->
                    
                <!-- Reinforcement Learning: 2.5 -->
                    
                <!-- Math: 2.0 -->
                    
                <!-- Medicine: 1.9 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- LLMs: 1.6 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Networks: 1.1 -->
                    
                <!-- Game Theory: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.0414
                </span>
                <a href="https://arxiv.org/abs/2505.13389" target="_blank" rel="noopener noreferrer">VSA: Faster Video Diffusion with Trainable Sparse Attention</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Peiyuan Zhang, Haofeng Huang, Yongqi Chen, Will Lin, Zhengzhong Liu, Ion Stoica, Eric Xing, Hao Zhang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Scaling video diffusion transformers (DiTs) is limited by their quadratic 3D attention, even though most of the attention mass concentrates on a small subset of positions. We turn this observation into VSA, a trainable, hardware-efficient sparse attention that replaces full attention at \emph{both} </span>
                
                <span class="abstract-full" style="display: none;">Scaling video diffusion transformers (DiTs) is limited by their quadratic 3D attention, even though most of the attention mass concentrates on a small subset of positions. We turn this observation into VSA, a trainable, hardware-efficient sparse attention that replaces full attention at \emph{both} training and inference. In VSA, a lightweight coarse stage pools tokens into tiles and identifies high-weight \emph{critical tokens}; a fine stage computes token-level attention only inside those tiles subjecting to block computing layout to ensure hard efficiency. This leads to a single differentiable kernel that trains end-to-end, requires no post-hoc profiling, and sustains 85\% of FlashAttention3 MFU. We perform a large sweep of ablation studies and scaling-law experiments by pretraining DiTs from 60M to 1.4B parameters. VSA reaches a Pareto point that cuts training FLOPS by 2.53$\times$ with no drop in diffusion loss. Retrofitting the open-source Wan-2.1 model speeds up attention time by 6$\times$ and lowers end-to-end generation time from 31s to 18s with comparable quality. These results establish trainable sparse attention as a practical alternative to full attention and a key enabler for further scaling of video diffusion models. Code will be available at https://github.com/hao-ai-lab/FastVideo.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.2%">
                            LLMs
                        </span>
                <!-- Medicine: 3.1 -->
                    
                <!-- 3D: 2.4 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Networks: 1.2 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                <!-- Computer Vision: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.0619
                </span>
                <a href="https://arxiv.org/abs/2505.19313" target="_blank" rel="noopener noreferrer">Concept Reachability in Diffusion Models: Beyond Dataset Constraints</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Marta Aparicio Rodriguez, Xenia Miscouridou, Anastasia Borovykh
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Despite significant advances in quality and complexity of the generations in text-to-image models, prompting does not always lead to the desired outputs. Controlling model behaviour by directly steering intermediate model activations has emerged as a viable alternative allowing to reach concepts in </span>
                
                <span class="abstract-full" style="display: none;">Despite significant advances in quality and complexity of the generations in text-to-image models, prompting does not always lead to the desired outputs. Controlling model behaviour by directly steering intermediate model activations has emerged as a viable alternative allowing to reach concepts in latent space that may otherwise remain inaccessible by prompt. In this work, we introduce a set of experiments to deepen our understanding of concept reachability. We design a training data setup with three key obstacles: scarcity of concepts, underspecification of concepts in the captions, and data biases with tied concepts. Our results show: (i) concept reachability in latent space exhibits a distinct phase transition, with only a small number of samples being sufficient to enable reachability, (ii) where in the latent space the intervention is performed critically impacts reachability, showing that certain concepts are reachable only at certain stages of transformation, and (iii) while prompting ability rapidly diminishes with a decrease in quality of the dataset, concepts often remain reliably reachable through steering. Model providers can leverage this to bypass costly retraining and dataset curation and instead innovate with user-facing control mechanisms.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.0%">
                            LLMs
                        </span>
                <!-- Federated Learning: 2.5 -->
                    
                <!-- Medicine: 2.2 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- Game Theory: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- Networks: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.0721
                </span>
                <a href="https://arxiv.org/abs/2505.20046" target="_blank" rel="noopener noreferrer">REARANK: Reasoning Re-ranking Agent via Reinforcement Learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Le Zhang, Bo Wang, Xipeng Qiu, Siva Reddy, Aishwarya Agrawal
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We present REARANK, a large language model (LLM)-based listwise reasoning reranking agent. REARANK explicitly reasons before reranking, significantly improving both performance and interpretability. Leveraging reinforcement learning and data augmentation, REARANK achieves substantial improvements ov</span>
                
                <span class="abstract-full" style="display: none;">We present REARANK, a large language model (LLM)-based listwise reasoning reranking agent. REARANK explicitly reasons before reranking, significantly improving both performance and interpretability. Leveraging reinforcement learning and data augmentation, REARANK achieves substantial improvements over baseline models across popular information retrieval benchmarks, notably requiring only 179 annotated samples. Built on top of Qwen2.5-7B, our REARANK-7B demonstrates performance comparable to GPT-4 on both in-domain and out-of-domain benchmarks and even surpasses GPT-4 on reasoning-intensive BRIGHT benchmarks. These results underscore the effectiveness of our approach and highlight how reinforcement learning can enhance LLM reasoning capabilities in reranking.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 10.8%">
                            LLMs
                        </span>
                <!-- Medicine: 3.7 -->
                    
                <!-- Computer Vision: 2.5 -->
                    
                <!-- Decision Trees: 2.0 -->
                    
                <!-- Reinforcement Learning: 2.0 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.092
                </span>
                <a href="https://arxiv.org/abs/2505.19653" target="_blank" rel="noopener noreferrer">Token-Importance Guided Direct Preference Optimization</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yang Ning, Lin Hai, Liu Yibo, Tian Baoliang, Liu Guoqing, Zhang Haijun
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Ensuring that large language models (LLMs) generate outputs aligned with human preferences is important for safe and effective AI interactions. While Direct Preference Optimization (DPO) employs an implicit reward function to optimize the policy model, however, it and its related variants overlook t</span>
                
                <span class="abstract-full" style="display: none;">Ensuring that large language models (LLMs) generate outputs aligned with human preferences is important for safe and effective AI interactions. While Direct Preference Optimization (DPO) employs an implicit reward function to optimize the policy model, however, it and its related variants overlook the differential importance of individual tokens and are sensitive to judgment noise in preference datasets during generation. Although recent methods attempt to assess the important weight of tokens via probability prediction or simplistic weighting schemes, these evaluation methods are prone to biases and still cannot fully address these issues. To solve this problem, we propose the Token-Importance Guided Direct Preference Optimization (TI-DPO), which introduces two key innovations: the gradient-based token-importance weights that dynamically prioritize critical tokens, and a triple loss that explicitly guides model outputs to approach human-preferred responses and stay away from non-preferred responses. Experimental results show that TI-DPO achieves higher accuracy and stronger generative diversity, providing more stable and computationally efficient solutions compared with DPO and other RLHF methods.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 12.9%">
                            LLMs
                        </span>
                <!-- Medicine: 3.2 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Computer Vision: 2.1 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- HPO and AutoML: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- 3D: 1.1 -->
                    
                <!-- Hardware: 1.1 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.1109
                </span>
                <a href="https://arxiv.org/abs/2505.18969" target="_blank" rel="noopener noreferrer">Machine Psychophysics: Cognitive Control in Vision-Language Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Dezhi Luo, Maijunxian Wang, Bingyang Wang, Tianwei Zhao, Yijiang Li, Hokin Deng
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Cognitive control refers to the ability to flexibly coordinate thought and action in pursuit of internal goals. A standard method for assessing cognitive control involves conflict tasks that contrast congruent and incongruent trials, measuring the ability to prioritize relevant information while sup</span>
                
                <span class="abstract-full" style="display: none;">Cognitive control refers to the ability to flexibly coordinate thought and action in pursuit of internal goals. A standard method for assessing cognitive control involves conflict tasks that contrast congruent and incongruent trials, measuring the ability to prioritize relevant information while suppressing interference. We evaluate 108 vision-language models on three classic conflict tasks and their more demanding "squared" variants across 2,220 trials. Model performance corresponds closely to human behavior under resource constraints and reveals individual differences. These results indicate that some form of human-like executive function have emerged in current multi-modal foundational models.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 14.4%">
                            LLMs
                        </span>
                <!-- Computer Vision: 2.5 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Decision Trees: 1.9 -->
                    
                <!-- Medicine: 1.9 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- 3D: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.1833
                </span>
                <a href="https://arxiv.org/abs/2505.20154" target="_blank" rel="noopener noreferrer">UORA: Uniform Orthogonal Reinitialization Adaptation in Parameter-Efficient Fine-Tuning of Large Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Xueyan Zhang, Jinman Zhao, Zhifei Yang, Yibo Zhong, Shuhao Guan, Linbo Cao, Yining Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper introduces Uniform Orthogonal Reinitialization Adaptation (UORA), a novel parameter-efficient fine-tuning (PEFT) approach for Large Language Models (LLMs). UORA achieves state-of-the-art performance and parameter efficiency by leveraging a low-rank approximation method to reduce the numbe</span>
                
                <span class="abstract-full" style="display: none;">This paper introduces Uniform Orthogonal Reinitialization Adaptation (UORA), a novel parameter-efficient fine-tuning (PEFT) approach for Large Language Models (LLMs). UORA achieves state-of-the-art performance and parameter efficiency by leveraging a low-rank approximation method to reduce the number of trainable parameters. Unlike existing methods such as LoRA and VeRA, UORA employs an interpolation-based reparametrization mechanism that selectively reinitializes rows and columns in frozen projection matrices, guided by the vector magnitude heuristic. This results in substantially fewer trainable parameters compared to LoRA and outperforms VeRA in computation and storage efficiency. Comprehensive experiments across various benchmarks demonstrate UORA's superiority in achieving competitive fine-tuning performance with negligible computational overhead. We demonstrate its performance on GLUE and E2E benchmarks and its effectiveness in instruction-tuning large language models and image classification models. Our contributions establish a new paradigm for scalable and resource-efficient fine-tuning of LLMs.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 22.0%">
                            LLMs
                        </span>
                <!-- Computer Vision: 2.7 -->
                    
                <!-- Medicine: 2.6 -->
                    
                <!-- Datasets: 1.9 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- T2I: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.2115
                </span>
                <a href="https://arxiv.org/abs/2505.19676" target="_blank" rel="noopener noreferrer">Large Language Models' Reasoning Stalls: An Investigation into the Capabilities of Frontier Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Lachlan McGinness, Peter Baumgartner
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Empirical methods to examine the capability of Large Language Models (LLMs) to use Automated Theorem Prover (ATP) reasoning strategies are studied. We evaluate the performance of State of the Art models from December 2023 and August 2024 on PRONTOQA steamroller reasoning problems. For that, we devel</span>
                
                <span class="abstract-full" style="display: none;">Empirical methods to examine the capability of Large Language Models (LLMs) to use Automated Theorem Prover (ATP) reasoning strategies are studied. We evaluate the performance of State of the Art models from December 2023 and August 2024 on PRONTOQA steamroller reasoning problems. For that, we develop methods for assessing LLM response accuracy and correct answer correlation.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 27.5%">
                            LLMs
                        </span>
                <!-- Medicine: 3.0 -->
                    
                <!-- Federated Learning: 2.6 -->
                    
                <!-- Computer Vision: 2.2 -->
                    
                <!-- Bayesian Optimization: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.2744
                </span>
                <a href="https://arxiv.org/abs/2501.13772" target="_blank" rel="noopener noreferrer">Jailbreak-AudioBench: In-Depth Evaluation and Analysis of Jailbreak Threats for Large Audio Language Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Hao Cheng, Erjia Xiao, Jing Shao, Yichi Wang, Le Yang, Chao Sheng, Philip Torr, Jindong Gu, Renjing Xu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Large Language Models (LLMs) demonstrate impressive zero-shot performance across a wide range of natural language processing tasks. Integrating various modality encoders further expands their capabilities, giving rise to Multimodal Large Language Models (MLLMs) that process not only text but also vi</span>
                
                <span class="abstract-full" style="display: none;">Large Language Models (LLMs) demonstrate impressive zero-shot performance across a wide range of natural language processing tasks. Integrating various modality encoders further expands their capabilities, giving rise to Multimodal Large Language Models (MLLMs) that process not only text but also visual and auditory modality inputs. However, these advanced capabilities may also pose significant security risks, as models can be exploited to generate harmful or inappropriate content through jailbreak attacks. While prior work has extensively explored how manipulating textual or visual modality inputs can circumvent safeguards in LLMs and MLLMs, the vulnerability of audio-specific Jailbreak on Large Audio-Language Models (LALMs) remains largely underexplored. To address this gap, we introduce Jailbreak-AudioBench, which consists of the Toolbox, curated Dataset, and comprehensive Benchmark. The Toolbox supports not only text-to-audio conversion but also a range of audio editing techniques. The curated Dataset provides diverse explicit and implicit jailbreak audio examples in both original and edited forms. Utilizing this dataset, we evaluate multiple state-of-the-art LALMs, establishing the most comprehensive audio jailbreak benchmark to date. Finally, Jailbreak-AudioBench establishes a foundation for advancing future research on LALMs safety alignment by enabling the in-depth exposure of more powerful jailbreak threats, such as query-based audio editing, and by facilitating the development of effective defense mechanisms.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 30.2%">
                            LLMs
                        </span>
                <!-- Medicine: 2.7 -->
                    
                <!-- Blockchain: 2.4 -->
                    
                <!-- Datasets: 2.4 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.4339
                </span>
                <a href="https://arxiv.org/abs/2505.13061" target="_blank" rel="noopener noreferrer">3D Visual Illusion Depth Estimation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Chengtang Yao, Zhidan Liu, Jiaxi Zeng, Lidong Yu, Yuwei Wu, Yunde Jia
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">3D visual illusion is a perceptual phenomenon where a two-dimensional plane is manipulated to simulate three-dimensional spatial relationships, making a flat artwork or object look three-dimensional in the human visual system. In this paper, we reveal that the machine visual system is also seriously</span>
                
                <span class="abstract-full" style="display: none;">3D visual illusion is a perceptual phenomenon where a two-dimensional plane is manipulated to simulate three-dimensional spatial relationships, making a flat artwork or object look three-dimensional in the human visual system. In this paper, we reveal that the machine visual system is also seriously fooled by 3D visual illusions, including monocular and binocular depth estimation. In order to explore and analyze the impact of 3D visual illusion on depth estimation, we collect a large dataset containing almost 3k scenes and 200k images to train and evaluate SOTA monocular and binocular depth estimation methods. We also propose a robust depth estimation framework that uses common sense from a vision-language model to adaptively select reliable depth from binocular disparity and monocular depth. Experiments show that SOTA monocular, binocular, and multi-view depth estimation approaches are all fooled by various 3D visual illusions, while our method achieves SOTA performance.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #76aa96" title="Confidence: 5.1%">
                            3D
                        </span>
                <!-- LLMs: 4.8 -->
                    
                <!-- Medicine: 3.8 -->
                    
                <!-- Computer Vision: 2.1 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Datasets: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.5945
                </span>
                <a href="https://arxiv.org/abs/2505.20129" target="_blank" rel="noopener noreferrer">Agentic 3D Scene Generation with Spatially Contextualized VLMs</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Xinhang Liu, Yu-Wing Tai, Chi-Keung Tang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Despite recent advances in multimodal content generation enabled by vision-language models (VLMs), their ability to reason about and generate structured 3D scenes remains largely underexplored. This limitation constrains their utility in spatially grounded tasks such as embodied AI, immersive simula</span>
                
                <span class="abstract-full" style="display: none;">Despite recent advances in multimodal content generation enabled by vision-language models (VLMs), their ability to reason about and generate structured 3D scenes remains largely underexplored. This limitation constrains their utility in spatially grounded tasks such as embodied AI, immersive simulations, and interactive 3D applications. We introduce a new paradigm that enables VLMs to generate, understand, and edit complex 3D environments by injecting a continually evolving spatial context. Constructed from multimodal input, this context consists of three components: a scene portrait that provides a high-level semantic blueprint, a semantically labeled point cloud capturing object-level geometry, and a scene hypergraph that encodes rich spatial relationships, including unary, binary, and higher-order constraints. Together, these components provide the VLM with a structured, geometry-aware working memory that integrates its inherent multimodal reasoning capabilities with structured 3D understanding for effective spatial reasoning. Building on this foundation, we develop an agentic 3D scene generation pipeline in which the VLM iteratively reads from and updates the spatial context. The pipeline features high-quality asset generation with geometric restoration, environment setup with automatic verification, and ergonomic adjustment guided by the scene hypergraph. Experiments show that our framework can handle diverse and challenging inputs, achieving a level of generalization not observed in prior work. Further results demonstrate that injecting spatial context enables VLMs to perform downstream tasks such as interactive scene editing and path planning, suggesting strong potential for spatially intelligent systems in computer graphics, 3D vision, and embodied applications.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.5%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #76aa96" title="Confidence: 6.7%">
                            3D
                        </span>
                <!-- Medicine: 4.1 -->
                    
                <!-- Datasets: 2.1 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- T2I: 1.1 -->
                    
                <!-- Hardware: 1.1 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.1209
                </span>
                <a href="https://arxiv.org/abs/2505.19429" target="_blank" rel="noopener noreferrer">Rhapsody: A Dataset for Highlight Detection in Podcasts</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Younghan Park, Anuj Diwan, David Harwath, Eunsol Choi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Podcasts have become daily companions for half a billion users. Given the enormous amount of podcast content available, highlights provide a valuable signal that helps viewers get the gist of an episode and decide if they want to invest in listening to it in its entirety. However, identifying highli</span>
                
                <span class="abstract-full" style="display: none;">Podcasts have become daily companions for half a billion users. Given the enormous amount of podcast content available, highlights provide a valuable signal that helps viewers get the gist of an episode and decide if they want to invest in listening to it in its entirety. However, identifying highlights automatically is challenging due to the unstructured and long-form nature of the content. We introduce Rhapsody, a dataset of 13K podcast episodes paired with segment-level highlight scores derived from YouTube's 'most replayed' feature. We frame the podcast highlight detection as a segment-level binary classification task. We explore various baseline approaches, including zero-shot prompting of language models and lightweight finetuned language models using segment-level classification heads. Our experimental results indicate that even state-of-the-art language models like GPT-4o and Gemini struggle with this task, while models finetuned with in-domain data significantly outperform their zero-shot performance. The finetuned model benefits from leveraging both speech signal features and transcripts. These findings highlight the challenges for fine-grained information access in long-form spoken media.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 10.7%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.2%">
                            Medicine
                        </span>
                <!-- Datasets: 2.1 -->
                    
                <!-- Computer Vision: 1.9 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.1676
                </span>
                <a href="https://arxiv.org/abs/2503.12183" target="_blank" rel="noopener noreferrer">Bridging Textual-Collaborative Gap through Semantic Codes for Sequential Recommendation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Enze Liu, Bowen Zheng, Wayne Xin Zhao, Ji-Rong Wen
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In recent years, substantial research efforts have been devoted to enhancing sequential recommender systems by integrating abundant side information with ID-based collaborative information. This study specifically focuses on leveraging the textual metadata (e.g., titles and brands) associated with i</span>
                
                <span class="abstract-full" style="display: none;">In recent years, substantial research efforts have been devoted to enhancing sequential recommender systems by integrating abundant side information with ID-based collaborative information. This study specifically focuses on leveraging the textual metadata (e.g., titles and brands) associated with items. While existing methods have achieved notable success by combining text and ID representations, they often struggle to strike a balance between textual information embedded in text representations and collaborative information from sequential patterns of user behavior. In light of this, we propose CCFRec, a novel Code-based textual and Collaborative semantic Fusion method for sequential Recommendation. The key idea behind our approach is to bridge the gap between textual and collaborative information using semantic codes. Specifically, we generate fine-grained semantic codes from multi-view text embeddings through vector quantization techniques. Subsequently, we develop a code-guided semantic-fusion module based on the cross-attention mechanism to flexibly extract and integrate relevant information from text representations. In order to further enhance the fusion of textual and collaborative semantics, we introduce an optimization strategy that employs code masking with two specific objectives: masked code modeling and masked sequence alignment. The merit of these objectives lies in leveraging mask prediction tasks and augmented item representations to capture code correlations within individual items and enhance the sequence modeling of the recommendation backbone. Extensive experiments conducted on four public datasets demonstrate the superiority of CCFRec, showing significant improvements over various sequential recommendation models. Our code is available at https://github.com/RUCAIBox/CCFRec.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.1%">
                            Medicine
                        </span>
                <!-- LLMs: 4.3 -->
                    
                <!-- Computer Vision: 2.5 -->
                    
                <!-- Federated Learning: 2.5 -->
                    
                <!-- GNN: 2.3 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.1877
                </span>
                <a href="https://arxiv.org/abs/2504.02154" target="_blank" rel="noopener noreferrer">FreSca: Scaling in Frequency Space Enhances Diffusion Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Chao Huang, Susan Liang, Yunlong Tang, Jing Bi, Li Ma, Yapeng Tian, Chenliang Xu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Latent diffusion models (LDMs) have achieved remarkable success in a variety of image tasks, yet achieving fine-grained, disentangled control over global structures versus fine details remains challenging. This paper explores frequency-based control within latent diffusion models. We first systemati</span>
                
                <span class="abstract-full" style="display: none;">Latent diffusion models (LDMs) have achieved remarkable success in a variety of image tasks, yet achieving fine-grained, disentangled control over global structures versus fine details remains challenging. This paper explores frequency-based control within latent diffusion models. We first systematically analyze frequency characteristics across pixel space, VAE latent space, and internal LDM representations. This reveals that the "noise difference" term, derived from classifier-free guidance at each step t, is a uniquely effective and semantically rich target for manipulation. Building on this insight, we introduce FreSca, a novel and plug-and-play framework that decomposes noise difference into low- and high-frequency components and applies independent scaling factors to them via spatial or energy-based cutoffs. Essentially, FreSca operates without any model retraining or architectural change, offering model- and task-agnostic control. We demonstrate its versatility and effectiveness in improving generation quality and structural emphasis on multiple architectures (e.g., SD3, SDXL) and across applications including image generation, editing, depth estimation, and video synthesis, thereby unlocking a new dimension of expressive control within LDMs.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 11.3%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.2%">
                            Medicine
                        </span>
                <!-- Blockchain: 2.3 -->
                    
                <!-- Computer Vision: 2.1 -->
                    
                <!-- 3D: 2.1 -->
                    
                <!-- Datasets: 2.0 -->
                    
                <!-- T2I: 2.0 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.2219
                </span>
                <a href="https://arxiv.org/abs/2505.10034" target="_blank" rel="noopener noreferrer">The First MPDD Challenge: Multimodal Personality-aware Depression Detection</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Changzeng Fu, Zelin Fu, Xinhe Kuang, Jiacheng Dong, Qi Zhang, Kaifeng Su, Yikai Su, Wenbo Shi, Junfeng Yao, Yuliang Zhao, Shiqi Zhao, Jiadong Wang, Siyang Song, Chaoran Liu, Yuichiro Yoshikawa, Bj\"orn Schuller, Hiroshi Ishiguro
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Depression is a widespread mental health issue affecting diverse age groups, with notable prevalence among college students and the elderly. However, existing datasets and detection methods primarily focus on young adults, neglecting the broader age spectrum and individual differences that influence</span>
                
                <span class="abstract-full" style="display: none;">Depression is a widespread mental health issue affecting diverse age groups, with notable prevalence among college students and the elderly. However, existing datasets and detection methods primarily focus on young adults, neglecting the broader age spectrum and individual differences that influence depression manifestation. Current approaches often establish a direct mapping between multimodal data and depression indicators, failing to capture the complexity and diversity of depression across individuals. This challenge includes two tracks based on age-specific subsets: Track 1 uses the MPDD-Elderly dataset for detecting depression in older adults, and Track 2 uses the MPDD-Young dataset for detecting depression in younger participants. The Multimodal Personality-aware Depression Detection (MPDD) Challenge aims to address this gap by incorporating multimodal data alongside individual difference factors. We provide a baseline model that fuses audio and video modalities with individual difference information to detect depression manifestations in diverse populations. This challenge aims to promote the development of more personalized and accurate de pression detection methods, advancing mental health research and fostering inclusive detection systems. More details are available on the official challenge website: https://hacilab.github.io/MPDDChallenge.github.io.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.3%">
                            Medicine
                        </span>
                <!-- LLMs: 4.3 -->
                    
                <!-- Computer Vision: 3.6 -->
                    
                <!-- Datasets: 2.0 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- 3D: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.249
                </span>
                <a href="https://arxiv.org/abs/2505.20218" target="_blank" rel="noopener noreferrer">Fine-grained List-wise Alignment for Generative Medication Recommendation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Chenxiao Fan, Chongming Gao, Wentao Shi, Yaxin Gong, Zihao Zhao, Fuli Feng
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Accurate and safe medication recommendations are critical for effective clinical decision-making, especially in multimorbidity cases. However, existing systems rely on point-wise prediction paradigms that overlook synergistic drug effects and potential adverse drug-drug interactions (DDIs). We propo</span>
                
                <span class="abstract-full" style="display: none;">Accurate and safe medication recommendations are critical for effective clinical decision-making, especially in multimorbidity cases. However, existing systems rely on point-wise prediction paradigms that overlook synergistic drug effects and potential adverse drug-drug interactions (DDIs). We propose FLAME, a fine-grained list-wise alignment framework for large language models (LLMs), enabling drug-by-drug generation of drug lists. FLAME formulates recommendation as a sequential decision process, where each step adds or removes a single drug. To provide fine-grained learning signals, we devise step-wise Group Relative Policy Optimization (GRPO) with potential-based reward shaping, which explicitly models DDIs and optimizes the contribution of each drug to the overall prescription. Furthermore, FLAME enhances patient modeling by integrating structured clinical knowledge and collaborative information into the representation space of LLMs. Experiments on benchmark datasets demonstrate that FLAME achieves state-of-the-art performance, delivering superior accuracy, controllable safety-accuracy trade-offs, and strong generalization across diverse clinical scenarios. Our code is available at https://github.com/cxfann/Flame.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.6%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.0%">
                            Medicine
                        </span>
                <!-- Hardware: 2.0 -->
                    
                <!-- Computer Vision: 2.0 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.2803
                </span>
                <a href="https://arxiv.org/abs/2505.08311" target="_blank" rel="noopener noreferrer">AM-Thinking-v1: Advancing the Frontier of Reasoning at 32B Scale</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yunjie Ji, Xiaoyu Tian, Sitong Zhao, Haotian Wang, Shuaiting Chen, Yiping Peng, Han Zhao, Xiangang Li
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We present AM-Thinking-v1, a 32B dense language model that advances the frontier of reasoning, embodying the collaborative spirit of open-source innovation. Outperforming DeepSeek-R1 and rivaling leading Mixture-of-Experts (MoE) models like Qwen3-235B-A22B and Seed1.5-Thinking, AM-Thinking-v1 achiev</span>
                
                <span class="abstract-full" style="display: none;">We present AM-Thinking-v1, a 32B dense language model that advances the frontier of reasoning, embodying the collaborative spirit of open-source innovation. Outperforming DeepSeek-R1 and rivaling leading Mixture-of-Experts (MoE) models like Qwen3-235B-A22B and Seed1.5-Thinking, AM-Thinking-v1 achieves impressive scores of 85.3 on AIME 2024, 74.4 on AIME 2025, and 70.3 on LiveCodeBench, showcasing state-of-the-art mathematical and coding capabilities among open-source models of similar scale.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 9.4%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.2%">
                            Medicine
                        </span>
                <!-- Blockchain: 3.0 -->
                    
                <!-- Federated Learning: 2.3 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.4 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.2856
                </span>
                <a href="https://arxiv.org/abs/2505.19740" target="_blank" rel="noopener noreferrer">Machine Learning Algorithm for Noise Reduction and Disease-Causing Gene Feature Extraction in Gene Sequencing Data</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Weichen Si, Yihao Ou, Zhen Tian
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In this study, we propose a machine learning-based method for noise reduction and disease-causing gene feature extraction in gene sequencing DeepSeqDenoise algorithm combines CNN and RNN to effectively remove the sequencing noise, and improves the signal-to-noise ratio by 9.4 dB. We screened 17 key </span>
                
                <span class="abstract-full" style="display: none;">In this study, we propose a machine learning-based method for noise reduction and disease-causing gene feature extraction in gene sequencing DeepSeqDenoise algorithm combines CNN and RNN to effectively remove the sequencing noise, and improves the signal-to-noise ratio by 9.4 dB. We screened 17 key features by feature engineering, and constructed an integrated learning model to predict disease-causing genes with 94.3% accuracy. We successfully identified 57 new candidate disease-causing genes in a cardiovascular disease cohort validation, and detected 3 missed variants in clinical applications. The method significantly outperforms existing tools and provides strong support for accurate diagnosis of genetic diseases.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.1%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.8%">
                            Medicine
                        </span>
                <!-- Computer Vision: 2.7 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- HPO and AutoML: 1.8 -->
                    
                <!-- Datasets: 1.7 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- T2I: 1.2 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.3872
                </span>
                <a href="https://arxiv.org/abs/2505.18833" target="_blank" rel="noopener noreferrer">Supermartingale Certificates for Quantitative Omega-regular Verification and Control</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Thomas A. Henzinger (Institute of Science and Technology Austria), Kaushik Mallik (IMDEA Software Institute), Pouya Sadeghi (Singapore Management University), {\DJ}or{\dj}e \v{Z}ikeli\'c (Singapore Management University)
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We present the first supermartingale certificate for quantitative $\omega$-regular properties of discrete-time infinite-state stochastic systems. Our certificate is defined on the product of the stochastic system and a limit-deterministic B\"uchi automaton that specifies the property of interest; he</span>
                
                <span class="abstract-full" style="display: none;">We present the first supermartingale certificate for quantitative $\omega$-regular properties of discrete-time infinite-state stochastic systems. Our certificate is defined on the product of the stochastic system and a limit-deterministic B\"uchi automaton that specifies the property of interest; hence we call it a limit-deterministic B\"uchi supermartingale (LDBSM). Previously known supermartingale certificates applied only to quantitative reachability, safety, or reach-avoid properties, and to qualitative (i.e., probability 1) $\omega$-regular properties. We also present fully automated algorithms for the template-based synthesis of LDBSMs, for the case when the stochastic system dynamics and the controller can be represented in terms of polynomial inequalities. Our experiments demonstrate the ability of our method to solve verification and control tasks for stochastic systems that were beyond the reach of previous supermartingale-based approaches.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.1%">
                            Medicine
                        </span>
                <!-- LLMs: 2.8 -->
                    
                <!-- Federated Learning: 2.5 -->
                    
                <!-- Bayesian Optimization: 2.4 -->
                    
                <!-- Quantum Computing: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 2.2 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- Math: 1.5 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.3956
                </span>
                <a href="https://arxiv.org/abs/2505.18194" target="_blank" rel="noopener noreferrer">Large Language Model-Driven Distributed Integrated Multimodal Sensing and Semantic Communications</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yubo Peng, Luping Xiang, Bingxin Zhang, Kun Yang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Traditional single-modal sensing systems-based solely on either radio frequency (RF) or visual data-struggle to cope with the demands of complex and dynamic environments. Furthermore, single-device systems are constrained by limited perspectives and insufficient spatial coverage, which impairs their</span>
                
                <span class="abstract-full" style="display: none;">Traditional single-modal sensing systems-based solely on either radio frequency (RF) or visual data-struggle to cope with the demands of complex and dynamic environments. Furthermore, single-device systems are constrained by limited perspectives and insufficient spatial coverage, which impairs their effectiveness in urban or non-line-of-sight scenarios. To overcome these challenges, we propose a novel large language model (LLM)-driven distributed integrated multimodal sensing and semantic communication (LLM-DiSAC) framework. Specifically, our system consists of multiple collaborative sensing devices equipped with RF and camera modules, working together with an aggregation center to enhance sensing accuracy. First, on sensing devices, LLM-DiSAC develops an RF-vision fusion network (RVFN), which employs specialized feature extractors for RF and visual data, followed by a cross-attention module for effective multimodal integration. Second, a LLM-based semantic transmission network (LSTN) is proposed to enhance communication efficiency, where the LLM-based decoder leverages known channel parameters, such as transceiver distance and signal-to-noise ratio (SNR), to mitigate semantic distortion. Third, at the aggregation center, a transformer-based aggregation model (TRAM) with an adaptive aggregation attention mechanism is developed to fuse distributed features and enhance sensing accuracy. To preserve data privacy, a two-stage distributed learning strategy is introduced, allowing local model training at the device level and centralized aggregation model training using intermediate features. Finally, evaluations on a synthetic multi-view RF-visual dataset generated by the Genesis simulation engine show that LLM-DiSAC achieves a good performance.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.5%">
                            Medicine
                        </span>
                <!-- LLMs: 3.5 -->
                    
                <!-- Computer Vision: 2.7 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- GNN: 2.1 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4304
                </span>
                <a href="https://arxiv.org/abs/2505.19301" target="_blank" rel="noopener noreferrer">A Novel Zero-Trust Identity Framework for Agentic AI: Decentralized Authentication and Fine-Grained Access Control</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ken Huang, Vineeth Sai Narajala, John Yeoh, Ramesh Raskar, Youssef Harkati, Jerry Huang, Idan Habler, Chris Hughes
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Traditional Identity and Access Management (IAM) systems, primarily designed for human users or static machine identities via protocols such as OAuth, OpenID Connect (OIDC), and SAML, prove fundamentally inadequate for the dynamic, interdependent, and often ephemeral nature of AI agents operating at</span>
                
                <span class="abstract-full" style="display: none;">Traditional Identity and Access Management (IAM) systems, primarily designed for human users or static machine identities via protocols such as OAuth, OpenID Connect (OIDC), and SAML, prove fundamentally inadequate for the dynamic, interdependent, and often ephemeral nature of AI agents operating at scale within Multi Agent Systems (MAS), a computational system composed of multiple interacting intelligent agents that work collectively.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.0%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.2%">
                            LLMs
                        </span>
                <!-- Hardware: 3.2 -->
                    
                <!-- Blockchain: 2.8 -->
                    
                <!-- Quantum Computing: 2.3 -->
                    
                <!-- Computer Vision: 2.0 -->
                    
                <!-- HPO and AutoML: 1.9 -->
                    
                <!-- Datasets: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Federated Learning: 1.6 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4608
                </span>
                <a href="https://arxiv.org/abs/2505.18902" target="_blank" rel="noopener noreferrer">Unsupervised cell segmentation by fast Gaussian Processes</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Laura Baracaldo, Blythe King, Haoran Yan, Yizi Lin, Nina Miolane, Mengyang Gu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Cell boundary information is crucial for analyzing cell behaviors from time-lapse microscopy videos. Existing supervised cell segmentation tools, such as ImageJ, require tuning various parameters and rely on restrictive assumptions about the shape of the objects. While recent supervised segmentation</span>
                
                <span class="abstract-full" style="display: none;">Cell boundary information is crucial for analyzing cell behaviors from time-lapse microscopy videos. Existing supervised cell segmentation tools, such as ImageJ, require tuning various parameters and rely on restrictive assumptions about the shape of the objects. While recent supervised segmentation tools based on convolutional neural networks enhance accuracy, they depend on high-quality labelled images, making them unsuitable for segmenting new types of objects not in the database. We developed a novel unsupervised cell segmentation algorithm based on fast Gaussian processes for noisy microscopy images without the need for parameter tuning or restrictive assumptions about the shape of the object. We derived robust thresholding criteria adaptive for heterogeneous images containing distinct brightness at different parts to separate objects from the background, and employed watershed segmentation to distinguish touching cell objects. Both simulated studies and real-data analysis of large microscopy images demonstrate the scalability and accuracy of our approach compared with the alternatives.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.8%">
                            Medicine
                        </span>
                <!-- Computer Vision: 3.3 -->
                    
                <!-- Federated Learning: 2.8 -->
                    
                <!-- Hardware: 2.6 -->
                    
                <!-- Evolutionary Algorithms: 2.5 -->
                    
                <!-- Bayesian Optimization: 2.2 -->
                    
                <!-- Blockchain: 2.0 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- LLMs: 1.3 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4703
                </span>
                <a href="https://arxiv.org/abs/2503.10981" target="_blank" rel="noopener noreferrer">Unlocking Text Capabilities in Vision Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Fawaz Sammani, Jonas Fischer, Nikos Deligiannis
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Visual classifiers provide high-dimensional feature representations that are challenging to interpret and analyze. Text, in contrast, provides a more expressive and human-friendly interpretable medium for understanding and analyzing model behavior. We propose a simple, yet powerful method for reform</span>
                
                <span class="abstract-full" style="display: none;">Visual classifiers provide high-dimensional feature representations that are challenging to interpret and analyze. Text, in contrast, provides a more expressive and human-friendly interpretable medium for understanding and analyzing model behavior. We propose a simple, yet powerful method for reformulating any pretrained visual classifier so that it can be queried with free-form text without compromising its original performance. Our approach is label-free, data and compute-efficient, and is trained to preserve the underlying classifiers distribution and decision-making processes. Our method unlocks several zero-shot text interpretability applications for any visual classifier. We apply our method on 40 visual classifiers and demonstrate two primary applications: 1) building both label-free and zero-shot concept bottleneck models and therefore converting any visual classifier to be inherently-interpretable and 2) zero-shot decoding of visual features into natural language sentences. In both tasks we establish new state-of-the-art results, outperforming existing works and surpassing CLIP-based baselines with ImageNet-only trained classifiers, while using up to 400x fewer images and 400,000x less text during training.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 11.8%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.0%">
                            Medicine
                        </span>
                <!-- Computer Vision: 3.0 -->
                    
                <!-- Decision Trees: 2.5 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- T2I: 1.4 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.476
                </span>
                <a href="https://arxiv.org/abs/2505.19722" target="_blank" rel="noopener noreferrer">Distilling Closed-Source LLM's Knowledge for Locally Stable and Economic Biomedical Entity Linking</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yihao Ai, Zhiyuan Ning, Weiwei Dai, Pengfei Wang, Yi Du, Wenjuan Cui, Kunpeng Liu, Yuanchun Zhou
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Biomedical entity linking aims to map nonstandard entities to standard entities in a knowledge base. Traditional supervised methods perform well but require extensive annotated data to transfer, limiting their usage in low-resource scenarios. Large language models (LLMs), especially closed-source LL</span>
                
                <span class="abstract-full" style="display: none;">Biomedical entity linking aims to map nonstandard entities to standard entities in a knowledge base. Traditional supervised methods perform well but require extensive annotated data to transfer, limiting their usage in low-resource scenarios. Large language models (LLMs), especially closed-source LLMs, can address these but risk stability issues and high economic costs: using these models is restricted by commercial companies and brings significant economic costs when dealing with large amounts of data. To address this, we propose ``RPDR'', a framework combining closed-source LLMs and open-source LLMs for re-ranking candidates retrieved by a retriever fine-tuned with a small amount of data. By prompting a closed-source LLM to generate training data from unannotated data and fine-tuning an open-source LLM for re-ranking, we effectively distill the knowledge to the open-source LLM that can be deployed locally, thus avoiding the stability issues and the problem of high economic costs. We evaluate RPDR on two datasets, including one real-world dataset and one publicly available dataset involving two languages: Chinese and English. RPDR achieves 0.019 Acc@1 improvement and 0.036 Acc@1 improvement on the Aier dataset and the Ask A Patient dataset when the amount of training data is not enough. The results demonstrate the superiority and generalizability of the proposed framework.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.0%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.7%">
                            Medicine
                        </span>
                <!-- Datasets: 1.9 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Hardware: 1.1 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4852
                </span>
                <a href="https://arxiv.org/abs/2505.19503" target="_blank" rel="noopener noreferrer">Locality-Aware Zero-Shot Human-Object Interaction Detection</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Sanghyun Kim, Deunsol Jung, Minsu Cho
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Recent methods for zero-shot Human-Object Interaction (HOI) detection typically leverage the generalization ability of large Vision-Language Model (VLM), i.e., CLIP, on unseen categories, showing impressive results on various zero-shot settings. However, existing methods struggle to adapt CLIP repre</span>
                
                <span class="abstract-full" style="display: none;">Recent methods for zero-shot Human-Object Interaction (HOI) detection typically leverage the generalization ability of large Vision-Language Model (VLM), i.e., CLIP, on unseen categories, showing impressive results on various zero-shot settings. However, existing methods struggle to adapt CLIP representations for human-object pairs, as CLIP tends to overlook fine-grained information necessary for distinguishing interactions. To address this issue, we devise, LAIN, a novel zero-shot HOI detection framework enhancing the locality and interaction awareness of CLIP representations. The locality awareness, which involves capturing fine-grained details and the spatial structure of individual objects, is achieved by aggregating the information and spatial priors of adjacent neighborhood patches. The interaction awareness, which involves identifying whether and how a human is interacting with an object, is achieved by capturing the interaction pattern between the human and the object. By infusing locality and interaction awareness into CLIP representation, LAIN captures detailed information about the human-object pairs. Our extensive experiments on existing benchmarks show that LAIN outperforms previous methods on various zero-shot settings, demonstrating the importance of locality and interaction awareness for effective zero-shot HOI detection.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.4%">
                            Medicine
                        </span>
                <!-- Computer Vision: 4.1 -->
                    
                <!-- Federated Learning: 2.6 -->
                    
                <!-- LLMs: 2.1 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Blockchain: 2.0 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.5615
                </span>
                <a href="https://arxiv.org/abs/2505.18823" target="_blank" rel="noopener noreferrer">MSLAU-Net: A Hybird CNN-Transformer Network for Medical Image Segmentation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Libin Lan, Yanxin Li, Xiaojuan Liu, Juan Zhou, Jianxun Zhang, Nannan Huang, Yudong Zhang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Both CNN-based and Transformer-based methods have achieved remarkable success in medical image segmentation tasks. However, CNN-based methods struggle to effectively capture global contextual information due to the inherent limitations of convolution operations. Meanwhile, Transformer-based methods </span>
                
                <span class="abstract-full" style="display: none;">Both CNN-based and Transformer-based methods have achieved remarkable success in medical image segmentation tasks. However, CNN-based methods struggle to effectively capture global contextual information due to the inherent limitations of convolution operations. Meanwhile, Transformer-based methods suffer from insufficient local feature modeling and face challenges related to the high computational complexity caused by the self-attention mechanism. To address these limitations, we propose a novel hybrid CNN-Transformer architecture, named MSLAU-Net, which integrates the strengths of both paradigms. The proposed MSLAU-Net incorporates two key ideas. First, it introduces Multi-Scale Linear Attention, designed to efficiently extract multi-scale features from medical images while modeling long-range dependencies with low computational complexity. Second, it adopts a top-down feature aggregation mechanism, which performs multi-level feature aggregation and restores spatial resolution using a lightweight structure. Extensive experiments conducted on benchmark datasets covering three imaging modalities demonstrate that the proposed MSLAU-Net outperforms other state-of-the-art methods on nearly all evaluation metrics, validating the superiority, effectiveness, and robustness of our approach. Our code is available at https://github.com/Monsoon49/MSLAU-Net.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.3%">
                            Medicine
                        </span>
                <!-- GNN: 4.7 -->
                    
                <!-- Computer Vision: 3.8 -->
                    
                <!-- Federated Learning: 3.3 -->
                    
                <!-- LLMs: 2.7 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.5722
                </span>
                <a href="https://arxiv.org/abs/2411.01271" target="_blank" rel="noopener noreferrer">Interacting Large Language Model Agents. Interpretable Models and Social Learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Adit Jain, Vikram Krishnamurthy
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper discusses the theory and algorithms for interacting large language model agents (LLMAs) using methods from statistical signal processing and microeconomics. While both fields are mature, their application to decision-making involving interacting LLMAs remains unexplored. Motivated by Baye</span>
                
                <span class="abstract-full" style="display: none;">This paper discusses the theory and algorithms for interacting large language model agents (LLMAs) using methods from statistical signal processing and microeconomics. While both fields are mature, their application to decision-making involving interacting LLMAs remains unexplored. Motivated by Bayesian sentiment analysis on online platforms, we construct interpretable models and algorithms that enable LLMAs to interact and perform Bayesian inference. Because interacting LLMAs learn from both prior decisions and external inputs, they can exhibit bias and herding behavior. Thus, developing interpretable models and stochastic control algorithms is essential to understand and mitigate these behaviors. This paper has three main results. First, we show using Bayesian revealed preferences from microeconomics that an individual LLMA satisfies the necessary and sufficient conditions for rationally inattentive (bounded rationality) Bayesian utility maximization and, given an observation, the LLMA chooses an action that maximizes a regularized utility. Second, we utilize Bayesian social learning to construct interpretable models for LLMAs that interact sequentially with each other and the environment while performing Bayesian inference. Our proposed models capture the herding behavior exhibited by interacting LLMAs. Third, we propose a stochastic control framework to delay herding and improve state estimation accuracy under 2 settings: (a) centrally controlled LLMAs (b) autonomous LLMAs with incentives. We demonstrate the effectiveness of our methods on real datasets for hate speech classification and product quality assessment, using open-source models like LLaMA and closed-source models like ChatGPT. The main takeaway of this paper, based on empirical analysis and mathematical formalism, is that LLMAs act as rationally bounded Bayesian agents that exhibit social learning when interacting.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.9%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.0%">
                            Medicine
                        </span>
                <!-- Decision Trees: 2.9 -->
                    
                <!-- Computer Vision: 2.7 -->
                    
                <!-- Federated Learning: 1.6 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- 3D: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.5892
                </span>
                <a href="https://arxiv.org/abs/2505.20149" target="_blank" rel="noopener noreferrer">Improvement Strategies for Few-Shot Learning in OCT Image Classification of Rare Retinal Diseases</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Cheng-Yu Tai (Dixson), Ching-Wen Chen (Dixson), Chi-Chin Wu (Dixson), Bo-Chen Chiu (Dixson), Cheng-Hung (Dixson), Lin, Cheng-Kai Lu, Jia-Kang Wang, Tzu-Lun Huang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper focuses on using few-shot learning to improve the accuracy of classifying OCT diagnosis images with major and rare classes. We used the GAN-based augmentation strategy as a baseline and introduced several novel methods to further enhance our model. The proposed strategy contains U-GAT-IT </span>
                
                <span class="abstract-full" style="display: none;">This paper focuses on using few-shot learning to improve the accuracy of classifying OCT diagnosis images with major and rare classes. We used the GAN-based augmentation strategy as a baseline and introduced several novel methods to further enhance our model. The proposed strategy contains U-GAT-IT for improving the generative part and uses the data balance technique to narrow down the skew of accuracy between all categories. The best model obtained was built with CBAM attention mechanism and fine-tuned InceptionV3, and achieved an overall accuracy of 97.85%, representing a significant improvement over the original baseline.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.9%">
                            Medicine
                        </span>
                <!-- LLMs: 2.7 -->
                    
                <!-- Federated Learning: 2.5 -->
                    
                <!-- Computer Vision: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.6171
                </span>
                <a href="https://arxiv.org/abs/2505.01781" target="_blank" rel="noopener noreferrer">Enhancing Black-Litterman Portfolio via Hybrid Forecasting Model Combining Multivariate Decomposition and Noise Reduction</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ziye Yang, Ke Lu, Yang Wang, Jerome Yen
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Modern portfolio construction demands robust methods for integrating data-driven insights into asset allocation. The Black-Litterman model offers a powerful Bayesian approach to adjust equilibrium returns using investor views to form a posterior expectation along with market priors. Mainstream resea</span>
                
                <span class="abstract-full" style="display: none;">Modern portfolio construction demands robust methods for integrating data-driven insights into asset allocation. The Black-Litterman model offers a powerful Bayesian approach to adjust equilibrium returns using investor views to form a posterior expectation along with market priors. Mainstream research mainly generates subjective views through statistical models or machine learning methods, among which hybrid models combined with decomposition algorithms perform well. However, most hybrid models do not pay enough attention to noise, and time series decomposition methods based on single variables make it difficult to fully utilize information between multiple variables. Multivariate decomposition also has problems of low efficiency and poor component quality. In this study, we propose a novel hybrid forecasting model SSA-MAEMD-TCN to automate and improve the view generation process. The proposed model combines Singular Spectrum Analysis (SSA) for denoising, Multivariate Aligned Empirical Mode Decomposition (MA-EMD) for frequency-aligned decomposition, and Temporal Convolutional Networks (TCNs) for deep sequence learning to capture complex temporal patterns across multiple financial indicators. Empirical tests on the Nasdaq 100 Index stocks show a significant improvement in forecasting performance compared to baseline models based on MAEMD and MEMD. The optimized portfolio performs well, with annualized returns and Sharpe ratios far exceeding those of the traditional portfolio over a short holding period, even after accounting for transaction costs.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.5%">
                            Medicine
                        </span>
                <!-- LLMs: 4.4 -->
                    
                <!-- Computer Vision: 3.2 -->
                    
                <!-- Federated Learning: 3.1 -->
                    
                <!-- Evolutionary Algorithms: 2.4 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                <!-- T2I: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.6241
                </span>
                <a href="https://arxiv.org/abs/2505.19330" target="_blank" rel="noopener noreferrer">Deriving The Fundamental Equation of Earthmoving and Configuring Vortex Studio Earthmoving Simulation for Soil Property Estimation Experimentation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: W. Jacob Wagner
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This document serves as supplementary material for two International Society for Terrain-Vehicle Systems conference publications regarding in situ soil property estimation by Wagner et al. in 2023 and 2025. It covers the derivation of the fundamental equation of earthmoving for a flat blade moving t</span>
                
                <span class="abstract-full" style="display: none;">This document serves as supplementary material for two International Society for Terrain-Vehicle Systems conference publications regarding in situ soil property estimation by Wagner et al. in 2023 and 2025. It covers the derivation of the fundamental equation of earthmoving for a flat blade moving through sloped soil and provides some information regarding the advanced configuration of Vortex Studio's soil-tool interaction simulation.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.0%">
                            Medicine
                        </span>
                <!-- LLMs: 4.2 -->
                    
                <!-- Hardware: 3.7 -->
                    
                <!-- Blockchain: 2.6 -->
                    
                <!-- Datasets: 2.0 -->
                    
                <!-- Quantum Computing: 2.0 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.6608
                </span>
                <a href="https://arxiv.org/abs/2505.20075" target="_blank" rel="noopener noreferrer">Curriculum-RLAIF: Curriculum Alignment with Reinforcement Learning from AI Feedback</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Mengdi Li, Jiaye Lin, Xufeng Zhao, Wenhao Lu, Peilin Zhao, Stefan Wermter, Di Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Reward models trained with conventional Reinforcement Learning from AI Feedback (RLAIF) methods suffer from limited generalizability, which hinders the alignment performance of the policy model during reinforcement learning (RL). This challenge stems from various issues, including distribution shift</span>
                
                <span class="abstract-full" style="display: none;">Reward models trained with conventional Reinforcement Learning from AI Feedback (RLAIF) methods suffer from limited generalizability, which hinders the alignment performance of the policy model during reinforcement learning (RL). This challenge stems from various issues, including distribution shift, preference label noise, and mismatches between overly challenging samples and model capacity. In this paper, we attempt to enhance the generalizability of reward models through a data-centric approach, driven by the insight that these issues are inherently intertwined from the perspective of data difficulty. To address this, we propose a novel framework, $\textit{Curriculum-RLAIF}$, which constructs preference pairs with varying difficulty levels and produces a curriculum that progressively incorporates preference pairs of increasing difficulty for reward model training. Our experimental results suggest that reward models trained with Curriculum-RLAIF achieve improved generalizability, significantly increasing the alignment performance of the policy model by a large margin without incurring additional inference costs compared to various non-curriculum baselines. Detailed analysis and comparisons with alternative approaches, including data selection via external pretrained reward models or internal self-selection mechanisms, as well as other curriculum strategies, further demonstrate the superiority of our approach in terms of simplicity, efficiency, and effectiveness.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.0%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.1%">
                            LLMs
                        </span>
                <!-- Federated Learning: 4.6 -->
                    
                <!-- Reinforcement Learning: 3.4 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Datasets: 1.0 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.6623
                </span>
                <a href="https://arxiv.org/abs/2402.11495" target="_blank" rel="noopener noreferrer">Continuous Multi-Task Pre-training for Malicious URL Detection and Webpage Classification</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yujie Li, Yiwei Liu, Peiyue Li, Yifan Jia, Yanbin Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Malicious URL detection and webpage classification are critical tasks in cybersecurity and information management. In recent years, extensive research has explored using BERT or similar language models to replace traditional machine learning methods for detecting malicious URLs and classifying webpa</span>
                
                <span class="abstract-full" style="display: none;">Malicious URL detection and webpage classification are critical tasks in cybersecurity and information management. In recent years, extensive research has explored using BERT or similar language models to replace traditional machine learning methods for detecting malicious URLs and classifying webpages. While previous studies show promising results, they often apply existing language models to these tasks without accounting for the inherent differences in domain data (e.g., URLs being loosely structured and semantically sparse compared to text), leaving room for performance improvement. Furthermore, current approaches focus on single tasks and have not been tested in multi-task scenarios. To address these challenges, we propose urlBERT, a pre-trained URL encoder leveraging Transformer to encode foundational knowledge from billions of unlabeled URLs. To achieve it, we propose to use 5 unsupervised pretraining tasks to capture multi-level information of URL lexical, syntax, and semantics, and generate contrastive and adversarial representations. Furthermore, to avoid inter-pre-training competition and interference, we proposed a grouped sequential learning method to ensure effective training across multi-tasks. Finally, we leverage a two-stage fine-tuning approach to improve the training stability and efficiency of the task model. To assess the multitasking potential of urlBERT, we fine-tune the task model in both single-task and multi-task modes. The former creates a classification model for a single task, while the latter builds a classification model capable of handling multiple tasks. We evaluate urlBERT on three downstream tasks: phishing URL detection, advertising URL detection, and webpage classification. The results demonstrate that urlBERT outperforms standard pre-trained models, and its multi-task mode is capable of addressing the real-world demands of multitasking.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.9%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.9%">
                            Medicine
                        </span>
                <!-- Computer Vision: 3.1 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.7147
                </span>
                <a href="https://arxiv.org/abs/2505.19538" target="_blank" rel="noopener noreferrer">DoctorRAG: Medical RAG Fusing Knowledge with Patient Analogy through Textual Gradients</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yuxing Lu, Gecheng Fu, Wei Wu, Xukai Zhao, Sin Yee Goi, Jinzhuo Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Existing medical RAG systems mainly leverage knowledge from medical knowledge bases, neglecting the crucial role of experiential knowledge derived from similar patient cases -- a key component of human clinical reasoning. To bridge this gap, we propose DoctorRAG, a RAG framework that emulates doctor</span>
                
                <span class="abstract-full" style="display: none;">Existing medical RAG systems mainly leverage knowledge from medical knowledge bases, neglecting the crucial role of experiential knowledge derived from similar patient cases -- a key component of human clinical reasoning. To bridge this gap, we propose DoctorRAG, a RAG framework that emulates doctor-like reasoning by integrating both explicit clinical knowledge and implicit case-based experience. DoctorRAG enhances retrieval precision by first allocating conceptual tags for queries and knowledge sources, together with a hybrid retrieval mechanism from both relevant knowledge and patient. In addition, a Med-TextGrad module using multi-agent textual gradients is integrated to ensure that the final output adheres to the retrieved knowledge and patient query. Comprehensive experiments on multilingual, multitask datasets demonstrate that DoctorRAG significantly outperforms strong baseline RAG models and gains improvements from iterative refinements. Our approach generates more accurate, relevant, and comprehensive responses, taking a step towards more doctor-like medical reasoning systems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.7%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.7%">
                            Medicine
                        </span>
                <!-- 3D: 2.2 -->
                    
                <!-- GNN: 2.1 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Hardware: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.7621
                </span>
                <a href="https://arxiv.org/abs/2505.20201" target="_blank" rel="noopener noreferrer">Reasoning Is Not All You Need: Examining LLMs for Multi-Turn Mental Health Conversations</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Mohit Chandra, Siddharth Sriraman, Harneet Singh Khanuja, Yiqiao Jin, Munmun De Choudhury
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Limited access to mental healthcare, extended wait times, and increasing capabilities of Large Language Models (LLMs) has led individuals to turn to LLMs for fulfilling their mental health needs. However, examining the multi-turn mental health conversation capabilities of LLMs remains under-explored</span>
                
                <span class="abstract-full" style="display: none;">Limited access to mental healthcare, extended wait times, and increasing capabilities of Large Language Models (LLMs) has led individuals to turn to LLMs for fulfilling their mental health needs. However, examining the multi-turn mental health conversation capabilities of LLMs remains under-explored. Existing evaluation frameworks typically focus on diagnostic accuracy and win-rates and often overlook alignment with patient-specific goals, values, and personalities required for meaningful conversations. To address this, we introduce MedAgent, a novel framework for synthetically generating realistic, multi-turn mental health sensemaking conversations and use it to create the Mental Health Sensemaking Dialogue (MHSD) dataset, comprising over 2,200 patient-LLM conversations. Additionally, we present MultiSenseEval, a holistic framework to evaluate the multi-turn conversation abilities of LLMs in healthcare settings using human-centric criteria. Our findings reveal that frontier reasoning models yield below-par performance for patient-centric communication and struggle at advanced diagnostic capabilities with average score of 31%. Additionally, we observed variation in model performance based on patient's persona and performance drop with increasing turns in the conversation. Our work provides a comprehensive synthetic data generation framework, a dataset and evaluation framework for assessing LLMs in multi-turn mental health conversations.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 22.6%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.3%">
                            Medicine
                        </span>
                <!-- Computer Vision: 2.5 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- 3D: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.7718
                </span>
                <a href="https://arxiv.org/abs/2505.19233" target="_blank" rel="noopener noreferrer">RAISE: Realness Assessment for Image Synthesis and Evaluation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Aniruddha Mukherjee, Spriha Dubey, Somdyuti Paul
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The rapid advancement of generative AI has enabled the creation of highly photorealistic visual content, offering practical substitutes for real images and videos in scenarios where acquiring real data is difficult or expensive. However, reliably substituting real visual content with AI-generated co</span>
                
                <span class="abstract-full" style="display: none;">The rapid advancement of generative AI has enabled the creation of highly photorealistic visual content, offering practical substitutes for real images and videos in scenarios where acquiring real data is difficult or expensive. However, reliably substituting real visual content with AI-generated counterparts requires robust assessment of the perceived realness of AI-generated visual content, a challenging task due to its inherent subjective nature. To address this, we conducted a comprehensive human study evaluating the perceptual realness of both real and AI-generated images, resulting in a new dataset, containing images paired with subjective realness scores, introduced as RAISE in this paper. Further, we develop and train multiple models on RAISE to establish baselines for realness prediction. Our experimental results demonstrate that features derived from deep foundation vision models can effectively capture the subjective realness. RAISE thus provides a valuable resource for developing robust, objective models of perceptual realness assessment.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.1%">
                            Medicine
                        </span>
                <!-- LLMs: 4.7 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Datasets: 2.0 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.8948
                </span>
                <a href="https://arxiv.org/abs/2502.05564" target="_blank" rel="noopener noreferrer">TabICL: A Tabular Foundation Model for In-Context Learning on Large Data</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jingang Qu, David Holzm\"uller, Ga\"el Varoquaux, Marine Le Morvan
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The long-standing dominance of gradient-boosted decision trees on tabular data is currently challenged by tabular foundation models using In-Context Learning (ICL): setting the training data as context for the test data and predicting in a single forward pass without parameter updates. While TabPFNv</span>
                
                <span class="abstract-full" style="display: none;">The long-standing dominance of gradient-boosted decision trees on tabular data is currently challenged by tabular foundation models using In-Context Learning (ICL): setting the training data as context for the test data and predicting in a single forward pass without parameter updates. While TabPFNv2 foundation model excels on tables with up to 10K samples, its alternating column- and row-wise attentions make handling large training sets computationally prohibitive. So, can ICL be effectively scaled and deliver a benefit for larger tables? We introduce TabICL, a tabular foundation model for classification, pretrained on synthetic datasets with up to 60K samples and capable of handling 500K samples on affordable resources. This is enabled by a novel two-stage architecture: a column-then-row attention mechanism to build fixed-dimensional embeddings of rows, followed by a transformer for efficient ICL. Across 200 classification datasets from the TALENT benchmark, TabICL is on par with TabPFNv2 while being systematically faster (up to 10 times), and significantly outperforms all other approaches. On 53 datasets with over 10K samples, TabICL surpasses both TabPFNv2 and CatBoost, demonstrating the potential of ICL for large data. Pretraining code, inference code, and pre-trained models are available at https://github.com/soda-inria/tabicl.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 8.2%">
                            Medicine
                        </span>
                <!-- Computer Vision: 2.5 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- LLMs: 2.1 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Datasets: 1.8 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- 3D: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.9058
                </span>
                <a href="https://arxiv.org/abs/2505.19540" target="_blank" rel="noopener noreferrer">Real-time Whole-body Model Predictive Control for Bipedal Locomotion with a Novel Kino-dynamic Model and Warm-start Method</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Junhyung Kim, Hokyun Lee, Jaeheung Park
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Advancements in optimization solvers and computing power have led to growing interest in applying whole-body model predictive control (WB-MPC) to bipedal robots. However, the high degrees of freedom and inherent model complexity of bipedal robots pose significant challenges in achieving fast and sta</span>
                
                <span class="abstract-full" style="display: none;">Advancements in optimization solvers and computing power have led to growing interest in applying whole-body model predictive control (WB-MPC) to bipedal robots. However, the high degrees of freedom and inherent model complexity of bipedal robots pose significant challenges in achieving fast and stable control cycles for real-time performance. This paper introduces a novel kino-dynamic model and warm-start strategy for real-time WB-MPC in bipedal robots. Our proposed kino-dynamic model combines the linear inverted pendulum plus flywheel and full-body kinematics model. Unlike the conventional whole-body model that rely on the concept of contact wrenches, our model utilizes the zero-moment point (ZMP), reducing baseline computational costs and ensuring consistently low latency during contact state transitions. Additionally, a modularized multi-layer perceptron (MLP) based warm-start strategy is proposed, leveraging a lightweight neural network to provide a good initial guess for each control cycle. Furthermore, we present a ZMP-based whole-body controller (WBC) that extends the existing WBC for explicitly controlling impulses and ZMP, integrating it into the real-time WB-MPC framework. Through various comparative experiments, the proposed kino-dynamic model and warm-start strategy have been shown to outperform previous studies. Simulations and real robot experiments further validate that the proposed framework demonstrates robustness to perturbation and satisfies real-time control requirements during walking.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.0%">
                            Medicine
                        </span>
                <!-- Computer Vision: 3.5 -->
                    
                <!-- LLMs: 3.2 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.9215
                </span>
                <a href="https://arxiv.org/abs/2505.18191" target="_blank" rel="noopener noreferrer">SzCORE as a benchmark: report from the seizure detection challenge at the 2025 AI in Epilepsy and Neurological Disorders Conference</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jonathan Dan, Amirhossein Shahbazinia, Christodoulos Kechris, David Atienza
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Reliable automatic seizure detection from long-term EEG remains a challenge, as current machine learning models often fail to generalize across patients or clinical settings. Manual EEG review remains the clinical standard, underscoring the need for robust models and standardized evaluation. To rigo</span>
                
                <span class="abstract-full" style="display: none;">Reliable automatic seizure detection from long-term EEG remains a challenge, as current machine learning models often fail to generalize across patients or clinical settings. Manual EEG review remains the clinical standard, underscoring the need for robust models and standardized evaluation. To rigorously assess algorithm performance, we organized a challenge using a private dataset of continuous EEG recordings from 65 subjects (4,360 hours). Expert neurophysiologists annotated the data, providing ground truth for seizure events. Participants were required to detect seizure onset and duration, with evaluation based on event-based metrics, including sensitivity, precision, F1-score, and false positives per day. The SzCORE framework ensured standardized evaluation. The primary ranking criterion was the event-based F1-score, reflecting clinical relevance by balancing sensitivity and false positives. The challenge received 30 submissions from 19 teams, with 28 algorithms evaluated. Results revealed wide variability in performance, with a top F1-score of 43% (sensitivity 37%, precision 45%), highlighting the ongoing difficulty of seizure detection. The challenge also revealed a gap between reported performance and real-world evaluation, emphasizing the importance of rigorous benchmarking. Compared to previous challenges and commercial systems, the best-performing algorithm in this contest showed improved performance. Importantly, the challenge platform now supports continuous benchmarking, enabling reproducible research, integration of new datasets, and clinical evaluation of seizure detection algorithms using a standardized framework.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.7%">
                            Medicine
                        </span>
                <!-- LLMs: 2.5 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Computer Vision: 2.0 -->
                    
                <!-- Datasets: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- GNN: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.9296
                </span>
                <a href="https://arxiv.org/abs/2406.16833" target="_blank" rel="noopener noreferrer">USDC: A Dataset of $\underline{U}$ser $\underline{S}$tance and $\underline{D}$ogmatism in Long $\underline{C}$onversations</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Mounika Marreddy, Subba Reddy Oota, Venkata Charan Chinni, Manish Gupta, Lucie Flek
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Analyzing user opinion changes in long conversation threads is extremely critical for applications like enhanced personalization, market research, political campaigns, customer service, targeted advertising, and content moderation. Unfortunately, previous studies on stance and dogmatism in user conv</span>
                
                <span class="abstract-full" style="display: none;">Analyzing user opinion changes in long conversation threads is extremely critical for applications like enhanced personalization, market research, political campaigns, customer service, targeted advertising, and content moderation. Unfortunately, previous studies on stance and dogmatism in user conversations have focused on training models using datasets annotated at the post level, treating each post as independent and randomly sampling posts from conversation threads. Hence, first, we build a dataset for studying user opinion fluctuations in 764 long multi-user Reddit conversation threads, called USDC. USDC contains annotations for 2 tasks: i) User Stance classification, which involves labeling a user's stance in a post within a conversation on a five-point scale; ii) User Dogmatism classification, which involves labeling a user's overall opinion in the conversation on a four-point scale. Besides being time-consuming and costly, manual annotations for USDC are challenging because: 1) Conversation threads could be very long, increasing the chances of noisy annotations; and 2) Interpreting instances where a user changes their opinion within a conversation is difficult because often such transitions are subtle and not expressed explicitly. Hence, we leverage majority voting on zero-shot, one-shot, and few-shot annotations from Mistral Large and GPT-4 to automate the annotation process. Human annotations on 200 test conversations achieved inter-annotator agreement scores of 0.49 for stance and 0.50 for dogmatism with these LLM annotations, indicating a reasonable level of consistency between human and LLM annotations. USDC is then used to finetune and instruction-tune multiple deployable small language models like LLaMA, Falcon and Vicuna for the stance and dogmatism classification tasks. We make the code and dataset publicly available [https://github.com/mounikamarreddy/USDC].</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.4%">
                            Medicine
                        </span>
                <!-- LLMs: 4.6 -->
                    
                <!-- Datasets: 2.8 -->
                    
                <!-- Hardware: 2.2 -->
                    
                <!-- Computer Vision: 2.1 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.0297
                </span>
                <a href="https://arxiv.org/abs/2505.14486" target="_blank" rel="noopener noreferrer">Robust Immersive Bilateral Teleoperation of Beyond-Human-Scale Systems with Enhanced Transparency and Sense of Embodiment</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Mahdi Hejrati, Pauli Mustalahti, Jouni Mattila
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In human-in-the-loop systems such as teleoperation, especially those involving heavy-duty manipulators, achieving high task performance requires both robust control and strong human engagement. This paper presents a bilateral teleoperation framework for beyond-human-scale robotic systems that enhanc</span>
                
                <span class="abstract-full" style="display: none;">In human-in-the-loop systems such as teleoperation, especially those involving heavy-duty manipulators, achieving high task performance requires both robust control and strong human engagement. This paper presents a bilateral teleoperation framework for beyond-human-scale robotic systems that enhances the transparency and the operator's sense of embodiment (SoE), specifically, the senses of agency and self-location, through an immersive virtual reality interface and distributed haptic feedback. To support this embodiment and establish high level of motion and force transparency, we develop a force-sensorless, robust control architecture that tackles input nonlinearities, master-surrogate asymmetries, unknown uncertainties, and arbitrary time delays. A human-robot augmented dynamic model is integrated into the control loop to enhance human-adaptability of the controller. Theoretical analysis confirms semi-global uniform ultimate boundedness of the closed-loop system, guaranteeing the robustness to the real-world uncertainties. Extensive real-world experiments demonstrate high accuracy tracking under up to 1:13 motion scaling and 1:1000 force scaling, showcasing the significance of the results. Additionally, the stability-transparency tradeoff for motion tracking and force reflection and tracking is established up to 150 ms of one-way fix and time-varying communication delays. The results of user study with 10 participants (9 male and 1 female) demonstrate that the system can imply a good level of SoE (76.4%), at the same time is very user friendly with no gender limitation. These results are significant given the scale and weight of the heavy-duty manipulators.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.8%">
                            Medicine
                        </span>
                <!-- LLMs: 3.2 -->
                    
                <!-- Federated Learning: 2.7 -->
                    
                <!-- Hardware: 2.2 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.1141
                </span>
                <a href="https://arxiv.org/abs/2505.18195" target="_blank" rel="noopener noreferrer">Acoustic and Machine Learning Methods for Speech-Based Suicide Risk Assessment: A Systematic Review</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ambre Marie, Marine Garnier, Thomas Bertin, Laura Machart, Guillaume Dardenne, Gwenol\'e Quellec, Sofian Berrouiguet
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Suicide remains a public health challenge, necessitating improved detection methods to facilitate timely intervention and treatment. This systematic review evaluates the role of Artificial Intelligence (AI) and Machine Learning (ML) in assessing suicide risk through acoustic analysis of speech. Foll</span>
                
                <span class="abstract-full" style="display: none;">Suicide remains a public health challenge, necessitating improved detection methods to facilitate timely intervention and treatment. This systematic review evaluates the role of Artificial Intelligence (AI) and Machine Learning (ML) in assessing suicide risk through acoustic analysis of speech. Following PRISMA guidelines, we analyzed 33 articles selected from PubMed, Cochrane, Scopus, and Web of Science databases. These studies primarily explored acoustic differences between individuals at risk of suicide (RS) and those not at risk (NRS), and evaluated ML classifier performance. Findings consistently showed significant acoustic feature variations between RS and NRS populations, particularly involving jitter, fundamental frequency (F0), Mel-frequency cepstral coefficients (MFCC), and power spectral density (PSD). Classifier effectiveness varied based on algorithms, modalities, and speech elicitation methods, with multimodal approaches integrating acoustic, linguistic, and metadata features demonstrating superior performance. However, limitations such as methodological variability, small sample sizes, lack of longitudinal data, and limited linguistic and demographic diversity restrict generalizability. Future research should focus on standardizing methods, expanding multimodal analyses, and utilizing larger, diverse datasets to support AI integration in clinical suicide risk assessment.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 8.9%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.5%">
                            LLMs
                        </span>
                <!-- Blockchain: 3.1 -->
                    
                <!-- Hardware: 2.6 -->
                    
                <!-- Datasets: 2.3 -->
                    
                <!-- Computer Vision: 2.2 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.2349
                </span>
                <a href="https://arxiv.org/abs/2505.18973" target="_blank" rel="noopener noreferrer">Hierarchical Mamba Meets Hyperbolic Geometry: A New Paradigm for Structured Language Embeddings</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Sarang Patil, Ashish Parmanand Pandey, Ioannis Koutis, Mengjia Xu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Selective state-space models have achieved great success in long-sequence modeling. However, their capacity for language representation, especially in complex hierarchical reasoning tasks, remains underexplored. Most large language models rely on flat Euclidean embeddings, limiting their ability to </span>
                
                <span class="abstract-full" style="display: none;">Selective state-space models have achieved great success in long-sequence modeling. However, their capacity for language representation, especially in complex hierarchical reasoning tasks, remains underexplored. Most large language models rely on flat Euclidean embeddings, limiting their ability to capture latent hierarchies. To address this limitation, we propose Hierarchical Mamba (HiM), integrating efficient Mamba2 with exponential growth and curved nature of hyperbolic geometry to learn hierarchy-aware language embeddings for deeper linguistic understanding. Mamba2-processed sequences are projected to the Poincare ball (via tangent-based mapping) or Lorentzian manifold (via cosine and sine-based mapping) with "learnable" curvature, optimized with a combined hyperbolic loss. Our HiM model facilitates the capture of relational distances across varying hierarchical levels, enabling effective long-range reasoning. This makes it well-suited for tasks like mixed-hop prediction and multi-hop inference in hierarchical classification. We evaluated our HiM with four linguistic and medical datasets for mixed-hop prediction and multi-hop inference tasks. Experimental results demonstrated that: 1) Both HiM models effectively capture hierarchical relationships for four ontological datasets, surpassing Euclidean baselines. 2) HiM-Poincare captures fine-grained semantic distinctions with higher h-norms, while HiM-Lorentz provides more stable, compact, and hierarchy-preserving embeddings favoring robustness over detail.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 12.6%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 10.0%">
                            Medicine
                        </span>
                <!-- Computer Vision: 2.6 -->
                    
                <!-- HPO and AutoML: 2.1 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- T2I: 1.2 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- 3D: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.2936
                </span>
                <a href="https://arxiv.org/abs/2505.19159" target="_blank" rel="noopener noreferrer">A Joint Learning Framework with Feature Reconstruction and Prediction for Incomplete Satellite Image Time Series in Agricultural Semantic Segmentation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yuze Wang, Mariana Belgiu, Haiyang Wu, Dandan Zhong, Yangyang Cao, Chao Tao
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Satellite Image Time Series (SITS) is crucial for agricultural semantic segmentation. However, Cloud contamination introduces time gaps in SITS, disrupting temporal dependencies and causing feature shifts, leading to degraded performance of models trained on complete SITS. Existing methods typically</span>
                
                <span class="abstract-full" style="display: none;">Satellite Image Time Series (SITS) is crucial for agricultural semantic segmentation. However, Cloud contamination introduces time gaps in SITS, disrupting temporal dependencies and causing feature shifts, leading to degraded performance of models trained on complete SITS. Existing methods typically address this by reconstructing the entire SITS before prediction or using data augmentation to simulate missing data. Yet, full reconstruction may introduce noise and redundancy, while the data-augmented model can only handle limited missing patterns, leading to poor generalization. We propose a joint learning framework with feature reconstruction and prediction to address incomplete SITS more effectively. During training, we simulate data-missing scenarios using temporal masks. The two tasks are guided by both ground-truth labels and the teacher model trained on complete SITS. The prediction task constrains the model from selectively reconstructing critical features from masked inputs that align with the teacher's temporal feature representations. It reduces unnecessary reconstruction and limits noise propagation. By integrating reconstructed features into the prediction task, the model avoids learning shortcuts and maintains its ability to handle varied missing patterns and complete SITS. Experiments on SITS from Hunan Province, Western France, and Catalonia show that our method improves mean F1-scores by 6.93% in cropland extraction and 7.09% in crop classification over baselines. It also generalizes well across satellite sensors, including Sentinel-2 and PlanetScope, under varying temporal missing rates and model backbones.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 9.0%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.4%">
                            LLMs
                        </span>
                <!-- Computer Vision: 4.6 -->
                    
                <!-- HPO and AutoML: 1.8 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Hardware: 1.1 -->
                    
                <!-- Quantum Computing: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.4728
                </span>
                <a href="https://arxiv.org/abs/2504.11442" target="_blank" rel="noopener noreferrer">TextArena</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Leon Guertler, Bobby Cheng, Simon Yu, Bo Liu, Leshem Choshen, Cheston Tan
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">TextArena is an open-source collection of competitive text-based games for training and evaluation of agentic behavior in Large Language Models (LLMs). It spans 57+ unique environments (including single-player, two-player, and multi-player setups) and allows for easy evaluation of model capabilities</span>
                
                <span class="abstract-full" style="display: none;">TextArena is an open-source collection of competitive text-based games for training and evaluation of agentic behavior in Large Language Models (LLMs). It spans 57+ unique environments (including single-player, two-player, and multi-player setups) and allows for easy evaluation of model capabilities via an online-play system (against humans and other submitted models) with real-time TrueSkill scores. Traditional benchmarks rarely assess dynamic social skills such as negotiation, theory of mind, and deception, creating a gap that TextArena addresses. Designed with research, community and extensibility in mind, TextArena emphasizes ease of adding new games, adapting the framework, testing models, playing against the models, and training models. Detailed documentation of environments, games, leaderboard, and examples are available on https://github.com/LeonGuertler/TextArena and https://www.textarena.ai/.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 15.9%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.7%">
                            Medicine
                        </span>
                <!-- Datasets: 3.1 -->
                    
                <!-- Hardware: 2.7 -->
                    
                <!-- Blockchain: 2.5 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.4728
                </span>
                <a href="https://arxiv.org/abs/2505.19249" target="_blank" rel="noopener noreferrer">RGC-Bent: A Novel Dataset for Bent Radio Galaxy Classification</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Mir Sazzat Hossain, Khan Muhammad Bin Asad, Payaswini Saikia, Adrita Khan, Md Akil Raihan Iftee, Rakibul Hasan Rajib, Arshad Momen, Md Ashraful Amin, Amin Ahsan Ali, AKM Mahbubur Rahman
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We introduce a novel machine learning dataset tailored for the classification of bent radio active galactic nuclei (AGN) in astronomical observations. Bent radio AGN, distinguished by their curved jet structures, provide critical insights into galaxy cluster dynamics, interactions within the intracl</span>
                
                <span class="abstract-full" style="display: none;">We introduce a novel machine learning dataset tailored for the classification of bent radio active galactic nuclei (AGN) in astronomical observations. Bent radio AGN, distinguished by their curved jet structures, provide critical insights into galaxy cluster dynamics, interactions within the intracluster medium, and the broader physics of AGN. Despite their astrophysical significance, the classification of bent radio AGN remains a challenge due to the scarcity of specialized datasets and benchmarks. To address this, we present a dataset, derived from a well-recognized radio astronomy survey, that is designed to support the classification of NAT (Narrow-Angle Tail) and WAT (Wide-Angle Tail) categories, along with detailed data processing steps. We further evaluate the performance of state-of-the-art deep learning models on the dataset, including Convolutional Neural Networks (CNNs), and transformer-based architectures. Our results demonstrate the effectiveness of advanced machine learning models in classifying bent radio AGN, with ConvNeXT achieving the highest F1-scores for both NAT and WAT sources. By sharing this dataset and benchmarks, we aim to facilitate the advancement of research in AGN classification, galaxy cluster environments and galaxy evolution.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 9.9%">
                            Medicine
                        </span>
                <!-- Federated Learning: 2.9 -->
                    
                <!-- LLMs: 2.7 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- Datasets: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.7015
                </span>
                <a href="https://arxiv.org/abs/2505.19389" target="_blank" rel="noopener noreferrer">Curation and Analysis of MIMICEL -- An Event Log for MIMIC-IV Emergency Department</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jia Wei, Chun Ouyang, Bemali Wickramanayake, Zhipeng He, Keshara Perera, Catarina Moreira
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The global issue of overcrowding in emergency departments (ED) necessitates the analysis of patient flow through ED to enhance efficiency and alleviate overcrowding. However, traditional analytical methods are time-consuming and costly. The healthcare industry is embracing process mining tools to an</span>
                
                <span class="abstract-full" style="display: none;">The global issue of overcrowding in emergency departments (ED) necessitates the analysis of patient flow through ED to enhance efficiency and alleviate overcrowding. However, traditional analytical methods are time-consuming and costly. The healthcare industry is embracing process mining tools to analyse healthcare processes and patient flows. Process mining aims to discover, monitor, and enhance processes by obtaining knowledge from event log data. However, the availability of event logs is a prerequisite for applying process mining techniques. Hence, this paper aims to generate an event log for analysing processes in ED. In this study, we extract an event log from the MIMIC-IV-ED dataset and name it MIMICEL. MIMICEL captures the process of patient journey in ED, allowing for analysis of patient flows and improving ED efficiency. We present analyses conducted using MIMICEL to demonstrate the utility of the dataset. The curation of MIMICEL facilitates extensive use of MIMIC-IV-ED data for ED analysis using process mining techniques, while also providing the process mining research communities with a valuable dataset for study.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 9.9%">
                            Medicine
                        </span>
                <!-- LLMs: 4.1 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- Datasets: 2.4 -->
                    
                <!-- Evolutionary Algorithms: 2.3 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Bayesian Optimization: 1.8 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Computer Vision: 1.2 -->
                    
                <!-- GNN: 1.0 -->
                    
                <!-- Quantum Computing: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.7925
                </span>
                <a href="https://arxiv.org/abs/2505.08704" target="_blank" rel="noopener noreferrer">LLM-based Prompt Ensemble for Reliable Medical Entity Recognition from EHRs</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: K M Sajjadul Islam, Ayesha Siddika Nipu, Jiawei Wu, Praveen Madiraju
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Electronic Health Records (EHRs) are digital records of patient information, often containing unstructured clinical text. Named Entity Recognition (NER) is essential in EHRs for extracting key medical entities like problems, tests, and treatments to support downstream clinical applications. This pap</span>
                
                <span class="abstract-full" style="display: none;">Electronic Health Records (EHRs) are digital records of patient information, often containing unstructured clinical text. Named Entity Recognition (NER) is essential in EHRs for extracting key medical entities like problems, tests, and treatments to support downstream clinical applications. This paper explores prompt-based medical entity recognition using large language models (LLMs), specifically GPT-4o and DeepSeek-R1, guided by various prompt engineering techniques, including zero-shot, few-shot, and an ensemble approach. Among all strategies, GPT-4o with prompt ensemble achieved the highest classification performance with an F1-score of 0.95 and recall of 0.98, outperforming DeepSeek-R1 on the task. The ensemble method improved reliability by aggregating outputs through embedding-based similarity and majority voting.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 11.8%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.6%">
                            LLMs
                        </span>
                <!-- Blockchain: 2.6 -->
                    
                <!-- Hardware: 2.4 -->
                    
                <!-- HPO and AutoML: 2.2 -->
                    
                <!-- Computer Vision: 2.1 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Datasets: 1.8 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.1208
                </span>
                <a href="https://arxiv.org/abs/2505.19624" target="_blank" rel="noopener noreferrer">Benchmarking Large Multimodal Models for Ophthalmic Visual Question Answering with OphthalWeChat</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Pusheng Xu, Xia Gong, Xiaolan Chen, Weiyi Zhang, Jiancheng Yang, Bingjie Yan, Meng Yuan, Yalin Zheng, Mingguang He, Danli Shi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Purpose: To develop a bilingual multimodal visual question answering (VQA) benchmark for evaluating VLMs in ophthalmology. Methods: Ophthalmic image posts and associated captions published between January 1, 2016, and December 31, 2024, were collected from WeChat Official Accounts. Based on these ca</span>
                
                <span class="abstract-full" style="display: none;">Purpose: To develop a bilingual multimodal visual question answering (VQA) benchmark for evaluating VLMs in ophthalmology. Methods: Ophthalmic image posts and associated captions published between January 1, 2016, and December 31, 2024, were collected from WeChat Official Accounts. Based on these captions, bilingual question-answer (QA) pairs in Chinese and English were generated using GPT-4o-mini. QA pairs were categorized into six subsets by question type and language: binary (Binary_CN, Binary_EN), single-choice (Single-choice_CN, Single-choice_EN), and open-ended (Open-ended_CN, Open-ended_EN). The benchmark was used to evaluate the performance of three VLMs: GPT-4o, Gemini 2.0 Flash, and Qwen2.5-VL-72B-Instruct. Results: The final OphthalWeChat dataset included 3,469 images and 30,120 QA pairs across 9 ophthalmic subspecialties, 548 conditions, 29 imaging modalities, and 68 modality combinations. Gemini 2.0 Flash achieved the highest overall accuracy (0.548), outperforming GPT-4o (0.522, P < 0.001) and Qwen2.5-VL-72B-Instruct (0.514, P < 0.001). It also led in both Chinese (0.546) and English subsets (0.550). Subset-specific performance showed Gemini 2.0 Flash excelled in Binary_CN (0.687), Single-choice_CN (0.666), and Single-choice_EN (0.646), while GPT-4o ranked highest in Binary_EN (0.717), Open-ended_CN (BLEU-1: 0.301; BERTScore: 0.382), and Open-ended_EN (BLEU-1: 0.183; BERTScore: 0.240). Conclusions: This study presents the first bilingual VQA benchmark for ophthalmology, distinguished by its real-world context and inclusion of multiple examinations per patient. The dataset reflects authentic clinical decision-making scenarios and enables quantitative evaluation of VLMs, supporting the development of accurate, specialized, and trustworthy AI systems for eye care.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 11.2%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.5%">
                            LLMs
                        </span>
                <!-- Datasets: 3.4 -->
                    
                <!-- Hardware: 2.8 -->
                    
                <!-- Blockchain: 2.6 -->
                    
                <!-- Computer Vision: 2.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- 3D: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.3465
                </span>
                <a href="https://arxiv.org/abs/2505.19779" target="_blank" rel="noopener noreferrer">Advancements in Medical Image Classification through Fine-Tuning Natural Domain Foundation Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Mobina Mansoori, Sajjad Shahabodini, Farnoush Bayatmakou, Jamshid Abouei, Konstantinos N. Plataniotis, Arash Mohammadi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Using massive datasets, foundation models are large-scale, pre-trained models that perform a wide range of tasks. These models have shown consistently improved results with the introduction of new methods. It is crucial to analyze how these trends impact the medical field and determine whether these</span>
                
                <span class="abstract-full" style="display: none;">Using massive datasets, foundation models are large-scale, pre-trained models that perform a wide range of tasks. These models have shown consistently improved results with the introduction of new methods. It is crucial to analyze how these trends impact the medical field and determine whether these advancements can drive meaningful change. This study investigates the application of recent state-of-the-art foundation models, DINOv2, MAE, VMamba, CoCa, SAM2, and AIMv2, for medical image classification. We explore their effectiveness on datasets including CBIS-DDSM for mammography, ISIC2019 for skin lesions, APTOS2019 for diabetic retinopathy, and CHEXPERT for chest radiographs. By fine-tuning these models and evaluating their configurations, we aim to understand the potential of these advancements in medical image classification. The results indicate that these advanced models significantly enhance classification outcomes, demonstrating robust performance despite limited labeled data. Based on our results, AIMv2, DINOv2, and SAM2 models outperformed others, demonstrating that progress in natural domain training has positively impacted the medical domain and improved classification outcomes. Our code is publicly available at: https://github.com/sajjad-sh33/Medical-Transfer-Learning.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 14.2%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.7%">
                            LLMs
                        </span>
                <!-- Computer Vision: 2.6 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Decision Trees: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.3873
                </span>
                <a href="https://arxiv.org/abs/2505.04121" target="_blank" rel="noopener noreferrer">Vision Graph Prompting via Semantic Low-Rank Decomposition</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zixiang Ai, Zichen Liu, Jiahuan Zhou
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Vision GNN (ViG) demonstrates superior performance by representing images as graph structures, providing a more natural way to capture irregular semantic patterns beyond traditional grid or sequence-based representations. To efficiently adapt ViG to downstream tasks, parameter-efficient fine-tuning </span>
                
                <span class="abstract-full" style="display: none;">Vision GNN (ViG) demonstrates superior performance by representing images as graph structures, providing a more natural way to capture irregular semantic patterns beyond traditional grid or sequence-based representations. To efficiently adapt ViG to downstream tasks, parameter-efficient fine-tuning techniques like visual prompting become increasingly essential. However, existing prompting methods are primarily designed for Transformer-based models, neglecting the rich topological relationships among nodes and edges in graph-based representations, limiting their capacity to model complex semantics. In this paper, we propose Vision Graph Prompting (VGP), a novel framework tailored for vision graph structures. Our core insight reveals that semantically connected components in the graph exhibit low-rank properties. Building on this observation, we introduce a semantic low-rank prompting method that decomposes low-rank semantic features and integrates them with prompts on vision graph topologies, capturing both global structural patterns and fine-grained semantic dependencies. Extensive experiments demonstrate our method significantly improves ViG's transfer performance on diverse downstream tasks, achieving results comparable to full fine-tuning while maintaining parameter efficiency. Our code is available at https://github.com/zhoujiahuan1991/ICML2025-VGP.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #b243cd" title="Confidence: 9.4%">
                            GNN
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.5%">
                            LLMs
                        </span>
                <!-- Computer Vision: 4.8 -->
                    
                <!-- Federated Learning: 2.6 -->
                    
                <!-- Medicine: 2.6 -->
                    
                <!-- HPO and AutoML: 2.0 -->
                    
                <!-- 3D: 1.9 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- T2I: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Robotics: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.6672
                </span>
                <a href="https://arxiv.org/abs/2505.19762" target="_blank" rel="noopener noreferrer">Language Model-Enhanced Message Passing for Heterophilic Graph Learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Wenjun Wang, Dawei Cheng
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Traditional graph neural networks (GNNs), which rely on homophily-driven message passing, struggle with heterophilic graphs where connected nodes exhibit dissimilar features and different labels. While existing methods address heterophily through graph structure refinement or adaptation of neighbor </span>
                
                <span class="abstract-full" style="display: none;">Traditional graph neural networks (GNNs), which rely on homophily-driven message passing, struggle with heterophilic graphs where connected nodes exhibit dissimilar features and different labels. While existing methods address heterophily through graph structure refinement or adaptation of neighbor aggregation functions, they often overlook the semantic potential of node text, rely on suboptimal message representation for propagation and compromise performance on homophilic graphs. To address these limitations, we propose a novel language model (LM)-enhanced message passing approach for heterophilic graph leaning (LEMP4HG). Specifically, in the context of text-attributed graph, we provide paired node texts for LM to generate their connection analysis, which are encoded and then fused with paired node textual embeddings through a gating mechanism. The synthesized messages are semantically enriched and adaptively balanced with both nodes' information, which mitigates contradictory signals when neighbor aggregation in heterophilic regions. Furthermore, we introduce an active learning strategy guided by our heuristic MVRD (Modulated Variation of Reliable Distance), selectively enhancing node pairs suffer most from message passing, reducing the cost of analysis generation and side effects on homophilic regions. Extensive experiments validate that our approach excels on heterophilic graphs and performs robustly on homophilic ones, with a graph convolutional network (GCN) backbone and a practical budget.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #b243cd" title="Confidence: 5.5%">
                            GNN
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.5%">
                            Medicine
                        </span>
                <!-- LLMs: 3.7 -->
                    
                <!-- Federated Learning: 2.7 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- Blockchain: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.1237
                </span>
                <a href="https://arxiv.org/abs/2505.19225" target="_blank" rel="noopener noreferrer">MedITok: A Unified Tokenizer for Medical Image Synthesis and Interpretation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Chenglong Ma, Yuanfeng Ji, Jin Ye, Zilong Li, Chenhui Wang, Junzhi Ning, Wei Li, Lihao Liu, Qiushan Guo, Tianbin Li, Junjun He, Hongming Shan
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Advanced autoregressive models have reshaped multimodal AI. However, their transformative potential in medical imaging remains largely untapped due to the absence of a unified visual tokenizer -- one capable of capturing fine-grained visual structures for faithful image reconstruction and realistic </span>
                
                <span class="abstract-full" style="display: none;">Advanced autoregressive models have reshaped multimodal AI. However, their transformative potential in medical imaging remains largely untapped due to the absence of a unified visual tokenizer -- one capable of capturing fine-grained visual structures for faithful image reconstruction and realistic image synthesis, as well as rich semantics for accurate diagnosis and image interpretation. To this end, we present MedITok, the first unified tokenizer tailored for medical images, encoding both low-level structural details and high-level clinical semantics within a unified latent space. To balance these competing objectives, we introduce a novel two-stage training framework: a visual representation alignment stage that cold-starts the tokenizer reconstruction learning with a visual semantic constraint, followed by a textual semantic representation alignment stage that infuses detailed clinical semantics into the latent space. Trained on the meticulously collected large-scale dataset with over 30 million medical images and 2 million image-caption pairs, MedITok achieves state-of-the-art performance on more than 30 datasets across 9 imaging modalities and 4 different tasks. By providing a unified token space for autoregressive modeling, MedITok supports a wide range of tasks in clinical diagnostics and generative healthcare applications. Model and code will be made publicly available at: https://github.com/Masaaki-75/meditok.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 16.5%">
                            Medicine
                        </span>
                <!-- LLMs: 3.2 -->
                    
                <!-- 3D: 2.4 -->
                    
                <!-- Computer Vision: 2.1 -->
                    
                <!-- Datasets: 1.9 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- T2I: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.8727
                </span>
                <a href="https://arxiv.org/abs/2310.10187" target="_blank" rel="noopener noreferrer">An Interpretable Deep-Learning Framework for Predicting Hospital Readmissions From Electronic Health Records</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Fabio Azzalini, Tommaso Dolci, Marco Vagaggini
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">With the increasing availability of patient data, modern medicine is shifting towards prospective healthcare. Electronic health records offer a variety of information useful for clinical patient characterization and the development of predictive models, given that similar medical histories often lea</span>
                
                <span class="abstract-full" style="display: none;">With the increasing availability of patient data, modern medicine is shifting towards prospective healthcare. Electronic health records offer a variety of information useful for clinical patient characterization and the development of predictive models, given that similar medical histories often lead to analogous health progressions. One application is the prediction of unplanned hospital readmissions, an essential task for reducing healthcare costs and improving patient outcomes. While predictive models demonstrate strong performances especially with deep learning approaches, they are often criticized for their lack of interpretability, a critical requirement in the medical domain where incorrect predictions may have severe consequences for patient safety. In this paper, we propose a novel and interpretable deep learning framework for predicting unplanned hospital readmissions, supported by NLP findings on word embeddings and by ConvLSTM neural networks for better handling temporal data. We validate the framework on two predictive tasks for hospital readmission within 30 and 180 days, using real-world data. Additionally, we introduce and evaluate a model-dependent technique designed to enhance result interpretability for medical professionals. Our solution outperforms traditional machine learning models in prediction accuracy while simultaneously providing more interpretable results.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 19.5%">
                            Medicine
                        </span>
                <!-- LLMs: 3.0 -->
                    
                <!-- Computer Vision: 2.4 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- Hardware: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.9373
                </span>
                <a href="https://arxiv.org/abs/2505.19188" target="_blank" rel="noopener noreferrer">Chordless Structure: A Pathway to Simple and Expressive GNNs</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Hongxu Pan, Shuxian Hu, Mo Zhou, Zhibin Wang, Rong Gu, Chen Tian, Kun Yang, Sheng Zhong
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Researchers have proposed various methods of incorporating more structured information into the design of Graph Neural Networks (GNNs) to enhance their expressiveness. However, these methods are either computationally expensive or lacking in provable expressiveness. In this paper, we observe that th</span>
                
                <span class="abstract-full" style="display: none;">Researchers have proposed various methods of incorporating more structured information into the design of Graph Neural Networks (GNNs) to enhance their expressiveness. However, these methods are either computationally expensive or lacking in provable expressiveness. In this paper, we observe that the chords increase the complexity of the graph structure while contributing little useful information in many cases. In contrast, chordless structures are more efficient and effective for representing the graph. Therefore, when leveraging the information of cycles, we choose to omit the chords. Accordingly, we propose a Chordless Structure-based Graph Neural Network (CSGNN) and prove that its expressiveness is strictly more powerful than the k-hop GNN (KPGNN) with polynomial complexity. Experimental results on real-world datasets demonstrate that CSGNN outperforms existing GNNs across various graph tasks while incurring lower computational costs and achieving better performance than the GNNs of 3-WL expressiveness.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #b243cd" title="Confidence: 11.8%">
                            GNN
                        </span>
                <!-- LLMs: 4.2 -->
                    
                <!-- Federated Learning: 3.1 -->
                    
                <!-- Bayesian Optimization: 2.2 -->
                    
                <!-- Medicine: 2.1 -->
                    
                <!-- Computer Vision: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -5.682
                </span>
                <a href="https://arxiv.org/abs/2505.19047" target="_blank" rel="noopener noreferrer">A Systematic Classification of Vulnerabilities in MoveEVM Smart Contracts (MWC)</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Sel\c{c}uk Topal
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We introduce the MoveEVM Weakness Classification (MWC) system -- a dedicated vulnerability taxonomy for smart contracts built with Move and executed in EVM-compatible environments. While Move was originally designed to prevent common security flaws via linear resource types and strict ownership, its</span>
                
                <span class="abstract-full" style="display: none;">We introduce the MoveEVM Weakness Classification (MWC) system -- a dedicated vulnerability taxonomy for smart contracts built with Move and executed in EVM-compatible environments. While Move was originally designed to prevent common security flaws via linear resource types and strict ownership, its integration with EVM bytecode introduces novel hybrid vulnerabilities not captured by existing systems like the SWC registry. Our taxonomy spans 37 categorized vulnerability types (MWC-100 to MWC-136) across six semantic frames, addressing issues such as hybrid gas metering, capability misuse, meta-transaction spoofing, and AI-integrated logic. Through analysis of real-world contracts from Aptos and Sui, we demonstrate that current verification tools often miss these hybrid risks. We also explore how formal methods and LLM-based audit agents can operationalize this classification, enabling scalable, logic-aware smart contract auditing. MWC lays the foundation for more secure and verifiable contracts in next-generation blockchain systems. (Shortened Abstract)</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.3%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #3cc377" title="Confidence: 5.2%">
                            Blockchain
                        </span>
                <!-- Medicine: 2.8 -->
                    
                <!-- Computer Vision: 2.4 -->
                    
                <!-- Datasets: 1.9 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -5.7176
                </span>
                <a href="https://arxiv.org/abs/2503.01762" target="_blank" rel="noopener noreferrer">Non-unitary enhanced transfer efficiency in quantum walk search on complex networks</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ugo Nzongani, Andrea Simonetto, Giuseppe Di Molfetta
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The task of finding an element in an unstructured database is known as spatial search and can be expressed as a quantum walk evolution on a graph. In this article, we modify the usual search problem by adding an extra trapping vertex to the graph, which is only connected to the target element. We st</span>
                
                <span class="abstract-full" style="display: none;">The task of finding an element in an unstructured database is known as spatial search and can be expressed as a quantum walk evolution on a graph. In this article, we modify the usual search problem by adding an extra trapping vertex to the graph, which is only connected to the target element. We study the transfer efficiency of the walker to a trapping site, using the search problem as a case study. Thus, our model offers no computational advantage for the search problem, but focuses on information transport in an open environment with a search Hamiltonian. The walker evolution is a mix between classical and quantum walk search dynamics. The balance between unitary and non-unitary dynamics is tuned with a parameter, and we numerically show that depending on the graph topology and the connectivity of the target element, this hybrid approach can outperform a purely classical or quantum evolution for reaching the trapping site. We show that this behavior is only observed in the presence of an extra trapping site, and that depending on the topology, the increase of non-unitary operations can be compensated by increasing the strength of the quantum walk exploration. This compensation comes at the cost of reducing or even suppressing the searching feature of the evolution. In that case, the unitary dynamics will only induce a regular quantum walk behavior. We also relate the optimal hybrid regime to the entropy's decay rate. As the introduction of non-unitary operations may be considered as noise, we interpret this phenomena as a noisy-assisted quantum evolution.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 8.6%">
                            Quantum Computing
                        </span>
                <!-- Reinforcement Learning: 3.3 -->
                    
                <!-- Federated Learning: 3.0 -->
                    
                <!-- Math: 2.9 -->
                    
                <!-- Evolutionary Algorithms: 2.6 -->
                    
                <!-- Bayesian Optimization: 1.8 -->
                    
                <!-- Cryptography: 1.6 -->
                    
                <!-- Networks: 1.4 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Medicine: 1.2 -->
                    
                <!-- Finance: 1.1 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -6.0212
                </span>
                <a href="https://arxiv.org/abs/2503.08962" target="_blank" rel="noopener noreferrer">On the status of current quantum machine learning software</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Manish K. Gupta, Tomasz Rybotycki, Piotr Gawron
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The recent advancements in noisy intermediate-scale quantum (NISQ) devices implementation allow us to study their application to real-life computational problems. However, hardware challenges are not the only ones that hinder our quantum computation capabilities. Software limitations are the other, </span>
                
                <span class="abstract-full" style="display: none;">The recent advancements in noisy intermediate-scale quantum (NISQ) devices implementation allow us to study their application to real-life computational problems. However, hardware challenges are not the only ones that hinder our quantum computation capabilities. Software limitations are the other, less explored side of this medal. Using satellite image segmentation as a task example, we investigated how difficult it is to run a hybrid quantum-classical model on a real, publicly available quantum device. We also analyzed the costs of such endeavor and the change in quality of model.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 11.3%">
                            Quantum Computing
                        </span>
                <!-- LLMs: 3.0 -->
                    
                <!-- Federated Learning: 2.5 -->
                    
                <!-- Evolutionary Algorithms: 2.4 -->
                    
                <!-- GNN: 2.2 -->
                    
                <!-- Blockchain: 2.1 -->
                    
                <!-- Medicine: 1.8 -->
                    
                <!-- Bayesian Optimization: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Cryptography: 1.1 -->
                    
                <!-- Networks: 1.1 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                <!-- Game Theory: 1.1 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -6.1522
                </span>
                <a href="https://arxiv.org/abs/2501.18739" target="_blank" rel="noopener noreferrer">Beyond Message Passing: Neural Graph Pattern Machine</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zehong Wang, Zheyuan Zhang, Tianyi Ma, Nitesh V Chawla, Chuxu Zhang, Yanfang Ye
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Graph learning tasks often hinge on identifying key substructure patterns -- such as triadic closures in social networks or benzene rings in molecular graphs -- that underpin downstream performance. However, most existing graph neural networks (GNNs) rely on message passing, which aggregates local n</span>
                
                <span class="abstract-full" style="display: none;">Graph learning tasks often hinge on identifying key substructure patterns -- such as triadic closures in social networks or benzene rings in molecular graphs -- that underpin downstream performance. However, most existing graph neural networks (GNNs) rely on message passing, which aggregates local neighborhood information iteratively and struggles to explicitly capture such fundamental motifs, like triangles, k-cliques, and rings. This limitation hinders both expressiveness and long-range dependency modeling. In this paper, we introduce the Neural Graph Pattern Machine (GPM), a novel framework that bypasses message passing by learning directly from graph substructures. GPM efficiently extracts, encodes, and prioritizes task-relevant graph patterns, offering greater expressivity and improved ability to capture long-range dependencies. Empirical evaluations across four standard tasks -- node classification, link prediction, graph classification, and graph regression -- demonstrate that GPM outperforms state-of-the-art baselines. Further analysis reveals that GPM exhibits strong out-of-distribution generalization, desirable scalability, and enhanced interpretability. Code and datasets are available at: https://github.com/Zehong-Wang/GPM.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #b243cd" title="Confidence: 14.6%">
                            GNN
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.6%">
                            LLMs
                        </span>
                <!-- Computer Vision: 2.6 -->
                    
                <!-- Medicine: 2.5 -->
                    
                <!-- Blockchain: 2.4 -->
                    
                <!-- HPO and AutoML: 2.2 -->
                    
                <!-- 3D: 2.0 -->
                    
                <!-- Decision Trees: 1.8 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -6.2404
                </span>
                <a href="https://arxiv.org/abs/2411.11197" target="_blank" rel="noopener noreferrer">Stealing Training Graphs from Graph Neural Networks</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Minhua Lin, Enyan Dai, Junjie Xu, Jinyuan Jia, Xiang Zhang, Suhang Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Graph Neural Networks (GNNs) have shown promising results in modeling graphs in various tasks. The training of GNNs, especially on specialized tasks such as bioinformatics, demands extensive expert annotations, which are expensive and usually contain sensitive information of data providers. The trai</span>
                
                <span class="abstract-full" style="display: none;">Graph Neural Networks (GNNs) have shown promising results in modeling graphs in various tasks. The training of GNNs, especially on specialized tasks such as bioinformatics, demands extensive expert annotations, which are expensive and usually contain sensitive information of data providers. The trained GNN models are often shared for deployment in the real world. As neural networks can memorize the training samples, the model parameters of GNNs have a high risk of leaking private training data. Our theoretical analysis shows the strong connections between trained GNN parameters and the training graphs used, confirming the training graph leakage issue. However, explorations into training data leakage from trained GNNs are rather limited. Therefore, we investigate a novel problem of stealing graphs from trained GNNs. To obtain high-quality graphs that resemble the target training set, a graph diffusion model with diffusion noise optimization is deployed as a graph generator. Furthermore, we propose a selection method that effectively leverages GNN model parameters to identify training graphs from samples generated by the graph diffusion model. Extensive experiments on real-world datasets demonstrate the effectiveness of the proposed framework in stealing training graphs from the trained GNN.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #b243cd" title="Confidence: 16.2%">
                            GNN
                        </span>
                <!-- Medicine: 2.8 -->
                    
                <!-- Bayesian Optimization: 2.2 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Reinforcement Learning: 2.0 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- LLMs: 1.6 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -7.0683
                </span>
                <a href="https://arxiv.org/abs/2309.14326" target="_blank" rel="noopener noreferrer">Efficient Pauli channel estimation with logarithmic quantum memory</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Sitan Chen, Weiyuan Gong
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Here we revisit one of the prototypical tasks for characterizing the structure of noise in quantum devices: estimating every eigenvalue of an $n$-qubit Pauli noise channel to error $\epsilon$. Prior work [14] proved no-go theorems for this task in the practical regime where one has a limited amount </span>
                
                <span class="abstract-full" style="display: none;">Here we revisit one of the prototypical tasks for characterizing the structure of noise in quantum devices: estimating every eigenvalue of an $n$-qubit Pauli noise channel to error $\epsilon$. Prior work [14] proved no-go theorems for this task in the practical regime where one has a limited amount of quantum memory, e.g. any protocol with $\le 0.99n$ ancilla qubits of quantum memory must make exponentially many measurements, provided it is non-concatenating. Such protocols can only interact with the channel by repeatedly preparing a state, passing it through the channel, and measuring immediately afterward.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 13.3%">
                            Quantum Computing
                        </span>
                <!-- LLMs: 3.1 -->
                    
                <!-- Medicine: 3.1 -->
                    
                <!-- Federated Learning: 2.5 -->
                    
                <!-- Evolutionary Algorithms: 2.3 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Bayesian Optimization: 1.6 -->
                    
                <!-- Networks: 1.5 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Math: 1.4 -->
                    
                <!-- Cryptography: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                <!-- Game Theory: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -7.6767
                </span>
                <a href="https://arxiv.org/abs/2505.19006" target="_blank" rel="noopener noreferrer">A quantitative notion of economic security for smart contract compositions</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Emily Priyadarshini, Massimo Bartoletti
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Decentralized applications are often composed of multiple interconnected smart contracts. This is especially evident in DeFi, where protocols are heavily intertwined and rely on a variety of basic building blocks such as tokens, decentralized exchanges and lending protocols. A crucial security chall</span>
                
                <span class="abstract-full" style="display: none;">Decentralized applications are often composed of multiple interconnected smart contracts. This is especially evident in DeFi, where protocols are heavily intertwined and rely on a variety of basic building blocks such as tokens, decentralized exchanges and lending protocols. A crucial security challenge in this setting arises when adversaries target individual components to cause systemic economic losses. Existing security notions focus on determining the existence of these attacks, but fail to quantify the effect of manipulating individual components on the overall economic security of the system. In this paper, we introduce a quantitative security notion that measures how an attack on a single component can amplify economic losses of the overall system. We study the fundamental properties of this notion and apply it to assess the security of key compositions. In particular, we analyse under-collateralized loan attacks in systems made of lending protocols and decentralized exchanges.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #3cc377" title="Confidence: 6.1%">
                            Blockchain
                        </span>
                <!-- LLMs: 3.9 -->
                    
                <!-- Federated Learning: 3.8 -->
                    
                <!-- Evolutionary Algorithms: 2.7 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Bayesian Optimization: 1.9 -->
                    
                <!-- Medicine: 1.7 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -8.6533
                </span>
                <a href="https://arxiv.org/abs/2504.04041" target="_blank" rel="noopener noreferrer">Authenticated Sublinear Quantum Private Information Retrieval</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Fengxia Liu, Zhiyong Zheng, Kun Tian, Yi Zhang, Heng Guo, Zhe Hu, Oleksiy Zhedanov, Zixian Gong
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper introduces a novel lower bound on communication complexity using quantum relative entropy and mutual information, refining previous classical entropy-based results. By leveraging Uhlmann's lemma and quantum Pinsker inequalities, the authors establish tighter bounds for information-theoret</span>
                
                <span class="abstract-full" style="display: none;">This paper introduces a novel lower bound on communication complexity using quantum relative entropy and mutual information, refining previous classical entropy-based results. By leveraging Uhlmann's lemma and quantum Pinsker inequalities, the authors establish tighter bounds for information-theoretic security, demonstrating that quantum protocols inherently outperform classical counterparts in balancing privacy and efficiency. Also explores symmetric Quantum Private Information Retrieval (QPIR) protocols that achieve sub-linear communication complexity while ensuring robustness against specious adversaries: A post-quantum cryptography based protocol that can be authenticated for the specious server; A ring-LWE-based protocol for post-quantum security in a single-server setting, ensuring robustness against quantum attacks; A multi-server protocol optimized for hardware practicality, reducing implementation overhead while maintaining sub-linear efficiency. These protocols address critical gaps in secure database queries, offering exponential communication improvements over classical linear-complexity methods. The work also analyzes security trade-offs under quantum specious adversaries, providing theoretical guarantees for privacy and correctness.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 14.1%">
                            Quantum Computing
                        </span>
                <!-- LLMs: 4.1 -->
                    
                <!-- Medicine: 3.0 -->
                    
                <!-- Blockchain: 2.2 -->
                    
                <!-- Computer Vision: 2.1 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Cryptography: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -8.9584
                </span>
                <a href="https://arxiv.org/abs/2505.16332" target="_blank" rel="noopener noreferrer">Is Quantum Optimization Ready? An Effort Towards Neural Network Compression using Adiabatic Quantum Computing</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zhehui Wanga, Benjamin Chen Ming Choonga, Tian Huang, Daniel Gerlinghoffa, Rick Siow Mong Goh, Cheng Liu, Tao Luo
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Quantum optimization is the most mature quantum computing technology to date, providing a promising approach towards efficiently solving complex combinatorial problems. Methods such as adiabatic quantum computing (AQC) have been employed in recent years on important optimization problems across vari</span>
                
                <span class="abstract-full" style="display: none;">Quantum optimization is the most mature quantum computing technology to date, providing a promising approach towards efficiently solving complex combinatorial problems. Methods such as adiabatic quantum computing (AQC) have been employed in recent years on important optimization problems across various domains. In deep learning, deep neural networks (DNN) have reached immense sizes to support new predictive capabilities. Optimization of large-scale models is critical for sustainable deployment, but becomes increasingly challenging with ever-growing model sizes and complexity. While quantum optimization is suitable for solving complex problems, its application to DNN optimization is not straightforward, requiring thorough reformulation for compatibility with commercially available quantum devices. In this work, we explore the potential of adopting AQC for fine-grained pruning-quantization of convolutional neural networks. We rework established heuristics to formulate model compression as a quadratic unconstrained binary optimization (QUBO) problem, and assess the solution space offered by commercial quantum annealing devices. Through our exploratory efforts of reformulation, we demonstrate that AQC can achieve effective compression of practical DNN models. Experiments demonstrate that adiabatic quantum computing (AQC) not only outperforms classical algorithms like genetic algorithms and reinforcement learning in terms of time efficiency but also excels at identifying global optima.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 14.6%">
                            Quantum Computing
                        </span>
                <!-- Bayesian Optimization: 3.5 -->
                    
                <!-- Evolutionary Algorithms: 3.4 -->
                    
                <!-- LLMs: 3.2 -->
                    
                <!-- Federated Learning: 3.1 -->
                    
                <!-- Medicine: 2.5 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- HPO and AutoML: 1.9 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -9.1385
                </span>
                <a href="https://arxiv.org/abs/2505.13525" target="_blank" rel="noopener noreferrer">Learning to Program Quantum Measurements for Machine Learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Samuel Yen-Chi Chen, Huan-Hsin Tseng, Hsin-Yi Lin, Shinjae Yoo
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The rapid advancements in quantum computing (QC) and machine learning (ML) have sparked significant interest, driving extensive exploration of quantum machine learning (QML) algorithms to address a wide range of complex challenges. The development of high-performance QML models requires expert-level</span>
                
                <span class="abstract-full" style="display: none;">The rapid advancements in quantum computing (QC) and machine learning (ML) have sparked significant interest, driving extensive exploration of quantum machine learning (QML) algorithms to address a wide range of complex challenges. The development of high-performance QML models requires expert-level expertise, presenting a key challenge to the widespread adoption of QML. Critical obstacles include the design of effective data encoding strategies and parameterized quantum circuits, both of which are vital for the performance of QML models. Furthermore, the measurement process is often neglected-most existing QML models employ predefined measurement schemes that may not align with the specific requirements of the targeted problem. We propose an innovative framework that renders the observable of a quantum system-specifically, the Hermitian matrix-trainable. This approach employs an end-to-end differentiable learning framework, enabling simultaneous optimization of the neural network used to program the parameterized observables and the standard quantum circuit parameters. Notably, the quantum observable parameters are dynamically programmed by the neural network, allowing the observables to adapt in real time based on the input data stream. Through numerical simulations, we demonstrate that the proposed method effectively programs observables dynamically within variational quantum circuits, achieving superior results compared to existing approaches. Notably, it delivers enhanced performance metrics, such as higher classification accuracy, thereby significantly improving the overall effectiveness of QML models.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 12.6%">
                            Quantum Computing
                        </span>
                <!-- Federated Learning: 4.7 -->
                    
                <!-- Reinforcement Learning: 3.3 -->
                    
                <!-- Bayesian Optimization: 2.9 -->
                    
                <!-- Evolutionary Algorithms: 2.4 -->
                    
                <!-- Medicine: 2.0 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- LLMs: 1.1 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                <!-- Math: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -9.4089
                </span>
                <a href="https://arxiv.org/abs/2408.07086" target="_blank" rel="noopener noreferrer">Quantum algorithms for optimizers</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Giacomo Nannicini
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This is a set of lecture notes for a Ph.D.-level course on quantum algorithms, with an emphasis on quantum optimization algorithms. It is developed for applied mathematicians and engineers, and requires no previous background in quantum mechanics. The main topics of this course, in addition to a rig</span>
                
                <span class="abstract-full" style="display: none;">This is a set of lecture notes for a Ph.D.-level course on quantum algorithms, with an emphasis on quantum optimization algorithms. It is developed for applied mathematicians and engineers, and requires no previous background in quantum mechanics. The main topics of this course, in addition to a rigorous introduction to the computational model, are: input/output models, quantum search, the quantum gradient algorithm, matrix manipulation algorithms, the mirror descent framework for semidefinite optimization (including the matrix multiplicative weights update algorithm), adiabatic optimization.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 14.1%">
                            Quantum Computing
                        </span>
                <!-- Medicine: 3.3 -->
                    
                <!-- Evolutionary Algorithms: 2.9 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Bayesian Optimization: 1.6 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- LLMs: 1.3 -->
                    
                <!-- Networks: 1.2 -->
                    
                <!-- Cryptography: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -9.6918
                </span>
                <a href="https://arxiv.org/abs/2409.12104" target="_blank" rel="noopener noreferrer">Performance of Quantum Approximate Optimization with Quantum Error Detection</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zichang He, David Amaro, Ruslan Shaydulin, Marco Pistoia
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Quantum algorithms must be scaled up to tackle real-world applications. Doing so requires overcoming the noise present on today's hardware. The quantum approximate optimization algorithm (QAOA) is a promising candidate for scaling up, due to its modest resource requirements and documented asymptotic</span>
                
                <span class="abstract-full" style="display: none;">Quantum algorithms must be scaled up to tackle real-world applications. Doing so requires overcoming the noise present on today's hardware. The quantum approximate optimization algorithm (QAOA) is a promising candidate for scaling up, due to its modest resource requirements and documented asymptotic speedup over state-of-the-art classical algorithms for some problems. However, achieving better-than-classical performance with QAOA is believed to require fault tolerance. In this paper, we demonstrate a partially fault-tolerant implementation of QAOA using the $[[k+2,k,2]]$ ``Iceberg'' error detection code. We observe that encoding the circuit with the Iceberg code improves the algorithmic performance as compared to the unencoded circuit for problems with up to $20$ logical qubits on a trapped-ion quantum computer. Additionally, we propose and calibrate a model for predicting the code performance. We use this model to characterize the limits of the Iceberg code and extrapolate its performance to future hardware with improved error rates. In particular, we show how our model can be used to determine the necessary conditions for QAOA to outperform the Goemans-Williamson algorithm on future hardware. To the best of our knowledge, our results demonstrate the largest universal quantum computing algorithm protected by partially fault-tolerant quantum error detection on practical applications to date, paving the way towards solving real-world applications with quantum computers.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 10.8%">
                            Quantum Computing
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #b3ebae" title="Confidence: 5.3%">
                            Federated Learning
                        </span>
                <!-- Evolutionary Algorithms: 4.0 -->
                    
                <!-- Computer Vision: 3.8 -->
                    
                <!-- Bayesian Optimization: 2.5 -->
                    
                <!-- Medicine: 1.9 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Hardware: 1.4 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -12.2946
                </span>
                <a href="https://arxiv.org/abs/2404.16366" target="_blank" rel="noopener noreferrer">Guarding Graph Neural Networks for Unsupervised Graph Anomaly Detection</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yuanchen Bei, Sheng Zhou, Jinke Shi, Yao Ma, Haishuai Wang, Jiajun Bu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Unsupervised graph anomaly detection aims at identifying rare patterns that deviate from the majority in a graph without the aid of labels, which is important for a variety of real-world applications. Recent advances have utilized Graph Neural Networks (GNNs) to learn effective node representations </span>
                
                <span class="abstract-full" style="display: none;">Unsupervised graph anomaly detection aims at identifying rare patterns that deviate from the majority in a graph without the aid of labels, which is important for a variety of real-world applications. Recent advances have utilized Graph Neural Networks (GNNs) to learn effective node representations by aggregating information from neighborhoods. This is motivated by the hypothesis that nodes in the graph tend to exhibit consistent behaviors with their neighborhoods. However, such consistency can be disrupted by graph anomalies in multiple ways. Most existing methods directly employ GNNs to learn representations, disregarding the negative impact of graph anomalies on GNNs, resulting in sub-optimal node representations and anomaly detection performance. While a few recent approaches have redesigned GNNs for graph anomaly detection under semi-supervised label guidance, how to address the adverse effects of graph anomalies on GNNs in unsupervised scenarios and learn effective representations for anomaly detection are still under-explored. To bridge this gap, in this paper, we propose a simple yet effective framework for Guarding Graph Neural Networks for Unsupervised Graph Anomaly Detection (G3AD). Specifically, G3AD first introduces two auxiliary networks along with correlation constraints to guard the GNNs against inconsistent information encoding. Furthermore, G3AD introduces an adaptive caching module to guard the GNNs from directly reconstructing the observed graph data that contains anomalies. Extensive experiments demonstrate that our G3AD can outperform twenty state-of-the-art methods on both synthetic and real-world graph anomaly datasets, with flexible generalization ability in different GNN backbones.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #b243cd" title="Confidence: 29.5%">
                            GNN
                        </span>
                <!-- Computer Vision: 3.5 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- LLMs: 1.9 -->
                    
                <!-- Medicine: 1.9 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.0 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -35.2371
                </span>
                <a href="https://arxiv.org/abs/2505.18282" target="_blank" rel="noopener noreferrer">Towards a Quantum-classical Augmented Network</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Nitin Jha, Abhishek Parakh, Mahadevan Subramaniam
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In the past decade, several small-scale quantum key distribution networks have been established. However, the deployment of large-scale quantum networks depends on the development of quantum repeaters, quantum channels, quantum memories, and quantum network protocols. To improve the security of exis</span>
                
                <span class="abstract-full" style="display: none;">In the past decade, several small-scale quantum key distribution networks have been established. However, the deployment of large-scale quantum networks depends on the development of quantum repeaters, quantum channels, quantum memories, and quantum network protocols. To improve the security of existing networks and adopt currently feasible quantum technologies, the next step is to augment classical networks with quantum devices, properties, and phenomena. To achieve this, we propose a change in the structure of the HTTP protocol such that it can carry both quantum and classical payload. This work lays the foundation for dividing one single network packet into classical and quantum payloads depending on the privacy needs. We implement logistic regression, CNN, LSTM, and BiLSTM models to classify the privacy label for outgoing communications. This enables reduced utilization of quantum resources allowing for a more efficient secure quantum network design. Experimental results using the proposed methods are presented.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 48.5%">
                            Quantum Computing
                        </span>
                <!-- Medicine: 3.2 -->
                    
                <!-- Evolutionary Algorithms: 2.4 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- LLMs: 1.2 -->
                    
                
            </div>
        </div>
        
    </div>
    
    <div class="date-section">
        <h2 class="date-header">2025-05-26</h2>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    7.1175
                </span>
                <a href="https://arxiv.org/abs/2504.13241" target="_blank" rel="noopener noreferrer">Recursive Deep Inverse Reinforcement Learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Paul Ghanem, Michael Potter, Owen Howell, Pau Closas, Alireza Ramezani, Deniz Erdogmus, Tales Imbiriba
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Inferring an adversary's goals from exhibited behavior is crucial for counterplanning and non-cooperative multi-agent systems in domains like cybersecurity, military, and strategy games. Deep Inverse Reinforcement Learning (IRL) methods based on maximum entropy principles show promise in recovering </span>
                
                <span class="abstract-full" style="display: none;">Inferring an adversary's goals from exhibited behavior is crucial for counterplanning and non-cooperative multi-agent systems in domains like cybersecurity, military, and strategy games. Deep Inverse Reinforcement Learning (IRL) methods based on maximum entropy principles show promise in recovering adversaries' goals but are typically offline, require large batch sizes with gradient descent, and rely on first-order updates, limiting their applicability in real-time scenarios. We propose an online Recursive Deep Inverse Reinforcement Learning (RDIRL) approach to recover the cost function governing the adversary actions and goals. Specifically, we minimize an upper bound on the standard Guided Cost Learning (GCL) objective using sequential second-order Newton updates, akin to the Extended Kalman Filter (EKF), leading to a fast (in terms of convergence) learning algorithm. We demonstrate that RDIRL is able to recover cost and reward functions of expert agents in standard and adversarial benchmark tasks. Experiments on benchmark tasks show that our proposed approach outperforms several leading IRL algorithms.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge high-confidence" style="background-color: #44f899" title="Confidence: 75.9%">
                            Reinforcement Learning
                        </span>
                <!-- LLMs: 3.5 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- Medicine: 2.1 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- HPO and AutoML: 1.8 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Datasets: 1.0 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    6.9515
                </span>
                <a href="https://arxiv.org/abs/2504.19229" target="_blank" rel="noopener noreferrer">Robust Nash equilibrium seeking based on semi-Markov switching topologies</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jianing Chen, Sitian Qin, Chuangyin Dang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper investigates a distributed robust Nash Equilibrium (NE) seeking problem in fluctuating environments. Specifically, the players, subject to the second-order dynamics, are considered to be influenced by external disturbances and uncertain dynamics while communicating via semi-Markov switchi</span>
                
                <span class="abstract-full" style="display: none;">This paper investigates a distributed robust Nash Equilibrium (NE) seeking problem in fluctuating environments. Specifically, the players, subject to the second-order dynamics, are considered to be influenced by external disturbances and uncertain dynamics while communicating via semi-Markov switching topologies. In such constantly changing network circumstances, the existence of disturbances and uncertain dynamics may directly affect the performance of most existing NE seeking algorithms. Moreover, the semi-Markov switching topologies may cause communication uncertainty, which are considered in NE seeking for the first time. To accommodate the above concerns, the following targets require to be reached simultaneously: (1) Disturbances and uncertain dynamics rejection in finite time; (2) Distributed estimation on unknown information required for players' cost functions; (3) A reasonable estimation consensus protocol under semi-Markov switching; (4) NE seeking for the second-order players. By combining supertwisting-based Integral Sliding-Mode Control (ISMC) with average consensus tracking, a novel robust NE seeking algorithm is constructed, incorporating an effective leader-follower consensus protocol. Furthermore, to lessen dispensable information transmission, a sampled-data-based event-triggered mechanism is introduced. Incorporating the advantages of both semi-Markov switching and event-triggered mechanism, another NE seeking algorithm is proposed. Through designing an appropriate Lyapunov-Krasovskii functional, it is shown that the leader-follower consensus can be achieved in the mean-square sense under event-triggered mechanism. Finally, a connectivity control game is formulated to illustrate the validity of the designed algorithms.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #546bc5" title="Confidence: 62.6%">
                            Game Theory
                        </span>
                <!-- Math: 3.7 -->
                    
                <!-- Networks: 3.2 -->
                    
                <!-- Cryptography: 2.7 -->
                    
                <!-- Finance: 2.4 -->
                    
                <!-- Pathfinding: 1.8 -->
                    
                <!-- Fuzzy Logic: 1.2 -->
                    
                <!-- Multi-armed Bandit: 1.1 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    2.7675
                </span>
                <a href="https://arxiv.org/abs/2504.10165" target="_blank" rel="noopener noreferrer">WildLive: Near Real-time Visual Wildlife Tracking onboard UAVs</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Nguyen Ngoc Dat, Tom Richardson, Matthew Watson, Kilian Meier, Jenna Kline, Sid Reid, Guy Maalouf, Duncan Hine, Majid Mirmehdi, Tilo Burghardt
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Live tracking of wildlife via high-resolution video processing directly onboard drones is widely unexplored and most existing solutions rely on streaming video to ground stations to support navigation. Yet, both autonomous animal-reactive flight control beyond visual line of sight and/or mission-spe</span>
                
                <span class="abstract-full" style="display: none;">Live tracking of wildlife via high-resolution video processing directly onboard drones is widely unexplored and most existing solutions rely on streaming video to ground stations to support navigation. Yet, both autonomous animal-reactive flight control beyond visual line of sight and/or mission-specific individual and behaviour recognition tasks rely to some degree on this capability. In response, we introduce WildLive - a near real-time animal detection and tracking framework for high-resolution imagery running directly onboard uncrewed aerial vehicles (UAVs). The system performs multi-animal detection and tracking at 17.81fps for HD and 7.53fps on 4K video streams suitable for operation during higher altitude flights to minimise animal disturbance. Our system is optimised for Jetson Orin AGX onboard hardware. It integrates the efficiency of sparse optical flow tracking and mission-specific sampling with device-optimised and proven YOLO-driven object detection and segmentation techniques. Essentially, computational resource is focused onto spatio-temporal regions of high uncertainty to significantly improve UAV processing speeds. Alongside, we introduce our WildLive dataset, which comprises 200K+ annotated animal instances across 19K+ frames from 4K UAV videos collected at the Ol Pejeta Conservancy in Kenya. All frames contain ground truth bounding boxes, segmentation masks, as well as individual tracklets and tracking point trajectories. We compare our system against current object tracking approaches including OC-SORT, ByteTrack, and SORT. Our multi-animal tracking experiments with onboard hardware confirm that near real-time high-resolution wildlife tracking is possible on UAVs whilst maintaining high accuracy levels as needed for future navigational and mission-specific animal-centric operational autonomy. Our materials are available at: https://dat-nguyenvn.github.io/WildLive/</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge high-confidence" style="background-color: #753a22" title="Confidence: 78.0%">
                            Computer Vision
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.2%">
                            Medicine
                        </span>
                <!-- LLMs: 3.3 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- HPO and AutoML: 1.8 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    1.071
                </span>
                <a href="https://arxiv.org/abs/2505.17732" target="_blank" rel="noopener noreferrer">RQR3D: Reparametrizing the regression targets for BEV-based 3D object detection</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ozsel Kilinc, Cem Tarhan
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Accurate, fast, and reliable 3D perception is essential for autonomous driving. Recently, bird's-eye view (BEV)-based perception approaches have emerged as superior alternatives to perspective-based solutions, offering enhanced spatial understanding and more natural outputs for planning. Existing BE</span>
                
                <span class="abstract-full" style="display: none;">Accurate, fast, and reliable 3D perception is essential for autonomous driving. Recently, bird's-eye view (BEV)-based perception approaches have emerged as superior alternatives to perspective-based solutions, offering enhanced spatial understanding and more natural outputs for planning. Existing BEV-based 3D object detection methods, typically adhering to angle-based representation, directly estimate the size and orientation of rotated bounding boxes. We observe that BEV-based 3D object detection is analogous to aerial oriented object detection, where angle-based methods are recognized for being affected by discontinuities in their loss functions. Drawing inspiration from this domain, we propose Restricted Quadrilateral Representation to define 3D regression targets. RQR3D regresses the smallest horizontal bounding box encapsulating the oriented box, along with the offsets between the corners of these two boxes, thereby transforming the oriented object detection problem into a keypoint regression task. RQR3D is compatible with any 3D object detection approach. We employ RQR3D within an anchor-free single-stage object detection method and introduce an objectness head to address class imbalance problem. Furthermore, we introduce a simplified radar fusion backbone that eliminates the need for voxel grouping and processes the BEV-mapped point cloud with standard 2D convolutions, rather than sparse convolutions. Extensive evaluations on the nuScenes dataset demonstrate that RQR3D achieves state-of-the-art performance in camera-radar 3D object detection, outperforming the previous best method by +4% in NDS and +2.4% in mAP, and significantly reducing the translation and orientation errors, which are crucial for safe autonomous driving. These consistent gains highlight the robustness, precision, and real-world readiness of our approach.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 18.4%">
                            Computer Vision
                        </span>
                <!-- Medicine: 3.8 -->
                    
                <!-- 3D: 2.6 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- LLMs: 1.5 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Hardware: 1.1 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                <!-- Evolutionary Algorithms: 1.0 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.5733
                </span>
                <a href="https://arxiv.org/abs/2503.01468" target="_blank" rel="noopener noreferrer">Overcoming Non-stationary Dynamics with Evidential Proximal Policy Optimization</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Abdullah Akg\"ul, Gulcin Baykal, Manuel Hau{\ss}mann, Melih Kandemir
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Continuous control of non-stationary environments is a major challenge for deep reinforcement learning algorithms. The time-dependency of the state transition dynamics aggravates the notorious stability problems of model-free deep actor-critic architectures. We posit that two properties will play a </span>
                
                <span class="abstract-full" style="display: none;">Continuous control of non-stationary environments is a major challenge for deep reinforcement learning algorithms. The time-dependency of the state transition dynamics aggravates the notorious stability problems of model-free deep actor-critic architectures. We posit that two properties will play a key role in overcoming non-stationarity in transition dynamics: (i) preserving the plasticity of the critic network, (ii) directed exploration for rapid adaptation to the changing dynamics. We show that performing on-policy reinforcement learning with an evidential critic provides both of these properties. The evidential design ensures a fast and sufficiently accurate approximation to the uncertainty around the state-value, which maintains the plasticity of the critic network by detecting the distributional shifts caused by the change in dynamics. The probabilistic critic also makes the actor training objective a random variable, enabling the use of directed exploration approaches as a by-product. We name the resulting algorithm as $\textit{ Evidential Proximal Policy Optimization (EPPO)}$ due to the integral role of evidential uncertainty quantification in both policy evaluation and policy improvement stages. Through experiments on non-stationary continuous control tasks, where the environment dynamics change at regular intervals, we demonstrate that our algorithm outperforms state-of-the-art on-policy reinforcement learning variants in both task-specific and overall return.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #44f899" title="Confidence: 6.5%">
                            Reinforcement Learning
                        </span>
                <!-- Bayesian Optimization: 2.9 -->
                    
                <!-- Math: 2.3 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Networks: 1.7 -->
                    
                <!-- Medicine: 1.6 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Cryptography: 1.4 -->
                    
                <!-- Game Theory: 1.4 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Finance: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- LLMs: 1.1 -->
                    
                <!-- Computer Vision: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.3423
                </span>
                <a href="https://arxiv.org/abs/2505.17473" target="_blank" rel="noopener noreferrer">OrionBench: A Benchmark for Chart and Human-Recognizable Object Detection in Infographics</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jiangning Zhu, Yuxing Zhou, Zheng Wang, Juntao Yao, Yima Gu, Yuhui Yuan, Shixia Liu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Given the central role of charts in scientific, business, and communication contexts, enhancing the chart understanding capabilities of vision-language models (VLMs) has become increasingly critical. A key limitation of existing VLMs lies in their inaccurate visual grounding of infographic elements,</span>
                
                <span class="abstract-full" style="display: none;">Given the central role of charts in scientific, business, and communication contexts, enhancing the chart understanding capabilities of vision-language models (VLMs) has become increasingly critical. A key limitation of existing VLMs lies in their inaccurate visual grounding of infographic elements, including charts and human-recognizable objects (HROs) such as icons and images. However, chart understanding often requires identifying relevant elements and reasoning over them. To address this limitation, we introduce OrionBench, a benchmark designed to support the development of accurate object detection models for charts and HROs in infographics. It contains 26,250 real and 78,750 synthetic infographics, with over 6.9 million bounding box annotations. These annotations are created by combining the model-in-the-loop and programmatic methods. We demonstrate the usefulness of OrionBench through three applications: 1) constructing a Thinking-with-Boxes scheme to boost the chart understanding performance of VLMs, 2) comparing existing object detection models, and 3) applying the developed detection model to document layout and UI element detection.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.6%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.1%">
                            Computer Vision
                        </span>
                <!-- Medicine: 4.1 -->
                    
                <!-- Hardware: 2.2 -->
                    
                <!-- Datasets: 2.1 -->
                    
                <!-- Blockchain: 2.1 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.3095
                </span>
                <a href="https://arxiv.org/abs/2505.11532" target="_blank" rel="noopener noreferrer">Revisiting Adversarial Perception Attacks and Defense Methods on Autonomous Driving Systems</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Cheng Chen, Yuhong Wang, Nafis S Munir, Xiangwei Zhou, Xugui Zhou
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Autonomous driving systems (ADS) increasingly rely on deep learning-based perception models, which remain vulnerable to adversarial attacks. In this paper, we revisit adversarial attacks and defense methods, focusing on road sign recognition and lead object detection and prediction (e.g., relative d</span>
                
                <span class="abstract-full" style="display: none;">Autonomous driving systems (ADS) increasingly rely on deep learning-based perception models, which remain vulnerable to adversarial attacks. In this paper, we revisit adversarial attacks and defense methods, focusing on road sign recognition and lead object detection and prediction (e.g., relative distance). Using a Level-2 production ADS, OpenPilot by Comma$.$ai, and the widely adopted YOLO model, we systematically examine the impact of adversarial perturbations and assess defense techniques, including adversarial training, image processing, contrastive learning, and diffusion models. Our experiments highlight both the strengths and limitations of these methods in mitigating complex attacks. Through targeted evaluations of model robustness, we aim to provide deeper insights into the vulnerabilities of ADS perception systems and contribute guidance for developing more resilient defense strategies.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.6%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 6.2%">
                            Computer Vision
                        </span>
                <!-- Medicine: 5.0 -->
                    
                <!-- Blockchain: 2.6 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2852
                </span>
                <a href="https://arxiv.org/abs/2505.17692" target="_blank" rel="noopener noreferrer">ViP$^2$-CLIP: Visual-Perception Prompting with Unified Alignment for Zero-Shot Anomaly Detection</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ziteng Yang, Jingzehua Xu, Yanshu Li, Zepeng Li, Yeqiang Wang, Xinghui Li
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Zero-shot anomaly detection (ZSAD) aims to detect anomalies without any target domain training samples, relying solely on external auxiliary data. Existing CLIP-based methods attempt to activate the model's ZSAD potential via handcrafted or static learnable prompts. The former incur high engineering</span>
                
                <span class="abstract-full" style="display: none;">Zero-shot anomaly detection (ZSAD) aims to detect anomalies without any target domain training samples, relying solely on external auxiliary data. Existing CLIP-based methods attempt to activate the model's ZSAD potential via handcrafted or static learnable prompts. The former incur high engineering costs and limited semantic coverage, whereas the latter apply identical descriptions across diverse anomaly types, thus fail to adapt to complex variations. Furthermore, since CLIP is originally pretrained on large-scale classification tasks, its anomaly segmentation quality is highly sensitive to the exact wording of class names, severely constraining prompting strategies that depend on class labels. To address these challenges, we introduce ViP$^{2}$-CLIP. The key insight of ViP$^{2}$-CLIP is a Visual-Perception Prompting (ViP-Prompt) mechanism, which fuses global and multi-scale local visual context to adaptively generate fine-grained textual prompts, eliminating manual templates and class-name priors. This design enables our model to focus on precise abnormal regions, making it particularly valuable when category labels are ambiguous or privacy-constrained. Extensive experiments on 15 industrial and medical benchmarks demonstrate that ViP$^{2}$-CLIP achieves state-of-the-art performance and robust cross-domain generalization.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.3%">
                            Computer Vision
                        </span>
                <!-- LLMs: 3.6 -->
                    
                <!-- Medicine: 3.1 -->
                    
                <!-- GNN: 3.1 -->
                    
                <!-- Federated Learning: 3.0 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2801
                </span>
                <a href="https://arxiv.org/abs/2505.17364" target="_blank" rel="noopener noreferrer">Optimizing YOLOv8 for Parking Space Detection: Comparative Analysis of Custom YOLOv8 Architecture</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Apar Pokhrel, Gia Dao
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Parking space occupancy detection is a critical component in the development of intelligent parking management systems. Traditional object detection approaches, such as YOLOv8, provide fast and accurate vehicle detection across parking lots but can struggle with borderline cases, such as partially v</span>
                
                <span class="abstract-full" style="display: none;">Parking space occupancy detection is a critical component in the development of intelligent parking management systems. Traditional object detection approaches, such as YOLOv8, provide fast and accurate vehicle detection across parking lots but can struggle with borderline cases, such as partially visible vehicles, small vehicles (e.g., motorcycles), and poor lighting conditions. In this work, we perform a comprehensive comparative analysis of customized backbone architectures integrated with YOLOv8. Specifically, we evaluate various backbones -- ResNet-18, VGG16, EfficientNetV2, Ghost -- on the PKLot dataset in terms of detection accuracy and computational efficiency. Experimental results highlight each architecture's strengths and trade-offs, providing insight into selecting suitable models for parking occupancy.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.9%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.6%">
                            Computer Vision
                        </span>
                <!-- Medicine: 4.6 -->
                    
                <!-- Blockchain: 2.4 -->
                    
                <!-- Datasets: 2.1 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2413
                </span>
                <a href="https://arxiv.org/abs/2505.17245" target="_blank" rel="noopener noreferrer">Extending Dataset Pruning to Object Detection: A Variance-based Approach</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ryota Yagi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Dataset pruning -- selecting a small yet informative subset of training data -- has emerged as a promising strategy for efficient machine learning, offering significant reductions in computational cost and storage compared to alternatives like dataset distillation. While pruning methods have shown s</span>
                
                <span class="abstract-full" style="display: none;">Dataset pruning -- selecting a small yet informative subset of training data -- has emerged as a promising strategy for efficient machine learning, offering significant reductions in computational cost and storage compared to alternatives like dataset distillation. While pruning methods have shown strong performance in image classification, their extension to more complex computer vision tasks, particularly object detection, remains relatively underexplored. In this paper, we present the first principled extension of classification pruning techniques to the object detection domain, to the best of our knowledge. We identify and address three key challenges that hinder this transition: the Object-Level Attribution Problem, the Scoring Strategy Problem, and the Image-Level Aggregation Problem. To overcome these, we propose tailored solutions, including a novel scoring method called Variance-based Prediction Score (VPS). VPS leverages both Intersection over Union (IoU) and confidence scores to effectively identify informative training samples specific to detection tasks. Extensive experiments on PASCAL VOC and MS COCO demonstrate that our approach consistently outperforms prior dataset pruning methods in terms of mean Average Precision (mAP). We also show that annotation count and class distribution shift can influence detection performance, but selecting informative examples is a more critical factor than dataset size or balance. Our work bridges dataset pruning and object detection, paving the way for dataset pruning in complex vision tasks.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.3%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.4%">
                            Computer Vision
                        </span>
                <!-- GNN: 2.1 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Medicine: 2.0 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Hardware: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2226
                </span>
                <a href="https://arxiv.org/abs/2412.11803" target="_blank" rel="noopener noreferrer">UAlign: Leveraging Uncertainty Estimations for Factuality Alignment on Large Language Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Boyang Xue, Fei Mi, Qi Zhu, Hongru Wang, Rui Wang, Sheng Wang, Erxin Yu, Xuming Hu, Kam-Fai Wong
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Despite demonstrating impressive capabilities, Large Language Models (LLMs) still often struggle to accurately express the factual knowledge they possess, especially in cases where the LLMs' knowledge boundaries are ambiguous. To improve LLMs' factual expressions, we propose the UAlign framework, wh</span>
                
                <span class="abstract-full" style="display: none;">Despite demonstrating impressive capabilities, Large Language Models (LLMs) still often struggle to accurately express the factual knowledge they possess, especially in cases where the LLMs' knowledge boundaries are ambiguous. To improve LLMs' factual expressions, we propose the UAlign framework, which leverages Uncertainty estimations to represent knowledge boundaries, and then explicitly incorporates these representations as input features into prompts for LLMs to Align with factual knowledge. First, we prepare the dataset on knowledge question-answering (QA) samples by calculating two uncertainty estimations, including confidence score and semantic entropy, to represent the knowledge boundaries for LLMs. Subsequently, using the prepared dataset, we train a reward model that incorporates uncertainty estimations and then employ the Proximal Policy Optimization (PPO) algorithm for factuality alignment on LLMs. Experimental results indicate that, by integrating uncertainty representations in LLM alignment, the proposed UAlign can significantly enhance the LLMs' capacities to confidently answer known questions and refuse unknown questions on both in-domain and out-of-domain tasks, showing reliability improvements and good generalizability over various prompt- and training-based baselines.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 11.0%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.7%">
                            Computer Vision
                        </span>
                <!-- Medicine: 2.8 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- 3D: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2125
                </span>
                <a href="https://arxiv.org/abs/2505.17460" target="_blank" rel="noopener noreferrer">Learning to Focus: Context Extraction for Efficient Code Vulnerability Detection with Language Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Xinran Zheng, Xingzhi Qian, Huichi Zhou, Shuo Yang, Yiling He, Suman Jana, Lorenzo Cavallaro
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Language models (LMs) show promise for vulnerability detection but struggle with long, real-world code due to sparse and uncertain vulnerability locations. These issues, exacerbated by token limits, often cause models to miss vulnerability-related signals, thereby impairing effective learning. A key</span>
                
                <span class="abstract-full" style="display: none;">Language models (LMs) show promise for vulnerability detection but struggle with long, real-world code due to sparse and uncertain vulnerability locations. These issues, exacerbated by token limits, often cause models to miss vulnerability-related signals, thereby impairing effective learning. A key intuition is to enhance LMs with concise, information-rich context. Commit-based annotations offer precise, CWE-agnostic supervision, but are unavailable during inference, as they depend on historical code changes. Moreover, their extreme sparsity, often covering only a few lines, makes it difficult for LMs to process directly. In this paper, we propose FocusVul, a model-agnostic framework that improves LM-based vulnerability detection by learning to select sensitive context. FocusVul learns commit-based annotation patterns through hierarchical semantic modeling and generalizes them to identify line-level vulnerability-relevant regions during inference. It then extracts LM-oriented context via both dependency and execution flows surrounding selected regions, yielding semantically rich inputs for effective vulnerability detection. Experiments on real-world benchmarks show that FocusVul consistently outperforms heuristic-based and full-function fine-tuning approaches, improving classification performance by 164.04% and reducing FLOPs by 19.12% on average.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.8%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.1%">
                            Computer Vision
                        </span>
                <!-- Medicine: 2.9 -->
                    
                <!-- HPO and AutoML: 2.8 -->
                    
                <!-- Federated Learning: 2.8 -->
                    
                <!-- GNN: 2.3 -->
                    
                <!-- Decision Trees: 2.3 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- 3D: 1.8 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2109
                </span>
                <a href="https://arxiv.org/abs/2411.14503" target="_blank" rel="noopener noreferrer">Planning-Driven Programming: A Large Language Model Programming Workflow</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Chao Lei, Yanchuan Chang, Nir Lipovetzky, Krista A. Ehinger
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The strong performance of large language models (LLMs) raises extensive discussion on their application to code generation. Recent research suggests continuous program refinements through visible tests to improve code generation accuracy in LLMs. However, these methods suffer from LLMs' inefficiency</span>
                
                <span class="abstract-full" style="display: none;">The strong performance of large language models (LLMs) raises extensive discussion on their application to code generation. Recent research suggests continuous program refinements through visible tests to improve code generation accuracy in LLMs. However, these methods suffer from LLMs' inefficiency and limited reasoning capacity. In this work, we propose an LLM programming workflow (LPW) designed to improve both initial code generation and subsequent refinements within a structured two-phase workflow. Specifically, the solution generation phase formulates a solution plan, which is then verified through visible tests to specify the intended natural language solution. Subsequently, the code implementation phase drafts an initial code according to the solution plan and its verification. If the generated code fails the visible tests, the plan verification serves as the intended solution to consistently inform the refinement process for correcting bugs. Compared to state-of-the-art methods across various existing LLMs, LPW significantly improves the Pass@1 accuracy by up to 16.4% on well-established text-to-code generation benchmarks. LPW also sets new state-of-the-art Pass@1 accuracy, achieving 98.2% on HumanEval, 84.8% on MBPP, 59.3% on LiveCode, 62.6% on APPS, and 34.7% on CodeContest, using GPT-4o as the backbone. Our code is publicly available at: https://github.com/you68681/lpw</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.9%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.0%">
                            Computer Vision
                        </span>
                <!-- Federated Learning: 2.4 -->
                    
                <!-- GNN: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 2.2 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Medicine: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.1969
                </span>
                <a href="https://arxiv.org/abs/2505.17654" target="_blank" rel="noopener noreferrer">EVADE: Multimodal Benchmark for Evasive Content Detection in E-Commerce Applications</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ancheng Xu, Zhihao Yang, Jingpeng Li, Guanghu Yuan, Longze Chen, Liang Yan, Jiehui Zhou, Zhen Qin, Hengyun Chang, Hamid Alinejad-Rokny, Bo Zheng, Min Yang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">E-commerce platforms increasingly rely on Large Language Models (LLMs) and Vision-Language Models (VLMs) to detect illicit or misleading product content. However, these models remain vulnerable to evasive content: inputs (text or images) that superficially comply with platform policies while covertl</span>
                
                <span class="abstract-full" style="display: none;">E-commerce platforms increasingly rely on Large Language Models (LLMs) and Vision-Language Models (VLMs) to detect illicit or misleading product content. However, these models remain vulnerable to evasive content: inputs (text or images) that superficially comply with platform policies while covertly conveying prohibited claims. Unlike traditional adversarial attacks that induce overt failures, evasive content exploits ambiguity and context, making it far harder to detect. Existing robustness benchmarks provide little guidance for this demanding, real-world challenge. We introduce EVADE, the first expert-curated, Chinese, multimodal benchmark specifically designed to evaluate foundation models on evasive content detection in e-commerce. The dataset contains 2,833 annotated text samples and 13,961 images spanning six demanding product categories, including body shaping, height growth, and health supplements. Two complementary tasks assess distinct capabilities: Single-Violation, which probes fine-grained reasoning under short prompts, and All-in-One, which tests long-context reasoning by merging overlapping policy rules into unified instructions. Notably, the All-in-One setting significantly narrows the performance gap between partial and full-match accuracy, suggesting that clearer rule definitions improve alignment between human and model judgment. We benchmark 26 mainstream LLMs and VLMs and observe substantial performance gaps: even state-of-the-art models frequently misclassify evasive samples. By releasing EVADE and strong baselines, we provide the first rigorous standard for evaluating evasive-content detection, expose fundamental limitations in current multimodal reasoning, and lay the groundwork for safer and more transparent content moderation systems in e-commerce. The dataset is publicly available at https://huggingface.co/datasets/koenshen/EVADE-Bench.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 15.0%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.2%">
                            Computer Vision
                        </span>
                <!-- Medicine: 4.6 -->
                    
                <!-- Datasets: 2.2 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Decision Trees: 2.0 -->
                    
                <!-- HPO and AutoML: 1.9 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.1188
                </span>
                <a href="https://arxiv.org/abs/2505.17393" target="_blank" rel="noopener noreferrer">Spectral Mixture Kernels for Bayesian Optimization</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yi Zhang, Cheng Hua
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Bayesian Optimization (BO) is a widely used approach for solving expensive black-box optimization tasks. However, selecting an appropriate probabilistic surrogate model remains an important yet challenging problem. In this work, we introduce a novel Gaussian Process (GP)-based BO method that incorpo</span>
                
                <span class="abstract-full" style="display: none;">Bayesian Optimization (BO) is a widely used approach for solving expensive black-box optimization tasks. However, selecting an appropriate probabilistic surrogate model remains an important yet challenging problem. In this work, we introduce a novel Gaussian Process (GP)-based BO method that incorporates spectral mixture kernels, derived from spectral densities formed by scale-location mixtures of Cauchy and Gaussian distributions. This method achieves a significant improvement in both efficiency and optimization performance, matching the computational speed of simpler kernels while delivering results that outperform more complex models and automatic BO methods. We provide bounds on the information gain and cumulative regret associated with obtaining the optimum. Extensive numerical experiments demonstrate that our method consistently outperforms existing baselines across a diverse range of synthetic and real-world problems, including both low- and high-dimensional settings.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.4%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #31bb31" title="Confidence: 5.2%">
                            Bayesian Optimization
                        </span>
                <!-- Medicine: 3.5 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- 3D: 2.0 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.0567
                </span>
                <a href="https://arxiv.org/abs/2505.17589" target="_blank" rel="noopener noreferrer">CosyVoice 3: Towards In-the-wild Speech Generation via Scaling-up and Post-training</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zhihao Du, Changfeng Gao, Yuxuan Wang, Fan Yu, Tianyu Zhao, Hao Wang, Xiang Lv, Hui Wang, Xian Shi, Keyu An, Guanrou Yang, Yabin Li, Yanni Chen, Zhifu Gao, Qian Chen, Yue Gu, Mengzhe Chen, Yafeng Chen, Shiliang Zhang, Wen Wang, Jieping Ye
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In our prior works, we introduced a scalable streaming speech synthesis model, CosyVoice 2, which integrates a large language model (LLM) and a chunk-aware flow matching (FM) model, and achieves low-latency bi-streaming speech synthesis and human-parity quality. Despite these advancements, CosyVoice</span>
                
                <span class="abstract-full" style="display: none;">In our prior works, we introduced a scalable streaming speech synthesis model, CosyVoice 2, which integrates a large language model (LLM) and a chunk-aware flow matching (FM) model, and achieves low-latency bi-streaming speech synthesis and human-parity quality. Despite these advancements, CosyVoice 2 exhibits limitations in language coverage, domain diversity, data volume, text formats, and post-training techniques. In this paper, we present CosyVoice 3, an improved model designed for zero-shot multilingual speech synthesis in the wild, surpassing its predecessor in content consistency, speaker similarity, and prosody naturalness. Key features of CosyVoice 3 include: 1) A novel speech tokenizer to improve prosody naturalness, developed via supervised multi-task training, including automatic speech recognition, speech emotion recognition, language identification, audio event detection, and speaker analysis. 2) A new differentiable reward model for post-training applicable not only to CosyVoice 3 but also to other LLM-based speech synthesis models. 3) Dataset Size Scaling: Training data is expanded from ten thousand hours to one million hours, encompassing 9 languages and 18 Chinese dialects across various domains and text formats. 4) Model Size Scaling: Model parameters are increased from 0.5 billion to 1.5 billion, resulting in enhanced performance on our multilingual benchmark due to the larger model capacity. These advancements contribute significantly to the progress of speech synthesis in the wild. We encourage readers to listen to the demo at https://funaudiollm.github.io/cosyvoice3.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.5%">
                            LLMs
                        </span>
                <!-- Computer Vision: 3.7 -->
                    
                <!-- Medicine: 3.6 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- 3D: 1.1 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.0639
                </span>
                <a href="https://arxiv.org/abs/2505.17638" target="_blank" rel="noopener noreferrer">Why Diffusion Models Don't Memorize: The Role of Implicit Dynamical Regularization in Training</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Tony Bonnaire, Rapha\"el Urfin, Giulio Biroli, Marc M\'ezard
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Diffusion models have achieved remarkable success across a wide range of generative tasks. A key challenge is understanding the mechanisms that prevent their memorization of training data and allow generalization. In this work, we investigate the role of the training dynamics in the transition from </span>
                
                <span class="abstract-full" style="display: none;">Diffusion models have achieved remarkable success across a wide range of generative tasks. A key challenge is understanding the mechanisms that prevent their memorization of training data and allow generalization. In this work, we investigate the role of the training dynamics in the transition from generalization to memorization. Through extensive experiments and theoretical analysis, we identify two distinct timescales: an early time $\tau_\mathrm{gen}$ at which models begin to generate high-quality samples, and a later time $\tau_\mathrm{mem}$ beyond which memorization emerges. Crucially, we find that $\tau_\mathrm{mem}$ increases linearly with the training set size $n$, while $\tau_\mathrm{gen}$ remains constant. This creates a growing window of training times with $n$ where models generalize effectively, despite showing strong memorization if training continues beyond it. It is only when $n$ becomes larger than a model-dependent threshold that overfitting disappears at infinite training times. These findings reveal a form of implicit dynamical regularization in the training dynamics, which allow to avoid memorization even in highly overparameterized settings. Our results are supported by numerical experiments with standard U-Net architectures on realistic and synthetic datasets, and by a theoretical analysis using a tractable random features model studied in the high-dimensional limit.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.7%">
                            LLMs
                        </span>
                <!-- Medicine: 2.7 -->
                    
                <!-- Federated Learning: 2.6 -->
                    
                <!-- GNN: 2.3 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.0903
                </span>
                <a href="https://arxiv.org/abs/2503.04556" target="_blank" rel="noopener noreferrer">Compositional Causal Reasoning Evaluation in Language Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jacqueline R. M. A. Maasch, Alihan H\"uy\"uk, Xinnuo Xu, Aditya V. Nori, Javier Gonzalez
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Causal reasoning and compositional reasoning are two core aspirations in AI. Measuring the extent of these behaviors requires principled evaluation methods. We explore a unified perspective that considers both behaviors simultaneously, termed compositional causal reasoning (CCR): the ability to infe</span>
                
                <span class="abstract-full" style="display: none;">Causal reasoning and compositional reasoning are two core aspirations in AI. Measuring the extent of these behaviors requires principled evaluation methods. We explore a unified perspective that considers both behaviors simultaneously, termed compositional causal reasoning (CCR): the ability to infer how causal measures compose and, equivalently, how causal quantities propagate through graphs. We instantiate a framework for the systematic evaluation of CCR for the average treatment effect and the probability of necessity and sufficiency. As proof of concept, we demonstrate CCR evaluation for language models in the LLama, Phi, and GPT families. On a math word problem, our framework revealed a range of taxonomically distinct error patterns. CCR errors increased with the complexity of causal paths for all models except o1.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 11.7%">
                            LLMs
                        </span>
                <!-- Medicine: 4.8 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Math: 1.0 -->
                    
                <!-- Computer Vision: 1.0 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.1221
                </span>
                <a href="https://arxiv.org/abs/2505.17202" target="_blank" rel="noopener noreferrer">CHART-6: Human-Centered Evaluation of Data Visualization Understanding in Vision-Language Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Arnav Verma, Kushin Mukherjee, Christopher Potts, Elisa Kreiss, Judith E. Fan
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Data visualizations are powerful tools for communicating patterns in quantitative data. Yet understanding any data visualization is no small feat -- succeeding requires jointly making sense of visual, numerical, and linguistic inputs arranged in a conventionalized format one has previously learned t</span>
                
                <span class="abstract-full" style="display: none;">Data visualizations are powerful tools for communicating patterns in quantitative data. Yet understanding any data visualization is no small feat -- succeeding requires jointly making sense of visual, numerical, and linguistic inputs arranged in a conventionalized format one has previously learned to parse. Recently developed vision-language models are, in principle, promising candidates for developing computational models of these cognitive operations. However, it is currently unclear to what degree these models emulate human behavior on tasks that involve reasoning about data visualizations. This gap reflects limitations in prior work that has evaluated data visualization understanding in artificial systems using measures that differ from those typically used to assess these abilities in humans. Here we evaluated eight vision-language models on six data visualization literacy assessments designed for humans and compared model responses to those of human participants. We found that these models performed worse than human participants on average, and this performance gap persisted even when using relatively lenient criteria to assess model performance. Moreover, while relative performance across items was somewhat correlated between models and humans, all models produced patterns of errors that were reliably distinct from those produced by human participants. Taken together, these findings suggest significant opportunities for further development of artificial systems that might serve as useful models of how humans reason about data visualizations. All code and data needed to reproduce these results are available at: https://osf.io/e25mu/?view_only=399daff5a14d4b16b09473cf19043f18.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 17.1%">
                            LLMs
                        </span>
                <!-- Medicine: 3.7 -->
                    
                <!-- Decision Trees: 2.9 -->
                    
                <!-- Datasets: 2.2 -->
                    
                <!-- Quantum Computing: 2.0 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.1261
                </span>
                <a href="https://arxiv.org/abs/2407.01796" target="_blank" rel="noopener noreferrer">Ground Every Sentence: Improving Retrieval-Augmented LLMs with Interleaved Reference-Claim Generation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Sirui Xia, Xintao Wang, Jiaqing Liang, Yifei Zhang, Weikang Zhou, Jiaji Deng, Fei Yu, Yanghua Xiao
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Retrieval-Augmented Generation (RAG) has been widely adopted to enhance Large Language Models (LLMs) in knowledge-intensive tasks. To enhance credibility and verifiability in RAG systems, Attributed Text Generation (ATG) is proposed, which provides citations to retrieval knowledge in LLM-generated r</span>
                
                <span class="abstract-full" style="display: none;">Retrieval-Augmented Generation (RAG) has been widely adopted to enhance Large Language Models (LLMs) in knowledge-intensive tasks. To enhance credibility and verifiability in RAG systems, Attributed Text Generation (ATG) is proposed, which provides citations to retrieval knowledge in LLM-generated responses. Prior methods mainly adopt coarse-grained attributions, with passage-level or paragraph-level references or citations, which fall short in verifiability. This paper proposes ReClaim (Refer & Claim), a fine-grained ATG method that alternates the generation of references and answers step by step. Different from previous coarse-grained attribution, ReClaim provides sentence-level citations in long-form question-answering tasks. With extensive experiments, we verify the effectiveness of ReClaim in extensive settings, achieving a citation accuracy rate of 90%.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 20.2%">
                            LLMs
                        </span>
                <!-- GNN: 2.3 -->
                    
                <!-- Medicine: 2.1 -->
                    
                <!-- RAG: 2.1 -->
                    
                <!-- Blockchain: 2.1 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Game Theory: 1.8 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Cryptography: 1.3 -->
                    
                <!-- Networks: 1.3 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- 3D: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.1448
                </span>
                <a href="https://arxiv.org/abs/2505.17447" target="_blank" rel="noopener noreferrer">LeTS: Learning to Think-and-Search via Process-and-Outcome Reward Hybridization</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Qi Zhang, Shouqing Yang, Lirong Gao, Hao Chen, Xiaomeng Hu, Jinglei Chen, Jiexiang Wang, Sheng Guo, Bo Zheng, Haobo Wang, Junbo Zhao
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Large language models (LLMs) have demonstrated impressive capabilities in reasoning with the emergence of reasoning models like OpenAI-o1 and DeepSeek-R1. Recent research focuses on integrating reasoning capabilities into the realm of retrieval-augmented generation (RAG) via outcome-supervised reinf</span>
                
                <span class="abstract-full" style="display: none;">Large language models (LLMs) have demonstrated impressive capabilities in reasoning with the emergence of reasoning models like OpenAI-o1 and DeepSeek-R1. Recent research focuses on integrating reasoning capabilities into the realm of retrieval-augmented generation (RAG) via outcome-supervised reinforcement learning (RL) approaches, while the correctness of intermediate think-and-search steps is usually neglected. To address this issue, we design a process-level reward module to mitigate the unawareness of intermediate reasoning steps in outcome-level supervision without additional annotation. Grounded on this, we propose Learning to Think-and-Search (LeTS), a novel framework that hybridizes stepwise process reward and outcome-based reward to current RL methods for RAG. Extensive experiments demonstrate the generalization and inference efficiency of LeTS across various RAG benchmarks. In addition, these results reveal the potential of process- and outcome-level reward hybridization in boosting LLMs' reasoning ability via RL under other scenarios. The code will be released soon.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 17.4%">
                            LLMs
                        </span>
                <!-- Federated Learning: 3.6 -->
                    
                <!-- Medicine: 3.0 -->
                    
                <!-- Evolutionary Algorithms: 2.2 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Bayesian Optimization: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Datasets: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.1465
                </span>
                <a href="https://arxiv.org/abs/2503.08200" target="_blank" rel="noopener noreferrer">Route Sparse Autoencoder to Interpret Large Language Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Wei Shi, Sihang Li, Tao Liang, Mingyang Wan, Guojun Ma, Xiang Wang, Xiangnan He
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Mechanistic interpretability of large language models (LLMs) aims to uncover the internal processes of information propagation and reasoning. Sparse autoencoders (SAEs) have demonstrated promise in this domain by extracting interpretable and monosemantic features. However, prior works primarily focu</span>
                
                <span class="abstract-full" style="display: none;">Mechanistic interpretability of large language models (LLMs) aims to uncover the internal processes of information propagation and reasoning. Sparse autoencoders (SAEs) have demonstrated promise in this domain by extracting interpretable and monosemantic features. However, prior works primarily focus on feature extraction from a single layer, failing to effectively capture activations that span multiple layers. In this paper, we introduce Route Sparse Autoencoder (RouteSAE), a new framework that integrates a routing mechanism with a shared SAE to efficiently extract features from multiple layers. It dynamically assigns weights to activations from different layers, incurring minimal parameter overhead while achieving high interpretability and flexibility for targeted feature manipulation. We evaluate RouteSAE through extensive experiments on Llama-3.2-1B-Instruct. Specifically, under the same sparsity constraint of 64, RouteSAE extracts 22.5% more features than baseline SAEs while achieving a 22.3% higher interpretability score. These results underscore the potential of RouteSAE as a scalable and effective method for LLM interpretability, with applications in feature discovery and model intervention. Our codes are available at https://github.com/swei2001/RouteSAEs.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 20.5%">
                            LLMs
                        </span>
                <!-- Medicine: 3.5 -->
                    
                <!-- GNN: 2.5 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                <!-- Datasets: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.7557
                </span>
                <a href="https://arxiv.org/abs/2505.17590" target="_blank" rel="noopener noreferrer">CGS-GAN: 3D Consistent Gaussian Splatting GANs for High Resolution Human Head Synthesis</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Florian Barthel, Wieland Morgenstern, Paul Hinzer, Anna Hilsmann, Peter Eisert
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Recently, 3D GANs based on 3D Gaussian splatting have been proposed for high quality synthesis of human heads. However, existing methods stabilize training and enhance rendering quality from steep viewpoints by conditioning the random latent vector on the current camera position. This compromises 3D</span>
                
                <span class="abstract-full" style="display: none;">Recently, 3D GANs based on 3D Gaussian splatting have been proposed for high quality synthesis of human heads. However, existing methods stabilize training and enhance rendering quality from steep viewpoints by conditioning the random latent vector on the current camera position. This compromises 3D consistency, as we observe significant identity changes when re-synthesizing the 3D head with each camera shift. Conversely, fixing the camera to a single viewpoint yields high-quality renderings for that perspective but results in poor performance for novel views. Removing view-conditioning typically destabilizes GAN training, often causing the training to collapse. In response to these challenges, we introduce CGS-GAN, a novel 3D Gaussian Splatting GAN framework that enables stable training and high-quality 3D-consistent synthesis of human heads without relying on view-conditioning. To ensure training stability, we introduce a multi-view regularization technique that enhances generator convergence with minimal computational overhead. Additionally, we adapt the conditional loss used in existing 3D Gaussian splatting GANs and propose a generator architecture designed to not only stabilize training but also facilitate efficient rendering and straightforward scaling, enabling output resolutions up to $2048^2$. To evaluate the capabilities of CGS-GAN, we curate a new dataset derived from FFHQ. This dataset enables very high resolutions, focuses on larger portions of the human head, reduces view-dependent artifacts for improved 3D consistency, and excludes images where subjects are obscured by hands or other objects. As a result, our approach achieves very high rendering quality, supported by competitive FID scores, while ensuring consistent 3D scene generation. Check our our project page here: https://fraunhoferhhi.github.io/cgs-gan/</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #76aa96" title="Confidence: 7.6%">
                            3D
                        </span>
                <!-- Medicine: 3.3 -->
                    
                <!-- Federated Learning: 3.0 -->
                    
                <!-- GNN: 2.6 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- LLMs: 2.1 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.114
                </span>
                <a href="https://arxiv.org/abs/2505.17098" target="_blank" rel="noopener noreferrer">TACO: Enhancing Multimodal In-context Learning via Task Mapping-Guided Sequence Configuration</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yanshu Li, Tian Yun, Jianjiang Yang, Pinyuan Feng, Jinfa Huang, Ruixiang Tang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Multimodal in-context learning (ICL) has emerged as a key mechanism for harnessing the capabilities of large vision-language models (LVLMs). However, its effectiveness remains highly sensitive to the quality of input in-context sequences, particularly for tasks involving complex reasoning or open-en</span>
                
                <span class="abstract-full" style="display: none;">Multimodal in-context learning (ICL) has emerged as a key mechanism for harnessing the capabilities of large vision-language models (LVLMs). However, its effectiveness remains highly sensitive to the quality of input in-context sequences, particularly for tasks involving complex reasoning or open-ended generation. A major limitation is our limited understanding of how LVLMs actually exploit these sequences during inference. To bridge this gap, we systematically interpret multimodal ICL through the lens of task mapping, which reveals how local and global relationships within and among demonstrations guide model reasoning. Building on this insight, we present TACO, a lightweight transformer-based model equipped with task-aware attention that dynamically configures in-context sequences. By injecting task-mapping signals into the autoregressive decoding process, TACO creates a bidirectional synergy between sequence construction and task reasoning. Experiments on five LVLMs and nine datasets demonstrate that TACO consistently surpasses baselines across diverse ICL tasks. These results position task mapping as a valuable perspective for interpreting and improving multimodal ICL.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.5%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.3%">
                            Medicine
                        </span>
                <!-- Federated Learning: 3.1 -->
                    
                <!-- GNN: 2.3 -->
                    
                <!-- Quantum Computing: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Computer Vision: 1.9 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.218
                </span>
                <a href="https://arxiv.org/abs/2505.17985" target="_blank" rel="noopener noreferrer">AI-Driven Robotics for Free-Space Optics</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Shiekh Zia Uddin, Sachin Vaidya, Shrish Choudhary, Zhuo Chen, Raafat K. Salib, Luke Huang, Dirk R. Englund, Marin Solja\v{c}i\'c
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Tabletop optical experiments are foundational to research in many areas of science, including photonics, quantum optics, materials science, metrology, and biomedical imaging. However these experiments remain fundamentally reliant on manual design, assembly, and alignment, limiting throughput and rep</span>
                
                <span class="abstract-full" style="display: none;">Tabletop optical experiments are foundational to research in many areas of science, including photonics, quantum optics, materials science, metrology, and biomedical imaging. However these experiments remain fundamentally reliant on manual design, assembly, and alignment, limiting throughput and reproducibility. Optics currently lacks generalizable robotic systems capable of operating across a diverse range of setups in realistic laboratory environments. Here we present OptoMate, an autonomous platform that integrates generative AI, computer vision, and precision robotics to enable automation of free-space optics experiments. Our platform interprets user-defined goals to generate valid optical setups using a fine-tuned large language model (LLM), assembles the setup via robotic pick-and-place with sub-millimeter accuracy, and performs fine alignment using a robot-deployable tool. The system then executes a range of automated measurements, including laser beam characterization, polarization mapping, and spectroscopy tasks. This work demonstrates the first flexible, AI-driven automation platform for optics, offering a path toward remote operation, cloud labs, and high-throughput discovery in the optical sciences.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.1%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.4%">
                            Medicine
                        </span>
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Datasets: 1.7 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.2216
                </span>
                <a href="https://arxiv.org/abs/2505.18052" target="_blank" rel="noopener noreferrer">BOTM: Echocardiography Segmentation via Bi-directional Optimal Token Matching</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zhihua Liu, Lei Tong, Xilin He, Che Liu, Rossella Arcucci, Chen Jin, Huiyu Zhou
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Existed echocardiography segmentation methods often suffer from anatomical inconsistency challenge caused by shape variation, partial observation and region ambiguity with similar intensity across 2D echocardiographic sequences, resulting in false positive segmentation with anatomical defeated struc</span>
                
                <span class="abstract-full" style="display: none;">Existed echocardiography segmentation methods often suffer from anatomical inconsistency challenge caused by shape variation, partial observation and region ambiguity with similar intensity across 2D echocardiographic sequences, resulting in false positive segmentation with anatomical defeated structures in challenging low signal-to-noise ratio conditions. To provide a strong anatomical guarantee across different echocardiographic frames, we propose a novel segmentation framework named BOTM (Bi-directional Optimal Token Matching) that performs echocardiography segmentation and optimal anatomy transportation simultaneously. Given paired echocardiographic images, BOTM learns to match two sets of discrete image tokens by finding optimal correspondences from a novel anatomical transportation perspective. We further extend the token matching into a bi-directional cross-transport attention proxy to regulate the preserved anatomical consistency within the cardiac cyclic deformation in temporal domain. Extensive experimental results show that BOTM can generate stable and accurate segmentation outcomes (e.g. -1.917 HD on CAMUS2H LV, +1.9% Dice on TED), and provide a better matching interpretation with anatomical consistency guarantee.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.5%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.5%">
                            LLMs
                        </span>
                <!-- Computer Vision: 2.6 -->
                    
                <!-- 3D: 2.6 -->
                    
                <!-- GNN: 2.4 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Quantum Computing: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- Networks: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.2477
                </span>
                <a href="https://arxiv.org/abs/2505.17748" target="_blank" rel="noopener noreferrer">Soft-CAM: Making black box models self-explainable for high-stakes decisions</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Kerol Djoumessi, Philipp Berens
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Convolutional neural networks (CNNs) are widely used for high-stakes applications like medicine, often surpassing human performance. However, most explanation methods rely on post-hoc attribution, approximating the decision-making process of already trained black-box models. These methods are often </span>
                
                <span class="abstract-full" style="display: none;">Convolutional neural networks (CNNs) are widely used for high-stakes applications like medicine, often surpassing human performance. However, most explanation methods rely on post-hoc attribution, approximating the decision-making process of already trained black-box models. These methods are often sensitive, unreliable, and fail to reflect true model reasoning, limiting their trustworthiness in critical applications. In this work, we introduce SoftCAM, a straightforward yet effective approach that makes standard CNN architectures inherently interpretable. By removing the global average pooling layer and replacing the fully connected classification layer with a convolution-based class evidence layer, SoftCAM preserves spatial information and produces explicit class activation maps that form the basis of the model's predictions. Evaluated on three medical datasets, SoftCAM maintains classification performance while significantly improving both the qualitative and quantitative explanation compared to existing post-hoc methods. Our results demonstrate that CNNs can be inherently interpretable without compromising performance, advancing the development of self-explainable deep learning for high-stakes decision-making.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.4%">
                            Medicine
                        </span>
                <!-- LLMs: 4.0 -->
                    
                <!-- Federated Learning: 2.8 -->
                    
                <!-- Computer Vision: 2.7 -->
                    
                <!-- GNN: 2.7 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Bayesian Optimization: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.2534
                </span>
                <a href="https://arxiv.org/abs/2505.18035" target="_blank" rel="noopener noreferrer">CAMME: Adaptive Deepfake Image Detection with Multi-Modal Cross-Attention</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Naseem Khan, Tuan Nguyen, Amine Bermak, Issa Khalil
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The proliferation of sophisticated AI-generated deepfakes poses critical challenges for digital media authentication and societal security. While existing detection methods perform well within specific generative domains, they exhibit significant performance degradation when applied to manipulations</span>
                
                <span class="abstract-full" style="display: none;">The proliferation of sophisticated AI-generated deepfakes poses critical challenges for digital media authentication and societal security. While existing detection methods perform well within specific generative domains, they exhibit significant performance degradation when applied to manipulations produced by unseen architectures--a fundamental limitation as generative technologies rapidly evolve. We propose CAMME (Cross-Attention Multi-Modal Embeddings), a framework that dynamically integrates visual, textual, and frequency-domain features through a multi-head cross-attention mechanism to establish robust cross-domain generalization. Extensive experiments demonstrate CAMME's superiority over state-of-the-art methods, yielding improvements of 12.56% on natural scenes and 13.25% on facial deepfakes. The framework demonstrates exceptional resilience, maintaining (over 91%) accuracy under natural image perturbations and achieving 89.01% and 96.14% accuracy against PGD and FGSM adversarial attacks, respectively. Our findings validate that integrating complementary modalities through cross-attention enables more effective decision boundary realignment for reliable deepfake detection across heterogeneous generative architectures.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.9%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.2%">
                            Medicine
                        </span>
                <!-- Computer Vision: 4.0 -->
                    
                <!-- 3D: 2.3 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Blockchain: 2.1 -->
                    
                <!-- Decision Trees: 2.0 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.3035
                </span>
                <a href="https://arxiv.org/abs/2412.09729" target="_blank" rel="noopener noreferrer">Doubly Robust Conformalized Survival Analysis with Right-Censored Data</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Matteo Sesia, Vladimir Svetnik
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We present a conformal inference method for constructing lower prediction bounds for survival times from right-censored data, extending recent approaches designed for more restrictive type-I censoring scenarios. The proposed method imputes unobserved censoring times using a machine learning model, a</span>
                
                <span class="abstract-full" style="display: none;">We present a conformal inference method for constructing lower prediction bounds for survival times from right-censored data, extending recent approaches designed for more restrictive type-I censoring scenarios. The proposed method imputes unobserved censoring times using a machine learning model, and then analyzes the imputed data using a survival model calibrated via weighted conformal inference. This approach is theoretically supported by an asymptotic double robustness property. Empirical studies on simulated and real data demonstrate that our method leads to relatively informative predictive inferences and is especially robust in challenging settings where the survival model may be inaccurate.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.5%">
                            Medicine
                        </span>
                <!-- LLMs: 3.3 -->
                    
                <!-- Decision Trees: 2.4 -->
                    
                <!-- Computer Vision: 2.2 -->
                    
                <!-- HPO and AutoML: 2.2 -->
                    
                <!-- 3D: 1.8 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.4 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.3411
                </span>
                <a href="https://arxiv.org/abs/2505.17233" target="_blank" rel="noopener noreferrer">Semantic-Aware Interpretable Multimodal Music Auto-Tagging</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Andreas Patakis, Vassilis Lyberatos, Spyridon Kantarelis, Edmund Dervakos, Giorgos Stamou
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Music auto-tagging is essential for organizing and discovering music in extensive digital libraries. While foundation models achieve exceptional performance in this domain, their outputs often lack interpretability, limiting trust and usability for researchers and end-users alike. In this work, we p</span>
                
                <span class="abstract-full" style="display: none;">Music auto-tagging is essential for organizing and discovering music in extensive digital libraries. While foundation models achieve exceptional performance in this domain, their outputs often lack interpretability, limiting trust and usability for researchers and end-users alike. In this work, we present an interpretable framework for music auto-tagging that leverages groups of musically meaningful multimodal features, derived from signal processing, deep learning, ontology engineering, and natural language processing. To enhance interpretability, we cluster features semantically and employ an expectation maximization algorithm, assigning distinct weights to each group based on its contribution to the tagging process. Our method achieves competitive tagging performance while offering a deeper understanding of the decision-making process, paving the way for more transparent and user-centric music tagging systems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.2%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.0%">
                            Medicine
                        </span>
                <!-- Computer Vision: 2.9 -->
                    
                <!-- Hardware: 2.3 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- 3D: 1.1 -->
                    
                <!-- T2I: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.3654
                </span>
                <a href="https://arxiv.org/abs/2505.17198" target="_blank" rel="noopener noreferrer">LengthLogD: A Length-Stratified Ensemble Framework for Enhanced Peptide Lipophilicity Prediction via Multi-Scale Feature Integration</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Shuang Wu, Meijie Wang, Lun Yu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Peptide compounds demonstrate considerable potential as therapeutic agents due to their high target affinity and low toxicity, yet their drug development is constrained by their low membrane permeability. Molecular weight and peptide length have significant effects on the logD of peptides, which in </span>
                
                <span class="abstract-full" style="display: none;">Peptide compounds demonstrate considerable potential as therapeutic agents due to their high target affinity and low toxicity, yet their drug development is constrained by their low membrane permeability. Molecular weight and peptide length have significant effects on the logD of peptides, which in turn influences their ability to cross biological membranes. However, accurate prediction of peptide logD remains challenging due to the complex interplay between sequence, structure, and ionization states. This study introduces LengthLogD, a predictive framework that establishes specialized models through molecular length stratification while innovatively integrating multi-scale molecular representations. We constructed feature spaces across three hierarchical levels: atomic (10 molecular descriptors), structural (1024-bit Morgan fingerprints), and topological (3 graph-based features including Wiener index), optimized through stratified ensemble learning. An adaptive weight allocation mechanism specifically developed for long peptides significantly enhances model generalizability. Experimental results demonstrate superior performance across all categories: short peptides (R^2=0.855), medium peptides (R^2=0.816), and long peptides (R^2=0.882), with a 34.7% reduction in prediction error for long peptides compared to conventional single-model approaches. Ablation studies confirm: 1) The length-stratified strategy contributes 41.2% to performance improvement; 2) Topological features account for 28.5% of predictive importance. Compared to state-of-the-art models, our method maintains short peptide prediction accuracy while achieving a 25.7% increase in the coefficient of determination (R^2) for long peptides. This research provides a precise logD prediction tool for peptide drug development, particularly demonstrating unique value in optimizing long peptide lead compounds.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.4%">
                            Medicine
                        </span>
                <!-- LLMs: 4.6 -->
                    
                <!-- Computer Vision: 2.4 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.3772
                </span>
                <a href="https://arxiv.org/abs/2505.17335" target="_blank" rel="noopener noreferrer">Secure Parsing and Serializing with Separation Logic Applied to CBOR, CDDL, and COSE</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Tahina Ramananandro, Gabriel Ebner, Guido Mart\'inez, Nikhil Swamy
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Incorrect handling of security-critical data formats, particularly in low-level languages, are the root cause of many security vulnerabilities. Provably correct parsing and serialization tools that target languages like C can help. Towards this end, we present PulseParse, a library of verified parse</span>
                
                <span class="abstract-full" style="display: none;">Incorrect handling of security-critical data formats, particularly in low-level languages, are the root cause of many security vulnerabilities. Provably correct parsing and serialization tools that target languages like C can help. Towards this end, we present PulseParse, a library of verified parser and serializer combinators for non-malleable binary formats. Specifications and proofs in PulseParse are in separation logic, offering a more abstract and compositional interface, with full support for data validation, parsing, and serialization. PulseParse also supports a class of recursive formats -- with a focus on security and handling adversarial inputs, we show how to parse such formats with only a constant amount of stack space.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.1%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.8%">
                            Medicine
                        </span>
                <!-- Blockchain: 2.5 -->
                    
                <!-- Datasets: 2.2 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- 3D: 1.1 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Computer Vision: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.3933
                </span>
                <a href="https://arxiv.org/abs/2505.17041" target="_blank" rel="noopener noreferrer">Exploring EFL Secondary Students' AI-generated Text Editing While Composition Writing</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: David James Woo, Yangyang Yu, Kai Guo
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Generative Artificial Intelligence is transforming how English as a foreign language students write. Still, little is known about how students manipulate text generated by generative AI during the writing process. This study investigates how EFL secondary school students integrate and modify AI-gene</span>
                
                <span class="abstract-full" style="display: none;">Generative Artificial Intelligence is transforming how English as a foreign language students write. Still, little is known about how students manipulate text generated by generative AI during the writing process. This study investigates how EFL secondary school students integrate and modify AI-generated text when completing an expository writing task. The study employed an exploratory mixed-methods design. Screen recordings were collected from 29 Hong Kong secondary school students who attended an AI-assisted writing workshop and recorded their screens while using generative AI to write an article. Content analysis with hierarchical coding and thematic analysis with a multiple case study approach were adopted to analyze the recordings. 15 types of AI-generated text edits across seven categories were identified from the recordings. Notably, AI-initiated edits from iOS and Google Docs emerged as unanticipated sources of AI-generated text. A thematic analysis revealed four patterns of students' editing behaviors based on planning and drafting direction: planning with top-down drafting and revising; top-down drafting and revising without planning; planning with bottom-up drafting and revising; and bottom-up drafting and revising without planning. Network graphs illustrate cases of each pattern, demonstrating that students' interactions with AI-generated text involve more complex cognitive processes than simple text insertion. The findings challenge assumptions about students' passive, simplistic use of generative AI tools and have implications for developing explicit instructional approaches to teaching AI-generated text editing strategies in the AFL writing pedagogy.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.5%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.3%">
                            Medicine
                        </span>
                <!-- Blockchain: 2.5 -->
                    
                <!-- Datasets: 2.0 -->
                    
                <!-- HPO and AutoML: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- Robotics: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4066
                </span>
                <a href="https://arxiv.org/abs/2402.14527" target="_blank" rel="noopener noreferrer">Federated Learning in Genetics: Extended Analysis of Accuracy, Performance and Privacy Trade-offs</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Anika Hannemann, Jan Ewald, Leo Seeger, Erik Buchmann
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Machine learning on large-scale genomic or transcriptomic data is important for many novel health applications. For example, precision medicine tailors medical treatments to patients on the basis of individual biomarkers, cellular and molecular states, etc. However, the data required is sensitive, v</span>
                
                <span class="abstract-full" style="display: none;">Machine learning on large-scale genomic or transcriptomic data is important for many novel health applications. For example, precision medicine tailors medical treatments to patients on the basis of individual biomarkers, cellular and molecular states, etc. However, the data required is sensitive, voluminous, heterogeneous, and typically distributed across locations where dedicated machine learning hardware is not available. Due to privacy and regulatory reasons, it is also problematic to aggregate all data at a trusted third party. Federated learning is a promising solution to this dilemma, because it enables decentralized, collaborative machine learning without exchanging raw data. In this paper, we perform comparative experiments with the federated learning frameworks TensorFlow Federated and Flower. Our test case is the training of disease prognosis and cell type classification models. We train the models with distributed transcriptomic data, considering both data heterogeneity and architectural heterogeneity. We measure model quality, robustness against privacy-enhancing noise and computational performance. We evaluate the resource overhead of a federated system from both client and global perspectives and assess benefits and limitations. Each of the federated learning frameworks has different strengths. However, our experiments confirm that both frameworks can readily build models on transcriptomic data, without transferring personal raw data to a third party with abundant computational resources. This paper is the extended version of https://link.springer.com/chapter/10.1007/978-3-031-63772-8_26.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.4%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #b3ebae" title="Confidence: 5.7%">
                            Federated Learning
                        </span>
                <!-- LLMs: 2.5 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.413
                </span>
                <a href="https://arxiv.org/abs/2505.17544" target="_blank" rel="noopener noreferrer">FreqU-FNet: Frequency-Aware U-Net for Imbalanced Medical Image Segmentation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ruiqi Xing
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Medical image segmentation faces persistent challenges due to severe class imbalance and the frequency-specific distribution of anatomical structures. Most conventional CNN-based methods operate in the spatial domain and struggle to capture minority class signals, often affected by frequency aliasin</span>
                
                <span class="abstract-full" style="display: none;">Medical image segmentation faces persistent challenges due to severe class imbalance and the frequency-specific distribution of anatomical structures. Most conventional CNN-based methods operate in the spatial domain and struggle to capture minority class signals, often affected by frequency aliasing and limited spectral selectivity. Transformer-based models, while powerful in modeling global dependencies, tend to overlook critical local details necessary for fine-grained segmentation. To overcome these limitations, we propose FreqU-FNet, a novel U-shaped segmentation architecture operating in the frequency domain. Our framework incorporates a Frequency Encoder that leverages Low-Pass Frequency Convolution and Daubechies wavelet-based downsampling to extract multi-scale spectral features. To reconstruct fine spatial details, we introduce a Spatial Learnable Decoder (SLD) equipped with an adaptive multi-branch upsampling strategy. Furthermore, we design a frequency-aware loss (FAL) function to enhance minority class learning. Extensive experiments on multiple medical segmentation benchmarks demonstrate that FreqU-FNet consistently outperforms both CNN and Transformer baselines, particularly in handling under-represented classes, by effectively exploiting discriminative frequency bands.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.9%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.7%">
                            LLMs
                        </span>
                <!-- GNN: 3.0 -->
                    
                <!-- Computer Vision: 3.0 -->
                    
                <!-- 3D: 2.2 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- T2I: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4287
                </span>
                <a href="https://arxiv.org/abs/2505.18066" target="_blank" rel="noopener noreferrer">Towards Uncertainty Aware Task Delegation and Human-AI Collaborative Decision-Making</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Min Hun Lee, Martyn Zhe Yu Tok
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Despite the growing promise of artificial intelligence (AI) in supporting decision-making across domains, fostering appropriate human reliance on AI remains a critical challenge. In this paper, we investigate the utility of exploring distance-based uncertainty scores for task delegation to AI and de</span>
                
                <span class="abstract-full" style="display: none;">Despite the growing promise of artificial intelligence (AI) in supporting decision-making across domains, fostering appropriate human reliance on AI remains a critical challenge. In this paper, we investigate the utility of exploring distance-based uncertainty scores for task delegation to AI and describe how these scores can be visualized through embedding representations for human-AI decision-making. After developing an AI-based system for physical stroke rehabilitation assessment, we conducted a study with 19 health professionals and 10 students in medicine/health to understand the effect of exploring distance-based uncertainty scores on users' reliance on AI. Our findings showed that distance-based uncertainty scores outperformed traditional probability-based uncertainty scores in identifying uncertain cases. In addition, after exploring confidence scores for task delegation and reviewing embedding-based visualizations of distance-based uncertainty scores, participants achieved an 8.20% higher rate of correct decisions, a 7.15% higher rate of changing their decisions to correct ones, and a 7.14% lower rate of incorrect changes after reviewing AI outputs than those reviewing probability-based uncertainty scores ($p<0.01$). Our findings highlight the potential of distance-based uncertainty scores to enhance decision accuracy and appropriate reliance on AI while discussing ongoing challenges for human-AI collaborative decision-making.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.3%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.5%">
                            Medicine
                        </span>
                <!-- Evolutionary Algorithms: 2.7 -->
                    
                <!-- Hardware: 2.3 -->
                    
                <!-- Federated Learning: 2.3 -->
                    
                <!-- Computer Vision: 2.0 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4312
                </span>
                <a href="https://arxiv.org/abs/2505.17208" target="_blank" rel="noopener noreferrer">RetroChat: Designing for the Preservation of Past Digital Experiences</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Suifang Zhou, Kexue Fu, Huanmin Yi, Ray Lc
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Rapid changes in social networks have transformed the way people express themselves, turning past neologisms, values, and mindsets embedded in these expressions into online heritage. How can we preserve these expressions as cultural heritage? Instead of traditional archiving methods for static mater</span>
                
                <span class="abstract-full" style="display: none;">Rapid changes in social networks have transformed the way people express themselves, turning past neologisms, values, and mindsets embedded in these expressions into online heritage. How can we preserve these expressions as cultural heritage? Instead of traditional archiving methods for static material, we designed an interactive and experiential form of archiving for Chinese social networks. Using dialogue data from 2000-2010 on early Chinese social media, we developed a GPT-driven agent within a retro chat interface, emulating the language and expression style of the period for interaction. Results from a qualitative study with 18 participants show that the design captures the past chatting experience and evokes memory flashbacks and nostalgia feeling through conversation. Participants, particularly those familiar with the era, adapted their language to match the agent's chatting style. This study explores how the design of preservation methods for digital experiences can be informed by experiential representations supported by generative tools.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.7%">
                            Medicine
                        </span>
                <!-- LLMs: 3.1 -->
                    
                <!-- Hardware: 2.4 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4613
                </span>
                <a href="https://arxiv.org/abs/2407.21077" target="_blank" rel="noopener noreferrer">Genetic Instruct: Scaling up Synthetic Generation of Coding Instructions for Large Language Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Somshubra Majumdar, Vahid Noroozi, Mehrzad Samadi, Sean Narenthiran, Aleksander Ficek, Wasi Uddin Ahmad, Jocelyn Huang, Jagadeesh Balam, Boris Ginsburg
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Large Language Models (LLMs) require high quality instruction data for effective alignment, particularly in code generation tasks where expert curated datasets are expensive to produce. We present Genetic-Instruct, a scalable algorithm for synthesizing large-scale, high quality coding instructions u</span>
                
                <span class="abstract-full" style="display: none;">Large Language Models (LLMs) require high quality instruction data for effective alignment, particularly in code generation tasks where expert curated datasets are expensive to produce. We present Genetic-Instruct, a scalable algorithm for synthesizing large-scale, high quality coding instructions using evolutionary principles. Starting from a small set of seed instructions, Genetic-Instruct generates diverse and challenging instruction-code pairs by leveraging an Instructor-LLM for generation, a Coder-LLM for code synthesis, and a Judge-LLM for automatic quality evaluation. Our proposed approach is highly parallelizable and effective even with a small seed data and weaker generator models. We generated more than 7.5 million coding instructions with the proposed approach. Then we evaluated it by fine-tuning LLMs with the synthetic samples and demonstrated a significant improvement in their code generation capability compared to the other synthetic generation approaches and publicly available datasets. Our results highlight the efficiency, scalability, and generalizability of the Genetic-Instruct framework.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 11.5%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.5%">
                            Medicine
                        </span>
                <!-- Datasets: 2.4 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- 3D: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4896
                </span>
                <a href="https://arxiv.org/abs/2505.17405" target="_blank" rel="noopener noreferrer">State of health prediction of lithium-ion batteries for driving conditions based on full parameter domain sparrow search algorithm and dual-module bidirectional gated recurrent unit</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jie Wen, Chenyu Jia, Guangshu Xia
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Aiming at the state of health (SOH) prediction of lithium-ion batteries (LiBs) for electric vehicles (EVs), this paper proposes a fusion model of a dual-module bidirectional gated recurrent unit (BiGRU) and sparrow search algorithm (SSA) with full parameter domain optimization. With the help of Spea</span>
                
                <span class="abstract-full" style="display: none;">Aiming at the state of health (SOH) prediction of lithium-ion batteries (LiBs) for electric vehicles (EVs), this paper proposes a fusion model of a dual-module bidirectional gated recurrent unit (BiGRU) and sparrow search algorithm (SSA) with full parameter domain optimization. With the help of Spearman correlation analysis and ablation experiments, the indirect health indicator (HI) that can characterize the battery degradation is extracted first based on the incremental capacity (IC) curves of the Oxford battery dataset, which simulates the driving conditions. On this basis, the filtered one-dimensional HI is inputted into the dual-module BiGRU for learning the pre- and post-textual information of the input sequence and extracting the sequence features. In order to combine the different hyperparameters in the dual-module BiGRU, SSA is used to optimize the hyperparameters in the full parameter domain. The proposed SSA-BiGRU model combines the advantages and structures of SSA and BiGRU to achieve the highly accurate SOH prediction of LiBs. Studies based on the Oxford battery dataset have shown that the SSA-BiGRU model has higher accuracy, better robustness and generalization ability. Moreover, the proposed SSA-BiGRU model is tested on a real road-driven EV charging dataset and accurate SOH prediction are obtained.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.5%">
                            Medicine
                        </span>
                <!-- Federated Learning: 4.5 -->
                    
                <!-- Reinforcement Learning: 2.2 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- Computer Vision: 2.0 -->
                    
                <!-- Bayesian Optimization: 1.8 -->
                    
                <!-- Math: 1.5 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- Finance: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.5487
                </span>
                <a href="https://arxiv.org/abs/2504.13794" target="_blank" rel="noopener noreferrer">Active Learning of Symbolic NetKAT Automata</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Mark Moeller, Tiago Ferreira, Thomas Lu, Nate Foster, Alexandra Silva
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">NetKAT is a domain-specific programming language and logic that has been successfully used to specify and verify the behavior of packet-switched networks. This paper develops techniques for automatically learning NetKAT models of unknown networks using active learning. Prior work has explored active</span>
                
                <span class="abstract-full" style="display: none;">NetKAT is a domain-specific programming language and logic that has been successfully used to specify and verify the behavior of packet-switched networks. This paper develops techniques for automatically learning NetKAT models of unknown networks using active learning. Prior work has explored active learning for a wide range of automata (e.g., deterministic, register, B\"uchi, timed etc.) and also developed applications, such as validating implementations of network protocols. We present algorithms for learning different types of NetKAT automata, including symbolic automata proposed in recent work. We prove the soundness of these algorithms, build a prototype implementation, and evaluate it on a standard benchmark. Our results highlight the applicability of symbolic NetKAT learning for realistic network configurations and topologies.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.2%">
                            Medicine
                        </span>
                <!-- LLMs: 4.2 -->
                    
                <!-- Evolutionary Algorithms: 3.5 -->
                    
                <!-- Federated Learning: 3.3 -->
                    
                <!-- Hardware: 2.7 -->
                    
                <!-- Quantum Computing: 2.3 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Datasets: 1.8 -->
                    
                <!-- Bayesian Optimization: 1.6 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- GNN: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.7004
                </span>
                <a href="https://arxiv.org/abs/2505.17992" target="_blank" rel="noopener noreferrer">Canonical Pose Reconstruction from Single Depth Image for 3D Non-rigid Pose Recovery on Limited Datasets</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Fahd Alhamazani, Yu-Kun Lai, Paul L. Rosin
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">3D reconstruction from 2D inputs, especially for non-rigid objects like humans, presents unique challenges due to the significant range of possible deformations. Traditional methods often struggle with non-rigid shapes, which require extensive training data to cover the entire deformation space. Thi</span>
                
                <span class="abstract-full" style="display: none;">3D reconstruction from 2D inputs, especially for non-rigid objects like humans, presents unique challenges due to the significant range of possible deformations. Traditional methods often struggle with non-rigid shapes, which require extensive training data to cover the entire deformation space. This study addresses these limitations by proposing a canonical pose reconstruction model that transforms single-view depth images of deformable shapes into a canonical form. This alignment facilitates shape reconstruction by enabling the application of rigid object reconstruction techniques, and supports recovering the input pose in voxel representation as part of the reconstruction task, utilizing both the original and deformed depth images. Notably, our model achieves effective results with only a small dataset of approximately 300 samples. Experimental results on animal and human datasets demonstrate that our model outperforms other state-of-the-art methods.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.9%">
                            Medicine
                        </span>
                <!-- 3D: 2.9 -->
                    
                <!-- LLMs: 2.7 -->
                    
                <!-- Federated Learning: 2.6 -->
                    
                <!-- Computer Vision: 2.4 -->
                    
                <!-- Quantum Computing: 2.2 -->
                    
                <!-- GNN: 2.1 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.7126
                </span>
                <a href="https://arxiv.org/abs/2505.18012" target="_blank" rel="noopener noreferrer">Classification of assembly tasks combining multiple primitive actions using Transformers and xLSTMs</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Miguel Neves, Pedro Neto
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The classification of human-performed assembly tasks is essential in collaborative robotics to ensure safety, anticipate robot actions, and facilitate robot learning. However, achieving reliable classification is challenging when segmenting tasks into smaller primitive actions is unfeasible, requiri</span>
                
                <span class="abstract-full" style="display: none;">The classification of human-performed assembly tasks is essential in collaborative robotics to ensure safety, anticipate robot actions, and facilitate robot learning. However, achieving reliable classification is challenging when segmenting tasks into smaller primitive actions is unfeasible, requiring us to classify long assembly tasks that encompass multiple primitive actions. In this study, we propose classifying long assembly sequential tasks based on hand landmark coordinates and compare the performance of two well-established classifiers, LSTM and Transformer, as well as a recent model, xLSTM. We used the HRC scenario proposed in the CT benchmark, which includes long assembly tasks that combine actions such as insertions, screw fastenings, and snap fittings. Testing was conducted using sequences gathered from both the human operator who performed the training sequences and three new operators. The testing results of real-padded sequences for the LSTM, Transformer, and xLSTM models was 72.9%, 95.0% and 93.2% for the training operator, and 43.5%, 54.3% and 60.8% for the new operators, respectively. The LSTM model clearly underperformed compared to the other two approaches. As expected, both the Transformer and xLSTM achieved satisfactory results for the operator they were trained on, though the xLSTM model demonstrated better generalization capabilities to new operators. The results clearly show that for this type of classification, the xLSTM model offers a slight edge over Transformers.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.9%">
                            Medicine
                        </span>
                <!-- LLMs: 2.4 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- Hardware: 2.3 -->
                    
                <!-- Federated Learning: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.7167
                </span>
                <a href="https://arxiv.org/abs/2505.17141" target="_blank" rel="noopener noreferrer">Fashion Industry in the Age of Generative Artificial Intelligence and Metaverse: A systematic Review</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Rania Ahmed, Eman Ahmed, Ahmed Elbarbary, Ashraf Darwish, Aboul Ella Hassanien
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The fashion industry is an extremely profitable market that generates trillions of dollars in revenue by producing and distributing apparel, footwear, and accessories. This systematic literature review (SLR) seeks to systematically review and analyze the research landscape about the Generative Artif</span>
                
                <span class="abstract-full" style="display: none;">The fashion industry is an extremely profitable market that generates trillions of dollars in revenue by producing and distributing apparel, footwear, and accessories. This systematic literature review (SLR) seeks to systematically review and analyze the research landscape about the Generative Artificial Intelligence (GAI) and metaverse in the fashion industry. Thus, investigating the impact of integrating both technologies to enhance the fashion industry. This systematic review uses the Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) methodology, including three essential phases: identification, evaluation, and reporting. In the identification phase, the target search problems are determined by selecting appropriate keywords and alternative synonyms. After that 578 documents from 2014 to the end of 2023 are retrieved. The evaluation phase applies three screening steps to assess papers and choose 118 eligible papers for full-text reading. Finally, the reporting phase thoroughly examines and synthesizes the 118 eligible papers to identify key themes associated with GAI and Metaverse in the fashion industry. Based on Strengths, Weaknesses, Opportunities, and Threats (SWOT) analyses performed for both GAI and metaverse for the fashion industry, it is concluded that the integration of GAI and the metaverse holds the capacity to profoundly revolutionize the fashion sector, presenting chances for improved manufacturing, design, sales, and client experiences. Accordingly, the research proposes a new framework to integrate GAI and metaverse to enhance the fashion industry. The framework presents different use cases to promote the fashion industry using the integration. Future research points for achieving a successful integration are demonstrated.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.2%">
                            Medicine
                        </span>
                <!-- Computer Vision: 2.2 -->
                    
                <!-- LLMs: 1.8 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Federated Learning: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.8125
                </span>
                <a href="https://arxiv.org/abs/2505.09473" target="_blank" rel="noopener noreferrer">Function-Correcting $b$-symbol Codes for Locally $(\lambda, \rho,b)$-Functions</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Gyanendra K. Verma, Anamika Singh, Abhay Kumar Singh
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The family of functions plays a central role in the design and effectiveness of function-correcting codes. By focusing on a well-defined family of functions, function-correcting codes can be constructed with minimal length while still ensuring full error detection or correction within that family. I</span>
                
                <span class="abstract-full" style="display: none;">The family of functions plays a central role in the design and effectiveness of function-correcting codes. By focusing on a well-defined family of functions, function-correcting codes can be constructed with minimal length while still ensuring full error detection or correction within that family. In this work, we explore the concept of locally $(\lambda,\rho)$-functions for $b$-symbol read channels and investigate the redundancy of the corresponding function-correcting $b$-symbol codes(FCBSC) by introducing the notions of locally $(\lambda,\rho,b)$-functions. First, we discuss the possible values of $\lambda$ and $\rho$ for which any function can be considered as locally $(\lambda,\rho)$-function in $b$-symbol metric. The findings improve some known results in the Hamming metric and present several new results in the $b$-symbol metric. Then we investigate the redundancy of $(f,t)$-FCBSC for locally $(\lambda,\rho,b)$-functions. We establish a recurrence relation between the optimal redundancy of $(f,t)$ -function-correcting codes for the $(b+1)$-read and $b$-read channels. We establish an upper bound on the redundancy of $(f,t)$-function-correcting $b$-symbol codes for general locally ($\lambda,\rho$, $b$)-functions by linking it to the minimum achievable length of $b$-symbol error-correcting codes and traditional Hamming-metric codes, given a fixed number of codewords and a specified minimum distance. We derive some explicit upper bounds on the redundancy of $(f,t)$-function-correcting $b$-symbol codes for $\rho=2t$. Moreover, for the case where $b=1$, we show that a locally ($3,2t,1$)-function achieves the optimal redundancy of $3t$. Additionally, we explicitly investigate locality and redundancy for the $b$-symbol weight distribution function for $b\geq1$.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.2%">
                            Medicine
                        </span>
                <!-- Federated Learning: 2.9 -->
                    
                <!-- Hardware: 2.7 -->
                    
                <!-- Bayesian Optimization: 2.4 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- Math: 1.9 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- LLMs: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.9108
                </span>
                <a href="https://arxiv.org/abs/2409.08691" target="_blank" rel="noopener noreferrer">Autoregressive Sequence Modeling for 3D Medical Image Representation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Siwen Wang, Churan Wang, Fei Gao, Lixian Su, Fandong Zhang, Yizhou Wang, Yizhou Yu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Three-dimensional (3D) medical images, such as Computed Tomography (CT) and Magnetic Resonance Imaging (MRI), are essential for clinical applications. However, the need for diverse and comprehensive representations is particularly pronounced when considering the variability across different organs, </span>
                
                <span class="abstract-full" style="display: none;">Three-dimensional (3D) medical images, such as Computed Tomography (CT) and Magnetic Resonance Imaging (MRI), are essential for clinical applications. However, the need for diverse and comprehensive representations is particularly pronounced when considering the variability across different organs, diagnostic tasks, and imaging modalities. How to effectively interpret the intricate contextual information and extract meaningful insights from these images remains an open challenge to the community. While current self-supervised learning methods have shown potential, they often consider an image as a whole thereby overlooking the extensive, complex relationships among local regions from one or multiple images. In this work, we introduce a pioneering method for learning 3D medical image representations through an autoregressive pre-training framework. Our approach sequences various 3D medical images based on spatial, contrast, and semantic correlations, treating them as interconnected visual tokens within a token sequence. By employing an autoregressive sequence modeling task, we predict the next visual token in the sequence, which allows our model to deeply understand and integrate the contextual information inherent in 3D medical images. Additionally, we implement a random startup strategy to avoid overestimating token relationships and to enhance the robustness of learning. The effectiveness of our approach is demonstrated by the superior performance over others on nine downstream tasks in public datasets.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 8.3%">
                            Medicine
                        </span>
                <!-- Computer Vision: 3.2 -->
                    
                <!-- LLMs: 2.3 -->
                    
                <!-- GNN: 2.2 -->
                    
                <!-- 3D: 2.0 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.9233
                </span>
                <a href="https://arxiv.org/abs/2505.17136" target="_blank" rel="noopener noreferrer">Foundation Models for Geospatial Reasoning: Assessing Capabilities of Large Language Models in Understanding Geometries and Topological Spatial Relations</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yuhan Ji, Song Gao, Ying Nie, Ivan Maji\'c, Krzysztof Janowicz
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Applying AI foundation models directly to geospatial datasets remains challenging due to their limited ability to represent and reason with geographical entities, specifically vector-based geometries and natural language descriptions of complex spatial relations. To address these issues, we investig</span>
                
                <span class="abstract-full" style="display: none;">Applying AI foundation models directly to geospatial datasets remains challenging due to their limited ability to represent and reason with geographical entities, specifically vector-based geometries and natural language descriptions of complex spatial relations. To address these issues, we investigate the extent to which a well-known-text (WKT) representation of geometries and their spatial relations (e.g., topological predicates) are preserved during spatial reasoning when the geospatial vector data are passed to large language models (LLMs) including GPT-3.5-turbo, GPT-4, and DeepSeek-R1-14B. Our workflow employs three distinct approaches to complete the spatial reasoning tasks for comparison, i.e., geometry embedding-based, prompt engineering-based, and everyday language-based evaluation. Our experiment results demonstrate that both the embedding-based and prompt engineering-based approaches to geospatial question-answering tasks with GPT models can achieve an accuracy of over 0.6 on average for the identification of topological spatial relations between two geometries. Among the evaluated models, GPT-4 with few-shot prompting achieved the highest performance with over 0.66 accuracy on topological spatial relation inference. Additionally, GPT-based reasoner is capable of properly comprehending inverse topological spatial relations and including an LLM-generated geometry can enhance the effectiveness for geographic entity retrieval. GPT-4 also exhibits the ability to translate certain vernacular descriptions about places into formal topological relations, and adding the geometry-type or place-type context in prompts may improve inference accuracy, but it varies by instance. The performance of these spatial reasoning tasks offers valuable insights for the refinement of LLMs with geographical knowledge towards the development of geo-foundation models capable of geospatial reasoning.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 12.3%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.0%">
                            Medicine
                        </span>
                <!-- Federated Learning: 2.9 -->
                    
                <!-- Evolutionary Algorithms: 2.3 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Datasets: 1.0 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.9878
                </span>
                <a href="https://arxiv.org/abs/2505.17613" target="_blank" rel="noopener noreferrer">MMMG: a Comprehensive and Reliable Evaluation Suite for Multitask Multimodal Generation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jihan Yao, Yushi Hu, Yujie Yi, Bin Han, Shangbin Feng, Guang Yang, Bingbing Wen, Ranjay Krishna, Lucy Lu Wang, Yulia Tsvetkov, Noah A. Smith, Banghua Zhu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Automatically evaluating multimodal generation presents a significant challenge, as automated metrics often struggle to align reliably with human evaluation, especially for complex tasks that involve multiple modalities. To address this, we present MMMG, a comprehensive and human-aligned benchmark f</span>
                
                <span class="abstract-full" style="display: none;">Automatically evaluating multimodal generation presents a significant challenge, as automated metrics often struggle to align reliably with human evaluation, especially for complex tasks that involve multiple modalities. To address this, we present MMMG, a comprehensive and human-aligned benchmark for multimodal generation across 4 modality combinations (image, audio, interleaved text and image, interleaved text and audio), with a focus on tasks that present significant challenges for generation models, while still enabling reliable automatic evaluation through a combination of models and programs. MMMG encompasses 49 tasks (including 29 newly developed ones), each with a carefully designed evaluation pipeline, and 937 instructions to systematically assess reasoning, controllability, and other key capabilities of multimodal generation models. Extensive validation demonstrates that MMMG is highly aligned with human evaluation, achieving an average agreement of 94.3%. Benchmarking results on 24 multimodal generation models reveal that even though the state-of-the-art model, GPT Image, achieves 78.3% accuracy for image generation, it falls short on multimodal reasoning and interleaved generation. Furthermore, results suggest considerable headroom for improvement in audio generation, highlighting an important direction for future research.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 9.0%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.3%">
                            LLMs
                        </span>
                <!-- Datasets: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- 3D: 1.9 -->
                    
                <!-- T2I: 1.8 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.1794
                </span>
                <a href="https://arxiv.org/abs/2505.17254" target="_blank" rel="noopener noreferrer">Approach to Finding a Robust Deep Learning Model</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Alexey Boldyrev, Fedor Ratnikov, Andrey Shevelev
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The rapid development of machine learning (ML) and artificial intelligence (AI) applications requires the training of large numbers of models. This growing demand highlights the importance of training models without human supervision, while ensuring that their predictions are reliable. In response t</span>
                
                <span class="abstract-full" style="display: none;">The rapid development of machine learning (ML) and artificial intelligence (AI) applications requires the training of large numbers of models. This growing demand highlights the importance of training models without human supervision, while ensuring that their predictions are reliable. In response to this need, we propose a novel approach for determining model robustness. This approach, supplemented with a proposed model selection algorithm designed as a meta-algorithm, is versatile and applicable to any machine learning model, provided that it is appropriate for the task at hand. This study demonstrates the application of our approach to evaluate the robustness of deep learning models. To this end, we study small models composed of a few convolutional and fully connected layers, using common optimizers due to their ease of interpretation and computational efficiency. Within this framework, we address the influence of training sample size, model weight initialization, and inductive bias on the robustness of deep learning models.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.8%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #b3ebae" title="Confidence: 6.9%">
                            Federated Learning
                        </span>
                <!-- LLMs: 3.7 -->
                    
                <!-- Evolutionary Algorithms: 3.0 -->
                    
                <!-- Bayesian Optimization: 2.0 -->
                    
                <!-- Reinforcement Learning: 1.9 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Hardware: 1.1 -->
                    
                <!-- Computer Vision: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.2432
                </span>
                <a href="https://arxiv.org/abs/2505.17939" target="_blank" rel="noopener noreferrer">Directed Semi-Simplicial Learning with Applications to Brain Activity Decoding</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Manuel Lecha, Andrea Cavallo, Francesca Dominici, Ran Levi, Alessio Del Bue, Elvin Isufi, Pietro Morerio, Claudio Battiloro
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Graph Neural Networks (GNNs) excel at learning from pairwise interactions but often overlook multi-way and hierarchical relationships. Topological Deep Learning (TDL) addresses this limitation by leveraging combinatorial topological spaces. However, existing TDL models are restricted to undirected s</span>
                
                <span class="abstract-full" style="display: none;">Graph Neural Networks (GNNs) excel at learning from pairwise interactions but often overlook multi-way and hierarchical relationships. Topological Deep Learning (TDL) addresses this limitation by leveraging combinatorial topological spaces. However, existing TDL models are restricted to undirected settings and fail to capture the higher-order directed patterns prevalent in many complex systems, e.g., brain networks, where such interactions are both abundant and functionally significant. To fill this gap, we introduce Semi-Simplicial Neural Networks (SSNs), a principled class of TDL models that operate on semi-simplicial sets -- combinatorial structures that encode directed higher-order motifs and their directional relationships. To enhance scalability, we propose Routing-SSNs, which dynamically select the most informative relations in a learnable manner. We prove that SSNs are strictly more expressive than standard graph and TDL models. We then introduce a new principled framework for brain dynamics representation learning, grounded in the ability of SSNs to provably recover topological descriptors shown to successfully characterize brain activity. Empirically, SSNs achieve state-of-the-art performance on brain dynamics classification tasks, outperforming the second-best model by up to 27%, and message passing GNNs by up to 50% in accuracy. Our results highlight the potential of principled topological models for learning from structured brain data, establishing a unique real-world case study for TDL. We also test SSNs on standard node classification and edge regression tasks, showing competitive performance. We will make the code and data publicly available.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.9%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #b243cd" title="Confidence: 5.3%">
                            GNN
                        </span>
                <!-- Medicine: 2.3 -->
                    
                <!-- Computer Vision: 2.1 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.3241
                </span>
                <a href="https://arxiv.org/abs/2505.17593" target="_blank" rel="noopener noreferrer">JELAI: Integrating AI and Learning Analytics in Jupyter Notebooks</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Manuel Valle Torre, Thom van der Velden, Marcus Specht, Catharine Oertel
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Generative AI offers potential for educational support, but often lacks pedagogical grounding and awareness of the student's learning context. Furthermore, researching student interactions with these tools within authentic learning environments remains challenging. To address this, we present JELAI,</span>
                
                <span class="abstract-full" style="display: none;">Generative AI offers potential for educational support, but often lacks pedagogical grounding and awareness of the student's learning context. Furthermore, researching student interactions with these tools within authentic learning environments remains challenging. To address this, we present JELAI, an open-source platform architecture designed to integrate fine-grained Learning Analytics (LA) with Large Language Model (LLM)-based tutoring directly within a Jupyter Notebook environment. JELAI employs a modular, containerized design featuring JupyterLab extensions for telemetry and chat, alongside a central middleware handling LA processing and context-aware LLM prompt enrichment. This architecture enables the capture of integrated code interaction and chat data, facilitating real-time, context-sensitive AI scaffolding and research into student behaviour. We describe the system's design, implementation, and demonstrate its feasibility through system performance benchmarks and two proof-of-concept use cases illustrating its capabilities for logging multi-modal data, analysing help-seeking patterns, and supporting A/B testing of AI configurations. JELAI's primary contribution is its technical framework, providing a flexible tool for researchers and educators to develop, deploy, and study LA-informed AI tutoring within the widely used Jupyter ecosystem.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 9.1%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.4%">
                            LLMs
                        </span>
                <!-- Hardware: 3.4 -->
                    
                <!-- Blockchain: 2.3 -->
                    
                <!-- Computer Vision: 2.0 -->
                    
                <!-- Datasets: 1.8 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.3272
                </span>
                <a href="https://arxiv.org/abs/2504.15928" target="_blank" rel="noopener noreferrer">A Clinician-Friendly Platform for Ophthalmic Image Analysis Without Technical Barriers</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Meng Wang, Tian Lin, Qingshan Hou, Aidi Lin, Jingcheng Wang, Qingsheng Peng, Truong X. Nguyen, Danqi Fang, Ke Zou, Ting Xu, Cancan Xue, Ten Cheer Quek, Qinkai Yu, Minxin Liu, Hui Zhou, Zixuan Xiao, Guiqin He, Huiyu Liang, Tingkun Shi, Man Chen, Linna Liu, Yuanyuan Peng, Lianyu Wang, Qiuming Hu, Junhong Chen, Zhenhua Zhang, Cheng Chen, Yitian Zhao, Dianbo Liu, Jianhua Wu, Xinjian Chen, Changqing Zhang, Triet Thanh Nguyen, Yanda Meng, Yalin Zheng, Yih Chung Tham, Carol Y. Cheung, Huazhu Fu, Haoyu Chen, Ching-Yu Cheng
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Artificial intelligence (AI) shows remarkable potential in medical imaging diagnostics, yet most current models require retraining when applied across different clinical settings, limiting their scalability. We introduce GlobeReady, a clinician-friendly AI platform that enables fundus disease diagno</span>
                
                <span class="abstract-full" style="display: none;">Artificial intelligence (AI) shows remarkable potential in medical imaging diagnostics, yet most current models require retraining when applied across different clinical settings, limiting their scalability. We introduce GlobeReady, a clinician-friendly AI platform that enables fundus disease diagnosis that operates without retraining, fine-tuning, or the needs for technical expertise. GlobeReady demonstrates high accuracy across imaging modalities: 93.9-98.5% for 11 fundus diseases using color fundus photographs (CPFs) and 87.2-92.7% for 15 fundus diseases using optic coherence tomography (OCT) scans. By leveraging training-free local feature augmentation, GlobeReady platform effectively mitigates domain shifts across centers and populations, achieving accuracies of 88.9-97.4% across five centers on average in China, 86.3-96.9% in Vietnam, and 73.4-91.0% in Singapore, and 90.2-98.9% in the UK. Incorporating a bulit-in confidence-quantifiable diagnostic mechanism further enhances the platform's accuracy to 94.9-99.4% with CFPs and 88.2-96.2% with OCT, while enabling identification of out-of-distribution cases with 86.3% accuracy across 49 common and rare fundus diseases using CFPs, and 90.6% accuracy across 13 diseases using OCT. Clinicians from countries rated GlobeReady highly for usability and clinical relevance (average score 4.6/5). These findings demonstrate GlobeReady's robustness, generalizability and potential to support global ophthalmic care without technical barriers.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 10.6%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.2%">
                            LLMs
                        </span>
                <!-- Computer Vision: 3.1 -->
                    
                <!-- Blockchain: 2.1 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- RAG: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.4377
                </span>
                <a href="https://arxiv.org/abs/2505.17915" target="_blank" rel="noopener noreferrer">Promptable cancer segmentation using minimal expert-curated data</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Lynn Karam, Yipei Wang, Veeru Kasivisvanathan, Mirabela Rusu, Yipeng Hu, Shaheer U. Saeed
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Automated segmentation of cancer on medical images can aid targeted diagnostic and therapeutic procedures. However, its adoption is limited by the high cost of expert annotations required for training and inter-observer variability in datasets. While weakly-supervised methods mitigate some challenge</span>
                
                <span class="abstract-full" style="display: none;">Automated segmentation of cancer on medical images can aid targeted diagnostic and therapeutic procedures. However, its adoption is limited by the high cost of expert annotations required for training and inter-observer variability in datasets. While weakly-supervised methods mitigate some challenges, using binary histology labels for training as opposed to requiring full segmentation, they require large paired datasets of histology and images, which are difficult to curate. Similarly, promptable segmentation aims to allow segmentation with no re-training for new tasks at inference, however, existing models perform poorly on pathological regions, again necessitating large datasets for training. In this work we propose a novel approach for promptable segmentation requiring only 24 fully-segmented images, supplemented by 8 weakly-labelled images, for training. Curating this minimal data to a high standard is relatively feasible and thus issues with the cost and variability of obtaining labels can be mitigated. By leveraging two classifiers, one weakly-supervised and one fully-supervised, our method refines segmentation through a guided search process initiated by a single-point prompt. Our approach outperforms existing promptable segmentation methods, and performs comparably with fully-supervised methods, for the task of prostate cancer segmentation, while using substantially less annotated data (up to 100X less). This enables promptable segmentation with very minimal labelled data, such that the labels can be curated to a very high standard.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 9.8%">
                            Medicine
                        </span>
                <!-- LLMs: 3.1 -->
                    
                <!-- Federated Learning: 2.9 -->
                    
                <!-- Computer Vision: 2.7 -->
                    
                <!-- Evolutionary Algorithms: 2.7 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.5214
                </span>
                <a href="https://arxiv.org/abs/2505.18021" target="_blank" rel="noopener noreferrer">Building Floor Number Estimation from Crowdsourced Street-Level Images: Munich Dataset and Baseline Method</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yao Sun, Sining Chen, Yifan Tian, Xiao Xiang Zhu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Accurate information on the number of building floors, or above-ground storeys, is essential for household estimation, utility provision, risk assessment, evacuation planning, and energy modeling. Yet large-scale floor-count data are rarely available in cadastral and 3D city databases. This study pr</span>
                
                <span class="abstract-full" style="display: none;">Accurate information on the number of building floors, or above-ground storeys, is essential for household estimation, utility provision, risk assessment, evacuation planning, and energy modeling. Yet large-scale floor-count data are rarely available in cadastral and 3D city databases. This study proposes an end-to-end deep learning framework that infers floor numbers directly from unrestricted, crowdsourced street-level imagery, avoiding hand-crafted features and generalizing across diverse facade styles. To enable benchmarking, we release the Munich Building Floor Dataset, a public set of over 6800 geo-tagged images collected from Mapillary and targeted field photography, each paired with a verified storey label. On this dataset, the proposed classification-regression network attains 81.2% exact accuracy and predicts 97.9% of buildings within +/-1 floor. The method and dataset together offer a scalable route to enrich 3D city models with vertical information and lay a foundation for future work in urban informatics, remote sensing, and geographic information science. Source code and data will be released under an open license at https://github.com/ya0-sun/Munich-SVI-Floor-Benchmark.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 10.9%">
                            Medicine
                        </span>
                <!-- LLMs: 3.7 -->
                    
                <!-- Datasets: 2.8 -->
                    
                <!-- 3D: 2.2 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.6129
                </span>
                <a href="https://arxiv.org/abs/2505.18075" target="_blank" rel="noopener noreferrer">Beyond flat-panel displays, applications of stereographic and holographic devices in 3D microscopy data analysis</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yong Wan, Holly A. Holman, Charles Hansen
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Laser scanning microscopy enables the acquisition of 3D data in biomedical research. A fundamental challenge in visualizing 3D data is that common flat-panel displays, being 2D in nature, cannot faithfully reproduce light fields. Recent years have witnessed the development of various 3D display tech</span>
                
                <span class="abstract-full" style="display: none;">Laser scanning microscopy enables the acquisition of 3D data in biomedical research. A fundamental challenge in visualizing 3D data is that common flat-panel displays, being 2D in nature, cannot faithfully reproduce light fields. Recent years have witnessed the development of various 3D display technologies. These technologies generally fall into two categories, stereography and holography, depending on the number of perspectives they can simultaneously present. We have integrated support for many commercially available 3D-capable displays into FluoRender, a visualization and analysis system for fluorescence microscopy data. This study investigates the opportunities and challenges of applying various 3D display devices in biological research, focusing on their practical use and potential for broad adoption. We found that 3D display devices, including the HoloLens and the Looking Glass, each have their merits and shortcomings. We predict that the convergence of stereographic and holographic technologies will create powerful tools for visualization and analysis in biological applications.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 9.4%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.6%">
                            LLMs
                        </span>
                <!-- Blockchain: 2.8 -->
                    
                <!-- Datasets: 2.3 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.6568
                </span>
                <a href="https://arxiv.org/abs/2505.17352" target="_blank" rel="noopener noreferrer">Alignment and Safety of Diffusion Models via Reinforcement Learning and Reward Modeling: A Survey</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Preeti Lamba, Kiran Ravish, Ankita Kushwaha, Pawan Kumar
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Diffusion models have emerged as leading generative models for images and other modalities, but aligning their outputs with human preferences and safety constraints remains a critical challenge. This thesis proposal investigates methods to align diffusion models using reinforcement learning (RL) and</span>
                
                <span class="abstract-full" style="display: none;">Diffusion models have emerged as leading generative models for images and other modalities, but aligning their outputs with human preferences and safety constraints remains a critical challenge. This thesis proposal investigates methods to align diffusion models using reinforcement learning (RL) and reward modeling. We survey recent advances in fine-tuning text-to-image diffusion models with human feedback, including reinforcement learning from human and AI feedback, direct preference optimization, and differentiable reward approaches. We classify these methods based on the type of feedback (human, automated, binary or ranked preferences), the fine-tuning technique (policy gradient, reward-weighted likelihood, direct backpropagation, etc.), and their efficiency and safety outcomes. We compare key algorithms and frameworks, highlighting how they improve alignment with user intent or safety standards, and discuss inter-relationships such as how newer methods build on or diverge from earlier ones. Based on the survey, we identify five promising research directions for the next two years: (1) multi-objective alignment with combined rewards, (2) efficient human feedback usage and active learning, (3) robust safety alignment against adversarial inputs, (4) continual and online alignment of diffusion models, and (5) interpretable and trustworthy reward modeling for generative images. Each direction is elaborated with its problem statement, challenges, related work, and a proposed research plan. The proposal is organized as a comprehensive document with literature review, comparative tables of methods, and detailed research plans, aiming to contribute new insights and techniques for safer and value-aligned diffusion-based generative AI.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 10.4%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.5%">
                            LLMs
                        </span>
                <!-- Computer Vision: 2.3 -->
                    
                <!-- Datasets: 2.3 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- HPO and AutoML: 1.8 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- 3D: 1.1 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.8146
                </span>
                <a href="https://arxiv.org/abs/2504.20118" target="_blank" rel="noopener noreferrer">OpenTCM: A GraphRAG-Empowered LLM-based System for Traditional Chinese Medicine Knowledge Retrieval and Diagnosis</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jinglin He, Yunqi Guo, Lai Kwan Lam, Waikei Leung, Lixing He, Yuanan Jiang, Chi Chiu Wang, Guoliang Xing, Hongkai Chen
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Traditional Chinese Medicine (TCM) represents a rich repository of ancient medical knowledge that continues to play an important role in modern healthcare. Due to the complexity and breadth of the TCM literature, the integration of AI technologies is critical for its modernization and broader access</span>
                
                <span class="abstract-full" style="display: none;">Traditional Chinese Medicine (TCM) represents a rich repository of ancient medical knowledge that continues to play an important role in modern healthcare. Due to the complexity and breadth of the TCM literature, the integration of AI technologies is critical for its modernization and broader accessibility. However, this integration poses considerable challenges, including the interpretation of obscure classical Chinese texts and the modeling of intricate semantic relationships among TCM concepts. In this paper, we develop OpenTCM, an LLM-based system that combines a domain-specific TCM knowledge graph and Graph-based Retrieval-Augmented Generation (GraphRAG). First, we extract more than 3.73 million classical Chinese characters from 68 gynecological books in the Chinese Medical Classics Database, with the help of TCM and gynecology experts. Second, we construct a comprehensive multi-relational knowledge graph comprising more than 48,000 entities and 152,000 interrelationships, using customized prompts and Chinese-oriented LLMs such as DeepSeek and Kimi to ensure high-fidelity semantic understanding. Last, we integrate OpenTCM with this knowledge graph, enabling high-fidelity ingredient knowledge retrieval and diagnostic question-answering without model fine-tuning. Experimental evaluations demonstrate that our prompt design and model selection significantly improve knowledge graph quality, achieving a precision of 98. 55% and an F1 score of 99. 55%. In addition, OpenTCM achieves mean expert scores of 4.5 in ingredient information retrieval and 3.8 in diagnostic question-answering tasks, outperforming state-of-the-art solutions in real-world TCM use cases.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 10.6%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 9.0%">
                            Medicine
                        </span>
                <!-- Blockchain: 1.9 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Datasets: 1.7 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.1272
                </span>
                <a href="https://arxiv.org/abs/2505.17647" target="_blank" rel="noopener noreferrer">4D-CTA Image and geometry dataset for kinematic analysis of abdominal aortic aneurysms</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Mostafa Jamshidian, Adam Wittek, Saeideh Sekhavat, Farah Alkhatib, Jens Carsten Ritter, Paul M. Parizel, Donatien Le Liepvre, Florian Bernard, Ludovic Minvielle, Antoine Fondan\`eche, Jane Polce, Christopher Wood, Karol Miller
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This article presents a dataset used in the article "Kinematics of Abdominal Aortic Aneurysms" [arXiv:2405.13377], published in the Journal of Biomechanics. The dataset is publicly available for download from the Zenodo data repository (https://doi.org/10.5281/zenodo.15477710). The dataset includes </span>
                
                <span class="abstract-full" style="display: none;">This article presents a dataset used in the article "Kinematics of Abdominal Aortic Aneurysms" [arXiv:2405.13377], published in the Journal of Biomechanics. The dataset is publicly available for download from the Zenodo data repository (https://doi.org/10.5281/zenodo.15477710). The dataset includes time-resolved 3D computed tomography angiography (4D-CTA) images of abdominal aortic aneurysm (AAA) captured throughout the cardiac cycle from ten patients diagnosed with AAA, along with ten patient-specific AAA geometries extracted from these images. Typically, the 4D-CTA dataset for each patient contains ten electrocardiogram (ECG)-gated 3D-CTA image frames acquired over a cardiac cycle, capturing both the systolic and diastolic phases of the AAA configuration. For method verification, the dataset also includes synthetic ground truth data generated from Patient 1's 3D-CTA AAA image in the diastolic phase. The ground truth data includes the patient-specific finite element (FE) biomechanical model and a synthetic systolic 3D-CTA image. The synthetic systolic image was generated by warping Patient 1's diastolic 3D-CTA image using the realistic displacement field obtained from the AAA biomechanical FE model. The images were acquired at Fiona Stanley Hospital in Western Australia and provided to the researchers at the Intelligent Systems for Medicine Laboratory at The University of Western Australia (ISML-UWA), where image-based AAA kinematic analysis was performed. Our dataset enabled the analysis of AAA wall displacement and strain throughout the cardiac cycle using a non-invasive, in vivo, image registration-based approach. The use of widely adopted, open-source file formats (NRRD for images and STL for geometries) facilitates broad applicability and reusability in AAA biomechanics studies that require patient-specific geometry and information about AAA kinematics during cardiac cycle.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 13.6%">
                            Medicine
                        </span>
                <!-- Datasets: 4.2 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- LLMs: 1.4 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Finance: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                <!-- Math: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.2271
                </span>
                <a href="https://arxiv.org/abs/2505.17317" target="_blank" rel="noopener noreferrer">Optimizing Image Capture for Computer Vision-Powered Taxonomic Identification and Trait Recognition of Biodiversity Specimens</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Alyson East, Elizabeth G. Campolongo, Luke Meyers, S M Rayeed, Samuel Stevens, Iuliia Zarubiieva, Isadora E. Fluck, Jennifer C. Gir\'on, Maximiliane Jousse, Scott Lowe, Kayla I Perry, Isabelle Betancourt, Noah Charney, Evan Donoso, Nathan Fox, Kim J. Landsbergen, Ekaterina Nepovinnykh, Michelle Ramirez, Parkash Singh, Khum Thapa-Magar, Matthew Thompson, Evan Waite, Tanya Berger-Wolf, Hilmar Lapp, Paula Mabee, Graham Taylor, Sydne Record
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Biological collections house millions of specimens documenting Earth's biodiversity, with digital images increasingly available through open-access platforms. Most imaging protocols were developed for human visual interpretation without considering computational analysis requirements. This paper aim</span>
                
                <span class="abstract-full" style="display: none;">Biological collections house millions of specimens documenting Earth's biodiversity, with digital images increasingly available through open-access platforms. Most imaging protocols were developed for human visual interpretation without considering computational analysis requirements. This paper aims to bridge the gap between current imaging practices and the potential for automated analysis by presenting key considerations for creating biological specimen images optimized for computer vision applications. We provide conceptual computer vision topics for context, addressing fundamental concerns including model generalization, data leakage, and comprehensive metadata documentation, and outline practical guidance on specimen imagine, and data storage. These recommendations were synthesized through interdisciplinary collaboration between taxonomists, collection managers, ecologists, and computer scientists. Through this synthesis, we have identified ten interconnected considerations that form a framework for successfully integrating biological specimen images into computer vision pipelines. The key elements include: (1) comprehensive metadata documentation, (2) standardized specimen positioning, (3) consistent size and color calibration, (4) protocols for handling multiple specimens in one image, (5) uniform background selection, (6) controlled lighting, (7) appropriate resolution and magnification, (8) optimal file formats, (9) robust data archiving strategies, and (10) accessible data sharing practices. By implementing these recommendations, collection managers, taxonomists, and biodiversity informaticians can generate images that support automated trait extraction, species identification, and novel ecological and evolutionary analyses at unprecedented scales. Successful implementation lies in thorough documentation of methodological choices.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 12.7%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.3%">
                            LLMs
                        </span>
                <!-- Computer Vision: 3.3 -->
                    
                <!-- Hardware: 3.0 -->
                    
                <!-- Datasets: 2.5 -->
                    
                <!-- Blockchain: 2.1 -->
                    
                <!-- Decision Trees: 1.9 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.8079
                </span>
                <a href="https://arxiv.org/abs/2505.17357" target="_blank" rel="noopener noreferrer">Graph Attention Neural Network for Botnet Detection: Evaluating Autoencoder, VAE and PCA-Based Dimension Reduction</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Hassan Wasswa, Hussein Abbass, Timothy Lynar
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">With the rise of IoT-based botnet attacks, researchers have explored various learning models for detection, including traditional machine learning, deep learning, and hybrid approaches. A key advancement involves deploying attention mechanisms to capture long-term dependencies among features, signif</span>
                
                <span class="abstract-full" style="display: none;">With the rise of IoT-based botnet attacks, researchers have explored various learning models for detection, including traditional machine learning, deep learning, and hybrid approaches. A key advancement involves deploying attention mechanisms to capture long-term dependencies among features, significantly improving detection accuracy. However, most models treat attack instances independently, overlooking inter-instance relationships. Graph Neural Networks (GNNs) address this limitation by learning an embedding space via iterative message passing where similar instances are placed closer based on node features and relationships, enhancing classification performance. To further improve detection, attention mechanisms have been embedded within GNNs, leveraging both long-range dependencies and inter-instance connections. However, transforming the high dimensional IoT attack datasets into a graph structured dataset poses challenges, such as large graph structures leading computational overhead. To mitigate this, this paper proposes a framework that first reduces dimensionality of the NetFlow-based IoT attack dataset before transforming it into a graph dataset. We evaluate three dimension reduction techniques--Variational Autoencoder (VAE-encoder), classical autoencoder (AE-encoder), and Principal Component Analysis (PCA)--and compare their effects on a Graph Attention neural network (GAT) model for botnet attack detection</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #b243cd" title="Confidence: 6.2%">
                            GNN
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.1%">
                            Medicine
                        </span>
                <!-- LLMs: 3.3 -->
                    
                <!-- Computer Vision: 2.8 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Datasets: 1.8 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.2967
                </span>
                <a href="https://arxiv.org/abs/2504.15141" target="_blank" rel="noopener noreferrer">Breaking Down Quantum Compilation: Profiling and Identifying Costly Passes</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Felix Zilk, Alessandro Tundo, Vincenzo De Maio, Ivona Brandic
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">With the increasing capabilities of quantum systems, the efficient, practical execution of quantum programs is becoming more critical. Each execution includes compilation time, which accounts for substantial overhead of the overall program runtime. To address this challenge, proposals that leverage </span>
                
                <span class="abstract-full" style="display: none;">With the increasing capabilities of quantum systems, the efficient, practical execution of quantum programs is becoming more critical. Each execution includes compilation time, which accounts for substantial overhead of the overall program runtime. To address this challenge, proposals that leverage precompilation techniques have emerged, whereby entire circuits or select components are precompiled to mitigate the compilation time spent during execution. Considering the impact of compilation time on quantum program execution, identifying the contribution of each individual compilation task to the execution time is necessary in directing the community's research efforts towards the development of an efficient compilation and execution pipeline. In this work, we perform a preliminary analysis of the quantum circuit compilation process in Qiskit, examining the cumulative runtime of each individual compilation task and identifying the tasks that most strongly impact the overall compilation time. Our results indicate that, as the desired level of optimization increases, circuit optimization and gate synthesis passes become the dominant tasks in compiling a Quantum Fourier Transform, with individual passes consuming up to 87% of the total compilation time. Mapping passes require the most compilation time for a GHZ state preparation circuit, accounting for over 99% of total compilation time.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 7.0%">
                            Quantum Computing
                        </span>
                <!-- Federated Learning: 3.4 -->
                    
                <!-- Medicine: 2.4 -->
                    
                <!-- Evolutionary Algorithms: 2.2 -->
                    
                <!-- Bayesian Optimization: 2.2 -->
                    
                <!-- LLMs: 1.9 -->
                    
                <!-- Math: 1.8 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Cryptography: 1.2 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                <!-- GNN: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.3579
                </span>
                <a href="https://arxiv.org/abs/2311.06358" target="_blank" rel="noopener noreferrer">Compact Matrix Quantum Group Equivariant Neural Networks</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Edward Pearce-Crump
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Group equivariant neural networks have proven effective in modelling a wide range of tasks where the data lives in a classical geometric space and exhibits well-defined group symmetries. However, these networks are not suitable for learning from data that lives in a non-commutative geometry, describ</span>
                
                <span class="abstract-full" style="display: none;">Group equivariant neural networks have proven effective in modelling a wide range of tasks where the data lives in a classical geometric space and exhibits well-defined group symmetries. However, these networks are not suitable for learning from data that lives in a non-commutative geometry, described formally by non-commutative $C^{*}$-algebras, since the $C^{*}$-algebra of continuous functions on a compact matrix group is commutative. To address this limitation, we derive the existence of a new type of equivariant neural network, called compact matrix quantum group equivariant neural networks, which encode symmetries that are described by compact matrix quantum groups. We characterise the weight matrices that appear in these neural networks for the easy compact matrix quantum groups, which are defined by set partitions. As a result, we obtain new characterisations of equivariant weight matrices for some compact matrix groups that have not appeared previously in the machine learning literature.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 7.6%">
                            Quantum Computing
                        </span>
                <!-- GNN: 3.7 -->
                    
                <!-- Medicine: 2.1 -->
                    
                <!-- LLMs: 2.0 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Math: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Cryptography: 1.4 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Networks: 1.2 -->
                    
                <!-- Game Theory: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -5.2427
                </span>
                <a href="https://arxiv.org/abs/2505.17931" target="_blank" rel="noopener noreferrer">AutoMiSeg: Automatic Medical Image Segmentation via Test-Time Adaptation of Foundation Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Xingjian Li, Qifeng Wu, Colleen Que, Yiran Ding, Adithya S. Ubaradka, Jianhua Xing, Tianyang Wang, Min Xu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Medical image segmentation is vital for clinical diagnosis, yet current deep learning methods often demand extensive expert effort, i.e., either through annotating large training datasets or providing prompts at inference time for each new case. This paper introduces a zero-shot and automatic segmen</span>
                
                <span class="abstract-full" style="display: none;">Medical image segmentation is vital for clinical diagnosis, yet current deep learning methods often demand extensive expert effort, i.e., either through annotating large training datasets or providing prompts at inference time for each new case. This paper introduces a zero-shot and automatic segmentation pipeline that combines off-the-shelf vision-language and segmentation foundation models. Given a medical image and a task definition (e.g., "segment the optic disc in an eye fundus image"), our method uses a grounding model to generate an initial bounding box, followed by a visual prompt boosting module that enhance the prompts, which are then processed by a promptable segmentation model to produce the final mask. To address the challenges of domain gap and result verification, we introduce a test-time adaptation framework featuring a set of learnable adaptors that align the medical inputs with foundation model representations. Its hyperparameters are optimized via Bayesian Optimization, guided by a proxy validation model without requiring ground-truth labels. Our pipeline offers an annotation-efficient and scalable solution for zero-shot medical image segmentation across diverse tasks. Our pipeline is evaluated on seven diverse medical imaging datasets and shows promising results. By proper decomposition and test-time adaptation, our fully automatic pipeline performs competitively with weakly-prompted interactive foundation models.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 22.7%">
                            Medicine
                        </span>
                <!-- LLMs: 4.6 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- 3D: 2.1 -->
                    
                <!-- Computer Vision: 2.1 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                <!-- Datasets: 1.0 -->
                    
                <!-- Bayesian Optimization: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -5.9754
                </span>
                <a href="https://arxiv.org/abs/2505.17971" target="_blank" rel="noopener noreferrer">Explainable Anatomy-Guided AI for Prostate MRI: Foundation Models and In Silico Clinical Trials for Virtual Biopsy-based Risk Assessment</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Danial Khan, Zohaib Salahuddin, Yumeng Zhang, Sheng Kuang, Shruti Atul Mali, Henry C. Woodruff, Sina Amirrajab, Rachel Cavill, Eduardo Ibor-Crespo, Ana Jimenez-Pastor, Adrian Galiana-Bordera, Paula Jimenez Gomez, Luis Marti-Bonmati, Philippe Lambin
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We present a fully automated, anatomically guided deep learning pipeline for prostate cancer (PCa) risk stratification using routine MRI. The pipeline integrates three key components: an nnU-Net module for segmenting the prostate gland and its zones on axial T2-weighted MRI; a classification module </span>
                
                <span class="abstract-full" style="display: none;">We present a fully automated, anatomically guided deep learning pipeline for prostate cancer (PCa) risk stratification using routine MRI. The pipeline integrates three key components: an nnU-Net module for segmenting the prostate gland and its zones on axial T2-weighted MRI; a classification module based on the UMedPT Swin Transformer foundation model, fine-tuned on 3D patches with optional anatomical priors and clinical data; and a VAE-GAN framework for generating counterfactual heatmaps that localize decision-driving image regions. The system was developed using 1,500 PI-CAI cases for segmentation and 617 biparametric MRIs with metadata from the CHAIMELEON challenge for classification (split into 70% training, 10% validation, and 20% testing). Segmentation achieved mean Dice scores of 0.95 (gland), 0.94 (peripheral zone), and 0.92 (transition zone). Incorporating gland priors improved AUC from 0.69 to 0.72, with a three-scale ensemble achieving top performance (AUC = 0.79, composite score = 0.76), outperforming the 2024 CHAIMELEON challenge winners. Counterfactual heatmaps reliably highlighted lesions within segmented regions, enhancing model interpretability. In a prospective multi-center in-silico trial with 20 clinicians, AI assistance increased diagnostic accuracy from 0.72 to 0.77 and Cohen's kappa from 0.43 to 0.53, while reducing review time per case by 40%. These results demonstrate that anatomy-aware foundation models with counterfactual explainability can enable accurate, interpretable, and efficient PCa risk assessment, supporting their potential use as virtual biopsies in clinical practice.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 23.9%">
                            Medicine
                        </span>
                <!-- LLMs: 3.1 -->
                    
                <!-- Computer Vision: 2.6 -->
                    
                <!-- 3D: 2.0 -->
                    
                <!-- HPO and AutoML: 1.8 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -6.0311
                </span>
                <a href="https://arxiv.org/abs/2405.20237" target="_blank" rel="noopener noreferrer">Training-efficient density quantum machine learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Brian Coyle, Snehal Raj, Natansh Mathur, El Amine Cherrat, Nishant Jain, Skander Kazdaghli, Iordanis Kerenidis
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Quantum machine learning (QML) requires powerful, flexible and efficiently trainable models to be successful in solving challenging problems. We introduce density quantum neural networks, a model family that prepares mixtures of trainable unitaries, with a distributional constraint over coefficients</span>
                
                <span class="abstract-full" style="display: none;">Quantum machine learning (QML) requires powerful, flexible and efficiently trainable models to be successful in solving challenging problems. We introduce density quantum neural networks, a model family that prepares mixtures of trainable unitaries, with a distributional constraint over coefficients. This framework balances expressivity and efficient trainability, especially on quantum hardware. For expressivity, the Hastings-Campbell Mixing lemma converts benefits from linear combination of unitaries into density models with similar performance guarantees but shallower circuits. For trainability, commuting-generator circuits enable density model construction with efficiently extractable gradients. The framework connects to various facets of QML including post-variational and measurement-based learning. In classical settings, density models naturally integrate the mixture of experts formalism, and offer natural overfitting mitigation. The framework is versatile - we uplift several quantum models into density versions to improve model performance, or trainability, or both. These include Hamming weight-preserving and equivariant models, among others. Extensive numerical experiments validate our findings.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 8.0%">
                            Quantum Computing
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.7%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.3%">
                            LLMs
                        </span>
                <!-- Federated Learning: 2.4 -->
                    
                <!-- Decision Trees: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -6.4511
                </span>
                <a href="https://arxiv.org/abs/2505.17034" target="_blank" rel="noopener noreferrer">Preparing for the Post Quantum Era: Quantum Ready Architecture for Security and Risk Management (QUASAR) -- A Strategic Framework for Cybersecurity</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Abraham Itzhak Weinberg
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">As quantum computing progresses, traditional cryptographic systems face the threat of obsolescence due to the capabilities of quantum algorithms. This paper introduces the Quantum-Ready Architecture for Security and Risk Management (QUASAR), a novel framework designed to help organizations prepare f</span>
                
                <span class="abstract-full" style="display: none;">As quantum computing progresses, traditional cryptographic systems face the threat of obsolescence due to the capabilities of quantum algorithms. This paper introduces the Quantum-Ready Architecture for Security and Risk Management (QUASAR), a novel framework designed to help organizations prepare for the post-quantum era. QUASAR provides a structured approach to transition from current cryptographic systems to quantum-resistant alternatives, emphasizing technical, security, and operational readiness. The framework integrates a set of actionable components, a timeline for phased implementation, and continuous optimization strategies to ensure ongoing preparedness. Through performance indicators, readiness scores, and optimization functions, QUASAR enables organizations to assess their current state, identify gaps, and execute targeted actions to mitigate risks posed by quantum computing. By offering a comprehensive, adaptable, and quantifiable strategy, QUASAR equips organizations with the tools necessary to future-proof their operations and secure sensitive data against the impending rise of quantum technologies.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 6.1%">
                            Quantum Computing
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.2%">
                            Medicine
                        </span>
                <!-- Evolutionary Algorithms: 2.7 -->
                    
                <!-- LLMs: 2.2 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -6.5202
                </span>
                <a href="https://arxiv.org/abs/2411.11369" target="_blank" rel="noopener noreferrer">Exact Quantum Algorithm for Unit Commitment Optimization based on Partially Connected Quantum Neural Networks</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jian Liu, Xu Zhou, Zhuojun Zhou, Le Luo
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The quantum hybrid algorithm has become a very promising and speedily method today for solving the larger-scale optimization in the noisy intermediate-scale quantum (NISQ) era. The unit commitment (UC) problem is a fundamental problem in the power system which aims to satisfy a balance load with min</span>
                
                <span class="abstract-full" style="display: none;">The quantum hybrid algorithm has become a very promising and speedily method today for solving the larger-scale optimization in the noisy intermediate-scale quantum (NISQ) era. The unit commitment (UC) problem is a fundamental problem in the power system which aims to satisfy a balance load with minimal cost. In this paper, we focus on the implement of the UC-solving by exact quantum algorithms based on the quantum neural network (QNN). This method is tested with up to 10-unit system with the balance load constraint. In order to improve the computing precision and reduce the network complexity, we suggest the knowledge-based partially connected quantum neural network (PCQNN). The results show that the exact solutions can be obtained by the improved algorithm and the depth of the quantum circuit can be reduced simultaneously.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 10.6%">
                            Quantum Computing
                        </span>
                <!-- Evolutionary Algorithms: 3.7 -->
                    
                <!-- Federated Learning: 3.5 -->
                    
                <!-- Cryptography: 2.5 -->
                    
                <!-- Math: 2.4 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- Bayesian Optimization: 1.6 -->
                    
                <!-- Medicine: 1.5 -->
                    
                <!-- Finance: 1.3 -->
                    
                <!-- Networks: 1.2 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- GNN: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -6.9094
                </span>
                <a href="https://arxiv.org/abs/2504.08456" target="_blank" rel="noopener noreferrer">Generalization Bounds in Hybrid Quantum-Classical Machine Learning Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Tongyan Wu, Amine Bentellis, Alona Sakhnenko, Jeanette Miriam Lorenz
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Hybrid classical-quantum models aim to harness the strengths of both quantum computing and classical machine learning, but their practical potential remains poorly understood. In this work, we develop a unified mathematical framework for analyzing generalization in hybrid models, offering insight in</span>
                
                <span class="abstract-full" style="display: none;">Hybrid classical-quantum models aim to harness the strengths of both quantum computing and classical machine learning, but their practical potential remains poorly understood. In this work, we develop a unified mathematical framework for analyzing generalization in hybrid models, offering insight into how these systems learn from data. We establish a novel generalization bound of the form $O\big( \sqrt{\frac{T\log{T}}{N}} + \frac{\alpha}{\sqrt{N}}\big)$ for $N$ training data points, $T$ trainable quantum gates, and bounded fully-connected layers $||F|| \leq \alpha$. This bound decomposes cleanly into quantum and classical contributions, extending prior work on both components and clarifying their interaction. We apply our results to the quantum-classical convolutional neural network (QCCNN), an architecture that integrates quantum convolutional layers with classical processing. Alongside the bound, we highlight conceptual limitations of applying classical statistical learning theory in the hybrid setting and suggest promising directions for future theoretical work.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 11.2%">
                            Quantum Computing
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.3%">
                            LLMs
                        </span>
                <!-- Medicine: 4.0 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Datasets: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -7.4602
                </span>
                <a href="https://arxiv.org/abs/2505.18133" target="_blank" rel="noopener noreferrer">Joint Encryption and Error Correction for Secure Quantum Communication</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Nitin Jha, Abhishek Parakh, Mahadevan Subramaniam
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Secure quantum networks are a bedrock requirement for developing a future quantum internet. However, quantum channels are susceptible to channel noise that introduce errors in the transmitted data. The traditional approach to providing error correction typically encapsulates the message in an error </span>
                
                <span class="abstract-full" style="display: none;">Secure quantum networks are a bedrock requirement for developing a future quantum internet. However, quantum channels are susceptible to channel noise that introduce errors in the transmitted data. The traditional approach to providing error correction typically encapsulates the message in an error correction code after encryption. Such separate processes incur overhead that must be avoided when possible. We, consequently, provide a single integrated process that allows for encryption as well as error correction. This is a first attempt to do so for secure quantum communication and combines the Calderbank-Shor-Steane (CSS) code with the three-stage secure quantum communication protocol. Lastly, it allows for arbitrary qubits to be transmitted from sender to receiver making the proposed protocol general purpose.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 14.9%">
                            Quantum Computing
                        </span>
                <!-- Networks: 2.2 -->
                    
                <!-- Cryptography: 1.8 -->
                    
                <!-- Medicine: 1.7 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- LLMs: 1.4 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                <!-- Hardware: 1.1 -->
                    
                <!-- Game Theory: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Math: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -8.2955
                </span>
                <a href="https://arxiv.org/abs/2401.10579" target="_blank" rel="noopener noreferrer">Trade-offs between classical and quantum space using spooky pebbling</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Arend-Jan Quist, Alfons Laarman
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Pebble games are used to study space/time trade-offs. Recently, spooky pebble games were introduced to study classical space / quantum space / time trade-offs for simulation of classical circuits on quantum computers. In this paper, the spooky pebble game framework is applied for the first time to g</span>
                
                <span class="abstract-full" style="display: none;">Pebble games are used to study space/time trade-offs. Recently, spooky pebble games were introduced to study classical space / quantum space / time trade-offs for simulation of classical circuits on quantum computers. In this paper, the spooky pebble game framework is applied for the first time to general circuits. Using this framework we prove an upper bound for quantum space in the spooky pebble game. We also prove that solving the spooky pebble game is PSPACE-complete. Moreover, we present a solver for the spooky pebble game based on satisfiability solvers combined with heuristic optimizers. This spooky pebble game solver was empirically evaluated by calculating optimal classical space / quantum space / time trade-offs. Within limited runtime, the solver could find a strategy reducing quantum space when classical space is taken into account, showing that the spooky pebble model is useful to reduce quantum space.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 16.6%">
                            Quantum Computing
                        </span>
                <!-- Computer Vision: 2.0 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Cryptography: 1.9 -->
                    
                <!-- Math: 1.9 -->
                    
                <!-- Networks: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- Medicine: 1.7 -->
                    
                <!-- Game Theory: 1.5 -->
                    
                <!-- LLMs: 1.4 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Finance: 1.3 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -8.5713
                </span>
                <a href="https://arxiv.org/abs/2505.17756" target="_blank" rel="noopener noreferrer">Qiskit Machine Learning: an open-source library for quantum machine learning tasks at scale on quantum hardware and classical simulators</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: M. Emre Sahin, Edoardo Altamura, Oscar Wallis, Stephen P. Wood, Anton Dekusar, Declan A. Millar, Takashi Imamichi, Atsushi Matsuo, Stefano Mensa
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We present Qiskit Machine Learning (ML), a high-level Python library that combines elements of quantum computing with traditional machine learning. The API abstracts Qiskit's primitives to facilitate interactions with classical simulators and quantum hardware. Qiskit ML started as a proof-of-concept</span>
                
                <span class="abstract-full" style="display: none;">We present Qiskit Machine Learning (ML), a high-level Python library that combines elements of quantum computing with traditional machine learning. The API abstracts Qiskit's primitives to facilitate interactions with classical simulators and quantum hardware. Qiskit ML started as a proof-of-concept code in 2019 and has since been developed to be a modular, intuitive tool for non-specialist users while allowing extensibility and fine-tuning controls for quantum computational scientists and developers. The library is available as a public, open-source tool and is distributed under the Apache version 2.0 license.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 13.9%">
                            Quantum Computing
                        </span>
                <!-- Medicine: 4.7 -->
                    
                <!-- HPO and AutoML: 2.4 -->
                    
                <!-- LLMs: 2.3 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- 3D: 1.8 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                <!-- GNN: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -9.1107
                </span>
                <a href="https://arxiv.org/abs/2501.04600" target="_blank" rel="noopener noreferrer">Do Automated Fixes Truly Mitigate Smart Contract Exploits?</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Sofia Bobadilla, Monica Jin, Martin Monperrus
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Automated Program Repair (APR) for smart contract security promises to automatically mitigate smart contract vulnerabilities responsible for billions in financial losses. However, the true effectiveness of this research in addressing smart contract exploits remains uncharted territory. This paper br</span>
                
                <span class="abstract-full" style="display: none;">Automated Program Repair (APR) for smart contract security promises to automatically mitigate smart contract vulnerabilities responsible for billions in financial losses. However, the true effectiveness of this research in addressing smart contract exploits remains uncharted territory. This paper bridges this critical gap by introducing a novel and systematic experimental framework for evaluating exploit mitigation of program repair tools for smart contracts. We qualitatively and quantitatively analyze 20 state-of-the-art APR tools using a dataset of 143 vulnerable smart contracts, for which we manually craft 91 executable exploits. We are the very first to define and measure the essential "exploit mitigation rate" , giving researchers and practitioners a real sense of effectiveness of cutting edge techniques. Our findings reveal substantial disparities in the state of the art, with an exploit mitigation rate ranging from a low of 29% to a high of 74%. Our study identifies systemic limitations, such as inconsistent functionality preservation, that must be addressed in future research on program repair for smart contracts.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #3cc377" title="Confidence: 6.1%">
                            Blockchain
                        </span>
                <!-- LLMs: 3.5 -->
                    
                <!-- Medicine: 3.3 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Datasets: 1.9 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -12.3548
                </span>
                <a href="https://arxiv.org/abs/2505.17416" target="_blank" rel="noopener noreferrer">LLM-BSCVM: An LLM-Based Blockchain Smart Contract Vulnerability Management Framework</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yanli Jin, Chunpei Li, Peng Fan, Peng Liu, Xianxian Li, Chen Liu, Wangjie Qiu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Smart contracts are a key component of the Web 3.0 ecosystem, widely applied in blockchain services and decentralized applications. However, the automated execution feature of smart contracts makes them vulnerable to potential attacks due to inherent flaws, which can lead to severe security risks an</span>
                
                <span class="abstract-full" style="display: none;">Smart contracts are a key component of the Web 3.0 ecosystem, widely applied in blockchain services and decentralized applications. However, the automated execution feature of smart contracts makes them vulnerable to potential attacks due to inherent flaws, which can lead to severe security risks and financial losses, even threatening the integrity of the entire decentralized finance system. Currently, research on smart contract vulnerabilities has evolved from traditional program analysis methods to deep learning techniques, with the gradual introduction of Large Language Models. However, existing studies mainly focus on vulnerability detection, lacking systematic cause analysis and Vulnerability Repair. To address this gap, we propose LLM-BSCVM, a Large Language Model-based smart contract vulnerability management framework, designed to provide end-to-end vulnerability detection, analysis, repair, and evaluation capabilities for Web 3.0 ecosystem. LLM-BSCVM combines retrieval-augmented generation technology and multi-agent collaboration, introducing a three-stage method of Decompose-Retrieve-Generate. This approach enables smart contract vulnerability management through the collaborative efforts of six intelligent agents, specifically: vulnerability detection, cause analysis, repair suggestion generation, risk assessment, vulnerability repair, and patch evaluation. Experimental results demonstrate that LLM-BSCVM achieves a vulnerability detection accuracy and F1 score exceeding 91\% on benchmark datasets, comparable to the performance of state-of-the-art (SOTA) methods, while reducing the false positive rate from 7.2\% in SOTA methods to 5.1\%, thus enhancing the reliability of vulnerability management. Furthermore, LLM-BSCVM supports continuous security monitoring and governance of smart contracts through a knowledge base hot-swapping dynamic update mechanism.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #3cc377" title="Confidence: 9.0%">
                            Blockchain
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.1%">
                            LLMs
                        </span>
                <!-- Medicine: 3.3 -->
                    
                <!-- Federated Learning: 3.2 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -67.7087
                </span>
                <a href="https://arxiv.org/abs/2412.18208" target="_blank" rel="noopener noreferrer">Quantum framework for Reinforcement Learning: integrating Markov Decision Process, quantum arithmetic, and trajectory search</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Thet Htar Su, Shaswot Shresthamali, Masaaki Kondo
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper introduces a quantum framework for addressing reinforcement learning (RL) tasks, grounded in the quantum principles and leveraging a fully quantum model of the classical Markov Decision Process (MDP). By employing quantum concepts and a quantum search algorithm, this work presents the imp</span>
                
                <span class="abstract-full" style="display: none;">This paper introduces a quantum framework for addressing reinforcement learning (RL) tasks, grounded in the quantum principles and leveraging a fully quantum model of the classical Markov Decision Process (MDP). By employing quantum concepts and a quantum search algorithm, this work presents the implementation and optimization of the agent-environment interactions entirely within the quantum domain, eliminating reliance on classical computations. Key contributions include the quantum-based state transitions, return calculation, and trajectory search mechanism that utilize quantum principles to demonstrate the realization of RL processes through quantum phenomena. The implementation emphasizes the fundamental role of quantum superposition in enhancing computational efficiency for RL tasks. Results demonstrate the capacity of a quantum model to achieve quantum enhancement in RL, highlighting the potential of fully quantum implementations in decision-making tasks. This work not only underscores the applicability of quantum computing in machine learning but also contributes the field of quantum reinforcement learning (QRL) by offering a robust framework for understanding and exploiting quantum computing in RL systems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge high-confidence" style="background-color: #d37d97" title="Confidence: 76.2%">
                            Quantum Computing
                        </span>
                <!-- Medicine: 2.7 -->
                    
                <!-- Evolutionary Algorithms: 2.5 -->
                    
                <!-- Reinforcement Learning: 2.0 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                <!-- LLMs: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
    </div>
    
    
    <div id="jsonPopup" class="json-popup">
        <pre id="jsonContent"></pre>
        <button onclick="copyJson()">Copy to Clipboard</button>
        <button onclick="closePopup()">Close</button>
    </div>

    <script>
        function extractPaperData(paperElement) {
            const titleElement = paperElement.querySelector('.paper-title a');
            const metaElement = paperElement.querySelector('.paper-meta');
            const abstractElement = paperElement.querySelector('.paper-abstract');
            const tagsElement = paperElement.querySelector('.paper-tags');
            
            // Get the date from the parent date-section header
            const dateSection = paperElement.closest('.date-section');
            const dateText = dateSection.querySelector('.date-header').textContent.trim();
            
            const authorsText = metaElement.textContent.replace('Authors:', '').trim();
            
            const paperData = {
                title: titleElement.textContent,
                url: titleElement.href,
                authors: authorsText.split(',').map(author => author.trim()),
                created: dateText,
                abstract: abstractElement.querySelector('.abstract-full').textContent
            };
            
            return paperData;
        }

        function showJson(paperElement) {
            const popup = document.getElementById('jsonPopup');
            const content = document.getElementById('jsonContent');
            const paperData = extractPaperData(paperElement);
            content.textContent = JSON.stringify(paperData, null, null);
            popup.style.display = 'block';
            document.addEventListener('click', function closePopupOnClick(event) {
                if (!popup.contains(event.target)) {
                    popup.style.display = 'none';
                    document.removeEventListener('click', closePopupOnClick);
                }
            });
        }
        function toggleAbstract(element) {
            const abstract = element.parentElement;
            const short = abstract.querySelector('.abstract-short');
            const full = abstract.querySelector('.abstract-full');
            const lowConfidenceTags = abstract.parentElement.querySelectorAll('.tag-badge.low-confidence');
            
            if (element.textContent === '... more') {
                short.style.display = 'none';
                full.style.display = 'inline';
                element.textContent = ' less';
                lowConfidenceTags.forEach(tag => tag.style.display = 'inline-block');
            } else {
                short.style.display = 'inline';
                full.style.display = 'none';
                element.textContent = '... more';
                lowConfidenceTags.forEach(tag => tag.style.display = 'none');
            }
        }

        function closePopup() {
            document.getElementById('jsonPopup').style.display = 'none';
        }

        function copyJson() {
            const content = document.getElementById('jsonContent').textContent;
            navigator.clipboard.writeText(content).catch(() => {
                // If clipboard API is not available, just show the popup
                alert('Could not copy to clipboard. JSON is displayed in the popup.');
            });
        }

        // Close popup when clicking outside
        window.onclick = function(event) {
            const popup = document.getElementById('jsonPopup');
            if (event.target === popup) {
                popup.style.display = 'none';
            }
        }
    </script>
</body>
</html> 