<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv Frontpage</title>
    <style>
        body {
            font-family: sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
        }
        .paper {
            margin-bottom: 30px;
            margin-top: 30px;
            padding: 20px;
            border: 1px solid #ddd;
            border-radius: 5px;
        }
        .paper-title {
            font-size: 1.2em;
            font-weight: bold;
            margin-bottom: 10px;
        }
        .paper-meta {
            color: #666;
            font-size: 0.9em;
            margin-bottom: 10px;
        }
        .paper-abstract {
            margin-bottom: 10px;
        }
        .abstract-short {
            display: inline;
        }
        .abstract-full {
            display: none;
        }
        .more-link {
            color: blue;
            cursor: pointer;
            text-decoration: underline;
        }
        .tag-badge {
            display: inline-block;
            padding: 3px 8px;
            margin-right: 5px;
            margin-bottom: 5px;
            border-radius: 3px;
            font-size: 0.8em;
            color: white;
        }
        .tag-badge.high-confidence {
            opacity: 1;
        }
        .tag-badge.low-confidence {
            opacity: 0.6;
            display: none;
        }
        .interestingness-score {
            display: inline-block;
            padding: 3px 8px;
            margin-right: 10px;
            color: white;
            border-radius: 3px;
            font-weight: bold;
        }
        .interestingness-positive {
            background-color: #4CAF50;
        }
        .interestingness-negative {
            background-color: #f44336;
        }
        .interestingness-neutral {
            background-color: #9e9e9e;
        }
        .last-updated {
            text-align: right;
            color: #666;
            font-size: 0.9em;
            margin-top: 20px;
            margin-bottom: 20px;
        }
        .intro {
            text-align: center;
            max-width: 60em;
            margin: 0 auto;
            color: #888;
        }
        .copy-icon {
            display: inline-block;
            width: 16px;
            height: 16px;
            cursor: pointer;
            margin-left: 5px;
            opacity: 0.5;
        }
        .copy-icon:hover {
            opacity: 1;
        }
        .json-popup {
            display: none;
            position: fixed;
            top: 20px;
            right: 20px;
            background: white;
            padding: 20px;
            border: 1px solid #ddd;
            border-radius: 5px;
            max-width: 500px;
            max-height: 300px;
            overflow: auto;
            box-shadow: 0 0 10px rgba(0,0,0,0.1);
        }
        a {
            color: inherit;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        h1 {
            text-align: center;
        }
        h1 a {
            text-decoration: underline;
        }
        .date-section {
            margin-bottom: 40px;
        }
        .date-header {
            color: #666;
            font-size: 1.5em;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 2px solid #eee;
        }
    </style>
</head>
<body>
    <h1>
        <a href="https://github.com/DataWraith/arxiv-frontpage">DataWraith's</a> ArXiv Frontpage
    </h1>

    <div class="last-updated">
        Last updated: 2025-05-28
    </div>

    <p class="intro">
        This frontpage is made by scraping ArXiv's computer science RSS feed and tagging papers with a classifier.
    </p>

    <p class="intro">
        Each tag is weighted according to my preferences to compute a paper's <i>interestingness</i> score.
    </p>
    
    
    <div class="date-section">
        <h2 class="date-header">2025-05-28</h2>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.3065
                </span>
                <a href="https://arxiv.org/abs/2505.18142" target="_blank" rel="noopener noreferrer">TokBench: Evaluating Your Visual Tokenizer before Visual Generation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Junfeng Wu, Dongliang Luo, Weizhi Zhao, Zhihao Xie, Yuanhao Wang, Junyi Li, Xudong Xie, Yuliang Liu, Xiang Bai
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In this work, we reveal the limitations of visual tokenizers and VAEs in preserving fine-grained features, and propose a benchmark to evaluate reconstruction performance for two challenging visual contents: text and face. Visual tokenizers and VAEs have significantly advanced visual generation and m</span>
                
                <span class="abstract-full" style="display: none;">In this work, we reveal the limitations of visual tokenizers and VAEs in preserving fine-grained features, and propose a benchmark to evaluate reconstruction performance for two challenging visual contents: text and face. Visual tokenizers and VAEs have significantly advanced visual generation and multimodal modeling by providing more efficient compressed or quantized image representations. However, while helping production models reduce computational burdens, the information loss from image compression fundamentally limits the upper bound of visual generation quality. To evaluate this upper bound, we focus on assessing reconstructed text and facial features since they typically: 1) exist at smaller scales, 2) contain dense and rich textures, 3) are prone to collapse, and 4) are highly sensitive to human vision. We first collect and curate a diverse set of clear text and face images from existing datasets. Unlike approaches using VLM models, we employ established OCR and face recognition models for evaluation, ensuring accuracy while maintaining an exceptionally lightweight assessment process <span style="font-weight: bold; color: rgb(214, 21, 21);">requiring just 2GB memory and 4 minutes</span> to complete. Using our benchmark, we analyze text and face reconstruction quality across various scales for different image tokenizers and VAEs. Our results show modern visual tokenizers still struggle to preserve fine-grained features, especially at smaller scales. We further extend this evaluation framework to video, conducting comprehensive analysis of video tokenizers. Additionally, we demonstrate that traditional metrics fail to accurately reflect reconstruction performance for faces and text, while our proposed metrics serve as an effective complement.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 9.1%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.4%">
                            Medicine
                        </span>
                <!-- Computer Vision: 3.9 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- T2I: 1.5 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4633
                </span>
                <a href="https://arxiv.org/abs/2505.19515" target="_blank" rel="noopener noreferrer">Analyzing Biases in Political Dialogue: Tagging U.S. Presidential Debates with an Extended DAMSL Framework</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Lavanya Prahallad, Radhika Mamidi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We present a critical discourse analysis of the 2024 U.S. presidential debates, examining Donald Trump's rhetorical strategies in his interactions with Joe Biden and Kamala Harris. We introduce a novel annotation framework, BEADS (Bias Enriched Annotation for Dialogue Structure), which systematicall</span>
                
                <span class="abstract-full" style="display: none;">We present a critical discourse analysis of the 2024 U.S. presidential debates, examining Donald Trump's rhetorical strategies in his interactions with Joe Biden and Kamala Harris. We introduce a novel annotation framework, BEADS (Bias Enriched Annotation for Dialogue Structure), which systematically extends the DAMSL framework to capture bias driven and adversarial discourse features in political communication. BEADS includes a domain and language agnostic set of tags that model ideological framing, emotional appeals, and confrontational tactics. Our methodology compares detailed human annotation with zero shot ChatGPT assisted tagging on verified transcripts from the Trump and Biden (19,219 words) and Trump and Harris (18,123 words) debates. Our analysis shows that Trump consistently dominated in key categories: Challenge and Adversarial Exchanges, Selective Emphasis, Appeal to Fear, Political Bias, and Perceived Dismissiveness. These findings underscore his use of emotionally charged and adversarial rhetoric to control the narrative and influence audience perception. In this work, we establish BEADS as a scalable and reproducible framework for critical discourse analysis across languages, domains, and political contexts.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 14.0%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.4%">
                            Medicine
                        </span>
                <!-- Computer Vision: 2.1 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- 3D: 1.1 -->
                    
                <!-- Federated Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -7.4602
                </span>
                <a href="https://arxiv.org/abs/2505.18133" target="_blank" rel="noopener noreferrer">Joint Encryption and Error Correction for Secure Quantum Communication</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Nitin Jha, Abhishek Parakh, Mahadevan Subramaniam
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Secure quantum networks are a bedrock requirement for developing a future quantum internet. However, quantum channels are susceptible to channel noise that introduce errors in the transmitted data. The traditional approach to providing error correction typically encapsulates the message in an error </span>
                
                <span class="abstract-full" style="display: none;">Secure quantum networks are a bedrock requirement for developing a future quantum internet. However, quantum channels are susceptible to channel noise that introduce errors in the transmitted data. The traditional approach to providing error correction typically encapsulates the message in an error correction code after encryption. Such separate processes incur overhead that must be avoided when possible. We, consequently, provide a single integrated process that allows for encryption as well as error correction. This is a first attempt to do so for secure quantum communication and combines the Calderbank-Shor-Steane (CSS) code with the three-stage secure quantum communication protocol. Lastly, it allows for arbitrary qubits to be transmitted from sender to receiver making the proposed protocol general purpose.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 14.9%">
                            Quantum Computing
                        </span>
                <!-- Networks: 2.2 -->
                    
                <!-- Cryptography: 1.8 -->
                    
                <!-- Medicine: 1.7 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- LLMs: 1.4 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                <!-- Hardware: 1.1 -->
                    
                <!-- Game Theory: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Math: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                
            </div>
        </div>
        
    </div>
    
    <div class="date-section">
        <h2 class="date-header">2025-05-27</h2>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.8123
                </span>
                <a href="https://arxiv.org/abs/2405.10148" target="_blank" rel="noopener noreferrer">SpecDETR: A Transformer-based Hyperspectral Point Object Detection Network</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zhaoxu Li, Wei An, Gaowei Guo, Longguang Wang, Yingqian Wang, Zaiping Lin
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Hyperspectral target detection (HTD) aims to identify specific materials based on spectral information in hyperspectral imagery and can detect extremely small-sized objects, some of which occupy a smaller than one-pixel area. However, existing HTD methods are developed based on per-pixel binary clas</span>
                
                <span class="abstract-full" style="display: none;">Hyperspectral target detection (HTD) aims to identify specific materials based on spectral information in hyperspectral imagery and can detect extremely small-sized objects, some of which occupy a smaller than one-pixel area. However, existing HTD methods are developed based on per-pixel binary classification, neglecting the three-dimensional cube structure of hyperspectral images (HSIs) that integrates both spatial and spectral dimensions. The synergistic existence of spatial and spectral features in HSIs enable objects to simultaneously exhibit both, yet the per-pixel HTD framework limits the joint expression of these features. In this paper, we rethink HTD from the perspective of spatial-spectral synergistic representation and propose hyperspectral point object detection as an innovative task framework. We introduce SpecDETR, the first specialized network for hyperspectral multi-class point object detection, which eliminates dependence on pre-trained backbone networks commonly required by vision-based object detectors. SpecDETR uses a multi-layer Transformer encoder with self-excited subpixel-scale attention modules to directly extract deep spatial-spectral joint features from hyperspectral cubes. We develop a simulated hyperspectral point object detection benchmark termed SPOD, and for the first time, evaluate and compare the performance of visual object detection networks and HTD methods on hyperspectral point object detection. Extensive experiments demonstrate that our proposed SpecDETR outperforms SOTA visual object detection networks and HTD methods. Our code and dataset are available at https://github.com/ZhaoxuLi123/SpecDETR.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 13.9%">
                            Computer Vision
                        </span>
                <!-- Medicine: 3.8 -->
                    
                <!-- LLMs: 2.8 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.6452
                </span>
                <a href="https://arxiv.org/abs/2505.19731" target="_blank" rel="noopener noreferrer">Accelerating Nash Learning from Human Feedback via Mirror Prox</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Daniil Tiapkin, Daniele Calandriello, Denis Belomestny, Eric Moulines, Alexey Naumov, Kashif Rasul, Michal Valko, Pierre Menard
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Traditional Reinforcement Learning from Human Feedback (RLHF) often relies on reward models, frequently assuming preference structures like the Bradley-Terry model, which may not accurately capture the complexities of real human preferences (e.g., intransitivity). Nash Learning from Human Feedback (</span>
                
                <span class="abstract-full" style="display: none;">Traditional Reinforcement Learning from Human Feedback (RLHF) often relies on reward models, frequently assuming preference structures like the Bradley-Terry model, which may not accurately capture the complexities of real human preferences (e.g., intransitivity). Nash Learning from Human Feedback (NLHF) offers a more direct alternative by framing the problem as finding a Nash equilibrium of a game defined by these preferences. In this work, we introduce Nash Mirror Prox ($\mathtt{Nash-MP}$), an online NLHF algorithm that leverages the Mirror Prox optimization scheme to achieve fast and stable convergence to the Nash equilibrium. Our theoretical analysis establishes that Nash-MP exhibits last-iterate linear convergence towards the $\beta$-regularized Nash equilibrium. Specifically, we prove that the KL-divergence to the optimal policy decreases at a rate of order $(1+2\beta)^{-N/2}$, where $N$ is a number of preference queries. We further demonstrate last-iterate linear convergence for the exploitability gap and uniformly for the span semi-norm of log-probabilities, with all these rates being independent of the size of the action space. Furthermore, we propose and analyze an approximate version of Nash-MP where proximal steps are estimated using stochastic policy gradients, making the algorithm closer to applications. Finally, we detail a practical implementation strategy for fine-tuning large language models and present experiments that demonstrate its competitive performance and compatibility with existing methods.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #44f899" title="Confidence: 5.2%">
                            Reinforcement Learning
                        </span>
                <!-- Federated Learning: 4.0 -->
                    
                <!-- LLMs: 2.7 -->
                    
                <!-- Bayesian Optimization: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Medicine: 1.8 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Math: 1.4 -->
                    
                <!-- Game Theory: 1.2 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                <!-- Hardware: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.3527
                </span>
                <a href="https://arxiv.org/abs/2505.20001" target="_blank" rel="noopener noreferrer">NEXT: Multi-Grained Mixture of Experts via Text-Modulation for Multi-Modal Object Re-ID</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Shihao Li, Chenglong Li, Aihua Zheng, Andong Lu, Jin Tang, Jixin Ma
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Multi-modal object re-identification (ReID) aims to extract identity features across heterogeneous spectral modalities to enable accurate recognition and retrieval in complex real-world scenarios. However, most existing methods rely on implicit feature fusion structures, making it difficult to model</span>
                
                <span class="abstract-full" style="display: none;">Multi-modal object re-identification (ReID) aims to extract identity features across heterogeneous spectral modalities to enable accurate recognition and retrieval in complex real-world scenarios. However, most existing methods rely on implicit feature fusion structures, making it difficult to model fine-grained recognition strategies under varying challenging conditions. Benefiting from the powerful semantic understanding capabilities of Multi-modal Large Language Models (MLLMs), the visual appearance of an object can be effectively translated into descriptive text. In this paper, we propose a reliable multi-modal caption generation method based on attribute confidence, which significantly reduces the unknown recognition rate of MLLMs in multi-modal semantic generation and improves the quality of generated text. Additionally, we propose a novel ReID framework NEXT, the Multi-grained Mixture of Experts via Text-Modulation for Multi-modal Object Re-Identification. Specifically, we decouple the recognition problem into semantic and structural expert branches to separately capture modality-specific appearance and intrinsic structure. For semantic recognition, we propose the Text-Modulated Semantic-sampling Experts (TMSE), which leverages randomly sampled high-quality semantic texts to modulate expert-specific sampling of multi-modal features and mining intra-modality fine-grained semantic cues. Then, to recognize coarse-grained structure features, we propose the Context-Shared Structure-aware Experts (CSSE) that focuses on capturing the holistic object structure across modalities and maintains inter-modality structural consistency through a soft routing mechanism. Finally, we propose the Multi-Modal Feature Aggregation (MMFA), which adopts a unified feature fusion strategy to simply and effectively integrate semantic and structural expert outputs into the final identity representations.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.0%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.5%">
                            Computer Vision
                        </span>
                <!-- Federated Learning: 3.9 -->
                    
                <!-- Medicine: 3.4 -->
                    
                <!-- GNN: 2.6 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.313
                </span>
                <a href="https://arxiv.org/abs/2505.18986" target="_blank" rel="noopener noreferrer">VL-SAM-V2: Open-World Object Detection with General and Specific Query Fusion</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zhiwei Lin, Yongtao Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Current perception models have achieved remarkable success by leveraging large-scale labeled datasets, but still face challenges in open-world environments with novel objects. To address this limitation, researchers introduce open-set perception models to detect or segment arbitrary test-time user-i</span>
                
                <span class="abstract-full" style="display: none;">Current perception models have achieved remarkable success by leveraging large-scale labeled datasets, but still face challenges in open-world environments with novel objects. To address this limitation, researchers introduce open-set perception models to detect or segment arbitrary test-time user-input categories. However, open-set models rely on human involvement to provide predefined object categories as input during inference. More recently, researchers have framed a more realistic and challenging task known as open-ended perception that aims to discover unseen objects without requiring any category-level input from humans at inference time. Nevertheless, open-ended models suffer from low performance compared to open-set models. In this paper, we present VL-SAM-V2, an open-world object detection framework that is capable of discovering unseen objects while achieving favorable performance. To achieve this, we combine queries from open-set and open-ended models and propose a general and specific query fusion module to allow different queries to interact. By adjusting queries from open-set models, we enable VL-SAM-V2 to be evaluated in the open-set or open-ended mode. In addition, to learn more diverse queries, we introduce ranked learnable queries to match queries with proposals from open-ended models by sorting. Moreover, we design a denoising point training strategy to facilitate the training process. Experimental results on LVIS show that our method surpasses the previous open-set and open-ended methods, especially on rare objects.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.4%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 6.6%">
                            Computer Vision
                        </span>
                <!-- Federated Learning: 3.1 -->
                    
                <!-- GNN: 3.1 -->
                    
                <!-- 3D: 2.1 -->
                    
                <!-- Medicine: 2.0 -->
                    
                <!-- HPO and AutoML: 2.0 -->
                    
                <!-- Decision Trees: 1.8 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- T2I: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.3056
                </span>
                <a href="https://arxiv.org/abs/2412.00592" target="_blank" rel="noopener noreferrer">LiDAR-EDIT: LiDAR Data Generation by Editing the Object Layouts in Real-World Scenes</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Shing-Hei Ho, Bao Thach, Minghan Zhu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We present LiDAR-EDIT, a novel paradigm for generating synthetic LiDAR data for autonomous driving. Our framework edits real-world LiDAR scans by introducing new object layouts while preserving the realism of the background environment. Compared to end-to-end frameworks that generate LiDAR point clo</span>
                
                <span class="abstract-full" style="display: none;">We present LiDAR-EDIT, a novel paradigm for generating synthetic LiDAR data for autonomous driving. Our framework edits real-world LiDAR scans by introducing new object layouts while preserving the realism of the background environment. Compared to end-to-end frameworks that generate LiDAR point clouds from scratch, LiDAR-EDIT offers users full control over the object layout, including the number, type, and pose of objects, while keeping most of the original real-world background. Our method also provides object labels for the generated data. Compared to novel view synthesis techniques, our framework allows for the creation of counterfactual scenarios with object layouts significantly different from the original real-world scene. LiDAR-EDIT uses spherical voxelization to enforce correct LiDAR projective geometry in the generated point clouds by construction. During object removal and insertion, generative models are employed to fill the unseen background and object parts that were occluded in the original real LiDAR scans. Experimental results demonstrate that our framework produces realistic LiDAR scans with practical value for downstream tasks.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.7%">
                            Computer Vision
                        </span>
                <!-- Medicine: 3.0 -->
                    
                <!-- Federated Learning: 2.7 -->
                    
                <!-- LLMs: 2.5 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2972
                </span>
                <a href="https://arxiv.org/abs/2405.14273" target="_blank" rel="noopener noreferrer">A fast algorithm to minimize prediction loss of the optimal solution in inverse optimization problem of MILP</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Akira Kitaoka
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We consider the inverse optimization problem of estimating the weights of the objective function such that the given solution is an optimal solution for a mixed integer linear program (MILP). In this inverse optimization problem, the known methods exhibit inefficient convergence. Specifically, if $d</span>
                
                <span class="abstract-full" style="display: none;">We consider the inverse optimization problem of estimating the weights of the objective function such that the given solution is an optimal solution for a mixed integer linear program (MILP). In this inverse optimization problem, the known methods exhibit inefficient convergence. Specifically, if $d$ denotes the dimension of the weights and $k$ the number of iterations, then the error of the weights is bounded by $O(k^{-1/(d-1)})$, leading to slow convergence as $d$ increases. We propose a projected subgradient method with a step size of $k^{-1/2}$ based on suboptimality loss. We theoretically show and demonstrate that the proposed method efficiently learns the weights. In particular, we show that there exists a constant $\gamma > 0$ such that the distance between the learned and true weights is bounded by $ O\left(k^{-1/(1+\gamma)} \exp\left(-\frac{\gamma k^{1/2}}{2+\gamma}\right)\right), $ or the optimal solution is exactly recovered. Furthermore, experiments demonstrate that the proposed method solves the inverse optimization problems of MILP using fewer than $1/7$ the number of MILP calls required by known methods, and converges within a finite number of iterations.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #31bb31" title="Confidence: 13.0%">
                            Bayesian Optimization
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #b3ebae" title="Confidence: 5.9%">
                            Federated Learning
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #a49950" title="Confidence: 5.3%">
                            Math
                        </span>
                <!-- Reinforcement Learning: 4.2 -->
                    
                <!-- Evolutionary Algorithms: 3.2 -->
                    
                <!-- Networks: 2.0 -->
                    
                <!-- Cryptography: 1.4 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Medicine: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Finance: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2944
                </span>
                <a href="https://arxiv.org/abs/2409.19833" target="_blank" rel="noopener noreferrer">HazyDet: Open-Source Benchmark for Drone-View Object Detection with Depth-Cues in Hazy Scenes</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Changfeng Feng, Zhenyuan Chen, Xiang Li, Chunping Wang, Jian Yang, Ming-Ming Cheng, Yimian Dai, Qiang Fu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Object detection from aerial platforms under adverse atmospheric conditions, particularly haze, is paramount for robust drone autonomy. Yet, this domain remains largely underexplored, primarily hindered by the absence of specialized benchmarks. To bridge this gap, we present \textit{HazyDet}, the fi</span>
                
                <span class="abstract-full" style="display: none;">Object detection from aerial platforms under adverse atmospheric conditions, particularly haze, is paramount for robust drone autonomy. Yet, this domain remains largely underexplored, primarily hindered by the absence of specialized benchmarks. To bridge this gap, we present \textit{HazyDet}, the first, large-scale benchmark specifically designed for drone-view object detection in hazy conditions. Comprising 383,000 real-world instances derived from both naturally hazy captures and synthetically hazed scenes augmented from clear images, HazyDet provides a challenging and realistic testbed for advancing detection algorithms. To address the severe visual degradation induced by haze, we propose the Depth-Conditioned Detector (DeCoDet), a novel architecture that integrates a Depth-Conditioned Kernel to dynamically modulate feature representations based on depth cues. The practical efficacy and robustness of DeCoDet are further enhanced by its training with a Progressive Domain Fine-Tuning (PDFT) strategy to navigate synthetic-to-real domain shifts, and a Scale-Invariant Refurbishment Loss (SIRLoss) to ensure resilient learning from potentially noisy depth annotations. Comprehensive empirical validation on HazyDet substantiates the superiority of our unified DeCoDet framework, which achieves state-of-the-art performance, surpassing the closest competitor by a notable +1.5\% mAP on challenging real-world hazy test scenarios. Our dataset and toolkit are available at https://github.com/GrokCV/HazyDet.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.5%">
                            Computer Vision
                        </span>
                <!-- Medicine: 4.5 -->
                    
                <!-- Federated Learning: 2.5 -->
                    
                <!-- GNN: 2.3 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- LLMs: 1.8 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Hardware: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2775
                </span>
                <a href="https://arxiv.org/abs/2505.04119" target="_blank" rel="noopener noreferrer">GAPrompt: Geometry-Aware Point Cloud Prompt for 3D Vision Model</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zixiang Ai, Zichen Liu, Yuanhang Lei, Zhenyu Cui, Xu Zou, Jiahuan Zhou
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Pre-trained 3D vision models have gained significant attention for their promising performance on point cloud data. However, fully fine-tuning these models for downstream tasks is computationally expensive and storage-intensive. Existing parameter-efficient fine-tuning (PEFT) approaches, which focus</span>
                
                <span class="abstract-full" style="display: none;">Pre-trained 3D vision models have gained significant attention for their promising performance on point cloud data. However, fully fine-tuning these models for downstream tasks is computationally expensive and storage-intensive. Existing parameter-efficient fine-tuning (PEFT) approaches, which focus primarily on input token prompting, struggle to achieve competitive performance due to their limited ability to capture the geometric information inherent in point clouds. To address this challenge, we propose a novel Geometry-Aware Point Cloud Prompt (GAPrompt) that leverages geometric cues to enhance the adaptability of 3D vision models. First, we introduce a Point Prompt that serves as an auxiliary input alongside the original point cloud, explicitly guiding the model to capture fine-grained geometric details. Additionally, we present a Point Shift Prompter designed to extract global shape information from the point cloud, enabling instance-specific geometric adjustments at the input level. Moreover, our proposed Prompt Propagation mechanism incorporates the shape information into the model's feature extraction process, further strengthening its ability to capture essential geometric characteristics. Extensive experiments demonstrate that GAPrompt significantly outperforms state-of-the-art PEFT methods and achieves competitive results compared to full fine-tuning on various benchmarks, while utilizing only 2.19% of trainable parameters. Our code is available at https://github.com/zhoujiahuan1991/ICML2025-VGP.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.5%">
                            Computer Vision
                        </span>
                <!-- GNN: 4.6 -->
                    
                <!-- Medicine: 3.9 -->
                    
                <!-- 3D: 3.7 -->
                    
                <!-- Federated Learning: 2.9 -->
                    
                <!-- LLMs: 2.6 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.4 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Hardware: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2646
                </span>
                <a href="https://arxiv.org/abs/2505.19420" target="_blank" rel="noopener noreferrer">ADD-SLAM: Adaptive Dynamic Dense SLAM with Gaussian Splatting</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Wenhua Wu, Chenpeng Su, Siting Zhu, Tianchen Deng, Zhe Liu, Hesheng Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Recent advancements in Neural Radiance Fields (NeRF) and 3D Gaussian-based Simultaneous Localization and Mapping (SLAM) methods have demonstrated exceptional localization precision and remarkable dense mapping performance. However, dynamic objects introduce critical challenges by disrupting scene co</span>
                
                <span class="abstract-full" style="display: none;">Recent advancements in Neural Radiance Fields (NeRF) and 3D Gaussian-based Simultaneous Localization and Mapping (SLAM) methods have demonstrated exceptional localization precision and remarkable dense mapping performance. However, dynamic objects introduce critical challenges by disrupting scene consistency, leading to tracking drift and mapping artifacts. Existing methods that employ semantic segmentation or object detection for dynamic identification and filtering typically rely on predefined categorical priors, while discarding dynamic scene information crucial for robotic applications such as dynamic obstacle avoidance and environmental interaction. To overcome these challenges, we propose ADD-SLAM: an Adaptive Dynamic Dense SLAM framework based on Gaussian splitting. We design an adaptive dynamic identification mechanism grounded in scene consistency analysis, comparing geometric and textural discrepancies between real-time observations and historical maps. Ours requires no predefined semantic category priors and adaptively discovers scene dynamics. Precise dynamic object recognition effectively mitigates interference from moving targets during localization. Furthermore, we propose a dynamic-static separation mapping strategy that constructs a temporal Gaussian model to achieve online incremental dynamic modeling. Experiments conducted on multiple dynamic datasets demonstrate our method's flexible and accurate dynamic segmentation capabilities, along with state-of-the-art performance in both localization and mapping.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 6.1%">
                            Computer Vision
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.9%">
                            LLMs
                        </span>
                <!-- Medicine: 4.0 -->
                    
                <!-- 3D: 3.7 -->
                    
                <!-- HPO and AutoML: 1.9 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- T2I: 1.6 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2631
                </span>
                <a href="https://arxiv.org/abs/2405.05648" target="_blank" rel="noopener noreferrer">ASGrasp: Generalizable Transparent Object Reconstruction and 6-DoF Grasp Detection from RGB-D Active Stereo Camera</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jun Shi, Yong A, Yixiang Jin, Dingzhe Li, Haoyu Niu, Zhezhu Jin, He Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In this paper, we tackle the problem of grasping transparent and specular objects. This issue holds importance, yet it remains unsolved within the field of robotics due to failure of recover their accurate geometry by depth cameras. For the first time, we propose ASGrasp, a 6-DoF grasp detection net</span>
                
                <span class="abstract-full" style="display: none;">In this paper, we tackle the problem of grasping transparent and specular objects. This issue holds importance, yet it remains unsolved within the field of robotics due to failure of recover their accurate geometry by depth cameras. For the first time, we propose ASGrasp, a 6-DoF grasp detection network that uses an RGB-D active stereo camera. ASGrasp utilizes a two-layer learning-based stereo network for the purpose of transparent object reconstruction, enabling material-agnostic object grasping in cluttered environments. In contrast to existing RGB-D based grasp detection methods, which heavily depend on depth restoration networks and the quality of depth maps generated by depth cameras, our system distinguishes itself by its ability to directly utilize raw IR and RGB images for transparent object geometry reconstruction. We create an extensive synthetic dataset through domain randomization, which is based on GraspNet-1Billion. Our experiments demonstrate that ASGrasp can achieve over 90% success rate for generalizable transparent object grasping in both simulation and the real via seamless sim-to-real transfer. Our method significantly outperforms SOTA networks and even surpasses the performance upper bound set by perfect visible point cloud inputs.Project page: https://pku-epic.github.io/ASGrasp</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.3%">
                            Computer Vision
                        </span>
                <!-- LLMs: 4.1 -->
                    
                <!-- Medicine: 3.7 -->
                    
                <!-- Federated Learning: 2.9 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Quantum Computing: 2.0 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2617
                </span>
                <a href="https://arxiv.org/abs/2505.19227" target="_blank" rel="noopener noreferrer">Scaling Laws for Gradient Descent and Sign Descent for Linear Bigram Models under Zipf's Law</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Frederik Kunstner, Francis Bach
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Recent works have highlighted optimization difficulties faced by gradient descent in training the first and last layers of transformer-based language models, which are overcome by optimizers such as Adam. These works suggest that the difficulty is linked to the heavy-tailed distribution of words in </span>
                
                <span class="abstract-full" style="display: none;">Recent works have highlighted optimization difficulties faced by gradient descent in training the first and last layers of transformer-based language models, which are overcome by optimizers such as Adam. These works suggest that the difficulty is linked to the heavy-tailed distribution of words in text data, where the frequency of the $k$th most frequent word $\pi_k$ is proportional to $1/k$, following Zipf's law. To better understand the impact of the data distribution on training performance, we study a linear bigram model for next-token prediction when the tokens follow a power law $\pi_k \propto 1/k^\alpha$ parameterized by the exponent $\alpha > 0$. We derive optimization scaling laws for deterministic gradient descent and sign descent as a proxy for Adam as a function of the exponent $\alpha$. Existing theoretical investigations in scaling laws assume that the eigenvalues of the data decay as a power law with exponent $\alpha > 1$. This assumption effectively makes the problem ``finite dimensional'' as most of the loss comes from a few of the largest eigencomponents. In comparison, we show that the problem is more difficult when the data have heavier tails. The case $\alpha = 1$ as found in text data is ``worst-case'' for gradient descent, in that the number of iterations required to reach a small relative error scales almost linearly with dimension. While the performance of sign descent also depends on the dimension, for Zipf-distributed data the number of iterations scales only with the square-root of the dimension, leading to a large improvement for large vocabularies.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #31bb31" title="Confidence: 6.3%">
                            Bayesian Optimization
                        </span>
                <!-- Math: 2.8 -->
                    
                <!-- Federated Learning: 2.8 -->
                    
                <!-- Reinforcement Learning: 2.3 -->
                    
                <!-- Networks: 2.0 -->
                    
                <!-- Medicine: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Cryptography: 1.6 -->
                    
                <!-- Finance: 1.4 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Game Theory: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2421
                </span>
                <a href="https://arxiv.org/abs/2405.07760" target="_blank" rel="noopener noreferrer">CAGES: Cost-Aware Gradient Entropy Search for Efficient Local Multi-Fidelity Bayesian Optimization</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Wei-Ting Tang, Joel A. Paulson
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Bayesian optimization (BO) is a popular approach for optimizing expensive-to-evaluate black-box objective functions. An important challenge in BO is its application to high-dimensional search spaces due in large part to the curse of dimensionality. One way to overcome this challenge is to focus on l</span>
                
                <span class="abstract-full" style="display: none;">Bayesian optimization (BO) is a popular approach for optimizing expensive-to-evaluate black-box objective functions. An important challenge in BO is its application to high-dimensional search spaces due in large part to the curse of dimensionality. One way to overcome this challenge is to focus on local BO methods that aim to efficiently learn gradients, which have shown strong empirical performance on high-dimensional problems including policy search in reinforcement learning (RL). Current local BO methods assume access to only a single high-fidelity information source whereas, in many problems, one has access to multiple cheaper approximations of the objective. We propose a novel algorithm, Cost-Aware Gradient Entropy Search (CAGES), for local BO of multi-fidelity black-box functions. CAGES makes no assumption about the relationship between different information sources, making it more flexible than other multi-fidelity methods. It also employs a new information-theoretic acquisition function, which enables systematic identification of samples that maximize the information gain about the unknown gradient per evaluation cost. We demonstrate CAGES can achieve significant performance improvements compared to other state-of-the-art methods on synthetic and benchmark RL problems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #31bb31" title="Confidence: 7.3%">
                            Bayesian Optimization
                        </span>
                <!-- Federated Learning: 3.3 -->
                    
                <!-- GNN: 2.9 -->
                    
                <!-- Evolutionary Algorithms: 2.6 -->
                    
                <!-- LLMs: 2.6 -->
                    
                <!-- Computer Vision: 1.9 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Reinforcement Learning: 1.8 -->
                    
                <!-- Networks: 1.7 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Hardware: 1.1 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Medicine: 1.0 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2157
                </span>
                <a href="https://arxiv.org/abs/2505.20021" target="_blank" rel="noopener noreferrer">Decomposing Complex Visual Comprehension into Atomic Visual Skills for Vision Language Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Hyunsik Chae, Seungwoo Yoon, Jaden Park, Chloe Yewon Chun, Yongin Cho, Mu Cai, Yong Jae Lee, Ernest K. Ryu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Recent Vision-Language Models (VLMs) have demonstrated impressive multimodal comprehension and reasoning capabilities, yet they often struggle with trivially simple visual tasks. In this work, we focus on the domain of basic 2D Euclidean geometry and systematically categorize the fundamental, indivi</span>
                
                <span class="abstract-full" style="display: none;">Recent Vision-Language Models (VLMs) have demonstrated impressive multimodal comprehension and reasoning capabilities, yet they often struggle with trivially simple visual tasks. In this work, we focus on the domain of basic 2D Euclidean geometry and systematically categorize the fundamental, indivisible visual perception skills, which we refer to as atomic visual skills. We then introduce the Atomic Visual Skills Dataset (AVSD) for evaluating VLMs on the atomic visual skills. Using AVSD, we benchmark state-of-the-art VLMs and find that they struggle with these tasks, despite being trivial for adult humans. Our findings highlight the need for purpose-built datasets to train and evaluate VLMs on atomic, rather than composite, visual perception tasks.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.6%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.3%">
                            Computer Vision
                        </span>
                <!-- Medicine: 4.3 -->
                    
                <!-- Hardware: 2.2 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- T2I: 1.1 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- 3D: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2128
                </span>
                <a href="https://arxiv.org/abs/2505.19850" target="_blank" rel="noopener noreferrer">DISCOVER: Automated Curricula for Sparse-Reward Reinforcement Learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Leander Diaz-Bone, Marco Bagatella, Jonas H\"ubotter, Andreas Krause
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Sparse-reward reinforcement learning (RL) can model a wide range of highly complex tasks. Solving sparse-reward tasks is RL's core premise - requiring efficient exploration coupled with long-horizon credit assignment - and overcoming these challenges is key for building self-improving agents with su</span>
                
                <span class="abstract-full" style="display: none;">Sparse-reward reinforcement learning (RL) can model a wide range of highly complex tasks. Solving sparse-reward tasks is RL's core premise - requiring efficient exploration coupled with long-horizon credit assignment - and overcoming these challenges is key for building self-improving agents with superhuman ability. We argue that solving complex and high-dimensional tasks requires solving simpler tasks that are relevant to the target task. In contrast, most prior work designs strategies for selecting exploratory tasks with the objective of solving any task, making exploration of challenging high-dimensional, long-horizon tasks intractable. We find that the sense of direction, necessary for effective exploration, can be extracted from existing RL algorithms, without needing any prior information. Based on this finding, we propose a method for directed sparse-reward goal-conditioned very long-horizon RL (DISCOVER), which selects exploratory goals in the direction of the target task. We connect DISCOVER to principled exploration in bandits, formally bounding the time until the target task becomes achievable in terms of the agent's initial distance to the target, but independent of the volume of the space of all tasks. Empirically, we perform a thorough evaluation in high-dimensional environments. We find that the directed goal selection of DISCOVER solves exploration problems that are beyond the reach of prior state-of-the-art exploration methods in RL.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #31bb31" title="Confidence: 5.1%">
                            Bayesian Optimization
                        </span>
                <!-- LLMs: 3.4 -->
                    
                <!-- Reinforcement Learning: 3.0 -->
                    
                <!-- Federated Learning: 2.9 -->
                    
                <!-- Medicine: 2.5 -->
                    
                <!-- Math: 2.3 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Game Theory: 1.2 -->
                    
                <!-- Hardware: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2008
                </span>
                <a href="https://arxiv.org/abs/2505.19841" target="_blank" rel="noopener noreferrer">Efficient Deconvolution in Populational Inverse Problems</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Arnaud Vadeboncoeur, Mark Girolami, Andrew M. Stuart
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This work is focussed on the inversion task of inferring the distribution over parameters of interest leading to multiple sets of observations. The potential to solve such distributional inversion problems is driven by increasing availability of data, but a major roadblock is blind deconvolution, ar</span>
                
                <span class="abstract-full" style="display: none;">This work is focussed on the inversion task of inferring the distribution over parameters of interest leading to multiple sets of observations. The potential to solve such distributional inversion problems is driven by increasing availability of data, but a major roadblock is blind deconvolution, arising when the observational noise distribution is unknown. However, when data originates from collections of physical systems, a population, it is possible to leverage this information to perform deconvolution. To this end, we propose a methodology leveraging large data sets of observations, collected from different instantiations of the same physical processes, to simultaneously deconvolve the data corrupting noise distribution, and to identify the distribution over model parameters defining the physical processes. A parameter-dependent mathematical model of the physical process is employed. A loss function characterizing the match between the observed data and the output of the mathematical model is defined; it is minimized as a function of the both the parameter inputs to the model of the physics and the parameterized observational noise. This coupled problem is addressed with a modified gradient descent algorithm that leverages specific structure in the noise model. Furthermore, a new active learning scheme is proposed, based on adaptive empirical measures, to train a surrogate model to be accurate in parameter regions of interest; this approach accelerates computation and enables automatic differentiation of black-box, potentially nondifferentiable, code computing parameter-to-solution maps. The proposed methodology is demonstrated on porous medium flow, damped elastodynamics, and simplified models of atmospheric dynamics.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #b3ebae" title="Confidence: 6.7%">
                            Federated Learning
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #31bb31" title="Confidence: 5.7%">
                            Bayesian Optimization
                        </span>
                <!-- Evolutionary Algorithms: 2.5 -->
                    
                <!-- Medicine: 2.1 -->
                    
                <!-- Reinforcement Learning: 2.0 -->
                    
                <!-- Networks: 1.6 -->
                    
                <!-- Robotics: 1.6 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Math: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Hardware: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.1966
                </span>
                <a href="https://arxiv.org/abs/2307.12179" target="_blank" rel="noopener noreferrer">Leveraging Knowledge Graphs for Zero-Shot Object-agnostic State Classification</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Filipos Gouidis, Theodore Patkos, Antonis Argyros, Dimitris Plexousakis
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We investigate the problem of Object State Classification (OSC) as a zero-shot learning problem. Specifically, we propose the first Object-agnostic State Classification (OaSC) method that infers the state of a certain object without relying on the knowledge or the estimation of the object class. In </span>
                
                <span class="abstract-full" style="display: none;">We investigate the problem of Object State Classification (OSC) as a zero-shot learning problem. Specifically, we propose the first Object-agnostic State Classification (OaSC) method that infers the state of a certain object without relying on the knowledge or the estimation of the object class. In that direction, we capitalize on Knowledge Graphs (KGs) for structuring and organizing knowledge, which, in combination with visual information, enable the inference of the states of objects in object/state pairs that have not been encountered in the method's training set. A series of experiments investigate the performance of the proposed method in various settings, against several hypotheses and in comparison with state of the art approaches for object attribute classification. The experimental results demonstrate that the knowledge of an object class is not decisive for the prediction of its state. Moreover, the proposed OaSC method outperforms existing methods in all datasets and benchmarks by a great margin.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #31bb31" title="Confidence: 5.1%">
                            Bayesian Optimization
                        </span>
                <!-- Federated Learning: 3.8 -->
                    
                <!-- Medicine: 2.6 -->
                    
                <!-- Computer Vision: 2.5 -->
                    
                <!-- Reinforcement Learning: 2.5 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Math: 1.8 -->
                    
                <!-- LLMs: 1.7 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.0157
                </span>
                <a href="https://arxiv.org/abs/2505.19737" target="_blank" rel="noopener noreferrer">Weighted Leave-One-Out Cross Validation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Luc Pronzato (RT-UQ), Maria-Jo\~ao Rendas
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We present a weighted version of Leave-One-Out (LOO) cross-validation for estimating the Integrated Squared Error (ISE) when approximating an unknown function by a predictor that depends linearly on evaluations of the function over a finite collection of sites. The method relies on the construction </span>
                
                <span class="abstract-full" style="display: none;">We present a weighted version of Leave-One-Out (LOO) cross-validation for estimating the Integrated Squared Error (ISE) when approximating an unknown function by a predictor that depends linearly on evaluations of the function over a finite collection of sites. The method relies on the construction of the best linear estimator of the squared prediction error at an arbitrary unsampled site based on squared LOO residuals, assuming that the function is a realization of a Gaussian Process (GP). A theoretical analysis of performance of the ISE estimator is presented, and robustness with respect to the choice of the GP kernel is investigated first analytically, then through numerical examples. Overall, the estimation of ISE is significantly more precise than with classical, unweighted, LOO cross validation. Application to model selection is briefly considered through examples.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #31bb31" title="Confidence: 6.3%">
                            Bayesian Optimization
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #a49950" title="Confidence: 5.9%">
                            Math
                        </span>
                <!-- Federated Learning: 3.4 -->
                    
                <!-- Networks: 2.5 -->
                    
                <!-- Medicine: 2.4 -->
                    
                <!-- Evolutionary Algorithms: 2.3 -->
                    
                <!-- Cryptography: 2.1 -->
                    
                <!-- Reinforcement Learning: 1.8 -->
                    
                <!-- Finance: 1.5 -->
                    
                <!-- Game Theory: 1.2 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- LLMs: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18793" target="_blank" rel="noopener noreferrer">Genie Centurion: Accelerating Scalable Real-World Robot Training with Human Rewind-and-Refine Guidance</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Wenhao Wang, Jianheng Song, Chiming Liu, Jiayao Ma, Siyuan Feng, Jingyuan Wang, Yuxin Jiang, Kylin Chen, Sikang Zhan, Yi Wang, Tong Meng, Modi Shi, Xindong He, Guanghui Ren, Yang Yang, Maoqing Yao
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">While Vision-Language-Action (VLA) models show strong generalizability in various tasks, real-world deployment of robotic policy still requires large-scale, high-quality human expert demonstrations. However, passive data collection via human teleoperation is costly, hard to scale, and often biased t</span>
                
                <span class="abstract-full" style="display: none;">While Vision-Language-Action (VLA) models show strong generalizability in various tasks, real-world deployment of robotic policy still requires large-scale, high-quality human expert demonstrations. However, passive data collection via human teleoperation is costly, hard to scale, and often biased toward passive demonstrations with limited diversity. To address this, we propose Genie Centurion (GCENT), a scalable and general data collection paradigm based on human rewind-and-refine guidance. When the robot execution failures occur, GCENT enables the system revert to a previous state with a rewind mechanism, after which a teleoperator provides corrective demonstrations to refine the policy. This framework supports a one-human-to-many-robots supervision scheme with a Task Sentinel module, which autonomously predicts task success and solicits human intervention when necessary, enabling scalable supervision. Empirical results show that GCENT achieves up to 40% higher task success rates than state-of-the-art data collection methods, and reaches comparable performance using less than half the data. We also quantify the data yield-to-effort ratio under multi-robot scenarios, demonstrating GCENT's potential for scalable and cost-efficient robot policy training in real-world environments.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.1 -->
                    
                <!-- LLMs: 3.9 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- GNN: 2.1 -->
                    
                <!-- Computer Vision: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Networks: 1.3 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18798" target="_blank" rel="noopener noreferrer">Governing Equation Discovery from Data Based on Differential Invariants</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Lexiang Hu, Yikang Li, Zhouchen Lin
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The explicit governing equation is one of the simplest and most intuitive forms for characterizing physical laws. However, directly discovering partial differential equations (PDEs) from data poses significant challenges, primarily in determining relevant terms from a vast search space. Symmetry, as</span>
                
                <span class="abstract-full" style="display: none;">The explicit governing equation is one of the simplest and most intuitive forms for characterizing physical laws. However, directly discovering partial differential equations (PDEs) from data poses significant challenges, primarily in determining relevant terms from a vast search space. Symmetry, as a crucial prior knowledge in scientific fields, has been widely applied in tasks such as designing equivariant networks and guiding neural PDE solvers. In this paper, we propose a pipeline for governing equation discovery based on differential invariants, which can losslessly reduce the search space of existing equation discovery methods while strictly adhering to symmetry. Specifically, we compute the set of differential invariants corresponding to the infinitesimal generators of the symmetry group and select them as the relevant terms for equation discovery. Taking DI-SINDy (SINDy based on Differential Invariants) as an example, we demonstrate that its success rate and accuracy in PDE discovery surpass those of other symmetry-informed governing equation discovery methods across a series of PDEs.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 3.6 -->
                    
                <!-- Federated Learning: 2.6 -->
                    
                <!-- Medicine: 2.6 -->
                    
                <!-- Hardware: 2.4 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18806" target="_blank" rel="noopener noreferrer">Mal-D2GAN: Double-Detector based GAN for Malware Generation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Nam Hoang Thanh, Trung Pham Duy, Lam Bui Thu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Machine learning (ML) has been developed to detect malware in recent years. Most researchers focused their efforts on improving the detection performance but ignored the robustness of the ML models. In addition, many machine learning algorithms are very vulnerable to intentional attacks. To solve th</span>
                
                <span class="abstract-full" style="display: none;">Machine learning (ML) has been developed to detect malware in recent years. Most researchers focused their efforts on improving the detection performance but ignored the robustness of the ML models. In addition, many machine learning algorithms are very vulnerable to intentional attacks. To solve these problems, adversarial malware examples are generated by GANs to enhance the robustness of the malware detector. However, since current GAN models suffer from limitations such as unstable training and weak adversarial examples, we propose the Mal-D2GAN model to address these problems. Specifically, the Mal-D2GAN architecture was designed with double-detector and a least square loss function and tested on a dataset of 20,000 samples. The results show that the Mal-D2GAN model reduced the detection accuracy (true positive rate) in 8 malware detectors. The performance was then compared with that of the existing MalGAN and Mal- LSGAN models.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 3.6 -->
                    
                <!-- Computer Vision: 3.1 -->
                    
                <!-- Medicine: 3.1 -->
                    
                <!-- LLMs: 2.1 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Bayesian Optimization: 1.7 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18810" target="_blank" rel="noopener noreferrer">Discrete gradient methods for port-Hamiltonian differential-algebraic equations</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Philipp L. Kinon, Riccardo Morandin, Philipp Schulze
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Discrete gradient methods are a powerful tool for the time discretization of dynamical systems, since they are structure-preserving regardless of the form of the total energy. In this work, we discuss the application of discrete gradient methods to the system class of nonlinear port-Hamiltonian diff</span>
                
                <span class="abstract-full" style="display: none;">Discrete gradient methods are a powerful tool for the time discretization of dynamical systems, since they are structure-preserving regardless of the form of the total energy. In this work, we discuss the application of discrete gradient methods to the system class of nonlinear port-Hamiltonian differential-algebraic equations - as they emerge from the port- and energy-based modeling of physical systems in various domains. We introduce a novel numerical scheme tailored for semi-explicit differential-algebraic equations and further address more general settings using the concepts of discrete gradient pairs and Dirac-dissipative structures. Additionally, the behavior under system transformations is investigated and we demonstrate that under suitable assumptions port-Hamiltonian differential-algebraic equations admit a representation which consists of a parametrized port-Hamiltonian semi-explicit system and an unstructured equation. Finally, we present the application to multibody system dynamics and discuss numerical results to demonstrate the capabilities of our approach.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 5.0 -->
                    
                <!-- LLMs: 3.2 -->
                    
                <!-- Federated Learning: 3.0 -->
                    
                <!-- Bayesian Optimization: 2.2 -->
                    
                <!-- Reinforcement Learning: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- GNN: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18818" target="_blank" rel="noopener noreferrer">Automated Verification of Monotonic Data Structure Traversals in C</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Matthew Sotoudeh
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Bespoke data structure operations are common in real-world C code. We identify one common subclass, monotonic data structure traversals (MDSTs), that iterate monotonically through the structure. For example, strlen iterates from start to end of a character array until a null byte is found, and a bin</span>
                
                <span class="abstract-full" style="display: none;">Bespoke data structure operations are common in real-world C code. We identify one common subclass, monotonic data structure traversals (MDSTs), that iterate monotonically through the structure. For example, strlen iterates from start to end of a character array until a null byte is found, and a binary search tree insert iterates from the tree root towards a leaf. We describe a new automated verification tool, Shrinker, to verify MDSTs written in C. Shrinker uses a new program analysis strategy called scapegoating size descent, which is designed to take advantage of the fact that many MDSTs produce very similar traces when executed on an input (e.g., some large list) as when executed on a 'shrunk' version of the input (e.g., the same list but with its first element deleted). We introduce a new benchmark set containing over one hundred instances proving correctness, equivalence, and memory safety properties of dozens of MDSTs found in major C codebases including Linux, NetBSD, OpenBSD, QEMU, Git, and Musl. Shrinker significantly increases the number of monotonic string and list traversals that can be verified vs. a portfolio of state-of-the-art tools.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 3.9 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- Networks: 2.0 -->
                    
                <!-- Medicine: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- Bayesian Optimization: 1.6 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Cryptography: 1.3 -->
                    
                <!-- Math: 1.3 -->
                    
                <!-- Game Theory: 1.3 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18824" target="_blank" rel="noopener noreferrer">FlatAttention: Dataflow and Fabric Collectives Co-Optimization for Efficient Multi-Head Attention on Tile-Based Many-PE Accelerators</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Chi Zhang, Luca Colagrande, Renzo Andri, Thomas Benz, Gamze Islamoglu, Alessandro Nadalini, Francesco Conti, Yawei Li, Luca Benini
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Multi-Head Attention (MHA) is a critical computational kernel in transformer-based AI models. Emerging scalable tile-based accelerator architectures integrate increasing numbers of tightly-packed processing elements (PEs) with tensor units. MHA dataflow mapping is crucial for achieving high utilizat</span>
                
                <span class="abstract-full" style="display: none;">Multi-Head Attention (MHA) is a critical computational kernel in transformer-based AI models. Emerging scalable tile-based accelerator architectures integrate increasing numbers of tightly-packed processing elements (PEs) with tensor units. MHA dataflow mapping is crucial for achieving high utilization of the available units. We propose FlatAttention, a new dataflow for MHA on tile-based many-PE accelerators, minimizing costly main memory (HBM) accesses by leveraging collective primitives integrated into the on-chip network fabric. FlatAttention achieves up to 89.3% utilization, and 4.1x performance speedup over FlashAttention-3 dataflow on tile-based accelerators whilst reducing HBM traffic by 16x. Through algorithm-architecture co-exploration, we identify an optimal configuration for a large scaled-out tile-based accelerator featuring a 32x32 tile mesh with 1024 TFLOPS @ FP16 peak performance, comparable to the state-of-the-art Nvidia H100 GPU. FlatAttention in this configuration achieves up to 1.3x higher utilization over FlashAttention-3 on the H100 GPU. Meanwhile, this tile-based accelerator configuration requires 40% less HBM bandwidth compared to the H100, enabling a 1.8x reduction in die size, estimated on the same technology node.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Hardware: 2.6 -->
                    
                <!-- Medicine: 2.5 -->
                    
                <!-- Computer Vision: 2.5 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- LLMs: 2.0 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Networks: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- Cryptography: 1.2 -->
                    
                <!-- 3D: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18825" target="_blank" rel="noopener noreferrer">How to build a consistency model: Learning flow maps via self-distillation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Nicholas M. Boffi, Michael S. Albergo, Eric Vanden-Eijnden
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Building on the framework proposed in Boffi et al. (2024), we present a systematic approach for learning flow maps associated with flow and diffusion models. Flow map-based models, commonly known as consistency models, encompass recent efforts to improve the efficiency of generative models based on </span>
                
                <span class="abstract-full" style="display: none;">Building on the framework proposed in Boffi et al. (2024), we present a systematic approach for learning flow maps associated with flow and diffusion models. Flow map-based models, commonly known as consistency models, encompass recent efforts to improve the efficiency of generative models based on solutions to differential equations. By exploiting a relationship between the velocity field underlying a continuous-time flow and the instantaneous rate of change of the flow map, we show how to convert existing distillation schemes into direct training algorithms via self-distillation, eliminating the need for pre-trained models. We empirically evaluate several instantiations of our framework, finding that high-dimensional tasks like image synthesis benefit from objective functions that avoid temporal and spatial derivatives of the flow map, while lower-dimensional tasks can benefit from objectives incorporating higher-order derivatives to capture sharp features.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 3.5 -->
                    
                <!-- LLMs: 3.1 -->
                    
                <!-- Evolutionary Algorithms: 2.4 -->
                    
                <!-- Medicine: 2.4 -->
                    
                <!-- Reinforcement Learning: 2.1 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Bayesian Optimization: 1.7 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Networks: 1.1 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18828" target="_blank" rel="noopener noreferrer">Improved Regret and Contextual Linear Extension for Pandora's Box and Prophet Inequality</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Junyan Liu, Ziyun Chen, Kun Wang, Haipeng Luo, Lillian J. Ratliff
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We study the Pandora's Box problem in an online learning setting with semi-bandit feedback. In each round, the learner sequentially pays to open up to $n$ boxes with unknown reward distributions, observes rewards upon opening, and decides when to stop. The utility of the learner is the maximum obser</span>
                
                <span class="abstract-full" style="display: none;">We study the Pandora's Box problem in an online learning setting with semi-bandit feedback. In each round, the learner sequentially pays to open up to $n$ boxes with unknown reward distributions, observes rewards upon opening, and decides when to stop. The utility of the learner is the maximum observed reward minus the cumulative cost of opened boxes, and the goal is to minimize regret defined as the gap between the cumulative expected utility and that of the optimal policy. We propose a new algorithm that achieves $\widetilde{O}(\sqrt{nT})$ regret after $T$ rounds, which improves the $\widetilde{O}(n\sqrt{T})$ bound of Agarwal et al. [2024] and matches the known lower bound up to logarithmic factors. To better capture real-life applications, we then extend our results to a natural but challenging contextual linear setting, where each box's expected reward is linear in some known but time-varying $d$-dimensional context and the noise distribution is fixed over time. We design an algorithm that learns both the linear function and the noise distributions, achieving $\widetilde{O}(nd\sqrt{T})$ regret. Finally, we show that our techniques also apply to the online Prophet Inequality problem, where the learner must decide immediately whether or not to accept a revealed reward. In both non-contextual and contextual settings, our approach achieves similar improvements and regret bounds.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Reinforcement Learning: 3.9 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- LLMs: 2.2 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- Medicine: 1.4 -->
                    
                <!-- Networks: 1.3 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- Math: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18836" target="_blank" rel="noopener noreferrer">Distributed Incremental SAT Solving with Mallob: Report and Case Study with Hierarchical Planning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Dominik Schreiber
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This report describes an extension of the distributed job scheduling and SAT solving platform Mallob by incremental SAT solving, embedded in a case study on SAT-based hierarchical planning. We introduce a low-latency interface for incremental jobs and specifically for IPASIR-style incremental SAT so</span>
                
                <span class="abstract-full" style="display: none;">This report describes an extension of the distributed job scheduling and SAT solving platform Mallob by incremental SAT solving, embedded in a case study on SAT-based hierarchical planning. We introduce a low-latency interface for incremental jobs and specifically for IPASIR-style incremental SAT solving to Mallob. This also allows to process many independent planning instances in parallel via Mallob's scheduling capabilities. In an experiment where 587 planning inputs are resolved in parallel on 2348 cores, we observe significant speedups for several planning domains where SAT solving constitutes a major part of the planner's running time. These findings indicate that our approach to distributed incremental SAT solving may be useful for a wide range of SAT applications.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.7 -->
                    
                <!-- Medicine: 3.0 -->
                    
                <!-- Evolutionary Algorithms: 2.2 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Networks: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Game Theory: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18838" target="_blank" rel="noopener noreferrer">Unconditionally Stable Mixed Finite Element Methods for Darcy Flow</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Maicon R. Correa, Abimael F. D. Loula
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Unconditionally stable finite element methods for Darcy flow are derived by adding least-squares residual forms of the governing equations to the classical mixed formulations. The proposed methods are free of mesh dependent stabilization parameters and allow the use of the classical continuous Lagra</span>
                
                <span class="abstract-full" style="display: none;">Unconditionally stable finite element methods for Darcy flow are derived by adding least-squares residual forms of the governing equations to the classical mixed formulations. The proposed methods are free of mesh dependent stabilization parameters and allow the use of the classical continuous Lagrangian finite element spaces of any order for the velocity and the potential. Stability, convergence and error estimates are derived and numerical experiments are presented to demonstrate the flexibility of the proposed finite element formulations and to confirm the predicted rates of convergence.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 3.3 -->
                    
                <!-- Hardware: 3.0 -->
                    
                <!-- Bayesian Optimization: 2.7 -->
                    
                <!-- Federated Learning: 2.6 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- Math: 1.6 -->
                    
                <!-- LLMs: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18839" target="_blank" rel="noopener noreferrer">DNF Learning via Locally Mixing Random Walks</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Josh Alman, Shivam Nadimpalli, Shyamal Patel, Rocco A. Servedio
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We give two results on PAC learning DNF formulas using membership queries in the challenging "distribution-free" learning framework, where learning algorithms must succeed for an arbitrary and unknown distribution over $\{0,1\}^n$.</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.1 -->
                    
                <!-- LLMs: 3.3 -->
                    
                <!-- Quantum Computing: 2.5 -->
                    
                <!-- HPO and AutoML: 2.3 -->
                    
                <!-- Blockchain: 2.1 -->
                    
                <!-- GNN: 2.1 -->
                    
                <!-- Computer Vision: 2.0 -->
                    
                <!-- Decision Trees: 2.0 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Game Theory: 1.1 -->
                    
                <!-- Cryptography: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Networks: 1.1 -->
                    
                <!-- Datasets: 1.0 -->
                    
                <!-- RAG: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18850" target="_blank" rel="noopener noreferrer">The Theory of the Unique Latent Pattern: A Formal Epistemic Framework for Structural Singularity in Complex Systems</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Mohamed Aly Bouke
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper introduces the Theory of the Unique Latent Pattern (ULP), a formal epistemic framework that redefines the origin of apparent complexity in dynamic systems. Rather than attributing unpredictability to intrinsic randomness or emergent nonlinearity, ULP asserts that every analyzable system i</span>
                
                <span class="abstract-full" style="display: none;">This paper introduces the Theory of the Unique Latent Pattern (ULP), a formal epistemic framework that redefines the origin of apparent complexity in dynamic systems. Rather than attributing unpredictability to intrinsic randomness or emergent nonlinearity, ULP asserts that every analyzable system is governed by a structurally unique, deterministic generative mechanism, one that remains hidden not due to ontological indeterminacy, but due to epistemic constraints. The theory is formalized using a non-universal generative mapping \( \mathcal{F}_S(P_S, t) \), where each system \( S \) possesses its own latent structure \( P_S \), irreducible and non-replicable across systems. Observed irregularities are modeled as projections of this generative map through observer-limited interfaces, introducing epistemic noise \( \varepsilon_S(t) \) as a measure of incomplete access. By shifting the locus of uncertainty from the system to the observer, ULP reframes chaos as a context-relative failure of representation. We contrast this position with foundational paradigms in chaos theory, complexity science, and statistical learning. While they assume or model shared randomness or collective emergence, ULP maintains that every instance harbors a singular structural identity. Although conceptual, the theory satisfies the criterion of falsifiability in the Popperian sense, it invites empirical challenge by asserting that no two systems governed by distinct latent mechanisms will remain indistinguishable under sufficient resolution. This opens avenues for structurally individuated models in AI, behavioral inference, and epistemic diagnostics.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 3.2 -->
                    
                <!-- Medicine: 2.0 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Bayesian Optimization: 1.9 -->
                    
                <!-- Networks: 1.8 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Game Theory: 1.7 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Cryptography: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Math: 1.4 -->
                    
                <!-- Finance: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Datasets: 1.0 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                <!-- Hardware: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18854" target="_blank" rel="noopener noreferrer">Three-Dimensional Nonlinear Guidance with Impact Time and Field-of-view Constraints</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ashok R Samrat, Swati Singh, Shashi Ranjan Kumar
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper addresses the time-constrained interception of targets at a predetermined time with bounded field-of-view capability of the seeker-equipped interceptors. We propose guidance laws using the effective lead angle and velocity lead angles of the interceptor to achieve a successful interceptio</span>
                
                <span class="abstract-full" style="display: none;">This paper addresses the time-constrained interception of targets at a predetermined time with bounded field-of-view capability of the seeker-equipped interceptors. We propose guidance laws using the effective lead angle and velocity lead angles of the interceptor to achieve a successful interception of the target. The former scheme extends the existing two-dimensional guidance strategy to a three-dimensional setting. We have shown that such an extension may result in high-frequency switching in the input demand, which may degrade the interceptor's performance. To overcome the potential limitations of such a guidance strategy, we propose an elegant solution using the velocity lead angles and the range error with a backstepping technique. Using the velocity lead angles as virtual inputs, the effective lead angle profile is subsequently regulated to satisfy the seeker's field-of-view bound. Unlike the existing strategies, the proposed guidance strategy does not rely on the time-to-go estimate, which is an appealing feature of the design, as the time-to-go estimate may not always be available with high precision. We provide a theoretical analysis of the error variable and subsequently analytically derive the bounds on achievable impact times. Numerical simulations are performed to support the theoretical findings. The performance of the proposed guidance strategy is compared with that of an existing one, and it has been shown to yield better performance. Finally, a study on different choices of virtual inputs is also provided.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Math: 3.8 -->
                    
                <!-- Networks: 3.7 -->
                    
                <!-- Reinforcement Learning: 3.4 -->
                    
                <!-- Federated Learning: 2.9 -->
                    
                <!-- Cryptography: 2.8 -->
                    
                <!-- Finance: 2.0 -->
                    
                <!-- Bayesian Optimization: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Game Theory: 1.3 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Medicine: 1.1 -->
                    
                <!-- Pathfinding: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18857" target="_blank" rel="noopener noreferrer">Hierarchical-embedding autoencoder with a predictor (HEAP) as efficient architecture for learning long-term evolution of complex multi-scale physical systems</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Alexander Khrabry, Edward Startsev, Andrew Powis, Igor Kaganovich
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We propose a novel efficient architecture for learning long-term evolution in complex multi-scale physical systems which is based on the idea of separation of scales. Structures of various scales that dynamically emerge in the system interact with each other only locally. Structures of similar scale</span>
                
                <span class="abstract-full" style="display: none;">We propose a novel efficient architecture for learning long-term evolution in complex multi-scale physical systems which is based on the idea of separation of scales. Structures of various scales that dynamically emerge in the system interact with each other only locally. Structures of similar scale can interact directly when they are in contact and indirectly when they are parts of larger structures that interact directly. This enables modeling a multi-scale system in an efficient way, where interactions between small-scale features that are apart from each other do not need to be modeled. The hierarchical fully-convolutional autoencoder transforms the state of a physical system not just into a single embedding layer, as it is done conventionally, but into a series of embedding layers which encode structures of various scales preserving spatial information at a corresponding resolution level. Shallower layers embed smaller structures on a finer grid, while deeper layers embed larger structures on a coarser grid. The predictor advances all embedding layers in sync. Interactions between features of various scales are modeled using a combination of convolutional operators. We compare the performance of our model to variations of a conventional ResNet architecture in application to the Hasegawa-Wakatani turbulence. A multifold improvement in long-term prediction accuracy was observed for crucial statistical characteristics of this system.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 3.3 -->
                    
                <!-- Federated Learning: 3.2 -->
                    
                <!-- Evolutionary Algorithms: 2.9 -->
                    
                <!-- LLMs: 2.3 -->
                    
                <!-- Bayesian Optimization: 2.2 -->
                    
                <!-- Reinforcement Learning: 2.0 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Networks: 1.8 -->
                    
                <!-- Game Theory: 1.7 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Math: 1.3 -->
                    
                <!-- Hardware: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18861" target="_blank" rel="noopener noreferrer">Securing Credit Inquiries: The Role of Real-Time User Approval in Preventing SSN Identity Theft</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Gogulakrishnan Thiyagarajan, Vinay Bist, Prabhudarshi Nayak
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Unauthorized credit inquiries are also a central entry point for identity theft, with Social Security Numbers (SSNs) being widely utilized in fraudulent cases. Traditional credit inquiry systems do not usually possess strict user authentication, making them vulnerable to unauthorized access. This pa</span>
                
                <span class="abstract-full" style="display: none;">Unauthorized credit inquiries are also a central entry point for identity theft, with Social Security Numbers (SSNs) being widely utilized in fraudulent cases. Traditional credit inquiry systems do not usually possess strict user authentication, making them vulnerable to unauthorized access. This paper proposes a real-time user authorization system to enhance security by enforcing explicit user approval before processing any credit inquiry. The system employs real-time verification and approval techniques. This ensures that the authorized user only approves or rejects a credit check request. It minimizes the risks of interference by third parties. Apart from enhancing security, this system complies with regulations like the General Data Protection Regulation (GDPR) and the Fair Credit Reporting Act (FCRA) while maintaining a seamless user experience. This article discusses the technical issues, scaling-up issues, and ways of implementing real-time user authorization in financial systems. Through this framework, financial institutions can drastically minimize the risk of identity theft, avert unauthorized credit checks, and increase customer trust in the credit verification system.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.5 -->
                    
                <!-- Medicine: 3.2 -->
                    
                <!-- Blockchain: 2.2 -->
                    
                <!-- Networks: 2.2 -->
                    
                <!-- Cryptography: 1.9 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Game Theory: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Finance: 1.2 -->
                    
                <!-- Math: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18872" target="_blank" rel="noopener noreferrer">Zero Trust Cybersecurity: Procedures and Considerations in Context</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Brady D. Lund, Tae Hee Lee, Ziang Wang, Ting Wang, Nishith Reddy Mannuru
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In response to the increasing complexity and sophistication of cyber threats, particularly those enhanced by advancements in artificial intelligence, traditional security methods are proving insufficient. This paper explores the Zero Trust cybersecurity framework, which operates on the principle of </span>
                
                <span class="abstract-full" style="display: none;">In response to the increasing complexity and sophistication of cyber threats, particularly those enhanced by advancements in artificial intelligence, traditional security methods are proving insufficient. This paper explores the Zero Trust cybersecurity framework, which operates on the principle of never trust, always verify to mitigate vulnerabilities within organizations. Specifically, it examines the applicability of Zero Trust principles in environments where large volumes of information are exchanged, such as schools and libraries. The discussion highlights the importance of continuous authentication, least privilege access, and breach assumption. The findings underscore avenues for future research that may help preserve the security of these vulnerable organizations.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.8 -->
                    
                <!-- Blockchain: 4.0 -->
                    
                <!-- Medicine: 2.7 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Quantum Computing: 2.0 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.4 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Math: 1.2 -->
                    
                <!-- Game Theory: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18876" target="_blank" rel="noopener noreferrer">DiffusionRL: Efficient Training of Diffusion Policies for Robotic Grasping Using RL-Adapted Large-Scale Datasets</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Maria Makarova, Qian Liu, Dzmitry Tsetserukou
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Diffusion models have been successfully applied in areas such as image, video, and audio generation. Recent works show their promise for sequential decision-making and dexterous manipulation, leveraging their ability to model complex action distributions. However, challenges persist due to the data </span>
                
                <span class="abstract-full" style="display: none;">Diffusion models have been successfully applied in areas such as image, video, and audio generation. Recent works show their promise for sequential decision-making and dexterous manipulation, leveraging their ability to model complex action distributions. However, challenges persist due to the data limitations and scenario-specific adaptation needs. In this paper, we address these challenges by proposing an optimized approach to training diffusion policies using large, pre-built datasets that are enhanced using Reinforcement Learning (RL). Our end-to-end pipeline leverages RL-based enhancement of the DexGraspNet dataset, lightweight diffusion policy training on a dexterous manipulation task for a five-fingered robotic hand, and a pose sampling algorithm for validation. The pipeline achieved a high success rate of 80% for three DexGraspNet objects. By eliminating manual data collection, our approach lowers barriers to adopting diffusion models in robotics, enhancing generalization and robustness for real-world applications.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.7 -->
                    
                <!-- Medicine: 4.5 -->
                    
                <!-- Hardware: 2.4 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- T2I: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18879" target="_blank" rel="noopener noreferrer">Efficient Online Random Sampling via Randomness Recycling</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Thomas L. Draper, Feras A. Saad
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">``Randomness recycling'' is a powerful algorithmic technique for reusing a fraction of the random information consumed by a randomized algorithm to reduce its entropy requirements. This article presents a family of efficient randomness recycling algorithms for sampling a sequence $X_1, X_2, X_3, \do</span>
                
                <span class="abstract-full" style="display: none;">``Randomness recycling'' is a powerful algorithmic technique for reusing a fraction of the random information consumed by a randomized algorithm to reduce its entropy requirements. This article presents a family of efficient randomness recycling algorithms for sampling a sequence $X_1, X_2, X_3, \dots$ of discrete random variables whose joint distribution follows an arbitrary stochastic process. We develop randomness recycling strategies to reduce the entropy cost of a variety of prominent sampling algorithms, which include uniform sampling, inverse transform sampling, lookup table sampling, alias sampling, and discrete distribution generating (DDG) tree sampling. Our method achieves an expected amortized entropy cost of $H(X_1,\dots,X_k)/k + \varepsilon$ input random bits per output sample using $O(\log(1/\varepsilon))$ space, which is arbitrarily close to the optimal Shannon entropy rate. The combination of space, time, and entropy properties of our method improve upon the Han and Hoshi interval algorithm and Knuth and Yao entropy-optimal algorithm for sampling a discrete random sequence. An empirical evaluation of the algorithm shows that it achieves state-of-the-art runtime performance on the Fisher-Yates shuffle when using a cryptographically secure pseudorandom number generator. Accompanying the manuscript is a performant random sampling library in the C programming language.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Evolutionary Algorithms: 3.2 -->
                    
                <!-- Federated Learning: 3.2 -->
                    
                <!-- Medicine: 2.6 -->
                    
                <!-- Networks: 2.5 -->
                    
                <!-- LLMs: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- Math: 1.6 -->
                    
                <!-- Bayesian Optimization: 1.6 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Finance: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Cryptography: 1.2 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                <!-- Datasets: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18884" target="_blank" rel="noopener noreferrer">LORE: Lagrangian-Optimized Robust Embeddings for Visual Encoders</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Borna Khodabandeh, Amirabbas Afzali, Amirhossein Afsharrad, Seyed Shahabeddin Mousavi, Sanjay Lall, Sajjad Amini, Seyed-Mohsen Moosavi-Dezfooli
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Visual encoders have become fundamental components in modern computer vision pipelines. However, ensuring robustness against adversarial perturbations remains a critical challenge. Recent efforts have explored both supervised and unsupervised adversarial fine-tuning strategies. We identify two key l</span>
                
                <span class="abstract-full" style="display: none;">Visual encoders have become fundamental components in modern computer vision pipelines. However, ensuring robustness against adversarial perturbations remains a critical challenge. Recent efforts have explored both supervised and unsupervised adversarial fine-tuning strategies. We identify two key limitations in these approaches: (i) they often suffer from instability, especially during the early stages of fine-tuning, resulting in suboptimal convergence and degraded performance on clean data, and (ii) they exhibit a suboptimal trade-off between robustness and clean data accuracy, hindering the simultaneous optimization of both objectives. To overcome these challenges, we propose Lagrangian-Optimized Robust Embeddings (LORE), a novel unsupervised adversarial fine-tuning framework. LORE utilizes constrained optimization, which offers a principled approach to balancing competing goals, such as improving robustness while preserving nominal performance. By enforcing embedding-space proximity constraints, LORE effectively maintains clean data performance throughout adversarial fine-tuning. Extensive experiments show that LORE significantly improves zero-shot adversarial robustness with minimal degradation in clean data accuracy. Furthermore, we demonstrate the effectiveness of the adversarially fine-tuned CLIP image encoder in out-of-distribution generalization and enhancing the interpretability of image embeddings.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.8 -->
                    
                <!-- Medicine: 2.7 -->
                    
                <!-- Blockchain: 2.5 -->
                    
                <!-- Computer Vision: 2.4 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18885" target="_blank" rel="noopener noreferrer">The Parameterized Complexity of Computing the Linear Vertex Arboricity</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Alexander Erhardt, Alexander Wolff
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The \emph{linear vertex arboricity} of a graph is the smallest number of sets into which the vertices of a graph can be partitioned so that each of these sets induces a linear forest. Chaplick et al. [JoCG 2020] showed that, somewhat surprisingly, the linear vertex arboricity of a graph is the same </span>
                
                <span class="abstract-full" style="display: none;">The \emph{linear vertex arboricity} of a graph is the smallest number of sets into which the vertices of a graph can be partitioned so that each of these sets induces a linear forest. Chaplick et al. [JoCG 2020] showed that, somewhat surprisingly, the linear vertex arboricity of a graph is the same as the \emph{3D weak line cover number} of the graph, that is, the minimum number of straight lines necessary to cover the vertices of a crossing-free straight-line drawing of the graph in $\mathbb{R}^3$. Chaplick et al. [JGAA 2023] showed that deciding whether a given graph has linear vertex arboricity 2 is NP-hard.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Math: 4.3 -->
                    
                <!-- Networks: 3.9 -->
                    
                <!-- Cryptography: 3.0 -->
                    
                <!-- Bayesian Optimization: 2.8 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- GNN: 2.2 -->
                    
                <!-- Game Theory: 2.0 -->
                    
                <!-- Pathfinding: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Finance: 1.5 -->
                    
                <!-- Medicine: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- LLMs: 1.3 -->
                    
                <!-- Hardware: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18892" target="_blank" rel="noopener noreferrer">Climate Implications of Diffusion-based Generative Visual AI Systems and their Mass Adoption</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Vanessa Utz, Steve DiPaola
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Climate implications of rapidly developing digital technologies, such as blockchains and the associated crypto mining and NFT minting, have been well documented and their massive GPU energy use has been identified as a cause for concern. However, we postulate that due to their more mainstream consum</span>
                
                <span class="abstract-full" style="display: none;">Climate implications of rapidly developing digital technologies, such as blockchains and the associated crypto mining and NFT minting, have been well documented and their massive GPU energy use has been identified as a cause for concern. However, we postulate that due to their more mainstream consumer appeal, the GPU use of text-prompt based diffusion AI art systems also requires thoughtful considerations. Given the recent explosion in the number of highly sophisticated generative art systems and their rapid adoption by consumers and creative professionals, the impact of these systems on the climate needs to be carefully considered. In this work, we report on the growth of diffusion-based visual AI systems, their patterns of use, growth and the implications on the climate. Our estimates show that the mass adoption of these tools potentially contributes considerably to global energy consumption. We end this paper with our thoughts on solutions and future areas of inquiry as well as associated difficulties, including the lack of publicly available data.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 4.5 -->
                    
                <!-- LLMs: 3.8 -->
                    
                <!-- Blockchain: 3.3 -->
                    
                <!-- Hardware: 2.8 -->
                    
                <!-- Evolutionary Algorithms: 2.7 -->
                    
                <!-- Medicine: 2.3 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18894" target="_blank" rel="noopener noreferrer">Digital Overconsumption and Waste: A Closer Look at the Impacts of Generative AI</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Vanessa Utz, Steve DiPaola
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Generative Artificial Intelligence (AI) systems currently contribute negatively to the production of digital waste, via the associated energy consumption and the related CO2 emissions. At this moment, a discussion is urgently needed on the replication of harmful consumer behavior, such as overconsum</span>
                
                <span class="abstract-full" style="display: none;">Generative Artificial Intelligence (AI) systems currently contribute negatively to the production of digital waste, via the associated energy consumption and the related CO2 emissions. At this moment, a discussion is urgently needed on the replication of harmful consumer behavior, such as overconsumption, in the digital space. We outline our previous work on the climate implications of commercially available generative AI systems and the sentiment of generative AI users when confronted with AI-related climate research. We expand on this work via a discussion of digital overconsumption and waste, other related societal impacts, and a possible solution pathway</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 3.9 -->
                    
                <!-- Blockchain: 3.3 -->
                    
                <!-- LLMs: 3.2 -->
                    
                <!-- Federated Learning: 3.1 -->
                    
                <!-- Evolutionary Algorithms: 2.3 -->
                    
                <!-- Hardware: 2.3 -->
                    
                <!-- Reinforcement Learning: 1.8 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Math: 1.2 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18903" target="_blank" rel="noopener noreferrer">StandUp4AI: A New Multilingual Dataset for Humor Detection in Stand-up Comedy Videos</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Valentin Barriere, Nahuel Gomez, Leo Hemamou, Sofia Callejas, Brian Ravenet
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Aiming towards improving current computational models of humor detection, we propose a new multimodal dataset of stand-up comedies, in seven languages: English, French, Spanish, Italian, Portuguese, Hungarian and Czech. Our dataset of more than 330 hours, is at the time of writing the biggest availa</span>
                
                <span class="abstract-full" style="display: none;">Aiming towards improving current computational models of humor detection, we propose a new multimodal dataset of stand-up comedies, in seven languages: English, French, Spanish, Italian, Portuguese, Hungarian and Czech. Our dataset of more than 330 hours, is at the time of writing the biggest available for this type of task, and the most diverse. The whole dataset is automatically annotated in laughter (from the audience), and the subpart left for model validation is manually annotated. Contrary to contemporary approaches, we do not frame the task of humor detection as a binary sequence classification, but as word-level sequence labeling, in order to take into account all the context of the sequence and to capture the continuous joke tagging mechanism typically occurring in natural conversations. As par with unimodal baselines results, we propose a method for e propose a method to enhance the automatic laughter detection based on Audio Speech Recognition errors. Our code and data are available online: https://tinyurl.com/EMNLPHumourStandUpPublic</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.0 -->
                    
                <!-- LLMs: 3.0 -->
                    
                <!-- Federated Learning: 2.6 -->
                    
                <!-- Computer Vision: 2.4 -->
                    
                <!-- Datasets: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Quantum Computing: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18912" target="_blank" rel="noopener noreferrer">Robust Stability Analysis of Positive Lure System with Neural Network Feedback</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Hamidreza Montazeri Hedesh, Moh. Kamalul Wafi, Bahram Shafai, Milad Siami
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper investigates the robustness of the Lur'e problem under positivity constraints, drawing on results from the positive Aizerman conjecture and the robustness properties of Metzler matrices. Specifically, we consider a control system of Lur'e type in which not only the linear part includes pa</span>
                
                <span class="abstract-full" style="display: none;">This paper investigates the robustness of the Lur'e problem under positivity constraints, drawing on results from the positive Aizerman conjecture and the robustness properties of Metzler matrices. Specifically, we consider a control system of Lur'e type in which not only the linear part includes parametric uncertainty but also the nonlinear sector bound is unknown. We investigate tools from positive linear systems to effectively solve the problems in complicated and uncertain nonlinear systems. By leveraging the positivity characteristic of the system, we derive an explicit formula for the stability radius of Lur'e systems. Furthermore, we extend our analysis to systems with neural network (NN) feedback loops. Building on this approach, we also propose a refinement method for sector bounds of feedforward neural networks (FFNNs). This study introduces a scalable and efficient approach for robustness analysis of both Lur'e and NN-controlled systems. Finally, the proposed results are supported by illustrative examples.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 3.9 -->
                    
                <!-- Federated Learning: 2.9 -->
                    
                <!-- Reinforcement Learning: 2.7 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- LLMs: 1.8 -->
                    
                <!-- Bayesian Optimization: 1.8 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Math: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18925" target="_blank" rel="noopener noreferrer">Words as Geometric Features: Estimating Homography using Optical Character Recognition as Compressed Image Representation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ross Greer, Alisha Ukani, Katherine Izhikevich, Earlence Fernandes, Stefan Savage, Alex C. Snoeren
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Document alignment and registration play a crucial role in numerous real-world applications, such as automated form processing, anomaly detection, and workflow automation. Traditional methods for document alignment rely on image-based features like keypoints, edges, and textures to estimate geometri</span>
                
                <span class="abstract-full" style="display: none;">Document alignment and registration play a crucial role in numerous real-world applications, such as automated form processing, anomaly detection, and workflow automation. Traditional methods for document alignment rely on image-based features like keypoints, edges, and textures to estimate geometric transformations, such as homographies. However, these approaches often require access to the original document images, which may not always be available due to privacy, storage, or transmission constraints. This paper introduces a novel approach that leverages Optical Character Recognition (OCR) outputs as features for homography estimation. By utilizing the spatial positions and textual content of OCR-detected words, our method enables document alignment without relying on pixel-level image data. This technique is particularly valuable in scenarios where only OCR outputs are accessible. Furthermore, the method is robust to OCR noise, incorporating RANSAC to handle outliers and inaccuracies in the OCR data. On a set of test documents, we demonstrate that our OCR-based approach even performs more accurately than traditional image-based methods, offering a more efficient and scalable solution for document registration tasks. The proposed method facilitates applications in document processing, all while reducing reliance on high-dimensional image data.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 3.3 -->
                    
                <!-- Computer Vision: 3.2 -->
                    
                <!-- Medicine: 2.1 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18945" target="_blank" rel="noopener noreferrer">Echo Planning for Autonomous Driving: From Current Observations to Future Trajectories and Back</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jintao Sun, Hu Zhang, Gangyi Ding, Zhedong Zheng
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Modern end-to-end autonomous driving systems suffer from a critical limitation: their planners lack mechanisms to enforce temporal consistency between predicted trajectories and evolving scene dynamics. This absence of self-supervision allows early prediction errors to compound catastrophically over</span>
                
                <span class="abstract-full" style="display: none;">Modern end-to-end autonomous driving systems suffer from a critical limitation: their planners lack mechanisms to enforce temporal consistency between predicted trajectories and evolving scene dynamics. This absence of self-supervision allows early prediction errors to compound catastrophically over time. We introduce Echo Planning, a novel self-correcting framework that establishes a closed-loop Current - Future - Current (CFC) cycle to harmonize trajectory prediction with scene coherence. Our key insight is that plausible future trajectories must be bi-directionally consistent, ie, not only generated from current observations but also capable of reconstructing them. The CFC mechanism first predicts future trajectories from the Bird's-Eye-View (BEV) scene representation, then inversely maps these trajectories back to estimate the current BEV state. By enforcing consistency between the original and reconstructed BEV representations through a cycle loss, the framework intrinsically penalizes physically implausible or misaligned trajectories. Experiments on nuScenes demonstrate state-of-the-art performance, reducing L2 error by 0.04 m and collision rate by 0.12% compared to one-shot planners. Crucially, our method requires no additional supervision, leveraging the CFC cycle as an inductive bias for robust planning. This work offers a deployable solution for safety-critical autonomous systems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 3.9 -->
                    
                <!-- Medicine: 3.0 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- 3D: 2.2 -->
                    
                <!-- GNN: 2.2 -->
                    
                <!-- Quantum Computing: 2.1 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Networks: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18946" target="_blank" rel="noopener noreferrer">SANNet: A Semantic-Aware Agentic AI Networking Framework for Multi-Agent Cross-Layer Coordination</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yong Xiao, Haoran Zhou, Xubo Li, Yayu Gao, Guangming Shi, Ping Zhang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Agentic AI networking (AgentNet) is a novel AI-native networking paradigm that relies on a large number of specialized AI agents to collaborate and coordinate for autonomous decision-making, dynamic environmental adaptation, and complex goal achievement. It has the potential to facilitate real-time </span>
                
                <span class="abstract-full" style="display: none;">Agentic AI networking (AgentNet) is a novel AI-native networking paradigm that relies on a large number of specialized AI agents to collaborate and coordinate for autonomous decision-making, dynamic environmental adaptation, and complex goal achievement. It has the potential to facilitate real-time network management alongside capabilities for self-configuration, self-optimization, and self-adaptation across diverse and complex networking environments, laying the foundation for fully autonomous networking systems in the future. Despite its promise, AgentNet is still in the early stage of development, and there still lacks an effective networking framework to support automatic goal discovery and multi-agent self-orchestration and task assignment. This paper proposes SANNet, a novel semantic-aware agentic AI networking architecture that can infer the semantic goal of the user and automatically assign agents associated with different layers of a mobile system to fulfill the inferred goal. Motivated by the fact that one of the major challenges in AgentNet is that different agents may have different and even conflicting objectives when collaborating for certain goals, we introduce a dynamic weighting-based conflict-resolving mechanism to address this issue. We prove that SANNet can provide theoretical guarantee in both conflict-resolving and model generalization performance for multi-agent collaboration in dynamic environment. We develop a hardware prototype of SANNet based on the open RAN and 5GS core platform. Our experimental results show that SANNet can significantly improve the performance of multi-agent networking systems, even when agents with conflicting objectives are selected to collaborate for the same goal.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 3.9 -->
                    
                <!-- Medicine: 3.2 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18952" target="_blank" rel="noopener noreferrer">Online Knowledge Distillation with Reward Guidance</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Chen Jia
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This work studies knowledge distillation (KD) for large language models (LLMs) through preference optimization. We propose a reward-guided imitation learning framework for sequential KD, formulating a min-max optimization problem between the policy and reward model (RM) to minimize the performance g</span>
                
                <span class="abstract-full" style="display: none;">This work studies knowledge distillation (KD) for large language models (LLMs) through preference optimization. We propose a reward-guided imitation learning framework for sequential KD, formulating a min-max optimization problem between the policy and reward model (RM) to minimize the performance gap between the student and teacher policies. Specifically, the reward optimization is constrained to achieve near-optimality within a confidence set for preference alignment. For preference data construction, we explore both offline and online preference-based KD. Additionally, we reformulate the RM using the $Q$-value function and extend the framework to white-box KD, where the teacher policy's predicted probabilities are accessible. Theoretical analysis and empirical results demonstrate the effectiveness of the proposed framework.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 3.2 -->
                    
                <!-- Computer Vision: 2.9 -->
                    
                <!-- Reinforcement Learning: 2.6 -->
                    
                <!-- LLMs: 2.6 -->
                    
                <!-- Bayesian Optimization: 2.5 -->
                    
                <!-- Federated Learning: 2.5 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18975" target="_blank" rel="noopener noreferrer">FastMamba: A High-Speed and Efficient Mamba Accelerator on FPGA with Accurate Quantization</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Aotao Wang, Haikuo Shao, Shaobo Ma, Zhongfeng Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">State Space Models (SSMs), like recent Mamba2, have achieved remarkable performance and received extensive attention. However, deploying Mamba2 on resource-constrained edge devices encounters many problems: severe outliers within the linear layer challenging the quantization, diverse and irregular e</span>
                
                <span class="abstract-full" style="display: none;">State Space Models (SSMs), like recent Mamba2, have achieved remarkable performance and received extensive attention. However, deploying Mamba2 on resource-constrained edge devices encounters many problems: severe outliers within the linear layer challenging the quantization, diverse and irregular element-wise tensor operations, and hardware-unfriendly nonlinear functions in the SSM block. To address these issues, this paper presents FastMamba, a dedicated accelerator on FPGA with hardware-algorithm co-design to promote the deployment efficiency of Mamba2. Specifically, we successfully achieve 8-bit quantization for linear layers through Hadamard transformation to eliminate outliers. Moreover, a hardware-friendly and fine-grained power-of-two quantization framework is presented for the SSM block and convolution layer, and a first-order linear approximation is developed to optimize the nonlinear functions. Based on the accurate algorithm quantization, we propose an accelerator that integrates parallel vector processing units, pipelined execution dataflow, and an efficient SSM Nonlinear Approximation Unit, which enhances computational efficiency and reduces hardware complexity. Finally, we evaluate FastMamba on Xilinx VC709 FPGA. For the input prefill task on Mamba2-130M, FastMamba achieves 68.80\times and 8.90\times speedup over Intel Xeon 4210R CPU and NVIDIA RTX 3090 GPU, respectively. In the output decode experiment with Mamba2-2.7B, FastMamba attains 6\times higher energy efficiency than RTX 3090 GPU.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.7 -->
                    
                <!-- Computer Vision: 3.5 -->
                    
                <!-- Hardware: 3.3 -->
                    
                <!-- LLMs: 2.5 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18980" target="_blank" rel="noopener noreferrer">Improving Anomalous Sound Detection through Pseudo-anomalous Set Selection and Pseudo-label Utilization under Unlabeled Conditions</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ibuki Kuroyanagi, Takuya Fujimura, Kazuya Takeda, Tomoki Toda
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper addresses performance degradation in anomalous sound detection (ASD) when neither sufficiently similar machine data nor operational state labels are available. We present an integrated pipeline that combines three complementary components derived from prior work and extends them to the un</span>
                
                <span class="abstract-full" style="display: none;">This paper addresses performance degradation in anomalous sound detection (ASD) when neither sufficiently similar machine data nor operational state labels are available. We present an integrated pipeline that combines three complementary components derived from prior work and extends them to the unlabeled ASD setting. First, we adapt an anomaly score based selector to curate external audio data resembling the normal sounds of the target machine. Second, we utilize triplet learning to assign pseudo-labels to unlabeled data, enabling finer classification of operational sounds and detection of subtle anomalies. Third, we employ iterative training to refine both the pseudo-anomalous set selection and pseudo-label assignment, progressively improving detection accuracy. Experiments on the DCASE2022-2024 Task 2 datasets demonstrate that, in unlabeled settings, our approach achieves an average AUC increase of over 6.6 points compared to conventional methods. In labeled settings, incorporating external data from the pseudo-anomalous set further boosts performance. These results highlight the practicality and robustness of our methods in scenarios with scarce machine data and labels, facilitating ASD deployment across diverse industrial settings with minimal annotation effort.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.0 -->
                    
                <!-- Computer Vision: 3.7 -->
                    
                <!-- LLMs: 3.6 -->
                    
                <!-- Federated Learning: 2.4 -->
                    
                <!-- Decision Trees: 1.8 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Robotics: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18984" target="_blank" rel="noopener noreferrer">Self-supervised learning method using multiple sampling strategies for general-purpose audio representation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ibuki Kuroyanagi, Tatsuya Komatsu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We propose a self-supervised learning method using multiple sampling strategies to obtain general-purpose audio representation. Multiple sampling strategies are used in the proposed method to construct contrastive losses from different perspectives and learn representations based on them. In this st</span>
                
                <span class="abstract-full" style="display: none;">We propose a self-supervised learning method using multiple sampling strategies to obtain general-purpose audio representation. Multiple sampling strategies are used in the proposed method to construct contrastive losses from different perspectives and learn representations based on them. In this study, in addition to the widely used clip-level sampling strategy, we introduce two new strategies, a frame-level strategy and a task-specific strategy. The proposed multiple strategies improve the performance of frame-level classification and other tasks like pitch detection, which are not the focus of the conventional single clip-level sampling strategy. We pre-trained the method on a subset of Audioset and applied it to a downstream task with frozen weights. The proposed method improved clip classification, sound event detection, and pitch detection performance by 25%, 20%, and 3.6%.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 3.5 -->
                    
                <!-- LLMs: 3.1 -->
                    
                <!-- Evolutionary Algorithms: 3.0 -->
                    
                <!-- Medicine: 3.0 -->
                    
                <!-- Computer Vision: 2.2 -->
                    
                <!-- Reinforcement Learning: 2.2 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.4 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18987" target="_blank" rel="noopener noreferrer">Error estimates for the interpolation and approximation of gradients and vector fields on protected Delaunay meshes in $\mathbb{R}^d$</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: David M. Williams, Mathijs Wintraecken
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">One frequently needs to interpolate or approximate gradients on simplicial meshes. Unfortunately, there are very few explicit mathematical results governing the interpolation or approximation of vector-valued functions on Delaunay meshes in more than two dimensions. Most of the existing results are </span>
                
                <span class="abstract-full" style="display: none;">One frequently needs to interpolate or approximate gradients on simplicial meshes. Unfortunately, there are very few explicit mathematical results governing the interpolation or approximation of vector-valued functions on Delaunay meshes in more than two dimensions. Most of the existing results are tailored towards interpolation with piecewise linear polynomials. In contrast, interpolation with piecewise high-order polynomials is not well understood. In particular, the results in this area are sometimes difficult to immediately interpret, or to specialize to the Delaunay setting. In order to address this issue, we derive explicit error estimates for high-order, piecewise polynomial gradient interpolation and approximation on protected Delaunay meshes. In addition, we generalize our analysis beyond gradients, and obtain error estimates for sufficiently-smooth vector fields. Throughout the paper, we show that the quality of interpolation and approximation often depends (in part) on the minimum thickness of simplices in the mesh. Fortunately, the minimum thickness can be precisely controlled on protected Delaunay meshes in $\mathbb{R}^d$.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 3.0 -->
                    
                <!-- Computer Vision: 2.4 -->
                    
                <!-- LLMs: 2.2 -->
                    
                <!-- Math: 2.1 -->
                    
                <!-- Medicine: 2.1 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Game Theory: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18988" target="_blank" rel="noopener noreferrer">NTIRE 2025 Challenge on Video Quality Enhancement for Video Conferencing: Datasets, Methods and Results</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Varun Jain, Zongwei Wu, Quan Zou, Louis Florentin, Henrik Turbell, Sandeep Siddhartha, Radu Timofte, others
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper presents a comprehensive review of the 1st Challenge on Video Quality Enhancement for Video Conferencing held at the NTIRE workshop at CVPR 2025, and highlights the problem statement, datasets, proposed solutions, and results. The aim of this challenge was to design a Video Quality Enhanc</span>
                
                <span class="abstract-full" style="display: none;">This paper presents a comprehensive review of the 1st Challenge on Video Quality Enhancement for Video Conferencing held at the NTIRE workshop at CVPR 2025, and highlights the problem statement, datasets, proposed solutions, and results. The aim of this challenge was to design a Video Quality Enhancement (VQE) model to enhance video quality in video conferencing scenarios by (a) improving lighting, (b) enhancing colors, (c) reducing noise, and (d) enhancing sharpness - giving a professional studio-like effect. Participants were given a differentiable Video Quality Assessment (VQA) model, training, and test videos. A total of 91 participants registered for the challenge. We received 10 valid submissions that were evaluated in a crowdsourced framework.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 3.5 -->
                    
                <!-- LLMs: 3.0 -->
                    
                <!-- Hardware: 2.3 -->
                    
                <!-- Blockchain: 2.0 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Computer Vision: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Networks: 1.2 -->
                    
                <!-- 3D: 1.1 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18994" target="_blank" rel="noopener noreferrer">Designing Pin-pression Gripper and Learning its Dexterous Grasping with Online In-hand Adjustment</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Hewen Xiao, Xiuping Liu, Hang Zhao, Jian Liu, Kai Xu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We introduce a novel design of parallel-jaw grippers drawing inspiration from pin-pression toys. The proposed pin-pression gripper features a distinctive mechanism in which each finger integrates a 2D array of pins capable of independent extension and retraction. This unique design allows the grippe</span>
                
                <span class="abstract-full" style="display: none;">We introduce a novel design of parallel-jaw grippers drawing inspiration from pin-pression toys. The proposed pin-pression gripper features a distinctive mechanism in which each finger integrates a 2D array of pins capable of independent extension and retraction. This unique design allows the gripper to instantaneously customize its finger's shape to conform to the object being grasped by dynamically adjusting the extension/retraction of the pins. In addition, the gripper excels in in-hand re-orientation of objects for enhanced grasping stability again via dynamically adjusting the pins. To learn the dynamic grasping skills of pin-pression grippers, we devise a dedicated reinforcement learning algorithm with careful designs of state representation and reward shaping. To achieve a more efficient grasp-while-lift grasping mode, we propose a curriculum learning scheme. Extensive evaluations demonstrate that our design, together with the learned skills, leads to highly flexible and robust grasping with much stronger generality to unseen objects than alternatives. We also highlight encouraging physical results of sim-to-real transfer on a physically manufactured pin-pression gripper, demonstrating the practical significance of our novel gripper design and grasping skill. Demonstration videos for this paper are available at https://github.com/siggraph-pin-pression-gripper/pin-pression-gripper-video.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 3.8 -->
                    
                <!-- Medicine: 3.1 -->
                    
                <!-- Reinforcement Learning: 2.7 -->
                    
                <!-- LLMs: 2.4 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.4 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18998" target="_blank" rel="noopener noreferrer">Property Directed Reachability with Extended Resolution</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Andrew Luka, Yakir Vizel
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Property Directed Reachability (\textsc{Pdr}), also known as IC3, is a state-of-the-art model checking algorithm widely used for verifying safety properties. While \textsc{Pdr} is effective in finding inductive invariants, its underlying proof system, Resolution, limits its ability to construct shor</span>
                
                <span class="abstract-full" style="display: none;">Property Directed Reachability (\textsc{Pdr}), also known as IC3, is a state-of-the-art model checking algorithm widely used for verifying safety properties. While \textsc{Pdr} is effective in finding inductive invariants, its underlying proof system, Resolution, limits its ability to construct short proofs for certain verification problems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.8 -->
                    
                <!-- HPO and AutoML: 3.4 -->
                    
                <!-- Medicine: 2.9 -->
                    
                <!-- Quantum Computing: 2.5 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- GNN: 2.3 -->
                    
                <!-- Blockchain: 2.1 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Bayesian Optimization: 1.8 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Networks: 1.1 -->
                    
                <!-- T2I: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.18999" target="_blank" rel="noopener noreferrer">Lightweight Embeddings with Graph Rewiring for Collaborative Filtering</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Xurong Liang, Tong Chen, Wei Yuan, Hongzhi Yin
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">As recommendation services scale rapidly and their deployment now commonly involves resource-constrained edge devices, GNN-based recommender systems face significant challenges, including high embedding storage costs and runtime latency from graph propagations. Our previous work, LEGCF, effectively </span>
                
                <span class="abstract-full" style="display: none;">As recommendation services scale rapidly and their deployment now commonly involves resource-constrained edge devices, GNN-based recommender systems face significant challenges, including high embedding storage costs and runtime latency from graph propagations. Our previous work, LEGCF, effectively reduced embedding storage costs but struggled to maintain recommendation performance under stricter storage limits. Additionally, LEGCF did not address the extensive runtime computation costs associated with graph propagation, which involves heavy multiplication and accumulation operations (MACs). These challenges consequently hinder effective training and inference on resource-constrained edge devices. To address these limitations, we propose Lightweight Embeddings with Rewired Graph for Graph Collaborative Filtering (LERG), an improved extension of LEGCF. LERG retains LEGCFs compositional codebook structure but introduces quantization techniques to reduce the storage cost, enabling the inclusion of more meta-embeddings within the same storage. To optimize graph propagation, we pretrain the quantized compositional embedding table using the full interaction graph on resource-rich servers, after which a fine-tuning stage is engaged to identify and prune low-contribution entities via a gradient-free binary integer programming approach, constructing a rewired graph that excludes these entities (i.e., user/item nodes) from propagating signals. The quantized compositional embedding table with selective embedding participation and sparse rewired graph are transferred to edge devices which significantly reduce computation memory and inference time. Experiments on three public benchmark datasets, including an industry-scale dataset, demonstrate that LERG achieves superior recommendation performance while dramatically reducing storage and computation costs for graph-based recommendation services.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 5.0 -->
                    
                <!-- GNN: 4.9 -->
                    
                <!-- LLMs: 3.0 -->
                    
                <!-- Computer Vision: 2.6 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- HPO and AutoML: 2.0 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Datasets: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.19001" target="_blank" rel="noopener noreferrer">DARTH: Declarative Recall Through Early Termination for Approximate Nearest Neighbor Search</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Manos Chatzakis, Yannis Papakonstantinou, Themis Palpanas
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Approximate Nearest Neighbor Search (ANNS) presents an inherent tradeoff between performance and recall (i.e., result quality). Each ANNS algorithm provides its own algorithm-dependent parameters to allow applications to influence the recall/performance tradeoff of their searches. This situation is </span>
                
                <span class="abstract-full" style="display: none;">Approximate Nearest Neighbor Search (ANNS) presents an inherent tradeoff between performance and recall (i.e., result quality). Each ANNS algorithm provides its own algorithm-dependent parameters to allow applications to influence the recall/performance tradeoff of their searches. This situation is doubly problematic. First, the application developers have to experiment with these algorithm-dependent parameters to fine-tune the parameters that produce the desired recall for each use case. This process usually takes a lot of effort. Even worse, the chosen parameters may produce good recall for some queries, but bad recall for hard queries. To solve these problems, we present DARTH, a method that uses target declarative recall. DARTH uses a novel method for providing target declarative recall on top of an ANNS index by employing an adaptive early termination strategy integrated into the search algorithm. Through a wide range of experiments, we demonstrate that DARTH effectively meets user-defined recall targets while achieving significant speedups, up to 14.6x (average: 6.8x; median: 5.7x) faster than the search without early termination for HNSW and up to 41.8x (average: 13.6x; median: 8.1x) for IVF. This paper appeared in ACM SIGMOD 2026.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 3.2 -->
                    
                <!-- Medicine: 3.1 -->
                    
                <!-- Evolutionary Algorithms: 2.8 -->
                    
                <!-- LLMs: 2.6 -->
                    
                <!-- Quantum Computing: 2.2 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- 3D: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.19002" target="_blank" rel="noopener noreferrer">Semi-pessimistic Reinforcement Learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jin Zhu, Xin Zhou, Jiaang Yao, Gholamali Aminian, Omar Rivasplata, Simon Little, Lexin Li, Chengchun Shi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Offline reinforcement learning (RL) aims to learn an optimal policy from pre-collected data. However, it faces challenges of distributional shift, where the learned policy may encounter unseen scenarios not covered in the offline data. Additionally, numerous applications suffer from a scarcity of la</span>
                
                <span class="abstract-full" style="display: none;">Offline reinforcement learning (RL) aims to learn an optimal policy from pre-collected data. However, it faces challenges of distributional shift, where the learned policy may encounter unseen scenarios not covered in the offline data. Additionally, numerous applications suffer from a scarcity of labeled reward data. Relying on labeled data alone often leads to a narrow state-action distribution, further amplifying the distributional shift, and resulting in suboptimal policy learning. To address these issues, we first recognize that the volume of unlabeled data is typically substantially larger than that of labeled data. We then propose a semi-pessimistic RL method to effectively leverage abundant unlabeled data. Our approach offers several advantages. It considerably simplifies the learning process, as it seeks a lower bound of the reward function, rather than that of the Q-function or state transition function. It is highly flexible, and can be integrated with a range of model-free and model-based RL algorithms. It enjoys the guaranteed improvement when utilizing vast unlabeled data, but requires much less restrictive conditions. We compare our method with a number of alternative solutions, both analytically and numerically, and demonstrate its clear competitiveness. We further illustrate with an application to adaptive deep brain stimulation for Parkinson's disease.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Reinforcement Learning: 4.7 -->
                    
                <!-- Federated Learning: 3.2 -->
                    
                <!-- Medicine: 3.0 -->
                    
                <!-- LLMs: 2.9 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Bayesian Optimization: 1.6 -->
                    
                <!-- Networks: 1.2 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Robotics: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.19010" target="_blank" rel="noopener noreferrer">Co-AttenDWG: Co-Attentive Dimension-Wise Gating and Expert Fusion for Multi-Modal Offensive Content Detection</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Md. Mithun Hossain, Md. Shakil Hossain, Sudipto Chaki, M. F. Mridha
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Multi-modal learning has become a critical research area because integrating text and image data can significantly improve performance in tasks such as classification, retrieval, and scene understanding. However, despite progress with pre-trained models, current approaches are limited by inadequate </span>
                
                <span class="abstract-full" style="display: none;">Multi-modal learning has become a critical research area because integrating text and image data can significantly improve performance in tasks such as classification, retrieval, and scene understanding. However, despite progress with pre-trained models, current approaches are limited by inadequate cross-modal interactions and static fusion strategies that do not fully exploit the complementary nature of different modalities. To address these shortcomings, we introduce a novel multi-modal Co-AttenDWG architecture that leverages dual-path encoding, co-attention with dimension-wise gating, and advanced expert fusion. Our approach begins by projecting text and image features into a common embedding space, where a dedicated co-attention mechanism enables simultaneous, fine-grained interactions between modalities. This mechanism is further enhanced by a dimension-wise gating network that adaptively regulates the feature contributions at the channel level, ensuring that only the most relevant information is emphasized. In parallel, dual-path encoders refine the representations by processing cross-modal information separately before an additional cross-attention layer further aligns modalities. The refined features are then aggregated via an expert fusion module that combines learned gating and self-attention to produce a robust, unified representation. We validate our approach on the MIMIC and SemEval Memotion 1.0, where experimental results demonstrate significant improvements in cross-modal alignment and state-of-the-art performance, underscoring the potential of our model for a wide range of multi-modal applications.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Medicine: 4.5 -->
                    
                <!-- LLMs: 4.2 -->
                    
                <!-- Quantum Computing: 2.0 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- 3D: 1.8 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.19013" target="_blank" rel="noopener noreferrer">Faithful Group Shapley Value</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Kiljae Lee, Ziqi Liu, Weijing Tang, Yuan Zhang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Data Shapley is an important tool for data valuation, which quantifies the contribution of individual data points to machine learning models. In practice, group-level data valuation is desirable when data providers contribute data in batch. However, we identify that existing group-level extensions o</span>
                
                <span class="abstract-full" style="display: none;">Data Shapley is an important tool for data valuation, which quantifies the contribution of individual data points to machine learning models. In practice, group-level data valuation is desirable when data providers contribute data in batch. However, we identify that existing group-level extensions of Data Shapley are vulnerable to shell company attacks, where strategic group splitting can unfairly inflate valuations. We propose Faithful Group Shapley Value (FGSV) that uniquely defends against such attacks. Building on original mathematical insights, we develop a provably fast and accurate approximation algorithm for computing FGSV. Empirical experiments demonstrate that our algorithm significantly outperforms state-of-the-art methods in computational efficiency and approximation accuracy, while ensuring faithful group-level valuation.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- LLMs: 4.9 -->
                    
                <!-- Medicine: 4.1 -->
                    
                <!-- Quantum Computing: 2.7 -->
                    
                <!-- Decision Trees: 2.7 -->
                    
                <!-- GNN: 2.6 -->
                    
                <!-- Federated Learning: 2.5 -->
                    
                <!-- Bayesian Optimization: 2.1 -->
                    
                <!-- HPO and AutoML: 2.0 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.19026" target="_blank" rel="noopener noreferrer">Staircase Recognition and Location Based on Polarization Vision</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Weifeng Kong, Zhiying Tan
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Staircase is one of the most common structures in artificial scenes. However, it is difficult for humanoid robots and people with lower limb disabilities or visual impairment to cross the scene without the help of sensors and intelligent algorithms. Staircase scene perception technology is a prerequ</span>
                
                <span class="abstract-full" style="display: none;">Staircase is one of the most common structures in artificial scenes. However, it is difficult for humanoid robots and people with lower limb disabilities or visual impairment to cross the scene without the help of sensors and intelligent algorithms. Staircase scene perception technology is a prerequisite for recognition and localization. This technology is of great significance for the mode switching of the robot and the calculation of the footprint position to adapt to the discontinuous terrain. However, there are still many problems that constrain the application of this technology, such as low recognition accuracy, high initial noise from sensors, unstable output signals and high computational requirements. In terms of scene reconstruction, the binocular and time of flight (TOF) reconstruction of the scene can be easily affected by environmental light and the surface material of the target object. In contrast, due to the special structure of the polarizer, the polarization can selectively transmit polarized light in a specific direction and this reconstruction method relies on the polarization information of the object surface. So the advantages of polarization reconstruction are reflected, which are less affected by environmental light and not dependent on the texture information of the object surface. In this paper, in order to achieve the detection of staircase, this paper proposes a contrast enhancement algorithm that integrates polarization and light intensity information, and integrates point cloud segmentation based on YOLOv11. To realize the high-quality reconstruction, we proposed a method of fusing polarized binocular and TOF depth information to realize the three-dimensional (3D) reconstruction of the staircase. Besides, it also proposes a joint calibration algorithm of monocular camera and TOF camera based on ICP registration and improved gray wolf optimization algorithm.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 4.6 -->
                    
                <!-- Medicine: 3.1 -->
                    
                <!-- Evolutionary Algorithms: 2.6 -->
                    
                <!-- Hardware: 2.5 -->
                    
                <!-- Bayesian Optimization: 2.2 -->
                    
                <!-- Reinforcement Learning: 1.9 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Math: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.19027" target="_blank" rel="noopener noreferrer">High Throughput QC-LDPC Decoder With Optimized Schedule Policy in Layered Decoding</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Dongxu Chang, Qingqing Peng, Guanghui Wang, Guiying Yan
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In this study, a scheduling policy of layered decoding for quasi-cycle (QC) low-density parity-check (LDPC) codes with high throughput and good performance is designed. The influence of scheduling on the delay of the decoder's hardware implementation and on the decoding performance are considered si</span>
                
                <span class="abstract-full" style="display: none;">In this study, a scheduling policy of layered decoding for quasi-cycle (QC) low-density parity-check (LDPC) codes with high throughput and good performance is designed. The influence of scheduling on the delay of the decoder's hardware implementation and on the decoding performance are considered simultaneously. Specifically, we analyze the idle time required under various scheduling sequences within a pipelined decoding architecture and formulate the problem as a traveling salesman problem (TSP) aiming at minimizing idle time. Furthermore, considering that different scheduling sequences can affect decoding performance, we refine the graph used to solve the TSP based on scheduling characteristics that promote improved decoding outcomes. Simulation results demonstrate that the identified scheduling sequence achieves a low number of hardware delays while maintaining excellent decoding performance for 5G New Radio (NR) LDPC codes.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 3.4 -->
                    
                <!-- Hardware: 2.4 -->
                    
                <!-- Medicine: 2.4 -->
                    
                <!-- Evolutionary Algorithms: 2.4 -->
                    
                <!-- Reinforcement Learning: 2.1 -->
                    
                <!-- LLMs: 2.1 -->
                    
                <!-- GNN: 2.1 -->
                    
                <!-- Bayesian Optimization: 1.6 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Networks: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-neutral">
                    0.0
                </span>
                <a href="https://arxiv.org/abs/2505.19036" target="_blank" rel="noopener noreferrer">Weak Physics Informed Neural Networks for Geometry Compatible Hyperbolic Conservation Laws on Manifolds</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Hanfei Zhou, Lei Shi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Physics-informed neural networks (PINNs), owing to their mesh-free nature, offer a powerful approach for solving high-dimensional partial differential equations (PDEs) in complex geometries, including irregular domains. This capability effectively circumvents the challenges of mesh generation that t</span>
                
                <span class="abstract-full" style="display: none;">Physics-informed neural networks (PINNs), owing to their mesh-free nature, offer a powerful approach for solving high-dimensional partial differential equations (PDEs) in complex geometries, including irregular domains. This capability effectively circumvents the challenges of mesh generation that traditional numerical methods face in high-dimensional or geometrically intricate settings. While recent studies have extended PINNs to manifolds, the theoretical foundations remain scarce. Existing theoretical analyses of PINNs in Euclidean space often rely on smoothness assumptions for the solutions. However, recent empirical evidence indicates that PINNs may struggle to approximate solutions with low regularity, such as those arising from nonlinear hyperbolic equations. In this paper, we develop a framework for PINNs tailored to the efficient approximation of weak solutions, particularly nonlinear hyperbolic equations defined on manifolds. We introduce a novel weak PINN (wPINN) formulation on manifolds that leverages the well-posedness theory to approximate entropy solutions of geometry-compatible hyperbolic conservation laws on manifolds. Employing tools from approximation theory, we establish a convergence analysis of the algorithm, including an analysis of approximation errors for time-dependent entropy solutions. This analysis provides insight into the accumulation of approximation errors over long time horizons. Notably, the network complexity depends only on the intrinsic dimension, independent of the ambient space dimension. Our results match the minimax rate in the d-dimensional Euclidean space, demonstrating that PINNs can alleviate the curse of dimensionality in the context of low-dimensional manifolds. Finally, we validate the performance of the proposed wPINN framework through numerical experiments, confirming its ability to efficiently approximate entropy solutions on manifolds.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><!-- Federated Learning: 4.4 -->
                    
                <!-- GNN: 3.2 -->
                    
                <!-- Bayesian Optimization: 3.1 -->
                    
                <!-- Evolutionary Algorithms: 2.5 -->
                    
                <!-- Reinforcement Learning: 2.5 -->
                    
                <!-- Math: 2.0 -->
                    
                <!-- Medicine: 1.9 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- LLMs: 1.6 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Networks: 1.1 -->
                    
                <!-- Game Theory: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.0416
                </span>
                <a href="https://arxiv.org/abs/2505.19821" target="_blank" rel="noopener noreferrer">Poison in the Well: Feature Embedding Disruption in Backdoor Attacks</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zhou Feng, Jiahao Chen, Chunyi Zhou, Yuwen Pu, Qingming Li, Shouling Ji
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Backdoor attacks embed malicious triggers into training data, enabling attackers to manipulate neural network behavior during inference while maintaining high accuracy on benign inputs. However, existing backdoor attacks face limitations manifesting in excessive reliance on training data, poor steal</span>
                
                <span class="abstract-full" style="display: none;">Backdoor attacks embed malicious triggers into training data, enabling attackers to manipulate neural network behavior during inference while maintaining high accuracy on benign inputs. However, existing backdoor attacks face limitations manifesting in excessive reliance on training data, poor stealth, and instability, which hinder their effectiveness in real-world applications. Therefore, this paper introduces ShadowPrint, a versatile backdoor attack that targets feature embeddings within neural networks to achieve high ASRs and stealthiness. Unlike traditional approaches, ShadowPrint reduces reliance on training data access and operates effectively with exceedingly low poison rates (as low as 0.01%). It leverages a clustering-based optimization strategy to align feature embeddings, ensuring robust performance across diverse scenarios while maintaining stability and stealth. Extensive evaluations demonstrate that ShadowPrint achieves superior ASR (up to 100%), steady CA (with decay no more than 1% in most cases), and low DDR (averaging below 5%) across both clean-label and dirty-label settings, and with poison rates ranging from as low as 0.01% to 0.05%, setting a new standard for backdoor attack capabilities and emphasizing the need for advanced defense strategies focused on feature space manipulations.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.8%">
                            LLMs
                        </span>
                <!-- Computer Vision: 4.3 -->
                    
                <!-- Medicine: 2.2 -->
                    
                <!-- GNN: 2.2 -->
                    
                <!-- Blockchain: 2.1 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- HPO and AutoML: 2.0 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- T2I: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.0568
                </span>
                <a href="https://arxiv.org/abs/2505.02329" target="_blank" rel="noopener noreferrer">Regulating Algorithmic Management: A Multi-Stakeholder Study of Challenges in Aligning Software and the Law for Workplace Scheduling</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jonathan Lynn, Rachel Y. Kim, Sicun Gao, Daniel Schneider, Sachin S. Pandya, Min Kyung Lee
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Algorithmic management (AM)'s impact on worker well-being has led to calls for regulation. However, little is known about the effectiveness and challenges in real-world AM regulation across the regulatory process -- rule operationalization, software use, and enforcement. Our multi-stakeholder study </span>
                
                <span class="abstract-full" style="display: none;">Algorithmic management (AM)'s impact on worker well-being has led to calls for regulation. However, little is known about the effectiveness and challenges in real-world AM regulation across the regulatory process -- rule operationalization, software use, and enforcement. Our multi-stakeholder study addresses this gap within workplace scheduling, one of the few AM domains with implemented regulations. We interviewed 38 stakeholders across the regulatory process: regulators, defense attorneys, worker advocates, managers, and workers. Our findings suggest that the efficacy of AM regulation is influenced by: (i) institutional constraints that challenge efforts to encode law into AM software, (ii) on-the-ground use of AM software that shapes its ability to facilitate compliance, (iii) mismatches between software and regulatory contexts that hinder enforcement, and (iv) unique concerns that software introduces when used to regulate AM. These findings underscore the importance of a sociotechnical approach to AM regulation, which considers organizational and collaborative contexts alongside the inherent attributes of software. We offer future research directions and implications for technology policy and design.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.4%">
                            LLMs
                        </span>
                <!-- Medicine: 3.3 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.0722
                </span>
                <a href="https://arxiv.org/abs/2505.15489" target="_blank" rel="noopener noreferrer">Seeing Through Deception: Uncovering Misleading Creator Intent in Multimodal News with Vision-Language Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jiaying Wu, Fanxiao Li, Min-Yen Kan, Bryan Hooi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The real-world impact of misinformation stems from the underlying misleading narratives that creators seek to convey. As such, interpreting misleading creator intent is essential for multimodal misinformation detection (MMD) systems aimed at effective information governance. In this paper, we introd</span>
                
                <span class="abstract-full" style="display: none;">The real-world impact of misinformation stems from the underlying misleading narratives that creators seek to convey. As such, interpreting misleading creator intent is essential for multimodal misinformation detection (MMD) systems aimed at effective information governance. In this paper, we introduce an automated framework that simulates real-world multimodal news creation by explicitly modeling creator intent through two components: the desired influence and the execution plan. Using this framework, we construct DeceptionDecoded, a large-scale benchmark comprising 12,000 image-caption pairs aligned with trustworthy reference articles. The dataset captures both misleading and non-misleading intents and spans manipulations across visual and textual modalities. We conduct a comprehensive evaluation of 14 state-of-the-art vision-language models (VLMs) on three intent-centric tasks: (1) misleading intent detection, (2) misleading source attribution, and (3) creator desire inference. Despite recent advances, we observe that current VLMs fall short in recognizing misleading intent, often relying on spurious cues such as superficial cross-modal consistency, stylistic signals, and heuristic authenticity hints. Our findings highlight the pressing need for intent-aware modeling in MMD and open new directions for developing systems capable of deeper reasoning about multimodal misinformation.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 9.4%">
                            LLMs
                        </span>
                <!-- Medicine: 4.1 -->
                    
                <!-- Computer Vision: 2.8 -->
                    
                <!-- Datasets: 2.2 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Blockchain: 2.0 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- 3D: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.092
                </span>
                <a href="https://arxiv.org/abs/2505.19653" target="_blank" rel="noopener noreferrer">Token-Importance Guided Direct Preference Optimization</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yang Ning, Lin Hai, Liu Yibo, Tian Baoliang, Liu Guoqing, Zhang Haijun
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Ensuring that large language models (LLMs) generate outputs aligned with human preferences is important for safe and effective AI interactions. While Direct Preference Optimization (DPO) employs an implicit reward function to optimize the policy model, however, it and its related variants overlook t</span>
                
                <span class="abstract-full" style="display: none;">Ensuring that large language models (LLMs) generate outputs aligned with human preferences is important for safe and effective AI interactions. While Direct Preference Optimization (DPO) employs an implicit reward function to optimize the policy model, however, it and its related variants overlook the differential importance of individual tokens and are sensitive to judgment noise in preference datasets during generation. Although recent methods attempt to assess the important weight of tokens via probability prediction or simplistic weighting schemes, these evaluation methods are prone to biases and still cannot fully address these issues. To solve this problem, we propose the Token-Importance Guided Direct Preference Optimization (TI-DPO), which introduces two key innovations: the gradient-based token-importance weights that dynamically prioritize critical tokens, and a triple loss that explicitly guides model outputs to approach human-preferred responses and stay away from non-preferred responses. Experimental results show that TI-DPO achieves higher accuracy and stronger generative diversity, providing more stable and computationally efficient solutions compared with DPO and other RLHF methods.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 12.9%">
                            LLMs
                        </span>
                <!-- Medicine: 3.2 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Computer Vision: 2.1 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- HPO and AutoML: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- 3D: 1.1 -->
                    
                <!-- Hardware: 1.1 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.1223
                </span>
                <a href="https://arxiv.org/abs/2503.01763" target="_blank" rel="noopener noreferrer">Retrieval Models Aren't Tool-Savvy: Benchmarking Tool Retrieval for Large Language Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zhengliang Shi, Yuhan Wang, Lingyong Yan, Pengjie Ren, Shuaiqiang Wang, Dawei Yin, Zhaochun Ren
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Tool learning aims to augment large language models (LLMs) with diverse tools, enabling them to act as agents for solving practical tasks. Due to the limited context length of tool-using LLMs, adopting information retrieval (IR) models to select useful tools from large toolsets is a critical initial</span>
                
                <span class="abstract-full" style="display: none;">Tool learning aims to augment large language models (LLMs) with diverse tools, enabling them to act as agents for solving practical tasks. Due to the limited context length of tool-using LLMs, adopting information retrieval (IR) models to select useful tools from large toolsets is a critical initial step. However, the performance of IR models in tool retrieval tasks remains underexplored and unclear. Most tool-use benchmarks simplify this step by manually pre-annotating a small set of relevant tools for each task, which is far from the real-world scenarios. In this paper, we propose ToolRet, a heterogeneous tool retrieval benchmark comprising 7.6k diverse retrieval tasks, and a corpus of 43k tools, collected from existing datasets. We benchmark six types of models on ToolRet. Surprisingly, even the models with strong performance in conventional IR benchmarks, exhibit poor performance on ToolRet. This low retrieval quality degrades the task pass rate of tool-use LLMs. As a further step, we contribute a large-scale training dataset with over 200k instances, which substantially optimizes the tool retrieval ability of IR models.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 13.4%">
                            LLMs
                        </span>
                <!-- Medicine: 3.4 -->
                    
                <!-- Federated Learning: 2.7 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.4 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.1254
                </span>
                <a href="https://arxiv.org/abs/2505.19121" target="_blank" rel="noopener noreferrer">Delving into Multilingual Ethical Bias: The MSQAD with Statistical Hypothesis Tests for Large Language Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Seunguk Yu, Juhwan Choi, Youngbin Kim
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Despite the recent strides in large language models, studies have underscored the existence of social biases within these systems. In this paper, we delve into the validation and comparison of the ethical biases of LLMs concerning globally discussed and potentially sensitive topics, hypothesizing th</span>
                
                <span class="abstract-full" style="display: none;">Despite the recent strides in large language models, studies have underscored the existence of social biases within these systems. In this paper, we delve into the validation and comparison of the ethical biases of LLMs concerning globally discussed and potentially sensitive topics, hypothesizing that these biases may arise from language-specific distinctions. Introducing the Multilingual Sensitive Questions & Answers Dataset (MSQAD), we collected news articles from Human Rights Watch covering 17 topics, and generated socially sensitive questions along with corresponding responses in multiple languages. We scrutinized the biases of these responses across languages and topics, employing two statistical hypothesis tests. The results showed that the null hypotheses were rejected in most cases, indicating biases arising from cross-language differences. It demonstrates that ethical biases in responses are widespread across various languages, and notably, these biases were prevalent even among different LLMs. By making the proposed MSQAD openly available, we aim to facilitate future research endeavors focused on examining cross-language biases in LLMs and their variant models.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 17.6%">
                            LLMs
                        </span>
                <!-- Medicine: 2.7 -->
                    
                <!-- Blockchain: 2.3 -->
                    
                <!-- Computer Vision: 2.1 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                <!-- Evolutionary Algorithms: 1.0 -->
                    
                <!-- Bayesian Optimization: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.1833
                </span>
                <a href="https://arxiv.org/abs/2505.20154" target="_blank" rel="noopener noreferrer">UORA: Uniform Orthogonal Reinitialization Adaptation in Parameter-Efficient Fine-Tuning of Large Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Xueyan Zhang, Jinman Zhao, Zhifei Yang, Yibo Zhong, Shuhao Guan, Linbo Cao, Yining Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper introduces Uniform Orthogonal Reinitialization Adaptation (UORA), a novel parameter-efficient fine-tuning (PEFT) approach for Large Language Models (LLMs). UORA achieves state-of-the-art performance and parameter efficiency by leveraging a low-rank approximation method to reduce the numbe</span>
                
                <span class="abstract-full" style="display: none;">This paper introduces Uniform Orthogonal Reinitialization Adaptation (UORA), a novel parameter-efficient fine-tuning (PEFT) approach for Large Language Models (LLMs). UORA achieves state-of-the-art performance and parameter efficiency by leveraging a low-rank approximation method to reduce the number of trainable parameters. Unlike existing methods such as LoRA and VeRA, UORA employs an interpolation-based reparametrization mechanism that selectively reinitializes rows and columns in frozen projection matrices, guided by the vector magnitude heuristic. This results in substantially fewer trainable parameters compared to LoRA and outperforms VeRA in computation and storage efficiency. Comprehensive experiments across various benchmarks demonstrate UORA's superiority in achieving competitive fine-tuning performance with negligible computational overhead. We demonstrate its performance on GLUE and E2E benchmarks and its effectiveness in instruction-tuning large language models and image classification models. Our contributions establish a new paradigm for scalable and resource-efficient fine-tuning of LLMs.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 22.0%">
                            LLMs
                        </span>
                <!-- Computer Vision: 2.7 -->
                    
                <!-- Medicine: 2.6 -->
                    
                <!-- Datasets: 1.9 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- T2I: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.2115
                </span>
                <a href="https://arxiv.org/abs/2505.19676" target="_blank" rel="noopener noreferrer">Large Language Models' Reasoning Stalls: An Investigation into the Capabilities of Frontier Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Lachlan McGinness, Peter Baumgartner
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Empirical methods to examine the capability of Large Language Models (LLMs) to use Automated Theorem Prover (ATP) reasoning strategies are studied. We evaluate the performance of State of the Art models from December 2023 and August 2024 on PRONTOQA steamroller reasoning problems. For that, we devel</span>
                
                <span class="abstract-full" style="display: none;">Empirical methods to examine the capability of Large Language Models (LLMs) to use Automated Theorem Prover (ATP) reasoning strategies are studied. We evaluate the performance of State of the Art models from December 2023 and August 2024 on PRONTOQA steamroller reasoning problems. For that, we develop methods for assessing LLM response accuracy and correct answer correlation.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 27.5%">
                            LLMs
                        </span>
                <!-- Medicine: 3.0 -->
                    
                <!-- Federated Learning: 2.6 -->
                    
                <!-- Computer Vision: 2.2 -->
                    
                <!-- Bayesian Optimization: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.4339
                </span>
                <a href="https://arxiv.org/abs/2505.13061" target="_blank" rel="noopener noreferrer">3D Visual Illusion Depth Estimation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Chengtang Yao, Zhidan Liu, Jiaxi Zeng, Lidong Yu, Yuwei Wu, Yunde Jia
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">3D visual illusion is a perceptual phenomenon where a two-dimensional plane is manipulated to simulate three-dimensional spatial relationships, making a flat artwork or object look three-dimensional in the human visual system. In this paper, we reveal that the machine visual system is also seriously</span>
                
                <span class="abstract-full" style="display: none;">3D visual illusion is a perceptual phenomenon where a two-dimensional plane is manipulated to simulate three-dimensional spatial relationships, making a flat artwork or object look three-dimensional in the human visual system. In this paper, we reveal that the machine visual system is also seriously fooled by 3D visual illusions, including monocular and binocular depth estimation. In order to explore and analyze the impact of 3D visual illusion on depth estimation, we collect a large dataset containing almost 3k scenes and 200k images to train and evaluate SOTA monocular and binocular depth estimation methods. We also propose a robust depth estimation framework that uses common sense from a vision-language model to adaptively select reliable depth from binocular disparity and monocular depth. Experiments show that SOTA monocular, binocular, and multi-view depth estimation approaches are all fooled by various 3D visual illusions, while our method achieves SOTA performance.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #76aa96" title="Confidence: 5.1%">
                            3D
                        </span>
                <!-- LLMs: 4.8 -->
                    
                <!-- Medicine: 3.8 -->
                    
                <!-- Computer Vision: 2.1 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Datasets: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.5945
                </span>
                <a href="https://arxiv.org/abs/2505.20129" target="_blank" rel="noopener noreferrer">Agentic 3D Scene Generation with Spatially Contextualized VLMs</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Xinhang Liu, Yu-Wing Tai, Chi-Keung Tang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Despite recent advances in multimodal content generation enabled by vision-language models (VLMs), their ability to reason about and generate structured 3D scenes remains largely underexplored. This limitation constrains their utility in spatially grounded tasks such as embodied AI, immersive simula</span>
                
                <span class="abstract-full" style="display: none;">Despite recent advances in multimodal content generation enabled by vision-language models (VLMs), their ability to reason about and generate structured 3D scenes remains largely underexplored. This limitation constrains their utility in spatially grounded tasks such as embodied AI, immersive simulations, and interactive 3D applications. We introduce a new paradigm that enables VLMs to generate, understand, and edit complex 3D environments by injecting a continually evolving spatial context. Constructed from multimodal input, this context consists of three components: a scene portrait that provides a high-level semantic blueprint, a semantically labeled point cloud capturing object-level geometry, and a scene hypergraph that encodes rich spatial relationships, including unary, binary, and higher-order constraints. Together, these components provide the VLM with a structured, geometry-aware working memory that integrates its inherent multimodal reasoning capabilities with structured 3D understanding for effective spatial reasoning. Building on this foundation, we develop an agentic 3D scene generation pipeline in which the VLM iteratively reads from and updates the spatial context. The pipeline features high-quality asset generation with geometric restoration, environment setup with automatic verification, and ergonomic adjustment guided by the scene hypergraph. Experiments show that our framework can handle diverse and challenging inputs, achieving a level of generalization not observed in prior work. Further results demonstrate that injecting spatial context enables VLMs to perform downstream tasks such as interactive scene editing and path planning, suggesting strong potential for spatially intelligent systems in computer graphics, 3D vision, and embodied applications.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.5%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #76aa96" title="Confidence: 6.7%">
                            3D
                        </span>
                <!-- Medicine: 4.1 -->
                    
                <!-- Datasets: 2.1 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- T2I: 1.1 -->
                    
                <!-- Hardware: 1.1 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.1225
                </span>
                <a href="https://arxiv.org/abs/2505.19501" target="_blank" rel="noopener noreferrer">Genome-Bench: A Scientific Reasoning Benchmark from Real-World Expert Discussions</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ming Yin, Yuanhao Qu, Dyllan Liu, Ling Yang, Le Cong, Mengdi Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In this short report, we present an automated pipeline tailored for the genomics domain and introduce \textit{Genome-Bench}, a new benchmark constructed from over a decade of scientific forum discussions on genome engineering. Our pipeline transforms raw interactions into a reinforcement learning fr</span>
                
                <span class="abstract-full" style="display: none;">In this short report, we present an automated pipeline tailored for the genomics domain and introduce \textit{Genome-Bench}, a new benchmark constructed from over a decade of scientific forum discussions on genome engineering. Our pipeline transforms raw interactions into a reinforcement learning friendly multiple-choice questions format, supported by 3000+ high quality question answer pairs spanning foundational biology, experimental troubleshooting, tool usage, and beyond. To our knowledge, this is the first end-to-end pipeline for teaching LLMs to reason from scientific discussions, with promising potential for generalization across scientific domains beyond biology.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.2%">
                            Medicine
                        </span>
                <!-- LLMs: 4.7 -->
                    
                <!-- Computer Vision: 2.5 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- Quantum Computing: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- HPO and AutoML: 1.9 -->
                    
                <!-- 3D: 1.8 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.1676
                </span>
                <a href="https://arxiv.org/abs/2503.12183" target="_blank" rel="noopener noreferrer">Bridging Textual-Collaborative Gap through Semantic Codes for Sequential Recommendation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Enze Liu, Bowen Zheng, Wayne Xin Zhao, Ji-Rong Wen
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In recent years, substantial research efforts have been devoted to enhancing sequential recommender systems by integrating abundant side information with ID-based collaborative information. This study specifically focuses on leveraging the textual metadata (e.g., titles and brands) associated with i</span>
                
                <span class="abstract-full" style="display: none;">In recent years, substantial research efforts have been devoted to enhancing sequential recommender systems by integrating abundant side information with ID-based collaborative information. This study specifically focuses on leveraging the textual metadata (e.g., titles and brands) associated with items. While existing methods have achieved notable success by combining text and ID representations, they often struggle to strike a balance between textual information embedded in text representations and collaborative information from sequential patterns of user behavior. In light of this, we propose CCFRec, a novel Code-based textual and Collaborative semantic Fusion method for sequential Recommendation. The key idea behind our approach is to bridge the gap between textual and collaborative information using semantic codes. Specifically, we generate fine-grained semantic codes from multi-view text embeddings through vector quantization techniques. Subsequently, we develop a code-guided semantic-fusion module based on the cross-attention mechanism to flexibly extract and integrate relevant information from text representations. In order to further enhance the fusion of textual and collaborative semantics, we introduce an optimization strategy that employs code masking with two specific objectives: masked code modeling and masked sequence alignment. The merit of these objectives lies in leveraging mask prediction tasks and augmented item representations to capture code correlations within individual items and enhance the sequence modeling of the recommendation backbone. Extensive experiments conducted on four public datasets demonstrate the superiority of CCFRec, showing significant improvements over various sequential recommendation models. Our code is available at https://github.com/RUCAIBox/CCFRec.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.1%">
                            Medicine
                        </span>
                <!-- LLMs: 4.3 -->
                    
                <!-- Computer Vision: 2.5 -->
                    
                <!-- Federated Learning: 2.5 -->
                    
                <!-- GNN: 2.3 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.169
                </span>
                <a href="https://arxiv.org/abs/2505.18956" target="_blank" rel="noopener noreferrer">How Do Images Align and Complement LiDAR? Towards a Harmonized Multi-modal 3D Panoptic Segmentation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yining Pan, Qiongjie Cui, Xulei Yang, Na Zhao
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">LiDAR-based 3D panoptic segmentation often struggles with the inherent sparsity of data from LiDAR sensors, which makes it challenging to accurately recognize distant or small objects. Recently, a few studies have sought to overcome this challenge by integrating LiDAR inputs with camera images, leve</span>
                
                <span class="abstract-full" style="display: none;">LiDAR-based 3D panoptic segmentation often struggles with the inherent sparsity of data from LiDAR sensors, which makes it challenging to accurately recognize distant or small objects. Recently, a few studies have sought to overcome this challenge by integrating LiDAR inputs with camera images, leveraging the rich and dense texture information provided by the latter. While these approaches have shown promising results, they still face challenges, such as misalignment during data augmentation and the reliance on post-processing steps. To address these issues, we propose Image-Assists-LiDAR (IAL), a novel multi-modal 3D panoptic segmentation framework. In IAL, we first introduce a modality-synchronized data augmentation strategy, PieAug, to ensure alignment between LiDAR and image inputs from the start. Next, we adopt a transformer decoder to directly predict panoptic segmentation results. To effectively fuse LiDAR and image features into tokens for the decoder, we design a Geometric-guided Token Fusion (GTF) module. Additionally, we leverage the complementary strengths of each modality as priors for query initialization through a Prior-based Query Generation (PQG) module, enhancing the decoder's ability to generate accurate instance masks. Our IAL framework achieves state-of-the-art performance compared to previous multi-modal 3D panoptic segmentation methods on two widely used benchmarks. Code and models are publicly available at .</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.1%">
                            Medicine
                        </span>
                <!-- 3D: 3.5 -->
                    
                <!-- Computer Vision: 3.0 -->
                    
                <!-- GNN: 2.8 -->
                    
                <!-- Federated Learning: 2.3 -->
                    
                <!-- LLMs: 2.1 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.1885
                </span>
                <a href="https://arxiv.org/abs/2505.13069" target="_blank" rel="noopener noreferrer">Suicide Risk Assessment Using Multimodal Speech Features: A Study on the SW1 Challenge Dataset</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ambre Marie, Ilias Maoudj, Guillaume Dardenne, Gwenol\'e Quellec
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The 1st SpeechWellness Challenge conveys the need for speech-based suicide risk assessment in adolescents. This study investigates a multimodal approach for this challenge, integrating automatic transcription with WhisperX, linguistic embeddings from Chinese RoBERTa, and audio embeddings from WavLM.</span>
                
                <span class="abstract-full" style="display: none;">The 1st SpeechWellness Challenge conveys the need for speech-based suicide risk assessment in adolescents. This study investigates a multimodal approach for this challenge, integrating automatic transcription with WhisperX, linguistic embeddings from Chinese RoBERTa, and audio embeddings from WavLM. Additionally, handcrafted acoustic features -- including MFCCs, spectral contrast, and pitch-related statistics -- were incorporated. We explored three fusion strategies: early concatenation, modality-specific processing, and weighted attention with mixup regularization. Results show that weighted attention provided the best generalization, achieving 69% accuracy on the development set, though a performance gap between development and test sets highlights generalization challenges. Our findings, strictly tied to the MINI-KID framework, emphasize the importance of refining embedding representations and fusion mechanisms to enhance classification reliability.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.5%">
                            Medicine
                        </span>
                <!-- LLMs: 3.2 -->
                    
                <!-- Computer Vision: 2.5 -->
                    
                <!-- Blockchain: 2.0 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- 3D: 1.1 -->
                    
                <!-- Datasets: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.2219
                </span>
                <a href="https://arxiv.org/abs/2505.10034" target="_blank" rel="noopener noreferrer">The First MPDD Challenge: Multimodal Personality-aware Depression Detection</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Changzeng Fu, Zelin Fu, Xinhe Kuang, Jiacheng Dong, Qi Zhang, Kaifeng Su, Yikai Su, Wenbo Shi, Junfeng Yao, Yuliang Zhao, Shiqi Zhao, Jiadong Wang, Siyang Song, Chaoran Liu, Yuichiro Yoshikawa, Bj\"orn Schuller, Hiroshi Ishiguro
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Depression is a widespread mental health issue affecting diverse age groups, with notable prevalence among college students and the elderly. However, existing datasets and detection methods primarily focus on young adults, neglecting the broader age spectrum and individual differences that influence</span>
                
                <span class="abstract-full" style="display: none;">Depression is a widespread mental health issue affecting diverse age groups, with notable prevalence among college students and the elderly. However, existing datasets and detection methods primarily focus on young adults, neglecting the broader age spectrum and individual differences that influence depression manifestation. Current approaches often establish a direct mapping between multimodal data and depression indicators, failing to capture the complexity and diversity of depression across individuals. This challenge includes two tracks based on age-specific subsets: Track 1 uses the MPDD-Elderly dataset for detecting depression in older adults, and Track 2 uses the MPDD-Young dataset for detecting depression in younger participants. The Multimodal Personality-aware Depression Detection (MPDD) Challenge aims to address this gap by incorporating multimodal data alongside individual difference factors. We provide a baseline model that fuses audio and video modalities with individual difference information to detect depression manifestations in diverse populations. This challenge aims to promote the development of more personalized and accurate de pression detection methods, advancing mental health research and fostering inclusive detection systems. More details are available on the official challenge website: https://hacilab.github.io/MPDDChallenge.github.io.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.3%">
                            Medicine
                        </span>
                <!-- LLMs: 4.3 -->
                    
                <!-- Computer Vision: 3.6 -->
                    
                <!-- Datasets: 2.0 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- 3D: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.2276
                </span>
                <a href="https://arxiv.org/abs/2505.12266" target="_blank" rel="noopener noreferrer">PMQ-VE: Progressive Multi-Frame Quantization for Video Enhancement</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: ZhanFeng Feng, Long Peng, Xin Di, Yong Guo, Wenbo Li, Yulun Zhang, Renjing Pei, Yang Wang, Yang Cao, Zheng-Jun Zha
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Multi-frame video enhancement tasks aim to improve the spatial and temporal resolution and quality of video sequences by leveraging temporal information from multiple frames, which are widely used in streaming video processing, surveillance, and generation. Although numerous Transformer-based enhanc</span>
                
                <span class="abstract-full" style="display: none;">Multi-frame video enhancement tasks aim to improve the spatial and temporal resolution and quality of video sequences by leveraging temporal information from multiple frames, which are widely used in streaming video processing, surveillance, and generation. Although numerous Transformer-based enhancement methods have achieved impressive performance, their computational and memory demands hinder deployment on edge devices. Quantization offers a practical solution by reducing the bit-width of weights and activations to improve efficiency. However, directly applying existing quantization methods to video enhancement tasks often leads to significant performance degradation and loss of fine details. This stems from two limitations: (a) inability to allocate varying representational capacity across frames, which results in suboptimal dynamic range adaptation; (b) over-reliance on full-precision teachers, which limits the learning of low-bit student models. To tackle these challenges, we propose a novel quantization method for video enhancement: Progressive Multi-Frame Quantization for Video Enhancement (PMQ-VE). This framework features a coarse-to-fine two-stage process: Backtracking-based Multi-Frame Quantization (BMFQ) and Progressive Multi-Teacher Distillation (PMTD). BMFQ utilizes a percentile-based initialization and iterative search with pruning and backtracking for robust clipping bounds. PMTD employs a progressive distillation strategy with both full-precision and multiple high-bit (INT) teachers to enhance low-bit models' capacity and quality. Extensive experiments demonstrate that our method outperforms existing approaches, achieving state-of-the-art performance across multiple tasks and benchmarks.The code will be made publicly available at: https://github.com/xiaoBIGfeng/PMQ-VE.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.5%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.1%">
                            Medicine
                        </span>
                <!-- Computer Vision: 2.9 -->
                    
                <!-- 3D: 2.5 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.2544
                </span>
                <a href="https://arxiv.org/abs/2505.19028" target="_blank" rel="noopener noreferrer">InfoChartQA: A Benchmark for Multimodal Question Answering on Infographic Charts</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Minzhi Lin, Tianchi Xie, Mengchen Liu, Yilin Ye, Changjian Chen, Shixia Liu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Understanding infographic charts with design-driven visual elements (e.g., pictograms, icons) requires both visual recognition and reasoning, posing challenges for multimodal large language models (MLLMs). However, existing visual-question answering benchmarks fall short in evaluating these capabili</span>
                
                <span class="abstract-full" style="display: none;">Understanding infographic charts with design-driven visual elements (e.g., pictograms, icons) requires both visual recognition and reasoning, posing challenges for multimodal large language models (MLLMs). However, existing visual-question answering benchmarks fall short in evaluating these capabilities of MLLMs due to the lack of paired plain charts and visual-element-based questions. To bridge this gap, we introduce InfoChartQA, a benchmark for evaluating MLLMs on infographic chart understanding. It includes 5,642 pairs of infographic and plain charts, each sharing the same underlying data but differing in visual presentations. We further design visual-element-based questions to capture their unique visual designs and communicative intent. Evaluation of 20 MLLMs reveals a substantial performance decline on infographic charts, particularly for visual-element-based questions related to metaphors. The paired infographic and plain charts enable fine-grained error analysis and ablation studies, which highlight new opportunities for advancing MLLMs in infographic chart understanding. We release InfoChartQA at https://github.com/CoolDawnAnt/InfoChartQA.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.2%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.0%">
                            Medicine
                        </span>
                <!-- Hardware: 3.0 -->
                    
                <!-- Computer Vision: 2.4 -->
                    
                <!-- Datasets: 2.1 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- 3D: 1.0 -->
                    
                <!-- T2I: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.2871
                </span>
                <a href="https://arxiv.org/abs/2501.13392" target="_blank" rel="noopener noreferrer">Time Series Embedding Methods for Classification Tasks: A Review</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Habib Irani, Yasamin Ghahremani, Arshia Kermani, Vangelis Metsis
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Time series analysis has become crucial in various fields, from engineering and finance to healthcare and social sciences. Due to their multidimensional nature, time series often need to be embedded into a fixed-dimensional feature space to enable processing with various machine learning algorithms.</span>
                
                <span class="abstract-full" style="display: none;">Time series analysis has become crucial in various fields, from engineering and finance to healthcare and social sciences. Due to their multidimensional nature, time series often need to be embedded into a fixed-dimensional feature space to enable processing with various machine learning algorithms. In this paper, we present a comprehensive review and quantitative evaluation of time series embedding methods for effective representations in machine learning and deep learning models. We introduce a taxonomy of embedding techniques, categorizing them based on their theoretical foundations and application contexts. Our work provides a quantitative evaluation of representative methods from each category by assessing their performance on downstream classification tasks across diverse real-world datasets. Our experimental results demonstrate that the performance of embedding methods varies significantly depending on the dataset and classification algorithm used, highlighting the importance of careful model selection and extensive experimentation for specific applications. To facilitate further research and practical applications, we provide an open-source code repository implementing these embedding methods. This study contributes to the field by offering a systematic comparison of time series embedding techniques, guiding practitioners in selecting appropriate methods for their specific applications, and providing a foundation for future advancements in time series analysis.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.0%">
                            Medicine
                        </span>
                <!-- LLMs: 4.5 -->
                    
                <!-- Federated Learning: 3.4 -->
                    
                <!-- Evolutionary Algorithms: 2.6 -->
                    
                <!-- Computer Vision: 2.2 -->
                    
                <!-- Datasets: 1.7 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.3872
                </span>
                <a href="https://arxiv.org/abs/2505.18833" target="_blank" rel="noopener noreferrer">Supermartingale Certificates for Quantitative Omega-regular Verification and Control</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Thomas A. Henzinger (Institute of Science and Technology Austria), Kaushik Mallik (IMDEA Software Institute), Pouya Sadeghi (Singapore Management University), {\DJ}or{\dj}e \v{Z}ikeli\'c (Singapore Management University)
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We present the first supermartingale certificate for quantitative $\omega$-regular properties of discrete-time infinite-state stochastic systems. Our certificate is defined on the product of the stochastic system and a limit-deterministic B\"uchi automaton that specifies the property of interest; he</span>
                
                <span class="abstract-full" style="display: none;">We present the first supermartingale certificate for quantitative $\omega$-regular properties of discrete-time infinite-state stochastic systems. Our certificate is defined on the product of the stochastic system and a limit-deterministic B\"uchi automaton that specifies the property of interest; hence we call it a limit-deterministic B\"uchi supermartingale (LDBSM). Previously known supermartingale certificates applied only to quantitative reachability, safety, or reach-avoid properties, and to qualitative (i.e., probability 1) $\omega$-regular properties. We also present fully automated algorithms for the template-based synthesis of LDBSMs, for the case when the stochastic system dynamics and the controller can be represented in terms of polynomial inequalities. Our experiments demonstrate the ability of our method to solve verification and control tasks for stochastic systems that were beyond the reach of previous supermartingale-based approaches.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.1%">
                            Medicine
                        </span>
                <!-- LLMs: 2.8 -->
                    
                <!-- Federated Learning: 2.5 -->
                    
                <!-- Bayesian Optimization: 2.4 -->
                    
                <!-- Quantum Computing: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 2.2 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- Math: 1.5 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.3956
                </span>
                <a href="https://arxiv.org/abs/2505.18194" target="_blank" rel="noopener noreferrer">Large Language Model-Driven Distributed Integrated Multimodal Sensing and Semantic Communications</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yubo Peng, Luping Xiang, Bingxin Zhang, Kun Yang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Traditional single-modal sensing systems-based solely on either radio frequency (RF) or visual data-struggle to cope with the demands of complex and dynamic environments. Furthermore, single-device systems are constrained by limited perspectives and insufficient spatial coverage, which impairs their</span>
                
                <span class="abstract-full" style="display: none;">Traditional single-modal sensing systems-based solely on either radio frequency (RF) or visual data-struggle to cope with the demands of complex and dynamic environments. Furthermore, single-device systems are constrained by limited perspectives and insufficient spatial coverage, which impairs their effectiveness in urban or non-line-of-sight scenarios. To overcome these challenges, we propose a novel large language model (LLM)-driven distributed integrated multimodal sensing and semantic communication (LLM-DiSAC) framework. Specifically, our system consists of multiple collaborative sensing devices equipped with RF and camera modules, working together with an aggregation center to enhance sensing accuracy. First, on sensing devices, LLM-DiSAC develops an RF-vision fusion network (RVFN), which employs specialized feature extractors for RF and visual data, followed by a cross-attention module for effective multimodal integration. Second, a LLM-based semantic transmission network (LSTN) is proposed to enhance communication efficiency, where the LLM-based decoder leverages known channel parameters, such as transceiver distance and signal-to-noise ratio (SNR), to mitigate semantic distortion. Third, at the aggregation center, a transformer-based aggregation model (TRAM) with an adaptive aggregation attention mechanism is developed to fuse distributed features and enhance sensing accuracy. To preserve data privacy, a two-stage distributed learning strategy is introduced, allowing local model training at the device level and centralized aggregation model training using intermediate features. Finally, evaluations on a synthetic multi-view RF-visual dataset generated by the Genesis simulation engine show that LLM-DiSAC achieves a good performance.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.5%">
                            Medicine
                        </span>
                <!-- LLMs: 3.5 -->
                    
                <!-- Computer Vision: 2.7 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- GNN: 2.1 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4304
                </span>
                <a href="https://arxiv.org/abs/2505.19301" target="_blank" rel="noopener noreferrer">A Novel Zero-Trust Identity Framework for Agentic AI: Decentralized Authentication and Fine-Grained Access Control</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ken Huang, Vineeth Sai Narajala, John Yeoh, Ramesh Raskar, Youssef Harkati, Jerry Huang, Idan Habler, Chris Hughes
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Traditional Identity and Access Management (IAM) systems, primarily designed for human users or static machine identities via protocols such as OAuth, OpenID Connect (OIDC), and SAML, prove fundamentally inadequate for the dynamic, interdependent, and often ephemeral nature of AI agents operating at</span>
                
                <span class="abstract-full" style="display: none;">Traditional Identity and Access Management (IAM) systems, primarily designed for human users or static machine identities via protocols such as OAuth, OpenID Connect (OIDC), and SAML, prove fundamentally inadequate for the dynamic, interdependent, and often ephemeral nature of AI agents operating at scale within Multi Agent Systems (MAS), a computational system composed of multiple interacting intelligent agents that work collectively.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.0%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.2%">
                            LLMs
                        </span>
                <!-- Hardware: 3.2 -->
                    
                <!-- Blockchain: 2.8 -->
                    
                <!-- Quantum Computing: 2.3 -->
                    
                <!-- Computer Vision: 2.0 -->
                    
                <!-- HPO and AutoML: 1.9 -->
                    
                <!-- Datasets: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Federated Learning: 1.6 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4325
                </span>
                <a href="https://arxiv.org/abs/2408.15619" target="_blank" rel="noopener noreferrer">Multi-Graph Inductive Representation Learning for Large-Scale Urban Rail Demand Prediction under Disruptions</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Dang Viet Anh Nguyen, J. Victor Flensburg, Fabrizio Cerreto, Bianca Pascariu, Paola Pellegrini, Carlos Lima Azevedo, Filipe Rodrigues
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">With the expansion of cities over time, URT (Urban Rail Transit) networks have also grown significantly. Demand prediction plays an important role in supporting planning, scheduling, fleet management, and other operational decisions. In this study, we propose an Origin-Destination (OD) demand predic</span>
                
                <span class="abstract-full" style="display: none;">With the expansion of cities over time, URT (Urban Rail Transit) networks have also grown significantly. Demand prediction plays an important role in supporting planning, scheduling, fleet management, and other operational decisions. In this study, we propose an Origin-Destination (OD) demand prediction model called Multi-Graph Inductive Representation Learning (mGraphSAGE) for large-scale URT networks under operational uncertainties. Our main contributions are twofold: we enhance prediction results while ensuring scalability for large networks by relying simultaneously on multiple graphs, where each OD pair is a node on a graph and distinct OD relationships, such as temporal and spatial correlations; we show the importance of including operational uncertainties such as train delays and cancellations as inputs in demand prediction for daily operations. The model is validated on three different scales of the URT network in Copenhagen, Denmark. Experimental results show that by leveraging information from neighboring ODs and learning node representations via sampling and aggregation, mGraphSAGE is particularly suitable for OD demand prediction in large-scale URT networks, outperforming reference machine learning methods. Furthermore, during periods with train cancellations and delays, the performance gap between mGraphSAGE and other methods improves compared to normal operating conditions, demonstrating its ability to leverage system reliability information for predicting OD demand under uncertainty.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.7%">
                            Medicine
                        </span>
                <!-- LLMs: 2.8 -->
                    
                <!-- GNN: 2.7 -->
                    
                <!-- Computer Vision: 2.5 -->
                    
                <!-- Hardware: 2.3 -->
                    
                <!-- HPO and AutoML: 2.1 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4703
                </span>
                <a href="https://arxiv.org/abs/2503.10981" target="_blank" rel="noopener noreferrer">Unlocking Text Capabilities in Vision Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Fawaz Sammani, Jonas Fischer, Nikos Deligiannis
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Visual classifiers provide high-dimensional feature representations that are challenging to interpret and analyze. Text, in contrast, provides a more expressive and human-friendly interpretable medium for understanding and analyzing model behavior. We propose a simple, yet powerful method for reform</span>
                
                <span class="abstract-full" style="display: none;">Visual classifiers provide high-dimensional feature representations that are challenging to interpret and analyze. Text, in contrast, provides a more expressive and human-friendly interpretable medium for understanding and analyzing model behavior. We propose a simple, yet powerful method for reformulating any pretrained visual classifier so that it can be queried with free-form text without compromising its original performance. Our approach is label-free, data and compute-efficient, and is trained to preserve the underlying classifiers distribution and decision-making processes. Our method unlocks several zero-shot text interpretability applications for any visual classifier. We apply our method on 40 visual classifiers and demonstrate two primary applications: 1) building both label-free and zero-shot concept bottleneck models and therefore converting any visual classifier to be inherently-interpretable and 2) zero-shot decoding of visual features into natural language sentences. In both tasks we establish new state-of-the-art results, outperforming existing works and surpassing CLIP-based baselines with ImageNet-only trained classifiers, while using up to 400x fewer images and 400,000x less text during training.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 11.8%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.0%">
                            Medicine
                        </span>
                <!-- Computer Vision: 3.0 -->
                    
                <!-- Decision Trees: 2.5 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- T2I: 1.4 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4763
                </span>
                <a href="https://arxiv.org/abs/2502.03393" target="_blank" rel="noopener noreferrer">CAPE: Covariate-Adjusted Pre-Training for Generalized Epidemic Time Series Forecasting</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zewen Liu, Juntong Ni, Max S. Y. Lau, Wei Jin
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Accurate forecasting of epidemic infection trajectories is crucial for safeguarding public health. However, limited data availability during emerging outbreaks and the complex interaction between environmental factors and disease dynamics present significant challenges for effective forecasting. In </span>
                
                <span class="abstract-full" style="display: none;">Accurate forecasting of epidemic infection trajectories is crucial for safeguarding public health. However, limited data availability during emerging outbreaks and the complex interaction between environmental factors and disease dynamics present significant challenges for effective forecasting. In response, we introduce CAPE, a novel epidemic pre-training framework designed to harness extensive disease datasets from diverse regions and integrate environmental factors directly into the modeling process for more informed decision-making on downstream diseases. Based on a covariate adjustment framework, CAPE utilizes pre-training combined with hierarchical environment contrasting to identify universal patterns across diseases while estimating latent environmental influences. We have compiled a diverse collection of epidemic time series datasets and validated the effectiveness of CAPE under various evaluation scenarios, including full-shot, few-shot, zero-shot, cross-location, and cross-disease settings, where it outperforms the leading baseline by an average of 9.9% in full-shot and 14.3% in zero-shot settings.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.4%">
                            Medicine
                        </span>
                <!-- LLMs: 4.3 -->
                    
                <!-- Hardware: 2.2 -->
                    
                <!-- Blockchain: 2.2 -->
                    
                <!-- Computer Vision: 2.1 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- 3D: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.5516
                </span>
                <a href="https://arxiv.org/abs/2505.20132" target="_blank" rel="noopener noreferrer">Tensorization is a powerful but underexplored tool for compression and interpretability of neural networks</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Safa Hamreras, Sukhbinder Singh, Rom\'an Or\'us
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Tensorizing a neural network involves reshaping some or all of its dense weight matrices into higher-order tensors and approximating them using low-rank tensor network decompositions. This technique has shown promise as a model compression strategy for large-scale neural networks. However, despite e</span>
                
                <span class="abstract-full" style="display: none;">Tensorizing a neural network involves reshaping some or all of its dense weight matrices into higher-order tensors and approximating them using low-rank tensor network decompositions. This technique has shown promise as a model compression strategy for large-scale neural networks. However, despite encouraging empirical results, tensorized neural networks (TNNs) remain underutilized in mainstream deep learning. In this position paper, we offer a perspective on both the potential and current limitations of TNNs. We argue that TNNs represent a powerful yet underexplored framework for deep learning--one that deserves greater attention from both engineering and theoretical communities. Beyond compression, we highlight the value of TNNs as a flexible class of architectures with distinctive scaling properties and increased interpretability. A central feature of TNNs is the presence of bond indices, which introduce new latent spaces not found in conventional networks. These internal representations may provide deeper insight into the evolution of features across layers, potentially advancing the goals of mechanistic interpretability. We conclude by outlining several key research directions aimed at overcoming the practical barriers to scaling and adopting TNNs in modern deep learning workflows.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.2%">
                            Medicine
                        </span>
                <!-- LLMs: 3.5 -->
                    
                <!-- Quantum Computing: 2.1 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Datasets: 1.9 -->
                    
                <!-- GNN: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.4 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.6195
                </span>
                <a href="https://arxiv.org/abs/2505.19785" target="_blank" rel="noopener noreferrer">MedDreamer: Model-Based Reinforcement Learning with Latent Imagination on Complex EHRs for Clinical Decision Support</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Qianyi Xu, Gousia Habib, Dilruk Perera, Mengling Feng
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Timely and personalized treatment decisions are essential across a wide range of healthcare settings where patient responses vary significantly and evolve over time. Clinical data used to support these decisions are often irregularly sampled, sparse, and noisy. Existing decision support systems comm</span>
                
                <span class="abstract-full" style="display: none;">Timely and personalized treatment decisions are essential across a wide range of healthcare settings where patient responses vary significantly and evolve over time. Clinical data used to support these decisions are often irregularly sampled, sparse, and noisy. Existing decision support systems commonly rely on discretization and imputation, which can distort critical temporal dynamics and degrade decision quality. Moreover, they often overlook the clinical significance of irregular recording frequencies, filtering out patterns in how and when data is collected. Reinforcement Learning (RL) is a natural fit for clinical decision-making, enabling sequential, long-term optimization in dynamic, uncertain environments. However, most existing treatment recommendation systems are model-free and trained solely on offline data, making them sample-inefficient, sensitive to data quality, and poorly generalizable across tasks or cohorts. To address these limitations, we propose MedDreamer, a two-phase model-based RL framework for personalized treatment recommendation. MedDreamer uses a world model with an Adaptive Feature Integration (AFI) module to effectively model irregular, sparse clinical data. Through latent imagination, it simulates plausible patient trajectories to enhance learning, refining its policy using a mix of real and imagined experiences. This enables learning policies that go beyond suboptimal historical decisions while remaining grounded in clinical data. To our knowledge, this is the first application of latent imagination to irregular healthcare data. Evaluations on sepsis and mechanical ventilation (MV) treatment using two large-scale EHR datasets show that MedDreamer outperforms both model-free and model-based baselines in clinical outcomes and off-policy metrics.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 8.1%">
                            Medicine
                        </span>
                <!-- LLMs: 4.7 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.6213
                </span>
                <a href="https://arxiv.org/abs/2406.18815" target="_blank" rel="noopener noreferrer">MissionGNN: Hierarchical Multimodal GNN-based Weakly Supervised Video Anomaly Recognition with Mission-Specific Knowledge Graph Generation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Sanggeon Yun, Ryozo Masukawa, Minhyoung Na, Mohsen Imani
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In the context of escalating safety concerns across various domains, the tasks of Video Anomaly Detection (VAD) and Video Anomaly Recognition (VAR) have emerged as critically important for applications in intelligent surveillance, evidence investigation, violence alerting, etc. These tasks, aimed at</span>
                
                <span class="abstract-full" style="display: none;">In the context of escalating safety concerns across various domains, the tasks of Video Anomaly Detection (VAD) and Video Anomaly Recognition (VAR) have emerged as critically important for applications in intelligent surveillance, evidence investigation, violence alerting, etc. These tasks, aimed at identifying and classifying deviations from normal behavior in video data, face significant challenges due to the rarity of anomalies which leads to extremely imbalanced data and the impracticality of extensive frame-level data annotation for supervised learning. This paper introduces a novel hierarchical graph neural network (GNN) based model MissionGNN that addresses these challenges by leveraging a state-of-the-art large language model and a comprehensive knowledge graph for efficient weakly supervised learning in VAR. Our approach circumvents the limitations of previous methods by avoiding heavy gradient computations on large multimodal models and enabling fully frame-level training without fixed video segmentation. Utilizing automated, mission-specific knowledge graph generation, our model provides a practical and efficient solution for real-time video analysis without the constraints of previous segmentation-based or multimodal approaches. Experimental validation on benchmark datasets demonstrates our model's performance in VAD and VAR, highlighting its potential to redefine the landscape of anomaly detection and recognition in video surveillance systems. The code is available here: https://github.com/c0510gy/MissionGNN.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.3%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.2%">
                            LLMs
                        </span>
                <!-- Computer Vision: 2.4 -->
                    
                <!-- GNN: 2.1 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Datasets: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.6623
                </span>
                <a href="https://arxiv.org/abs/2402.11495" target="_blank" rel="noopener noreferrer">Continuous Multi-Task Pre-training for Malicious URL Detection and Webpage Classification</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yujie Li, Yiwei Liu, Peiyue Li, Yifan Jia, Yanbin Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Malicious URL detection and webpage classification are critical tasks in cybersecurity and information management. In recent years, extensive research has explored using BERT or similar language models to replace traditional machine learning methods for detecting malicious URLs and classifying webpa</span>
                
                <span class="abstract-full" style="display: none;">Malicious URL detection and webpage classification are critical tasks in cybersecurity and information management. In recent years, extensive research has explored using BERT or similar language models to replace traditional machine learning methods for detecting malicious URLs and classifying webpages. While previous studies show promising results, they often apply existing language models to these tasks without accounting for the inherent differences in domain data (e.g., URLs being loosely structured and semantically sparse compared to text), leaving room for performance improvement. Furthermore, current approaches focus on single tasks and have not been tested in multi-task scenarios. To address these challenges, we propose urlBERT, a pre-trained URL encoder leveraging Transformer to encode foundational knowledge from billions of unlabeled URLs. To achieve it, we propose to use 5 unsupervised pretraining tasks to capture multi-level information of URL lexical, syntax, and semantics, and generate contrastive and adversarial representations. Furthermore, to avoid inter-pre-training competition and interference, we proposed a grouped sequential learning method to ensure effective training across multi-tasks. Finally, we leverage a two-stage fine-tuning approach to improve the training stability and efficiency of the task model. To assess the multitasking potential of urlBERT, we fine-tune the task model in both single-task and multi-task modes. The former creates a classification model for a single task, while the latter builds a classification model capable of handling multiple tasks. We evaluate urlBERT on three downstream tasks: phishing URL detection, advertising URL detection, and webpage classification. The results demonstrate that urlBERT outperforms standard pre-trained models, and its multi-task mode is capable of addressing the real-world demands of multitasking.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.9%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.9%">
                            Medicine
                        </span>
                <!-- Computer Vision: 3.1 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.7091
                </span>
                <a href="https://arxiv.org/abs/2505.19500" target="_blank" rel="noopener noreferrer">Objective, Absolute and Hue-aware Metrics for Intrinsic Image Decomposition on Real-World Scenes: A Proof of Concept</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Shogo Sato, Masaru Tsuchida, Mariko Yamaguchi, Takuhiro Kaneko, Kazuhiko Murasaki, Taiga Yoshida, Ryuichi Tanida
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Intrinsic image decomposition (IID) is the task of separating an image into albedo and shade. In real-world scenes, it is difficult to quantitatively assess IID quality due to the unavailability of ground truth. The existing method provides the relative reflection intensities based on human-judged a</span>
                
                <span class="abstract-full" style="display: none;">Intrinsic image decomposition (IID) is the task of separating an image into albedo and shade. In real-world scenes, it is difficult to quantitatively assess IID quality due to the unavailability of ground truth. The existing method provides the relative reflection intensities based on human-judged annotations. However, these annotations have challenges in subjectivity, relative evaluation, and hue non-assessment. To address these, we propose a concept of quantitative evaluation with a calculated albedo from a hyperspectral imaging and light detection and ranging (LiDAR) intensity. Additionally, we introduce an optional albedo densification approach based on spectral similarity. This paper conducted a concept verification in a laboratory environment, and suggested the feasibility of an objective, absolute, and hue-aware assessment. (This paper is accepted by IEEE ICIP 2025. )</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.3%">
                            Medicine
                        </span>
                <!-- LLMs: 3.9 -->
                    
                <!-- Federated Learning: 2.8 -->
                    
                <!-- Evolutionary Algorithms: 2.4 -->
                    
                <!-- Blockchain: 2.1 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.7129
                </span>
                <a href="https://arxiv.org/abs/2504.05634" target="_blank" rel="noopener noreferrer">Simplifying Data Integration: SLM-Driven Systems for Unified Semantic Queries Across Heterogeneous Databases</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Teng Lin
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The integration of heterogeneous databases into a unified querying framework remains a critical challenge, particularly in resource-constrained environments. This paper presents a novel Small Language Model(SLM)-driven system that synergizes advancements in lightweight Retrieval-Augmented Generation</span>
                
                <span class="abstract-full" style="display: none;">The integration of heterogeneous databases into a unified querying framework remains a critical challenge, particularly in resource-constrained environments. This paper presents a novel Small Language Model(SLM)-driven system that synergizes advancements in lightweight Retrieval-Augmented Generation (RAG) and semantic-aware data structuring to enable efficient, accurate, and scalable query resolution across diverse data formats. By integrating MiniRAG's semantic-aware heterogeneous graph indexing and topology-enhanced retrieval with SLM-powered structured data extraction, our system addresses the limitations of traditional methods in handling Multi-Entity Question Answering (Multi-Entity QA) and complex semantic queries. Experimental results demonstrate superior performance in accuracy and efficiency, while the introduction of semantic entropy as an unsupervised evaluation metric provides robust insights into model uncertainty. This work pioneers a cost-effective, domain-agnostic solution for next-generation database systems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.9%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.2%">
                            Medicine
                        </span>
                <!-- Hardware: 2.1 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Datasets: 1.8 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.7734
                </span>
                <a href="https://arxiv.org/abs/2505.19522" target="_blank" rel="noopener noreferrer">Applications and Effect Evaluation of Generative Adversarial Networks in Semi-Supervised Learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jiyu Hu, Haijiang Zeng, Zhen Tian
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In recent years, image classification, as a core task in computer vision, relies on high-quality labelled data, which restricts the wide application of deep learning models in practical scenarios. To alleviate the problem of insufficient labelled samples, semi-supervised learning has gradually becom</span>
                
                <span class="abstract-full" style="display: none;">In recent years, image classification, as a core task in computer vision, relies on high-quality labelled data, which restricts the wide application of deep learning models in practical scenarios. To alleviate the problem of insufficient labelled samples, semi-supervised learning has gradually become a research hotspot. In this paper, we construct a semi-supervised image classification model based on Generative Adversarial Networks (GANs), and through the introduction of the collaborative training mechanism of generators, discriminators and classifiers, we achieve the effective use of limited labelled data and a large amount of unlabelled data, improve the quality of image generation and classification accuracy, and provide an effective solution for the task of image recognition in complex environments.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.9%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.2%">
                            LLMs
                        </span>
                <!-- Federated Learning: 3.5 -->
                    
                <!-- Hardware: 2.3 -->
                    
                <!-- Blockchain: 2.1 -->
                    
                <!-- Datasets: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.8952
                </span>
                <a href="https://arxiv.org/abs/2505.19213" target="_blank" rel="noopener noreferrer">Improving Medical Reasoning with Curriculum-Aware Reinforcement Learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Shaohao Rui, Kaitao Chen, Weijie Ma, Xiaosong Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Recent advances in reinforcement learning with verifiable, rule-based rewards have greatly enhanced the reasoning capabilities and out-of-distribution generalization of VLMs/LLMs, obviating the need for manually crafted reasoning chains. Despite these promising developments in the general domain, th</span>
                
                <span class="abstract-full" style="display: none;">Recent advances in reinforcement learning with verifiable, rule-based rewards have greatly enhanced the reasoning capabilities and out-of-distribution generalization of VLMs/LLMs, obviating the need for manually crafted reasoning chains. Despite these promising developments in the general domain, their translation to medical imaging remains limited. Current medical reinforcement fine-tuning (RFT) methods predominantly focus on close-ended VQA, thereby restricting the model's ability to engage in world knowledge retrieval and flexible task adaptation. More critically, these methods fall short of addressing the critical clinical demand for open-ended, reasoning-intensive decision-making. To bridge this gap, we introduce \textbf{MedCCO}, the first multimodal reinforcement learning framework tailored for medical VQA that unifies close-ended and open-ended data within a curriculum-driven RFT paradigm. Specifically, MedCCO is initially fine-tuned on a diverse set of close-ended medical VQA tasks to establish domain-grounded reasoning capabilities, and is then progressively adapted to open-ended tasks to foster deeper knowledge enhancement and clinical interpretability. We validate MedCCO across eight challenging medical VQA benchmarks, spanning both close-ended and open-ended settings. Experimental results show that MedCCO consistently enhances performance and generalization, achieving a 11.4\% accuracy gain across three in-domain tasks, and a 5.7\% improvement on five out-of-domain benchmarks. These findings highlight the promise of curriculum-guided RL in advancing robust, clinically-relevant reasoning in medical multimodal language models.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 8.6%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.8%">
                            LLMs
                        </span>
                <!-- Computer Vision: 2.2 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.9058
                </span>
                <a href="https://arxiv.org/abs/2505.19540" target="_blank" rel="noopener noreferrer">Real-time Whole-body Model Predictive Control for Bipedal Locomotion with a Novel Kino-dynamic Model and Warm-start Method</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Junhyung Kim, Hokyun Lee, Jaeheung Park
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Advancements in optimization solvers and computing power have led to growing interest in applying whole-body model predictive control (WB-MPC) to bipedal robots. However, the high degrees of freedom and inherent model complexity of bipedal robots pose significant challenges in achieving fast and sta</span>
                
                <span class="abstract-full" style="display: none;">Advancements in optimization solvers and computing power have led to growing interest in applying whole-body model predictive control (WB-MPC) to bipedal robots. However, the high degrees of freedom and inherent model complexity of bipedal robots pose significant challenges in achieving fast and stable control cycles for real-time performance. This paper introduces a novel kino-dynamic model and warm-start strategy for real-time WB-MPC in bipedal robots. Our proposed kino-dynamic model combines the linear inverted pendulum plus flywheel and full-body kinematics model. Unlike the conventional whole-body model that rely on the concept of contact wrenches, our model utilizes the zero-moment point (ZMP), reducing baseline computational costs and ensuring consistently low latency during contact state transitions. Additionally, a modularized multi-layer perceptron (MLP) based warm-start strategy is proposed, leveraging a lightweight neural network to provide a good initial guess for each control cycle. Furthermore, we present a ZMP-based whole-body controller (WBC) that extends the existing WBC for explicitly controlling impulses and ZMP, integrating it into the real-time WB-MPC framework. Through various comparative experiments, the proposed kino-dynamic model and warm-start strategy have been shown to outperform previous studies. Simulations and real robot experiments further validate that the proposed framework demonstrates robustness to perturbation and satisfies real-time control requirements during walking.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.0%">
                            Medicine
                        </span>
                <!-- Computer Vision: 3.5 -->
                    
                <!-- LLMs: 3.2 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.9096
                </span>
                <a href="https://arxiv.org/abs/2505.19445" target="_blank" rel="noopener noreferrer">MetaGMT: Improving Actionable Interpretability of Graph Multilinear Networks via Meta-Learning Filtration</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Rishabh Bhattacharya, Hari Shankar, Vaishnavi Shivkumar, Ponnurangam Kumaraguru
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The growing adoption of Graph Neural Networks (GNNs) in high-stakes domains like healthcare and finance demands reliable explanations of their decision-making processes. While inherently interpretable GNN architectures like Graph Multi-linear Networks (GMT) have emerged, they remain vulnerable to ge</span>
                
                <span class="abstract-full" style="display: none;">The growing adoption of Graph Neural Networks (GNNs) in high-stakes domains like healthcare and finance demands reliable explanations of their decision-making processes. While inherently interpretable GNN architectures like Graph Multi-linear Networks (GMT) have emerged, they remain vulnerable to generating explanations based on spurious correlations, potentially undermining trust in critical applications. We present MetaGMT, a meta-learning framework that enhances explanation fidelity through a novel bi-level optimization approach. We demonstrate that MetaGMT significantly improves both explanation quality (AUC-ROC, Precision@K) and robustness to spurious patterns, across BA-2Motifs, MUTAG, and SP-Motif benchmarks. Our approach maintains competitive classification accuracy while producing more faithful explanations (with an increase up to 8% of Explanation ROC on SP-Motif 0.5) compared to baseline methods. These advancements in interpretability could enable safer deployment of GNNs in sensitive domains by (1) facilitating model debugging through more reliable explanations, (2) supporting targeted retraining when biases are identified, and (3) enabling meaningful human oversight. By addressing the critical challenge of explanation reliability, our work contributes to building more trustworthy and actionable GNN systems for real-world applications.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 10.0%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #b243cd" title="Confidence: 5.5%">
                            GNN
                        </span>
                <!-- Medicine: 2.2 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- 3D: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.9168
                </span>
                <a href="https://arxiv.org/abs/2412.16441" target="_blank" rel="noopener noreferrer">Towards Graph Foundation Models: Learning Generalities Across Graphs via Task-Trees</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zehong Wang, Zheyuan Zhang, Tianyi Ma, Nitesh V Chawla, Chuxu Zhang, Yanfang Ye
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Foundation models are pretrained on large-scale corpora to learn generalizable patterns across domains and tasks -- such as contours, textures, and edges in images, or tokens and sentences in text. In contrast, discovering such generalities in graph-structured data, especially across heterogeneous g</span>
                
                <span class="abstract-full" style="display: none;">Foundation models are pretrained on large-scale corpora to learn generalizable patterns across domains and tasks -- such as contours, textures, and edges in images, or tokens and sentences in text. In contrast, discovering such generalities in graph-structured data, especially across heterogeneous graph tasks, remains an open challenge. To address this, we propose a novel approach to cross-task generalization in graphs via task-trees, which serve as unified learning instances aligning node-, edge-, and graph-level tasks. We theoretically analyze the stability, transferability, and generalization properties of task-trees, showing that pretraining a graph neural network (GNN) on diverse task-trees with a reconstruction objective induces transferable knowledge. This enables efficient adaptation to downstream tasks with minimal fine-tuning. To validate our framework, we introduce Graph Generality Identifier on Task-Trees (GIT), a graph foundation model that demonstrates strong performance on over 30 graphs across five domains via fine-tuning, in-context learning, and zero-shot generalization. Code and data are available at https://github.com/Zehong-Wang/GIT.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.3%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #b243cd" title="Confidence: 5.6%">
                            GNN
                        </span>
                <!-- Computer Vision: 3.0 -->
                    
                <!-- Medicine: 2.7 -->
                    
                <!-- 3D: 2.2 -->
                    
                <!-- Blockchain: 2.0 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- T2I: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.9423
                </span>
                <a href="https://arxiv.org/abs/2505.20033" target="_blank" rel="noopener noreferrer">EmoNet-Face: An Expert-Annotated Benchmark for Synthetic Emotion Recognition</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Christoph Schuhmann, Robert Kaczmarczyk, Gollam Rabby, Maurice Kraus, Felix Friedrich, Huu Nguyen, Krishna Kalyan, Kourosh Nadi, Kristian Kersting, S\"oren Auer
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Effective human-AI interaction relies on AI's ability to accurately perceive and interpret human emotions. Current benchmarks for vision and vision-language models are severely limited, offering a narrow emotional spectrum that overlooks nuanced states (e.g., bitterness, intoxication) and fails to d</span>
                
                <span class="abstract-full" style="display: none;">Effective human-AI interaction relies on AI's ability to accurately perceive and interpret human emotions. Current benchmarks for vision and vision-language models are severely limited, offering a narrow emotional spectrum that overlooks nuanced states (e.g., bitterness, intoxication) and fails to distinguish subtle differences between related feelings (e.g., shame vs. embarrassment). Existing datasets also often use uncontrolled imagery with occluded faces and lack demographic diversity, risking significant bias. To address these critical gaps, we introduce EmoNet Face, a comprehensive benchmark suite. EmoNet Face features: (1) A novel 40-category emotion taxonomy, meticulously derived from foundational research to capture finer details of human emotional experiences. (2) Three large-scale, AI-generated datasets (EmoNet HQ, Binary, and Big) with explicit, full-face expressions and controlled demographic balance across ethnicity, age, and gender. (3) Rigorous, multi-expert annotations for training and high-fidelity evaluation. (4) We build Empathic Insight Face, a model achieving human-expert-level performance on our benchmark. The publicly released EmoNet Face suite - taxonomy, datasets, and model - provides a robust foundation for developing and evaluating AI systems with a deeper understanding of human emotions.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 8.8%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.1%">
                            LLMs
                        </span>
                <!-- Computer Vision: 2.5 -->
                    
                <!-- 3D: 2.3 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Datasets: 1.9 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- T2I: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.9939
                </span>
                <a href="https://arxiv.org/abs/2505.19242" target="_blank" rel="noopener noreferrer">Deformable Attentive Visual Enhancement for Referring Segmentation Using Vision-Language Model</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Alaa Dalaq, Muzammil Behzad
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Image segmentation is a fundamental task in computer vision, aimed at partitioning an image into semantically meaningful regions. Referring image segmentation extends this task by using natural language expressions to localize specific objects, requiring effective integration of visual and linguisti</span>
                
                <span class="abstract-full" style="display: none;">Image segmentation is a fundamental task in computer vision, aimed at partitioning an image into semantically meaningful regions. Referring image segmentation extends this task by using natural language expressions to localize specific objects, requiring effective integration of visual and linguistic information. In this work, we propose SegVLM, a vision-language model that incorporates architectural improvements to enhance segmentation accuracy and cross-modal alignment. The model integrates squeeze-and-excitation (SE) blocks for dynamic feature recalibration, deformable convolutions for geometric adaptability, and residual connections for deep feature learning. We also introduce a novel referring-aware fusion (RAF) loss that balances region-level alignment, boundary precision, and class imbalance. Extensive experiments and ablation studies demonstrate that each component contributes to consistent performance improvements. SegVLM also shows strong generalization across diverse datasets and referring expression scenarios.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 11.3%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 8.9%">
                            Medicine
                        </span>
                <!-- Computer Vision: 4.1 -->
                    
                <!-- Decision Trees: 2.0 -->
                    
                <!-- 3D: 2.0 -->
                    
                <!-- HPO and AutoML: 1.8 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- T2I: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.1221
                </span>
                <a href="https://arxiv.org/abs/2504.19718" target="_blank" rel="noopener noreferrer">Pixels2Points: Fusing 2D and 3D Features for Facial Skin Segmentation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Victoria Yue Chen, Daoye Wang, Stephan Garbin, Jan Bednarik, Sebastian Winberg, Timo Bolkart, Thabo Beeler
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Face registration deforms a template mesh to closely fit a 3D face scan, the quality of which commonly degrades in non-skin regions (e.g., hair, beard, accessories), because the optimized template-to-scan distance pulls the template mesh towards the noisy scan surface. Improving registration quality</span>
                
                <span class="abstract-full" style="display: none;">Face registration deforms a template mesh to closely fit a 3D face scan, the quality of which commonly degrades in non-skin regions (e.g., hair, beard, accessories), because the optimized template-to-scan distance pulls the template mesh towards the noisy scan surface. Improving registration quality requires a clean separation of skin and non-skin regions on the scan mesh. Existing image-based (2D) or scan-based (3D) segmentation methods however perform poorly. Image-based segmentation outputs multi-view inconsistent masks, and they cannot account for scan inaccuracies or scan-image misalignment, while scan-based methods suffer from lower spatial resolution compared to images. In this work, we introduce a novel method that accurately separates skin from non-skin geometry on 3D human head scans. For this, our method extracts features from multi-view images using a frozen image foundation model and aggregates these features in 3D. These lifted 2D features are then fused with 3D geometric features extracted from the scan mesh, to then predict a segmentation mask directly on the scan mesh. We show that our segmentations improve the registration accuracy over pure 2D or 3D segmentation methods by 8.89% and 14.3%, respectively. Although trained only on synthetic data, our model generalizes well to real data.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.8%">
                            Medicine
                        </span>
                <!-- Computer Vision: 3.5 -->
                    
                <!-- 3D: 3.4 -->
                    
                <!-- LLMs: 2.6 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.1804
                </span>
                <a href="https://arxiv.org/abs/2502.04345" target="_blank" rel="noopener noreferrer">JingFang: An Expert-Level Large Language Model for Traditional Chinese Medicine Clinical Consultation and Syndrome Differentiation-Based Treatment</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yehan Yang, Tianhao Ma, Ruotai Li, Xinhan Zheng, Guodong Shan, Chisheng Li
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The effective application of traditional Chinese medicine (TCM) requires extensive knowledge of TCM and clinical experience. The emergence of Large Language Models (LLMs) provides a solution to this, while existing LLMs for TCM exhibit critical limitations of incomplete clinical consultation and dia</span>
                
                <span class="abstract-full" style="display: none;">The effective application of traditional Chinese medicine (TCM) requires extensive knowledge of TCM and clinical experience. The emergence of Large Language Models (LLMs) provides a solution to this, while existing LLMs for TCM exhibit critical limitations of incomplete clinical consultation and diagnoses, as well as inaccurate syndrome differentiation. To address these issues, we establish JingFang (JF), a novel TCM LLM that demonstrates the level of expertise in clinical consultation and syndrome differentiation. We propose a Multi-Agent Collaborative Chain-of-Thought Mechanism (MACCTM) for comprehensive and targeted clinical consultation, enabling JF with effective and accurate diagnostic ability. In addition, a Syndrome Agent and a Dual-Stage Recovery Scheme (DSRS) are developed to accurately enhance the differentiation of the syndrome and the subsequent corresponding treatment. JingFang not only facilitates the application of LLMs but also promotes the effective application of TCM for healthcare.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 14.3%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.5%">
                            Medicine
                        </span>
                <!-- Hardware: 2.2 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Datasets: 1.7 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Computer Vision: 1.0 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.2355
                </span>
                <a href="https://arxiv.org/abs/2505.19077" target="_blank" rel="noopener noreferrer">An Autocovariance Least-Squares-Based Data-Driven Kalman Filter for Unknown Systems</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Suyang Hu, Xiaoxu Lyu, Peihu Duan, Dawei Shi, Ling Shi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This article investigates the problem of data-driven state estimation for linear systems with both unknown system dynamics and noise covariances. We propose an Autocovariance Least-squares-based Data-driven Kalman Filter (ADKF), which provides a unified framework for simultaneous system identificati</span>
                
                <span class="abstract-full" style="display: none;">This article investigates the problem of data-driven state estimation for linear systems with both unknown system dynamics and noise covariances. We propose an Autocovariance Least-squares-based Data-driven Kalman Filter (ADKF), which provides a unified framework for simultaneous system identification and state estimation by utilizing pre-collected input-output trajectories and estimated initial states. Specifically, we design a SDP-based algorithm for estimating the noise covariances. We quantify the impact of model inaccuracy on noise covariances estimation using this identification algorithm, and introduce a feedback control mechanism for data collection to enhance the accuracy and stability of noise covariance estimation. The estimated noise covariances account for model inaccuracy, which are shown to be more suitable for state estimation. We also quantify the performance gap between the ADKF and the traditional Kalman filter with known system dynamics and noise covariances, showing that this gap decreases as the number and length of pre-collected trajectories increase. Finally, numerical simulations validate the robustness and effectiveness of the proposed ADKF.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 9.7%">
                            Medicine
                        </span>
                <!-- Computer Vision: 2.9 -->
                    
                <!-- Hardware: 2.6 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- LLMs: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.2432
                </span>
                <a href="https://arxiv.org/abs/2505.19161" target="_blank" rel="noopener noreferrer">Benchmarking Laparoscopic Surgical Image Restoration and Beyond</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jialun Pei, Diandian Guo, Donghui Yang, Zhixi Li, Yuxin Feng, Long Ma, Bo Du, Pheng-Ann Heng
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In laparoscopic surgery, a clear and high-quality visual field is critical for surgeons to make accurate intraoperative decisions. However, persistent visual degradation, including smoke generated by energy devices, lens fogging from thermal gradients, and lens contamination due to blood or tissue f</span>
                
                <span class="abstract-full" style="display: none;">In laparoscopic surgery, a clear and high-quality visual field is critical for surgeons to make accurate intraoperative decisions. However, persistent visual degradation, including smoke generated by energy devices, lens fogging from thermal gradients, and lens contamination due to blood or tissue fluid splashes during surgical procedures, severely impair visual clarity. These degenerations can seriously hinder surgical workflow and pose risks to patient safety. To systematically investigate and address various forms of surgical scene degradation, we introduce a real-world open-source surgical image restoration dataset covering laparoscopic environments, called SurgClean, which involves multi-type image restoration tasks, e.g., desmoking, defogging, and desplashing. SurgClean comprises 1,020 images with diverse degradation types and corresponding paired reference labels. Based on SurgClean, we establish a standardized evaluation benchmark and provide performance for 22 representative generic task-specific image restoration approaches, including 12 generic and 10 task-specific image restoration approaches. Experimental results reveal substantial performance gaps relative to clinical requirements, highlighting a critical opportunity for algorithm advancements in intelligent surgical restoration. Furthermore, we explore the degradation discrepancies between surgical and natural scenes from structural perception and semantic understanding perspectives, providing fundamental insights for domain-specific image restoration research. Our work aims to empower the capabilities of restoration algorithms to increase surgical environments and improve the efficiency of clinical procedures.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 10.3%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.0%">
                            LLMs
                        </span>
                <!-- Computer Vision: 2.8 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- 3D: 2.0 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- T2I: 1.1 -->
                    
                <!-- GNN: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.2454
                </span>
                <a href="https://arxiv.org/abs/2505.18424" target="_blank" rel="noopener noreferrer">How We Won the ISLES'24 Challenge by Preprocessing</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Tianyi Ren, Juampablo E. Heras Rivera, Hitender Oswal, Yutong Pan, William Henry, Jacob Ruzevick, Mehmet Kurt
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Stroke is among the top three causes of death worldwide, and accurate identification of stroke lesion boundaries is critical for diagnosis and treatment. Supervised deep learning methods have emerged as the leading solution for stroke lesion segmentation but require large, diverse, and annotated dat</span>
                
                <span class="abstract-full" style="display: none;">Stroke is among the top three causes of death worldwide, and accurate identification of stroke lesion boundaries is critical for diagnosis and treatment. Supervised deep learning methods have emerged as the leading solution for stroke lesion segmentation but require large, diverse, and annotated datasets. The ISLES'24 challenge addresses this need by providing longitudinal stroke imaging data, including CT scans taken on arrival to the hospital and follow-up MRI taken 2-9 days from initial arrival, with annotations derived from follow-up MRI. Importantly, models submitted to the ISLES'24 challenge are evaluated using only CT inputs, requiring prediction of lesion progression that may not be visible in CT scans for segmentation. Our winning solution shows that a carefully designed preprocessing pipeline including deep-learning-based skull stripping and custom intensity windowing is beneficial for accurate segmentation. Combined with a standard large residual nnU-Net architecture for segmentation, this approach achieves a mean test Dice of 28.5 with a standard deviation of 21.27.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 10.5%">
                            Medicine
                        </span>
                <!-- LLMs: 2.7 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.3108
                </span>
                <a href="https://arxiv.org/abs/2505.18881" target="_blank" rel="noopener noreferrer">SD-OVON: A Semantics-aware Dataset and Benchmark Generation Pipeline for Open-Vocabulary Object Navigation in Dynamic Scenes</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Dicong Qiu, Jiadi You, Zeying Gong, Ronghe Qiu, Hui Xiong, Junwei Liang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We present the Semantics-aware Dataset and Benchmark Generation Pipeline for Open-vocabulary Object Navigation in Dynamic Scenes (SD-OVON). It utilizes pretraining multimodal foundation models to generate infinite unique photo-realistic scene variants that adhere to real-world semantics and daily co</span>
                
                <span class="abstract-full" style="display: none;">We present the Semantics-aware Dataset and Benchmark Generation Pipeline for Open-vocabulary Object Navigation in Dynamic Scenes (SD-OVON). It utilizes pretraining multimodal foundation models to generate infinite unique photo-realistic scene variants that adhere to real-world semantics and daily commonsense for the training and the evaluation of navigation agents, accompanied with a plugin for generating object navigation task episodes compatible to the Habitat simulator. In addition, we offer two pre-generated object navigation task datasets, SD-OVON-3k and SD-OVON-10k, comprising respectively about 3k and 10k episodes of the open-vocabulary object navigation task, derived from the SD-OVON-Scenes dataset with 2.5k photo-realistic scans of real-world environments and the SD-OVON-Objects dataset with 0.9k manually inspected scanned and artist-created manipulatable object models. Unlike prior datasets limited to static environments, SD-OVON covers dynamic scenes and manipulatable objects, facilitating both real-to-sim and sim-to-real robotic applications. This approach enhances the realism of navigation tasks, the training and the evaluation of open-vocabulary object navigation agents in complex settings. To demonstrate the effectiveness of our pipeline and datasets, we propose two baselines and evaluate them along with state-of-the-art baselines on SD-OVON-3k. The datasets, benchmark and source code are publicly available.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.9%">
                            Medicine
                        </span>
                <!-- Computer Vision: 4.2 -->
                    
                <!-- LLMs: 3.8 -->
                    
                <!-- Datasets: 2.5 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.4426
                </span>
                <a href="https://arxiv.org/abs/2505.11335" target="_blank" rel="noopener noreferrer">The Final Layer Holds the Key: A Unified and Efficient GNN Calibration Framework</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jincheng Huang, Jie Xu, Xiaoshuang Shi, Ping Hu, Lei Feng, Xiaofeng Zhu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Graph Neural Networks (GNNs) have demonstrated remarkable effectiveness on graph-based tasks. However, their predictive confidence is often miscalibrated, typically exhibiting under-confidence, which harms the reliability of their decisions. Existing calibration methods for GNNs normally introduce a</span>
                
                <span class="abstract-full" style="display: none;">Graph Neural Networks (GNNs) have demonstrated remarkable effectiveness on graph-based tasks. However, their predictive confidence is often miscalibrated, typically exhibiting under-confidence, which harms the reliability of their decisions. Existing calibration methods for GNNs normally introduce additional calibration components, which fail to capture the intrinsic relationship between the model and the prediction confidence, resulting in limited theoretical guarantees and increased computational overhead. To address this issue, we propose a simple yet efficient graph calibration method. We establish a unified theoretical framework revealing that model confidence is jointly governed by class-centroid-level and node-level calibration at the final layer. Based on this insight, we theoretically show that reducing the weight decay of the final-layer parameters alleviates GNN under-confidence by acting on the class-centroid level, while node-level calibration acts as a finer-grained complement to class-centroid level calibration, which encourages each test node to be closer to its predicted class centroid at the final-layer representations. Extensive experiments validate the superiority of our method.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #b243cd" title="Confidence: 5.4%">
                            GNN
                        </span>
                <!-- Federated Learning: 3.9 -->
                    
                <!-- Computer Vision: 3.0 -->
                    
                <!-- LLMs: 2.4 -->
                    
                <!-- Medicine: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- Bayesian Optimization: 1.4 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Hardware: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.4728
                </span>
                <a href="https://arxiv.org/abs/2504.11442" target="_blank" rel="noopener noreferrer">TextArena</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Leon Guertler, Bobby Cheng, Simon Yu, Bo Liu, Leshem Choshen, Cheston Tan
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">TextArena is an open-source collection of competitive text-based games for training and evaluation of agentic behavior in Large Language Models (LLMs). It spans 57+ unique environments (including single-player, two-player, and multi-player setups) and allows for easy evaluation of model capabilities</span>
                
                <span class="abstract-full" style="display: none;">TextArena is an open-source collection of competitive text-based games for training and evaluation of agentic behavior in Large Language Models (LLMs). It spans 57+ unique environments (including single-player, two-player, and multi-player setups) and allows for easy evaluation of model capabilities via an online-play system (against humans and other submitted models) with real-time TrueSkill scores. Traditional benchmarks rarely assess dynamic social skills such as negotiation, theory of mind, and deception, creating a gap that TextArena addresses. Designed with research, community and extensibility in mind, TextArena emphasizes ease of adding new games, adapting the framework, testing models, playing against the models, and training models. Detailed documentation of environments, games, leaderboard, and examples are available on https://github.com/LeonGuertler/TextArena and https://www.textarena.ai/.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 15.9%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.7%">
                            Medicine
                        </span>
                <!-- Datasets: 3.1 -->
                    
                <!-- Hardware: 2.7 -->
                    
                <!-- Blockchain: 2.5 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.4756
                </span>
                <a href="https://arxiv.org/abs/2505.18182" target="_blank" rel="noopener noreferrer">Machine Learning-Based Analysis of ECG and PCG Signals for Rheumatic Heart Disease Detection: A Scoping Review (2015-2025)</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Damilare Emmanuel Olatunji, Julius Dona Zannu, Carine Pierrette Mukamakuza, Godbright Nixon Uiso, Mona Mamoun Mubarak Aman, John Bosco Thuo, Chol Buol, Nchofon Tagha Ghogomu, Evelyne Umubyeyi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Objective: To conduct a systematic assessment of machine learning applications that utilize electrocardiogram (ECG) and heart sound data in the development of cost-effective detection tools for rheumatic heart disease (RHD) from the year 2015 to 2025, thereby supporting the World Heart Federation's </span>
                
                <span class="abstract-full" style="display: none;">Objective: To conduct a systematic assessment of machine learning applications that utilize electrocardiogram (ECG) and heart sound data in the development of cost-effective detection tools for rheumatic heart disease (RHD) from the year 2015 to 2025, thereby supporting the World Heart Federation's "25 by 25" mortality reduction objective through the creation of alternatives to echocardiography in underserved regions. Methods: Following PRISMA-ScR guidelines, we conducted a comprehensive search across PubMed, IEEE Xplore, Scopus, and Embase for peer-reviewed literature focusing on ML-based ECG/PCG analysis for RHD detection. Two independent reviewers screened studies, and data extraction focused on methodology, validation approaches, and performance metrics. Results: Analysis of 37 relevant studies revealed that convolutional neural networks (CNNs) have become the predominant technology in post-2020 implementations, achieving a median accuracy of 93.7%. However, 73% of studies relied on single-center datasets, only 10.8% incorporated external validation, and none addressed cost-effectiveness. Performance varied markedly across different valvular lesions, and despite 44% of studies originating from endemic regions, significant gaps persisted in implementation science and demographic diversity. Conclusion: While ML-based ECG/PCG analysis shows promise for RHD detection, substantial methodological limitations hinder clinical translation. Future research must prioritize standardized benchmarking frameworks, multimodal architectures, cost-effectiveness assessments, and prospective trials in endemic settings. Significance: This review provides a critical roadmap for developing accessible ML-based RHD screening tools to help bridge the diagnostic gap in resourceconstrained settings where conventional auscultation misses up to 90% of cases and echocardiography remains inaccessible.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 8.9%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.2%">
                            LLMs
                        </span>
                <!-- Blockchain: 2.4 -->
                    
                <!-- Datasets: 2.4 -->
                    
                <!-- Hardware: 2.2 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.4783
                </span>
                <a href="https://arxiv.org/abs/2505.18927" target="_blank" rel="noopener noreferrer">Benchmarking Large Language Models for Cyberbullying Detection in Real-World YouTube Comments</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Amel Muminovic (International Balkan University)
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">As online platforms grow, comment sections increasingly host harassment that undermines user experience and well-being. This study benchmarks three leading large language models, OpenAI GPT-4.1, Google Gemini 1.5 Pro, and Anthropic Claude 3 Opus, on a corpus of 5,080 YouTube comments sampled from hi</span>
                
                <span class="abstract-full" style="display: none;">As online platforms grow, comment sections increasingly host harassment that undermines user experience and well-being. This study benchmarks three leading large language models, OpenAI GPT-4.1, Google Gemini 1.5 Pro, and Anthropic Claude 3 Opus, on a corpus of 5,080 YouTube comments sampled from high-abuse threads in gaming, lifestyle, food vlog, and music channels. The dataset comprises 1,334 harmful and 3,746 non-harmful messages in English, Arabic, and Indonesian, annotated independently by two reviewers with substantial agreement (Cohen's kappa = 0.83). Using a unified prompt and deterministic settings, GPT-4.1 achieved the best overall balance with an F1 score of 0.863, precision of 0.887, and recall of 0.841. Gemini flagged the highest share of harmful posts (recall = 0.875) but its precision fell to 0.767 due to frequent false positives. Claude delivered the highest precision at 0.920 and the lowest false-positive rate of 0.022, yet its recall dropped to 0.720. Qualitative analysis showed that all three models struggle with sarcasm, coded insults, and mixed-language slang. These results underscore the need for moderation pipelines that combine complementary models, incorporate conversational context, and fine-tune for under-represented languages and implicit abuse. A de-identified version of the dataset and full prompts is publicly released to promote reproducibility and further progress in automated content moderation.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 13.7%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.8%">
                            Medicine
                        </span>
                <!-- Datasets: 2.5 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.74
                </span>
                <a href="https://arxiv.org/abs/2505.20099" target="_blank" rel="noopener noreferrer">Large Language Models Meet Knowledge Graphs for Question Answering: Synthesis and Opportunities</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Chuangtao Ma, Yongrui Chen, Tianxing Wu, Arijit Khan, Haofen Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Large language models (LLMs) have demonstrated remarkable performance on question-answering (QA) tasks because of their superior capabilities in natural language understanding and generation. However, LLM-based QA struggles with complex QA tasks due to poor reasoning capacity, outdated knowledge, an</span>
                
                <span class="abstract-full" style="display: none;">Large language models (LLMs) have demonstrated remarkable performance on question-answering (QA) tasks because of their superior capabilities in natural language understanding and generation. However, LLM-based QA struggles with complex QA tasks due to poor reasoning capacity, outdated knowledge, and hallucinations. Several recent works synthesize LLMs and knowledge graphs (KGs) for QA to address the above challenges. In this survey, we propose a new structured taxonomy that categorizes the methodology of synthesizing LLMs and KGs for QA according to the categories of QA and the KG's role when integrating with LLMs. We systematically survey state-of-the-art advances in synthesizing LLMs and KGs for QA and compare and analyze these approaches in terms of strength, limitations, and KG requirements. We then align the approaches with QA and discuss how these approaches address the main challenges of different complex QA. Finally, we summarize the advancements, evaluation metrics, and benchmark datasets and highlight open challenges and opportunities.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 37.6%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.1%">
                            Medicine
                        </span>
                <!-- Hardware: 2.0 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.3465
                </span>
                <a href="https://arxiv.org/abs/2505.19779" target="_blank" rel="noopener noreferrer">Advancements in Medical Image Classification through Fine-Tuning Natural Domain Foundation Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Mobina Mansoori, Sajjad Shahabodini, Farnoush Bayatmakou, Jamshid Abouei, Konstantinos N. Plataniotis, Arash Mohammadi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Using massive datasets, foundation models are large-scale, pre-trained models that perform a wide range of tasks. These models have shown consistently improved results with the introduction of new methods. It is crucial to analyze how these trends impact the medical field and determine whether these</span>
                
                <span class="abstract-full" style="display: none;">Using massive datasets, foundation models are large-scale, pre-trained models that perform a wide range of tasks. These models have shown consistently improved results with the introduction of new methods. It is crucial to analyze how these trends impact the medical field and determine whether these advancements can drive meaningful change. This study investigates the application of recent state-of-the-art foundation models, DINOv2, MAE, VMamba, CoCa, SAM2, and AIMv2, for medical image classification. We explore their effectiveness on datasets including CBIS-DDSM for mammography, ISIC2019 for skin lesions, APTOS2019 for diabetic retinopathy, and CHEXPERT for chest radiographs. By fine-tuning these models and evaluating their configurations, we aim to understand the potential of these advancements in medical image classification. The results indicate that these advanced models significantly enhance classification outcomes, demonstrating robust performance despite limited labeled data. Based on our results, AIMv2, DINOv2, and SAM2 models outperformed others, demonstrating that progress in natural domain training has positively impacted the medical domain and improved classification outcomes. Our code is publicly available at: https://github.com/sajjad-sh33/Medical-Transfer-Learning.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 14.2%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.7%">
                            LLMs
                        </span>
                <!-- Computer Vision: 2.6 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- Decision Trees: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.3469
                </span>
                <a href="https://arxiv.org/abs/2505.07214" target="_blank" rel="noopener noreferrer">Towards user-centered interactive medical image segmentation in VR with an assistive AI agent</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Pascal Spiegler, Arash Harirpoush, Yiming Xiao
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Crucial in disease analysis and surgical planning, manual segmentation of volumetric medical scans (e.g. MRI, CT) is laborious, error-prone, and challenging to master, while fully automatic algorithms can benefit from user feedback. Therefore, with the complementary power of the latest radiological </span>
                
                <span class="abstract-full" style="display: none;">Crucial in disease analysis and surgical planning, manual segmentation of volumetric medical scans (e.g. MRI, CT) is laborious, error-prone, and challenging to master, while fully automatic algorithms can benefit from user feedback. Therefore, with the complementary power of the latest radiological AI foundation models and virtual reality (VR)'s intuitive data interaction, we propose SAMIRA, a novel conversational AI agent for medical VR that assists users with localizing, segmenting, and visualizing 3D medical concepts. Through speech-based interaction, the agent helps users understand radiological features, locate clinical targets, and generate segmentation masks that can be refined with just a few point prompts. The system also supports true-to-scale 3D visualization of segmented pathology to enhance patient-specific anatomical understanding. Furthermore, to determine the optimal interaction paradigm under near-far attention-switching for refining segmentation masks in an immersive, human-in-the-loop workflow, we compare VR controller pointing, head pointing, and eye tracking as input modes. With a user study, evaluations demonstrated a high usability score (SUS=90.0 $\pm$ 9.0), low overall task load, as well as strong support for the proposed VR system's guidance, training potential, and integration of AI in radiological segmentation tasks.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 15.6%">
                            Medicine
                        </span>
                <!-- LLMs: 4.7 -->
                    
                <!-- Computer Vision: 2.1 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.1766
                </span>
                <a href="https://arxiv.org/abs/2505.19600" target="_blank" rel="noopener noreferrer">Indoor Air Quality Detection Robot Model Based on the Internet of Things (IoT)</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Anggiat Mora Simamora, Asep Denih, Mohamad Iqbal Suriansyah
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper presents the design, implementation, and evaluation of an IoT-based robotic system for mapping and monitoring indoor air quality. The primary objective was to develop a mobile robot capable of autonomously mapping a closed environment, detecting concentrations of CO$_2$, volatile organic </span>
                
                <span class="abstract-full" style="display: none;">This paper presents the design, implementation, and evaluation of an IoT-based robotic system for mapping and monitoring indoor air quality. The primary objective was to develop a mobile robot capable of autonomously mapping a closed environment, detecting concentrations of CO$_2$, volatile organic compounds (VOCs), smoke, temperature, and humidity, and transmitting real-time data to a web interface. The system integrates a set of sensors (SGP30, MQ-2, DHT11, VL53L0X, MPU6050) with an ESP32 microcontroller. It employs a mapping algorithm for spatial data acquisition and utilizes a Mamdani fuzzy logic system for air quality classification. Empirical tests in a model room demonstrated average localization errors below $5\%$, actuator motion errors under $2\%$, and sensor measurement errors within $12\%$ across all modalities. The contributions of this work include: (1) a low-cost, integrated IoT robotic platform for simultaneous mapping and air quality detection; (2) a web-based user interface for real-time visualization and control; and (3) validation of system accuracy under laboratory conditions.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 15.3%">
                            Medicine
                        </span>
                <!-- Hardware: 3.5 -->
                    
                <!-- LLMs: 3.1 -->
                    
                <!-- Evolutionary Algorithms: 2.4 -->
                    
                <!-- Datasets: 2.1 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Computer Vision: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.9373
                </span>
                <a href="https://arxiv.org/abs/2505.19188" target="_blank" rel="noopener noreferrer">Chordless Structure: A Pathway to Simple and Expressive GNNs</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Hongxu Pan, Shuxian Hu, Mo Zhou, Zhibin Wang, Rong Gu, Chen Tian, Kun Yang, Sheng Zhong
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Researchers have proposed various methods of incorporating more structured information into the design of Graph Neural Networks (GNNs) to enhance their expressiveness. However, these methods are either computationally expensive or lacking in provable expressiveness. In this paper, we observe that th</span>
                
                <span class="abstract-full" style="display: none;">Researchers have proposed various methods of incorporating more structured information into the design of Graph Neural Networks (GNNs) to enhance their expressiveness. However, these methods are either computationally expensive or lacking in provable expressiveness. In this paper, we observe that the chords increase the complexity of the graph structure while contributing little useful information in many cases. In contrast, chordless structures are more efficient and effective for representing the graph. Therefore, when leveraging the information of cycles, we choose to omit the chords. Accordingly, we propose a Chordless Structure-based Graph Neural Network (CSGNN) and prove that its expressiveness is strictly more powerful than the k-hop GNN (KPGNN) with polynomial complexity. Experimental results on real-world datasets demonstrate that CSGNN outperforms existing GNNs across various graph tasks while incurring lower computational costs and achieving better performance than the GNNs of 3-WL expressiveness.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #b243cd" title="Confidence: 11.8%">
                            GNN
                        </span>
                <!-- LLMs: 4.2 -->
                    
                <!-- Federated Learning: 3.1 -->
                    
                <!-- Bayesian Optimization: 2.2 -->
                    
                <!-- Medicine: 2.1 -->
                    
                <!-- Computer Vision: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.9907
                </span>
                <a href="https://arxiv.org/abs/2505.18930" target="_blank" rel="noopener noreferrer">WeedNet: A Foundation Model-Based Global-to-Local AI Approach for Real-Time Weed Species Identification and Classification</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yanben Shen, Timilehin T. Ayanlade, Venkata Naresh Boddepalli, Mojdeh Saadati, Ashlyn Rairdin, Zi K. Deng, Muhammad Arbab Arshad, Aditya Balu, Daren Mueller, Asheesh K Singh, Wesley Everman, Nirav Merchant, Baskar Ganapathysubramanian, Meaghan Anderson, Soumik Sarkar, Arti Singh
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Early identification of weeds is essential for effective management and control, and there is growing interest in automating the process using computer vision techniques coupled with AI methods. However, challenges associated with training AI-based weed identification models, such as limited expert-</span>
                
                <span class="abstract-full" style="display: none;">Early identification of weeds is essential for effective management and control, and there is growing interest in automating the process using computer vision techniques coupled with AI methods. However, challenges associated with training AI-based weed identification models, such as limited expert-verified data and complexity and variability in morphological features, have hindered progress. To address these issues, we present WeedNet, the first global-scale weed identification model capable of recognizing an extensive set of weed species, including noxious and invasive plant species. WeedNet is an end-to-end real-time weed identification pipeline and uses self-supervised learning, fine-tuning, and enhanced trustworthiness strategies. WeedNet achieved 91.02% accuracy across 1,593 weed species, with 41% species achieving 100% accuracy. Using a fine-tuning strategy and a Global-to-Local approach, the local Iowa WeedNet model achieved an overall accuracy of 97.38% for 85 Iowa weeds, most classes exceeded a 90% mean accuracy per class. Testing across intra-species dissimilarity (developmental stages) and inter-species similarity (look-alike species) suggests that diversity in the images collected, spanning all the growth stages and distinguishable plant characteristics, is crucial in driving model performance. The generalizability and adaptability of the Global WeedNet model enable it to function as a foundational model, with the Global-to-Local strategy allowing fine-tuning for region-specific weed communities. Additional validation of drone- and ground-rover-based images highlights the potential of WeedNet for integration into robotic platforms. Furthermore, integration with AI for conversational use provides intelligent agricultural and ecological conservation consulting tools for farmers, agronomists, researchers, land managers, and government agencies across diverse landscapes.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 16.6%">
                            Medicine
                        </span>
                <!-- LLMs: 3.6 -->
                    
                <!-- Hardware: 3.2 -->
                    
                <!-- Datasets: 2.5 -->
                    
                <!-- Computer Vision: 2.4 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Quantum Computing: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -5.7176
                </span>
                <a href="https://arxiv.org/abs/2503.01762" target="_blank" rel="noopener noreferrer">Non-unitary enhanced transfer efficiency in quantum walk search on complex networks</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ugo Nzongani, Andrea Simonetto, Giuseppe Di Molfetta
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The task of finding an element in an unstructured database is known as spatial search and can be expressed as a quantum walk evolution on a graph. In this article, we modify the usual search problem by adding an extra trapping vertex to the graph, which is only connected to the target element. We st</span>
                
                <span class="abstract-full" style="display: none;">The task of finding an element in an unstructured database is known as spatial search and can be expressed as a quantum walk evolution on a graph. In this article, we modify the usual search problem by adding an extra trapping vertex to the graph, which is only connected to the target element. We study the transfer efficiency of the walker to a trapping site, using the search problem as a case study. Thus, our model offers no computational advantage for the search problem, but focuses on information transport in an open environment with a search Hamiltonian. The walker evolution is a mix between classical and quantum walk search dynamics. The balance between unitary and non-unitary dynamics is tuned with a parameter, and we numerically show that depending on the graph topology and the connectivity of the target element, this hybrid approach can outperform a purely classical or quantum evolution for reaching the trapping site. We show that this behavior is only observed in the presence of an extra trapping site, and that depending on the topology, the increase of non-unitary operations can be compensated by increasing the strength of the quantum walk exploration. This compensation comes at the cost of reducing or even suppressing the searching feature of the evolution. In that case, the unitary dynamics will only induce a regular quantum walk behavior. We also relate the optimal hybrid regime to the entropy's decay rate. As the introduction of non-unitary operations may be considered as noise, we interpret this phenomena as a noisy-assisted quantum evolution.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 8.6%">
                            Quantum Computing
                        </span>
                <!-- Reinforcement Learning: 3.3 -->
                    
                <!-- Federated Learning: 3.0 -->
                    
                <!-- Math: 2.9 -->
                    
                <!-- Evolutionary Algorithms: 2.6 -->
                    
                <!-- Bayesian Optimization: 1.8 -->
                    
                <!-- Cryptography: 1.6 -->
                    
                <!-- Networks: 1.4 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Medicine: 1.2 -->
                    
                <!-- Finance: 1.1 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -6.0212
                </span>
                <a href="https://arxiv.org/abs/2503.08962" target="_blank" rel="noopener noreferrer">On the status of current quantum machine learning software</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Manish K. Gupta, Tomasz Rybotycki, Piotr Gawron
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The recent advancements in noisy intermediate-scale quantum (NISQ) devices implementation allow us to study their application to real-life computational problems. However, hardware challenges are not the only ones that hinder our quantum computation capabilities. Software limitations are the other, </span>
                
                <span class="abstract-full" style="display: none;">The recent advancements in noisy intermediate-scale quantum (NISQ) devices implementation allow us to study their application to real-life computational problems. However, hardware challenges are not the only ones that hinder our quantum computation capabilities. Software limitations are the other, less explored side of this medal. Using satellite image segmentation as a task example, we investigated how difficult it is to run a hybrid quantum-classical model on a real, publicly available quantum device. We also analyzed the costs of such endeavor and the change in quality of model.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 11.3%">
                            Quantum Computing
                        </span>
                <!-- LLMs: 3.0 -->
                    
                <!-- Federated Learning: 2.5 -->
                    
                <!-- Evolutionary Algorithms: 2.4 -->
                    
                <!-- GNN: 2.2 -->
                    
                <!-- Blockchain: 2.1 -->
                    
                <!-- Medicine: 1.8 -->
                    
                <!-- Bayesian Optimization: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Cryptography: 1.1 -->
                    
                <!-- Networks: 1.1 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                <!-- Game Theory: 1.1 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -6.1522
                </span>
                <a href="https://arxiv.org/abs/2501.18739" target="_blank" rel="noopener noreferrer">Beyond Message Passing: Neural Graph Pattern Machine</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zehong Wang, Zheyuan Zhang, Tianyi Ma, Nitesh V Chawla, Chuxu Zhang, Yanfang Ye
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Graph learning tasks often hinge on identifying key substructure patterns -- such as triadic closures in social networks or benzene rings in molecular graphs -- that underpin downstream performance. However, most existing graph neural networks (GNNs) rely on message passing, which aggregates local n</span>
                
                <span class="abstract-full" style="display: none;">Graph learning tasks often hinge on identifying key substructure patterns -- such as triadic closures in social networks or benzene rings in molecular graphs -- that underpin downstream performance. However, most existing graph neural networks (GNNs) rely on message passing, which aggregates local neighborhood information iteratively and struggles to explicitly capture such fundamental motifs, like triangles, k-cliques, and rings. This limitation hinders both expressiveness and long-range dependency modeling. In this paper, we introduce the Neural Graph Pattern Machine (GPM), a novel framework that bypasses message passing by learning directly from graph substructures. GPM efficiently extracts, encodes, and prioritizes task-relevant graph patterns, offering greater expressivity and improved ability to capture long-range dependencies. Empirical evaluations across four standard tasks -- node classification, link prediction, graph classification, and graph regression -- demonstrate that GPM outperforms state-of-the-art baselines. Further analysis reveals that GPM exhibits strong out-of-distribution generalization, desirable scalability, and enhanced interpretability. Code and datasets are available at: https://github.com/Zehong-Wang/GPM.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #b243cd" title="Confidence: 14.6%">
                            GNN
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.6%">
                            LLMs
                        </span>
                <!-- Computer Vision: 2.6 -->
                    
                <!-- Medicine: 2.5 -->
                    
                <!-- Blockchain: 2.4 -->
                    
                <!-- HPO and AutoML: 2.2 -->
                    
                <!-- 3D: 2.0 -->
                    
                <!-- Decision Trees: 1.8 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -6.2404
                </span>
                <a href="https://arxiv.org/abs/2411.11197" target="_blank" rel="noopener noreferrer">Stealing Training Graphs from Graph Neural Networks</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Minhua Lin, Enyan Dai, Junjie Xu, Jinyuan Jia, Xiang Zhang, Suhang Wang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Graph Neural Networks (GNNs) have shown promising results in modeling graphs in various tasks. The training of GNNs, especially on specialized tasks such as bioinformatics, demands extensive expert annotations, which are expensive and usually contain sensitive information of data providers. The trai</span>
                
                <span class="abstract-full" style="display: none;">Graph Neural Networks (GNNs) have shown promising results in modeling graphs in various tasks. The training of GNNs, especially on specialized tasks such as bioinformatics, demands extensive expert annotations, which are expensive and usually contain sensitive information of data providers. The trained GNN models are often shared for deployment in the real world. As neural networks can memorize the training samples, the model parameters of GNNs have a high risk of leaking private training data. Our theoretical analysis shows the strong connections between trained GNN parameters and the training graphs used, confirming the training graph leakage issue. However, explorations into training data leakage from trained GNNs are rather limited. Therefore, we investigate a novel problem of stealing graphs from trained GNNs. To obtain high-quality graphs that resemble the target training set, a graph diffusion model with diffusion noise optimization is deployed as a graph generator. Furthermore, we propose a selection method that effectively leverages GNN model parameters to identify training graphs from samples generated by the graph diffusion model. Extensive experiments on real-world datasets demonstrate the effectiveness of the proposed framework in stealing training graphs from the trained GNN.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #b243cd" title="Confidence: 16.2%">
                            GNN
                        </span>
                <!-- Medicine: 2.8 -->
                    
                <!-- Bayesian Optimization: 2.2 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Reinforcement Learning: 2.0 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- LLMs: 1.6 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -7.0683
                </span>
                <a href="https://arxiv.org/abs/2309.14326" target="_blank" rel="noopener noreferrer">Efficient Pauli channel estimation with logarithmic quantum memory</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Sitan Chen, Weiyuan Gong
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Here we revisit one of the prototypical tasks for characterizing the structure of noise in quantum devices: estimating every eigenvalue of an $n$-qubit Pauli noise channel to error $\epsilon$. Prior work [14] proved no-go theorems for this task in the practical regime where one has a limited amount </span>
                
                <span class="abstract-full" style="display: none;">Here we revisit one of the prototypical tasks for characterizing the structure of noise in quantum devices: estimating every eigenvalue of an $n$-qubit Pauli noise channel to error $\epsilon$. Prior work [14] proved no-go theorems for this task in the practical regime where one has a limited amount of quantum memory, e.g. any protocol with $\le 0.99n$ ancilla qubits of quantum memory must make exponentially many measurements, provided it is non-concatenating. Such protocols can only interact with the channel by repeatedly preparing a state, passing it through the channel, and measuring immediately afterward.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 13.3%">
                            Quantum Computing
                        </span>
                <!-- LLMs: 3.1 -->
                    
                <!-- Medicine: 3.1 -->
                    
                <!-- Federated Learning: 2.5 -->
                    
                <!-- Evolutionary Algorithms: 2.3 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Bayesian Optimization: 1.6 -->
                    
                <!-- Networks: 1.5 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Math: 1.4 -->
                    
                <!-- Cryptography: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                <!-- Game Theory: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -7.6767
                </span>
                <a href="https://arxiv.org/abs/2505.19006" target="_blank" rel="noopener noreferrer">A quantitative notion of economic security for smart contract compositions</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Emily Priyadarshini, Massimo Bartoletti
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Decentralized applications are often composed of multiple interconnected smart contracts. This is especially evident in DeFi, where protocols are heavily intertwined and rely on a variety of basic building blocks such as tokens, decentralized exchanges and lending protocols. A crucial security chall</span>
                
                <span class="abstract-full" style="display: none;">Decentralized applications are often composed of multiple interconnected smart contracts. This is especially evident in DeFi, where protocols are heavily intertwined and rely on a variety of basic building blocks such as tokens, decentralized exchanges and lending protocols. A crucial security challenge in this setting arises when adversaries target individual components to cause systemic economic losses. Existing security notions focus on determining the existence of these attacks, but fail to quantify the effect of manipulating individual components on the overall economic security of the system. In this paper, we introduce a quantitative security notion that measures how an attack on a single component can amplify economic losses of the overall system. We study the fundamental properties of this notion and apply it to assess the security of key compositions. In particular, we analyse under-collateralized loan attacks in systems made of lending protocols and decentralized exchanges.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #3cc377" title="Confidence: 6.1%">
                            Blockchain
                        </span>
                <!-- LLMs: 3.9 -->
                    
                <!-- Federated Learning: 3.8 -->
                    
                <!-- Evolutionary Algorithms: 2.7 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Bayesian Optimization: 1.9 -->
                    
                <!-- Medicine: 1.7 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -8.6533
                </span>
                <a href="https://arxiv.org/abs/2504.04041" target="_blank" rel="noopener noreferrer">Authenticated Sublinear Quantum Private Information Retrieval</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Fengxia Liu, Zhiyong Zheng, Kun Tian, Yi Zhang, Heng Guo, Zhe Hu, Oleksiy Zhedanov, Zixian Gong
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper introduces a novel lower bound on communication complexity using quantum relative entropy and mutual information, refining previous classical entropy-based results. By leveraging Uhlmann's lemma and quantum Pinsker inequalities, the authors establish tighter bounds for information-theoret</span>
                
                <span class="abstract-full" style="display: none;">This paper introduces a novel lower bound on communication complexity using quantum relative entropy and mutual information, refining previous classical entropy-based results. By leveraging Uhlmann's lemma and quantum Pinsker inequalities, the authors establish tighter bounds for information-theoretic security, demonstrating that quantum protocols inherently outperform classical counterparts in balancing privacy and efficiency. Also explores symmetric Quantum Private Information Retrieval (QPIR) protocols that achieve sub-linear communication complexity while ensuring robustness against specious adversaries: A post-quantum cryptography based protocol that can be authenticated for the specious server; A ring-LWE-based protocol for post-quantum security in a single-server setting, ensuring robustness against quantum attacks; A multi-server protocol optimized for hardware practicality, reducing implementation overhead while maintaining sub-linear efficiency. These protocols address critical gaps in secure database queries, offering exponential communication improvements over classical linear-complexity methods. The work also analyzes security trade-offs under quantum specious adversaries, providing theoretical guarantees for privacy and correctness.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 14.1%">
                            Quantum Computing
                        </span>
                <!-- LLMs: 4.1 -->
                    
                <!-- Medicine: 3.0 -->
                    
                <!-- Blockchain: 2.2 -->
                    
                <!-- Computer Vision: 2.1 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Cryptography: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -8.9584
                </span>
                <a href="https://arxiv.org/abs/2505.16332" target="_blank" rel="noopener noreferrer">Is Quantum Optimization Ready? An Effort Towards Neural Network Compression using Adiabatic Quantum Computing</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zhehui Wanga, Benjamin Chen Ming Choonga, Tian Huang, Daniel Gerlinghoffa, Rick Siow Mong Goh, Cheng Liu, Tao Luo
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Quantum optimization is the most mature quantum computing technology to date, providing a promising approach towards efficiently solving complex combinatorial problems. Methods such as adiabatic quantum computing (AQC) have been employed in recent years on important optimization problems across vari</span>
                
                <span class="abstract-full" style="display: none;">Quantum optimization is the most mature quantum computing technology to date, providing a promising approach towards efficiently solving complex combinatorial problems. Methods such as adiabatic quantum computing (AQC) have been employed in recent years on important optimization problems across various domains. In deep learning, deep neural networks (DNN) have reached immense sizes to support new predictive capabilities. Optimization of large-scale models is critical for sustainable deployment, but becomes increasingly challenging with ever-growing model sizes and complexity. While quantum optimization is suitable for solving complex problems, its application to DNN optimization is not straightforward, requiring thorough reformulation for compatibility with commercially available quantum devices. In this work, we explore the potential of adopting AQC for fine-grained pruning-quantization of convolutional neural networks. We rework established heuristics to formulate model compression as a quadratic unconstrained binary optimization (QUBO) problem, and assess the solution space offered by commercial quantum annealing devices. Through our exploratory efforts of reformulation, we demonstrate that AQC can achieve effective compression of practical DNN models. Experiments demonstrate that adiabatic quantum computing (AQC) not only outperforms classical algorithms like genetic algorithms and reinforcement learning in terms of time efficiency but also excels at identifying global optima.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 14.6%">
                            Quantum Computing
                        </span>
                <!-- Bayesian Optimization: 3.5 -->
                    
                <!-- Evolutionary Algorithms: 3.4 -->
                    
                <!-- LLMs: 3.2 -->
                    
                <!-- Federated Learning: 3.1 -->
                    
                <!-- Medicine: 2.5 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- HPO and AutoML: 1.9 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -9.1385
                </span>
                <a href="https://arxiv.org/abs/2505.13525" target="_blank" rel="noopener noreferrer">Learning to Program Quantum Measurements for Machine Learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Samuel Yen-Chi Chen, Huan-Hsin Tseng, Hsin-Yi Lin, Shinjae Yoo
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The rapid advancements in quantum computing (QC) and machine learning (ML) have sparked significant interest, driving extensive exploration of quantum machine learning (QML) algorithms to address a wide range of complex challenges. The development of high-performance QML models requires expert-level</span>
                
                <span class="abstract-full" style="display: none;">The rapid advancements in quantum computing (QC) and machine learning (ML) have sparked significant interest, driving extensive exploration of quantum machine learning (QML) algorithms to address a wide range of complex challenges. The development of high-performance QML models requires expert-level expertise, presenting a key challenge to the widespread adoption of QML. Critical obstacles include the design of effective data encoding strategies and parameterized quantum circuits, both of which are vital for the performance of QML models. Furthermore, the measurement process is often neglected-most existing QML models employ predefined measurement schemes that may not align with the specific requirements of the targeted problem. We propose an innovative framework that renders the observable of a quantum system-specifically, the Hermitian matrix-trainable. This approach employs an end-to-end differentiable learning framework, enabling simultaneous optimization of the neural network used to program the parameterized observables and the standard quantum circuit parameters. Notably, the quantum observable parameters are dynamically programmed by the neural network, allowing the observables to adapt in real time based on the input data stream. Through numerical simulations, we demonstrate that the proposed method effectively programs observables dynamically within variational quantum circuits, achieving superior results compared to existing approaches. Notably, it delivers enhanced performance metrics, such as higher classification accuracy, thereby significantly improving the overall effectiveness of QML models.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 12.6%">
                            Quantum Computing
                        </span>
                <!-- Federated Learning: 4.7 -->
                    
                <!-- Reinforcement Learning: 3.3 -->
                    
                <!-- Bayesian Optimization: 2.9 -->
                    
                <!-- Evolutionary Algorithms: 2.4 -->
                    
                <!-- Medicine: 2.0 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- LLMs: 1.1 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                <!-- Math: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -9.4089
                </span>
                <a href="https://arxiv.org/abs/2408.07086" target="_blank" rel="noopener noreferrer">Quantum algorithms for optimizers</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Giacomo Nannicini
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This is a set of lecture notes for a Ph.D.-level course on quantum algorithms, with an emphasis on quantum optimization algorithms. It is developed for applied mathematicians and engineers, and requires no previous background in quantum mechanics. The main topics of this course, in addition to a rig</span>
                
                <span class="abstract-full" style="display: none;">This is a set of lecture notes for a Ph.D.-level course on quantum algorithms, with an emphasis on quantum optimization algorithms. It is developed for applied mathematicians and engineers, and requires no previous background in quantum mechanics. The main topics of this course, in addition to a rigorous introduction to the computational model, are: input/output models, quantum search, the quantum gradient algorithm, matrix manipulation algorithms, the mirror descent framework for semidefinite optimization (including the matrix multiplicative weights update algorithm), adiabatic optimization.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 14.1%">
                            Quantum Computing
                        </span>
                <!-- Medicine: 3.3 -->
                    
                <!-- Evolutionary Algorithms: 2.9 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Bayesian Optimization: 1.6 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- LLMs: 1.3 -->
                    
                <!-- Networks: 1.2 -->
                    
                <!-- Cryptography: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -9.6918
                </span>
                <a href="https://arxiv.org/abs/2409.12104" target="_blank" rel="noopener noreferrer">Performance of Quantum Approximate Optimization with Quantum Error Detection</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zichang He, David Amaro, Ruslan Shaydulin, Marco Pistoia
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Quantum algorithms must be scaled up to tackle real-world applications. Doing so requires overcoming the noise present on today's hardware. The quantum approximate optimization algorithm (QAOA) is a promising candidate for scaling up, due to its modest resource requirements and documented asymptotic</span>
                
                <span class="abstract-full" style="display: none;">Quantum algorithms must be scaled up to tackle real-world applications. Doing so requires overcoming the noise present on today's hardware. The quantum approximate optimization algorithm (QAOA) is a promising candidate for scaling up, due to its modest resource requirements and documented asymptotic speedup over state-of-the-art classical algorithms for some problems. However, achieving better-than-classical performance with QAOA is believed to require fault tolerance. In this paper, we demonstrate a partially fault-tolerant implementation of QAOA using the $[[k+2,k,2]]$ ``Iceberg'' error detection code. We observe that encoding the circuit with the Iceberg code improves the algorithmic performance as compared to the unencoded circuit for problems with up to $20$ logical qubits on a trapped-ion quantum computer. Additionally, we propose and calibrate a model for predicting the code performance. We use this model to characterize the limits of the Iceberg code and extrapolate its performance to future hardware with improved error rates. In particular, we show how our model can be used to determine the necessary conditions for QAOA to outperform the Goemans-Williamson algorithm on future hardware. To the best of our knowledge, our results demonstrate the largest universal quantum computing algorithm protected by partially fault-tolerant quantum error detection on practical applications to date, paving the way towards solving real-world applications with quantum computers.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 10.8%">
                            Quantum Computing
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #b3ebae" title="Confidence: 5.3%">
                            Federated Learning
                        </span>
                <!-- Evolutionary Algorithms: 4.0 -->
                    
                <!-- Computer Vision: 3.8 -->
                    
                <!-- Bayesian Optimization: 2.5 -->
                    
                <!-- Medicine: 1.9 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Hardware: 1.4 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -12.2946
                </span>
                <a href="https://arxiv.org/abs/2404.16366" target="_blank" rel="noopener noreferrer">Guarding Graph Neural Networks for Unsupervised Graph Anomaly Detection</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yuanchen Bei, Sheng Zhou, Jinke Shi, Yao Ma, Haishuai Wang, Jiajun Bu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Unsupervised graph anomaly detection aims at identifying rare patterns that deviate from the majority in a graph without the aid of labels, which is important for a variety of real-world applications. Recent advances have utilized Graph Neural Networks (GNNs) to learn effective node representations </span>
                
                <span class="abstract-full" style="display: none;">Unsupervised graph anomaly detection aims at identifying rare patterns that deviate from the majority in a graph without the aid of labels, which is important for a variety of real-world applications. Recent advances have utilized Graph Neural Networks (GNNs) to learn effective node representations by aggregating information from neighborhoods. This is motivated by the hypothesis that nodes in the graph tend to exhibit consistent behaviors with their neighborhoods. However, such consistency can be disrupted by graph anomalies in multiple ways. Most existing methods directly employ GNNs to learn representations, disregarding the negative impact of graph anomalies on GNNs, resulting in sub-optimal node representations and anomaly detection performance. While a few recent approaches have redesigned GNNs for graph anomaly detection under semi-supervised label guidance, how to address the adverse effects of graph anomalies on GNNs in unsupervised scenarios and learn effective representations for anomaly detection are still under-explored. To bridge this gap, in this paper, we propose a simple yet effective framework for Guarding Graph Neural Networks for Unsupervised Graph Anomaly Detection (G3AD). Specifically, G3AD first introduces two auxiliary networks along with correlation constraints to guard the GNNs against inconsistent information encoding. Furthermore, G3AD introduces an adaptive caching module to guard the GNNs from directly reconstructing the observed graph data that contains anomalies. Extensive experiments demonstrate that our G3AD can outperform twenty state-of-the-art methods on both synthetic and real-world graph anomaly datasets, with flexible generalization ability in different GNN backbones.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #b243cd" title="Confidence: 29.5%">
                            GNN
                        </span>
                <!-- Computer Vision: 3.5 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- LLMs: 1.9 -->
                    
                <!-- Medicine: 1.9 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.0 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -35.2371
                </span>
                <a href="https://arxiv.org/abs/2505.18282" target="_blank" rel="noopener noreferrer">Towards a Quantum-classical Augmented Network</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Nitin Jha, Abhishek Parakh, Mahadevan Subramaniam
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In the past decade, several small-scale quantum key distribution networks have been established. However, the deployment of large-scale quantum networks depends on the development of quantum repeaters, quantum channels, quantum memories, and quantum network protocols. To improve the security of exis</span>
                
                <span class="abstract-full" style="display: none;">In the past decade, several small-scale quantum key distribution networks have been established. However, the deployment of large-scale quantum networks depends on the development of quantum repeaters, quantum channels, quantum memories, and quantum network protocols. To improve the security of existing networks and adopt currently feasible quantum technologies, the next step is to augment classical networks with quantum devices, properties, and phenomena. To achieve this, we propose a change in the structure of the HTTP protocol such that it can carry both quantum and classical payload. This work lays the foundation for dividing one single network packet into classical and quantum payloads depending on the privacy needs. We implement logistic regression, CNN, LSTM, and BiLSTM models to classify the privacy label for outgoing communications. This enables reduced utilization of quantum resources allowing for a more efficient secure quantum network design. Experimental results using the proposed methods are presented.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 48.5%">
                            Quantum Computing
                        </span>
                <!-- Medicine: 3.2 -->
                    
                <!-- Evolutionary Algorithms: 2.4 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- LLMs: 1.2 -->
                    
                
            </div>
        </div>
        
    </div>
    
    <div class="date-section">
        <h2 class="date-header">2025-05-26</h2>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    7.1175
                </span>
                <a href="https://arxiv.org/abs/2504.13241" target="_blank" rel="noopener noreferrer">Recursive Deep Inverse Reinforcement Learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Paul Ghanem, Michael Potter, Owen Howell, Pau Closas, Alireza Ramezani, Deniz Erdogmus, Tales Imbiriba
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Inferring an adversary's goals from exhibited behavior is crucial for counterplanning and non-cooperative multi-agent systems in domains like cybersecurity, military, and strategy games. Deep Inverse Reinforcement Learning (IRL) methods based on maximum entropy principles show promise in recovering </span>
                
                <span class="abstract-full" style="display: none;">Inferring an adversary's goals from exhibited behavior is crucial for counterplanning and non-cooperative multi-agent systems in domains like cybersecurity, military, and strategy games. Deep Inverse Reinforcement Learning (IRL) methods based on maximum entropy principles show promise in recovering adversaries' goals but are typically offline, require large batch sizes with gradient descent, and rely on first-order updates, limiting their applicability in real-time scenarios. We propose an online Recursive Deep Inverse Reinforcement Learning (RDIRL) approach to recover the cost function governing the adversary actions and goals. Specifically, we minimize an upper bound on the standard Guided Cost Learning (GCL) objective using sequential second-order Newton updates, akin to the Extended Kalman Filter (EKF), leading to a fast (in terms of convergence) learning algorithm. We demonstrate that RDIRL is able to recover cost and reward functions of expert agents in standard and adversarial benchmark tasks. Experiments on benchmark tasks show that our proposed approach outperforms several leading IRL algorithms.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge high-confidence" style="background-color: #44f899" title="Confidence: 75.9%">
                            Reinforcement Learning
                        </span>
                <!-- LLMs: 3.5 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- Medicine: 2.1 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- HPO and AutoML: 1.8 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Datasets: 1.0 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    6.9515
                </span>
                <a href="https://arxiv.org/abs/2504.19229" target="_blank" rel="noopener noreferrer">Robust Nash equilibrium seeking based on semi-Markov switching topologies</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jianing Chen, Sitian Qin, Chuangyin Dang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper investigates a distributed robust Nash Equilibrium (NE) seeking problem in fluctuating environments. Specifically, the players, subject to the second-order dynamics, are considered to be influenced by external disturbances and uncertain dynamics while communicating via semi-Markov switchi</span>
                
                <span class="abstract-full" style="display: none;">This paper investigates a distributed robust Nash Equilibrium (NE) seeking problem in fluctuating environments. Specifically, the players, subject to the second-order dynamics, are considered to be influenced by external disturbances and uncertain dynamics while communicating via semi-Markov switching topologies. In such constantly changing network circumstances, the existence of disturbances and uncertain dynamics may directly affect the performance of most existing NE seeking algorithms. Moreover, the semi-Markov switching topologies may cause communication uncertainty, which are considered in NE seeking for the first time. To accommodate the above concerns, the following targets require to be reached simultaneously: (1) Disturbances and uncertain dynamics rejection in finite time; (2) Distributed estimation on unknown information required for players' cost functions; (3) A reasonable estimation consensus protocol under semi-Markov switching; (4) NE seeking for the second-order players. By combining supertwisting-based Integral Sliding-Mode Control (ISMC) with average consensus tracking, a novel robust NE seeking algorithm is constructed, incorporating an effective leader-follower consensus protocol. Furthermore, to lessen dispensable information transmission, a sampled-data-based event-triggered mechanism is introduced. Incorporating the advantages of both semi-Markov switching and event-triggered mechanism, another NE seeking algorithm is proposed. Through designing an appropriate Lyapunov-Krasovskii functional, it is shown that the leader-follower consensus can be achieved in the mean-square sense under event-triggered mechanism. Finally, a connectivity control game is formulated to illustrate the validity of the designed algorithms.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #546bc5" title="Confidence: 62.6%">
                            Game Theory
                        </span>
                <!-- Math: 3.7 -->
                    
                <!-- Networks: 3.2 -->
                    
                <!-- Cryptography: 2.7 -->
                    
                <!-- Finance: 2.4 -->
                    
                <!-- Pathfinding: 1.8 -->
                    
                <!-- Fuzzy Logic: 1.2 -->
                    
                <!-- Multi-armed Bandit: 1.1 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    2.7675
                </span>
                <a href="https://arxiv.org/abs/2504.10165" target="_blank" rel="noopener noreferrer">WildLive: Near Real-time Visual Wildlife Tracking onboard UAVs</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Nguyen Ngoc Dat, Tom Richardson, Matthew Watson, Kilian Meier, Jenna Kline, Sid Reid, Guy Maalouf, Duncan Hine, Majid Mirmehdi, Tilo Burghardt
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Live tracking of wildlife via high-resolution video processing directly onboard drones is widely unexplored and most existing solutions rely on streaming video to ground stations to support navigation. Yet, both autonomous animal-reactive flight control beyond visual line of sight and/or mission-spe</span>
                
                <span class="abstract-full" style="display: none;">Live tracking of wildlife via high-resolution video processing directly onboard drones is widely unexplored and most existing solutions rely on streaming video to ground stations to support navigation. Yet, both autonomous animal-reactive flight control beyond visual line of sight and/or mission-specific individual and behaviour recognition tasks rely to some degree on this capability. In response, we introduce WildLive - a near real-time animal detection and tracking framework for high-resolution imagery running directly onboard uncrewed aerial vehicles (UAVs). The system performs multi-animal detection and tracking at 17.81fps for HD and 7.53fps on 4K video streams suitable for operation during higher altitude flights to minimise animal disturbance. Our system is optimised for Jetson Orin AGX onboard hardware. It integrates the efficiency of sparse optical flow tracking and mission-specific sampling with device-optimised and proven YOLO-driven object detection and segmentation techniques. Essentially, computational resource is focused onto spatio-temporal regions of high uncertainty to significantly improve UAV processing speeds. Alongside, we introduce our WildLive dataset, which comprises 200K+ annotated animal instances across 19K+ frames from 4K UAV videos collected at the Ol Pejeta Conservancy in Kenya. All frames contain ground truth bounding boxes, segmentation masks, as well as individual tracklets and tracking point trajectories. We compare our system against current object tracking approaches including OC-SORT, ByteTrack, and SORT. Our multi-animal tracking experiments with onboard hardware confirm that near real-time high-resolution wildlife tracking is possible on UAVs whilst maintaining high accuracy levels as needed for future navigational and mission-specific animal-centric operational autonomy. Our materials are available at: https://dat-nguyenvn.github.io/WildLive/</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge high-confidence" style="background-color: #753a22" title="Confidence: 78.0%">
                            Computer Vision
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.2%">
                            Medicine
                        </span>
                <!-- LLMs: 3.3 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- HPO and AutoML: 1.8 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    1.071
                </span>
                <a href="https://arxiv.org/abs/2505.17732" target="_blank" rel="noopener noreferrer">RQR3D: Reparametrizing the regression targets for BEV-based 3D object detection</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ozsel Kilinc, Cem Tarhan
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Accurate, fast, and reliable 3D perception is essential for autonomous driving. Recently, bird's-eye view (BEV)-based perception approaches have emerged as superior alternatives to perspective-based solutions, offering enhanced spatial understanding and more natural outputs for planning. Existing BE</span>
                
                <span class="abstract-full" style="display: none;">Accurate, fast, and reliable 3D perception is essential for autonomous driving. Recently, bird's-eye view (BEV)-based perception approaches have emerged as superior alternatives to perspective-based solutions, offering enhanced spatial understanding and more natural outputs for planning. Existing BEV-based 3D object detection methods, typically adhering to angle-based representation, directly estimate the size and orientation of rotated bounding boxes. We observe that BEV-based 3D object detection is analogous to aerial oriented object detection, where angle-based methods are recognized for being affected by discontinuities in their loss functions. Drawing inspiration from this domain, we propose Restricted Quadrilateral Representation to define 3D regression targets. RQR3D regresses the smallest horizontal bounding box encapsulating the oriented box, along with the offsets between the corners of these two boxes, thereby transforming the oriented object detection problem into a keypoint regression task. RQR3D is compatible with any 3D object detection approach. We employ RQR3D within an anchor-free single-stage object detection method and introduce an objectness head to address class imbalance problem. Furthermore, we introduce a simplified radar fusion backbone that eliminates the need for voxel grouping and processes the BEV-mapped point cloud with standard 2D convolutions, rather than sparse convolutions. Extensive evaluations on the nuScenes dataset demonstrate that RQR3D achieves state-of-the-art performance in camera-radar 3D object detection, outperforming the previous best method by +4% in NDS and +2.4% in mAP, and significantly reducing the translation and orientation errors, which are crucial for safe autonomous driving. These consistent gains highlight the robustness, precision, and real-world readiness of our approach.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 18.4%">
                            Computer Vision
                        </span>
                <!-- Medicine: 3.8 -->
                    
                <!-- 3D: 2.6 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- LLMs: 1.5 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Hardware: 1.1 -->
                    
                <!-- Blockchain: 1.0 -->
                    
                <!-- Evolutionary Algorithms: 1.0 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.5733
                </span>
                <a href="https://arxiv.org/abs/2503.01468" target="_blank" rel="noopener noreferrer">Overcoming Non-stationary Dynamics with Evidential Proximal Policy Optimization</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Abdullah Akg\"ul, Gulcin Baykal, Manuel Hau{\ss}mann, Melih Kandemir
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Continuous control of non-stationary environments is a major challenge for deep reinforcement learning algorithms. The time-dependency of the state transition dynamics aggravates the notorious stability problems of model-free deep actor-critic architectures. We posit that two properties will play a </span>
                
                <span class="abstract-full" style="display: none;">Continuous control of non-stationary environments is a major challenge for deep reinforcement learning algorithms. The time-dependency of the state transition dynamics aggravates the notorious stability problems of model-free deep actor-critic architectures. We posit that two properties will play a key role in overcoming non-stationarity in transition dynamics: (i) preserving the plasticity of the critic network, (ii) directed exploration for rapid adaptation to the changing dynamics. We show that performing on-policy reinforcement learning with an evidential critic provides both of these properties. The evidential design ensures a fast and sufficiently accurate approximation to the uncertainty around the state-value, which maintains the plasticity of the critic network by detecting the distributional shifts caused by the change in dynamics. The probabilistic critic also makes the actor training objective a random variable, enabling the use of directed exploration approaches as a by-product. We name the resulting algorithm as $\textit{ Evidential Proximal Policy Optimization (EPPO)}$ due to the integral role of evidential uncertainty quantification in both policy evaluation and policy improvement stages. Through experiments on non-stationary continuous control tasks, where the environment dynamics change at regular intervals, we demonstrate that our algorithm outperforms state-of-the-art on-policy reinforcement learning variants in both task-specific and overall return.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #44f899" title="Confidence: 6.5%">
                            Reinforcement Learning
                        </span>
                <!-- Bayesian Optimization: 2.9 -->
                    
                <!-- Math: 2.3 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Networks: 1.7 -->
                    
                <!-- Medicine: 1.6 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Cryptography: 1.4 -->
                    
                <!-- Game Theory: 1.4 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Robotics: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Finance: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- LLMs: 1.1 -->
                    
                <!-- Computer Vision: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.3423
                </span>
                <a href="https://arxiv.org/abs/2505.17473" target="_blank" rel="noopener noreferrer">OrionBench: A Benchmark for Chart and Human-Recognizable Object Detection in Infographics</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jiangning Zhu, Yuxing Zhou, Zheng Wang, Juntao Yao, Yima Gu, Yuhui Yuan, Shixia Liu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Given the central role of charts in scientific, business, and communication contexts, enhancing the chart understanding capabilities of vision-language models (VLMs) has become increasingly critical. A key limitation of existing VLMs lies in their inaccurate visual grounding of infographic elements,</span>
                
                <span class="abstract-full" style="display: none;">Given the central role of charts in scientific, business, and communication contexts, enhancing the chart understanding capabilities of vision-language models (VLMs) has become increasingly critical. A key limitation of existing VLMs lies in their inaccurate visual grounding of infographic elements, including charts and human-recognizable objects (HROs) such as icons and images. However, chart understanding often requires identifying relevant elements and reasoning over them. To address this limitation, we introduce OrionBench, a benchmark designed to support the development of accurate object detection models for charts and HROs in infographics. It contains 26,250 real and 78,750 synthetic infographics, with over 6.9 million bounding box annotations. These annotations are created by combining the model-in-the-loop and programmatic methods. We demonstrate the usefulness of OrionBench through three applications: 1) constructing a Thinking-with-Boxes scheme to boost the chart understanding performance of VLMs, 2) comparing existing object detection models, and 3) applying the developed detection model to document layout and UI element detection.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.6%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.1%">
                            Computer Vision
                        </span>
                <!-- Medicine: 4.1 -->
                    
                <!-- Hardware: 2.2 -->
                    
                <!-- Datasets: 2.1 -->
                    
                <!-- Blockchain: 2.1 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.3095
                </span>
                <a href="https://arxiv.org/abs/2505.11532" target="_blank" rel="noopener noreferrer">Revisiting Adversarial Perception Attacks and Defense Methods on Autonomous Driving Systems</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Cheng Chen, Yuhong Wang, Nafis S Munir, Xiangwei Zhou, Xugui Zhou
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Autonomous driving systems (ADS) increasingly rely on deep learning-based perception models, which remain vulnerable to adversarial attacks. In this paper, we revisit adversarial attacks and defense methods, focusing on road sign recognition and lead object detection and prediction (e.g., relative d</span>
                
                <span class="abstract-full" style="display: none;">Autonomous driving systems (ADS) increasingly rely on deep learning-based perception models, which remain vulnerable to adversarial attacks. In this paper, we revisit adversarial attacks and defense methods, focusing on road sign recognition and lead object detection and prediction (e.g., relative distance). Using a Level-2 production ADS, OpenPilot by Comma$.$ai, and the widely adopted YOLO model, we systematically examine the impact of adversarial perturbations and assess defense techniques, including adversarial training, image processing, contrastive learning, and diffusion models. Our experiments highlight both the strengths and limitations of these methods in mitigating complex attacks. Through targeted evaluations of model robustness, we aim to provide deeper insights into the vulnerabilities of ADS perception systems and contribute guidance for developing more resilient defense strategies.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.6%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 6.2%">
                            Computer Vision
                        </span>
                <!-- Medicine: 5.0 -->
                    
                <!-- Blockchain: 2.6 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2852
                </span>
                <a href="https://arxiv.org/abs/2505.17692" target="_blank" rel="noopener noreferrer">ViP$^2$-CLIP: Visual-Perception Prompting with Unified Alignment for Zero-Shot Anomaly Detection</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ziteng Yang, Jingzehua Xu, Yanshu Li, Zepeng Li, Yeqiang Wang, Xinghui Li
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Zero-shot anomaly detection (ZSAD) aims to detect anomalies without any target domain training samples, relying solely on external auxiliary data. Existing CLIP-based methods attempt to activate the model's ZSAD potential via handcrafted or static learnable prompts. The former incur high engineering</span>
                
                <span class="abstract-full" style="display: none;">Zero-shot anomaly detection (ZSAD) aims to detect anomalies without any target domain training samples, relying solely on external auxiliary data. Existing CLIP-based methods attempt to activate the model's ZSAD potential via handcrafted or static learnable prompts. The former incur high engineering costs and limited semantic coverage, whereas the latter apply identical descriptions across diverse anomaly types, thus fail to adapt to complex variations. Furthermore, since CLIP is originally pretrained on large-scale classification tasks, its anomaly segmentation quality is highly sensitive to the exact wording of class names, severely constraining prompting strategies that depend on class labels. To address these challenges, we introduce ViP$^{2}$-CLIP. The key insight of ViP$^{2}$-CLIP is a Visual-Perception Prompting (ViP-Prompt) mechanism, which fuses global and multi-scale local visual context to adaptively generate fine-grained textual prompts, eliminating manual templates and class-name priors. This design enables our model to focus on precise abnormal regions, making it particularly valuable when category labels are ambiguous or privacy-constrained. Extensive experiments on 15 industrial and medical benchmarks demonstrate that ViP$^{2}$-CLIP achieves state-of-the-art performance and robust cross-domain generalization.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.3%">
                            Computer Vision
                        </span>
                <!-- LLMs: 3.6 -->
                    
                <!-- Medicine: 3.1 -->
                    
                <!-- GNN: 3.1 -->
                    
                <!-- Federated Learning: 3.0 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2801
                </span>
                <a href="https://arxiv.org/abs/2505.17364" target="_blank" rel="noopener noreferrer">Optimizing YOLOv8 for Parking Space Detection: Comparative Analysis of Custom YOLOv8 Architecture</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Apar Pokhrel, Gia Dao
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Parking space occupancy detection is a critical component in the development of intelligent parking management systems. Traditional object detection approaches, such as YOLOv8, provide fast and accurate vehicle detection across parking lots but can struggle with borderline cases, such as partially v</span>
                
                <span class="abstract-full" style="display: none;">Parking space occupancy detection is a critical component in the development of intelligent parking management systems. Traditional object detection approaches, such as YOLOv8, provide fast and accurate vehicle detection across parking lots but can struggle with borderline cases, such as partially visible vehicles, small vehicles (e.g., motorcycles), and poor lighting conditions. In this work, we perform a comprehensive comparative analysis of customized backbone architectures integrated with YOLOv8. Specifically, we evaluate various backbones -- ResNet-18, VGG16, EfficientNetV2, Ghost -- on the PKLot dataset in terms of detection accuracy and computational efficiency. Experimental results highlight each architecture's strengths and trade-offs, providing insight into selecting suitable models for parking occupancy.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.9%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.6%">
                            Computer Vision
                        </span>
                <!-- Medicine: 4.6 -->
                    
                <!-- Blockchain: 2.4 -->
                    
                <!-- Datasets: 2.1 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2413
                </span>
                <a href="https://arxiv.org/abs/2505.17245" target="_blank" rel="noopener noreferrer">Extending Dataset Pruning to Object Detection: A Variance-based Approach</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ryota Yagi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Dataset pruning -- selecting a small yet informative subset of training data -- has emerged as a promising strategy for efficient machine learning, offering significant reductions in computational cost and storage compared to alternatives like dataset distillation. While pruning methods have shown s</span>
                
                <span class="abstract-full" style="display: none;">Dataset pruning -- selecting a small yet informative subset of training data -- has emerged as a promising strategy for efficient machine learning, offering significant reductions in computational cost and storage compared to alternatives like dataset distillation. While pruning methods have shown strong performance in image classification, their extension to more complex computer vision tasks, particularly object detection, remains relatively underexplored. In this paper, we present the first principled extension of classification pruning techniques to the object detection domain, to the best of our knowledge. We identify and address three key challenges that hinder this transition: the Object-Level Attribution Problem, the Scoring Strategy Problem, and the Image-Level Aggregation Problem. To overcome these, we propose tailored solutions, including a novel scoring method called Variance-based Prediction Score (VPS). VPS leverages both Intersection over Union (IoU) and confidence scores to effectively identify informative training samples specific to detection tasks. Extensive experiments on PASCAL VOC and MS COCO demonstrate that our approach consistently outperforms prior dataset pruning methods in terms of mean Average Precision (mAP). We also show that annotation count and class distribution shift can influence detection performance, but selecting informative examples is a more critical factor than dataset size or balance. Our work bridges dataset pruning and object detection, paving the way for dataset pruning in complex vision tasks.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.3%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.4%">
                            Computer Vision
                        </span>
                <!-- GNN: 2.1 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Medicine: 2.0 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Hardware: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2226
                </span>
                <a href="https://arxiv.org/abs/2412.11803" target="_blank" rel="noopener noreferrer">UAlign: Leveraging Uncertainty Estimations for Factuality Alignment on Large Language Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Boyang Xue, Fei Mi, Qi Zhu, Hongru Wang, Rui Wang, Sheng Wang, Erxin Yu, Xuming Hu, Kam-Fai Wong
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Despite demonstrating impressive capabilities, Large Language Models (LLMs) still often struggle to accurately express the factual knowledge they possess, especially in cases where the LLMs' knowledge boundaries are ambiguous. To improve LLMs' factual expressions, we propose the UAlign framework, wh</span>
                
                <span class="abstract-full" style="display: none;">Despite demonstrating impressive capabilities, Large Language Models (LLMs) still often struggle to accurately express the factual knowledge they possess, especially in cases where the LLMs' knowledge boundaries are ambiguous. To improve LLMs' factual expressions, we propose the UAlign framework, which leverages Uncertainty estimations to represent knowledge boundaries, and then explicitly incorporates these representations as input features into prompts for LLMs to Align with factual knowledge. First, we prepare the dataset on knowledge question-answering (QA) samples by calculating two uncertainty estimations, including confidence score and semantic entropy, to represent the knowledge boundaries for LLMs. Subsequently, using the prepared dataset, we train a reward model that incorporates uncertainty estimations and then employ the Proximal Policy Optimization (PPO) algorithm for factuality alignment on LLMs. Experimental results indicate that, by integrating uncertainty representations in LLM alignment, the proposed UAlign can significantly enhance the LLMs' capacities to confidently answer known questions and refuse unknown questions on both in-domain and out-of-domain tasks, showing reliability improvements and good generalizability over various prompt- and training-based baselines.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 11.0%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.7%">
                            Computer Vision
                        </span>
                <!-- Medicine: 2.8 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- 3D: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2125
                </span>
                <a href="https://arxiv.org/abs/2505.17460" target="_blank" rel="noopener noreferrer">Learning to Focus: Context Extraction for Efficient Code Vulnerability Detection with Language Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Xinran Zheng, Xingzhi Qian, Huichi Zhou, Shuo Yang, Yiling He, Suman Jana, Lorenzo Cavallaro
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Language models (LMs) show promise for vulnerability detection but struggle with long, real-world code due to sparse and uncertain vulnerability locations. These issues, exacerbated by token limits, often cause models to miss vulnerability-related signals, thereby impairing effective learning. A key</span>
                
                <span class="abstract-full" style="display: none;">Language models (LMs) show promise for vulnerability detection but struggle with long, real-world code due to sparse and uncertain vulnerability locations. These issues, exacerbated by token limits, often cause models to miss vulnerability-related signals, thereby impairing effective learning. A key intuition is to enhance LMs with concise, information-rich context. Commit-based annotations offer precise, CWE-agnostic supervision, but are unavailable during inference, as they depend on historical code changes. Moreover, their extreme sparsity, often covering only a few lines, makes it difficult for LMs to process directly. In this paper, we propose FocusVul, a model-agnostic framework that improves LM-based vulnerability detection by learning to select sensitive context. FocusVul learns commit-based annotation patterns through hierarchical semantic modeling and generalizes them to identify line-level vulnerability-relevant regions during inference. It then extracts LM-oriented context via both dependency and execution flows surrounding selected regions, yielding semantically rich inputs for effective vulnerability detection. Experiments on real-world benchmarks show that FocusVul consistently outperforms heuristic-based and full-function fine-tuning approaches, improving classification performance by 164.04% and reducing FLOPs by 19.12% on average.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.8%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.1%">
                            Computer Vision
                        </span>
                <!-- Medicine: 2.9 -->
                    
                <!-- HPO and AutoML: 2.8 -->
                    
                <!-- Federated Learning: 2.8 -->
                    
                <!-- GNN: 2.3 -->
                    
                <!-- Decision Trees: 2.3 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- 3D: 1.8 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.2109
                </span>
                <a href="https://arxiv.org/abs/2411.14503" target="_blank" rel="noopener noreferrer">Planning-Driven Programming: A Large Language Model Programming Workflow</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Chao Lei, Yanchuan Chang, Nir Lipovetzky, Krista A. Ehinger
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The strong performance of large language models (LLMs) raises extensive discussion on their application to code generation. Recent research suggests continuous program refinements through visible tests to improve code generation accuracy in LLMs. However, these methods suffer from LLMs' inefficiency</span>
                
                <span class="abstract-full" style="display: none;">The strong performance of large language models (LLMs) raises extensive discussion on their application to code generation. Recent research suggests continuous program refinements through visible tests to improve code generation accuracy in LLMs. However, these methods suffer from LLMs' inefficiency and limited reasoning capacity. In this work, we propose an LLM programming workflow (LPW) designed to improve both initial code generation and subsequent refinements within a structured two-phase workflow. Specifically, the solution generation phase formulates a solution plan, which is then verified through visible tests to specify the intended natural language solution. Subsequently, the code implementation phase drafts an initial code according to the solution plan and its verification. If the generated code fails the visible tests, the plan verification serves as the intended solution to consistently inform the refinement process for correcting bugs. Compared to state-of-the-art methods across various existing LLMs, LPW significantly improves the Pass@1 accuracy by up to 16.4% on well-established text-to-code generation benchmarks. LPW also sets new state-of-the-art Pass@1 accuracy, achieving 98.2% on HumanEval, 84.8% on MBPP, 59.3% on LiveCode, 62.6% on APPS, and 34.7% on CodeContest, using GPT-4o as the backbone. Our code is publicly available at: https://github.com/you68681/lpw</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.9%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.0%">
                            Computer Vision
                        </span>
                <!-- Federated Learning: 2.4 -->
                    
                <!-- GNN: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 2.2 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Medicine: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.1969
                </span>
                <a href="https://arxiv.org/abs/2505.17654" target="_blank" rel="noopener noreferrer">EVADE: Multimodal Benchmark for Evasive Content Detection in E-Commerce Applications</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ancheng Xu, Zhihao Yang, Jingpeng Li, Guanghu Yuan, Longze Chen, Liang Yan, Jiehui Zhou, Zhen Qin, Hengyun Chang, Hamid Alinejad-Rokny, Bo Zheng, Min Yang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">E-commerce platforms increasingly rely on Large Language Models (LLMs) and Vision-Language Models (VLMs) to detect illicit or misleading product content. However, these models remain vulnerable to evasive content: inputs (text or images) that superficially comply with platform policies while covertl</span>
                
                <span class="abstract-full" style="display: none;">E-commerce platforms increasingly rely on Large Language Models (LLMs) and Vision-Language Models (VLMs) to detect illicit or misleading product content. However, these models remain vulnerable to evasive content: inputs (text or images) that superficially comply with platform policies while covertly conveying prohibited claims. Unlike traditional adversarial attacks that induce overt failures, evasive content exploits ambiguity and context, making it far harder to detect. Existing robustness benchmarks provide little guidance for this demanding, real-world challenge. We introduce EVADE, the first expert-curated, Chinese, multimodal benchmark specifically designed to evaluate foundation models on evasive content detection in e-commerce. The dataset contains 2,833 annotated text samples and 13,961 images spanning six demanding product categories, including body shaping, height growth, and health supplements. Two complementary tasks assess distinct capabilities: Single-Violation, which probes fine-grained reasoning under short prompts, and All-in-One, which tests long-context reasoning by merging overlapping policy rules into unified instructions. Notably, the All-in-One setting significantly narrows the performance gap between partial and full-match accuracy, suggesting that clearer rule definitions improve alignment between human and model judgment. We benchmark 26 mainstream LLMs and VLMs and observe substantial performance gaps: even state-of-the-art models frequently misclassify evasive samples. By releasing EVADE and strong baselines, we provide the first rigorous standard for evaluating evasive-content detection, expose fundamental limitations in current multimodal reasoning, and lay the groundwork for safer and more transparent content moderation systems in e-commerce. The dataset is publicly available at https://huggingface.co/datasets/koenshen/EVADE-Bench.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 15.0%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.2%">
                            Computer Vision
                        </span>
                <!-- Medicine: 4.6 -->
                    
                <!-- Datasets: 2.2 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Decision Trees: 2.0 -->
                    
                <!-- HPO and AutoML: 1.9 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-positive">
                    0.1188
                </span>
                <a href="https://arxiv.org/abs/2505.17393" target="_blank" rel="noopener noreferrer">Spectral Mixture Kernels for Bayesian Optimization</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yi Zhang, Cheng Hua
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Bayesian Optimization (BO) is a widely used approach for solving expensive black-box optimization tasks. However, selecting an appropriate probabilistic surrogate model remains an important yet challenging problem. In this work, we introduce a novel Gaussian Process (GP)-based BO method that incorpo</span>
                
                <span class="abstract-full" style="display: none;">Bayesian Optimization (BO) is a widely used approach for solving expensive black-box optimization tasks. However, selecting an appropriate probabilistic surrogate model remains an important yet challenging problem. In this work, we introduce a novel Gaussian Process (GP)-based BO method that incorporates spectral mixture kernels, derived from spectral densities formed by scale-location mixtures of Cauchy and Gaussian distributions. This method achieves a significant improvement in both efficiency and optimization performance, matching the computational speed of simpler kernels while delivering results that outperform more complex models and automatic BO methods. We provide bounds on the information gain and cumulative regret associated with obtaining the optimum. Extensive numerical experiments demonstrate that our method consistently outperforms existing baselines across a diverse range of synthetic and real-world problems, including both low- and high-dimensional settings.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.4%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #31bb31" title="Confidence: 5.2%">
                            Bayesian Optimization
                        </span>
                <!-- Medicine: 3.5 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- 3D: 2.0 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.062
                </span>
                <a href="https://arxiv.org/abs/2505.17201" target="_blank" rel="noopener noreferrer">A Framework for Multi-View Multiple Object Tracking using Single-View Multi-Object Trackers on Fish Data</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Chaim Chai Elchik, Fatemeh Karimi Nejadasl, Seyed Sahand Mohammadi Ziabari, Ali Mohammed Mansoor Alsahag
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Multi-object tracking (MOT) in computer vision has made significant advancements, yet tracking small fish in underwater environments presents unique challenges due to complex 3D motions and data noise. Traditional single-view MOT models often fall short in these settings. This thesis addresses these</span>
                
                <span class="abstract-full" style="display: none;">Multi-object tracking (MOT) in computer vision has made significant advancements, yet tracking small fish in underwater environments presents unique challenges due to complex 3D motions and data noise. Traditional single-view MOT models often fall short in these settings. This thesis addresses these challenges by adapting state-of-the-art single-view MOT models, FairMOT and YOLOv8, for underwater fish detecting and tracking in ecological studies. The core contribution of this research is the development of a multi-view framework that utilizes stereo video inputs to enhance tracking accuracy and fish behavior pattern recognition. By integrating and evaluating these models on underwater fish video datasets, the study aims to demonstrate significant improvements in precision and reliability compared to single-view approaches. The proposed framework detects fish entities with a relative accuracy of 47% and employs stereo-matching techniques to produce a novel 3D output, providing a more comprehensive understanding of fish movements and interactions</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 8.7%">
                            LLMs
                        </span>
                <!-- Medicine: 4.9 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Datasets: 1.8 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Robotics: 1.2 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.064
                </span>
                <a href="https://arxiv.org/abs/2505.17426" target="_blank" rel="noopener noreferrer">UniTTS: An end-to-end TTS system without decoupling of acoustic and semantic information</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Rui Wang, Qianguo Sun, Tianrong Chen, Zhiyun Zeng, Junlong Wu, Jiaxing Zhang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The emergence of multi-codebook neutral audio codecs such as Residual Vector Quantization (RVQ) and Group Vector Quantization (GVQ) has significantly advanced Large-Language-Model (LLM) based Text-to-Speech (TTS) systems. These codecs are crucial in separating semantic and acoustic information while</span>
                
                <span class="abstract-full" style="display: none;">The emergence of multi-codebook neutral audio codecs such as Residual Vector Quantization (RVQ) and Group Vector Quantization (GVQ) has significantly advanced Large-Language-Model (LLM) based Text-to-Speech (TTS) systems. These codecs are crucial in separating semantic and acoustic information while efficiently harnessing semantic priors. However, since semantic and acoustic information cannot be fully aligned, a significant drawback of these methods when applied to LLM-based TTS is that large language models may have limited access to comprehensive audio information. To address this limitation, we propose DistilCodec and UniTTS, which collectively offer the following advantages: 1) This method can distill a multi-codebook audio codec into a single-codebook audio codec with 32,768 codes while achieving a near 100\% utilization. 2) As DistilCodec does not employ a semantic alignment scheme, a large amount of high-quality unlabeled audio (such as audiobooks with sound effects, songs, etc.) can be incorporated during training, further expanding data diversity and broadening its applicability. 3) Leveraging the comprehensive audio information modeling of DistilCodec, we integrated three key tasks into UniTTS's pre-training framework: audio modality autoregression, text modality autoregression, and speech-text cross-modal autoregression. This allows UniTTS to accept interleaved text and speech/audio prompts while substantially preserving LLM's text capabilities. 4) UniTTS employs a three-stage training process: Pre-Training, Supervised Fine-Tuning (SFT), and Alignment. Source code and model checkpoints are publicly available at https://github.com/IDEA-Emdoor-Lab/UniTTS and https://github.com/IDEA-Emdoor-Lab/DistilCodec.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 9.6%">
                            LLMs
                        </span>
                <!-- Medicine: 4.7 -->
                    
                <!-- Blockchain: 2.5 -->
                    
                <!-- Datasets: 2.0 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- 3D: 1.6 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- T2I: 1.0 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.0901
                </span>
                <a href="https://arxiv.org/abs/2503.13794" target="_blank" rel="noopener noreferrer">LED: LLM Enhanced Open-Vocabulary Object Detection without Human Curated Data Generation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yang Zhou, Shiyu Zhao, Yuxiao Chen, Zhenting Wang, Can Jin, Dimitris N. Metaxas
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Large foundation models trained on large-scale vision-language data can boost Open-Vocabulary Object Detection (OVD) via synthetic training data, yet the hand-crafted pipelines often introduce bias and overfit to specific prompts. We sidestep this issue by directly fusing hidden states from Large La</span>
                
                <span class="abstract-full" style="display: none;">Large foundation models trained on large-scale vision-language data can boost Open-Vocabulary Object Detection (OVD) via synthetic training data, yet the hand-crafted pipelines often introduce bias and overfit to specific prompts. We sidestep this issue by directly fusing hidden states from Large Language Models (LLMs) into detectors-an avenue surprisingly under-explored. This paper presents a systematic method to enhance visual grounding by utilizing decoder layers of the LLM of an MLLM. We introduce a zero-initialized cross-attention adapter to enable efficient knowledge fusion from LLMs to object detectors, a new approach called LED (LLM Enhanced Open-Vocabulary Object Detection). We find that intermediate LLM layers already encode rich spatial semantics; adapting only the early layers yields most of the gain. With Swin-T as the vision encoder, Qwen2-0.5B + LED lifts GroundingDINO by 3.82 % on OmniLabel at just 8.7 % extra GFLOPs, and a larger vision backbone pushes the improvement to 6.22 %. Extensive ablations on adapter variants, LLM scales and fusion depths further corroborate our design.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 13.5%">
                            LLMs
                        </span>
                <!-- Computer Vision: 3.3 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Medicine: 1.5 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Hardware: 1.0 -->
                    
                <!-- Cryptography: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.111
                </span>
                <a href="https://arxiv.org/abs/2505.15400" target="_blank" rel="noopener noreferrer">When to Continue Thinking: Adaptive Thinking Mode Switching for Efficient Reasoning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Xiaoyun Zhang, Jingqing Ruan, Xing Ma, Yawen Zhu, Haodong Zhao, Hao Li, Jiansong Chen, Ke Zeng, Xunliang Cai
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Large reasoning models (LRMs) achieve remarkable performance via long reasoning chains, but often incur excessive computational overhead due to redundant reasoning, especially on simple tasks. In this work, we systematically quantify the upper bounds of LRMs under both Long-Thinking and No-Thinking </span>
                
                <span class="abstract-full" style="display: none;">Large reasoning models (LRMs) achieve remarkable performance via long reasoning chains, but often incur excessive computational overhead due to redundant reasoning, especially on simple tasks. In this work, we systematically quantify the upper bounds of LRMs under both Long-Thinking and No-Thinking modes, and uncover the phenomenon of "Internal Self-Recovery Mechanism" where models implicitly supplement reasoning during answer generation. Building on this insight, we propose Adaptive Self-Recovery Reasoning (ASRR), a framework that suppresses unnecessary reasoning and enables implicit recovery. By introducing accuracy-aware length reward regulation, ASRR adaptively allocates reasoning effort according to problem difficulty, achieving high efficiency with negligible performance sacrifice. Experiments across multiple benchmarks and models show that, compared with GRPO, ASRR reduces reasoning budget by up to 32.5% (1.5B) and 25.7% (7B) with minimal accuracy loss (1.2% and 0.6% pass@1), and significantly boosts harmless rates on safety benchmarks (up to +21.7%). Our results highlight the potential of ASRR for enabling efficient, adaptive, and safer reasoning in LRMs.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 14.4%">
                            LLMs
                        </span>
                <!-- Medicine: 3.8 -->
                    
                <!-- Computer Vision: 3.4 -->
                    
                <!-- Federated Learning: 2.9 -->
                    
                <!-- Evolutionary Algorithms: 2.2 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- HPO and AutoML: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- T2I: 1.0 -->
                    
                <!-- Datasets: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.1448
                </span>
                <a href="https://arxiv.org/abs/2505.17447" target="_blank" rel="noopener noreferrer">LeTS: Learning to Think-and-Search via Process-and-Outcome Reward Hybridization</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Qi Zhang, Shouqing Yang, Lirong Gao, Hao Chen, Xiaomeng Hu, Jinglei Chen, Jiexiang Wang, Sheng Guo, Bo Zheng, Haobo Wang, Junbo Zhao
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Large language models (LLMs) have demonstrated impressive capabilities in reasoning with the emergence of reasoning models like OpenAI-o1 and DeepSeek-R1. Recent research focuses on integrating reasoning capabilities into the realm of retrieval-augmented generation (RAG) via outcome-supervised reinf</span>
                
                <span class="abstract-full" style="display: none;">Large language models (LLMs) have demonstrated impressive capabilities in reasoning with the emergence of reasoning models like OpenAI-o1 and DeepSeek-R1. Recent research focuses on integrating reasoning capabilities into the realm of retrieval-augmented generation (RAG) via outcome-supervised reinforcement learning (RL) approaches, while the correctness of intermediate think-and-search steps is usually neglected. To address this issue, we design a process-level reward module to mitigate the unawareness of intermediate reasoning steps in outcome-level supervision without additional annotation. Grounded on this, we propose Learning to Think-and-Search (LeTS), a novel framework that hybridizes stepwise process reward and outcome-based reward to current RL methods for RAG. Extensive experiments demonstrate the generalization and inference efficiency of LeTS across various RAG benchmarks. In addition, these results reveal the potential of process- and outcome-level reward hybridization in boosting LLMs' reasoning ability via RL under other scenarios. The code will be released soon.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 17.4%">
                            LLMs
                        </span>
                <!-- Federated Learning: 3.6 -->
                    
                <!-- Medicine: 3.0 -->
                    
                <!-- Evolutionary Algorithms: 2.2 -->
                    
                <!-- GNN: 1.9 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Bayesian Optimization: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- Datasets: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.1465
                </span>
                <a href="https://arxiv.org/abs/2503.08200" target="_blank" rel="noopener noreferrer">Route Sparse Autoencoder to Interpret Large Language Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Wei Shi, Sihang Li, Tao Liang, Mingyang Wan, Guojun Ma, Xiang Wang, Xiangnan He
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Mechanistic interpretability of large language models (LLMs) aims to uncover the internal processes of information propagation and reasoning. Sparse autoencoders (SAEs) have demonstrated promise in this domain by extracting interpretable and monosemantic features. However, prior works primarily focu</span>
                
                <span class="abstract-full" style="display: none;">Mechanistic interpretability of large language models (LLMs) aims to uncover the internal processes of information propagation and reasoning. Sparse autoencoders (SAEs) have demonstrated promise in this domain by extracting interpretable and monosemantic features. However, prior works primarily focus on feature extraction from a single layer, failing to effectively capture activations that span multiple layers. In this paper, we introduce Route Sparse Autoencoder (RouteSAE), a new framework that integrates a routing mechanism with a shared SAE to efficiently extract features from multiple layers. It dynamically assigns weights to activations from different layers, incurring minimal parameter overhead while achieving high interpretability and flexibility for targeted feature manipulation. We evaluate RouteSAE through extensive experiments on Llama-3.2-1B-Instruct. Specifically, under the same sparsity constraint of 64, RouteSAE extracts 22.5% more features than baseline SAEs while achieving a 22.3% higher interpretability score. These results underscore the potential of RouteSAE as a scalable and effective method for LLM interpretability, with applications in feature discovery and model intervention. Our codes are available at https://github.com/swei2001/RouteSAEs.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 20.5%">
                            LLMs
                        </span>
                <!-- Medicine: 3.5 -->
                    
                <!-- GNN: 2.5 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                <!-- Datasets: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.2747
                </span>
                <a href="https://arxiv.org/abs/2505.18120" target="_blank" rel="noopener noreferrer">Bidirectional Knowledge Distillation for Enhancing Sequential Recommendation with Large Language Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jiongran Wu, Jiahao Liu, Dongsheng Li, Guangping Zhang, Mingzhe Han, Hansu Gu, Peng Zhang, Li Shang, Tun Lu, Ning Gu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Large language models (LLMs) have demonstrated exceptional performance in understanding and generating semantic patterns, making them promising candidates for sequential recommendation tasks. However, when combined with conventional recommendation models (CRMs), LLMs often face challenges related to</span>
                
                <span class="abstract-full" style="display: none;">Large language models (LLMs) have demonstrated exceptional performance in understanding and generating semantic patterns, making them promising candidates for sequential recommendation tasks. However, when combined with conventional recommendation models (CRMs), LLMs often face challenges related to high inference costs and static knowledge transfer methods. In this paper, we propose a novel mutual distillation framework, LLMD4Rec, that fosters dynamic and bidirectional knowledge exchange between LLM-centric and CRM-based recommendation systems. Unlike traditional unidirectional distillation methods, LLMD4Rec enables iterative optimization by alternately refining both models, enhancing the semantic understanding of CRMs and enriching LLMs with collaborative signals from user-item interactions. By leveraging sample-wise adaptive weighting and aligning output distributions, our approach eliminates the need for additional parameters while ensuring effective knowledge transfer. Extensive experiments on real-world datasets demonstrate that LLMD4Rec significantly improves recommendation accuracy across multiple benchmarks without increasing inference costs. This method provides a scalable and efficient solution for combining the strengths of both LLMs and CRMs in sequential recommendation systems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 38.5%">
                            LLMs
                        </span>
                <!-- Medicine: 4.4 -->
                    
                <!-- Computer Vision: 2.9 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Blockchain: 1.3 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- T2I: 1.2 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -0.9394
                </span>
                <a href="https://arxiv.org/abs/2501.11960" target="_blank" rel="noopener noreferrer">TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yang Cao, Sikun Yang, Chen Li, Haolong Xiang, Lianyong Qi, Bo Liu, Rongsheng Li, Ming Liu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Text anomaly detection is crucial for identifying spam, misinformation, and offensive language in natural language processing tasks. Despite the growing adoption of embedding-based methods, their effectiveness and generalizability across diverse application scenarios remain under-explored. To addres</span>
                
                <span class="abstract-full" style="display: none;">Text anomaly detection is crucial for identifying spam, misinformation, and offensive language in natural language processing tasks. Despite the growing adoption of embedding-based methods, their effectiveness and generalizability across diverse application scenarios remain under-explored. To address this, we present TAD-Bench, a comprehensive benchmark designed to systematically evaluate embedding-based approaches for text anomaly detection. TAD-Bench integrates multiple datasets spanning different domains, combining state-of-the-art embeddings from large language models with a variety of anomaly detection algorithms. Through extensive experiments, we analyze the interplay between embeddings and detection methods, uncovering their strengths, weaknesses, and applicability to different tasks. These findings offer new perspectives on building more robust, efficient, and generalizable anomaly detection systems for real-world applications.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.6%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.4%">
                            Computer Vision
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.1%">
                            Medicine
                        </span>
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- 3D: 1.5 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.114
                </span>
                <a href="https://arxiv.org/abs/2505.17098" target="_blank" rel="noopener noreferrer">TACO: Enhancing Multimodal In-context Learning via Task Mapping-Guided Sequence Configuration</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yanshu Li, Tian Yun, Jianjiang Yang, Pinyuan Feng, Jinfa Huang, Ruixiang Tang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Multimodal in-context learning (ICL) has emerged as a key mechanism for harnessing the capabilities of large vision-language models (LVLMs). However, its effectiveness remains highly sensitive to the quality of input in-context sequences, particularly for tasks involving complex reasoning or open-en</span>
                
                <span class="abstract-full" style="display: none;">Multimodal in-context learning (ICL) has emerged as a key mechanism for harnessing the capabilities of large vision-language models (LVLMs). However, its effectiveness remains highly sensitive to the quality of input in-context sequences, particularly for tasks involving complex reasoning or open-ended generation. A major limitation is our limited understanding of how LVLMs actually exploit these sequences during inference. To bridge this gap, we systematically interpret multimodal ICL through the lens of task mapping, which reveals how local and global relationships within and among demonstrations guide model reasoning. Building on this insight, we present TACO, a lightweight transformer-based model equipped with task-aware attention that dynamically configures in-context sequences. By injecting task-mapping signals into the autoregressive decoding process, TACO creates a bidirectional synergy between sequence construction and task reasoning. Experiments on five LVLMs and nine datasets demonstrate that TACO consistently surpasses baselines across diverse ICL tasks. These results position task mapping as a valuable perspective for interpreting and improving multimodal ICL.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.5%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.3%">
                            Medicine
                        </span>
                <!-- Federated Learning: 3.1 -->
                    
                <!-- GNN: 2.3 -->
                    
                <!-- Quantum Computing: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Computer Vision: 1.9 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Decision Trees: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.2212
                </span>
                <a href="https://arxiv.org/abs/2505.17105" target="_blank" rel="noopener noreferrer">Transparency in Healthcare AI: Testing European Regulatory Provisions against Users' Transparency Needs</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Anna Spagnolli, Cecilia Tolomini, Elisa Beretta, Claudio Sarra
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Artificial Intelligence (AI) plays an essential role in healthcare and is pervasively incorporated into medical software and equipment. In the European Union, healthcare is a high-risk application domain for AI, and providers must prepare Instructions for Use (IFU) according to the European regulati</span>
                
                <span class="abstract-full" style="display: none;">Artificial Intelligence (AI) plays an essential role in healthcare and is pervasively incorporated into medical software and equipment. In the European Union, healthcare is a high-risk application domain for AI, and providers must prepare Instructions for Use (IFU) according to the European regulation 2024/1689 (AI Act). To this regulation, the principle of transparency is cardinal and requires the IFU to be clear and relevant to the users. This study tests whether these latter requirements are satisfied by the IFU structure. A survey was administered online via the Qualtrics platform to four types of direct stakeholders, i.e., managers (N = 238), healthcare professionals (N = 115), patients (N = 229), and Information Technology experts (N = 230). The participants rated the relevance of a set of transparency needs and indicated the IFU section addressing them. The results reveal differentiated priorities across stakeholders and a troubled mapping of transparency needs onto the IFU structure. Recommendations to build a locally meaningful IFU are derived.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.3%">
                            Medicine
                        </span>
                <!-- Blockchain: 2.3 -->
                    
                <!-- LLMs: 2.3 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Datasets: 1.0 -->
                    
                <!-- Networks: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.248
                </span>
                <a href="https://arxiv.org/abs/2505.17862" target="_blank" rel="noopener noreferrer">Daily-Omni: Towards Audio-Visual Reasoning with Temporal Alignment across Modalities</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ziwei Zhou, Rui Wang, Zuxuan Wu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Recent Multimodal Large Language Models (MLLMs) achieve promising performance on visual and audio benchmarks independently. However, the ability of these models to process cross-modal information synchronously remains largely unexplored. In this paper, we introduce: 1) Daily-Omni, an Audio-Visual Qu</span>
                
                <span class="abstract-full" style="display: none;">Recent Multimodal Large Language Models (MLLMs) achieve promising performance on visual and audio benchmarks independently. However, the ability of these models to process cross-modal information synchronously remains largely unexplored. In this paper, we introduce: 1) Daily-Omni, an Audio-Visual Questioning and Answering benchmark comprising 684 videos of daily life scenarios from diverse sources, rich in both audio and visual information, and featuring 1197 multiple-choice QA pairs across 6 major tasks; 2) Daily-Omni QA Generation Pipeline, which includes automatic annotation, QA generation and QA optimization, significantly improves efficiency for human evaluation and scalability of the benchmark; 3) Daily-Omni-Agent, a training-free agent utilizing open-source Visual Language Model (VLM), Audio Language Model (ALM) and Automatic Speech Recognition (ASR) model to establish a baseline for this benchmark. The results show that current MLLMs still struggle significantly with tasks requiring audio-visual integration, but combining VLMs and ALMs with simple temporal alignment techniques can achieve substantially better performance. Codes and benchmark are available at \href{https://github.com/Lliar-liar/Daily-Omni}{https://github.com/Lliar-liar/Daily-Omni}.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 15.2%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.3%">
                            Medicine
                        </span>
                <!-- Computer Vision: 3.1 -->
                    
                <!-- Datasets: 2.0 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Federated Learning: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- T2I: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.3411
                </span>
                <a href="https://arxiv.org/abs/2505.17233" target="_blank" rel="noopener noreferrer">Semantic-Aware Interpretable Multimodal Music Auto-Tagging</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Andreas Patakis, Vassilis Lyberatos, Spyridon Kantarelis, Edmund Dervakos, Giorgos Stamou
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Music auto-tagging is essential for organizing and discovering music in extensive digital libraries. While foundation models achieve exceptional performance in this domain, their outputs often lack interpretability, limiting trust and usability for researchers and end-users alike. In this work, we p</span>
                
                <span class="abstract-full" style="display: none;">Music auto-tagging is essential for organizing and discovering music in extensive digital libraries. While foundation models achieve exceptional performance in this domain, their outputs often lack interpretability, limiting trust and usability for researchers and end-users alike. In this work, we present an interpretable framework for music auto-tagging that leverages groups of musically meaningful multimodal features, derived from signal processing, deep learning, ontology engineering, and natural language processing. To enhance interpretability, we cluster features semantically and employ an expectation maximization algorithm, assigning distinct weights to each group based on its contribution to the tagging process. Our method achieves competitive tagging performance while offering a deeper understanding of the decision-making process, paving the way for more transparent and user-centric music tagging systems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.2%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.0%">
                            Medicine
                        </span>
                <!-- Computer Vision: 2.9 -->
                    
                <!-- Hardware: 2.3 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Decision Trees: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- HPO and AutoML: 1.7 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- 3D: 1.1 -->
                    
                <!-- T2I: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.3654
                </span>
                <a href="https://arxiv.org/abs/2505.17198" target="_blank" rel="noopener noreferrer">LengthLogD: A Length-Stratified Ensemble Framework for Enhanced Peptide Lipophilicity Prediction via Multi-Scale Feature Integration</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Shuang Wu, Meijie Wang, Lun Yu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Peptide compounds demonstrate considerable potential as therapeutic agents due to their high target affinity and low toxicity, yet their drug development is constrained by their low membrane permeability. Molecular weight and peptide length have significant effects on the logD of peptides, which in </span>
                
                <span class="abstract-full" style="display: none;">Peptide compounds demonstrate considerable potential as therapeutic agents due to their high target affinity and low toxicity, yet their drug development is constrained by their low membrane permeability. Molecular weight and peptide length have significant effects on the logD of peptides, which in turn influences their ability to cross biological membranes. However, accurate prediction of peptide logD remains challenging due to the complex interplay between sequence, structure, and ionization states. This study introduces LengthLogD, a predictive framework that establishes specialized models through molecular length stratification while innovatively integrating multi-scale molecular representations. We constructed feature spaces across three hierarchical levels: atomic (10 molecular descriptors), structural (1024-bit Morgan fingerprints), and topological (3 graph-based features including Wiener index), optimized through stratified ensemble learning. An adaptive weight allocation mechanism specifically developed for long peptides significantly enhances model generalizability. Experimental results demonstrate superior performance across all categories: short peptides (R^2=0.855), medium peptides (R^2=0.816), and long peptides (R^2=0.882), with a 34.7% reduction in prediction error for long peptides compared to conventional single-model approaches. Ablation studies confirm: 1) The length-stratified strategy contributes 41.2% to performance improvement; 2) Topological features account for 28.5% of predictive importance. Compared to state-of-the-art models, our method maintains short peptide prediction accuracy while achieving a 25.7% increase in the coefficient of determination (R^2) for long peptides. This research provides a precise logD prediction tool for peptide drug development, particularly demonstrating unique value in optimizing long peptide lead compounds.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.4%">
                            Medicine
                        </span>
                <!-- LLMs: 4.6 -->
                    
                <!-- Computer Vision: 2.4 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.3775
                </span>
                <a href="https://arxiv.org/abs/2505.18125" target="_blank" rel="noopener noreferrer">TabSTAR: A Foundation Tabular Model With Semantically Target-Aware Representations</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Alan Arazi, Eilam Shapira, Roi Reichart
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">While deep learning has achieved remarkable success across many domains, it has historically underperformed on tabular learning tasks, which remain dominated by gradient boosting decision trees (GBDTs). However, recent advancements are paving the way for Tabular Foundation Models, which can leverage</span>
                
                <span class="abstract-full" style="display: none;">While deep learning has achieved remarkable success across many domains, it has historically underperformed on tabular learning tasks, which remain dominated by gradient boosting decision trees (GBDTs). However, recent advancements are paving the way for Tabular Foundation Models, which can leverage real-world knowledge and generalize across diverse datasets, particularly when the data contains free-text. Although incorporating language model capabilities into tabular tasks has been explored, most existing methods utilize static, target-agnostic textual representations, limiting their effectiveness. We introduce TabSTAR: a Foundation Tabular Model with Semantically Target-Aware Representations. TabSTAR is designed to enable transfer learning on tabular data with textual features, with an architecture free of dataset-specific parameters. It unfreezes a pretrained text encoder and takes as input target tokens, which provide the model with the context needed to learn task-specific embeddings. TabSTAR achieves state-of-the-art performance for both medium- and large-sized datasets across known benchmarks of classification tasks with text features, and its pretraining phase exhibits scaling laws in the number of datasets, offering a pathway for further performance improvements.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.4%">
                            Medicine
                        </span>
                <!-- Federated Learning: 3.0 -->
                    
                <!-- LLMs: 2.9 -->
                    
                <!-- Computer Vision: 2.7 -->
                    
                <!-- Evolutionary Algorithms: 2.2 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Quantum Computing: 1.9 -->
                    
                <!-- HPO and AutoML: 1.8 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4081
                </span>
                <a href="https://arxiv.org/abs/2505.17665" target="_blank" rel="noopener noreferrer">EMRA-proxy: Enhancing Multi-Class Region Semantic Segmentation in Remote Sensing Images with Attention Proxy</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yichun Yu, Yuqing Lan, Zhihuan Xing, Xiaoyi Yang, Tingyue Tang, Dan Yu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">High-resolution remote sensing (HRRS) image segmentation is challenging due to complex spatial layouts and diverse object appearances. While CNNs excel at capturing local features, they struggle with long-range dependencies, whereas Transformers can model global context but often neglect local detai</span>
                
                <span class="abstract-full" style="display: none;">High-resolution remote sensing (HRRS) image segmentation is challenging due to complex spatial layouts and diverse object appearances. While CNNs excel at capturing local features, they struggle with long-range dependencies, whereas Transformers can model global context but often neglect local details and are computationally expensive.We propose a novel approach, Region-Aware Proxy Network (RAPNet), which consists of two components: Contextual Region Attention (CRA) and Global Class Refinement (GCR). Unlike traditional methods that rely on grid-based layouts, RAPNet operates at the region level for more flexible segmentation. The CRA module uses a Transformer to capture region-level contextual dependencies, generating a Semantic Region Mask (SRM). The GCR module learns a global class attention map to refine multi-class information, combining the SRM and attention map for accurate segmentation.Experiments on three public datasets show that RAPNet outperforms state-of-the-art methods, achieving superior multi-class segmentation accuracy.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.1%">
                            Medicine
                        </span>
                <!-- GNN: 3.4 -->
                    
                <!-- LLMs: 3.3 -->
                    
                <!-- Computer Vision: 3.1 -->
                    
                <!-- Federated Learning: 2.2 -->
                    
                <!-- 3D: 2.1 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.413
                </span>
                <a href="https://arxiv.org/abs/2505.17544" target="_blank" rel="noopener noreferrer">FreqU-FNet: Frequency-Aware U-Net for Imbalanced Medical Image Segmentation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ruiqi Xing
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Medical image segmentation faces persistent challenges due to severe class imbalance and the frequency-specific distribution of anatomical structures. Most conventional CNN-based methods operate in the spatial domain and struggle to capture minority class signals, often affected by frequency aliasin</span>
                
                <span class="abstract-full" style="display: none;">Medical image segmentation faces persistent challenges due to severe class imbalance and the frequency-specific distribution of anatomical structures. Most conventional CNN-based methods operate in the spatial domain and struggle to capture minority class signals, often affected by frequency aliasing and limited spectral selectivity. Transformer-based models, while powerful in modeling global dependencies, tend to overlook critical local details necessary for fine-grained segmentation. To overcome these limitations, we propose FreqU-FNet, a novel U-shaped segmentation architecture operating in the frequency domain. Our framework incorporates a Frequency Encoder that leverages Low-Pass Frequency Convolution and Daubechies wavelet-based downsampling to extract multi-scale spectral features. To reconstruct fine spatial details, we introduce a Spatial Learnable Decoder (SLD) equipped with an adaptive multi-branch upsampling strategy. Furthermore, we design a frequency-aware loss (FAL) function to enhance minority class learning. Extensive experiments on multiple medical segmentation benchmarks demonstrate that FreqU-FNet consistently outperforms both CNN and Transformer baselines, particularly in handling under-represented classes, by effectively exploiting discriminative frequency bands.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.9%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.7%">
                            LLMs
                        </span>
                <!-- GNN: 3.0 -->
                    
                <!-- Computer Vision: 3.0 -->
                    
                <!-- 3D: 2.2 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Quantum Computing: 1.7 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- T2I: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4167
                </span>
                <a href="https://arxiv.org/abs/2409.03575" target="_blank" rel="noopener noreferrer">Detecting Spatial Dependence in Transcriptomics Data using Vectorised Persistence Diagrams</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Katharina Limbeck, Bastian Rieck
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Evaluating spatial patterns in data is an integral task across various domains, including geostatistics, astronomy, and spatial tissue biology. The analysis of transcriptomics data in particular relies on methods for detecting spatially-dependent features that exhibit significant spatial patterns fo</span>
                
                <span class="abstract-full" style="display: none;">Evaluating spatial patterns in data is an integral task across various domains, including geostatistics, astronomy, and spatial tissue biology. The analysis of transcriptomics data in particular relies on methods for detecting spatially-dependent features that exhibit significant spatial patterns for both explanatory analysis and feature selection. However, given the complex and high-dimensional nature of these data, there is a need for robust, stable, and reliable descriptors of spatial dependence. We leverage the stability and multiscale properties of persistent homology to address this task. To this end, we introduce a novel framework using functional topological summaries, such as Betti curves and persistence landscapes, for identifying and describing non-random patterns in spatial data. In particular, we propose a non-parametric one-sample permutation test for spatial dependence and investigate its utility across both simulated and real spatial omics data. Our vectorised approach outperforms baseline methods at accurately detecting spatial dependence. Further, we find that our method is more robust to outliers than alternative tests using Moran's I.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.0%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.4%">
                            Medicine
                        </span>
                <!-- Datasets: 2.4 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Federated Learning: 1.5 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- T2I: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4613
                </span>
                <a href="https://arxiv.org/abs/2407.21077" target="_blank" rel="noopener noreferrer">Genetic Instruct: Scaling up Synthetic Generation of Coding Instructions for Large Language Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Somshubra Majumdar, Vahid Noroozi, Mehrzad Samadi, Sean Narenthiran, Aleksander Ficek, Wasi Uddin Ahmad, Jocelyn Huang, Jagadeesh Balam, Boris Ginsburg
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Large Language Models (LLMs) require high quality instruction data for effective alignment, particularly in code generation tasks where expert curated datasets are expensive to produce. We present Genetic-Instruct, a scalable algorithm for synthesizing large-scale, high quality coding instructions u</span>
                
                <span class="abstract-full" style="display: none;">Large Language Models (LLMs) require high quality instruction data for effective alignment, particularly in code generation tasks where expert curated datasets are expensive to produce. We present Genetic-Instruct, a scalable algorithm for synthesizing large-scale, high quality coding instructions using evolutionary principles. Starting from a small set of seed instructions, Genetic-Instruct generates diverse and challenging instruction-code pairs by leveraging an Instructor-LLM for generation, a Coder-LLM for code synthesis, and a Judge-LLM for automatic quality evaluation. Our proposed approach is highly parallelizable and effective even with a small seed data and weaker generator models. We generated more than 7.5 million coding instructions with the proposed approach. Then we evaluated it by fine-tuning LLMs with the synthetic samples and demonstrated a significant improvement in their code generation capability compared to the other synthetic generation approaches and publicly available datasets. Our results highlight the efficiency, scalability, and generalizability of the Genetic-Instruct framework.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 11.5%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.5%">
                            Medicine
                        </span>
                <!-- Datasets: 2.4 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- 3D: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4834
                </span>
                <a href="https://arxiv.org/abs/2505.18015" target="_blank" rel="noopener noreferrer">SemSegBench & DetecBench: Benchmarking Reliability and Generalization Beyond Classification</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Shashank Agnihotri, David Schader, Jonas Jakubassa, Nico Sharei, Simon Kral, Mehmet Ege Ka\c{c}ar, Ruben Weber, Margret Keuper
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Reliability and generalization in deep learning are predominantly studied in the context of image classification. Yet, real-world applications in safety-critical domains involve a broader set of semantic tasks, such as semantic segmentation and object detection, which come with a diverse set of dedi</span>
                
                <span class="abstract-full" style="display: none;">Reliability and generalization in deep learning are predominantly studied in the context of image classification. Yet, real-world applications in safety-critical domains involve a broader set of semantic tasks, such as semantic segmentation and object detection, which come with a diverse set of dedicated model architectures. To facilitate research towards robust model design in segmentation and detection, our primary objective is to provide benchmarking tools regarding robustness to distribution shifts and adversarial manipulations. We propose the benchmarking tools SEMSEGBENCH and DETECBENCH, along with the most extensive evaluation to date on the reliability and generalization of semantic segmentation and object detection models. In particular, we benchmark 76 segmentation models across four datasets and 61 object detectors across two datasets, evaluating their performance under diverse adversarial attacks and common corruptions. Our findings reveal systematic weaknesses in state-of-the-art models and uncover key trends based on architecture, backbone, and model capacity. SEMSEGBENCH and DETECBENCH are open-sourced in our GitHub repository (https://github.com/shashankskagnihotri/benchmarking_reliability_generalization) along with our complete set of total 6139 evaluations. We anticipate the collected data to foster and encourage future research towards improved model reliability beyond classification.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 7.3%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.1%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 6.1%">
                            Computer Vision
                        </span>
                <!-- Datasets: 2.1 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                <!-- Hardware: 1.4 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.4954
                </span>
                <a href="https://arxiv.org/abs/2505.13880" target="_blank" rel="noopener noreferrer">U-SAM: An audio language Model for Unified Speech, Audio, and Music Understanding</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ziqian Wang, Xianjun Xia, Xinfa Zhu, Lei Xie
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The text generation paradigm for audio tasks has opened new possibilities for unified audio understanding. However, existing models face significant challenges in achieving a comprehensive understanding across diverse audio types, such as speech, general audio events, and music. Furthermore, their e</span>
                
                <span class="abstract-full" style="display: none;">The text generation paradigm for audio tasks has opened new possibilities for unified audio understanding. However, existing models face significant challenges in achieving a comprehensive understanding across diverse audio types, such as speech, general audio events, and music. Furthermore, their exclusive reliance on cross-entropy loss for alignment often falls short, as it treats all tokens equally and fails to account for redundant audio features, leading to weaker cross-modal alignment. To deal with the above challenges, this paper introduces U-SAM, an advanced audio language model that integrates specialized encoders for speech, audio, and music with a pre-trained large language model (LLM). U-SAM employs a Mixture of Experts (MoE) projector for task-aware feature fusion, dynamically routing and integrating the domain-specific encoder outputs. Additionally, U-SAM incorporates a Semantic-Aware Contrastive Loss Module, which explicitly identifies redundant audio features under language supervision and rectifies their semantic and spectral representations to enhance cross-modal alignment. Extensive experiments demonstrate that U-SAM consistently outperforms both specialized models and existing audio language models across multiple benchmarks. Moreover, it exhibits emergent capabilities on unseen tasks, showcasing its generalization potential. Code is available (https://github.com/Honee-W/U-SAM/).</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 11.1%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.6%">
                            Medicine
                        </span>
                <!-- Computer Vision: 3.1 -->
                    
                <!-- Hardware: 2.4 -->
                    
                <!-- HPO and AutoML: 1.8 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- T2I: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.5618
                </span>
                <a href="https://arxiv.org/abs/2505.18039" target="_blank" rel="noopener noreferrer">Clip4Retrofit: Enabling Real-Time Image Labeling on Edge Devices via Cross-Architecture CLIP Distillation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Li Zhong, Ahmed Ghazal, Jun-Jun Wan, Frederik Zilly, Patrick Mackens, Joachim E. Vollrath, Bogdan Sorin Coseriu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Foundation models like CLIP (Contrastive Language-Image Pretraining) have revolutionized vision-language tasks by enabling zero-shot and few-shot learning through cross-modal alignment. However, their computational complexity and large memory footprint make them unsuitable for deployment on resource</span>
                
                <span class="abstract-full" style="display: none;">Foundation models like CLIP (Contrastive Language-Image Pretraining) have revolutionized vision-language tasks by enabling zero-shot and few-shot learning through cross-modal alignment. However, their computational complexity and large memory footprint make them unsuitable for deployment on resource-constrained edge devices, such as in-car cameras used for image collection and real-time processing. To address this challenge, we propose Clip4Retrofit, an efficient model distillation framework that enables real-time image labeling on edge devices. The framework is deployed on the Retrofit camera, a cost-effective edge device retrofitted into thousands of vehicles, despite strict limitations on compute performance and memory. Our approach distills the knowledge of the CLIP model into a lightweight student model, combining EfficientNet-B3 with multi-layer perceptron (MLP) projection heads to preserve cross-modal alignment while significantly reducing computational requirements. We demonstrate that our distilled model achieves a balance between efficiency and performance, making it ideal for deployment in real-world scenarios. Experimental results show that Clip4Retrofit can perform real-time image labeling and object identification on edge devices with limited resources, offering a practical solution for applications such as autonomous driving and retrofitting existing systems. This work bridges the gap between state-of-the-art vision-language models and their deployment in resource-constrained environments, paving the way for broader adoption of foundation models in edge computing.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.8%">
                            Medicine
                        </span>
                <!-- Computer Vision: 4.3 -->
                    
                <!-- LLMs: 4.2 -->
                    
                <!-- Hardware: 2.7 -->
                    
                <!-- Federated Learning: 2.1 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- HPO and AutoML: 1.4 -->
                    
                <!-- 3D: 1.3 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- GNN: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.5734
                </span>
                <a href="https://arxiv.org/abs/2505.13052" target="_blank" rel="noopener noreferrer">Model Selection for Gaussian-gated Gaussian Mixture of Experts Using Dendrograms of Mixing Measures</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Tuan Thai, TrungTin Nguyen, Dat Do, Nhat Ho, Christopher Drovandi
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Mixture of Experts (MoE) models constitute a widely utilized class of ensemble learning approaches in statistics and machine learning, known for their flexibility and computational efficiency. They have become integral components in numerous state-of-the-art deep neural network architectures, partic</span>
                
                <span class="abstract-full" style="display: none;">Mixture of Experts (MoE) models constitute a widely utilized class of ensemble learning approaches in statistics and machine learning, known for their flexibility and computational efficiency. They have become integral components in numerous state-of-the-art deep neural network architectures, particularly for analyzing heterogeneous data across diverse domains. Despite their practical success, the theoretical understanding of model selection, especially concerning the optimal number of mixture components or experts, remains limited and poses significant challenges. These challenges primarily stem from the inclusion of covariates in both the Gaussian gating functions and expert networks, which introduces intrinsic interactions governed by partial differential equations with respect to their parameters. In this paper, we revisit the concept of dendrograms of mixing measures and introduce a novel extension to Gaussian-gated Gaussian MoE models that enables consistent estimation of the true number of mixture components and achieves the pointwise optimal convergence rate for parameter estimation in overfitted scenarios. Notably, this approach circumvents the need to train and compare a range of models with varying numbers of components, thereby alleviating the computational burden, particularly in high-dimensional or deep neural network settings. Experimental results on synthetic data demonstrate the effectiveness of the proposed method in accurately recovering the number of experts. It outperforms common criteria such as the Akaike information criterion, the Bayesian information criterion, and the integrated completed likelihood, while achieving optimal convergence rates for parameter estimation and accurately approximating the regression function.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.8%">
                            Medicine
                        </span>
                <!-- Federated Learning: 3.3 -->
                    
                <!-- Hardware: 3.0 -->
                    
                <!-- LLMs: 2.9 -->
                    
                <!-- Bayesian Optimization: 2.7 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Computer Vision: 1.2 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.5892
                </span>
                <a href="https://arxiv.org/abs/2407.02495" target="_blank" rel="noopener noreferrer">Minds, Brains, AI</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jay Seitz
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In the last year or so and going back many decades there has been extensive claims by major computational scientists, engineers, and others that AGI, artificial general intelligence, is five or ten years away, but without a scintilla of scientific evidence, for a broad body of these claims. Computer</span>
                
                <span class="abstract-full" style="display: none;">In the last year or so and going back many decades there has been extensive claims by major computational scientists, engineers, and others that AGI, artificial general intelligence, is five or ten years away, but without a scintilla of scientific evidence, for a broad body of these claims. Computers will become conscious, have a theory of mind, think and reason, will become more intelligent than humans, and so on. But the claims are science fiction, not science. This article reviews evidence for the following three propositions using extensive body of scientific research and related sources from the cognitive and neurosciences, evolutionary evidence, linguistics, data science, comparative psychology, self-driving cars, robotics. and the learning sciences. (1) Do computing machines think or reason? (2) Are computing machines sentient or conscious? (3) Do computing machines have a theory of mind?</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.4%">
                            Medicine
                        </span>
                <!-- LLMs: 4.3 -->
                    
                <!-- Blockchain: 2.9 -->
                    
                <!-- Hardware: 2.3 -->
                    
                <!-- Quantum Computing: 2.2 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 1.9 -->
                    
                <!-- Datasets: 1.5 -->
                    
                <!-- GNN: 1.1 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                <!-- 3D: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.7167
                </span>
                <a href="https://arxiv.org/abs/2505.17141" target="_blank" rel="noopener noreferrer">Fashion Industry in the Age of Generative Artificial Intelligence and Metaverse: A systematic Review</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Rania Ahmed, Eman Ahmed, Ahmed Elbarbary, Ashraf Darwish, Aboul Ella Hassanien
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The fashion industry is an extremely profitable market that generates trillions of dollars in revenue by producing and distributing apparel, footwear, and accessories. This systematic literature review (SLR) seeks to systematically review and analyze the research landscape about the Generative Artif</span>
                
                <span class="abstract-full" style="display: none;">The fashion industry is an extremely profitable market that generates trillions of dollars in revenue by producing and distributing apparel, footwear, and accessories. This systematic literature review (SLR) seeks to systematically review and analyze the research landscape about the Generative Artificial Intelligence (GAI) and metaverse in the fashion industry. Thus, investigating the impact of integrating both technologies to enhance the fashion industry. This systematic review uses the Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) methodology, including three essential phases: identification, evaluation, and reporting. In the identification phase, the target search problems are determined by selecting appropriate keywords and alternative synonyms. After that 578 documents from 2014 to the end of 2023 are retrieved. The evaluation phase applies three screening steps to assess papers and choose 118 eligible papers for full-text reading. Finally, the reporting phase thoroughly examines and synthesizes the 118 eligible papers to identify key themes associated with GAI and Metaverse in the fashion industry. Based on Strengths, Weaknesses, Opportunities, and Threats (SWOT) analyses performed for both GAI and metaverse for the fashion industry, it is concluded that the integration of GAI and the metaverse holds the capacity to profoundly revolutionize the fashion sector, presenting chances for improved manufacturing, design, sales, and client experiences. Accordingly, the research proposes a new framework to integrate GAI and metaverse to enhance the fashion industry. The framework presents different use cases to promote the fashion industry using the integration. Future research points for achieving a successful integration are demonstrated.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.2%">
                            Medicine
                        </span>
                <!-- Computer Vision: 2.2 -->
                    
                <!-- LLMs: 1.8 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Federated Learning: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.7169
                </span>
                <a href="https://arxiv.org/abs/2505.17057" target="_blank" rel="noopener noreferrer">Equilibrium-distribution-function based mesoscopic finite-difference methods for partial differential equations: Modeling and Analysis</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Baochang shi, Rui Du, Zhenhua Chai
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">In this paper, based on the idea of direct modeling with equilibrium distribution functions (EDFs) we develop a general framework of mesoscopic numerical method (MesoNM) for macroscopic partial differential equations (PDEs), including but not limited to nonlinear convection-diffusion equation (NCDE)</span>
                
                <span class="abstract-full" style="display: none;">In this paper, based on the idea of direct modeling with equilibrium distribution functions (EDFs) we develop a general framework of mesoscopic numerical method (MesoNM) for macroscopic partial differential equations (PDEs), including but not limited to nonlinear convection-diffusion equation (NCDE) and the Navier-Stokes equations (NSEs). Different from the mesoscopic lattice Boltzmann method, this kind of MesoNM is an EDF-based mesoscopic finite-difference (MesoFD) method, and through taking the moments of MesoFD scheme its macroscopic version, called MMFD method, can be derived directly. Both MesoFD scheme and MMFD schemes are muti-level FD methods, MesoFD scheme being mesoscopic, and MMFD scheme being its macroscopic form which has the form of the central FD scheme. They are unified FD schemes for PDEs and can be implicit or explicit forms as needed. The macroscopic moment equations (MEs) can be derived from the MesoFD or MMFD scheme through the Taylor expansion method, and the common PDEs can be recovered from the MEs by using direct Taylor expansion method. Moreover, the stability of MMFD scheme is analyzed for linear CDE with anisotropic diffusion, and the stability conditions of a two-level explicit MMFD scheme and a two-level $\theta$-MMFD scheme (hybrid explicit and implicit MMFD scheme) are obtained, respectively. Finally, we note that some existing lattice Boltzmann (LB) based macroscopic FD models for the NSEs and NCDE are the special cases of present MMFD, which can be considered as a unified framework of FD schemes for PDEs, from this point of view.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.9%">
                            Medicine
                        </span>
                <!-- Federated Learning: 2.4 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Math: 1.8 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- LLMs: 1.7 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Computer Vision: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.7702
                </span>
                <a href="https://arxiv.org/abs/2505.17977" target="_blank" rel="noopener noreferrer">SmartNote: An LLM-Powered, Personalised Release Note Generator That Just Works</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Farbod Daneshyan, Runzhi He, Jianyu Wu, Minghui Zhou
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The release note is a crucial document outlining changes in new software versions. Yet, many developers view the process of writing software release notes as a tedious and dreadful task. Consequently, numerous tools have been developed by researchers and practitioners to automate the generation of s</span>
                
                <span class="abstract-full" style="display: none;">The release note is a crucial document outlining changes in new software versions. Yet, many developers view the process of writing software release notes as a tedious and dreadful task. Consequently, numerous tools have been developed by researchers and practitioners to automate the generation of software release notes. However, these tools fail to consider project domain and target audience for personalisation, limiting their relevance and conciseness. Additionally, they suffer from limited applicability, often necessitating significant workflow adjustments and adoption efforts, hindering practical use and stressing developers. Despite recent advancements in natural language processing and the proven capabilities of large language models in various code and text-related tasks, there are no existing studies investigating the integration and utilisation of LLMs in automated release note generation. Therefore, we propose SmartNote, a novel and widely applicable release note generation approach that produces high-quality, contextually personalised release notes using LLM technology. SmartNote aggregates changes and uses an LLM to describe and summarise the changes using code, commit, and pull request details. It categorises and scores commits to generate structured and concise release notes of prioritised changes. Our human and automatic evaluations reveal that SmartNote outperforms or achieves comparable performance to DeepRelease, Conventional Changelog, and the projects'original release notes across four quality metrics: completeness, clarity, conciseness, and organisation. In both evaluations, SmartNote ranked first for completeness and organisation, while clarity ranked first in the human evaluation. A further evaluation demonstrates that SmartNote is effective in terms of context awareness and applicability.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 24.5%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.1%">
                            Medicine
                        </span>
                <!-- Datasets: 2.3 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                <!-- Robotics: 1.0 -->
                    
                <!-- HPO and AutoML: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.8125
                </span>
                <a href="https://arxiv.org/abs/2505.09473" target="_blank" rel="noopener noreferrer">Function-Correcting $b$-symbol Codes for Locally $(\lambda, \rho,b)$-Functions</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Gyanendra K. Verma, Anamika Singh, Abhay Kumar Singh
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The family of functions plays a central role in the design and effectiveness of function-correcting codes. By focusing on a well-defined family of functions, function-correcting codes can be constructed with minimal length while still ensuring full error detection or correction within that family. I</span>
                
                <span class="abstract-full" style="display: none;">The family of functions plays a central role in the design and effectiveness of function-correcting codes. By focusing on a well-defined family of functions, function-correcting codes can be constructed with minimal length while still ensuring full error detection or correction within that family. In this work, we explore the concept of locally $(\lambda,\rho)$-functions for $b$-symbol read channels and investigate the redundancy of the corresponding function-correcting $b$-symbol codes(FCBSC) by introducing the notions of locally $(\lambda,\rho,b)$-functions. First, we discuss the possible values of $\lambda$ and $\rho$ for which any function can be considered as locally $(\lambda,\rho)$-function in $b$-symbol metric. The findings improve some known results in the Hamming metric and present several new results in the $b$-symbol metric. Then we investigate the redundancy of $(f,t)$-FCBSC for locally $(\lambda,\rho,b)$-functions. We establish a recurrence relation between the optimal redundancy of $(f,t)$ -function-correcting codes for the $(b+1)$-read and $b$-read channels. We establish an upper bound on the redundancy of $(f,t)$-function-correcting $b$-symbol codes for general locally ($\lambda,\rho$, $b$)-functions by linking it to the minimum achievable length of $b$-symbol error-correcting codes and traditional Hamming-metric codes, given a fixed number of codewords and a specified minimum distance. We derive some explicit upper bounds on the redundancy of $(f,t)$-function-correcting $b$-symbol codes for $\rho=2t$. Moreover, for the case where $b=1$, we show that a locally ($3,2t,1$)-function achieves the optimal redundancy of $3t$. Additionally, we explicitly investigate locality and redundancy for the $b$-symbol weight distribution function for $b\geq1$.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 7.2%">
                            Medicine
                        </span>
                <!-- Federated Learning: 2.9 -->
                    
                <!-- Hardware: 2.7 -->
                    
                <!-- Bayesian Optimization: 2.4 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- Math: 1.9 -->
                    
                <!-- Quantum Computing: 1.8 -->
                    
                <!-- Reinforcement Learning: 1.6 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- LLMs: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.9108
                </span>
                <a href="https://arxiv.org/abs/2409.08691" target="_blank" rel="noopener noreferrer">Autoregressive Sequence Modeling for 3D Medical Image Representation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Siwen Wang, Churan Wang, Fei Gao, Lixian Su, Fandong Zhang, Yizhou Wang, Yizhou Yu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Three-dimensional (3D) medical images, such as Computed Tomography (CT) and Magnetic Resonance Imaging (MRI), are essential for clinical applications. However, the need for diverse and comprehensive representations is particularly pronounced when considering the variability across different organs, </span>
                
                <span class="abstract-full" style="display: none;">Three-dimensional (3D) medical images, such as Computed Tomography (CT) and Magnetic Resonance Imaging (MRI), are essential for clinical applications. However, the need for diverse and comprehensive representations is particularly pronounced when considering the variability across different organs, diagnostic tasks, and imaging modalities. How to effectively interpret the intricate contextual information and extract meaningful insights from these images remains an open challenge to the community. While current self-supervised learning methods have shown potential, they often consider an image as a whole thereby overlooking the extensive, complex relationships among local regions from one or multiple images. In this work, we introduce a pioneering method for learning 3D medical image representations through an autoregressive pre-training framework. Our approach sequences various 3D medical images based on spatial, contrast, and semantic correlations, treating them as interconnected visual tokens within a token sequence. By employing an autoregressive sequence modeling task, we predict the next visual token in the sequence, which allows our model to deeply understand and integrate the contextual information inherent in 3D medical images. Additionally, we implement a random startup strategy to avoid overestimating token relationships and to enhance the robustness of learning. The effectiveness of our approach is demonstrated by the superior performance over others on nine downstream tasks in public datasets.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 8.3%">
                            Medicine
                        </span>
                <!-- Computer Vision: 3.2 -->
                    
                <!-- LLMs: 2.3 -->
                    
                <!-- GNN: 2.2 -->
                    
                <!-- 3D: 2.0 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Blockchain: 1.4 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Reinforcement Learning: 1.3 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -1.9233
                </span>
                <a href="https://arxiv.org/abs/2505.17136" target="_blank" rel="noopener noreferrer">Foundation Models for Geospatial Reasoning: Assessing Capabilities of Large Language Models in Understanding Geometries and Topological Spatial Relations</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yuhan Ji, Song Gao, Ying Nie, Ivan Maji\'c, Krzysztof Janowicz
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Applying AI foundation models directly to geospatial datasets remains challenging due to their limited ability to represent and reason with geographical entities, specifically vector-based geometries and natural language descriptions of complex spatial relations. To address these issues, we investig</span>
                
                <span class="abstract-full" style="display: none;">Applying AI foundation models directly to geospatial datasets remains challenging due to their limited ability to represent and reason with geographical entities, specifically vector-based geometries and natural language descriptions of complex spatial relations. To address these issues, we investigate the extent to which a well-known-text (WKT) representation of geometries and their spatial relations (e.g., topological predicates) are preserved during spatial reasoning when the geospatial vector data are passed to large language models (LLMs) including GPT-3.5-turbo, GPT-4, and DeepSeek-R1-14B. Our workflow employs three distinct approaches to complete the spatial reasoning tasks for comparison, i.e., geometry embedding-based, prompt engineering-based, and everyday language-based evaluation. Our experiment results demonstrate that both the embedding-based and prompt engineering-based approaches to geospatial question-answering tasks with GPT models can achieve an accuracy of over 0.6 on average for the identification of topological spatial relations between two geometries. Among the evaluated models, GPT-4 with few-shot prompting achieved the highest performance with over 0.66 accuracy on topological spatial relation inference. Additionally, GPT-based reasoner is capable of properly comprehending inverse topological spatial relations and including an LLM-generated geometry can enhance the effectiveness for geographic entity retrieval. GPT-4 also exhibits the ability to translate certain vernacular descriptions about places into formal topological relations, and adding the geometry-type or place-type context in prompts may improve inference accuracy, but it varies by instance. The performance of these spatial reasoning tasks offers valuable insights for the refinement of LLMs with geographical knowledge towards the development of geo-foundation models capable of geospatial reasoning.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 12.3%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.0%">
                            Medicine
                        </span>
                <!-- Federated Learning: 2.9 -->
                    
                <!-- Evolutionary Algorithms: 2.3 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Datasets: 1.0 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.0301
                </span>
                <a href="https://arxiv.org/abs/2505.17674" target="_blank" rel="noopener noreferrer">SVL: Spike-based Vision-language Pretraining for Efficient 3D Open-world Understanding</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Xuerui Qiu, Peixi Wu, Yaozhi Wen, Shaowei Gu, Yuqi Pan, Xinhao Luo, Bo XU, Guoqi Li
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Spiking Neural Networks (SNNs) provide an energy-efficient way to extract 3D spatio-temporal features. However, existing SNNs still exhibit a significant performance gap compared to Artificial Neural Networks (ANNs) due to inadequate pre-training strategies. These limitations manifest as restricted </span>
                
                <span class="abstract-full" style="display: none;">Spiking Neural Networks (SNNs) provide an energy-efficient way to extract 3D spatio-temporal features. However, existing SNNs still exhibit a significant performance gap compared to Artificial Neural Networks (ANNs) due to inadequate pre-training strategies. These limitations manifest as restricted generalization ability, task specificity, and a lack of multimodal understanding, particularly in challenging tasks such as multimodal question answering and zero-shot 3D classification. To overcome these challenges, we propose a Spike-based Vision-Language (SVL) pretraining framework that empowers SNNs with open-world 3D understanding while maintaining spike-driven efficiency. SVL introduces two key components: (i) Multi-scale Triple Alignment (MTA) for label-free triplet-based contrastive learning across 3D, image, and text modalities, and (ii) Re-parameterizable Vision-Language Integration (Rep-VLI) to enable lightweight inference without relying on large text encoders. Extensive experiments show that SVL achieves a top-1 accuracy of 85.4% in zero-shot 3D classification, surpassing advanced ANN models, and consistently outperforms prior SNNs on downstream tasks, including 3D classification (+6.1%), DVS action recognition (+2.1%), 3D detection (+1.1%), and 3D segmentation (+2.1%) with remarkable efficiency. Moreover, SVL enables SNNs to perform open-world 3D question answering, sometimes outperforming ANNs. To the best of our knowledge, SVL represents the first scalable, generalizable, and hardware-friendly paradigm for 3D open-world understanding, effectively bridging the gap between SNNs and ANNs in complex open-world understanding tasks. Code is available https://github.com/bollossom/SVL.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #76aa96" title="Confidence: 8.0%">
                            3D
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.3%">
                            Medicine
                        </span>
                <!-- LLMs: 3.7 -->
                    
                <!-- GNN: 2.2 -->
                    
                <!-- Computer Vision: 2.0 -->
                    
                <!-- Federated Learning: 1.6 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- T2I: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.3422
                </span>
                <a href="https://arxiv.org/abs/2505.15180" target="_blank" rel="noopener noreferrer">NeuBM: Mitigating Model Bias in Graph Neural Networks through Neutral Input Calibration</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jiawei Gu, Ziyue Qiao, Xiao Luo
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Graph Neural Networks (GNNs) have shown remarkable performance across various domains, yet they often struggle with model bias, particularly in the presence of class imbalance. This bias can lead to suboptimal performance and unfair predictions, especially for underrepresented classes. We introduce </span>
                
                <span class="abstract-full" style="display: none;">Graph Neural Networks (GNNs) have shown remarkable performance across various domains, yet they often struggle with model bias, particularly in the presence of class imbalance. This bias can lead to suboptimal performance and unfair predictions, especially for underrepresented classes. We introduce NeuBM (Neutral Bias Mitigation), a novel approach to mitigate model bias in GNNs through neutral input calibration. NeuBM leverages a dynamically updated neutral graph to estimate and correct the inherent biases of the model. By subtracting the logits obtained from the neutral graph from those of the input graph, NeuBM effectively recalibrates the model's predictions, reducing bias across different classes. Our method integrates seamlessly into existing GNN architectures and training procedures, requiring minimal computational overhead. Extensive experiments on multiple benchmark datasets demonstrate that NeuBM significantly improves the balanced accuracy and recall of minority classes, while maintaining strong overall performance. The effectiveness of NeuBM is particularly pronounced in scenarios with severe class imbalance and limited labeled data, where traditional methods often struggle. We provide theoretical insights into how NeuBM achieves bias mitigation, relating it to the concept of representation balancing. Our analysis reveals that NeuBM not only adjusts the final predictions but also influences the learning of balanced feature representations throughout the network.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #b243cd" title="Confidence: 6.1%">
                            GNN
                        </span>
                <!-- Medicine: 3.5 -->
                    
                <!-- LLMs: 3.5 -->
                    
                <!-- Federated Learning: 2.7 -->
                    
                <!-- Computer Vision: 2.4 -->
                    
                <!-- Reinforcement Learning: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- Hardware: 1.3 -->
                    
                <!-- Decision Trees: 1.3 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Robotics: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.3423
                </span>
                <a href="https://arxiv.org/abs/2505.17972" target="_blank" rel="noopener noreferrer">MR-EEGWaveNet: Multiresolutional EEGWaveNet for Seizure Detection from Long EEG Recordings</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Kazi Mahmudul Hassan, Xuyang Zhao, Hidenori Sugano, Toshihisa Tanaka
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Feature engineering for generalized seizure detection models remains a significant challenge. Recently proposed models show variable performance depending on the training data and remain ineffective at accurately distinguishing artifacts from seizure data. In this study, we propose a novel end-to-en</span>
                
                <span class="abstract-full" style="display: none;">Feature engineering for generalized seizure detection models remains a significant challenge. Recently proposed models show variable performance depending on the training data and remain ineffective at accurately distinguishing artifacts from seizure data. In this study, we propose a novel end-to-end model, ''Multiresolutional EEGWaveNet (MR-EEGWaveNet),'' which efficiently distinguishes seizure events from background electroencephalogram (EEG) and artifacts/noise by capturing both temporal dependencies across different time frames and spatial relationships between channels. The model has three modules: convolution, feature extraction, and predictor. The convolution module extracts features through depth-wise and spatio-temporal convolution. The feature extraction module individually reduces the feature dimension extracted from EEG segments and their sub-segments. Subsequently, the extracted features are concatenated into a single vector for classification using a fully connected classifier called the predictor module. In addition, an anomaly score-based post-classification processing technique was introduced to reduce the false-positive rates of the model. Experimental results were reported and analyzed using different parameter settings and datasets (Siena (public) and Juntendo (private)). The proposed MR-EEGWaveNet significantly outperformed the conventional non-multiresolution approach, improving the F1 scores from 0.177 to 0.336 on Siena and 0.327 to 0.488 on Juntendo, with precision gains of 15.9% and 20.62%, respectively.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 10.1%">
                            Medicine
                        </span>
                <!-- Computer Vision: 4.8 -->
                    
                <!-- LLMs: 2.7 -->
                    
                <!-- Hardware: 2.3 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- 3D: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.2 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.5436
                </span>
                <a href="https://arxiv.org/abs/2505.17293" target="_blank" rel="noopener noreferrer">Model-Free Graph Data Selection under Distribution Shift</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ting-Wei Li, Ruizhong Qiu, Hanghang Tong
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Graph domain adaptation (GDA) is a fundamental task in graph machine learning, with techniques like shift-robust graph neural networks (GNNs) and specialized training procedures to tackle the distribution shift problem. Although these model-centric approaches show promising results, they often strug</span>
                
                <span class="abstract-full" style="display: none;">Graph domain adaptation (GDA) is a fundamental task in graph machine learning, with techniques like shift-robust graph neural networks (GNNs) and specialized training procedures to tackle the distribution shift problem. Although these model-centric approaches show promising results, they often struggle with severe shifts and constrained computational resources. To address these challenges, we propose a novel model-free framework, GRADATE (GRAph DATa sElector), that selects the best training data from the source domain for the classification task on the target domain. GRADATE picks training samples without relying on any GNN model's predictions or training recipes, leveraging optimal transport theory to capture and adapt to distribution changes. GRADATE is data-efficient, scalable and meanwhile complements existing model-centric GDA approaches. Through comprehensive empirical studies on several real-world graph-level datasets and multiple covariate shift types, we demonstrate that GRADATE outperforms existing selection methods and enhances off-the-shelf GDA methods with much fewer training data.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #b243cd" title="Confidence: 6.6%">
                            GNN
                        </span>
                <!-- Medicine: 3.8 -->
                    
                <!-- Computer Vision: 3.6 -->
                    
                <!-- LLMs: 2.4 -->
                    
                <!-- HPO and AutoML: 2.3 -->
                    
                <!-- Federated Learning: 2.3 -->
                    
                <!-- 3D: 1.7 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.3 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.6533
                </span>
                <a href="https://arxiv.org/abs/2505.17640" target="_blank" rel="noopener noreferrer">A Network Science Approach to Granular Time Series Segmentation</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ivana Kesi\'c, Carolina Fortuna, Mihael Mohor\v{c}i\v{c}, Bla\v{z} Bertalani\v{c}
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Time series segmentation (TSS) is one of the time series (TS) analysis techniques, that has received considerably less attention compared to other TS related tasks. In recent years, deep learning architectures have been introduced for TSS, however their reliance on sliding windows limits segmentatio</span>
                
                <span class="abstract-full" style="display: none;">Time series segmentation (TSS) is one of the time series (TS) analysis techniques, that has received considerably less attention compared to other TS related tasks. In recent years, deep learning architectures have been introduced for TSS, however their reliance on sliding windows limits segmentation granularity due to fixed window sizes and strides. To overcome these challenges, we propose a new more granular TSS approach that utilizes the Weighted Dual Perspective Visbility Graph (WDPVG) TS into a graph and combines it with a Graph Attention Network (GAT). By transforming TS into graphs, we are able to capture different structural aspects of the data that would otherwise remain hidden. By utilizing the representation learning capabilities of Graph Neural Networks, our method is able to effectively identify meaningful segments within the TS. To better understand the potential of our approach, we also experimented with different TS-to-graph transformations and compared their performance. Our contributions include: a) formulating the TSS as a node classification problem on graphs; b) conducting an extensive analysis of various TS- to-graph transformations applied to TSS using benchmark datasets from the TSSB repository; c) providing the first detailed study on utilizing GNNs for analyzing graph representations of TS in the context of TSS; d) demonstrating the effectiveness of our method, which achieves an average F1 score of 0.97 across 59 diverse TSS benchmark datasets; e) outperforming the seq2point baseline method by 0.05 in terms of F1 score; and f) reducing the required training data compared to the baseline methods.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #b243cd" title="Confidence: 5.7%">
                            GNN
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #b3ebae" title="Confidence: 5.2%">
                            Federated Learning
                        </span>
                <!-- Medicine: 4.4 -->
                    
                <!-- Evolutionary Algorithms: 2.4 -->
                    
                <!-- LLMs: 1.9 -->
                    
                <!-- Reinforcement Learning: 1.8 -->
                    
                <!-- Bayesian Optimization: 1.7 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Computer Vision: 1.3 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Hardware: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.6602
                </span>
                <a href="https://arxiv.org/abs/2505.17484" target="_blank" rel="noopener noreferrer">Anatomy-Guided Multitask Learning for MRI-Based Classification of Placenta Accreta Spectrum and its Subtypes</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Hai Jiang, Qiongting Liu, Yuanpin Zhou, Jiawei Pan, Ting Song, Yao Lu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Placenta Accreta Spectrum Disorders (PAS) pose significant risks during pregnancy, frequently leading to postpartum hemorrhage during cesarean deliveries and other severe clinical complications, with bleeding severity correlating to the degree of placental invasion. Consequently, accurate prenatal d</span>
                
                <span class="abstract-full" style="display: none;">Placenta Accreta Spectrum Disorders (PAS) pose significant risks during pregnancy, frequently leading to postpartum hemorrhage during cesarean deliveries and other severe clinical complications, with bleeding severity correlating to the degree of placental invasion. Consequently, accurate prenatal diagnosis of PAS and its subtypes-placenta accreta (PA), placenta increta (PI), and placenta percreta (PP)-is crucial. However, existing guidelines and methodologies predominantly focus on the presence of PAS, with limited research addressing subtype recognition. Additionally, previous multi-class diagnostic efforts have primarily relied on inefficient two-stage cascaded binary classification tasks. In this study, we propose a novel convolutional neural network (CNN) architecture designed for efficient one-stage multiclass diagnosis of PAS and its subtypes, based on 4,140 magnetic resonance imaging (MRI) slices. Our model features two branches: the main classification branch utilizes a residual block architecture comprising multiple residual blocks, while the second branch integrates anatomical features of the uteroplacental area and the adjacent uterine serous layer to enhance the model's attention during classification. Furthermore, we implement a multitask learning strategy to leverage both branches effectively. Experiments conducted on a real clinical dataset demonstrate that our model achieves state-of-the-art performance.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 9.8%">
                            Medicine
                        </span>
                <!-- LLMs: 3.6 -->
                    
                <!-- Federated Learning: 3.5 -->
                    
                <!-- Computer Vision: 2.6 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Blockchain: 1.9 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- 3D: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.8146
                </span>
                <a href="https://arxiv.org/abs/2504.20118" target="_blank" rel="noopener noreferrer">OpenTCM: A GraphRAG-Empowered LLM-based System for Traditional Chinese Medicine Knowledge Retrieval and Diagnosis</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jinglin He, Yunqi Guo, Lai Kwan Lam, Waikei Leung, Lixing He, Yuanan Jiang, Chi Chiu Wang, Guoliang Xing, Hongkai Chen
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Traditional Chinese Medicine (TCM) represents a rich repository of ancient medical knowledge that continues to play an important role in modern healthcare. Due to the complexity and breadth of the TCM literature, the integration of AI technologies is critical for its modernization and broader access</span>
                
                <span class="abstract-full" style="display: none;">Traditional Chinese Medicine (TCM) represents a rich repository of ancient medical knowledge that continues to play an important role in modern healthcare. Due to the complexity and breadth of the TCM literature, the integration of AI technologies is critical for its modernization and broader accessibility. However, this integration poses considerable challenges, including the interpretation of obscure classical Chinese texts and the modeling of intricate semantic relationships among TCM concepts. In this paper, we develop OpenTCM, an LLM-based system that combines a domain-specific TCM knowledge graph and Graph-based Retrieval-Augmented Generation (GraphRAG). First, we extract more than 3.73 million classical Chinese characters from 68 gynecological books in the Chinese Medical Classics Database, with the help of TCM and gynecology experts. Second, we construct a comprehensive multi-relational knowledge graph comprising more than 48,000 entities and 152,000 interrelationships, using customized prompts and Chinese-oriented LLMs such as DeepSeek and Kimi to ensure high-fidelity semantic understanding. Last, we integrate OpenTCM with this knowledge graph, enabling high-fidelity ingredient knowledge retrieval and diagnostic question-answering without model fine-tuning. Experimental evaluations demonstrate that our prompt design and model selection significantly improve knowledge graph quality, achieving a precision of 98. 55% and an F1 score of 99. 55%. In addition, OpenTCM achieves mean expert scores of 4.5 in ingredient information retrieval and 3.8 in diagnostic question-answering tasks, outperforming state-of-the-art solutions in real-world TCM use cases.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 10.6%">
                            LLMs
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 9.0%">
                            Medicine
                        </span>
                <!-- Blockchain: 1.9 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Datasets: 1.7 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- GNN: 1.3 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -2.8294
                </span>
                <a href="https://arxiv.org/abs/2505.17367" target="_blank" rel="noopener noreferrer">EVM-Fusion: An Explainable Vision Mamba Architecture with Neural Algorithmic Fusion</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Zichuan Yang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Medical image classification is critical for clinical decision-making, yet demands for accuracy, interpretability, and generalizability remain challenging. This paper introduces EVM-Fusion, an Explainable Vision Mamba architecture featuring a novel Neural Algorithmic Fusion (NAF) mechanism for multi</span>
                
                <span class="abstract-full" style="display: none;">Medical image classification is critical for clinical decision-making, yet demands for accuracy, interpretability, and generalizability remain challenging. This paper introduces EVM-Fusion, an Explainable Vision Mamba architecture featuring a novel Neural Algorithmic Fusion (NAF) mechanism for multi-organ medical image classification. EVM-Fusion leverages a multipath design, where DenseNet and U-Net based pathways, enhanced by Vision Mamba (Vim) modules, operate in parallel with a traditional feature pathway. These diverse features are dynamically integrated via a two-stage fusion process: cross-modal attention followed by the iterative NAF block, which learns an adaptive fusion algorithm. Intrinsic explainability is embedded through path-specific spatial attention, Vim {\Delta}-value maps, traditional feature SE-attention, and cross-modal attention weights. Experiments on a diverse 9-class multi-organ medical image dataset demonstrate EVM-Fusion's strong classification performance, achieving 99.75% test accuracy and provide multi-faceted insights into its decision-making process, highlighting its potential for trustworthy AI in medical diagnostics.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 13.2%">
                            Medicine
                        </span>
                <!-- LLMs: 3.5 -->
                    
                <!-- Computer Vision: 2.4 -->
                    
                <!-- 3D: 2.4 -->
                    
                <!-- HPO and AutoML: 2.1 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Datasets: 1.7 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- T2I: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.1272
                </span>
                <a href="https://arxiv.org/abs/2505.17647" target="_blank" rel="noopener noreferrer">4D-CTA Image and geometry dataset for kinematic analysis of abdominal aortic aneurysms</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Mostafa Jamshidian, Adam Wittek, Saeideh Sekhavat, Farah Alkhatib, Jens Carsten Ritter, Paul M. Parizel, Donatien Le Liepvre, Florian Bernard, Ludovic Minvielle, Antoine Fondan\`eche, Jane Polce, Christopher Wood, Karol Miller
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This article presents a dataset used in the article "Kinematics of Abdominal Aortic Aneurysms" [arXiv:2405.13377], published in the Journal of Biomechanics. The dataset is publicly available for download from the Zenodo data repository (https://doi.org/10.5281/zenodo.15477710). The dataset includes </span>
                
                <span class="abstract-full" style="display: none;">This article presents a dataset used in the article "Kinematics of Abdominal Aortic Aneurysms" [arXiv:2405.13377], published in the Journal of Biomechanics. The dataset is publicly available for download from the Zenodo data repository (https://doi.org/10.5281/zenodo.15477710). The dataset includes time-resolved 3D computed tomography angiography (4D-CTA) images of abdominal aortic aneurysm (AAA) captured throughout the cardiac cycle from ten patients diagnosed with AAA, along with ten patient-specific AAA geometries extracted from these images. Typically, the 4D-CTA dataset for each patient contains ten electrocardiogram (ECG)-gated 3D-CTA image frames acquired over a cardiac cycle, capturing both the systolic and diastolic phases of the AAA configuration. For method verification, the dataset also includes synthetic ground truth data generated from Patient 1's 3D-CTA AAA image in the diastolic phase. The ground truth data includes the patient-specific finite element (FE) biomechanical model and a synthetic systolic 3D-CTA image. The synthetic systolic image was generated by warping Patient 1's diastolic 3D-CTA image using the realistic displacement field obtained from the AAA biomechanical FE model. The images were acquired at Fiona Stanley Hospital in Western Australia and provided to the researchers at the Intelligent Systems for Medicine Laboratory at The University of Western Australia (ISML-UWA), where image-based AAA kinematic analysis was performed. Our dataset enabled the analysis of AAA wall displacement and strain throughout the cardiac cycle using a non-invasive, in vivo, image registration-based approach. The use of widely adopted, open-source file formats (NRRD for images and STL for geometries) facilitates broad applicability and reusability in AAA biomechanics studies that require patient-specific geometry and information about AAA kinematics during cardiac cycle.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 13.6%">
                            Medicine
                        </span>
                <!-- Datasets: 4.2 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- LLMs: 1.4 -->
                    
                <!-- Robotics: 1.1 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Finance: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                <!-- Math: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.1518
                </span>
                <a href="https://arxiv.org/abs/2505.18002" target="_blank" rel="noopener noreferrer">Rethinking Contrastive Learning in Graph Anomaly Detection: A Clean-View Perspective</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Di Jin, Jingyi Cao, Xiaobao Wang, Bingdao Feng, Dongxiao He, Longbiao Wang, Jianwu Dang
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Graph anomaly detection aims to identify unusual patterns in graph-based data, with wide applications in fields such as web security and financial fraud detection. Existing methods typically rely on contrastive learning, assuming that a lower similarity between a node and its local subgraph indicate</span>
                
                <span class="abstract-full" style="display: none;">Graph anomaly detection aims to identify unusual patterns in graph-based data, with wide applications in fields such as web security and financial fraud detection. Existing methods typically rely on contrastive learning, assuming that a lower similarity between a node and its local subgraph indicates abnormality. However, these approaches overlook a crucial limitation: the presence of interfering edges invalidates this assumption, since it introduces disruptive noise that compromises the contrastive learning process. Consequently, this limitation impairs the ability to effectively learn meaningful representations of normal patterns, leading to suboptimal detection performance. To address this issue, we propose a Clean-View Enhanced Graph Anomaly Detection framework (CVGAD), which includes a multi-scale anomaly awareness module to identify key sources of interference in the contrastive learning process. Moreover, to mitigate bias from the one-step edge removal process, we introduce a novel progressive purification module. This module incrementally refines the graph by iteratively identifying and removing interfering edges, thereby enhancing model performance. Extensive experiments on five benchmark datasets validate the effectiveness of our approach.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #b243cd" title="Confidence: 7.6%">
                            GNN
                        </span>
                <!-- LLMs: 3.5 -->
                    
                <!-- Federated Learning: 3.5 -->
                    
                <!-- Computer Vision: 2.2 -->
                    
                <!-- Medicine: 2.1 -->
                    
                <!-- Blockchain: 1.8 -->
                    
                <!-- Reinforcement Learning: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.5 -->
                    
                <!-- Quantum Computing: 1.4 -->
                    
                <!-- 3D: 1.1 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.5453
                </span>
                <a href="https://arxiv.org/abs/2409.04491" target="_blank" rel="noopener noreferrer">Protein sequence classification using natural language processing techniques</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Huma Perveen (School of Mathematical and Physical Sciences, University of Sussex, Brighton, UK), Julie Weeds (School of Engineering and Informatics, University of Sussex, Brighton, UK)
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Purpose: This study aimed to enhance protein sequence classification using natural language processing (NLP) techniques while addressing the impact of sequence similarity on model performance. We compared various machine learning and deep learning models under two different data-splitting strategies</span>
                
                <span class="abstract-full" style="display: none;">Purpose: This study aimed to enhance protein sequence classification using natural language processing (NLP) techniques while addressing the impact of sequence similarity on model performance. We compared various machine learning and deep learning models under two different data-splitting strategies: random splitting and ECOD family-based splitting, which ensures evolutionary-related sequences are grouped together. Methods: The study evaluated models such as K-Nearest Neighbors (KNN), Multinomial Na\"ive Bayes, Logistic Regression, Multi-Layer Perceptron (MLP), Decision Tree, Random Forest, XGBoost, Voting and Stacking classifiers, Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM), and transformer models (BertForSequenceClassification, DistilBERT, and ProtBert). Performance was tested using different amino acid ranges and sequence lengths with a focus on generalization across unseen evolutionary families. Results: The Voting classifier achieved the highest performance with 74% accuracy, 74% weighted F1 score, and 65% macro F1 score under random splitting, while ProtBERT obtained 77% accuracy, 76% weighted F1 score, and 61% macro F1 score among transformer models. However, performance declined across all models when tested using ECOD-based splitting, revealing the impact of sequence similarity on classification performance. Conclusion: Advanced NLP techniques, particularly ensemble methods like Voting classifiers, and transformer models show significant potential in protein classification, with sufficient training data and sequence similarity management being crucial for optimal performance. However, the use of biologically meaningful splitting methods, such as ECOD family-based splitting, is crucial for realistic performance evaluation and generalization to unseen evolutionary families.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 14.0%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.4%">
                            LLMs
                        </span>
                <!-- Blockchain: 2.4 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- Hardware: 2.2 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- HPO and AutoML: 1.9 -->
                    
                <!-- Datasets: 1.9 -->
                    
                <!-- Federated Learning: 1.8 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- GNN: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.7422
                </span>
                <a href="https://arxiv.org/abs/2505.17363" target="_blank" rel="noopener noreferrer">Are GNNs Worth the Effort for IoT Botnet Detection? A Comparative Study of VAE-GNN vs. ViT-MLP and VAE-MLP Approaches</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Hassan Wasswa, Hussein Abbass, Timothy Lynar
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Due to the exponential rise in IoT-based botnet attacks, researchers have explored various advanced techniques for both dimensionality reduction and attack detection to enhance IoT security. Among these, Variational Autoencoders (VAE), Vision Transformers (ViT), and Graph Neural Networks (GNN), incl</span>
                
                <span class="abstract-full" style="display: none;">Due to the exponential rise in IoT-based botnet attacks, researchers have explored various advanced techniques for both dimensionality reduction and attack detection to enhance IoT security. Among these, Variational Autoencoders (VAE), Vision Transformers (ViT), and Graph Neural Networks (GNN), including Graph Convolutional Networks (GCN) and Graph Attention Networks (GAT), have garnered significant research attention in the domain of attack detection. This study evaluates the effectiveness of four state-of-the-art deep learning architectures for IoT botnet detection: a VAE encoder with a Multi-Layer Perceptron (MLP), a VAE encoder with a GCN, a VAE encoder with a GAT, and a ViT encoder with an MLP. The evaluation is conducted on a widely studied IoT benchmark dataset--the N-BaIoT dataset for both binary and multiclass tasks. For the binary classification task, all models achieved over 99.93% in accuracy, recall, precision, and F1-score, with no notable differences in performance. In contrast, for the multiclass classification task, GNN-based models showed significantly lower performance compared to VAE-MLP and ViT-MLP, with accuracies of 86.42%, 89.46%, 99.72%, and 98.38% for VAE-GCN, VAE-GAT, VAE-MLP, and ViT-MLP, respectively.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 13.7%">
                            Medicine
                        </span>
                <!-- LLMs: 2.6 -->
                    
                <!-- GNN: 2.0 -->
                    
                <!-- Hardware: 2.0 -->
                    
                <!-- Datasets: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Computer Vision: 1.6 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -3.8356
                </span>
                <a href="https://arxiv.org/abs/2505.17677" target="_blank" rel="noopener noreferrer">Towards Dynamic 3D Reconstruction of Hand-Instrument Interaction in Ophthalmic Surgery</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Ming Hu, Zhendi Yu, Feilong Tang, Kaiwen Chen, Yulong Li, Imran Razzak, Junjun He, Tolga Birdal, Kaijing Zhou, Zongyuan Ge
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Accurate 3D reconstruction of hands and instruments is critical for vision-based analysis of ophthalmic microsurgery, yet progress has been hampered by the lack of realistic, large-scale datasets and reliable annotation tools. In this work, we introduce OphNet-3D, the first extensive RGB-D dynamic 3</span>
                
                <span class="abstract-full" style="display: none;">Accurate 3D reconstruction of hands and instruments is critical for vision-based analysis of ophthalmic microsurgery, yet progress has been hampered by the lack of realistic, large-scale datasets and reliable annotation tools. In this work, we introduce OphNet-3D, the first extensive RGB-D dynamic 3D reconstruction dataset for ophthalmic surgery, comprising 41 sequences from 40 surgeons and totaling 7.1 million frames, with fine-grained annotations of 12 surgical phases, 10 instrument categories, dense MANO hand meshes, and full 6-DoF instrument poses. To scalably produce high-fidelity labels, we design a multi-stage automatic annotation pipeline that integrates multi-view data observation, data-driven motion prior with cross-view geometric consistency and biomechanical constraints, along with a combination of collision-aware interaction constraints for instrument interactions. Building upon OphNet-3D, we establish two challenging benchmarks-bimanual hand pose estimation and hand-instrument interaction reconstruction-and propose two dedicated architectures: H-Net for dual-hand mesh recovery and OH-Net for joint reconstruction of two-hand-two-instrument interactions. These models leverage a novel spatial reasoning module with weak-perspective camera modeling and collision-aware center-based representation. Both architectures outperform existing methods by substantial margins, achieving improvements of over 2mm in Mean Per Joint Position Error (MPJPE) and up to 23% in ADD-S metrics for hand and instrument reconstruction, respectively.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 13.8%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.6%">
                            LLMs
                        </span>
                <!-- Datasets: 3.1 -->
                    
                <!-- Hardware: 2.3 -->
                    
                <!-- 3D: 2.2 -->
                    
                <!-- Federated Learning: 1.7 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Quantum Computing: 1.3 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.3579
                </span>
                <a href="https://arxiv.org/abs/2311.06358" target="_blank" rel="noopener noreferrer">Compact Matrix Quantum Group Equivariant Neural Networks</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Edward Pearce-Crump
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Group equivariant neural networks have proven effective in modelling a wide range of tasks where the data lives in a classical geometric space and exhibits well-defined group symmetries. However, these networks are not suitable for learning from data that lives in a non-commutative geometry, describ</span>
                
                <span class="abstract-full" style="display: none;">Group equivariant neural networks have proven effective in modelling a wide range of tasks where the data lives in a classical geometric space and exhibits well-defined group symmetries. However, these networks are not suitable for learning from data that lives in a non-commutative geometry, described formally by non-commutative $C^{*}$-algebras, since the $C^{*}$-algebra of continuous functions on a compact matrix group is commutative. To address this limitation, we derive the existence of a new type of equivariant neural network, called compact matrix quantum group equivariant neural networks, which encode symmetries that are described by compact matrix quantum groups. We characterise the weight matrices that appear in these neural networks for the easy compact matrix quantum groups, which are defined by set partitions. As a result, we obtain new characterisations of equivariant weight matrices for some compact matrix groups that have not appeared previously in the machine learning literature.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 7.6%">
                            Quantum Computing
                        </span>
                <!-- GNN: 3.7 -->
                    
                <!-- Medicine: 2.1 -->
                    
                <!-- LLMs: 2.0 -->
                    
                <!-- Federated Learning: 1.9 -->
                    
                <!-- Blockchain: 1.7 -->
                    
                <!-- Math: 1.5 -->
                    
                <!-- Bayesian Optimization: 1.5 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Evolutionary Algorithms: 1.4 -->
                    
                <!-- Cryptography: 1.4 -->
                    
                <!-- Datasets: 1.4 -->
                    
                <!-- Networks: 1.2 -->
                    
                <!-- Game Theory: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -4.4712
                </span>
                <a href="https://arxiv.org/abs/2505.17133" target="_blank" rel="noopener noreferrer">Learning Probabilities of Causation from Finite Population Data</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Shuai Wang, Song Jiang, Yizhou Sun, Judea Pearl, Ang Li
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Probabilities of causation play a crucial role in modern decision-making. This paper addresses the challenge of predicting probabilities of causation for subpopulations with \textbf{insufficient} data using machine learning models. Tian and Pearl first defined and derived tight bounds for three fund</span>
                
                <span class="abstract-full" style="display: none;">Probabilities of causation play a crucial role in modern decision-making. This paper addresses the challenge of predicting probabilities of causation for subpopulations with \textbf{insufficient} data using machine learning models. Tian and Pearl first defined and derived tight bounds for three fundamental probabilities of causation: the probability of necessity and sufficiency (PNS), the probability of sufficiency (PS), and the probability of necessity (PN). However, estimating these probabilities requires both experimental and observational distributions specific to each subpopulation, which are often unavailable or impractical to obtain with limited population-level data. Therefore, for most subgroups, the amount of data they have is not enough to guarantee the accuracy of their probabilities. Hence, to estimate these probabilities for subpopulations with \textbf{insufficient} data, we propose using machine learning models that draw insights from subpopulations with sufficient data. Our evaluation of multiple machine learning models indicates that, given the population-level data and an appropriate choice of machine learning model and activation function, PNS can be effectively predicted. Through simulation studies on multiple Structured Causal Models (SCMs), we show that our multilayer perceptron (MLP) model with the Mish activation function achieves a mean absolute error (MAE) of approximately $0.02$ in predicting PNS for $32,768$ subpopulations across most SCMs using data from only $2,000$ subpopulations with known PNS values.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 16.2%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #b3ebae" title="Confidence: 5.0%">
                            Federated Learning
                        </span>
                <!-- LLMs: 2.9 -->
                    
                <!-- Evolutionary Algorithms: 2.8 -->
                    
                <!-- Quantum Computing: 2.1 -->
                    
                <!-- Bayesian Optimization: 1.8 -->
                    
                <!-- Datasets: 1.7 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- GNN: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -5.2442
                </span>
                <a href="https://arxiv.org/abs/2505.17096" target="_blank" rel="noopener noreferrer">TAGS: 3D Tumor-Adaptive Guidance for SAM</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Sirui Li, Linkai Peng, Zheyuan Zhang, Gorkem Durak, Ulas Bagci
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Foundation models (FMs) such as CLIP and SAM have recently shown great promise in image segmentation tasks, yet their adaptation to 3D medical imaging-particularly for pathology detection and segmentation-remains underexplored. A critical challenge arises from the domain gap between natural images a</span>
                
                <span class="abstract-full" style="display: none;">Foundation models (FMs) such as CLIP and SAM have recently shown great promise in image segmentation tasks, yet their adaptation to 3D medical imaging-particularly for pathology detection and segmentation-remains underexplored. A critical challenge arises from the domain gap between natural images and medical volumes: existing FMs, pre-trained on 2D data, struggle to capture 3D anatomical context, limiting their utility in clinical applications like tumor segmentation. To address this, we propose an adaptation framework called TAGS: Tumor Adaptive Guidance for SAM, which unlocks 2D FMs for 3D medical tasks through multi-prompt fusion. By preserving most of the pre-trained weights, our approach enhances SAM's spatial feature extraction using CLIP's semantic insights and anatomy-specific prompts. Extensive experiments on three open-source tumor segmentation datasets prove that our model surpasses the state-of-the-art medical image segmentation models (+46.88% over nnUNet), interactive segmentation frameworks, and other established medical FMs, including SAM-Med2D, SAM-Med3D, SegVol, Universal, 3D-Adapter, and SAM-B (at least +13% over them). This highlights the robustness and adaptability of our proposed framework across diverse medical segmentation tasks.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 23.8%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #753a22" title="Confidence: 5.5%">
                            Computer Vision
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.1%">
                            LLMs
                        </span>
                <!-- 3D: 3.6 -->
                    
                <!-- Hardware: 1.7 -->
                    
                <!-- Decision Trees: 1.5 -->
                    
                <!-- Blockchain: 1.5 -->
                    
                <!-- Datasets: 1.3 -->
                    
                <!-- GNN: 1.2 -->
                    
                <!-- Federated Learning: 1.2 -->
                    
                <!-- Quantum Computing: 1.2 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Evolutionary Algorithms: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -5.9754
                </span>
                <a href="https://arxiv.org/abs/2505.17971" target="_blank" rel="noopener noreferrer">Explainable Anatomy-Guided AI for Prostate MRI: Foundation Models and In Silico Clinical Trials for Virtual Biopsy-based Risk Assessment</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Danial Khan, Zohaib Salahuddin, Yumeng Zhang, Sheng Kuang, Shruti Atul Mali, Henry C. Woodruff, Sina Amirrajab, Rachel Cavill, Eduardo Ibor-Crespo, Ana Jimenez-Pastor, Adrian Galiana-Bordera, Paula Jimenez Gomez, Luis Marti-Bonmati, Philippe Lambin
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We present a fully automated, anatomically guided deep learning pipeline for prostate cancer (PCa) risk stratification using routine MRI. The pipeline integrates three key components: an nnU-Net module for segmenting the prostate gland and its zones on axial T2-weighted MRI; a classification module </span>
                
                <span class="abstract-full" style="display: none;">We present a fully automated, anatomically guided deep learning pipeline for prostate cancer (PCa) risk stratification using routine MRI. The pipeline integrates three key components: an nnU-Net module for segmenting the prostate gland and its zones on axial T2-weighted MRI; a classification module based on the UMedPT Swin Transformer foundation model, fine-tuned on 3D patches with optional anatomical priors and clinical data; and a VAE-GAN framework for generating counterfactual heatmaps that localize decision-driving image regions. The system was developed using 1,500 PI-CAI cases for segmentation and 617 biparametric MRIs with metadata from the CHAIMELEON challenge for classification (split into 70% training, 10% validation, and 20% testing). Segmentation achieved mean Dice scores of 0.95 (gland), 0.94 (peripheral zone), and 0.92 (transition zone). Incorporating gland priors improved AUC from 0.69 to 0.72, with a three-scale ensemble achieving top performance (AUC = 0.79, composite score = 0.76), outperforming the 2024 CHAIMELEON challenge winners. Counterfactual heatmaps reliably highlighted lesions within segmented regions, enhancing model interpretability. In a prospective multi-center in-silico trial with 20 clinicians, AI assistance increased diagnostic accuracy from 0.72 to 0.77 and Cohen's kappa from 0.43 to 0.53, while reducing review time per case by 40%. These results demonstrate that anatomy-aware foundation models with counterfactual explainability can enable accurate, interpretable, and efficient PCa risk assessment, supporting their potential use as virtual biopsies in clinical practice.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 23.9%">
                            Medicine
                        </span>
                <!-- LLMs: 3.1 -->
                    
                <!-- Computer Vision: 2.6 -->
                    
                <!-- 3D: 2.0 -->
                    
                <!-- HPO and AutoML: 1.8 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Quantum Computing: 1.5 -->
                    
                <!-- Federated Learning: 1.3 -->
                    
                <!-- Datasets: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -6.0311
                </span>
                <a href="https://arxiv.org/abs/2405.20237" target="_blank" rel="noopener noreferrer">Training-efficient density quantum machine learning</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Brian Coyle, Snehal Raj, Natansh Mathur, El Amine Cherrat, Nishant Jain, Skander Kazdaghli, Iordanis Kerenidis
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Quantum machine learning (QML) requires powerful, flexible and efficiently trainable models to be successful in solving challenging problems. We introduce density quantum neural networks, a model family that prepares mixtures of trainable unitaries, with a distributional constraint over coefficients</span>
                
                <span class="abstract-full" style="display: none;">Quantum machine learning (QML) requires powerful, flexible and efficiently trainable models to be successful in solving challenging problems. We introduce density quantum neural networks, a model family that prepares mixtures of trainable unitaries, with a distributional constraint over coefficients. This framework balances expressivity and efficient trainability, especially on quantum hardware. For expressivity, the Hastings-Campbell Mixing lemma converts benefits from linear combination of unitaries into density models with similar performance guarantees but shallower circuits. For trainability, commuting-generator circuits enable density model construction with efficiently extractable gradients. The framework connects to various facets of QML including post-variational and measurement-based learning. In classical settings, density models naturally integrate the mixture of experts formalism, and offer natural overfitting mitigation. The framework is versatile - we uplift several quantum models into density versions to improve model performance, or trainability, or both. These include Hamming weight-preserving and equivariant models, among others. Extensive numerical experiments validate our findings.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 8.0%">
                            Quantum Computing
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 6.7%">
                            Medicine
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 6.3%">
                            LLMs
                        </span>
                <!-- Federated Learning: 2.4 -->
                    
                <!-- Decision Trees: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- HPO and AutoML: 1.6 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- 3D: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Datasets: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -6.4511
                </span>
                <a href="https://arxiv.org/abs/2505.17034" target="_blank" rel="noopener noreferrer">Preparing for the Post Quantum Era: Quantum Ready Architecture for Security and Risk Management (QUASAR) -- A Strategic Framework for Cybersecurity</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Abraham Itzhak Weinberg
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">As quantum computing progresses, traditional cryptographic systems face the threat of obsolescence due to the capabilities of quantum algorithms. This paper introduces the Quantum-Ready Architecture for Security and Risk Management (QUASAR), a novel framework designed to help organizations prepare f</span>
                
                <span class="abstract-full" style="display: none;">As quantum computing progresses, traditional cryptographic systems face the threat of obsolescence due to the capabilities of quantum algorithms. This paper introduces the Quantum-Ready Architecture for Security and Risk Management (QUASAR), a novel framework designed to help organizations prepare for the post-quantum era. QUASAR provides a structured approach to transition from current cryptographic systems to quantum-resistant alternatives, emphasizing technical, security, and operational readiness. The framework integrates a set of actionable components, a timeline for phased implementation, and continuous optimization strategies to ensure ongoing preparedness. Through performance indicators, readiness scores, and optimization functions, QUASAR enables organizations to assess their current state, identify gaps, and execute targeted actions to mitigate risks posed by quantum computing. By offering a comprehensive, adaptable, and quantifiable strategy, QUASAR equips organizations with the tools necessary to future-proof their operations and secure sensitive data against the impending rise of quantum technologies.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 6.1%">
                            Quantum Computing
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #4ff278" title="Confidence: 5.2%">
                            Medicine
                        </span>
                <!-- Evolutionary Algorithms: 2.7 -->
                    
                <!-- LLMs: 2.2 -->
                    
                <!-- Hardware: 2.1 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -6.5202
                </span>
                <a href="https://arxiv.org/abs/2411.11369" target="_blank" rel="noopener noreferrer">Exact Quantum Algorithm for Unit Commitment Optimization based on Partially Connected Quantum Neural Networks</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Jian Liu, Xu Zhou, Zhuojun Zhou, Le Luo
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">The quantum hybrid algorithm has become a very promising and speedily method today for solving the larger-scale optimization in the noisy intermediate-scale quantum (NISQ) era. The unit commitment (UC) problem is a fundamental problem in the power system which aims to satisfy a balance load with min</span>
                
                <span class="abstract-full" style="display: none;">The quantum hybrid algorithm has become a very promising and speedily method today for solving the larger-scale optimization in the noisy intermediate-scale quantum (NISQ) era. The unit commitment (UC) problem is a fundamental problem in the power system which aims to satisfy a balance load with minimal cost. In this paper, we focus on the implement of the UC-solving by exact quantum algorithms based on the quantum neural network (QNN). This method is tested with up to 10-unit system with the balance load constraint. In order to improve the computing precision and reduce the network complexity, we suggest the knowledge-based partially connected quantum neural network (PCQNN). The results show that the exact solutions can be obtained by the improved algorithm and the depth of the quantum circuit can be reduced simultaneously.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 10.6%">
                            Quantum Computing
                        </span>
                <!-- Evolutionary Algorithms: 3.7 -->
                    
                <!-- Federated Learning: 3.5 -->
                    
                <!-- Cryptography: 2.5 -->
                    
                <!-- Math: 2.4 -->
                    
                <!-- Computer Vision: 1.7 -->
                    
                <!-- Reinforcement Learning: 1.7 -->
                    
                <!-- Bayesian Optimization: 1.6 -->
                    
                <!-- Medicine: 1.5 -->
                    
                <!-- Finance: 1.3 -->
                    
                <!-- Networks: 1.2 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- GNN: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -6.9094
                </span>
                <a href="https://arxiv.org/abs/2504.08456" target="_blank" rel="noopener noreferrer">Generalization Bounds in Hybrid Quantum-Classical Machine Learning Models</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Tongyan Wu, Amine Bentellis, Alona Sakhnenko, Jeanette Miriam Lorenz
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Hybrid classical-quantum models aim to harness the strengths of both quantum computing and classical machine learning, but their practical potential remains poorly understood. In this work, we develop a unified mathematical framework for analyzing generalization in hybrid models, offering insight in</span>
                
                <span class="abstract-full" style="display: none;">Hybrid classical-quantum models aim to harness the strengths of both quantum computing and classical machine learning, but their practical potential remains poorly understood. In this work, we develop a unified mathematical framework for analyzing generalization in hybrid models, offering insight into how these systems learn from data. We establish a novel generalization bound of the form $O\big( \sqrt{\frac{T\log{T}}{N}} + \frac{\alpha}{\sqrt{N}}\big)$ for $N$ training data points, $T$ trainable quantum gates, and bounded fully-connected layers $||F|| \leq \alpha$. This bound decomposes cleanly into quantum and classical contributions, extending prior work on both components and clarifying their interaction. We apply our results to the quantum-classical convolutional neural network (QCCNN), an architecture that integrates quantum convolutional layers with classical processing. Alongside the bound, we highlight conceptual limitations of applying classical statistical learning theory in the hybrid setting and suggest promising directions for future theoretical work.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 11.2%">
                            Quantum Computing
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.3%">
                            LLMs
                        </span>
                <!-- Medicine: 4.0 -->
                    
                <!-- Computer Vision: 2.3 -->
                    
                <!-- Hardware: 1.6 -->
                    
                <!-- GNN: 1.5 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                <!-- Reinforcement Learning: 1.4 -->
                    
                <!-- Evolutionary Algorithms: 1.2 -->
                    
                <!-- Blockchain: 1.2 -->
                    
                <!-- Decision Trees: 1.2 -->
                    
                <!-- HPO and AutoML: 1.1 -->
                    
                <!-- Datasets: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -7.4602
                </span>
                <a href="https://arxiv.org/abs/2505.18133" target="_blank" rel="noopener noreferrer">Joint Encryption and Error Correction for Secure Quantum Communication</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Nitin Jha, Abhishek Parakh, Mahadevan Subramaniam
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Secure quantum networks are a bedrock requirement for developing a future quantum internet. However, quantum channels are susceptible to channel noise that introduce errors in the transmitted data. The traditional approach to providing error correction typically encapsulates the message in an error </span>
                
                <span class="abstract-full" style="display: none;">Secure quantum networks are a bedrock requirement for developing a future quantum internet. However, quantum channels are susceptible to channel noise that introduce errors in the transmitted data. The traditional approach to providing error correction typically encapsulates the message in an error correction code after encryption. Such separate processes incur overhead that must be avoided when possible. We, consequently, provide a single integrated process that allows for encryption as well as error correction. This is a first attempt to do so for secure quantum communication and combines the Calderbank-Shor-Steane (CSS) code with the three-stage secure quantum communication protocol. Lastly, it allows for arbitrary qubits to be transmitted from sender to receiver making the proposed protocol general purpose.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 14.9%">
                            Quantum Computing
                        </span>
                <!-- Networks: 2.2 -->
                    
                <!-- Cryptography: 1.8 -->
                    
                <!-- Medicine: 1.7 -->
                    
                <!-- GNN: 1.7 -->
                    
                <!-- Evolutionary Algorithms: 1.6 -->
                    
                <!-- Computer Vision: 1.5 -->
                    
                <!-- Decision Trees: 1.4 -->
                    
                <!-- LLMs: 1.4 -->
                    
                <!-- HPO and AutoML: 1.3 -->
                    
                <!-- Federated Learning: 1.1 -->
                    
                <!-- Hardware: 1.1 -->
                    
                <!-- Game Theory: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                <!-- Math: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.0 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -8.2955
                </span>
                <a href="https://arxiv.org/abs/2401.10579" target="_blank" rel="noopener noreferrer">Trade-offs between classical and quantum space using spooky pebbling</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Arend-Jan Quist, Alfons Laarman
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Pebble games are used to study space/time trade-offs. Recently, spooky pebble games were introduced to study classical space / quantum space / time trade-offs for simulation of classical circuits on quantum computers. In this paper, the spooky pebble game framework is applied for the first time to g</span>
                
                <span class="abstract-full" style="display: none;">Pebble games are used to study space/time trade-offs. Recently, spooky pebble games were introduced to study classical space / quantum space / time trade-offs for simulation of classical circuits on quantum computers. In this paper, the spooky pebble game framework is applied for the first time to general circuits. Using this framework we prove an upper bound for quantum space in the spooky pebble game. We also prove that solving the spooky pebble game is PSPACE-complete. Moreover, we present a solver for the spooky pebble game based on satisfiability solvers combined with heuristic optimizers. This spooky pebble game solver was empirically evaluated by calculating optimal classical space / quantum space / time trade-offs. Within limited runtime, the solver could find a strategy reducing quantum space when classical space is taken into account, showing that the spooky pebble model is useful to reduce quantum space.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 16.6%">
                            Quantum Computing
                        </span>
                <!-- Computer Vision: 2.0 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Cryptography: 1.9 -->
                    
                <!-- Math: 1.9 -->
                    
                <!-- Networks: 1.9 -->
                    
                <!-- Evolutionary Algorithms: 1.8 -->
                    
                <!-- Medicine: 1.7 -->
                    
                <!-- Game Theory: 1.5 -->
                    
                <!-- LLMs: 1.4 -->
                    
                <!-- GNN: 1.4 -->
                    
                <!-- Finance: 1.3 -->
                    
                <!-- HPO and AutoML: 1.2 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Decision Trees: 1.1 -->
                    
                <!-- Reinforcement Learning: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -8.5713
                </span>
                <a href="https://arxiv.org/abs/2505.17756" target="_blank" rel="noopener noreferrer">Qiskit Machine Learning: an open-source library for quantum machine learning tasks at scale on quantum hardware and classical simulators</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: M. Emre Sahin, Edoardo Altamura, Oscar Wallis, Stephen P. Wood, Anton Dekusar, Declan A. Millar, Takashi Imamichi, Atsushi Matsuo, Stefano Mensa
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">We present Qiskit Machine Learning (ML), a high-level Python library that combines elements of quantum computing with traditional machine learning. The API abstracts Qiskit's primitives to facilitate interactions with classical simulators and quantum hardware. Qiskit ML started as a proof-of-concept</span>
                
                <span class="abstract-full" style="display: none;">We present Qiskit Machine Learning (ML), a high-level Python library that combines elements of quantum computing with traditional machine learning. The API abstracts Qiskit's primitives to facilitate interactions with classical simulators and quantum hardware. Qiskit ML started as a proof-of-concept code in 2019 and has since been developed to be a modular, intuitive tool for non-specialist users while allowing extensibility and fine-tuning controls for quantum computational scientists and developers. The library is available as a public, open-source tool and is distributed under the Apache version 2.0 license.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #d37d97" title="Confidence: 13.9%">
                            Quantum Computing
                        </span>
                <!-- Medicine: 4.7 -->
                    
                <!-- HPO and AutoML: 2.4 -->
                    
                <!-- LLMs: 2.3 -->
                    
                <!-- Evolutionary Algorithms: 2.1 -->
                    
                <!-- Hardware: 1.8 -->
                    
                <!-- 3D: 1.8 -->
                    
                <!-- Decision Trees: 1.6 -->
                    
                <!-- Datasets: 1.6 -->
                    
                <!-- Blockchain: 1.6 -->
                    
                <!-- Computer Vision: 1.4 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                <!-- GNN: 1.3 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -9.1107
                </span>
                <a href="https://arxiv.org/abs/2501.04600" target="_blank" rel="noopener noreferrer">Do Automated Fixes Truly Mitigate Smart Contract Exploits?</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Sofia Bobadilla, Monica Jin, Martin Monperrus
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Automated Program Repair (APR) for smart contract security promises to automatically mitigate smart contract vulnerabilities responsible for billions in financial losses. However, the true effectiveness of this research in addressing smart contract exploits remains uncharted territory. This paper br</span>
                
                <span class="abstract-full" style="display: none;">Automated Program Repair (APR) for smart contract security promises to automatically mitigate smart contract vulnerabilities responsible for billions in financial losses. However, the true effectiveness of this research in addressing smart contract exploits remains uncharted territory. This paper bridges this critical gap by introducing a novel and systematic experimental framework for evaluating exploit mitigation of program repair tools for smart contracts. We qualitatively and quantitatively analyze 20 state-of-the-art APR tools using a dataset of 143 vulnerable smart contracts, for which we manually craft 91 executable exploits. We are the very first to define and measure the essential "exploit mitigation rate" , giving researchers and practitioners a real sense of effectiveness of cutting edge techniques. Our findings reveal substantial disparities in the state of the art, with an exploit mitigation rate ranging from a low of 29% to a high of 74%. Our study identifies systemic limitations, such as inconsistent functionality preservation, that must be addressed in future research on program repair for smart contracts.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #3cc377" title="Confidence: 6.1%">
                            Blockchain
                        </span>
                <!-- LLMs: 3.5 -->
                    
                <!-- Medicine: 3.3 -->
                    
                <!-- Federated Learning: 2.0 -->
                    
                <!-- Evolutionary Algorithms: 2.0 -->
                    
                <!-- Hardware: 1.9 -->
                    
                <!-- Datasets: 1.9 -->
                    
                <!-- Quantum Computing: 1.6 -->
                    
                <!-- Bayesian Optimization: 1.3 -->
                    
                <!-- Computer Vision: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -12.3548
                </span>
                <a href="https://arxiv.org/abs/2505.17416" target="_blank" rel="noopener noreferrer">LLM-BSCVM: An LLM-Based Blockchain Smart Contract Vulnerability Management Framework</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Yanli Jin, Chunpei Li, Peng Fan, Peng Liu, Xianxian Li, Chen Liu, Wangjie Qiu
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">Smart contracts are a key component of the Web 3.0 ecosystem, widely applied in blockchain services and decentralized applications. However, the automated execution feature of smart contracts makes them vulnerable to potential attacks due to inherent flaws, which can lead to severe security risks an</span>
                
                <span class="abstract-full" style="display: none;">Smart contracts are a key component of the Web 3.0 ecosystem, widely applied in blockchain services and decentralized applications. However, the automated execution feature of smart contracts makes them vulnerable to potential attacks due to inherent flaws, which can lead to severe security risks and financial losses, even threatening the integrity of the entire decentralized finance system. Currently, research on smart contract vulnerabilities has evolved from traditional program analysis methods to deep learning techniques, with the gradual introduction of Large Language Models. However, existing studies mainly focus on vulnerability detection, lacking systematic cause analysis and Vulnerability Repair. To address this gap, we propose LLM-BSCVM, a Large Language Model-based smart contract vulnerability management framework, designed to provide end-to-end vulnerability detection, analysis, repair, and evaluation capabilities for Web 3.0 ecosystem. LLM-BSCVM combines retrieval-augmented generation technology and multi-agent collaboration, introducing a three-stage method of Decompose-Retrieve-Generate. This approach enables smart contract vulnerability management through the collaborative efforts of six intelligent agents, specifically: vulnerability detection, cause analysis, repair suggestion generation, risk assessment, vulnerability repair, and patch evaluation. Experimental results demonstrate that LLM-BSCVM achieves a vulnerability detection accuracy and F1 score exceeding 91\% on benchmark datasets, comparable to the performance of state-of-the-art (SOTA) methods, while reducing the false positive rate from 7.2\% in SOTA methods to 5.1\%, thus enhancing the reliability of vulnerability management. Furthermore, LLM-BSCVM supports continuous security monitoring and governance of smart contracts through a knowledge base hot-swapping dynamic update mechanism.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge low-confidence" style="background-color: #3cc377" title="Confidence: 9.0%">
                            Blockchain
                        </span>
                <span class="tag-badge low-confidence" style="background-color: #5f6936" title="Confidence: 5.1%">
                            LLMs
                        </span>
                <!-- Medicine: 3.3 -->
                    
                <!-- Federated Learning: 3.2 -->
                    
                <!-- Computer Vision: 1.8 -->
                    
                <!-- Evolutionary Algorithms: 1.7 -->
                    
                <!-- GNN: 1.6 -->
                    
                <!-- Reinforcement Learning: 1.5 -->
                    
                <!-- Hardware: 1.2 -->
                    
                <!-- Quantum Computing: 1.1 -->
                    
                <!-- Bayesian Optimization: 1.1 -->
                    
                
            </div>
        </div>
        
        <div class="paper">
            <div class="paper-title">
                <span class="interestingness-score interestingness-negative">
                    -67.7087
                </span>
                <a href="https://arxiv.org/abs/2412.18208" target="_blank" rel="noopener noreferrer">Quantum framework for Reinforcement Learning: integrating Markov Decision Process, quantum arithmetic, and trajectory search</a>
                <span class="copy-icon" onclick="event.stopPropagation(); showJson(this.closest('.paper'))">ðŸ“‹</span>
            </div>
            <div class="paper-meta">
                Authors: Thet Htar Su, Shaswot Shresthamali, Masaaki Kondo
            </div>
            <div class="paper-abstract">
                <span class="abstract-short">This paper introduces a quantum framework for addressing reinforcement learning (RL) tasks, grounded in the quantum principles and leveraging a fully quantum model of the classical Markov Decision Process (MDP). By employing quantum concepts and a quantum search algorithm, this work presents the imp</span>
                
                <span class="abstract-full" style="display: none;">This paper introduces a quantum framework for addressing reinforcement learning (RL) tasks, grounded in the quantum principles and leveraging a fully quantum model of the classical Markov Decision Process (MDP). By employing quantum concepts and a quantum search algorithm, this work presents the implementation and optimization of the agent-environment interactions entirely within the quantum domain, eliminating reliance on classical computations. Key contributions include the quantum-based state transitions, return calculation, and trajectory search mechanism that utilize quantum principles to demonstrate the realization of RL processes through quantum phenomena. The implementation emphasizes the fundamental role of quantum superposition in enhancing computational efficiency for RL tasks. Results demonstrate the capacity of a quantum model to achieve quantum enhancement in RL, highlighting the potential of fully quantum implementations in decision-making tasks. This work not only underscores the applicability of quantum computing in machine learning but also contributes the field of quantum reinforcement learning (QRL) by offering a robust framework for understanding and exploiting quantum computing in RL systems.</span>
                <span class="more-link" onclick="toggleAbstract(this)">... more</span>
                
            </div>
            <div class="paper-tags"><span class="tag-badge high-confidence" style="background-color: #d37d97" title="Confidence: 76.2%">
                            Quantum Computing
                        </span>
                <!-- Medicine: 2.7 -->
                    
                <!-- Evolutionary Algorithms: 2.5 -->
                    
                <!-- Reinforcement Learning: 2.0 -->
                    
                <!-- Hardware: 1.5 -->
                    
                <!-- Federated Learning: 1.4 -->
                    
                <!-- LLMs: 1.4 -->
                    
                <!-- Bayesian Optimization: 1.2 -->
                    
                <!-- Blockchain: 1.1 -->
                    
                
            </div>
        </div>
        
    </div>
    
    
    <div id="jsonPopup" class="json-popup">
        <pre id="jsonContent"></pre>
        <button onclick="copyJson()">Copy to Clipboard</button>
        <button onclick="closePopup()">Close</button>
    </div>

    <script>
        function extractPaperData(paperElement) {
            const titleElement = paperElement.querySelector('.paper-title a');
            const metaElement = paperElement.querySelector('.paper-meta');
            const abstractElement = paperElement.querySelector('.paper-abstract');
            const tagsElement = paperElement.querySelector('.paper-tags');
            
            // Get the date from the parent date-section header
            const dateSection = paperElement.closest('.date-section');
            const dateText = dateSection.querySelector('.date-header').textContent.trim();
            
            const authorsText = metaElement.textContent.replace('Authors:', '').trim();
            
            const paperData = {
                title: titleElement.textContent,
                url: titleElement.href,
                authors: authorsText.split(',').map(author => author.trim()),
                created: dateText,
                abstract: abstractElement.querySelector('.abstract-full').textContent
            };
            
            return paperData;
        }

        function showJson(paperElement) {
            const popup = document.getElementById('jsonPopup');
            const content = document.getElementById('jsonContent');
            const paperData = extractPaperData(paperElement);
            content.textContent = JSON.stringify(paperData, null, null);
            popup.style.display = 'block';
            document.addEventListener('click', function closePopupOnClick(event) {
                if (!popup.contains(event.target)) {
                    popup.style.display = 'none';
                    document.removeEventListener('click', closePopupOnClick);
                }
            });
        }
        function toggleAbstract(element) {
            const abstract = element.parentElement;
            const short = abstract.querySelector('.abstract-short');
            const full = abstract.querySelector('.abstract-full');
            const lowConfidenceTags = abstract.parentElement.querySelectorAll('.tag-badge.low-confidence');
            
            if (element.textContent === '... more') {
                short.style.display = 'none';
                full.style.display = 'inline';
                element.textContent = ' less';
                lowConfidenceTags.forEach(tag => tag.style.display = 'inline-block');
            } else {
                short.style.display = 'inline';
                full.style.display = 'none';
                element.textContent = '... more';
                lowConfidenceTags.forEach(tag => tag.style.display = 'none');
            }
        }

        function closePopup() {
            document.getElementById('jsonPopup').style.display = 'none';
        }

        function copyJson() {
            const content = document.getElementById('jsonContent').textContent;
            navigator.clipboard.writeText(content).catch(() => {
                // If clipboard API is not available, just show the popup
                alert('Could not copy to clipboard. JSON is displayed in the popup.');
            });
        }

        // Close popup when clicking outside
        window.onclick = function(event) {
            const popup = document.getElementById('jsonPopup');
            if (event.target === popup) {
                popup.style.display = 'none';
            }
        }
    </script>
</body>
</html> 